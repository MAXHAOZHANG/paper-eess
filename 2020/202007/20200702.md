# ArXiv eess --Thu, 2 Jul 2020
### 1.End-to-End JPEG Decoding and Artifacts Suppression Using Heterogeneous Residual Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2007.00639.pdf)
>  Existing deep learning models separate JPEG artifacts suppression from the decoding protocol as independent task. In this work, we take one step forward to design a true end-to-end heterogeneous residual convolutional neural network (HR-CNN) with spectrum decomposition and heterogeneous reconstruction mechanism. Benefitting from the full CNN architecture and GPU acceleration, the proposed model considerably improves the reconstruction efficiency. Numerical experiments show that the overall reconstruction speed reaches to the same magnitude of the standard CPU JPEG decoding protocol, while both decoding and artifacts suppression are completed together. We formulate the JPEG artifacts suppression task as an interactive process of decoding and image detail reconstructions. A heterogeneous, fully convolutional, mechanism is proposed to particularly address the uncorrelated nature of different spectral channels. Directly starting from the JPEG code in k-space, the network first extracts the spectral samples channel by channel, and restores the spectral snapshots with expanded throughput. These intermediate snapshots are then heterogeneously decoded and merged into the pixel space image. A cascaded residual learning segment is designed to further enhance the image details. Experiments verify that the model achieves outstanding performance in JPEG artifacts suppression, while its full convolutional operations and elegant network structure offers higher computational efficiency for practical online usage compared with other deep learning models on this topic.      
### 2.Kalman Filter Meets Subjective Logic: A Self-Assessing Kalman Filter Using Subjective Logic  [ :arrow_down: ](https://arxiv.org/pdf/2007.00550.pdf)
>  Self-assessment is a key to safety and robustness in automated driving. In order to design safer and more robust automated driving functions, the goal is to self-assess the performance of each module in a whole automated driving system. One crucial component in automated driving systems is the tracking of surrounding objects, where the Kalman filter is the most fundamental tracking algorithm. For Kalman filters, some classical online consistency measures exist for self-assessment, which are based on classical probability theory. However, these classical approaches lack the ability to measure the explicit statistical uncertainty within the self-assessment, which is an important quality measure, particularly, if only a small number of samples is available for the self-assessment. In this work, we propose a novel online self-assessment method using subjective logic, which is a modern extension of probabilistic logic that explicitly models the statistical uncertainty. Thus, by embedding classical Kalman filtering into subjective logic, our method additionally features an explicit measure for statistical uncertainty in the self-assessment.      
### 3.Instantaneous PSD Estimation for Speech Enhancement based on Generalized Principal Components  [ :arrow_down: ](https://arxiv.org/pdf/2007.00542.pdf)
>  Power spectral density (PSD) estimates of various microphone signal components are essential to many speech enhancement procedures. As speech is highly non-nonstationary, performance improvements may be gained by maintaining time-variations in PSD estimates. In this paper, we propose an instantaneous PSD estimation approach based on generalized principal components. Similarly to other eigenspace-based PSD estimation approaches, we rely on recursive averaging in order to obtain a microphone signal correlation matrix estimate to be decomposed. However, instead of estimating the PSDs directly from the temporally smooth generalized eigenvalues of this matrix, yielding temporally smooth PSD estimates, we propose to estimate the PSDs from newly defined instantaneous generalized eigenvalues, yielding instantaneous PSD estimates. The instantaneous generalized eigenvalues are defined from the generalized principal components, i.e. a generalized eigenvector-based transform of the microphone signals. We further show that the smooth generalized eigenvalues can be understood as a recursive average of the instantaneous generalized eigenvalues. Simulation results comparing the multi-channel Wiener filter (MWF) with smooth and instantaneous PSD estimates indicate better speech enhancement performance for the latter. A MATLAB implementation is available online.      
### 4.Computation of the Transient in Max-Plus Linear Systems via SMT-Solving  [ :arrow_down: ](https://arxiv.org/pdf/2007.00505.pdf)
>  This paper proposes a new approach, grounded in Satisfiability Modulo Theories (SMT), to study the transient of a Max-Plus Linear (MPL) system, that is the number of steps leading to its periodic regime. Differently from state-of-the-art techniques, our approach allows the analysis of periodic behaviors for subsets of initial states, as well as the characterization of sets of initial states exhibiting the same specific periodic behavior and transient. Our experiments show that the proposed technique dramatically outperforms state-of-the-art methods based on max-plus algebra computations for systems of large dimensions.      
### 5.PAD-UFES-20: a skin lesion benchmark composed of patient data and clinical images collected from smartphones  [ :arrow_down: ](https://arxiv.org/pdf/2007.00478.pdf)
>  Over the past few years, different computer-aided diagnosis (CAD) systems have been proposed to tackle skin lesion analysis. Most of these systems work only for dermoscopy images since there is a strong lack of public clinical images archive available to design them. To fill this gap, we release a skin lesion benchmark composed of clinical images collected from smartphone devices and a set of patient clinical data containing up to 22 features. The dataset consists of 1,373 patients, 1,641 skin lesions, and 2,298 images for six different diagnostics: three skin diseases and three skin cancers. In total, 58.4\% of the skin lesions are biopsy-proven, including 100\% of the skin cancers. By releasing this benchmark, we aim to aid future research and the development of new tools to assist clinicians to detect skin cancer.      
### 6.On the Role of Models in Learning Control: Actor-Critic Iterative Learning Control  [ :arrow_down: ](https://arxiv.org/pdf/2007.00430.pdf)
>  Learning from data of past tasks can substantially improve the accuracy of mechatronic systems. Often, for fast and safe learning a model of the system is required. The aim of this paper is to develop a model-free approach for fast and safe learning for mechatronic systems. The developed actor-critic iterative learning control (ACILC) framework uses a feedforward parameterization with basis functions. These basis functions encode implicit model knowledge and the actor-critic algorithm learns the feedforward parameters without explicitly using a model. Experimental results on a printer setup demonstrate that the developed ACILC framework is capable of achieving the same feedforward signal as preexisting model-based methods without using explicit model knowledge.      
### 7.The Basic Geometric Structures of Electromagnetic Digital Information: Statistical characterization of the digital measurement of spatio-Doppler and polarimetric fluctuations of the radar electromagnetic wave  [ :arrow_down: ](https://arxiv.org/pdf/2007.00428.pdf)
>  The aim is to describe new geometric approaches to define the statistics of spatio-temporal and polarimetric measurements of the states of an electromagnetic wave, using the works of Maurice Fr{é}chet, Jean-Louis Koszul and Jean-Marie Souriau, with in particular the notion of 'average' state of this digital measurement as a Fr{é}chet barycentre in a metric space and a model derived from statistical mechanics to define and calculate a maximum density of entropy (extension of the notion of Gaussian) to describe the fluctuations of the electromagnetic wave. The article will illustrate these new tools with examples of radar application for Doppler, spatio-temporal and polarimetric measurement of the electromagnetic wave by introducing a distance on the covariance matrices of the electromagnetic digital signal, based on Fisher's metric from Information Geometry.      
### 8.Distributed Model Predictive Control with Reconfigurable Terminal Ingredients for Reference Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2007.00427.pdf)
>  A novel distributed model predictive control (MPC) scheme is proposed for reference tracking of large-scale systems. In this scheme, the terminal ingredients are reconfigured online taking the current state of the system into account. This results in an infinite-dimensional optimization problem with an infinite number of constraints. By restricting the terminal ingredients to asymmetric ellipsoidal sets and affine controllers respectively, the optimal control problem is formulated as a semi-infinite program. Using robust optimization tools, the infinite number of constraints is then transformed into a finite number of matrix inequalities yielding a finite, albeit non-convex mathematical program. This is in turn shown to be equivalent to a convex program through a change of variables. The asymptotic stability of the resulting closed-loop system is established by constructing a suitable Lyapunov function. Finally, a modification of the proposed scheme where the terminal control gain is fixed is introduced. Both of the proposed schemes are shown to have larger feasible sets than existing distributed MPC schemes. The proposed MPC schemes are tested in simulation on a benchmark problem and on a power network system; they are found to scale well in the number of subsystems while preserving some degree of optimality.      
### 9.Performance Evaluation of UAV-enabled Cellular Networks with Battery-limited Drones  [ :arrow_down: ](https://arxiv.org/pdf/2007.00374.pdf)
>  Unmanned aerial vehicles (UAVs) can be used as flying base stations (BSs) to offload Macro-BSs in hotspots. However, due to the limited battery on-board, UAVs can typically stay in operation for less than 1.5 hours. Afterward, the UAV has to fly back to a dedicated charging station that recharges/replaces the UAV's battery. In this paper, we study the performance of a UAV-enabled cellular network while capturing the influence of the spatial distribution of the charging stations. In particular, we use tools from stochastic geometry to derive the coverage probability of a UAV-enabled cellular network as a function of the battery size, the density of the charging stations, and the time required for recharging/replacing the battery.      
### 10.On the Minimization of Sobolev Norms of Time-Varying Graph Signals: Estimation of New Coronavirus Disease 2019 Cases  [ :arrow_down: ](https://arxiv.org/pdf/2007.00336.pdf)
>  The mathematical modeling of infectious diseases is a fundamental research field for the planning of strategies to contain outbreaks. The models associated with this field of study usually have exponential prior assumptions in the number of new cases, while the exploration of spatial data has been little analyzed in these models. In this paper, we model the number of new cases of the Coronavirus Disease 2019 (COVID-19) as a problem of reconstruction of time-varying graph signals. To this end, we proposed a new method based on the minimization of the Sobolev norm in graph signal processing. Our method outperforms state-of-the-art algorithms in two COVID-19 databases provided by Johns Hopkins University. In the same way, we prove the benefits of the convergence rate of the Sobolev reconstruction method by relying on the condition number of the Hessian associated with the underlying optimization problem of our method.      
### 11.Identification of TV Channel Watching from Smart Meter Data Using Energy Disaggregation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00326.pdf)
>  Smart meters are used to measure the energy consumption of households. Specifically, within the energy consumption task smart meter have been used for load forecasting, reduction of consumer bills as well as reduction of grid distortions. Except energy consumption smart meters can be used to disaggregate energy consumption on device level. In this paper we investigate the potential of identifying the multimedia content played by a TV or monitor device using the central house's smart meter measuring the aggregated energy consumption from all working appliances of the household. The proposed architecture is based on elastic matching of aggregated energy signal frames with 20 reference TV channel signals. Different elastic matching algorithms were used with the best achieved video content identification accuracy being 93.6% using the MVM algorithm.      
### 12.Kernel Learning for High-Resolution Time-Frequency Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2007.00322.pdf)
>  Kernel functions in quadratic time-frequency distributions (TFDs) are viewed as low-pass filters in the ambiguity function (AF) domain to suppress interfering cross-terms (CTs). Traditional kernel design methods are signal-dependent or have manually selected parameters, which impose restrictions on eliminating CTs and achieving high-resolution TFDs. To address this issue, this paper proposes a data-driven kernel learning model directly from Wigner-Ville distribution (WVD) of the noisy signal. Specifically, the proposed kernel learning based TFD (KL-TFD) model consists of several multi-channel learning convolutional kernels stacked to simulate adaptive directional filters, and increasing dilations are adopted to enlarge the kernel size so that a trade-off between computation and performance is achieved. In addition, channel-wise weights are employed to distinguish the significant directions and trivial ones. Finally, channel fusion is implemented by a simple 1X1 convolutional kernel. Numerical experiments examined over both synthetic and real-life data confirm that the proposed KL-TFD provides the state-of-the-art performance when compared to existing kernel function design based methods.      
### 13.Deep Neural Networks for Computational Optical Form Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2007.00319.pdf)
>  Deep neural networks have been successfully applied in many different fields like computational imaging, medical healthcare, signal processing, or autonomous driving. In a proof-of-principle study, we demonstrate that computational optical form measurement can also benefit from deep learning. A data-driven machine learning approach is explored to solve an inverse problem in the accurate measurement of optical surfaces. The approach is developed and tested using virtual measurements with known ground truth.      
### 14.Interference Distribution Prediction for Link Adaptation in Ultra-Reliable Low-Latency Communications  [ :arrow_down: ](https://arxiv.org/pdf/2007.00306.pdf)
>  The strict latency and reliability requirements of ultra-reliable low-latency communications (URLLC) use cases are among the main drivers in fifth generation (5G) network design. Link adaptation (LA) is considered to be one of the bottlenecks to realize URLLC. In this paper, we focus on predicting the signal to interference plus noise ratio at the user to enhance the LA. Motivated by the fact that most of the URLLC use cases with most extreme latency and reliability requirements are characterized by semi-deterministic traffic, we propose to exploit the time correlation of the interference to compute useful statistics needed to predict the interference power in the next transmission. This prediction is exploited in the LA context to maximize the spectral efficiency while guaranteeing reliability at an arbitrary level. Numerical results are compared with state of the art interference prediction techniques for LA. We show that exploiting time correlation of the interference is an important enabler of URLLC.      
### 15.Exploring the time-domain deep attractor network with two-stream architectures in a reverberant environment  [ :arrow_down: ](https://arxiv.org/pdf/2007.00272.pdf)
>  With the success of deep learning in speech signal processing, speaker-independent speech separation under the reverberant environment remains challenging. The deep attractor network (DAN) performs speech separation with speaker attractor, but it is conducted in the time-frequency domain, which is not optimal. The recently proposed convolutional time-domain audio separation network (Conv-TasNet) surpasses ideal masks in anechoic signals, while its architecture renders the problem of separating signals with variable numbers of speakers. Moreover, these models will suffer performance degradation in a reverberant environment. In this study, we propose a time-domain deep attractor network (TD-DAN) with two-stream convolutional networks, which efficiently performs both dereverberation and separation tasks under the condition of variable numbers of speakers. The speaker encoding stream (SES) of TD-DAN models speaker information, and is explored with various waveform encoders. The speech decoding steam (SDS) accepts speaker attractors from SES, and learns to predict early reflections. Experiment results demonstrated that the TD-DAN achieved scale-invariant source-to-distortion ratio (SI-SDR) gains of 10.40/9.78 dB and 9.15/7.92 dB on the reverberant 2- and 3-speaker development/evaluation set, exceeding Conv-TasNet 1.55/1.33 dB and 0.94/1.21 dB, respectively.      
### 16.UAV-Assisted Attack Prevention, Detection, and Recovery of 5G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.00244.pdf)
>  Unmanned aerial vehicles (UAVs) are emerging as enablers for supporting many applications and services, such as precision agriculture, search and rescue, temporary network deployment or coverage extension, and security. UAVs are being considered for integration into emerging 5G networks as aerial users or network support nodes. We propose to leverage UAVs in 5G to assist in the prevention, detection, and recovery of attacks on 5G networks. Specifically, we consider jamming, spoofing, eavesdropping and the corresponding mitigation mechanisms that are enabled by the versatility of UAVs. We introduce the hot zone, safe zone and UAV-based secondary authorization entity, among others, to increase the resilience and confidentiality of 5G radio access networks and services. We present simulation results and discuss open issues and research directions, including the need for experimental evaluation and a research platform for prototyping and testing the proposed technologies.      
### 17.The NTT DCASE2020 Challenge Task 6 system: Automated Audio Captioning with Keywords and Sentence Length Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00225.pdf)
>  This technical report describes the system participating to the Detection and Classification of Acoustic Scenes and Events (DCASE) 2020 Challenge, Task 6: automated audio captioning. Our submission focuses on solving two indeterminacy problems in automated audio captioning: word selection indeterminacy and sentence length indeterminacy. We simultaneously solve the main caption generation and sub indeterminacy problems by estimating keywords and sentence length through multi-task learning. We tested a simplified model of our submission using the development-testing dataset. Our model achieved 20.7 SPIDEr score where that of the baseline system was 5.4.      
### 18.A Transformer-based Audio Captioning Model with Keyword Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00222.pdf)
>  One of the problems with automated audio captioning (AAC) is the indeterminacy in word selection corresponding to the audio event/scene. Since one acoustic event/scene can be described with several words, it results in a combinatorial explosion of possible captions and difficulty in training. To solve this problem, we propose a Transformer-based audio-captioning model with keyword estimation called TRACKE. It simultaneously solves the word-selection indeterminacy problem with the main task of AAC while executing the sub-task of acoustic event detection/acoustic scene classification (i.e., keyword estimation). TRACKE estimates keywords, which comprise a word set corresponding to audio events/scenes in the input audio, and generates the caption while referring to the estimated keywords to reduce word-selection indeterminacy. Experimental results on a public AAC dataset indicate that TRACKE achieved state-of-the-art performance and successfully estimated both the caption and its keywords.      
### 19.Massive MIMO As Extreme Learning Machine  [ :arrow_down: ](https://arxiv.org/pdf/2007.00221.pdf)
>  This work shows that massive multiple-input multiple-output (MIMO) with low-resolution analog-to-digital converters (ADCs) forms a natural extreme learning machine (ELM), where the massive number of receive antennas act as hidden nodes of the ELM, and the low-resolution ADCs serve as the activation function of the ELM. It is demonstrated that by adding biases to received signals and optimizing the ELM output weights, the system can effectively tackle hardware impairments, e.g., the power amplifier nonlinearity at transmitter side. It is interesting that the low-resolution ADCs can bring benefit to the receiver in handling nonlinear impairments, and the most computation-intensive part of the ELM is naturally accomplished by signal transmission and reception.      
### 20.Review of Learning-Assisted Power System Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2007.00210.pdf)
>  Machine learning, with a dramatic breakthrough in recent years, is showing great potential to upgrade the power system optimization toolbox. Understanding the strength and limitation of machine learning approaches is crucial to answer when and how to integrate them in various power system optimization tasks. This paper pays special attention to the coordination between machine learning approaches and optimization models, and carefully evaluates to what extent such data-driven analysis may benefit the rule-based optimization. A series of typical references are selected and categorized into four kinds: the boundary parameter improvement, the optimization option selection, the surrogate model and the hybrid model. This taxonomy provides a novel perspective to understand the latest research progress and achievements. We further discuss several key challenges and provide an in-depth comparison on the features and designs of different categories. Deep integration of machine learning approaches and optimization models is expected to become the most promising technical trend.      
### 21.Low-light Image Restoration with Short- and Long-exposure Raw Pairs  [ :arrow_down: ](https://arxiv.org/pdf/2007.00199.pdf)
>  Low-light imaging with handheld mobile devices is a challenging issue. Limited by the existing models and training data, most existing methods cannot be effectively applied in real scenarios. In this paper, we propose a new low-light image restoration method by using the complementary information of short- and long-exposure images. We first propose a novel data generation method to synthesize realistic short- and longexposure raw images by simulating the imaging pipeline in lowlight environment. Then, we design a new long-short-exposure fusion network (LSFNet) to deal with the problems of low-light image fusion, including high noise, motion blur, color distortion and misalignment. The proposed LSFNet takes pairs of shortand long-exposure raw images as input, and outputs a clear RGB image. Using our data generation method and the proposed LSFNet, we can recover the details and color of the original scene, and improve the low-light image quality effectively. Experiments demonstrate that our method can outperform the state-of-the art methods.      
### 22.Personalization of Hearing Aid Compression by Human-In-Loop Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.00192.pdf)
>  Existing prescriptive compression strategies used in hearing aid fitting are designed based on gain averages from a group of users which are not necessarily optimal for a specific user. Nearly half of hearing aid users prefer settings that differ from the commonly prescribed settings. This paper presents a human-in-loop deep reinforcement learning approach that personalizes hearing aid compression to achieve improved hearing perception. The developed approach is designed to learn a specific user's hearing preferences in order to optimize compression based on the user's feedbacks. Both simulation and subject testing results are reported which demonstrate the effectiveness of the developed personalized compression.      
### 23.Whole-Word Segmental Speech Recognition with Acoustic Word Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2007.00183.pdf)
>  Segmental models are sequence prediction models in which scores of hypotheses are based on entire variable-length segments of frames. We consider segmental models for whole-word ("acoustic-to-word") speech recognition, with the segment feature vectors defined using acoustic word embeddings. Such models are computationally challenging as the number of paths is proportional to the vocabulary size, which can be orders of magnitude larger than when using subword units like phones. We describe an efficient approach for end-to-end whole-word segmental models, with forward-backward and Viterbi decoding performed on a GPU and a simple segment scoring function that reduces space complexity. In addition, we investigate the use of pre-training via jointly trained acoustic word embeddings (AWEs) and acoustically grounded word embeddings (AGWEs) of written word labels. We find that word error rate can be reduced by a large margin by pre-training the acoustic representation with AWEs, and additional (smaller) gains can be obtained by pre-training the word prediction layer with AGWEs. Our final models improve over comparable A2W models.      
### 24.Pinning Controllability of Boolean Networks: Application to Large-Scale Genetic Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.00171.pdf)
>  This paper focuses on making up for the drawback of recent results about pinning controllability of Boolean control networks (BCNs). First of all, a sufficient criterion is derived for the structural controllability of BCNs. Based on this criterion, to make an arbitrary BCN be controllable, an efficient method is developed to design the feasible pinning strategy which involves identifying pinning nodes and determining control form. Comparing with the traditional pinning approach of which time complexity is $O(2^{2n})$, the time complexity of this pinning method is reduced to $O(n2^{3\kappa}+(n+m)^2)$ with the number of state variables $n$, that of input variables $m$ and the largest in-degree among all nodes $\kappa$. Since a practical genetic network is always sparsely connected, $\kappa$ is far less than $n$ despite its size being large-scale. Finally, a T-cell receptor kinetics model with $37$ state nodes and $3$ input nodes is considered to demonstrate the application of obtained theoretical results.      
### 25.Calibrationless Multi-coil Magnetic Resonance Imaging with Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2007.00165.pdf)
>  We present a method for combining the data retrieved by multiple coils of a Magnetic Resonance Imaging (MRI) system with the a priori assumption of compressed sensing to reconstruct a single image. The final image is the result of an optimization problem that only includes constraints based on fundamental physics (Maxwell's equations and the Biot-Savart law) and accepted phenomena (e.g. sparsity in the Wavelet domain). The problem is solved using an alternating minimization approach: two convex optimization problems are alternately solved, one with the Fast Iterative Shrinkage Threshold Algorithm (FISTA) and the other with the Primal-Dual Hybrid Gradient (PDHG) method. We show results on simulated data as well as data of the knee, brain, and ankle. In all cases studied, results from the new algorithm show higher quality and increased detail when compared to conventional reconstruction algorithms.      
### 26.A Novel RL-assisted Deep Learning Framework for Task-informative Signals Selection and Classification for Spontaneous BCIs  [ :arrow_down: ](https://arxiv.org/pdf/2007.00162.pdf)
>  In this work, we formulate the problem of estimating and selecting task-relevant temporal signal segments from a single EEG trial in the form of a Markov decision process and propose a novel reinforcement-learning mechanism that can be combined with the existing deep-learning based BCI methods. To be specific, we devise an actor-critic network such that an agent can determine which timepoints need to be used (informative) or discarded (uninformative) in composing the intention-related features in a given trial, and thus enhancing the intention identification performance. To validate the effectiveness of our proposed method, we conducted experiments with a publicly available big MI dataset and applied our novel mechanism to various recent deep-learning architectures designed for MI classification. Based on the exhaustive experiments, we observed that our proposed method helped achieve statistically significant improvements in performance.      
### 27.RE-MIMO: Recurrent and Permutation Equivariant Neural MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2007.00140.pdf)
>  In this paper, we present a novel neural network for MIMO symbol detection. It is motivated by several important considerations in wireless communication systems; permutation equivariance and a variable number of users. The neural detector learns an iterative decoding algorithm that is implemented as a stack of iterative units. Each iterative unit is a neural computation module comprising of 3 sub-modules: the likelihood module, the encoder module, and the predictor module. The likelihood module injects information about the generative (forward) process into the neural network. The encoder-predictor modules together update the state vector and symbol estimates. The encoder module updates the state vector and employs a transformer based attention network to handle the interactions among the users in a permutation equivariant manner. The predictor module refines the symbol estimates. The modular and permutation equivariant architecture allows for dealing with a varying number of users. The resulting neural detector architecture is unique and exhibits several desirable properties unseen in any of the previously proposed neural detectors. We compare its performance against existing methods and the results show the ability of our network to efficiently handle a variable number of transmitters with high accuracy.      
### 28.Multi-view Frequency LSTM: An Efficient Frontend for Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2007.00131.pdf)
>  Acoustic models in real-time speech recognition systems typically stack multiple unidirectional LSTM layers to process the acoustic frames over time. Performance improvements over vanilla LSTM architectures have been reported by prepending a stack of frequency-LSTM (FLSTM) layers to the time LSTM. These FLSTM layers can learn a more robust input feature to the time LSTM layers by modeling time-frequency correlations in the acoustic input signals. A drawback of FLSTM based architectures however is that they operate at a predefined, and tuned, window size and stride, referred to as 'view' in this paper. We present a simple and efficient modification by combining the outputs of multiple FLSTM stacks with different views, into a dimensionality reduced feature representation. The proposed multi-view FLSTM architecture allows to model a wider range of time-frequency correlations compared to an FLSTM model with single view. When trained on 50K hours of English far-field speech data with CTC loss followed by sMBR sequence training, we show that the multi-view FLSTM acoustic model provides relative Word Error Rate (WER) improvements of 3-7% for different speaker and acoustic environment scenarios over an optimized single FLSTM model, while retaining a similar computational footprint.      
### 29.Accelerating Prostate Diffusion Weighted MRI using Guided Denoising Convolutional Neural Network: Retrospective Feasibility Study  [ :arrow_down: ](https://arxiv.org/pdf/2007.00121.pdf)
>  Purpose: To investigate feasibility of accelerating prostate diffusion-weighted imaging (DWI) by reducing the number of acquired averages and denoising the resulting image using a proposed guided denoising convolutional neural network (DnCNN). Materials and Methods: Raw data from the prostate DWI scans were retrospectively gathered (between July 2018 and July 2019) from six single-vendor MRI scanners. 118 data sets were used for training and validation (age: 64.3 +- 8 years) and 37 - for testing (age: 65.1 +- 7.3 years). High b-value diffusion-weighted (hb-DW) data were reconstructed into noisy images using two averages and reference images using all sixteen averages. A conventional DnCNN was modified into a guided DnCNN, which uses the low b-value DWI image as a guidance input. Quantitative and qualitative reader evaluations were performed on the denoised hb-DW images. A cumulative link mixed regression model was used to compare the readers scores. The agreement between the apparent diffusion coefficient (ADC) maps (denoised vs reference) was analyzed using Bland Altman analysis. Results: Compared to the DnCNN, the guided DnCNN produced denoised hb-DW images with higher peak signal-to-noise ratio and structural similarity index and lower normalized mean square error (p &lt; 0.001). Compared to the reference images, the denoised images received higher image quality scores (p &lt; 0.0001). The ADC values based on the denoised hb-DW images were in good agreement with the reference ADC values. Conclusion: Accelerating prostate DWI by reducing the number of acquired averages and denoising the resulting image using the proposed guided DnCNN is technically feasible.      
### 30.Coverage Analysis and Scaling Laws of Ultra-Dense Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.00108.pdf)
>  In this paper, we develop an innovative approach to quantitatively characterize the performance of ultra-dense wireless networks in a plethora of propagation environments. The proposed framework has the potential of significantly simplifying the cumbersome procedure of analyzing the coverage probability and allowing the remarkable unification of single- and multi-antenna networks through compact representations. By harnessing this key feature, we develop a novel statistical machinery to study the scaling laws of wireless network densification considering general channel power distributions including the entire space of multipath and shadowing models as well as associated beamforming gain due to the use of multiple antenna. We further formulate the relationship between network density, antenna height, antenna array seize and carrier frequency showing how the coverage probability can be maintained with ultra-densification. From a system design perspective, we present a new innovative theoretical discovery stipulating that if multiple antenna BS are deployed and moved to higher frequencies, then monotonically increasing the coverage probability by means of ultra-densification is possible, and this without lowering the antenna height. Such findings are completely different from the conclusions in existing works, who suggest to lower the BS height as to leverage the potential of network densification. Simulation results substantiate performance trends leveraging network densification and antenna deployment and configuration against path loss models and signal-to-noise plus interference (SINR) thresholds.      
### 31.Traffic Delay Reduction at Highway Diverges Using an Advance Warning System Based on a Probabilistic Prediction Model  [ :arrow_down: ](https://arxiv.org/pdf/2007.00101.pdf)
>  This paper presents an on-board advance warning system for vehicles based on a probabilistic prediction model that advises them on when to change lanes to reach a highway diverge on time. The system is based on a model that estimates the probability of reaching a goal state on the road using one or multiple lane changes. This estimate is based on several traffic-related parameters such as the distribution of inter-vehicle headway distances as well as driver-related parameters like lane change duration. For an upcoming diverge, the advance warning system uses the model to continuously calculate the probability of reaching it and advise the driver to change lanes when the probability dips below a certain threshold. To evaluate the performance of the proposed system in reducing traffic delay at highway diverges, it was used on a segment of a four-lane highway to advise vehicles taking an off-ramp on when to change lanes. Results show that using the proposed system reduces average delay up to 6% and maximum delay up to 16%, depending on traffic flow and the ratio of vehicles taking the off-ramp.      
### 32.Deep neural networks for the evaluation and design of photonic devices  [ :arrow_down: ](https://arxiv.org/pdf/2007.00084.pdf)
>  The data sciences revolution is poised to transform the way photonic systems are simulated and designed. Photonics are in many ways an ideal substrate for machine learning: the objective of much of computational electromagnetics is the capture of non-linear relationships in high dimensional spaces, which is the core strength of neural networks. Additionally, the mainstream availability of Maxwell solvers makes the training and evaluation of neural networks broadly accessible and tailorable to specific problems. In this Review, we will show how deep neural networks, configured as discriminative networks, can learn from training sets and operate as high-speed surrogate electromagnetic solvers. We will also examine how deep generative networks can learn geometric features in device distributions and even be configured to serve as robust global optimizers. Fundamental data sciences concepts framed within the context of photonics will also be discussed, including the network training process, delineation of different network classes and architectures, and dimensionality reduction.      
### 33.Multi-way Graph Signal Processing on Tensors: Integrative analysis of irregular geometries  [ :arrow_down: ](https://arxiv.org/pdf/2007.00041.pdf)
>  Graph signal processing (GSP) is an important methodology for studying arbitrarily structured data. As acquired data is increasingly taking the form of multi-way tensors, new signal processing tools are needed to maximally utilize the multi-way structure within the data. We review modern signal processing frameworks generalizing GSP to multi-way data, starting from graph signals coupled to familiar regular axes such as time in sensor networks, and then extending to general graphs across all tensor modes. This widely applicable paradigm motivates reformulating and improving upon classical problems and approaches to creatively address the challenges in tensor-based data. We synthesize common themes arising from current efforts to combine GSP with tensor analysis and highlight future directions in extending GSP to the multi-way paradigm.      
### 34.Unsupervised Deep Learning for Massive MIMO Hybrid Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2007.00038.pdf)
>  Hybrid beamforming is a promising technique to reduce the complexity and cost of massive multiple-input multiple-output (MIMO) systems while providing high data rate. However, the hybrid precoder design is a challenging task requiring channel state information (CSI) feedback and solving a complex optimization problem. This paper proposes a novel RSSI-based unsupervised deep learning method to design the hybrid beamforming in massive MIMO systems. Furthermore, we propose i) a method to design the synchronization signal (SS) in initial access (IA); and ii) a method to design the codebook for the analog precoder. We also evaluate the system performance through a realistic channel model in various scenarios. We show that the proposed method not only greatly increases the spectral efficiency especially in frequency-division duplex (FDD) communication by using partial CSI feedback, but also has near-optimal sum-rate and outperforms other state-of-the-art full-CSI solutions.      
### 35.UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2007.00544.pdf)
>  Autonomous deployment of unmanned aerial vehicles (UAVs) supporting next-generation communication networks requires efficient trajectory planning methods. We propose a new end-to-end reinforcement learning (RL) approach to UAV-enabled data collection from Internet of Things (IoT) devices in an urban environment. An autonomous drone is tasked with gathering data from distributed sensor nodes subject to limited flying time and obstacle avoidance. While previous approaches, learning and non-learning based, must perform expensive recomputations or relearn a behavior when important scenario parameters such as the number of sensors, sensor positions, or maximum flying time, change, we train a double deep Q-network (DDQN) with combined experience replay to learn a UAV control policy that generalizes over changing scenario parameters. By exploiting a multi-layer map of the environment fed through convolutional network layers to the agent, we show that our proposed network architecture enables the agent to make movement decisions for a variety of scenario parameters that balance the data collection goal with flight time efficiency and safety constraints. Considerable advantages in learning efficiency from using a map centered on the UAV's position over a non-centered map are also illustrated.      
### 36.Optimisation of the PointPillars network for 3D object detection in point clouds  [ :arrow_down: ](https://arxiv.org/pdf/2007.00493.pdf)
>  In this paper we present our research on the optimisation of a deep neural network for 3D object detection in a point cloud. Techniques like quantisation and pruning available in the Brevitas and PyTorch tools were used. We performed the experiments for the PointPillars network, which offers a reasonable compromise between detection accuracy and calculation complexity. The aim of this work was to propose a variant of the network which we will ultimately implement in an FPGA device. This will allow for real-time LiDAR data processing with low energy consumption. The obtained results indicate that even a significant quantisation from 32-bit floating point to 2-bit integer in the main part of the algorithm, results in 5%-9% decrease of the detection accuracy, while allowing for almost a 16-fold reduction in size of the model.      
### 37.Optimisation of a Siamese Neural Network for Real-Time Energy Efficient Object Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2007.00491.pdf)
>  In this paper the research on optimisation of visual object tracking using a Siamese neural network for embedded vision systems is presented. It was assumed that the solution shall operate in real-time, preferably for a high resolution video stream, with the lowest possible energy consumption. To meet these requirements, techniques such as the reduction of computational precision and pruning were considered. Brevitas, a tool dedicated for optimisation and quantisation of neural networks for FPGA implementation, was used. A number of training scenarios were tested with varying levels of optimisations - from integer uniform quantisation with 16 bits to ternary and binary networks. Next, the influence of these optimisations on the tracking performance was evaluated. It was possible to reduce the size of the convolutional filters up to 10 times in relation to the original network. The obtained results indicate that using quantisation can significantly reduce the memory and computational complexity of the proposed network while still enabling precise tracking, thus allow to use it in embedded vision systems. Moreover, quantisation of weights positively affects the network training by decreasing overfitting.      
### 38.Non-rigid 3D motion estimation at high temporal resolution from prospectively undersampled k-space data using low-rank MR-MOTUS  [ :arrow_down: ](https://arxiv.org/pdf/2007.00488.pdf)
>  With the recent introduction of the MR-LINAC, an MR-scanner combined with a radiotherapy LINAC, MR-based motion estimation has become of increasing interest to (retrospectively) characterize tumor and organs-at-risk motion during radiotherapy. To this extent, we introduce low-rank MR-MOTUS, a framework to retrospectively reconstruct time-resolved non-rigid 3D+t motion-fields from a single low-resolution reference image and prospectively undersampled k-space data acquired during motion. Low-rank MR-MOTUS exploits spatio-temporal correlations in internal body motion with a low-rank motion model, and inverts a signal model that relates motion-fields directly to a reference image and k-space data. The low-rank model reduces the degrees-of-freedom, memory consumption and reconstruction times by assuming a factorization of space-time motion-fields in spatial and temporal components. Low-rank MR-MOTUS was employed to estimate motion in 2D/3D abdominothoracic scans and 3D head scans. Data were acquired using golden-ratio radial readouts. Reconstructed 2D and 3D respiratory motion-fields were respectively validated against time-resolved and respiratory-resolved image reconstructions, and the head motion against static image reconstructions from fully-sampled data acquired right before and right after the motion. Results show that 2D+t respiratory motion can be estimated retrospectively at 40.8 motion-fields-per-second, 3D+t respiratory motion at 7.6 motion-fields-per-second and 3D+t head-neck motion at 9.3 motion-fields-per-second. The validations show good consistency with image reconstructions. The proposed framework can estimate time-resolved non-rigid 3D motion-fields, which allows to characterize drifts and intra and inter-cycle patterns in breathing motion during radiotherapy, and could form the basis for real-time MR-guided radiotherapy.      
### 39.Automatic Crack Detection on Road Pavements Using Encoder Decoder Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2007.00477.pdf)
>  Inspired by the development of deep learning in computer vision and object detection, the proposed algorithm considers an encoder-decoder architecture with hierarchical feature learning and dilated convolution, named U-Hierarchical Dilated Network (U-HDN), to perform crack detection in an end-to-end method. Crack characteristics with multiple context information are automatically able to learn and perform end-to-end crack detection. Then, a multi-dilation module embedded in an encoder-decoder architecture is proposed. The crack features of multiple context sizes can be integrated into the multi-dilation module by dilation convolution with different dilatation rates, which can obtain much more cracks information. Finally, the hierarchical feature learning module is designed to obtain a multi-scale features from the high to low-level convolutional layers, which are integrated to predict pixel-wise crack detection. Some experiments on public crack databases using 118 images were performed and the results were compared with those obtained with other methods on the same images. The results show that the proposed U-HDN method achieves high performance because it can extract and fuse different context sizes and different levels of feature maps than other algorithms.      
### 40.Multi-objective Optimal Control of Dynamic Integrated Model of Climate and Economy: Evolution in Action  [ :arrow_down: ](https://arxiv.org/pdf/2007.00449.pdf)
>  One of the widely used models for studying economics of climate change is the Dynamic Integrated model of Climate and Economy (DICE), which has been developed by Professor William Nordhaus, one of the laureates of the 2018 Nobel Memorial Prize in Economic Sciences. Originally a single-objective optimal control problem has been defined on DICE dynamics, which is aimed to maximize the social welfare. In this paper, a bi-objective optimal control problem defined on DICE model, objectives of which are maximizing social welfare and minimizing the temperature deviation of atmosphere. This multi-objective optimal control problem solved using Non-Dominated Sorting Genetic Algorithm II (NSGA-II) also it is compared to previous works on single-objective version of the problem. The resulting Pareto front rediscovers the previous results and generalizes to a wide range of non-dominant solutions to minimize the global temperature deviation while optimizing the economic welfare. The previously used single-objective approach is unable to create such a variety of possibilities, hence, its offered solution is limited in vision and reachable performance. Beside this, resulting Pareto-optimal set reveals the fact that temperature deviation cannot go below a certain lower limit, unless we have significant technology advancement or positive change in global conditions.      
### 41.Joint-Diagonalizability-Constrained Multichannel Nonnegative Matrix Factorization Based on Multivariate Complex Sub-Gaussian Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2007.00416.pdf)
>  In this paper, we address a statistical model extension of multichannel nonnegative matrix factorization (MNMF) for blind source separation, and we propose a new parameter update algorithm used in the sub-Gaussian model. MNMF employs full-rank spatial covariance matrices and can simulate situations in which the reverberation is strong and the sources are not point sources. In conventional MNMF, spectrograms of observed signals are assumed to follow a multivariate Gaussian distribution. In this paper, first, to extend the MNMF model, we introduce the multivariate generalized Gaussian distribution as the multivariate sub-Gaussian distribution. Since the cost function of MNMF based on this multivariate sub-Gaussian model is difficult to minimize, we additionally introduce the joint-diagonalizability constraint in spatial covariance matrices to MNMF similarly to FastMNMF, and transform the cost function to the form to which we can apply the auxiliary functions to derive the valid parameter update rules. Finally, from blind source separation experiments, we show that the proposed method outperforms the conventional methods in source-separation accuracy.      
### 42.Handling Variable-Dimensional Time Series with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.00411.pdf)
>  Several applications of Internet of Things(IoT) technology involve capturing data from multiple sensors resulting in multi-sensor time series. Existing neural networks based approaches for such multi-sensor or multivariate time series modeling assume fixed input dimension or number of sensors. Such approaches can struggle in the practical setting where different instances of the same device or equipment such as mobiles, wearables, engines, etc. come with different combinations of installed sensors. We consider training neural network models from such multi-sensor time series, where the time series have varying input dimensionality owing to availability or installation of a different subset of sensors at each source of time series. We propose a novel neural network architecture suitable for zero-shot transfer learning allowing robust inference for multivariate time series with previously unseen combination of available dimensions or sensors at test time. Such a combinatorial generalization is achieved by conditioning the layers of a core neural network-based time series model with a "conditioning vector" that carries information of the available combination of sensors for each time series. This conditioning vector is obtained by summarizing the set of learned "sensor embedding vectors" corresponding to the available sensors in a time series via a graph neural network. We evaluate the proposed approach on publicly available activity recognition and equipment prognostics datasets, and show that the proposed approach allows for better generalization in comparison to a deep gated recurrent neural network baseline.      
### 43.Asynchronous Real-Time Optimization of Footstep Placement andTiming in Bipedal Walking Robots  [ :arrow_down: ](https://arxiv.org/pdf/2007.00385.pdf)
>  Online footstep planning is essential for bipedal walking robots to be able to walk in the presence of disturbances. Until recently this has been achieved by only optimizing the placement of the footstep, keeping the duration of the step constant. In this paper we introduce a footstep planner capable of optimizing footstep placement and timing in real-time by asynchronously combining two optimizers, which we refer to as asynchronous real-time optimization (ARTO). The first optimizer which runs at approximately 25 Hz, utilizes a fourth-order Runge-Kutta (RK4) method to accurately approximate the dynamics of the linear inverted pendulum (LIP) model for bipedal walking, then uses non-linear optimization to find optimal footsteps and duration at a lower frequency. The second optimizer that runs at approximately 250 Hz, uses analytical gradients derived from the full dynamics of the LIP model and constraint penalty terms to perform gradient descent, which finds approximately optimal footstep placement and timing at a higher frequency. By combining the two optimizers asynchronously, ARTO has the benefits of fast reactions to disturbances from the gradient descent optimizer, accurate solutions that avoid local optima from the RK4 optimizer, and increases the probability that a feasible solution will be found from the two optimizers. Experimentally, we show that ARTO is able to recover from considerably larger pushes and produces feasible solutions to larger reference velocity changes than a standard footstep location optimizer, and outperforms using just the RK4 optimizer alone.      
### 44.An Efficient Slow-Time Adaptation for Massive MIMO Hybrid Beamforming in mm-Wave Time-Varying Channels  [ :arrow_down: ](https://arxiv.org/pdf/2007.00329.pdf)
>  In this paper, adaptive hybrid beamforming methods are proposed for millimeter-wave range massive multiple-input-multiple-output (MIMO) systems considering single carrier wideband transmission in uplink data mode. A statistical analog beamformer is adaptively constructed in slow-time, while the channel is time-varying and erroneously estimated. A recursive filtering approach is proposed, which aims robustness against estimation errors for generalized eigen-beamformer (GEB). Approximated expressions are obtained for channel covariance matrices that decouple angular spread and center angle of multipath components. With these expressions, modified adaptive construction methods for GEB are proposed, which use only the quantized estimated power levels on angular patches. The performances of the proposed slow-time adaptation techniques for statistical Massive MIMO beamforming are evaluated in terms of the output signal-to-interference-and-noise-ratio (SINR), instantaneous channel estimation and beam accuracy. They are shown to be very efficient such that the computational complexity is significantly reduced while the performance remains almost the same as that of the ideal GEB even in large angular estimation errors.      
### 45.Robust navigation with tinyML for autonomous mini-vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2007.00302.pdf)
>  Autonomous navigation vehicles have rapidly improved thanks to the breakthroughs of Deep Learning. However, scaling autonomous driving to low-power and real-time systems deployed on dynamic environments poses several challenges that prevent their adoption. In this work, we show an end-to-end integration of data, algorithms, and deployment tools that enables the deployment of a family of tiny-CNNs on extra-low-power MCUs for autonomous driving mini-vehicles (image classification task). Our end-to-end environment enables a closed-loop learning system that allows the CNNs (learners) to learn through demonstration by imitating the original computer-vision algorithm (teacher) while doubling the throughput. Thereby, our CNNs gain robustness to lighting conditions and increase their accuracy up to 20% when deployed in the most challenging setup with a very fast-rate camera. Further, we leverage GAP8, a parallel ultra-low-power RISC-V SoC, to meet the real-time requirements. When running a family of CNN for an image classification task, GAP8 reduces their latency by over 20x compared to using an STM32L4 (Cortex-M4) or obtains +21.4% accuracy than an NXP k64f (Cortex-M4) solution with the same energy budget.      
### 46.Robust Semantic Segmentation in Adverse Weather Conditions by means of Fast Video-Sequence Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00290.pdf)
>  Computer vision tasks such as semantic segmentation perform very well in good weather conditions, but if the weather turns bad, they have problems to achieve this performance in these conditions. One possibility to obtain more robust and reliable results in adverse weather conditions is to use video-segmentation approaches instead of commonly used single-image segmentation methods. Video-segmentation approaches capture temporal information of the previous video-frames in addition to current image information, and hence, they are more robust against disturbances, especially if they occur in only a few frames of the video-sequence. However, video-segmentation approaches, which are often based on recurrent neural networks, cannot be applied in real-time applications anymore, since their recurrent structures in the network are computational expensive. For instance, the inference time of the LSTM-ICNet, in which recurrent units are placed at proper positions in the single-segmentation approach ICNet, increases up to 61 percent compared to the basic ICNet. Hence, in this work, the LSTM-ICNet is sped up by modifying the recurrent units of the network so that it becomes real-time capable again. Experiments on different datasets and various weather conditions show that the inference time can be decreased by about 23 percent by these modifications, while they achieve similar performance than the LSTM-ICNet and outperform the single-segmentation approach enormously in adverse weather conditions.      
### 47.Consistent Independent Low-Rank Matrix Analysis for Determined Blind Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00274.pdf)
>  Independent low-rank matrix analysis (ILRMA) is the state-of-the-art algorithm for blind source separation (BSS) in the determined situation (the number of microphones is greater than or equal to that of source signals). ILRMA achieves a great separation performance by modeling the power spectrograms of the source signals via the nonnegative matrix factorization (NMF). Such highly developed source model can effectively solve the permutation problem of the frequency-domain BSS, which should be the reason of the excellence of ILRMA. In this paper, we further improve the separation performance of ILRMA by additionally considering the general structure of spectrogram called consistency, and hence we call the proposed method Consistent ILRMA. Since a spectrogram is calculated by an overlapping window (and a window function induces spectral smearing called main- and side-lobes), the time-frequency bins depend on each other. In other words, the time-frequency components are related each other via the uncertainty principle. Such co-occurrence among the spectral components can be an assistant for solving the permutation problem, which has been demonstrated by a recent study. Based on these facts, we propose an algorithm for realizing Consistent ILRMA by slightly modifying the original algorithm. Its performance was extensively studied through the experiments performed with various window lengths and shift lengths. The results indicated several tendencies of the original and proposed ILRMA which include some topics have not discussed well in the literature. For example, the proposed Consistent ILRMA tends to outperform the original ILRMA when the window length is sufficiently long compared to the reverberation time of the mixing system.      
### 48.On the Latency, Rate and Reliability Tradeoff in Wireless Networked Control Systems for IIoT  [ :arrow_down: ](https://arxiv.org/pdf/2007.00256.pdf)
>  Wireless networked control systems (WNCSs) provide a key enabling technique for Industry Internet of Things (IIoT). However, in the literature of WNCSs, most of the research focuses on the control perspective, and has considered oversimplified models of wireless communications which do not capture the key parameters of a practical wireless communication system, such as latency, data rate and reliability. In this paper, we focus on a WNCS, where a controller transmits quantized and encoded control codewords to a remote actuator through a wireless channel, and adopt a detailed model of the wireless communication system, which jointly considers the inter-related communication parameters. We derive the stability region of the WNCS. If and only if the tuple of the communication parameters lies in the region, the average cost function, i.e., a performance metric of the WNCS, is bounded. We further obtain a necessary and sufficient condition under which the stability region is $n$-bounded, where $n$ is the control codeword blocklength. We also analyze the average cost function of the WNCS. Such analysis is non-trivial because the finite-bit control-signal quantizer introduces a non-linear and discontinuous quantization function which makes the performance analysis very difficult. We derive tight upper and lower bounds on the average cost function in terms of latency, data rate and reliability. Our analytical results provide important insights into the design of the optimal parameters to minimize the average cost within the stability region.      
### 49.Private Speech Characterization with Secure Multiparty Computation  [ :arrow_down: ](https://arxiv.org/pdf/2007.00253.pdf)
>  Deep learning in audio signal processing, such as human voice audio signal classification, is a rich application area of machine learning. Legitimate use cases include voice authentication, gunfire detection, and emotion recognition. While there are clear advantages to automated human speech classification, application developers can gain knowledge beyond the professed scope from unprotected audio signal processing. In this paper we propose the first privacy-preserving solution for deep learning-based audio classification that is provably secure. Our approach, which is based on Secure Multiparty Computation, allows to classify a speech signal of one party (Alice) with a deep neural network of another party (Bob) without Bob ever seeing Alice's speech signal in an unencrypted manner. As threat models, we consider both passive security, i.e. with semi-honest parties who follow the instructions of the cryptographic protocols, as well as active security, i.e. with malicious parties who deviate from the protocols. We evaluate the efficiency-security-accuracy trade-off of the proposed solution in a use case for privacy-preserving emotion detection from speech with a convolutional neural network. In the semi-honest case we can classify a speech signal in under 0.3 sec; in the malicious case it takes $\sim$1.6 sec. In both cases there is no leakage of information, and we achieve classification accuracies that are the same as when computations are done on unencrypted data.      
### 50.BiO-Net: Learning Recurrent Bi-directional Connections for Encoder-Decoder Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2007.00243.pdf)
>  U-Net has become one of the state-of-the-art deep learning-based approaches for modern computer vision tasks such as semantic segmentation, super resolution, image denoising, and inpainting. Previous extensions of U-Net have focused mainly on the modification of its existing building blocks or the development of new functional modules for performance gains. As a result, these variants usually lead to an unneglectable increase in model complexity. To tackle this issue in such U-Net variants, in this paper, we present a novel Bi-directional O-shape network (BiO-Net) that reuses the building blocks in a recurrent manner without introducing any extra parameters. Our proposed bi-directional skip connections can be directly adopted into any encoder-decoder architecture to further enhance its capabilities in various task domains. We evaluated our method on various medical image analysis tasks and the results show that our BiO-Net significantly outperforms the vanilla U-Net as well as other state-of-the-art methods.      
### 51.Sequential Unsupervised Domain Adaptation through Prototypical Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2007.00197.pdf)
>  We develop an algorithm for unsupervised domain adaptation (UDA) of a classifier from a labeled source domain to an unlabeled target domain in a sequential learning setting. UDA has been studied extensively recently but the vast majority of the existing methods consider a joint learning setting where the model is trained on the source domain and the target domain data simultaneously. We consider a more practical setting, where the model has been trained on the labeled source domain data and then needs to be adapted to the unlabeled source domain, without having access to the source domain training data. We tackle this problem by aligning the distributions of the source and the target domain in a discriminative embedding space. To overcome the challenges of learning in a sequential setting, we learn an intermediate prototypical distribution from the source labeled data and then use this distribution for knowledge transfer to the target domain. We provide theoretical justification for the proposed algorithm by showing that it optimizes an upper-bound for the expected risk in the target domain. We also conduct extensive experiments with several standard benchmarks and demonstrate the competitiveness of the proposed method compared to existing joint learning UDA algorithms.      
### 52.Millimeter Wave Doppler Sensor for Nondestructive Evaluation of Materials  [ :arrow_down: ](https://arxiv.org/pdf/2007.00195.pdf)
>  Resonance modes are intrinsic characteristics of objects when excited at those frequencies. Probing the resonance signatures can reveal useful information about material composition, geometry, presence of defects, and other characteristics of the object under test. Vibration spectra can be measured remotely with high degree of sensitivity using a millimeter wave (mmW) Doppler sensor and a remote excitation source. This novel nondestructive evaluation (NDE) method can work in a non-contact manner as an alternative or complementary approach to conventional NDE methods such as those based on acoustic/ultrasonic and optical techniques. Millimeter wave vibrometry can be used for a wide range of civil and national security applications. Examples include detection of defects and degradation for diagnostics and prognostics of materials components and rapid standoff inspection of shielded/sealed containers for contraband. In this paper, we evaluate the performance of a compact mmW vibrometer developed at Argonne. Our 94 GHz I-Q Doppler sensor monitors the mechanical vibration signature of the object under interrogation that is induced by continuous wave excitation. For proof-of-principle demonstrations, the test objects were mechanically excited by an electronically controlled shaker using sinusoidal waves at various frequencies ranging from DC to 200 Hz. We will present a number of laboratory test results and will discuss the method's applicability to some practical NDE applications.      
### 53.Ultrasonic and Electromagnetic Sensors for Downhole Reservoir Characterization  [ :arrow_down: ](https://arxiv.org/pdf/2007.00191.pdf)
>  The current work covers the evaluation of ultrasonic and electromagnetic (EM) techniques applied to temperature measurement and flow characterization for Enhanced Geothermal System (EGS). We have evaluated both ultrasonic techniques and microwave radiometry for temperature gradient and profile measurements. A waveguide-based ultrasonic probe was developed to measure the temperature gradient. A statistic approach on estimating the average grain size via spectral analysis of the scattered ultrasonic signals is introduced. For directional temperature measurement, different microwave antenna designs are compared numerically and an array loop antenna design is selected for further development. Finally techniques to characterize the porosity and permeability of a hot dry rock resource are presented.      
### 54.Reinforcement Learning based Control of Imitative Policies for Near-Accident Driving  [ :arrow_down: ](https://arxiv.org/pdf/2007.00178.pdf)
>  Autonomous driving has achieved significant progress in recent years, but autonomous cars are still unable to tackle high-risk situations where a potential accident is likely. In such near-accident scenarios, even a minor change in the vehicle's actions may result in drastically different consequences. To avoid unsafe actions in near-accident scenarios, we need to fully explore the environment. However, reinforcement learning (RL) and imitation learning (IL), two widely-used policy learning methods, cannot model rapid phase transitions and are not scalable to fully cover all the states. To address driving in near-accident scenarios, we propose a hierarchical reinforcement and imitation learning (H-ReIL) approach that consists of low-level policies learned by IL for discrete driving modes, and a high-level policy learned by RL that switches between different driving modes. Our approach exploits the advantages of both IL and RL by integrating them into a unified learning framework. Experimental results and user studies suggest our approach can achieve higher efficiency and safety compared to other methods. Analyses of the policies demonstrate our high-level policy appropriately switches between different low-level policies in near-accident driving situations.      
### 55.A Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2007.00144.pdf)
>  An important problem in machine auditory perception is to recognize and detect sound events. In this paper, we propose a sequential self-teaching approach to learning sounds. Our main proposition is that it is harder to learn sounds in adverse situations such as from weakly labeled and/or noisy labeled data, and in these situations a single stage of learning is not sufficient. Our proposal is a sequential stage-wise learning process that improves generalization capabilities of a given modeling system. We justify this method via technical results and on Audioset, the largest sound events dataset, our sequential learning approach can lead to up to 9% improvement in performance. A comprehensive evaluation also shows that the method leads to improved transferability of knowledge from previously trained models, thereby leading to improved generalization capabilities on transfer learning tasks.      
### 56.Enforcing Almost-Sure Reachability in POMDPs  [ :arrow_down: ](https://arxiv.org/pdf/2007.00085.pdf)
>  Partially-Observable Markov Decision Processes (POMDPs) are a well-known formal model for planning scenarios where agents operate under limited information about their environment. In safety-critical domains, the agent must adhere to a policy satisfying certain behavioral constraints. We study the problem of synthesizing policies that almost-surely reach some goal state while a set of bad states is never visited. In particular, we present an iterative symbolic approach that computes a winning region, that is, a set of system configurations such that all policies that stay within this set are guaranteed to satisfy the constraints. The approach generalizes and improves previous work in terms of scalability and efficacy, as demonstrated in the empirical evaluation. Additionally, we show the applicability to safe exploration by restricting agent behavior to these winning regions.      
### 57.A Survey on Instance Segmentation: State of the art  [ :arrow_down: ](https://arxiv.org/pdf/2007.00047.pdf)
>  Object detection or localization is an incremental step in progression from coarse to fine digital image inference. It not only provides the classes of the image objects, but also provides the location of the image objects which have been classified. The location is given in the form of bounding boxes or centroids. Semantic segmentation gives fine inference by predicting labels for every pixel in the input image. Each pixel is labelled according to the object class within which it is enclosed. Furthering this evolution, instance segmentation gives different labels for separate instances of objects belonging to the same class. Hence, instance segmentation may be defined as the technique of simultaneously solving the problem of object detection as well as that of semantic segmentation. In this survey paper on instance segmentation -- its background, issues, techniques, evolution, popular datasets, related work up to the state of the art and future scope have been discussed. The paper provides valuable information for those who want to do research in the field of instance segmentation.      
### 58.Fast Training of Deep Networks with One-Class CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2007.00046.pdf)
>  One-class CNNs have shown promise in novelty detection. However, very less work has been done on extending them to multiclass classification. The proposed approach is a viable effort in this direction. It uses one-class CNNs i.e., it trains one CNN per class, for multiclass classification. An ensemble of such one-class CNNs is used for multiclass classification. The benefits of the approach are generally better recognition accuracy while taking almost even half or two-thirds of the training time of a conventional multi-class deep network. The proposed approach has been applied successfully to face recognition and object recognition tasks. For face recognition, a 1000 frame RGB video, featuring many faces together, has been used for benchmarking of the proposed approach. Its database is available on request via e-mail. For object recognition, the Caltech-101 Image Database and 17Flowers Dataset have also been used. The experimental results support the claims made.      
### 59.A Hybrid Distribution Feeder Long-Term Load Forecasting Method Based on Sequence Prediction  [ :arrow_down: ](https://arxiv.org/pdf/1812.04480.pdf)
>  Distribution feeder long-term load forecast (LTLF) is a critical task many electric utility companies perform on an annual basis. The goal of this task is to forecast the annual load of distribution feeders. The previous top-down and bottom-up LTLF methods are unable to incorporate different levels of information. This paper proposes a hybrid modeling method using sequence prediction for this classic and important task. The proposed method can seamlessly integrate top-down, bottom-up and sequential information hidden in multi-year data. Two advanced sequence prediction models Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks are investigated in this paper. They successfully solve the vanishing and exploding gradient problems a standard recurrent neural network has. This paper firstly explains the theories of LSTM and GRU networks and then discusses the steps of feature selection, feature engineering and model implementation in detail. In the end, a real-world application example for a large urban grid in West Canada is provided. LSTM and GRU networks under different sequential configurations and traditional models including bottom-up, ARIMA and feed-forward neural network are all implemented and compared in detail. The proposed method demonstrates superior performance and great practicality.      

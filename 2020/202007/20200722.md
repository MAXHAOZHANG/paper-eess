# ArXiv eess --Wed, 22 Jul 2020
### 1.Performance Analysis of an Outdoor Visible Light Communications System for Internet-of-Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2007.10975.pdf)
>  This paper looks at the performance of an outdoor visible light (OVLC) communication system used for Internet-of-Vehicles (IoV). In the proposed system an amplify-and-forward (AF) opportunistic scheme is used to extend the range of information broadcast from a traffic light to vehicles. The Gamma-Gamma channel gain and the Lambertian direct current (DC) channel gain are used to model the fading coefficient of each transmission and the short and thermal noise models used to represent the system noise. The statistics of the system are examined by deriving closed-form expressions for the cumulative distribution function (CDF) and probability density function (PDF) for the equivalent end-to-end signal-to-noise ratio (SNR). Novel closed form equations are also developed for the outage probability and ergodic capacity. Numerical simulations performed showed that the system performance in terms of both outage probability and ergodic capacity improves with decreasing turbulence intensity. Results also illustrate that, as the distance between the vehicles increases, the system performance is more deteriorated.      
### 2.Graph Signal Processing for Infrastructure Resilience: Suitability and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2007.10964.pdf)
>  Graph signal processing (GSP) is an emerging field developed for analyzing signals defined on irregular spatial structures modeled as graphs. Given the considerable literature regarding the resilience of infrastructure networks using graph theory, it is not surprising that a number of applications of GSP can be found in the resilience domain. GSP techniques assume that the choice of graphical Fourier transform (GFT) imparts a particular spectral structure on the signal of interest. We assess a number of power distribution systems with respect to metrics of signal structure and identify several correlates to system properties and further demonstrate how these metrics relate to performance of some GSP techniques. We also discuss the feasibility of a data-driven approach that improves these metrics and apply it to a water distribution scenario. Overall, we find that many of the candidate systems analyzed are properly structured in the chosen GFT basis and amenable to GSP techniques, but identify considerable variability and nuance that merits future investigation.      
### 3.Driving Conditions-Driven Energy Management for Hybrid Electric Vehicles: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2007.10880.pdf)
>  Motivated by the concerns on transported fuel consumption and global air pollution, industrial engineers, and academic researchers have made many efforts to construct more efficient and environment-friendly vehicles. Hybrid electric vehicles (HEVs) are the representative ones because they can satisfy the power demand by coordinating energy supplements among different energy storage devices. To achieve this goal, energy management approaches are crucial technology, and driving cycles are the critical influence factor. Therefore, this paper aims to summarize driving cycle-driven energy management strategies (EMSs) for HEVs. First, the definition and significance of driving cycles in the energy management field are clarified, and the recent literature in this research domain is reviewed and revisited. In addition, according to the known information of driving cycles, the EMSs are divided into three categories, and the relevant study directions, such as standard driving cycles, long-term driving cycle generation (LT-DCG) and short-term driving cycle prediction (ST-DCP) are illuminated and analyzed. Furthermore, the existing database of driving cycles in highway and urban aspects are displayed and discussed. Finally, this article also elaborates on the future prospects of energy management technologies related to driving cycles. This paper focusing on helping the relevant researchers realize the state-of-the-art of HEVs energy management field and also recognize its future development direction.      
### 4.A Temporal-to-Spatial Neural Network for Classification of Hand Movements from Electromyography Data  [ :arrow_down: ](https://arxiv.org/pdf/2007.10879.pdf)
>  Deep convolutional neural networks (CNNs) are appealing for the purpose of classification of hand movements from surface electromyography (sEMG) data because they have the ability to perform automated person-specific feature extraction from raw data. In this paper, we make the novel contribution of proposing and evaluating a design for the early processing layers in the deep CNN for multichannel sEMG. Specifically, we propose a novel temporal-to-spatial (TtS) CNN architecture, where the first layer performs convolution separately on each sEMG channel to extract temporal features. This is motivated by the idea that sEMG signals in each channel are mediated by one or a small subset of muscles, whose temporal activation patterns are associated with the signature features of a gesture. The temporal layer captures these signature features for each channel separately, which are then spatially mixed in successive layers to recognise a specific gesture. A practical advantage is that this approach also makes the CNN simple to design for different sample rates. We use NinaPro database 1 (27 subjects and 52 movements + rest), sampled at 100 Hz, and database 2 (40 subjects and 40 movements + rest), sampled at 2 kHz, to evaluate our proposed CNN design. We benchmark against a feature-based support vector machine (SVM) classifier, two CNNs from the literature, and an additional standard design of CNN. We find that our novel TtS CNN design achieves 66.6% per-class accuracy on database 1, and 67.8% on database 2, and that the TtS CNN outperforms all other compared classifiers using a statistical hypothesis test at the 2% significance level.      
### 5.Automated and Sound Synthesis of Lyapunov Functions with SMT Solvers  [ :arrow_down: ](https://arxiv.org/pdf/2007.10865.pdf)
>  In this paper we employ SMT solvers to soundly synthesise Lyapunov functions that assert the stability of a given dynamical model. The search for a Lyapunov function is framed as the satisfiability of a second-order logical formula, asking whether there exists a function satisfying a desired specification (stability) for all possible initial conditions of the model. We synthesise Lyapunov functions for linear, non-linear (polynomial), and for parametric models. For non-linear models, the algorithm also determines a region of validity for the Lyapunov function. We exploit an inductive framework to synthesise Lyapunov functions, starting from parametric templates. The inductive framework comprises two elements: a learner proposes a Lyapunov function, and a verifier checks its validity - its lack is expressed via a counterexample (a point over the state space), for further use by the learner. Whilst the verifier uses the SMT solver Z3, thus ensuring the overall soundness of the procedure, we examine two alternatives for the learner: a numerical approach based on the optimisation tool Gurobi, and a sound approach based again on Z3. The overall technique is evaluated over a broad set of benchmarks, which shows that this methodology not only scales to 10-dimensional models within reasonable computational time, but also offers a novel soundness proof for the generated Lyapunov functions and their domains of validity.      
### 6.Critical Clearing Time Sensitivity for Differential-Algebraic Power System Model  [ :arrow_down: ](https://arxiv.org/pdf/2007.10813.pdf)
>  Standard power systems are modeled using differential-algebraic equations (DAE). Following a transient event, voltage collapse can occur as a bifurcation of the transient load flow solutions which is marked by the system trajectory reaching a singular surface in state space where the voltage causality is lost. If the system is under such a risk, preventive control decisions such as changes in AVR setpoints need to be taken to enhance the stability. In this regard, the knowledge of sensitivity of critical clearing time (CCT) to controllable system parameters can be of great help. The stability boundary of DAE systems is more complicated than ODE systems where in addition to stable manifolds of unstable equilibrium points (UEP) and periodic orbits, singular surfaces play an important role. In the present work, we derive the expressions for CCT sensitivity for a generic DAE model using trajectory sensitivities with applications to power system transient stability analysis (TSA) and preventive control. The results are illustrated for multiple test systems which are then validated against computationally intensive time-domain simulations (TDS).      
### 7.Anomaly Detection in Unsupervised Surveillance Setting Using Ensemble of Multimodal Data with Adversarial Defense  [ :arrow_down: ](https://arxiv.org/pdf/2007.10812.pdf)
>  Autonomous aerial surveillance using drone feed is an interesting and challenging research domain. To ensure safety from intruders and potential objects posing threats to the zone being protected, it is crucial to be able to distinguish between normal and abnormal states in real-time. Additionally, we also need to consider any device malfunction. However, the inherent uncertainty embedded within the type and level of abnormality makes supervised techniques less suitable since the adversary may present a unique anomaly for intrusion. As a result, an unsupervised method for anomaly detection is preferable taking the unpredictable nature of attacks into account. Again in our case, the autonomous drone provides heterogeneous data streams consisting of images and other analog or digital sensor data, all of which can play a role in anomaly detection if they are ensembled synergistically. To that end, an ensemble detection mechanism is proposed here which estimates the degree of abnormality of analyzing the real-time image and IMU (Inertial Measurement Unit) sensor data in an unsupervised manner. First, we have implemented a Convolutional Neural Network (CNN) regression block, named AngleNet to estimate the angle between a reference image and current test image, which provides us with a measure of the anomaly of the device. Moreover, the IMU data are used in autoencoders to predict abnormality. Finally, the results from these two pipelines are ensembled to estimate the final degree of abnormality. Furthermore, we have applied adversarial attack to test the robustness and security of the proposed approach and integrated defense mechanism. The proposed method performs satisfactorily on the IEEE SP Cup-2020 dataset with an accuracy of 97.8%. Additionally, we have also tested this approach on an in-house dataset to validate its robustness.      
### 8.Hue-Correction Scheme Considering Non-Linear Camera Response for Multi-Exposure Image Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2007.10802.pdf)
>  We propose a novel hue-correction scheme for multi-exposure image fusion (MEF). Various MEF methods have so far been studied to generate higher-quality images. However, there are few MEF methods considering hue distortion unlike other fields of image processing, due to a lack of a reference image that has correct hue. In the proposed scheme, we generate an HDR image as a reference for hue correction, from input multi-exposure images. After that, hue distortion in images fused by an MEF method is removed by using hue information of the HDR one, on the basis of the constant-hue plane in the RGB color space. In simulations, the proposed scheme is demonstrated to be effective to correct hue-distortion caused by conventional MEF methods. Experimental results also show that the proposed scheme can generate high-quality images, regardless of exposure conditions of input multi-exposure images.      
### 9.Label-free detection of Giardia lamblia cysts using a deep learning-enabled portable imaging flow cytometer  [ :arrow_down: ](https://arxiv.org/pdf/2007.10795.pdf)
>  We report a field-portable and cost-effective imaging flow cytometer that uses deep learning to accurately detect Giardia lamblia cysts in water samples at a volumetric throughput of 100 mL/h. This flow cytometer uses lensfree color holographic imaging to capture and reconstruct phase and intensity images of microscopic objects in a continuously flowing sample, and automatically identifies Giardia Lamblia cysts in real-time without the use of any labels or fluorophores. The imaging flow cytometer is housed in an environmentally-sealed enclosure with dimensions of 19 cm x 19 cm x 16 cm and weighs 1.6 kg. We demonstrate that this portable imaging flow cytometer coupled to a laptop computer can detect and quantify, in real-time, low levels of Giardia contamination (e.g., &lt;10 cysts per 50 mL) in both freshwater and seawater samples. The field-portable and label-free nature of this method has the potential to allow rapid and automated screening of drinking water supplies in resource limited settings in order to detect waterborne parasites and monitor the integrity of the filters used for water treatment.      
### 10.Limited-angle tomographic reconstruction of dense layered objects by dynamical machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.10734.pdf)
>  Limited-angle tomography of strongly scattering quasi-transparent objects is a challenging, highly ill-posed problem with practical implications in medical and biological imaging, manufacturing, automation, and environmental and food security. Regularizing priors are necessary to reduce artifacts by improving the condition of such problems. Recently, it was shown that one effective way to learn the priors for strongly scattering yet highly structured 3D objects, e.g. layered and Manhattan, is by a static neural network [Goy et al, Proc. Natl. Acad. Sci. 116, 19848-19856 (2019)]. Here, we present a radically different approach where the collection of raw images from multiple angles is viewed analogously to a dynamical system driven by the object-dependent forward scattering operator. The sequence index in angle of illumination plays the role of discrete time in the dynamical system analogy. Thus, the imaging problem turns into a problem of nonlinear system identification, which also suggests dynamical learning as better fit to regularize the reconstructions. We devised a recurrent neural network (RNN) architecture with a novel split-convolutional gated recurrent unit (SC-GRU) as the fundamental building block. Through comprehensive comparison of several quantitative metrics, we show that the dynamic method improves upon previous static approaches with fewer artifacts and better overall reconstruction fidelity.      
### 11.Optimization of data-driven filterbank for automatic speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2007.10729.pdf)
>  Most of the speech processing applications use triangular filters spaced in mel-scale for feature extraction. In this paper, we propose a new data-driven filter design method which optimizes filter parameters from a given speech data. First, we introduce a frame-selection based approach for developing speech-signal-based frequency warping scale. Then, we propose a new method for computing the filter frequency responses by using principal component analysis (PCA). The main advantage of the proposed method over the recently introduced deep learning based methods is that it requires very limited amount of unlabeled speech-data. We demonstrate that the proposed filterbank has more speaker discriminative power than commonly used mel filterbank as well as existing data-driven filterbank. We conduct automatic speaker verification (ASV) experiments with different corpora using various classifier back-ends. We show that the acoustic features created with proposed filterbank are better than existing mel-frequency cepstral coefficients (MFCCs) and speech-signal-based frequency cepstral coefficients (SFCCs) in most cases. In the experiments with VoxCeleb1 and popular i-vector back-end, we observe 9.75% relative improvement in equal error rate (EER) over MFCCs. Similarly, the relative improvement is 4.43% with recently introduced x-vector system. We obtain further improvement using fusion of the proposed method with standard MFCC-based approach.      
### 12.Audio Adversarial Examples for Robust Hybrid CTC/Attention Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2007.10723.pdf)
>  Recent advances in Automatic Speech Recognition (ASR) demonstrated how end-to-end systems are able to achieve state-of-the-art performance. There is a trend towards deeper neural networks, however those ASR models are also more complex and prone against specially crafted noisy data. Those Audio Adversarial Examples (AAE) were previously demonstrated on ASR systems that use Connectionist Temporal Classification (CTC), as well as attention-based encoder-decoder architectures. Following the idea of the hybrid CTC/attention ASR system, this work proposes algorithms to generate AAEs to combine both approaches into a joint CTC-attention gradient method. Evaluation is performed using a hybrid CTC/attention end-to-end ASR model on two reference sentences as case study, as well as the TEDlium v2 speech recognition task. We then demonstrate the application of this algorithm for adversarial training to obtain a more robust ASR model.      
### 13.Very Fast Keyword Spotting System with Real Time Factor below 0.01  [ :arrow_down: ](https://arxiv.org/pdf/2007.10706.pdf)
>  In the paper we present an architecture of a keyword spotting (KWS) system that is based on modern neural networks, yields good performance on various types of speech data and can run very fast. We focus mainly on the last aspect and propose optimizations for all the steps required in a KWS design: signal processing and likelihood computation, Viterbi decoding, spot candidate detection and confidence calculation. We present time and memory efficient modelling by bidirectional feedforward sequential memory networks (an alternative to recurrent nets) either by standard triphones or so called quasi-monophones, and an entirely forward decoding of speech frames (with minimal need for look back). Several variants of the proposed scheme are evaluated on 3 large Czech datasets (broadcast, internet and telephone, 17 hours in total) and their performance is compared by Detection Error Tradeoff (DET) diagrams and real-time (RT) factors. We demonstrate that the complete system can run in a single pass with a RT factor close to 0.001 if all optimizations (including a GPU for likelihood computation) are applied.      
### 14.Mutual Information Matrix for Interpretable Fault Detection  [ :arrow_down: ](https://arxiv.org/pdf/2007.10692.pdf)
>  This paper presents a novel mutual information (MI) matrix based method for fault detection. Given a m-dimensional fault process, the MI matrix is a m$\times$m matrix in which the (i,j)-th entry measures the MI values between the i-th dimension and the j-th dimension variables. We demonstrate that the transformed components extracted from the obtained MI matrix can precisely unveil the dynamics of the underlying (possibly nonlinear) process, thus offering a reliable indicator to the occurrence of different types of faults. We also suggest that the recently proposed matrix-based Renyi's $\alpha$-entropy is a good surrogate to the classical Shannon's entropy in MI estimation. Experiments on both synthetic data and the benchmark Tennessee Eastman process demonstrate the interpretability of our methodology in identifying the root variables that cause the faults, and the superiority of our methodology in terms the improved fault detection rate (FDR) and the lowest false alarm rate (FAR).      
### 15.Fully Automated Segmentation of the Left Ventricle in Magnetic Resonance Images  [ :arrow_down: ](https://arxiv.org/pdf/2007.10665.pdf)
>  Automatic and robust segmentation of the left ventricle (LV) in magnetic resonance images (MRI) has remained challenging for many decades. With the great success of deep learning in object detection and classification, the research focus of LV segmentation has changed to convolutional neural network (CNN) in recent years. However, LV segmentation is a pixel-level classification problem and its categories are intractable compared to object detection and classification. Although lots of CNN based methods have been proposed for LV segmentation, no robust and reproducible results are achieved yet. In this paper, we try to reproduce the CNN based LV segmentation methods with their disclosed codes and trained CNN models. Not surprisingly, the reproduced results are significantly worse than their claimed accuracies. We also proposed a fully automated LV segmentation method based on slope difference distribution (SDD) threshold selection to compare with the reproduced CNN methods. The proposed method achieved 95.44% DICE score on the test set of automated cardiac diagnosis challenge (ACDC) while the two compared CNN methods achieved 90.28% and 87.13% DICE scores. Our achieved accuracy is also higher than the best accuracy reported in the published literatures. The MATLAB codes of our proposed method are freely available on line.      
### 16.Flow Sampling: Accurate and Load-balanced Sampling Policies  [ :arrow_down: ](https://arxiv.org/pdf/2007.10660.pdf)
>  Software-defined networking simplifies network monitoring by means of per-flow sampling, wherein the controller keeps track of the active flows in the network and samples the switches on each flow path to collect the flow statistics. A tradeoff in this process is between the controller's sampling preference and the balancing of loads among switches. On the one hand, the controller may prefer to sample some of the switches on the flow path because they yield more accurate flow statistics. On the other hand, it is desirable to sample the switches uniformly so that their resource consumptions and lifespan are balanced. Focusing on the application of traffic matrix estimation, this paper formulates the per-flow sampling problem as a Markov decision process and devises policies that can achieve good tradeoffs between sampling accuracy and load balancing. Three classes of policies are investigated: the optimal policy, the state-independent policies, and the index policies, including the Whittle index and a second-order index policies. The second-order index policy is the most desired policy among all: 1) in terms of performance, it is on an equal footing with the Whittle index policy, and outperforms the state-independent policies by much; 2) in terms of complexity, it is much simpler than the optimal policy, and is comparable to state-independent policies and the Whittle index policy; 3) in terms of realizability, it requires no prior information on the network dynamics, hence is much easier to implement in practice.      
### 17.Gasper: GrAph Signal ProcEssing in R  [ :arrow_down: ](https://arxiv.org/pdf/2007.10642.pdf)
>  We present a short tutorial on to the use of the R gasper package. Gasper is a package dedicated to signal processing on graphs.      
### 18.SLNSpeech: solving extended speech separation problem by the help of sign language  [ :arrow_down: ](https://arxiv.org/pdf/2007.10629.pdf)
>  A speech separation task can be roughly divided into audio-only separation and audio-visual separation. In order to make speech separation technology applied in the real scenario of the disabled, this paper presents an extended speech separation problem which refers in particular to sign language assisted speech separation. However, most existing datasets for speech separation are audios and videos which contain audio and/or visual modalities. To address the extended speech separation problem, we introduce a large-scale dataset named Sign Language News Speech (SLNSpeech) dataset in which three modalities of audio, visual, and sign language are coexisted. Then, we design a general deep learning network for the self-supervised learning of three modalities, particularly, using sign language embeddings together with audio or audio-visual information for better solving the speech separation task. Specifically, we use 3D residual convolutional network to extract sign language features and use pretrained VGGNet model to exact visual features. After that, an improved U-Net with skip connections in feature extraction stage is applied for learning the embeddings among the mixed spectrogram transformed from source audios, the sign language features and visual features. Experiments results show that, besides visual modality, sign language modality can also be used alone to supervise speech separation task. Moreover, we also show the effectiveness of sign language assisted speech separation when the visual modality is disturbed. Source code will be released in http://cheertt.top/homepage/      
### 19.Cognitive IoT based Health Monitoring Scheme using Non-Orthogonal Multiple Access  [ :arrow_down: ](https://arxiv.org/pdf/2007.10607.pdf)
>  It has become very essential to address the limited spectrum capacity and their efficient utilization to support the increasing number of Internet of Things devices. When it comes to medical infrastructure, it becomes very imperative for medical devices to communicate with the base station. In such situations, communication over the wireless medium must provide optimized throughput (data rate) with effectual energy usage, which will ensure precise medical feedback by the responsible staff. Taking into account, it is necessary to operate wireless communication precisely at a higher frequency with more substantial bandwidth and low latency. Cognitive Radio (CR) is traditionally a viable choice, where it identifies and utilizes the vacant spectrum, thus maximizing the primary user's capacity and achieving spectral efficiency. To ensure such outcomes, the Non-Orthogonal Multiple Access (NOMA) techniques have proven to deliver an effective solution to the increasing number of devices with unimpaired performance, especially when the communication shifts towards a higher frequency band such as the mmWave band. In this chapter, IoT based CR network in uplink communication is proposed alongside employing NOMA techniques for optimal throughput, and energy efficiency for a medical infrastructure. Numerical results show that effectual throughput and energy efficiency for a High Reliable Communication (HRC) device and Moderate Reliable Communication (MRC) device improve over 83.13% and 73.95%, respectively and their corresponding energy efficacy values show vast improvement (83.11% and 73.96% respectively). Likewise, for interference case both the throughput and the energy efficiency improve approximately over 93% for all devices.      
### 20.Complex ResNet Aided DoA Estimation for Near-Field MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2007.10590.pdf)
>  The near-field effect of short-range multiple-input multiple-output (MIMO) systems imposes many challenges on direction-of-arrival (DoA) estimation. Most conventional scenarios assume that the far-field planar wavefronts hold. In this paper, we investigate the DoA estimation problem in short-range MIMO communications, where the effect of near-field spherical wave is non-negligible. By converting it into a regression task, a novel DoA estimation framework based on complex-valued deep learning (CVDL) is proposed for the near-field region in short-range MIMO communication systems. Under the assumption of a spherical wave model, the array steering vector is determined by both the distance and the direction. However, solving this regression task containing a massive number of variables is challenging, since datasets need to capture numerous complicated feature representations. To overcome this, a virtual covariance matrix (VCM) based on received signals is constructed, and thus such features extracted from the VCM can deal with the complicated coupling relationship between the direction and the distance. Although the emergence of wireless big data driven by future communication networks promotes deep learning-based wireless signal processing, the learning algorithms of complex-valued signals are still ongoing. This paper proposes a one-dimensional (1-D) residual network that can directly tackle complex-valued features due to the inherent 1-D structure of signal subspace vectors. In addition, we put forth a cropped VCM based policy which can be applied to different antenna sizes. The proposed method is able to fully exploit the complex-valued information. Our simulation results demonstrate the superiority of the proposed CVDL approach over the baseline schemes in terms of the accuracy of DoA estimation.      
### 21.Identification of Utility-Scale Renewable Energy Penetration Threshold in a Dynamic Setting  [ :arrow_down: ](https://arxiv.org/pdf/2007.10569.pdf)
>  Integration of renewable energy resources with the electric grid is necessary for a sustainable energy future. However, increased penetration of inverter based resources (IBRs) reduce grid inertia, which might then compromise power system reliability. Therefore, power utilities are often interested in identifying the maximum IBR penetration limit for their system. The proposed research presents a methodology to identify the IBR penetration threshold beyond which voltage, frequency, and tie-line limits will be exceeded. The sensitivity of the IBR penetration threshold to momentary cessation due to low voltages, transmission versus distribution connected solar generation, and stalling of induction motors are also analyzed. Dynamic simulation studies conducted on a 24,000-bus model of the Western Interconnection (WI) demonstrate the practicality of the proposed approach.      
### 22.Power Allocation for Coexisting Multicarrier Radar and Communication Systems in Cluttered Environments  [ :arrow_down: ](https://arxiv.org/pdf/2007.10542.pdf)
>  In this paper, power allocation is examined for the coexistence of a radar and a communication system that employ multicarrier waveforms. We propose two designs for the considered spectrum sharing problem by maximizing the output signal-to-interference-plus-noise ratio (SINR) at the radar receiver while maintaining certain communication throughput and power constraints. The first is a joint design where the subchannel powers of both the radar and communication systems are jointly optimized. Since the resulting problem is highly nonconvex, we introduce a reformulation by combining the power variables of both systems into a single stacked variable, which allows us to bypass a conventional computationally intensive alternating optimization procedure. The resulting problem is then solved via a quadratic transform method along with a sequential convex programming (SCP) technique. The second is a unilateral design which optimizes the radar transmission power with fixed communication power. The unilateral design is suitable for cases where the communication system pre-exists while the radar occasionally joins the channel as a secondary user. The problem is solved by a Taylor expansion based iterative SCP procedure. Numerical results are presented to demonstrate the effectiveness of the proposed joint and unilateral designs in comparison with a subcarrier allocation based method.      
### 23.Deep multi-metric learning for text-independent speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2007.10479.pdf)
>  Text-independent speaker verification is an important artificial intelligence problem that has a wide spectrum of applications, such as criminal investigation, payment certification, and interest-based customer services. The purpose of text-independent speaker verification is to determine whether two given uncontrolled utterances originate from the same speaker or not. Extracting speech features for each speaker using deep neural networks is a promising direction to explore and a straightforward solution is to train the discriminative feature extraction network by using a metric learning loss function. However, a single loss function often has certain limitations. Thus, we use deep multi-metric learning to address the problem and introduce three different losses for this problem, i.e., triplet loss, n-pair loss and angular loss. The three loss functions work in a cooperative way to train a feature extraction network equipped with Residual connections and squeeze-and-excitation attention. We conduct experiments on the large-scale \texttt{VoxCeleb2} dataset, which contains over a million utterances from over $6,000$ speakers, and the proposed deep neural network obtains an equal error rate of $3.48\%$, which is a very competitive result. Codes for both training and testing and pretrained models are available at \url{<a class="link-external link-https" href="https://github.com/GreatJiweix/DmmlTiSV" rel="external noopener nofollow">this https URL</a>}, which is the first publicly available code repository for large-scale text-independent speaker verification with performance on par with the state-of-the-art systems.      
### 24.Active MR k-space Sampling with Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.10469.pdf)
>  Deep learning approaches have recently shown great promise in accelerating magnetic resonance image (MRI) acquisition. The majority of existing work have focused on designing better reconstruction models given a pre-determined acquisition trajectory, ignoring the question of trajectory optimization. In this paper, we focus on learning acquisition trajectories given a fixed image reconstruction model. We formulate the problem as a sequential decision process and propose the use of reinforcement learning to solve it. Experiments on a large scale public MRI dataset of knees show that our proposed models significantly outperform the state-of-the-art in active MRI acquisition, over a large range of acceleration factors.      
### 25.Detection, Attribution and Localization of GAN Generated Images  [ :arrow_down: ](https://arxiv.org/pdf/2007.10466.pdf)
>  Recent advances in Generative Adversarial Networks (GANs) have led to the creation of realistic-looking digital images that pose a major challenge to their detection by humans or computers. GANs are used in a wide range of tasks, from modifying small attributes of an image (StarGAN [14]), transferring attributes between image pairs (CycleGAN [91]), as well as generating entirely new images (ProGAN [36], StyleGAN [37], SPADE/GauGAN [64]). In this paper, we propose a novel approach to detect, attribute and localize GAN generated images that combines image features with deep learning methods. For every image, co-occurrence matrices are computed on neighborhood pixels of RGB channels in different directions (horizontal, vertical and diagonal). A deep learning network is then trained on these features to detect, attribute and localize these GAN generated/manipulated images. A large scale evaluation of our approach on 5 GAN datasets comprising over 2.76 million images (ProGAN, StarGAN, CycleGAN, StyleGAN and SPADE/GauGAN) shows promising results in detecting GAN generated images.      
### 26.Zero-Error Tracking for Autonomous Vehicles through Epsilon-Trajectory Generation  [ :arrow_down: ](https://arxiv.org/pdf/2007.10441.pdf)
>  This paper presents a control method and trajectory planner for vehicles with first-order nonholonomic constraints that guarantee asymptotic convergence to a time-indexed trajectory. To overcome the nonholonomic constraint, a fixed point in front of the vehicle can be controlled to track a desired trajectory, albeit with a steady-state error. To eliminate steady state error, a sufficiently smooth trajectory is reformulated for the new reference point such that, when tracking the new trajectory, the vehicle asymptotically converges to the original trajectory. The resulting zero-error tracking law is demonstrated through a novel framework for creating time-indexed Clothoids. The Clothoids can be planned to pass through arbitrary waypoints using traditional methods yet result in trajectories that can be followed with zero steady-state error. The results of the control method and planner are illustrated in simulation wherein zero-error tracking is demonstrated.      
### 27.Integrative Analysis for COVID-19 Patient Outcome Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2007.10416.pdf)
>  While image analysis of chest computed tomography (CT) for COVID-19 diagnosis has been intensively studied, little work has been performed for image-based patient outcome prediction. Management of high-risk patients with early intervention is a key to lower the fatality rate of COVID-19 pneumonia, as a majority of patients recover naturally. Therefore, an accurate prediction of disease progression with baseline imaging at the time of the initial presentation can help in patient management. In lieu of only size and volume information of pulmonary abnormalities and features through deep learning based image segmentation, here we combine radiomics of lung opacities and non-imaging features from demographic data, vital signs, and laboratory findings to predict need for intensive care unit (ICU) admission. To our knowledge, this is the first study that uses holistic information of a patient including both imaging and non-imaging data for outcome prediction. The proposed methods were thoroughly evaluated on datasets separately collected from three hospitals, one in the United States, one in Iran, and another in Italy, with a total 295 patients with reverse transcription polymerase chain reaction (RT-PCR) assay positive COVID-19 pneumonia. Our experimental results demonstrate that adding non-imaging features can significantly improve the performance of prediction to achieve AUC up to 0.884 and sensitivity as high as 96.1%, which can be valuable to provide clinical decision support in managing COVID-19 patients. Our methods may also be applied to other lung diseases including but not limited to community acquired pneumonia.      
### 28.Robust-Adaptive Interval Predictive Control for Linear Uncertain Systems  [ :arrow_down: ](https://arxiv.org/pdf/2007.10401.pdf)
>  We consider the problem of stabilization of a linear system, under state and control constraints, and subject to bounded disturbances and unknown parameters in the state matrix. First, using a simple least square solution and available noisy measurements, the set of admissible values for parameters is evaluated. Second, for the estimated set of parameter values and the corresponding linear interval model of the system, two interval predictors are recalled and an unconstrained stabilizing control is designed that uses the predicted intervals. Third, to guarantee the robust constraint satisfaction, a model predictive control algorithm is developed, which is based on solution of an optimization problem posed for the interval predictor. The conditions for recursive feasibility and asymptotic performance are established. Efficiency of the proposed control framework is illustrated by numeric simulations.      
### 29.Acoustic Neighbor Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2007.10329.pdf)
>  This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding (SNE) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained: an acoustic encoder that accepts speech signals in the form of frame-wise subword posterior probabilities obtained from an acoustic model and a text encoder that accepts text in the form of subword transcriptions. Compared to a known method based on a triplet loss, the proposed method is shown to have more effective gradients for neural network training. Experimentally, it also gives more accurate results when the two encoder networks are used in tandem in a word (name) recognition task, and when the text encoder network is used standalone in an approximate phonetic match task. In particular, in a name recognition task depending solely on the Euclidean distance between embedding vectors, the proposed embeddings can achieve recognition accuracy that closely approaches that of conventional finite state transducer(FST)-based decoding. For test data with 1K vocabularies, the accuracy difference is 0.6% points using only 18-dimensional embeddings, and for test data with a 1M vocabulary, the difference is 0.4% points using 100-dimensional embeddings.      
### 30.Foley Music: Learning to Generate Music from Videos  [ :arrow_down: ](https://arxiv.org/pdf/2007.10984.pdf)
>  In this paper, we introduce Foley Music, a system that can synthesize plausible music for a silent video clip about people playing musical instruments. We first identify two key intermediate representations for a successful video to music generator: body keypoints from videos and MIDI events from audio recordings. We then formulate music generation from videos as a motion-to-MIDI translation problem. We present a Graph$-$Transformer framework that can accurately predict MIDI event sequences in accordance with the body movements. The MIDI event can then be converted to realistic music using an off-the-shelf music synthesizer tool. We demonstrate the effectiveness of our models on videos containing a variety of music performances. Experimental results show that our model outperforms several existing systems in generating music that is pleasant to listen to. More importantly, the MIDI representations are fully interpretable and transparent, thus enabling us to perform music editing flexibly. We encourage the readers to watch the demo video with audio turned on to experience the results.      
### 31.Shape and Viewpoint without Keypoints  [ :arrow_down: ](https://arxiv.org/pdf/2007.10982.pdf)
>  We present a learning framework that learns to recover the 3D shape, pose and texture from a single image, trained on an image collection without any ground truth 3D shape, multi-view, camera viewpoints or keypoint supervision. We approach this highly under-constrained problem in a "analysis by synthesis" framework where the goal is to predict the likely shape, texture and camera viewpoint that could produce the image with various learned category-specific priors. Our particular contribution in this paper is a representation of the distribution over cameras, which we call "camera-multiplex". Instead of picking a point estimate, we maintain a set of camera hypotheses that are optimized during training to best explain the image given the current shape and texture. We call our approach Unsupervised Category-Specific Mesh Reconstruction (U-CMR), and present qualitative and quantitative results on CUB, Pascal 3D and new web-scraped datasets. We obtain state-of-the-art camera prediction results and show that we can learn to predict diverse shapes and textures across objects using an image collection without any keypoint annotations or 3D ground truth. Project page: <a class="link-external link-https" href="https://shubham-goel.github.io/ucmr" rel="external noopener nofollow">this https URL</a>      
### 32.Modern Design Methodologies and the Development of Mechatronic Products  [ :arrow_down: ](https://arxiv.org/pdf/2007.10962.pdf)
>  This article presents a quick view on the development of mechatronic products and how the techniques of Design Thinking, Concurrent Engineering and Agilism can be integrated to address this development. Design Thinking is employed in the early stages in order to better explore creativity, whereas Concurrent Engineering and Agilism are applied during the development of the product, in order to deal with emerging requirements, typical of the development of complex products.      
### 33.UAV Target Tracking in Urban Environments Using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.10934.pdf)
>  Persistent target tracking in urban environments using UAV is a difficult task due to the limited field of view, visibility obstruction from obstacles and uncertain target motion. The vehicle needs to plan intelligently in 3D such that the target visibility is maximized. In this paper, we introduce Target Following DQN (TF-DQN), a deep reinforcement learning technique based on Deep Q-Networks with a curriculum training framework for the UAV to persistently track the target in the presence of obstacles and target motion uncertainty. The algorithm is evaluated through several simulation experiments qualitatively as well as quantitatively. The results show that the UAV tracks the target persistently in diverse environments while avoiding obstacles on the trained environments as well as on unseen environments.      
### 34.Time-Frequency Scattering Accurately Models Auditory Similarities Between Instrumental Playing Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2007.10926.pdf)
>  Instrumental playing techniques such as vibratos, glissandos, and trills often denote musical expressivity, both in classical and folk contexts. However, most existing approaches to music similarity retrieval fail to describe timbre beyond the so-called ``ordinary'' technique, use instrument identity as a proxy for timbre quality, and do not allow for customization to the perceptual idiosyncrasies of a new subject. In this article, we ask 31 human subjects to organize 78 isolated notes into a set of timbre clusters. Analyzing their responses suggests that timbre perception operates within a more flexible taxonomy than those provided by instruments or playing techniques alone. In addition, we propose a machine listening model to recover the cluster graph of auditory similarities across instruments, mutes, and techniques. Our model relies on joint time--frequency scattering features to extract spectrotemporal modulations as acoustic features. Furthermore, it minimizes triplet loss in the cluster graph by means of the large-margin nearest neighbor (LMNN) metric learning algorithm. Over a dataset of 9346 isolated notes, we report a state-of-the-art average precision at rank five (AP@5) of $99.0\%\pm1$. An ablation study demonstrates that removing either the joint time--frequency scattering transform or the metric learning algorithm noticeably degrades performance.      
### 35.DeepNetQoE: Self-adaptive QoE Optimization Framework of Deep Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.10878.pdf)
>  Future advances in deep learning and its impact on the development of artificial intelligence (AI) in all fields depends heavily on data size and computational power. Sacrificing massive computing resources in exchange for better precision rates of the network model is recognized by many researchers. This leads to huge computing consumption and satisfactory results are not always expected when computing resources are limited. Therefore, it is necessary to find a balance between resources and model performance to achieve satisfactory results. This article proposes a self-adaptive quality of experience (QoE) framework, DeepNetQoE, to guide the training of deep networks. A self-adaptive QoE model is set up that relates the model's accuracy with the computing resources required for training which will allow the experience value of the model to improve. To maximize the experience value when computer resources are limited, a resource allocation model and solutions need to be established. In addition, we carry out experiments based on four network models to analyze the experience values with respect to the crowd counting example. Experimental results show that the proposed DeepNetQoE is capable of adaptively obtaining a high experience value according to user needs and therefore guiding users to determine the computational resources allocated to the network models.      
### 36.Ratio of Products of Mixture Gamma Variates with Applications to Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2007.10826.pdf)
>  In this paper, the statistical properties of the product of independent and non-identically distributed mixture Gamma (MG) random variables (RVs) are provided first. Specifically, simple exact closed-form expressions for the probability density function (PDF), cumulative distribution function (CDF), and moment generating function (MGF) are derived in terms of univariate Meijer's $G$-function. The statistical characterisations of the distribution of the ratio of products of MG variates are then derived. These statistics are used to analyse the outage probability (OP), the average error probability for different modulation schemes, the effective rate (ER) of communications systems and the average area under the receiver operating characteristics (AUC) curve of energy detection over cascaded fading channels. Additionally, the lower bound of secure outage probability (SOP$^L$) and probability of non-zero secrecy capacity (PNSC) of the physical layer and the OP of the multihop communications systems with decode-and-forward (DF) relaying protocol and co-channel interference (CCI) are studied by utilising the statistics of the ratio of the products. The derived performance metrics are applied for the Beaulieu-Xie and $\alpha-\lambda-\eta-\mu$ shadowed fading channels that have not been yet investigated in the literature. Accordingly, the equivalent parameters of a MG distribution for the aforementioned channels are given. A comparison between the numerical results and the Monte Carlo simulations is presented to verify the validation of our analysis.      
### 37.Lymphocyte counting -- Error Analysis of Regression versus Bounding Box Detection Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2007.10817.pdf)
>  We consider the problem of counting cell nuclei from celltype-agnostic histopathological stains, exemplified here by the Haematoxylin and Eosin stain. We compare direct estimation by classification and regression against bounding box prediction models for a dataset with relatively low sample sizes. We find from a fine-grained analysis of MSE errors that all models suffer from a substantial underestimation bias. Detection models, while more capricious and sensitive in training, are more robust against underestimation in their optimum. Furthermore the simple idea of combining models from different prediction setups results in large improvements.      
### 38.Infinite Sequences, Series Convergence and the Discrete Time Fourier Transform over Finite Fields  [ :arrow_down: ](https://arxiv.org/pdf/2007.10816.pdf)
>  Digital Transforms have important applications on subjects such as channel coding, cryptography and digital signal processing. In this paper, two Fourier Transforms are considered, the discrete time Fourier transform (DTFT) and the finite field Fourier transform (FFFT). A finite field version of the DTFT is introduced and the FFFT is redefined with a complex kernel, which makes it a more appropriate finite field version of the Discrete Fourier Transform. These transforms can handle FIR and IIR filters defined over finite algebraic structures.      
### 39.Probabilistic Neighbourhood Component Analysis: Sample Efficient Uncertainty Estimation in Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.10800.pdf)
>  While Deep Neural Networks (DNNs) achieve state-of-the-art accuracy in various applications, they often fall short in accurately estimating their predictive uncertainty and, in turn, fail to recognize when these predictions may be wrong. Several uncertainty-aware models, such as Bayesian Neural Network (BNNs) and Deep Ensembles have been proposed in the literature for quantifying predictive uncertainty. However, research in this area has been largely confined to the big data regime. In this work, we show that the uncertainty estimation capability of state-of-the-art BNNs and Deep Ensemble models degrades significantly when the amount of training data is small. To address the issue of accurate uncertainty estimation in the small-data regime, we propose a probabilistic generalization of the popular sample-efficient non-parametric kNN approach. Our approach enables deep kNN classifier to accurately quantify underlying uncertainties in its prediction. We demonstrate the usefulness of the proposed approach by achieving superior uncertainty quantification as compared to state-of-the-art on a real-world application of COVID-19 diagnosis from chest X-Rays. Our code is available at <a class="link-external link-https" href="https://github.com/ankurmallick/sample-efficient-uq" rel="external noopener nofollow">this https URL</a>      
### 40.Comparison of Different Methods for Time Sequence Prediction in Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2007.10786.pdf)
>  As a combination of various kinds of technologies, autonomous vehicles could complete a series of driving tasks by itself, such as perception, decision-making, planning, and control. Since there is no human driver to handle the emergency situation, future transportation information is significant for automated vehicles. This paper proposes different methods to forecast the time series for autonomous vehicles, which are the nearest neighborhood (NN), fuzzy coding (FC), and long short term memory (LSTM). First, the formulation and operational process for these three approaches are introduced. Then, the vehicle velocity is regarded as a case study and the real-world dataset is utilized to predict future information via these techniques. Finally, the performance, merits, and drawbacks of the presented methods are analyzed and discussed.      
### 41.Automated Detection and Forecasting of COVID-19 using Deep Learning Techniques: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2007.10785.pdf)
>  Coronavirus, or COVID-19, is a hazardous disease that has endangered the health of many people around the world by directly affecting the lungs. COVID-19 is a medium-sized, coated virus with a single-stranded RNA. This virus has one of the largest RNA genomes and is approximately 120 nm. The X-Ray and computed tomography (CT) imaging modalities are widely used to obtain a fast and accurate medical diagnosis. Identifying COVID-19 from these medical images is extremely challenging as it is time-consuming, demanding, and prone to human errors. Hence, artificial intelligence (AI) methodologies can be used to obtain consistent high performance. Among the AI methodologies, deep learning (DL) networks have gained much popularity compared to traditional machine learning (ML) methods. Unlike ML techniques, all stages of feature extraction, feature selection, and classification are accomplished automatically in DL models. In this paper, a complete survey of studies on the application of DL techniques for COVID-19 diagnostic and automated segmentation of lungs is discussed, concentrating on works that used X-Ray and CT images. Additionally, a review of papers on the forecasting of coronavirus prevalence in different parts of the world with DL techniques is presented. Lastly, the challenges faced in the automated detection of COVID-19 using DL techniques and directions for future research are discussed.      
### 42.Enhancement of damaged-image prediction through Cahn-Hilliard Image Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2007.10753.pdf)
>  We assess the benefit of including an image inpainting filter before passing damaged images into a classification neural network. For this we employ a modified Cahn-Hilliard equation as an image inpainting filter, which is solved via a finite volume scheme with reduced computational cost and adequate properties for energy stability and boundedness. The benchmark dataset employed here is the MNIST dataset, which consists in binary images of digits. We train a neural network based of dense layers with the training set of MNIST, and subsequently we contaminate the test set with damage of different types and intensities. We then compare the prediction accuracy of the neural network with and without applying the Cahn-Hilliard filter to the damaged images test. Our results quantify the significant improvement of damaged-image prediction due to applying the Cahn-Hilliard filter, which for specific damages can increase up to 50% and is in general advantageous for low to moderate damage.      
### 43.Learning to Read and Follow Music in Complete Score Sheet Images  [ :arrow_down: ](https://arxiv.org/pdf/2007.10736.pdf)
>  This paper addresses the task of score following in sheet music given as unprocessed images. While existing work either relies on OMR software to obtain a computer-readable score representation, or crucially relies on prepared sheet image excerpts, we propose the first system that directly performs score following in full-page, completely unprocessed sheet images. Based on incoming audio and a given image of the score, our system directly predicts the most likely position within the page that matches the audio, outperforming current state-of-the-art image-based score followers in terms of alignment precision. We also compare our method to an OMR-based approach and empirically show that it can be a viable alternative to such a system.      
### 44.Balance Scene Learning Mechanism for Offshore and Inshore Ship Detection in SAR Images  [ :arrow_down: ](https://arxiv.org/pdf/2007.10714.pdf)
>  This letter proposes a novel Balance Scene Learning Mechanism (BSLM) for both offshore and inshore ship detection in SAR images.      
### 45.Deep Preset: Blending and Retouching Photos with Color Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2007.10701.pdf)
>  End-users, without knowledge in photography, desire to beautify their photos to have a similar color style as a well-retouched reference. However, recent works in image style transfer are overused. They usually synthesize undesirable results due to transferring exact colors to the wrong destination. It becomes even worse in sensitive cases such as portraits. In this work, we concentrate on learning low-level image transformation, especially color-shifting methods, rather than mixing contextual features, then present a novel scheme to train color style transfer with ground-truth. Furthermore, we propose a color style transfer named Deep Preset. It is designed to 1) generalize the features representing the color transformation from content with natural colors to retouched reference, then blend it into the contextual features of content, 2) predict hyper-parameters (settings or preset) of the applied low-level color transformation methods, 3) stylize content to have a similar color style as reference. We script Lightroom, a powerful tool in editing photos, to generate 600,000 training samples using 1,200 images from the Flick2K dataset and 500 user-generated presets with 69 settings. Experimental results show that our Deep Preset outperforms the previous works in color style transfer quantitatively and qualitatively.      
### 46.Technical details of distributed localization  [ :arrow_down: ](https://arxiv.org/pdf/2007.10672.pdf)
>  This file proves the properties of the angle constraints and shows how to construct displacement constraints by various kinds of relative measurements.      
### 47.Guided multi-branch learning systems for DCASE 2020 Task 4  [ :arrow_down: ](https://arxiv.org/pdf/2007.10638.pdf)
>  In this paper, we describe in detail our systems for DCASE 2020 Task 4. The systems are based on the 1st-place system of DCASE 2019 Task 4, which adopts weakly-supervised framework with an attention-based embedding-level multiple instance learning pooling module and a semi-supervised learning approach named Guided learning (GL). This year, we incorporate Multiple branch learning (MBL) into the original system to further improve its performance. MBL makes different branches with different pooling strategies (including instance-level and embedding-level strategies) and different pooling modules (including attention pooling, global max pooling or global average pooling modules) share the same feature encoder of the model. Therefore, multiple branches pursuing different purposes and focusing on different characteristics of the data can help the feature encoder model the feature space better and avoid over-fitting. To better exploit the strongly-labeled synthetic data, inspired by multi-task learning, we also employ a sound event detection branch (SEDB). To combine sound separation (SS) with sound event detection (SED), we fuse the results of SED systems with SS-SED systems which are trained using separated sources output by an SS system. The experimental results prove that MBL can improve the model performance and using SS has great potential to improve the performance of SED ensemble system.      
### 48.AinnoSeg: Panoramic Segmentation with High Perfomance  [ :arrow_down: ](https://arxiv.org/pdf/2007.10591.pdf)
>  Panoramic segmentation is a scene where image segmentation tasks is more difficult. With the development of CNN networks, panoramic segmentation tasks have been sufficiently developed.However, the current panoramic segmentation algorithms are more concerned with context semantics, but the details of image are not processed enough. Moreover, they cannot solve the problems which contains the accuracy of occluded object segmentation,little object segmentation,boundary pixel in object segmentation etc. Aiming to address these issues, this paper presents some useful tricks. (a) By changing the basic segmentation model, the model can take into account the large objects and the boundary pixel classification of image details. (b) Modify the loss function so that it can take into account the boundary pixels of multiple objects in the image. (c) Use a semi-supervised approach to regain control of the training process. (d) Using multi-scale training and reasoning. All these operations named AinnoSeg, AinnoSeg can achieve state-of-art performance on the well-known dataset ADE20K.      
### 49.CyCNN: A Rotation Invariant CNN using Polar Mapping and Cylindrical Convolution Layers  [ :arrow_down: ](https://arxiv.org/pdf/2007.10588.pdf)
>  Deep Convolutional Neural Networks (CNNs) are empirically known to be invariant to moderate translation but not to rotation in image classification. This paper proposes a deep CNN model, called CyCNN, which exploits polar mapping of input images to convert rotation to translation. To deal with the cylindrical property of the polar coordinates, we replace convolution layers in conventional CNNs to cylindrical convolutional (CyConv) layers. A CyConv layer exploits the cylindrically sliding windows (CSW) mechanism that vertically extends the input-image receptive fields of boundary units in a convolutional layer. We evaluate CyCNN and conventional CNN models for classification tasks on rotated MNIST, CIFAR-10, and SVHN datasets. We show that if there is no data augmentation during training, CyCNN significantly improves classification accuracies when compared to conventional CNN models. Our implementation of CyCNN is publicly available on <a class="link-external link-https" href="https://github.com/mcrl/CyCNN" rel="external noopener nofollow">this https URL</a>.      
### 50.Heterogeneous Task Offloading and Resource Allocations via Deep Recurrent Reinforcement Learning in Partial Observable Multi-Fog Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.10581.pdf)
>  As wireless services and applications become more sophisticated and require faster and higher-capacity networks, there is a need for an efficient management of the execution of increasingly complex tasks based on the requirements of each application. In this regard, fog computing enables the integration of virtualized servers into networks and brings cloud services closer to end devices. In contrast to the cloud server, the computing capacity of fog nodes is limited and thus a single fog node might not be capable of computing-intensive tasks. In this context, task offloading can be particularly useful at the fog nodes by selecting the suitable nodes and proper resource management while guaranteeing the Quality-of-Service (QoS) requirements of the users. This paper studies the design of a joint task offloading and resource allocation control for heterogeneous service tasks in multi-fog nodes systems. This problem is formulated as a partially observable stochastic game, in which each fog node cooperates to maximize the aggregated local rewards while the nodes only have access to local observations. To deal with partial observability, we apply a deep recurrent Q-network (DRQN) approach to approximate the optimal value functions. The solution is then compared to a deep Q-network (DQN) and deep convolutional Q-network (DCQN) approach to evaluate the performance of different neural networks. Moreover, to guarantee the convergence and accuracy of the neural network, an adjusted exploration-exploitation method is adopted. Provided numerical results show that the proposed algorithm can achieve a higher average success rate and lower average overflow than baseline methods.      
### 51.Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing  [ :arrow_down: ](https://arxiv.org/pdf/2007.10558.pdf)
>  In this paper, we introduce a new problem, named audio-visual video parsing, which aims to parse a video into temporal event segments and label them as either audible, visible, or both. Such a problem is essential for a complete understanding of the scene depicted inside a video. To facilitate exploration, we collect a Look, Listen, and Parse (LLP) dataset to investigate audio-visual video parsing in a weakly-supervised manner. This task can be naturally formulated as a Multimodal Multiple Instance Learning (MMIL) problem. Concretely, we propose a novel hybrid attention network to explore unimodal and cross-modal temporal contexts simultaneously. We develop an attentive MMIL pooling method to adaptively explore useful audio and visual content from different temporal extent and modalities. Furthermore, we discover and mitigate modality bias and noisy label issues with an individual-guided learning mechanism and label smoothing technique, respectively. Experimental results show that the challenging audio-visual video parsing can be achieved even with only video-level weak labels. Our proposed framework can effectively leverage unimodal and cross-modal temporal contexts and alleviate modality bias and noisy labels problems.      
### 52.INS/Odometer Land Navigation by Accurate Measurement Modeling and Multiple-Model Adaptive Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2007.10543.pdf)
>  Land vehicle navigation based on inertial navigation system (INS) and odometers is a classical autonomous navigation application and has been extensively studied over the past several decades. In this work, we seriously analyze the error characteristics of the odometer (OD) pulses and investigate three types of odometer measurement models in the INS/OD integrated system. Specifically, in the pulse velocity model, a preliminary Kalman filter is designed to obtain accurate vehicle velocity from the accumulated pulses; the pulse increment model is accordingly obtained by integrating the pulse velocity; a new pulse accumulation model is proposed by augmenting the travelled distance into the system state. The three types of measurements, along with the nonhonolomic constraint (NHC), are implemented in the standard extended Kalman filter. In view of the motion-related pulse error characteristics, the multiple model adaptive estimation (MMAE) approach is exploited to further enhance the performance. Simulations and long-distance experiments are conducted to verify the feasibility and effectiveness of the proposed methods. It is shown that the standard pulse velocity measurement achieves the superior performance, whereas the accumulated pulse measurement is most favorable with the MMAE enhancement.      
### 53.Verification and Parameter Synthesis for Real-Time Programs using Refinement of Trace Abstraction  [ :arrow_down: ](https://arxiv.org/pdf/2007.10539.pdf)
>  We address the safety verification and synthesis problems for real-time systems. We introduce real-time programs that are made of instructions that can perform assignments to discrete and real-valued variables. They are general enough to capture interesting classes of timed systems such as timed automata, stopwatch automata, time(d) Petri nets and hybrid automata. <br>We propose a semi-algorithm using refinement of trace abstractions to solve both the reachability verification problem and the parameter synthesis problem for real-time programs. <br>All of the algorithms proposed have been implemented and we have conducted a series of experiments, comparing the performance of our new approach to state-of-the-art tools in classical reachability, robustness analysis and parameter synthesis for timed systems. We show that our new method provides solutions to problems which are unsolvable by the current state-of-the-art tools.      
### 54.DeepCorn: A Semi-Supervised Deep Learning Method for High-Throughput Image-Based Corn Kernel Counting and Yield Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2007.10521.pdf)
>  The success of modern farming and plant breeding relies on accurate and efficient collection of data. For a commercial organization that manages large amounts of crops, collecting accurate and consistent data is a bottleneck. Due to limited time and labor, accurately phenotyping crops to record color, head count, height, weight, etc. is severely limited. However, this information, combined with other genetic and environmental factors, is vital for developing new superior crop species that help feed the world's growing population. Recent advances in machine learning, in particular deep learning, have shown promise in mitigating this bottleneck. In this paper, we propose a novel deep learning method for counting on-ear corn kernels in-field to aid in the gathering of real-time data and, ultimately, to improve decision making to maximize yield. We name this approach DeepCorn, and show that this framework is robust under various conditions and can accurately and efficiently count corn kernels. We also adopt a semi-supervised learning approach to further improve the performance of our proposed method. Our experimental results demonstrate the superiority and effectiveness of our proposed method compared to other state-of-the-art methods.      
### 55.Effects of Approximate Multiplication on Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.10500.pdf)
>  This paper analyzes the effects of approximate multiplication when performing inferences on deep convolutional neural networks (CNNs). The approximate multiplication can reduce the cost of underlying circuits so that CNN inferences can be performed more efficiently in hardware accelerators. The study identifies the critical factors in the convolution, fully-connected, and batch normalization layers that allow more accurate CNN predictions despite the errors from approximate multiplication. The same factors also provide an arithmetic explanation of why bfloat16 multiplication performs well on CNNs. The experiments are performed with recognized network architectures to show that the approximate multipliers can produce predictions that are nearly as accurate as the FP32 references, without additional training. For example, the ResNet and Inception-v4 models with Mitch-$w$6 multiplication produces Top-5 errors that are within 0.2% compared to the FP32 references. A brief cost comparison of Mitch-$w$6 against bfloat16 is presented, where a MAC operation saves up to 80% of energy compared to the bfloat16 arithmetic. The most far-reaching contribution of this paper is the analytical justification that multiplications can be approximated while additions need to be exact in CNN MAC operations.      

# ArXiv eess --Mon, 27 Jul 2020
### 1.Sparsifying Dictionary Learning for Beamspace Channel Representation and Estimation in Millimeter-Wave Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2007.12680.pdf)
>  Millimeter-wave massive multiple-input-multiple-output (mmWave mMIMO) is reported as a key enabler in the fifth-generation communication and beyond. It is customary to use a lens antenna array to transform a mmWave mMIMO channel into a beamspace where the channel exhibits sparsity. Exploiting this sparsity enables the applicability of hybrid precoding and achieves pilot reduction. This beamspace transformation is equivalent to performing a Fourier transformation of the channel. A motivation for the Fourier character of this transformation is the fact that the steering response vectors in antenna arrays are Fourier basis vectors. Still, a Fourier transformation is not necessarily the optimal one, due to many reasons. Accordingly, this paper proposes using a learned sparsifying dictionary as the transformation operator leading to another beamspace. Since the dictionary is obtained by training over actual channel measurements, this transformation is shown to yield two immediate advantages. First, is enhancing channel sparsity, thereby leading to more efficient pilot reduction. Second, is improving the channel representation quality, and thus reducing the underlying power leakage phenomenon. Consequently, this allows for both improved channel estimation and facilitated beam selection in mmWave mMIMO. This is especially the case when the antenna array is not perfectly uniform. Besides, a learned dictionary is also used as the precoding operator for the same reasons. Extensive simulations under various operating scenarios and environments validate the added benefits of using learned dictionaries in improving the channel estimation quality and the beam selectivity, thereby improving the spectral efficiency.      
### 2.A safety aware model based reinforcement learning framework for systems with uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2007.12666.pdf)
>  Safety awareness is critical in reinforcement learning when restarts are not available and/or when the system is safety-critical. In real-world applications, safety requirements are often expressed in terms of state and/or control constraints. In the past, Model Based Reinforcement learning approaches combined with barrier transformations have been used as an effective tool to learn the optimal control policy under state constraints. However, Model Based Reinforcement learning barrier (MBRLB) methods work with known models which are difficult to obtain in real-world applications. The inclusion of parameter estimation in the MBRLB method is proposed in this research to realize safe reinforcement learning in the presence of modeling uncertainties for safety critical systems      
### 3.Generalized likelihood ratio test detector for a modified replacement model target in a multivariate t-distributed background  [ :arrow_down: ](https://arxiv.org/pdf/2007.12662.pdf)
>  A closed-form expression is derived for the generalized likelihood ratio test (GLRT) detector of a subpixel target in a multispectral image whose area and brightness are both unknown. This expression extends a previous result (which assumed a Gaussian background distribution) to a fatter tailed elliptically-contoured (EC) multivariate t-distributed background. Numerical experiments with simulated data indicate that the EC-based detector outperforms the simpler Gaussian-based detectors, and that the relative performance of the new detector, compared to other EC-based detectors, depends on the regime of target strength and background occlusion.      
### 4.Channel-Level Variable Quantization Network for Deep Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2007.12619.pdf)
>  Deep image compression systems mainly contain four components: encoder, quantizer, entropy model, and decoder. To optimize these four components, a joint rate-distortion framework was proposed, and many deep neural network-based methods achieved great success in image compression. However, almost all convolutional neural network-based methods treat channel-wise feature maps equally, reducing the flexibility in handling different types of information. In this paper, we propose a channel-level variable quantization network to dynamically allocate more bitrates for significant channels and withdraw bitrates for negligible channels. Specifically, we propose a variable quantization controller. It consists of two key components: the channel importance module, which can dynamically learn the importance of channels during training, and the splitting-merging module, which can allocate different bitrates for different channels. We also formulate the quantizer into a Gaussian mixture model manner. Quantitative and qualitative experiments verify the effectiveness of the proposed model and demonstrate that our method achieves superior performance and can produce much better visual reconstructions.      
### 5.Internet of Drones: a Survey on Communications, Technologies, Protocols, Architectures and Services  [ :arrow_down: ](https://arxiv.org/pdf/2007.12611.pdf)
>  The Internet of Drones (IoD) recently gained momentum due to its high adaptability to a wide variety of complex scenarios. Indeed, Unmanned Aerial Vehicles (UAVs) can successfully be employed in different application scenarios, like agriculture, search and rescue missions, surveillance systems, mission-critical services, etc., thanks to some technological and practical advantages: high mobility, capability to extend wireless coverage areas, or ability to reach places inaccessible to humans. Moreover, the employment of drones promisingly improves different network architectures performance indexes, i.e., reliability, connectivity, throughput, delay. Nevertheless, the adoption of networks of drones gives rise to several issues related to the unreliability of the wireless medium, batteries lifetime, high mobility degree and frequent topology changes. Moreover, security and privacy issues need to be properly investigated. This explains the very large number of works produced in the recent literature on IoD-related topics. With respect to other surveys on IoD-related topics, this work categorizes the multifaceted aspects of IoD, proposing a classification of the IoD environment. The proposed classification approach develops along two main directions. At a macroscopic level, it follows the structure of the Internet protocol stack, starting from the physical layer and extending to the upper layers, without neglecting crosslayer and optimization approaches. At a finer level, all the most relevant works belonging to each layer of the stack are further classified, according to the different issues peculiar of the layer, and highlighting the most relevant differences with the other surveys present in literature. Finally, a discussion on the main research challenges and possible future directions is carried out, focusing on the open issues and the most promising technologies in the IoD field.      
### 6.Decision-Making in Driver-Automation Shared Control: A Review and Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2007.12597.pdf)
>  Shared control schemes allow a human driver to work with an automated driving agent in driver-vehicle systems while retaining the driver's abilities to control. The human driver, as an essential agent in the driver-vehicle shared control systems, should be precisely modeled regarding their cognitive processes, control strategies, and decision-making processes. The interactive strategy design between drivers and automated driving agents brings an excellent challenge for human-centric driver assistance systems due to the inherent characteristics of humans. Many open-ended questions arise, such as what proper role of human drivers should act in a shared control scheme? How to make an intelligent decision capable of balancing the benefits of agents in shared control systems? Due to the advent of these attentions and questions, it is desirable to present a survey on the decision-making between human drivers and highly automated vehicles, to understand their architectures, human driver modeling, and interaction strategies under the driver-vehicle shared schemes. Finally, we give a further discussion on the key future challenges and opportunities. They are likely to shape new potential research directions.      
### 7.Dereverberation using joint estimation of dry speech signal and acoustic system  [ :arrow_down: ](https://arxiv.org/pdf/2007.12581.pdf)
>  The purpose of speech dereverberation is to remove quality-degrading effects of a time-invariant impulse response filter from the signal. In this report, we describe an approach to speech dereverberation that involves joint estimation of the dry speech signal and of the room impulse response. We explore deep learning models that apply to each task separately, and how these can be combined in a joint model with shared parameters.      
### 8.Combined Sparse Regularization for Nonlinear Adaptive Filters  [ :arrow_down: ](https://arxiv.org/pdf/2007.12579.pdf)
>  Nonlinear adaptive filters often show some sparse behavior due to the fact that not all the coefficients are equally useful for the modeling of any nonlinearity. Recently, a class of proportionate algorithms has been proposed for nonlinear filters to leverage sparsity of their coefficients. However, the choice of the norm penalty of the cost function may be not always appropriate depending on the problem. In this paper, we introduce an adaptive combined scheme based on a block-based approach involving two nonlinear filters with different regularization that allows to achieve always superior performance than individual rules. The proposed method is assessed in nonlinear system identification problems, showing its effectiveness in taking advantage of the online combined regularization.      
### 9.Stain Style Transfer of Histopathology Images Via Structure-Preserved Generative Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.12578.pdf)
>  Computational histopathology image diagnosis becomes increasingly popular and important, where images are segmented or classified for disease diagnosis by computers. While pathologists do not struggle with color variations in slides, computational solutions usually suffer from this critical issue. To address the issue of color variations in histopathology images, this study proposes two stain style transfer models, SSIM-GAN and DSCSI-GAN, based on the generative adversarial networks. By cooperating structural preservation metrics and feedback of an auxiliary diagnosis net in learning, medical-relevant information presented by image texture, structure, and chroma-contrast features is preserved in color-normalized images. Particularly, the smart treat of chromatic image content in our DSCSI-GAN model helps to achieve noticeable normalization improvement in image regions where stains mix due to histological substances co-localization. Extensive experimentation on public histopathology image sets indicates that our methods outperform prior arts in terms of generating more stain-consistent images, better preserving histological information in images, and obtaining significantly higher learning efficiency. Our python implementation is published on <a class="link-external link-https" href="https://github.com/hanwen0529/DSCSI-GAN" rel="external noopener nofollow">this https URL</a>.      
### 10.Integrated Longitudinal Speed Decision-Making and Energy Efficiency Control for Connected Electrified Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2007.12565.pdf)
>  To improve the driving mobility and energy efficiency of connected autonomous electrified vehicles, this paper presents an integrated longitudinal speed decision-making and energy efficiency control strategy. The proposed approach is a hierarchical control architecture, which is assumed to consist of higher-level and lower-level controls. As the core of this study, model predictive control and reinforcement learning are combined to improve the powertrain mobility and fuel economy for a group of automated vehicles. The higher-level exploits the signal phase and timing and state information of connected autonomous vehicles via vehicle to infrastructure and vehicle to vehicle communication to reduce stopping at red lights. The higher-level outputs the optimal vehicle velocity using model predictive control technique and receives the power split control from the lower-level con-troller. These two levels communicate with each other via a controller area network in the real vehicle. The lower-level utilizes a model-free reinforcement learning method to improve the fuel economy for each connected autonomous vehicle. Numerical tests illustrate that vehicle mobility can be noticeably improved (traveling time reduced by 30%) by reducing red-light idling. The effectiveness and performance of the proposed method are validated via comparison analysis among different energy efficiency controls (fuel economy promoted by 13%).      
### 11.Adaptive Energy Management for Real Driving Conditions via Transfer Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2007.12560.pdf)
>  This article proposes a transfer reinforcement learning (RL) based adaptive energy managing approach for a hybrid electric vehicle (HEV) with parallel topology. This approach is bi-level. The up-level characterizes how to transform the Q-value tables in the RL framework via driving cycle transformation (DCT). Especially, transition probability matrices (TPMs) of power request are computed for different cycles, and induced matrix norm (IMN) is employed as a critical criterion to identify the transformation differences and to determine the alteration of the control strategy. The lower-level determines how to set the corresponding control strategies with the transformed Q-value tables and TPMs by using model-free reinforcement learning (RL) algorithm. Numerical tests illustrate that the transferred performance can be tuned by IMN value and the transfer RL controller could receive a higher fuel economy. The comparison demonstrates that the proposed strategy exceeds the conventional RL approach in both calculation speed and control performance.      
### 12.Performance-Driven Cascade Controller Tuning with Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2007.12536.pdf)
>  We propose a performance-based autotuning method for cascade control systems, where the parameters of a linear axis drive motion controller from two control loops are tuned jointly. Using Bayesian optimization as all parameters are tuned simultaneously, the method is guaranteed to converge asymptotically to the global optimum of the cost. The data-efficiency and performance of the method are studied numerically for several training configurations and compared numerically to those achieved with classical tuning methods and to the exhaustive evaluation of the cost. On the real system, the tracking performance and robustness against disturbances are compared experimentally to nominal tuning. The numerical study and the experimental data both demonstrate that the proposed automated tuning method is efficient in terms of required tuning iterations, robust to disturbances, and results in improved tracking.      
### 13.Study of Different Deep Learning Approach with Explainable AI for Screening Patients with COVID-19 Symptoms: Using CT Scan and Chest X-ray Image Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2007.12525.pdf)
>  The outbreak of COVID-19 disease caused more than 100,000 deaths so far in the USA alone. It is necessary to conduct an initial screening of patients with the symptoms of COVID-19 disease to control the spread of the disease. However, it is becoming laborious to conduct the tests with the available testing kits due to the growing number of patients. Some studies proposed CT scan or chest X-ray images as an alternative solution. Therefore, it is essential to use every available resource, instead of either a CT scan or chest X-ray to conduct a large number of tests simultaneously. As a result, this study aims to develop a deep learning-based model that can detect COVID-19 patients with better accuracy both on CT scan and chest X-ray image dataset. In this work, eight different deep learning approaches such as VGG16, InceptionResNetV2, ResNet50, DenseNet201, VGG19, MobilenetV2, NasNetMobile, and ResNet15V2 have been tested on two dataset-one dataset includes 400 CT scan images, and another dataset includes 400 chest X-ray images studied. Besides, Local Interpretable Model-agnostic Explanations (LIME) is used to explain the model's interpretability. Using LIME, test results demonstrate that it is conceivable to interpret top features that should have worked to build a trust AI framework to distinguish between patients with COVID-19 symptoms with other patients.      
### 14.Robust Vision Using Retro Reflective Markers for Remote Handling in ITER  [ :arrow_down: ](https://arxiv.org/pdf/2007.12514.pdf)
>  The International Thermonuclear Experimental Reactor (ITER)'s working environment is characterized by extreme conditions, that deem maintenance and inspection tasks to be carried out through remote handling. 3D Node is a hardware/software module that extracts critical information from the remote environment during fine alignment tasks using an eye-in-hand camera system and updates the models behind the virtual reality-based remote handling platform. In this work we develop a retro-reflective marker-based version of 3D Node that estimates the pose of a planar target, the knuckle of the cassette locking system, using the markers attached to its surface. We demonstrate a pin-tool insertion task using these methods. Results show that our approach works reliably with a single low-resolution camera and outperforms the previously researched stereo depth estimation based approaches. We conclude that retro-reflective marker-based tracking has the potential to be a key enabler for remote handling operations in ITER.      
### 15.Secure Control in Partially Observable Environments to Satisfy LTL Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2007.12501.pdf)
>  This paper studies the synthesis of control policies for an agent that has to satisfy a temporal logic specification in a partially observable environment, in the presence of an adversary. The interaction of the agent (defender) with the adversary is modeled as a partially observable stochastic game. The goal is to generate a defender policy to maximize satisfaction of a given temporal logic specification under any adversary policy. The search for policies is limited to the space of finite state controllers, which leads to a tractable approach to determine policies. We relate the satisfaction of the specification to reaching (a subset of) recurrent states of a Markov chain. We present an algorithm to determine a set of defender and adversary finite state controllers of fixed sizes that will satisfy the temporal logic specification, and prove that it is sound. We then propose a value-iteration algorithm to maximize the probability of satisfying the temporal logic specification under finite state controllers of fixed sizes. Lastly, we extend this setting to the scenario where the size of the finite state controller of the defender can be increased to improve the satisfaction probability. We illustrate our approach with an example.      
### 16.Parkinson's Disease Detection with Ensemble Architectures based on ILSVRC Models  [ :arrow_down: ](https://arxiv.org/pdf/2007.12496.pdf)
>  In this work, we explore various neural network architectures using Magnetic Resonance (MR) T1 images of the brain to identify Parkinson's Disease (PD), which is one of the most common neurodegenerative and movement disorders. We propose three ensemble architectures combining some winning Convolutional Neural Network models of ImageNet Large Scale Visual Recognition Challenge (ILSVRC). All of our proposed architectures outperform existing approaches to detect PD from MR images, achieving upto 95\% detection accuracy. We also find that when we construct our ensemble architecture using models pretrained on the ImageNet dataset unrelated to PD, the detection performance is significantly better compared to models without any prior training. Our finding suggests a promising direction when no or insufficient training data is available.      
### 17.Grid-Based Stochastic Model Predictive Control for Trajectory Planning in Uncertain Environments  [ :arrow_down: ](https://arxiv.org/pdf/2007.12430.pdf)
>  Stochastic Model Predictive Control has proved to be an efficient method to plan trajectories in uncertain environments, e.g., for autonomous vehicles. Chance constraints ensure that the probability of collision is bounded by a predefined risk parameter. However, considering chance constraints in an optimization problem can be challenging and computationally demanding. In this paper, we present a grid-based Stochastic Model Predictive Control approach. This approach allows to determine a simple deterministic reformulation of the chance constraints and reduces the computational effort, while considering the stochastic nature of the environment. Within the proposed method, we first divide the environment into a grid and, for each predicted step, assign each cell a probability value, which represents the probability that this cell will be occupied by surrounding vehicles. Then, the probabilistic grid is transformed into a binary grid of admissible and inadmissible cells by applying a threshold, representing a risk parameter. Only cells with an occupancy probability lower than the threshold are admissible for the controlled vehicle. Given the admissible cells, a convex hull is generated, which can then be used for trajectory planning. Simulations of an autonomous driving highway scenario show the benefits of the proposed grid-based Stochastic Model Predictive Control method.      
### 18.A Framework to Control Inter-Area Oscillations with Local Measurement  [ :arrow_down: ](https://arxiv.org/pdf/2007.12426.pdf)
>  Inter-area oscillations in power system limit of power transfer capability though tie-lines. For stable operation, wide-area power system stabilizers are deployed to provide sufficient damping. However, as the feedback is through a communication network, it brings challenges such as additional communication layer and cybersecurity issues. To address this, a framework for synthesizing remote signal from local measurement as feedback in the wide-area power system stabilizer is proposed. The remote signal is synthesized using different variants of observers in a case study of two-area benchmark system. The proposed framework can improve the damping of inter-area oscillations for static output feedback controller. The presented framework should help to design attack-resilient controller design in smart grid.      
### 19.Positive Semidefinite Matrix Factorization: A Connection with Phase Retrieval and Affine Rank Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2007.12364.pdf)
>  Positive semidefinite matrix factorization (PSDMF) expresses each entry of a nonnegative matrix as the inner product of two positive semidefinite (psd) matrices. When all these psd matrices are constrained to be diagonal, this model is equivalent to nonnegative matrix factorization. Applications include combinatorial optimization, quantum-based statistical models, and recommender systems, among others. However, despite the increasing interest in PSDMF, only a few PSDMF algorithms were proposed in the literature. In this paper, we show that PSDMF algorithms can be designed based on phase retrieval (PR) and affine rank minimization (ARM) algorithms. This procedure allows a significant shortcut in designing new PSDMF algorithms, as it allows to leverage some of the useful numerical properties of existing PR and ARM methods to the PSDMF framework. Motivated by this idea, we introduce a new family of PSDMF algorithms based on singular value projection (SVP) and iterative hard thresholding (IHT). This family subsumes previously-proposed projected gradient PSDMF methods; additionally, we show a new connection between SVP-based methods and majorization-minimization. Numerical experiments show that our proposed methods outperform state-of-the-art coordinate descent algorithms in terms of convergence speed and computational complexity, in certain scenarios. In certain cases, our proposed normalized-IHT-based method is the only algorithm able to find a solution. These results support our claim that the PSDMF framework can inherit desired numerical properties from PR and ARM algorithms, leading to more efficient PSDMF algorithms, and motivate further study of the links between these models.      
### 20.COVID TV-UNet: Segmenting COVID-19 Chest CT Images Using Connectivity Imposed U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2007.12303.pdf)
>  The novel corona-virus disease (COVID-19) pandemic has caused a major outbreak in more than 200 countries around the world, leading to a severe impact on the health and life of many people globally. As of mid-July 2020, more than 12 million people were infected, and more than 570,000 death were reported. Computed Tomography (CT) images can be used as an alternative to the time-consuming RT-PCR test, to detect COVID-19. In this work we propose a segmentation framework to detect chest regions in CT images, which are infected by COVID-19. We use an architecture similar to U-Net model, and train it to detect ground glass regions, on pixel level. As the infected regions tend to form a connected component (rather than randomly distributed pixels), we add a suitable regularization term to the loss function, to promote connectivity of the segmentation map for COVID-19 pixels. 2D-anisotropic total-variation is used for this purpose, and therefore the proposed model is called "TV-UNet". Through experimental results on a relatively large-scale CT segmentation dataset of around 900 images, we show that adding this new regularization term leads to 2\% gain on overall segmentation performance compared to the U-Net model. Our experimental analysis, ranging from visual evaluation of the predicted segmentation results to quantitative assessment of segmentation performance (precision, recall, Dice score, and mIoU) demonstrated great ability to identify COVID-19 associated regions of the lungs, achieving a mIoU rate of over 99\%, and a Dice score of around 86\%.      
### 21.Frequency Domain-based Perceptual Loss for Super Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2007.12296.pdf)
>  We introduce Frequency Domain Perceptual Loss (FDPL), a loss function for single image super resolution (SR). Unlike previous loss functions used to train SR models, which are all calculated in the pixel (spatial) domain, FDPL is computed in the frequency domain. By working in the frequency domain we can encourage a given model to learn a mapping that prioritizes those frequencies most related to human perception. While the goal of FDPL is not to maximize the Peak Signal to Noise Ratio (PSNR), we found that there is a correlation between decreasing FDPL and increasing PSNR. Training a model with FDPL results in a higher average PSRN (30.94), compared to the same model trained with pixel loss (30.59), as measured on the Set5 image dataset. We also show that our method achieves higher qualitative results, which is the goal of a perceptual loss function. However, it is not clear that the improved perceptual quality is due to the slightly higher PSNR or the perceptual nature of FDPL.      
### 22.On the performance of optical phased array technology for beam steering  [ :arrow_down: ](https://arxiv.org/pdf/2007.12265.pdf)
>  Optical phased arrays are of strong interest for beam steering in telecom and LIDAR applications. A phased array ideally requires that the field produced by each element in the array (a pixel) is fully controllable in phase and amplitude (ideally constant). This is needed to realize a phase gradient along a direction in the array, and thus beam steering in that direction. In practice, grating lobes appear if the pixel size is not sub-wavelength, which is an issue for many optical technologies. Furthermore, the phase performance of an optical pixel may not span the required $2\pi$ phase range, or may not produce a constant amplitude over its phase range. These limitations result in imperfections in the phase gradient, which in turn introduce undesirable secondary lobes. We discuss the effects of non-ideal pixels on beam formation, in a general and technology-agnostic manner. By examining the strength of secondary lobes with respect to the main lobe, we quantify beam steering quality, and make recommendations on the pixel performance required for beam steering within prescribed specifications. By applying appropriate compensation strategies, we show that it is possible to realize high-quality beam steering even when the pixel performance is non-ideal, with intensity of the secondary lobes be two orders of magnitude smaller than the main lobe.      
### 23.T2 Mapping from Super-Resolution-Reconstructed Clinical Fast Spin Echo Magnetic Resonance Acquisitions  [ :arrow_down: ](https://arxiv.org/pdf/2007.12199.pdf)
>  Relaxometry studies in preterm and at-term newborns have provided insight into brain microstructure, thus opening new avenues for studying normal brain development and supporting diagnosis in equivocal neurological situations. However, such quantitative techniques require long acquisition times and therefore cannot be straightforwardly translated to in utero brain developmental studies. In clinical fetal brain magnetic resonance imaging routine, 2D low-resolution T2-weighted fast spin echo sequences are used to minimize the effects of unpredictable fetal motion during acquisition. As super-resolution techniques make it possible to reconstruct a 3D high-resolution volume of the fetal brain from clinical low-resolution images, their combination with quantitative acquisition schemes could provide fast and accurate T2 measurements. In this context, the present work demonstrates the feasibility of using super-resolution reconstruction from conventional T2-weighted fast spin echo sequences for 3D isotropic T2 mapping. A quantitative magnetic resonance phantom was imaged using a clinical T2-weighted fast spin echo sequence at variable echo time to allow for super-resolution reconstruction at every echo time and subsequent T2 mapping of samples whose relaxometric properties are close to those of fetal brain tissue. We demonstrate that this approach is highly repeatable, accurate and robust when using six echo times (total acquisition time under 9 minutes) as compared to gold-standard single-echo spin echo sequences (several hours for one single 2D slice).      
### 24.Review and Prospect: NMR Spectroscopy Denoising &amp; Reconstruction with Low Rank Hankel Matrices and Tensors  [ :arrow_down: ](https://arxiv.org/pdf/2007.12646.pdf)
>  Nuclear Magnetic Resonance (NMR) spectroscopy is an important analytical tool in chemistry, biology, and life science, but it suffers from relatively low sensitivity and long acquisition time. Thus, improving the apparent signal-to-noise ratio and accelerating data acquisition become indispensable. In this review, we summarize the recent progress on low rank Hankel matrix and tensor methods, that exploit the exponential property of free induction decay signals, to enable effective denoising and spectra reconstruction. We also outline future developments that are likely to make NMR spectroscopy a far more powerful technique.      
### 25.Improved Slice-wise Tumour Detection in Brain MRIs by Computing Dissimilarities between Latent Representations  [ :arrow_down: ](https://arxiv.org/pdf/2007.12528.pdf)
>  Anomaly detection for Magnetic Resonance Images (MRIs) can be solved with unsupervised methods by learning the distribution of healthy images and identifying anomalies as outliers. In presence of an additional dataset of unlabelled data containing also anomalies, the task can be framed as a semi-supervised task with negative and unlabelled sample points. Recently, in Albu et al., 2020, we have proposed a slice-wise semi-supervised method for tumour detection based on the computation of a dissimilarity function in the latent space of a Variational AutoEncoder, trained on unlabelled data. The dissimilarity is computed between the encoding of the image and the encoding of its reconstruction obtained through a different autoencoder trained only on healthy images. In this paper we present novel and improved results for our method, obtained by training the Variational AutoEncoders on a subset of the HCP and BRATS-2018 datasets and testing on the remaining individuals. We show that by training the models on higher resolution images and by improving the quality of the reconstructions, we obtain results which are comparable with different baselines, which employ a single VAE trained on healthy individuals. As expected, the performance of our method increases with the size of the threshold used to determine the presence of an anomaly.      
### 26.An LSTM Approach to Temporal 3D Object Detection in LiDAR Point Clouds  [ :arrow_down: ](https://arxiv.org/pdf/2007.12392.pdf)
>  Detecting objects in 3D LiDAR data is a core technology for autonomous driving and other robotics applications. Although LiDAR data is acquired over time, most of the 3D object detection algorithms propose object bounding boxes independently for each frame and neglect the useful information available in the temporal domain. To address this problem, in this paper we propose a sparse LSTM-based multi-frame 3d object detection algorithm. We use a U-Net style 3D sparse convolution network to extract features for each frame's LiDAR point-cloud. These features are fed to the LSTM module together with the hidden and memory features from last frame to predict the 3d objects in the current frame as well as hidden and memory features that are passed to the next frame. Experiments on the Waymo Open Dataset show that our algorithm outperforms the traditional frame by frame approach by 7.5% mAP@0.7 and other multi-frame approaches by 1.2% while using less memory and computation per frame. To the best of our knowledge, this is the first work to use an LSTM for 3D object detection in sparse point clouds.      
### 27.Anticipating the Long-Term Effect of Online Learning in Control  [ :arrow_down: ](https://arxiv.org/pdf/2007.12377.pdf)
>  Control schemes that learn using measurement data collected online are increasingly promising for the control of complex and uncertain systems. However, in most approaches of this kind, learning is viewed as a side effect that passively improves control performance, e.g., by updating a model of the system dynamics. Determining how improvements in control performance due to learning can be actively exploited in the control synthesis is still an open research question. In this paper, we present AntLer, a design algorithm for learning-based control laws that anticipates learning, i.e., that takes the impact of future learning in uncertain dynamic settings explicitly into account. AntLer expresses system uncertainty using a non-parametric probabilistic model. Given a cost function that measures control performance, AntLer chooses the control parameters such that the expected cost of the closed-loop system is minimized approximately. We show that AntLer approximates an optimal solution arbitrarily accurately with probability one. Furthermore, we apply AntLer to a nonlinear system, which yields better results compared to the case where learning is not anticipated.      
### 28.Decentralized Safe Reactive Planning under TWTL Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2007.12278.pdf)
>  We investigate a multi-agent planning problem, where each agent aims to achieve an individual task while avoiding collisions with others. We assume that each agent's task is expressed as a Time-Window Temporal Logic (TWTL) specification defined over a 3D environment. We propose a decentralized receding horizon algorithm for online planning of trajectories. We show that when the environment is sufficiently connected, the resulting agent trajectories are always safe (collision-free) and lead to the satisfaction of the TWTL specifications or their finite temporal relaxations. Accordingly, deadlocks are always avoided and each agent is guaranteed to safely achieve its task with a finite time-delay in the worst case. Performance of the proposed algorithm is demonstrated via numerical simulations and experiments with quadrotors.      
### 29.IoT meets COVID-19: Status, Challenges, and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2007.12268.pdf)
>  Due to the global pandemic of COVID-19, there is an urgent need to utilize existing technologies to their full potential. Internet of Things (IoT) is regarded as one of the most trending technologies with a great potential in fighting against the coronavirus outbreak. The IoT comprises of a scarce network in which the IoT devices sense the environment and send useful data on the Internet. In this paper, we examine the current status of IoT applications related to COVID-19, identify their deployment and operational challenges, and suggest possible opportunities to further contain the pandemic. Furthermore, we perform analysis for implementing IoT in which internal and external factors are discussed.      

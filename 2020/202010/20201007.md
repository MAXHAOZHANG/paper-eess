# ArXiv eess --Wed, 7 Oct 2020
### 1.GLOSS: A Tensor Decomposition Approach for Anomaly Detection in Spatiotemporal Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.02889.pdf)
>  Anomaly detection in spatiotemporal data is a challenging problem encountered in a variety of applications including hyperspectral imaging, video surveillance, urban traffic monitoring and environmental monitoring. Existing anomaly detection methods are mostly suited for dealing with point anomalies in sequence data. These methods cannot deal with temporal and spatial dependencies that arise in spatiotemporal data. In recent years, tensor based anomaly detection methods have been proposed to deal with the multi-way structure inherent to these data. Most of the tensor based methods are supervised or semi-supervised, which rely on training models based on labeled cases and assume relatively stable patterns in normal cases. In this paper, we introduce an unsupervised tensor based anomaly detection method for spatiotemporal urban traffic data. The proposed method assumes that the anomalies are sparse and temporally continuous, i.e. anomalies appear as spatially contiguous groups of locations that show anomalous values consistently for a short duration of time. Moreover, we preserve the local geometric structure of the data through graph regularization across each mode. The proposed framework, Graph Regularized Low-rank plus Temporally Smooth Sparse decomposition (GLOSS), is formulated as an optimization problem and solved using ADMM. The resulting algorithm is shown to converge and be robust against missing data and noise. The proposed framework is evaluated on both synthetic and real spatiotemporal urban traffic data and compared with baseline methods.      
### 2.A General Framework for Decentralized Safe Optimal Control of Connected and Automated Vehicles in Multi-Lane Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2010.02881.pdf)
>  We address the problem of optimally controlling Connected and Automated Vehicles (CAVs) arriving from four multi-lane roads at an intersection where they conflict in terms of safely crossing (including turns) with no collision. The objective is to jointly minimize the travel time and energy consumption of each CAV while ensuring safety. This problem was solved in prior work for single-lane roads. A direct extension to multiple lanes on each road is limited by the computational complexity required to obtain an explicit optimal control solution. Instead, we propose a general framework that first converts a multi-lane intersection problem into a decentralized optimal control problem for each CAV with less conservative safety constraints than prior work. We then employ a method combining optimal control and control barrier functions, which has been shown to efficiently track tractable unconstrained optimal CAV trajectories while also guaranteeing the satisfaction of all constraints. Simulation examples are included to show the effectiveness of the proposed framework under symmetric and asymmetric intersection geometries and different schemes for CAV sequencing.      
### 3.Adaptive Synchronization of Heterogeneous Multi-Agent Systems: A Free Observer Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.02862.pdf)
>  Adaptive synchronization protocols for heterogeneous multi-agent network are investigated. The interaction between each of the agents is carried out through a directed graph. We highlight the lack of communication between agents and the presence of uncertainties in each system among the conventional problems that can arise in cooperative networks. Two methodologies are presented to deal with the uncertainties: A strategy based on robust optimal control and a strategy based on neural networks. Likewise, an input estimation methodology is designed to face the disconnection that any agent may present on the network. These control laws can guarantee synchronization between agents even when there are disturbances or no communication from any agent. Stability and boundary analyzes are performed. Cooperative cruise control simulation results are shown to validate the performance of the proposed control methods.      
### 4.COVIDomaly: A Deep Convolutional Autoencoder Approach for Detecting Early Cases of COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2010.02814.pdf)
>  As of September 2020, the COVID-19 pandemic continues to devastate the health and well-being of the global population. With more than 33 million confirmed cases and over a million deaths, global health organizations are still a long way from fully containing the pandemic. This pandemic has raised serious questions about the emergency preparedness of health agencies, not only in terms of treatment of an unseen disease, but also in identifying its early symptoms. In the particular case of COVID-19, several studies have indicated that chest radiography images of the infected patients show characteristic abnormalities. However, at the onset of a given pandemic, such as COVID-19, there may not be sufficient data for the affected cases to train models for their robust detection. Hence, supervised classification is ill-posed for this problem because the time spent in collecting large amounts of infected peoples' data could lead to the loss of human lives and delays in preventive interventions. Therefore, we formulate this problem within a one-class classification framework, in which the data for healthy patients is abundantly available, whereas no training data is present for the class of interest (COVID-19 in our case). To solve this problem, we present COVIDomaly, a convolutional autoencoder framework to detect unseen COVID-19 cases from the chest radiographs. We tested two settings on a publicly available dataset (COVIDx) by training the model on chest X-rays from (i) only healthy adults, and (ii) healthy and other non-COVID-19 pneumonia, and detected COVID-19 as an anomaly. After performing 3-fold cross validation, we obtain a pooled ROC-AUC of 0.7652 and 0.6902 in the two settings respectively. These results are very encouraging and pave the way towards research for ensuring emergency preparedness in future pandemics, especially the ones that could be detected from chest X-rays.      
### 5.Unified Supervised-Unsupervised (SUPER) Learning for X-ray CT Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2010.02761.pdf)
>  Traditional model-based image reconstruction (MBIR) methods combine forward and noise models with simple object priors. Recent machine learning methods for image reconstruction typically involve supervised learning or unsupervised learning, both of which have their advantages and disadvantages. In this work, we propose a unified supervised-unsupervised (SUPER) learning framework for X-ray computed tomography (CT) image reconstruction. The proposed learning formulation combines both unsupervised learning-based priors (or even simple analytical priors) together with (supervised) deep network-based priors in a unified MBIR framework based on a fixed point iteration analysis. The proposed training algorithm is also an approximate scheme for a bilevel supervised training optimization problem, wherein the network-based regularizer in the lower-level MBIR problem is optimized using an upper-level reconstruction loss. The training problem is optimized by alternating between updating the network weights and iteratively updating the reconstructions based on those weights. We demonstrate the learned SUPER models' efficacy for low-dose CT image reconstruction, for which we use the NIH AAPM Mayo Clinic Low Dose CT Grand Challenge dataset for training and testing. In our experiments, we studied different combinations of supervised deep network priors and unsupervised learning-based or analytical priors. Both numerical and visual results show the superiority of the proposed unified SUPER methods over standalone supervised learning-based methods, iterative MBIR methods, and variations of SUPER obtained via ablation studies. We also show that the proposed algorithm converges rapidly in practice.      
### 6.Machine Learning Empowered Trajectory and Passive Beamforming Design in UAV-RIS Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.02749.pdf)
>  A novel framework is proposed for integrating reconfigurable intelligent surfaces (RIS) in unmanned aerial vehicle (UAV) enabled wireless networks, where an RIS is deployed for enhancing the service quality of the UAV. Non-orthogonal multiple access (NOMA) technique is invoked to further improve the spectrum efficiency of the network, while mobile users (MUs) are considered as roaming continuously. The energy consumption minimizing problem is formulated by jointly designing the movement of the UAV, phase shifts of the RIS, power allocation policy from the UAV to MUs, as well as determining the dynamic decoding order. A decaying deep Q-network (D-DQN) based algorithm is proposed for tackling this pertinent problem. In the proposed D-DQN based algorithm, the central controller is selected as an agent for periodically observing the state of UAV-enabled wireless network and for carrying out actions to adapt to the dynamic environment. In contrast to the conventional DQN algorithm, the decaying learning rate is leveraged in the proposed D-DQN based algorithm for attaining a tradeoff between accelerating training speed and converging to the local optimal. Numerical results demonstrate that: 1) In contrast to the conventional Q-learning algorithm, which cannot converge when being adopted for solving the formulated problem, the proposed D-DQN based algorithm is capable of converging with minor constraints; 2) The energy dissipation of the UAV can be significantly reduced by integrating RISs in UAV-enabled wireless networks; 3) By designing the dynamic decoding order and power allocation policy, the RIS-NOMA case consumes 11.7% less energy than the RIS-OMA case.      
### 7.Neural Generation of Blocks for Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2010.02748.pdf)
>  Well-trained generative neural networks (GNN) are very efficient at compressing visual information for static images in their learned parameters but not as efficient as inter- and intra-prediction for most video content. However, for content entering a frame, such as during panning or zooming out, and content with curves, irregular shapes, or fine detail, generation by a GNN can give better compression efficiency (lower rate-distortion). This paper proposes encoding content-specific learned parameters of a GNN within a video bitstream at specific times and using the GNN to generate content for specific ranges of blocks and frames. The blocks to generate are just the ones for which generation gives more efficient compression than inter- or intra- prediction. This approach maximizes the usefulness of the information contained in the learned parameters.      
### 8.Image Translation for Medical Image Generation -- Ischemic Stroke Lesions  [ :arrow_down: ](https://arxiv.org/pdf/2010.02745.pdf)
>  Deep learning-based automated disease detection and segmentation algorithms promise to accelerate and improve many clinical processes. However, such algorithms require vast amounts of annotated training data, which are typically not available in a medical context, e.g., due to data privacy concerns, legal obstructions, and non-uniform data formats. Synthetic databases of annotated pathologies could provide the required amounts of training data. Here, we demonstrate with the example of ischemic stroke that a significant improvement in lesion segmentation is feasible using deep learning-based data augmentation. To this end, we train different image-to-image translation models to synthesize diffusion-weighted magnetic resonance images (DWIs) of brain volumes with and without stroke lesions from semantic segmentation maps. In addition, we train a generative adversarial network to generate synthetic lesion masks. Subsequently, we combine these two components to build a large database of synthetic stroke DWIs. The performance of the various generative models is evaluated using a U-Net which is trained to segment stroke lesions on a clinical test set. We compare the results to human expert inter-reader scores. For the model with the best performance, we report a maximum Dice score of 82.6\%, which significantly outperforms the model trained on the clinical images alone (74.8\%), and also the inter-reader Dice score of two human readers of 76.9\%. Moreover, we show that for a very limited database of only 10 or 50 clinical cases, synthetic data can be used to pre-train the segmentation algorithms, which ultimately yields an improvement by a factor of as high as 8 compared to a setting where no synthetic data is used.      
### 9.Assessing Automated Machine Learning service to detect COVID-19 from X-Ray and CT images: A Real-time Smartphone Application case study  [ :arrow_down: ](https://arxiv.org/pdf/2010.02715.pdf)
>  The recent outbreak of SARS COV-2 gave us a unique opportunity to study for a non interventional and sustainable AI solution. Lung disease remains a major healthcare challenge with high morbidity and mortality worldwide. The predominant lung disease was lung cancer. Until recently, the world has witnessed the global pandemic of COVID19, the Novel coronavirus outbreak. We have experienced how viral infection of lung and heart claimed thousands of lives worldwide. With the unprecedented advancement of Artificial Intelligence in recent years, Machine learning can be used to easily detect and classify medical imagery. It is much faster and most of the time more accurate than human radiologists. Once implemented, it is more cost-effective and time-saving. In our study, we evaluated the efficacy of Microsoft Cognitive Service to detect and classify COVID19 induced pneumonia from other Viral/Bacterial pneumonia based on X-Ray and CT images. We wanted to assess the implication and accuracy of the Automated ML-based Rapid Application Development (RAD) environment in the field of Medical Image diagnosis. This study will better equip us to respond with an ML-based diagnostic Decision Support System(DSS) for a Pandemic situation like COVID19. After optimization, the trained network achieved 96.8% Average Precision which was implemented as a Web Application for consumption. However, the same trained network did not perform the same like Web Application when ported to Smartphone for Real-time inference. Which was our main interest of study. The authors believe, there is scope for further study on this issue. One of the main goal of this study was to develop and evaluate the performance of AI-powered Smartphone-based Real-time Application. Facilitating primary diagnostic services in less equipped and understaffed rural healthcare centers of the world with unreliable internet service.      
### 10.Joint Collaboration and Compression Design for Distributed Sequential Estimation in a Wireless Sensor Network  [ :arrow_down: ](https://arxiv.org/pdf/2010.02700.pdf)
>  In this work, we propose a joint collaboration-compression framework for sequential estimation of a random vector parameter in a resource constrained wireless sensor network (WSN). Specifically, we propose a framework where the local sensors first collaborate (via a collaboration matrix) with each other. Then a subset of sensors selected to communicate with the FC linearly compress their observations before transmission. We design near-optimal collaboration and linear compression strategies under power constraints via alternating minimization of the sequential minimum mean square error. We show that the objective function for collaboration design can be non-convex depending on the network topology. We reformulate and solve the collaboration design problem using quadratically constrained quadratic program (QCQP). Moreover, the compression design problem is also formulated as a QCQP. We propose two versions of compression design, one centralized where the compression strategies are derived at the FC and the other decentralized, where the local sensors compute their individual compression matrices independently. It is noted that the design of decentralized compression strategy is a non-convex problem. We obtain a near-optimal solution by using the bisection method. In contrast to the one-shot estimator, our proposed algorithm is capable of handling dynamic system parameters such as channel gains and energy constraints. Importantly, we show that the proposed methods can also be used for estimating time-varying random vector parameters. Finally, numerical results are provided to demonstrate the effectiveness of the proposed framework.      
### 11.The Academia Sinica Systems of Voice Conversion for VCC2020  [ :arrow_down: ](https://arxiv.org/pdf/2010.02669.pdf)
>  This paper describes the Academia Sinica systems for the two tasks of Voice Conversion Challenge 2020, namely voice conversion within the same language (Task 1) and cross-lingual voice conversion (Task 2). For both tasks, we followed the cascaded ASR+TTS structure, using phonetic tokens as the TTS input instead of the text or characters. For Task 1, we used the international phonetic alphabet (IPA) as the input of the TTS model. For Task 2, we used unsupervised phonetic symbols extracted by the vector-quantized variational autoencoder (VQVAE). In the evaluation, the listening test showed that our systems performed well in the VCC2020 challenge.      
### 12.Histopathological Stain Transfer using Style Transfer Network with Adversarial Loss  [ :arrow_down: ](https://arxiv.org/pdf/2010.02659.pdf)
>  Deep learning models that are trained on histopathological images obtained from a single lab and/or scanner give poor inference performance on images obtained from another scanner/lab with a different staining protocol. In recent years, there has been a good amount of research done for image stain normalization to address this issue. In this work, we present a novel approach for the stain normalization problem using fast neural style transfer coupled with adversarial loss. We also propose a novel stain transfer generator network based on High-Resolution Network (HRNet) which requires less training time and gives good generalization with few paired training images of reference stain and test stain. This approach has been tested on Whole Slide Images (WSIs) obtained from 8 different labs, where images from one lab were treated as a reference stain. A deep learning model was trained on this stain and the rest of the images were transferred to it using the corresponding stain transfer generator network. Experimentation suggests that this approach is able to successfully perform stain normalization with good visual quality and provides better inference performance compared to not applying stain normalization.      
### 13.Multirotors from Takeoff to Real-Time Full Identification Using the Modified Relay Feedback Test and Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.02645.pdf)
>  Low cost real-time identification of multirotor unmanned aerial vehicle (UAV) dynamics is an active area of research supported by the surge in demand and emerging application domains. Such real-time identification capabilities shorten development time and cost, making UAVs' technology more accessible, and enable a variety of advanced applications. In this paper, we present a novel comprehensive approach, called DNN-MRFT, for real-time identification and tuning of multirotor UAVs using the Modified Relay Feedback Test (MRFT) and Deep Neural Networks (DNN). The first contribution is the development of a generalized framework for the application of DNN-MRFT to higher-order systems. The second contribution is a method for the exact estimation of identified process gain which mitigates the inaccuracies introduced due to the use of the describing function method in approximating the response of Lure's systems. The third contribution is a generalized controller based on DNN-MRFT that takes-off a UAV with unknown dynamics and identifies the inner loops dynamics in-flight. Using the developed generalized framework, DNN-MRFT is sequentially applied to the outer translational loops of the UAV utilizing in-flight results obtained for the inner attitude loops. DNN-MRFT takes on average 15 seconds to get the full knowledge of multirotor UAV dynamics and was tested on multiple designs and sizes. The identification accuracy of DNN-MRFT is demonstrated by the ability of a UAV to pass through a vertical window without any further tuning, calibration, or feedforward terms. Such demonstrated accuracy, speed, and robustness of identification pushes the limits of state-of-the-art in real-time identification of UAVs.      
### 14.Low Complexity Method for Simulation of Epidemics Based on Dijkstra's Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2010.02540.pdf)
>  Models of epidemics over networks have become popular, as they describe the impact of individual behavior on infection spread. However, they come with high computational complexity, which constitutes a problem in case large-scale scenarios are considered. This paper presents a discrete-time multi-agent SIR (Susceptible, Infected, Recovered) model that extends known results in literature. Based on that, using the novel notion of Contagion Graph, it proposes a graphbased method derived from Dijkstra's algorithm that allows to decrease the computational complexity of a simulation. The Contagion Graph can be also employed as an approximation scheme describing the "mean behavior" of an epidemic over a network and requiring low computational power. Theoretical findings are confirmed by randomized large-scale simulation.      
### 15.Progressive InSAR phase estimation  [ :arrow_down: ](https://arxiv.org/pdf/2010.02533.pdf)
>  This paper introduces a novel scheme to progressively estimate interferometric phases from a stack of synthetic aperture radar (SAR) images. The scheme is shown to yield comparable performance to full-covariance algorithms for a realistic decorrelation scenario. The implementation is suited for continuous processing and updating of phase products, without compromising long-term phase accuracy. It also limits the requirements in terms of data transfer between archive and processing facility, a significant issue for processing large archives of SAR data.      
### 16.A model-free method for learning flexibility capacity of loads providing grid support  [ :arrow_down: ](https://arxiv.org/pdf/2010.02517.pdf)
>  Flexible loads are a resource for the Balancing Authority (BA) of the future to aid in the balance of power supply and demand. In order to be used as a resource, the BA must know the capacity of the flexible loads to vary their power demand over a baseline without violating consumers' quality of service (QoS). Existing work on capacity characterization is model-based: They need models relating power consumption to variables that dictate QoS, such as temperature in case of an air conditioning system. However, in many cases the model parameters are not known or difficult to obtain. In this work, we pose a data driven capacity characterization method that does not require model information, it only needs access to a simulator. The capacity is characterized as the set of feasible spectral densities (SDs) of the demand deviation. The proposed method is an extension of our recent work on SD-based capacity characterization that was limited to linear time invariant (LTI) dynamics of loads. The method proposed here is applicable to nonlinear dynamics. Numerical evaluation of the method is provided, including a comparison with the model-based solution for the LTI case.      
### 17.A Unified Deep Learning Framework for Short-Duration Speaker Verification in Adverse Environments  [ :arrow_down: ](https://arxiv.org/pdf/2010.02477.pdf)
>  Speaker verification (SV) has recently attracted considerable research interest due to the growing popularity of virtual assistants. At the same time, there is an increasing requirement for an SV system: it should be robust to short speech segments, especially in noisy and reverberant environments. In this paper, we consider one more important requirement for practical applications: the system should be robust to an audio stream containing long non-speech segments, where a voice activity detection (VAD) is not applied. To meet these two requirements, we introduce feature pyramid module (FPM)-based multi-scale aggregation (MSA) and self-adaptive soft VAD (SAS-VAD). We present the FPM-based MSA to deal with short speech segments in noisy and reverberant environments. Also, we use the SAS-VAD to increase the robustness to long non-speech segments. To further improve the robustness to acoustic distortions (i.e., noise and reverberation), we apply a masking-based speech enhancement (SE) method. We combine SV, VAD, and SE models in a unified deep learning framework and jointly train the entire network in an end-to-end manner. To the best of our knowledge, this is the first work combining these three models in a deep learning framework. We conduct experiments on Korean indoor (KID) and VoxCeleb datasets, which are corrupted by noise and reverberation. The results show that the proposed method is effective for SV in the challenging conditions and performs better than the baseline i-vector and deep speaker embedding systems.      
### 18.Task Admission Control and Boundary Analysis of Cognitive Cloud Data Centers  [ :arrow_down: ](https://arxiv.org/pdf/2010.02457.pdf)
>  A novel cloud data center (DC) model is studied here with cognitive capabilities for real-time (or online) flow compared to the batch tasks. Here, a DC can determine the cost of using resources and an online user or the user with batch tasks may decide whether or not to pay for getting the services. The online service tasks have a higher priority in getting the service over batch tasks. Both types of tasks need a certain number of virtual machines (VM). By targeting on the maximization of total discounted reward, an optimal policy for admitting task tasks is finally verified to be a state-related control limit policy. Next, a lower and an upper bound for such an optimal policy are derived, respectively, for the estimation and utilization in reality. Finally, a comprehensive set of experiments on the various cases to validate this proposed model and the solution is conducted. As a demonstration, the machine learning method is adopted to show how to obtain the optimal values by using a feed-forward neural network model. The results achieved in this paper will be expectedly utilized in various cloud data centers with cognitive characteristics in an economically optimal strategy.      
### 19.Localized and Distributed H2 State Feedback Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.02440.pdf)
>  Distributed linear control plays a crucial role in large-scale cyber-physical systems. It is generally desirable to both impose information exchange (communication) constraints on the distributed controller, and to limit the propagation of disturbances to a local region without cascading to the global network (localization). Recently proposed System Level Synthesis (SLS) theory provides a framework where such communication and localization requirements can be tractably incorporated in controller design and implementation. In this work, we develop upon the SLS framework and derive a solution to the localized and distributed H2 state feedback control problem, which previously could only be solved via the FIR (Finite Impulse Response) approximation. In particular, the proposed synthesis procedure can be decomposed column-wise, and is therefore scalable to arbitrary large-scale networks. Further, we lift the FIR filter requirement for SLS controllers and make explicit the distributed and localized state space implementation of the controller in the infinite-horizon case. Our simulation demonstrates superior performance and numerical stability of the proposed procedure over previous methods.      
### 20.The Sequence-to-Sequence Baseline for the Voice Conversion Challenge 2020: Cascading ASR and TTS  [ :arrow_down: ](https://arxiv.org/pdf/2010.02434.pdf)
>  This paper presents the sequence-to-sequence (seq2seq) baseline system for the voice conversion challenge (VCC) 2020. We consider a naive approach for voice conversion (VC), which is to first transcribe the input speech with an automatic speech recognition (ASR) model, followed using the transcriptions to generate the voice of the target with a text-to-speech (TTS) model. We revisit this method under a sequence-to-sequence (seq2seq) framework by utilizing ESPnet, an open-source end-to-end speech processing toolkit, and the many well-configured pretrained models provided by the community. Official evaluation results show that our system comes out top among the participating systems in terms of conversion similarity, demonstrating the promising ability of seq2seq models to convert speaker identity. The implementation is made open-source at: <a class="link-external link-https" href="https://github.com/espnet/espnet/tree/master/egs/vcc20" rel="external noopener nofollow">this https URL</a>.      
### 21.ASDN: A Deep Convolutional Network for Arbitrary Scale Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2010.02414.pdf)
>  Deep convolutional neural networks have significantly improved the peak signal-to-noise ratio of SuperResolution (SR). However, image viewer applications commonly allow users to zoom the images to arbitrary magnification scales, thus far imposing a large number of required training scales at a tremendous computational cost. To obtain a more computationally efficient model for arbitrary scale SR, this paper employs a Laplacian pyramid method to reconstruct any-scale high-resolution (HR) images using the high-frequency image details in a Laplacian Frequency Representation. For SR of small-scales (between 1 and 2), images are constructed by interpolation from a sparse set of precalculated Laplacian pyramid levels. SR of larger scales is computed by recursion from small scales, which significantly reduces the computational cost. For a full comparison, fixed- and any-scale experiments are conducted using various benchmarks. At fixed scales, ASDN outperforms predefined upsampling methods (e.g., SRCNN, VDSR, DRRN) by about 1 dB in PSNR. At any-scale, ASDN generally exceeds Meta-SR on many scales.      
### 22.Adaptive Active-Passive Networked Multiagent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.02412.pdf)
>  Active-passive multiagent systems consist of agents subject to inputs (active agents) and agents with no inputs (passive agents), where active and passive agent roles are considered to be interchangeable in order to capture a wide array of applications. A challenge in the control of active-passive multiagent systems is the presence of information exchange uncertainties that can yield to undesirable closed-loop system performance. Motivated by this standpoint, this paper proposes an adaptive control algorithm for this class of multiagent systems to suppress the negative effects of information exchange uncertainties. Specifically, by estimating these uncertainties, the proposed adaptive control architecture has the ability to recover the active-passive multiagent system performance in a distributed manner. As a result, the agents converge to a user-adjustable neighborhood of the average of the applied inputs to the active agents. The efficacy of the proposed control architecture is also validated from a human-robot collaboration perspective, where a human is visiting several task locations, and the multiagent system identifies these locations and moves toward them as a coverage control problem.      
### 23.A Comment on Surgical Eigenstructure Assignment via State Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2010.02365.pdf)
>  Assignability of all eigenvalues and a subset of key eigenvectors/generalized eigenvectors of a linear time-invariant system via state feedback is considered. We clarify that, if the key eigenvectors/generalized eigenvectors and their associated eigenvalues satisfy the classical conditions for full eigenstructure assignment, the remaining eigenvalues can be assigned at will.      
### 24.Learning to Localise Automated Vehicles in Challenging Environments using Inertial Navigation Systems (INS)  [ :arrow_down: ](https://arxiv.org/pdf/2010.02363.pdf)
>  An algorithm based on Artificial Neural Networks is proposed in this paper to improve the accuracy of Inertial Navigation System (INS)/ Global Navigation Satellite System (GNSS) integrated navigation during the absence of GNSS signals. The INS which can be used to continuously position autonomous vehicles during GNSS signal losses around urban canyons, bridges, tunnels and trees, suffers from unbounded exponential error drifts cascaded over time during the integration of the gyroscope and double integration of the accelerometer to displacement. More so, the error drift is characterised by a pattern dependent on time. The Input Delay Neural Network (IDNN) has the ability to learn the error drift over time [1] and possesses the quality of being more computationally efficient than the Recurrent Neural Network (RNN), Long Short-Term Memory, and the Gated Recurrent Unit Network. Furthermore published literatures focus on travel routes which do not take complex driving scenarios into consideration, we therefore investigate in this paper the performance of the proposed algorithm on challenging scenarios, such as hard brake, roundabouts, sharp cornering, successive left and right turns and quick changes in vehicular acceleration across numerous test sequences. The results obtained show that the Neural Network-based approaches are able to provide up to 89.55 % improvement on the INS displacement estimation and 93.35 % on the INS orientation rate estimation.      
### 25.Multi-Objective Approach for Optimal Size and Location of DGs in Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.02313.pdf)
>  In the recent years, due to the economic and environmental requirements, the use of distributed generations (DGs) has increased. If DGs have the optimal size and are located at the optimal locations, they are capable of enhancing the voltage profile and reducing the power loss. This paper proposes a new approach to obtain the optimal location and size of DGs. To this end, exchange market algorithm (EMA) is offered to find the optimal size and location of DGs subject to minimizing loss, increasing voltage profile, and improving voltage stability in the distribution systems. The effectiveness of the proposed approach is verified on both 33- and 69-bus IEEE standard systems.      
### 26.Model-Free Control of Dynamical Systems with Deep Reservoir Computing  [ :arrow_down: ](https://arxiv.org/pdf/2010.02285.pdf)
>  We propose and demonstrate a nonlinear control method that can be applied to unknown, complex systems where the controller is based on a type of artificial neural network known as a reservoir computer. In contrast to many modern neural-network-based control techniques, which are robust to system uncertainties but require a model nonetheless, our technique requires no prior knowledge of the system and is thus model-free. Further, our approach does not require an initial system identification step, resulting in a relatively simple and efficient learning process. Reservoir computers are well-suited to the control problem because they require small training data sets and remarkably low training times. By iteratively training and adding layers of reservoir computers to the controller, a precise and efficient control law is identified quickly. With examples on both numerical and high-speed experimental systems, we demonstrate that our approach is capable of controlling highly complex dynamical systems that display deterministic chaos to nontrivial target trajectories.      
### 27.Early Detection of Myocardial Infarction in Low-Quality Echocardiography  [ :arrow_down: ](https://arxiv.org/pdf/2010.02281.pdf)
>  Myocardial infarction (MI), or commonly known as heart attack, is a life-threatening worldwide health problem from which 32.4 million of people suffer each year. Early diagnosis and treatment of MI are crucial to prevent further heart tissue damages. However, MI detection in early stages is challenging because the symptoms are not easy to distinguish in electrocardiography findings or biochemical marker values found in the blood. Echocardiography is a noninvasive clinical tool for a more accurate early MI diagnosis, which is used to analyze the regional wall motion abnormalities. When echocardiography quality is poor, the diagnosis becomes a challenging and sometimes infeasible task even for a cardiologist. In this paper, we introduce a three-phase approach for early MI detection in low-quality echocardiography: 1) segmentation of the entire left ventricle (LV) wall of the heart using state-of-the-art deep learning model, 2) analysis of the segmented LV wall by feature engineering, and 3) early MI detection. The main contributions of this study are: highly accurate segmentation of the LV wall from low-resolution (both temporal and spatial) and noisy echocardiographic data, generating the segmentation ground-truth at pixel-level for the unannotated dataset using pseudo labeling approach, and composition of the first public echocardiographic dataset (HMC-QU) labeled by the cardiologists at the Hamad Medical Corporation Hospital in Qatar. Furthermore, the outputs of the proposed approach can significantly help cardiologists for a better assessment of the LV wall characteristics. The proposed method is evaluated in a 5-fold cross validation scheme on the HMC-QU dataset. The proposed approach has achieved an average level of 95.72% sensitivity and 99.58% specificity for the LV wall segmentation, and 85.97% sensitivity, 74.03% specificity, and 86.85% precision for MI detection.      
### 28.Textual Supervision for Visually Grounded Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2010.02806.pdf)
>  Visually-grounded models of spoken language understanding extract semantic information directly from speech, without relying on transcriptions. This is useful for low-resource languages, where transcriptions can be expensive or impossible to obtain. Recent work showed that these models can be improved if transcriptions are available at training time. However, it is not clear how an end-to-end approach compares to a traditional pipeline-based approach when one has access to transcriptions. Comparing different strategies, we find that the pipeline approach works better when enough text is available. With low-resource languages in mind, we also show that translations can be effectively used in place of transcriptions but more data is needed to obtain similar results.      
### 29.Vec2Instance: Parameterization for Deep Instance Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.02725.pdf)
>  Current advances in deep learning is leading to human-level accuracy in computer vision tasks such as object classification, localization, semantic segmentation, and instance segmentation. In this paper, we describe a new deep convolutional neural network architecture called Vec2Instance for instance segmentation. Vec2Instance provides a framework for parametrization of instances, allowing convolutional neural networks to efficiently estimate the complex shapes of instances around their centroids. We demonstrate the feasibility of the proposed architecture with respect to instance segmentation tasks on satellite images, which have a wide range of applications. Moreover, we demonstrate the usefulness of the new method for extracting building foot-prints from satellite images. Total pixel-wise accuracy of our approach is 89\%, near the accuracy of the state-of-the-art Mask RCNN (91\%). Vec2Instance is an alternative approach to complex instance segmentation pipelines, offering simplicity and intuitiveness. The code developed under this study is available in the Vec2Instance GitHub repository, <a class="link-external link-https" href="https://github.com/lakmalnd/Vec2Instance" rel="external noopener nofollow">this https URL</a>      
### 30.Parallax Motion Effect Generation Through Instance Segmentation And Depth Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2010.02680.pdf)
>  Stereo vision is a growing topic in computer vision due to the innumerable opportunities and applications this technology offers for the development of modern solutions, such as virtual and augmented reality applications. To enhance the user's experience in three-dimensional virtual environments, the motion parallax estimation is a promising technique to achieve this objective. In this paper, we propose an algorithm for generating parallax motion effects from a single image, taking advantage of state-of-the-art instance segmentation and depth estimation approaches. This work also presents a comparison against such algorithms to investigate the trade-off between efficiency and quality of the parallax motion effects, taking into consideration a multi-task learning network capable of estimating instance segmentation and depth estimation at once. Experimental results and visual quality assessment indicate that the PyD-Net network (depth estimation) combined with Mask R-CNN or FBNet networks (instance segmentation) can produce parallax motion effects with good visual quality.      
### 31.Real-time Uncertainty Decomposition for Online Learning Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.02613.pdf)
>  Safety-critical decisions based on machine learning models require a clear understanding of the involved uncertainties to avoid hazardous or risky situations. While aleatoric uncertainty can be explicitly modeled given a parametric description, epistemic uncertainty rather describes the presence or absence of training data. This paper proposes a novel generic method for modeling epistemic uncertainty and shows its advantages over existing approaches for neural networks on various data sets. It can be directly combined with aleatoric uncertainty estimates and allows for prediction in real-time as the inference is sample-free. We exploit this property in a model-based quadcopter control setting and demonstrate how the controller benefits from a differentiation between aleatoric and epistemic uncertainty in online learning of thermal disturbances.      
### 32.Target State Estimation and Prediction for High Speed Interception  [ :arrow_down: ](https://arxiv.org/pdf/2010.02512.pdf)
>  Accurate estimation and prediction of trajectory is essential for interception of any high speed target. In this paper, an extended Kalman filter is used to estimate the current location of target from its visual information and then predict its future position by using the observation sequence. Target motion model is developed considering the approximate known pattern of the target trajectory. In this work, we utilise visual information of the target to carry out the predictions. The proposed algorithm is developed in ROS-Gazebo environment and is verified using hardware implementation.      
### 33.Downscaling Attacks: What You See is Not What You Get  [ :arrow_down: ](https://arxiv.org/pdf/2010.02456.pdf)
>  The resizing of images, which is typically a required part of preprocessing for computer vision systems, is vulnerable to attack. We show that images can be created such that the image is completely different at machine-vision scales than at other scales. The default settings for some common computer vision and machine learning systems are vulnerable although defenses exist and are trivial to administer provided that defenders are aware of the threat. These attacks and defenses help to establish the role of input sanitization in machine learning.      
### 34.Pay Attention to the cough: Early Diagnosis of COVID-19 using Interpretable Symptoms Embeddings with Cough Sound Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2010.02417.pdf)
>  COVID-19 (coronavirus disease 2019) pandemic caused by SARS-CoV-2 has led to a treacherous and devastating catastrophe for humanity. At the time of writing, no specific antivirus drugs or vaccines are recommended to control infection transmission and spread. The current diagnosis of COVID-19 is done by Reverse-Transcription Polymer Chain Reaction (RT-PCR) testing. However, this method is expensive, time-consuming, and not easily available in straitened regions. An interpretable and COVID-19 diagnosis AI framework is devised and developed based on the cough sounds features and symptoms metadata to overcome these limitations. The proposed framework's performance was evaluated using a medical dataset containing Symptoms and Demographic data of 30000 audio segments, 328 cough sounds from 150 patients with four cough classes ( COVID-19, Asthma, Bronchitis, and Healthy). Experiments' results show that the model captures the better and robust feature embedding to distinguish between COVID-19 patient coughs and several types of non-COVID-19 coughs with higher specificity and accuracy of 95.04 $\pm$ 0.18% and 96.83$\pm$ 0.18% respectively, all the while maintaining interpretability.      
### 35.A Generalized Framework for Analytic Regularization of Uniform Cubic B-spline Displacement Fields  [ :arrow_down: ](https://arxiv.org/pdf/2010.02400.pdf)
>  Image registration is an inherently ill-posed problem that lacks the constraints needed for a unique mapping between voxels of the two images being registered. As such, one must regularize the registration to achieve physically meaningful transforms. The regularization penalty is usually a function of derivatives of the displacement-vector field, and can be calculated either analytically or numerically. The numerical approach, however, is computationally expensive depending on the image size, and therefore a computationally efficient analytical framework has been developed. Using cubic B-splines as the registration transform, we develop a generalized mathematical framework that supports five distinct regularizers: diffusion, curvature, linear elastic, third-order, and total displacement. We validate our approach by comparing each with its numerical counterpart in terms of accuracy. We also provide benchmarking results showing that the analytic solutions run significantly faster -- up to two orders of magnitude -- than finite differencing based numerical implementations.      
### 36.Single-Pixel Pattern Recognition with Coherent Nonlinear Optics  [ :arrow_down: ](https://arxiv.org/pdf/2010.02273.pdf)
>  We propose and experimentally demonstrate a nonlinear-optics approach to pattern recognition with single-pixel imaging and deep neural network. It employs mode selective image up-conversion to project a raw image onto a set of coherent spatial modes, whereby its signature features are extracted nonlinear-optically. With 40 projection modes, the classification accuracy reaches a high value of 99.49% for the MNIST handwritten digit images, and up to 95.32% even when they are mixed with strong noise. Our experiment harnesses rich coherent processes in nonlinear optics for efficient machine learning, with potential applications in online classification of large size images, fast lidar data analyses, complex pattern recognition, and so on.      
### 37.Smoother Network Tuning and Interpolation for Continuous-level Image Processing  [ :arrow_down: ](https://arxiv.org/pdf/2010.02270.pdf)
>  In Convolutional Neural Network (CNN) based image processing, most studies propose networks that are optimized to single-level (or single-objective); thus, they underperform on other levels and must be retrained for delivery of optimal performance. Using multiple models to cover multiple levels involves very high computational costs. To solve these problems, recent approaches train networks on two different levels and propose their own interpolation methods to enable arbitrary intermediate levels. However, many of them fail to generalize or have certain side effects in practical usage. In this paper, we define these frameworks as network tuning and interpolation and propose a novel module for continuous-level learning, called Filter Transition Network (FTN). This module is a structurally smoother module than existing ones. Therefore, the frameworks with FTN generalize well across various tasks and networks and cause fewer undesirable side effects. For stable learning of FTN, we additionally propose a method to initialize non-linear neural network layers with identity mappings. Extensive results for various image processing tasks indicate that the performance of FTN is comparable in multiple continuous levels, and is significantly smoother and lighter than that of other frameworks.      
### 38.The Interactive Dance Club: Avoiding Chaos In A Multi Participant Environment  [ :arrow_down: ](https://arxiv.org/pdf/2010.02207.pdf)
>  In 1998 we designed enabling technology and a venue concept that allowed several participants to influence a shared musical and visual experience. Our primary goal was to deliver musically coherent and visually satisfying results from several participants' input. The result, the Interactive Dance Club, ran for four nights at the ACM SIGGRAPH 98 convention in Orlando, Florida. In this paper we will briefly describe the Interactive Dance Club, our "10 Commandments of Interactivity," and what we learned from its premiere at SIGGRAPH 98.      

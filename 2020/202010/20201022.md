# ArXiv eess --Thu, 22 Oct 2020
### 1.Build Smart Grids on Artificial Intelligence -- A Real-world Example  [ :arrow_down: ](https://arxiv.org/pdf/2010.11175.pdf)
>  Power grid data are going big with the deployment of various sensors. The big data in power grids creates huge opportunities for applying artificial intelligence technologies to improve resilience and reliability. This paper introduces multiple real-world applications based on artificial intelligence to improve power grid situational awareness and resilience. These applications include event identification, inertia estimation, event location and magnitude estimation, data authentication, control, and stability assessment. These applications are operating on a real-world system called FNET-GridEye, which is a wide-area measurement network and arguably the world-largest cyber-physical system that collects power grid big data. These applications showed much better performance compared with conventional approaches and accomplished new tasks that are impossible to realized using conventional technologies. These encouraging results demonstrate that combining power grid big data and artificial intelligence can uncover and capture the non-linear correlation between power grid data and its stabilities indices and will potentially enable many advanced applications that can significantly improve power grid resilience.      
### 2.Large-Scale High PV Power Grid Dynamic Model Development -- A Case Study on the U.S. Eastern Interconnection  [ :arrow_down: ](https://arxiv.org/pdf/2010.11150.pdf)
>  Power systems are undergoing a transformation toward a low-carbon non-synchronous generation portfolio. A major concern for system planners and operators is the system dynamics in the high renewable penetration future. Because of the scale of the system and numerous components involved, it is extremely difficult to develop high PV dynamic models based upon actual power system models. The main contribution of this paper is providing an example of developing high PV penetration models based on the validated dynamic model of an actual large-scale power grid - the U.S. Eastern Interconnection system. The displacement of conventional generators by PV is realized by optimization. Combining the PV distribution optimization and the validated dynamic model information, this approach avoids the uncertainties brought about by transmission planning. As the existing dynamic models can be validated by measurements, this approach improves the credibility of the high PV models in representing future power grids. This generic approach can be applied to develop high PV dynamic models for other actual large-scale systems.      
### 3.FastEmit: Low-latency Streaming ASR with Sequence-level Emission Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2010.11148.pdf)
>  Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible. However, emitting fast without degrading quality, as measured by word error rate (WER), is highly challenging. Existing approaches including Early and Late Penalties and Constrained Alignments penalize emission delay by manipulating per-token or per-frame probability prediction in sequence transducer models. While being successful in reducing delay, these approaches suffer from significant accuracy regression and also require additional word alignment information from an existing model. In this work, we propose a sequence-level emission regularization method, named FastEmit, that applies latency regularization directly on per-sequence probability in training transducer models, and does not require any alignment. We demonstrate that FastEmit is more suitable to the sequence-level optimization of transducer models for streaming ASR by applying it on various end-to-end streaming ASR networks including RNN-Transducer, Transformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve 150-300 ms latency reduction with significantly better accuracy over previous techniques on a Voice Search test set. FastEmit also improves streaming ASR accuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile latency from 210 ms to only 30 ms on LibriSpeech.      
### 4.Adaptive Frequency-Regulation Demand Response Using Substation Solar Irradiance Measurement in High-PV Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.11136.pdf)
>  This letter proposes a distributed and adaptive demand response approach for primary frequency regulation in high-PV power systems. Using solar irradiance measurement at substations, the proposed approach allows accurate estimation of real-time system inertia of high-PV systems, thus facilitating the estimation of power imbalance after a contingency. The test results from the U.S. Electric Reliability Council of Texas (ERCOT) high-PV penetration models validated its effectiveness.      
### 5.Towards End-to-End Training of Automatic Speech Recognition for Nigerian Pidgin  [ :arrow_down: ](https://arxiv.org/pdf/2010.11123.pdf)
>  Nigerian Pidgin remains one of the most popular languages in West Africa. With at least 75 million speakers along the West African coast, the language has spread to diasporic communities through Nigerian immigrants in England, Canada, and America, amongst others. In contrast, the language remains an under-resourced one in the field of natural language processing, particularly on speech recognition and translation tasks. In this work, we present the first parallel (speech-to-text) data on Nigerian pidgin. We also trained the first end-to-end speech recognition system (QuartzNet and Jasper model) on this language which were both optimized using Connectionist Temporal Classification (CTC) loss. With baseline results, we were able to achieve a low word error rate (WER) of 0.77% using a greedy decoder on our dataset. Finally, we open-source the data and code along with this publication in order to encourage future research in this direction.      
### 6.Model Selection for Signal Processing: a Minimum Error Approach and a General Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2010.11114.pdf)
>  Estimation of the number of signals in the presence of noise is an important problem in several areas of statistical signal processing. There are a lot of modern works on the design of an optimal solution to this problem in terms of some criteria. Each criterion generates a model order selection (MOS) algorithm. <br>However, the minimum error probability criterion has not received significant attention, despite the fact that errors in the estimation of the number of signals might directly affect the performance of the signal processing system as a whole. In this paper, we propose a new approach to the design of MOS algorithms partially based on the minimum error probability criterion. <br>Also, we pay a lot of attention to the performance and consistency analysis of the MOS algorithms. In this study, an abridged error probability is used as a universal performance measure of the MOS algorithms. We propose a theoretical framework that allows to obtain closed-form expressions for the abridged error probabilities of a wide range of MOS algorithms. Moreover, a parametric consistency analysis of the presented MOS algorithms is provided. <br>Next, we use the obtained results to provide a parametric optimization of the presented MOS algorithms. <br>Finally, we study a quasilikelihood (QL) approach to the design and analysis of the MOS algorithms. The proposed theoretical framework is used to obtain the abridged error probabilities as functions of the unknown signal parameter. These functions, in its turn, allow us to find the scope of the QL approach.      
### 7.Anatomically-Informed Deep Learning on Contrast-Enhanced Cardiac MRI for Scar Segmentation and Clinical Feature Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2010.11081.pdf)
>  Many cardiac diseases are associated with structural remodeling of the myocardium. Cardiac magnetic resonance (CMR) imaging with contrast enhancement, such as late gadolinium enhancement (LGE), has unparalleled capability to visualize fibrotic tissue remodeling, allowing for direct characterization of the pathophysiological abnormalities leading to arrhythmias and sudden cardiac death (SCD). Automating segmentation of the ventricles with fibrosis distribution could dramatically enhance the utility of LGE-CMR in heart disease clinical research and in the management of patients with risk of arrhythmias and SCD. Here we describe an anatomically-informed deep learning (DL) approach to myocardium and scar segmentation and clinical feature extraction from LGE-CMR images. The technology enables clinical use by ensuring anatomical accuracy and complete automation. Algorithm performance is strong for both myocardium segmentation ($98\%$ accuracy and $0.79$ Dice score in a hold-out test set) and evaluation measures shown to correlate with heart disease, such as scar amount ($6.3\%$ relative error). Our approach for clinical feature extraction, which satisfies highly complex geometric constraints without stunting the learning process, has the potential of a broad applicability in computer vision beyond cardiology, and even outside of medicine.      
### 8.Minimum Mean-Squared-Error Autocorrelation Processing in Coprime Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2010.11073.pdf)
>  Coprime arrays enable Direction-of-Arrival (DoA) estimation of an increased number of sources. To that end, the receiver estimates the autocorrelation matrix of a larger virtual uniform linear array (coarray), by applying selection or averaging to the physical array's autocorrelation estimates, followed by spatial-smoothing. Both selection and averaging have been designed under no optimality criterion and attain arbitrary (suboptimal) Mean-Squared-Error (MSE) estimation performance. In this work, we design a novel coprime array receiver that estimates the coarray autocorrelations with Minimum-MSE (MMSE), for any probability distribution of the source DoAs. Our extensive numerical evaluation illustrates that the proposed MMSE approach returns superior autocorrelation estimates which, in turn, enable higher DoA estimation performance compared to standard counterparts.      
### 9.A Large-Scale Analysis of IoT Firmware Version Distribution in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2010.11026.pdf)
>  This paper examines the up-to-dateness of installed firmware versions of IoT devices accessible via public internet. It analyzes datasets of 1.06m devices collected from the IoT search engine Censys and maps the results against the latest firmware version each manufacturer offers. By applying the SEMMA data mining process, a fully scalable and adaptive approach is developed. This approach relies on three data artifacts: raw data from Censys, a mapping table with firmware versions and a keyword search list. The preliminary results confirm the heterogeneity of connected IoT devices. They show that manufacturer, device type and country influence the up-to-dateness of firmware. The results suggest users as a "weak link" as they do not update the firmware of their devices in a timely manner. However, the heterogeneity leads to results not showing a high reliability, yet.      
### 10.Frequency Response and Transfer Functions of Large Self-similar Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.11015.pdf)
>  This paper focuses on computing the frequency response and transfer functions for large self-similar networks under different circumstances. Modeling large scale systems is difficult due, typically, to the dimension of the problem, and self-similarity is the characteristic we exploit to make the problem more tractable. For each circumstance, we propose algorithms to obtain both transfer functions and frequency response, and we show that finite networks' dynamics are integer order, while infinite networks are fractional order or irrational. Based on that result, we also show that the effect of varying a network's operating condition to its dynamics can always be isolated, which is then expressed as a multiplicative disturbance acting upon a nominal plant. In addition, we analyze the non-integer-order nature residing in infinite dimensional systems in the context of self-similar networks. Finally, leveraging the main result of this paper, we also illustrate its capability of approximating some irrational expressions by using rational functions.      
### 11.Addressing the Recitative Problem in Real-time Opera Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2010.11013.pdf)
>  Robust real-time opera tracking (score following) would be extremely useful for many processes surrounding live opera staging and streaming, including automatic lyrics displays, camera control, or live video cutting. Recent work has shown that, with some appropriate measures to account for common problems such as breaks and interruptions, spontaneous applause, various noises and interludes, current audio-to-audio alignment algorithms can be made to follow an entire opera from beginning to end, in a relatively robust way. However, they remain inaccurate when the textual content becomes prominent against the melody or music -- notably, during recitativo passages. In this paper, we address this specific problem by proposing to use two specialized trackers in parallel, one focusing on music-, the other on speech-sensitive features. We first carry out a systematic study on speech-related features, targeting the precise alignment of corresponding recitatives from different performances of the same opera. Then we propose different solutions, based on pre-trained music and speech classifiers, to combine the two trackers in order to improve the global accuracy over the course of the entire opera.      
### 12.The UPC Speaker Verification System Submitted to VoxCeleb Speaker Recognition Challenge 2020 (VoxSRC-20)  [ :arrow_down: ](https://arxiv.org/pdf/2010.10937.pdf)
>  This report describes the submission from Technical University of Catalonia (UPC) to the VoxCeleb Speaker Recognition Challenge (VoxSRC-20) at Interspeech 2020. The final submission is a combination of three systems. System-1 is an autoencoder based approach which tries to reconstruct similar i-vectors, whereas System-2 and -3 are Convolutional Neural Network (CNN) based siamese architectures. The siamese networks have two and three branches, respectively, where each branch is a CNN encoder. The double-branch siamese performs binary classification using cross entropy loss during training. Whereas, our triple-branch siamese is trained to learn speaker embeddings using triplet loss. We provide results of our systems on VoxCeleb-1 test, VoxSRC-20 validation and test sets.      
### 13.Attention-based scaling adaptation for target speech extraction  [ :arrow_down: ](https://arxiv.org/pdf/2010.10923.pdf)
>  The target speech extraction has attracted widespread attention in recent years, however, the research of improving the target speaker clues is still limited. In this work, we focus on investigating the dynamic interaction between different mixtures and the target speaker to exploit the discriminative target speaker clues. We propose a special attention mechanism in a scaling adaptation layer to better adapt the network towards extracting the target speech. Furthermore, by introducing a mixture embedding matrix pooling method, our proposed attention-based scaling adaptation (ASA) can exploit the target speaker clues in a more efficient way. Experimental results on the spatialized reverberant WSJ0 2-mix dataset demonstrate that the proposed method improves the performance of the target speech extraction significantly. Furthermore, we find that under the same network configurations, the ASA in a single-channel condition can achieve competitive performance gains as that achieved from two-channel mixtures with inter-microphone phase difference (IPD) features.      
### 14.Multi-task Metric Learning for Text-independent Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2010.10919.pdf)
>  In this work, we introduce metric learning (ML) to enhance the deep embedding learning for text-independent speaker verification (SV). Specifically, the deep speaker embedding network is trained with conventional cross entropy loss and auxiliary pair-based ML loss function. For the auxiliary ML task, training samples of a mini-batch are first arranged into pairs, then positive and negative pairs are selected and weighted through their own and relative similarities, and finally the auxiliary ML loss is calculated by the similarity of the selected pairs. To evaluate the proposed method, we conduct experiments on the Speaker in the Wild (SITW) dataset. The results demonstrate the effectiveness of the proposed method.      
### 15.Multi-robot Implicit Control of Herds  [ :arrow_down: ](https://arxiv.org/pdf/2010.10895.pdf)
>  This paper presents a novel control strategy to herd a group of non-cooperative preys by means of a team of robotic hunters. In herding problems, the motion of the preys is typically determined by strong nonlinear reactive dynamics, escaping from the hunters. Besides, many applications demand the herding of numerous and/or heterogeneous entities, making the development of flexible control solutions challenging. In this context, our main contribution is a control approach that finds suitable herding actions, even when the nonlinearities in the preys' dynamics yield to implicit equations. We resort to numerical analysis theory to characterise the conditions that ensure the existence of such actions and propose a duple of design methods to compute them, one transforming the continuous time implicit system into an expanded explicit system, and the other applying a numerical method to find the action in discrete time. Additionally, the control strategy includes an adaptation law that makes it robust against uncertainty in the parameters of the preys. Simulations and real experiments validate the proposal in different scenarios.      
### 16.BERT for Joint Multichannel Speech Dereverberation with Spatial-aware Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2010.10892.pdf)
>  We propose a method for joint multichannel speech dereverberation with two spatial-aware multichannel tasks: direction-of-arrival (DOA) estimation and speech separation. The proposed method addresses tasks as a sequence to sequence mapping problem, which is general enough for a variety of front-end speech processing tasks. The proposed method is inspired by the excellent sequence modeling capability of bi-directional encoder representation from transformers (BERT). Instead of utilizing explicit representations from pretraining in a self-supervised way, we utilizes transformer encoded hidden representations in a supervised way. Both multichannel spectral magnitude and spectral phase information are encoded. Experimental result demonstrates the effectiveness of the proposed method.      
### 17.Learning Integrodifferential Models for Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2010.10888.pdf)
>  We introduce an integrodifferential extension of the edge-enhancing anisotropic diffusion model for image denoising. By accumulating weighted structural information on multiple scales, our model is the first to create anisotropy through multiscale integration. It follows the philosophy of combining the advantages of model-based and data-driven approaches within compact, insightful, and mathematically well-founded models with improved performance. We explore trained results of scale-adaptive weighting and contrast parameters to obtain an explicit modelling by smooth functions. This leads to a transparent model with only three parameters, without significantly decreasing its denoising performance. Experiments demonstrate that it outperforms its diffusion-based predecessors. We show that both multiscale information and anisotropy are crucial for its success.      
### 18.Safety With Limited Range Sensing Constraints For Fixed Wing Aircraft  [ :arrow_down: ](https://arxiv.org/pdf/2010.10883.pdf)
>  In this paper we discuss how to use a barrier function that is subject to kinematic constraints and limited sensing in order to guarantee that fixed wing unmanned aerial vehicles (UAVs) will maintain safe distances from each other at all times despite being subject to limited range sensing constraints. Prior work has shown that a barrier function can be used to guarantee safe system operation when the state can be sensed at all times. However, in this paper we show that this construction does not guarantee safety when the UAVs are subject to limited range sensing. To resolve this issue, we introduce a method for constructing a new barrier function that accommodates limited sensing range from a previously existing barrier function that may not necessarily accommodate limited range sensing. We show that, under appropriate conditions, the newly constructed barrier function ensures system safety even in the presence of limited range sensing. We demonstrate the contribution of this paper in a scenario of 20 fixed wing aircraft, where because of the proposed algorithm, the vehicles are able to maintain safe distances from each other even though the vehicles are subject to limited range sensing.      
### 19.Experimental Automatic Calibration of a Semi-Active Suspension Controller via Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.10831.pdf)
>  The End-of-Line (EoL) calibration of semi-active suspension systems for road vehicles is usually a critical and expensive task, needing a team of vehicle and control experts as well as many hours of professional driving. In this paper, we propose a purely data-based tuning method enabling the automatic calibration of the parameters of a proprietary suspension controller by relying on little experimental time and exploiting Bayesian Optimization tools. A detailed methodology on how to select the most critical degrees of freedom of the algorithm is also provided. The effectiveness of the proposed approach is assessed on a commercial multi-body simulator as well as on a real car.      
### 20.Koopman operator approach for computing structure of solutions and Observability of non-linear finite state system  [ :arrow_down: ](https://arxiv.org/pdf/2010.10752.pdf)
>  Given a discrete dynamical system defined by a map in a vector space over a finite field called Finite State Systems (FSS), a dual linear system over the space of functions on the state space is constructed using the dual map. This system constitutes the well known Koopman linear system framework of dynamical systems, hence called the Koopman linear system (KLS). It is first shown that several structural properties of solutions of the FSS can be inferred from the solutions of the KLS. The problems of computation of structural parameters of solutions of non-linear FSS are computationally hard and hence become infeasible as the number of variables increases. In contrast, it has been well known that these problems can be solved by linear algebra for linear FSS in terms of elementary divisors of matrices and their orders. In the next step, the KLS is reduced to the smallest order (called RO-KLS) while still retaining all the information of the parameters of structure of solutions of the FSS. Hence when the order of the RO-KLS is sufficiently small, the above computational problems of non-linear FSS are practically feasible. Next, it is shown that the observability of the non-linear FSS with an output function is equivalent to that of the RO-KLS with an appropriate linear output map. Hence, the problem of non-linear observability is solved by an observer design for the equivalent RO-KLS. Such a construction should have striking applications to realistic FSS arising in Cryptology and Biological networks.      
### 21.A statistical framework for model-based inverse problems in ultrasound elastography  [ :arrow_down: ](https://arxiv.org/pdf/2010.10729.pdf)
>  Model-based computational elasticity imaging of tissues can be posed as solving an inverse problem over finite elements spanning the displacement image. As most existing quasi-static elastography methods count on deterministic formulations of the forward model resulting in a constrained optimization problem, the impact of displacement observation errors has not been well addressed. To this end, we propose a new statistical technique that leads to a unified optimization problem for elasticity imaging. Our statistical model takes the imperfect nature of the displacement measurements into account, and leads to an observation model for the Young's modulus that involves signal dependent colored noise. To solve the resulting regularized optimization problem, we propose a fixed-point algorithm that leverages proximal splitting methods. Preliminary qualitative and quantitative results demonstrate the effectiveness and robustness of the proposed methodology.      
### 22.Learning Disentangled Phone and Speaker Representations in a Semi-Supervised VQ-VAE Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2010.10727.pdf)
>  We present a new approach to disentangle speaker voice and phone content by introducing new components to the VQ-VAE architecture for speech synthesis. The original VQ-VAE does not generalize well to unseen speakers or content. To alleviate this problem, we have incorporated a speaker encoder and speaker VQ codebook that learns global speaker characteristics entirely separate from the existing sub-phone codebooks. We also compare two training methods: self-supervised with global conditions and semi-supervised with speaker labels. Adding a speaker VQ component improves objective measures of speech synthesis quality (estimated MOS, speaker similarity, ASR-based intelligibility) and provides learned representations that are meaningful. Our speaker VQ codebook indices can be used in a simple speaker diarization task and perform slightly better than an x-vector baseline. Additionally, phones can be recognized from sub-phone VQ codebook indices in our semi-supervised VQ-VAE better than self-supervised with global conditions.      
### 23.Detection of COVID-19 through the analysis of vocal fold oscillations  [ :arrow_down: ](https://arxiv.org/pdf/2010.10707.pdf)
>  Phonation, or the vibration of the vocal folds, is the primary source of vocalization in the production of voiced sounds by humans. It is a complex bio-mechanical process that is highly sensitive to changes in the speaker's respiratory parameters. Since most symptomatic cases of COVID-19 present with moderate to severe impairment of respiratory functions, we hypothesize that signatures of COVID-19 may be observable by examining the vibrations of the vocal folds. Our goal is to validate this hypothesis, and to quantitatively characterize the changes observed to enable the detection of COVID-19 from voice. For this, we use a dynamical system model for the oscillation of the vocal folds, and solve it using our recently developed ADLES algorithm to yield vocal fold oscillation patterns directly from recorded speech. Experimental results on a clinically curated dataset of COVID-19 positive and negative subjects reveal characteristic patterns of vocal fold oscillations that are correlated with COVID-19. We show that these are prominent and discriminative enough that even simple classifiers such as logistic regression yields high detection accuracies using just the recordings of isolated extended vowels.      
### 24.Real-time Speech Frequency Bandwidth Extension  [ :arrow_down: ](https://arxiv.org/pdf/2010.10677.pdf)
>  In this paper we propose a lightweight model for frequency bandwidth extension of speech signals, increasing the sampling frequency from 8kHz to 16kHz while restoring the high frequency content to a level almost indistinguishable from the 16kHz ground truth. The model architecture is based on SEANet (Sound EnhAncement Network), a wave-to-wave fully convolutional model, which uses a combination of feature losses and adversarial losses to reconstruct an enhanced version of the input speech. In addition, we propose a variant of SEANet that can be deployed on-device in streaming mode, achieving an architectural latency of 16ms. When profiled on a single core of a mobile CPU, processing one 16ms frame takes only 1.5ms. The low latency makes it viable for bi-directional voice communication systems.      
### 25.Exploring Overcomplete Representations for Single Image Deraining using CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2010.10661.pdf)
>  Removal of rain streaks from a single image is an extremely challenging problem since the rainy images often contain rain streaks of different size, shape, direction and density. Most recent methods for deraining use a deep network following a generic "encoder-decoder" architecture which captures low-level features across the initial layers and high-level features in the deeper layers. For the task of deraining, the rain streaks which are to be removed are relatively small and focusing much on global features is not an efficient way to solve the problem. To this end, we propose using an overcomplete convolutional network architecture which gives special attention in learning local structures by restraining the receptive field of filters. We combine it with U-Net so that it does not lose out on the global structures as well while focusing more on low-level features, to compute the derained image. The proposed network called, Over-and-Under Complete Deraining Network (OUCD), consists of two branches: overcomplete branch which is confined to small receptive field size in order to focus on the local structures and an undercomplete branch that has larger receptive fields to primarily focus on global structures. Extensive experiments on synthetic and real datasets demonstrate that the proposed method achieves significant improvements over the recent state-of-the-art methods.      
### 26.Statistical Analysis of the LMS Algorithm for Proper and Improper Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2010.10657.pdf)
>  The LMS algorithm is one of the most widely used techniques in adaptive filtering. Accurate modeling of the algorithm in various circumstances is paramount to achieving an efficient adaptive Wiener filter design process. In the recent decades, concerns have been raised on studying improper signals and providing an accurate model of the LMS algorithm for both proper and improper signals. Other models for the LMS algorithm for improper signals available in the scientific literature either make use of the independence assumptions regarding the desired signal and the input signal vector, or are exclusive to proper signals; it is shown that by not considering these assumptions a more general model can be derived. In the presented simulations it is possible to verify that the model introduced in this paper outperforms the other available models.      
### 27.On Consensusability of Linear Interconnected Multi-Agent Systems and Simultaneous Stabilization  [ :arrow_down: ](https://arxiv.org/pdf/2010.10632.pdf)
>  Consensusability of multi-agent systems (MASs) certifies the existence of a distributed controller capable of driving the states of each subsystem to a consensus value. We study the consensusability of linear interconnected MASs (LIMASs) where, as in several real-world applications, subsystems are physically coupled. We show that consensusability is related to the simultaneous stabilizability of multiple LTI systems, and present a novel sufficient condition in form of a linear program for verifying this property. We also derive several necessary and sufficient consensusability conditions for LIMASs in terms of parameters of the subsystem matrices and the eigenvalues of the physical and communication graph Laplacians. The results show that weak physical couplings among subsystems and densely-connected physical and communication graphs are favorable for consensusability. Finally, we validate our results through simulations of networks of supercapacitors and DC microgrids.      
### 28.An Optimization-and-Simulation Framework for Redesigning University Campus Bus System with Social Distancing  [ :arrow_down: ](https://arxiv.org/pdf/2010.10630.pdf)
>  The outbreak of coronavirus disease 2019 (COVID-19) has led to significant challenges for schools, workplaces and communities to return to operations during the pandemic, while policymakers need to balance between individuals' safety and operational efficiency. In this paper, we present a mixed-integer programming model for redesigning routes and bus schedules for the University of Michigan (UM)'s campus bus system, to prepare for students' return in the 2020 Fall semester. To ensure less than 15-minute travel time for all routes and to enforce social distancing among passengers, we propose a hub-and-spoke design and utilize real data of student activities to identify hub locations and reduce the number of bus stops used in the new routes. The new bus routes, although using only 50% or even fewer seats in each bus, can still satisfy peak-hour demand in regular semesters at UM. We sample a variety of scenarios that cover variations of peak demand, social-distancing requirements, broken-down buses or no-shows of drivers, to demonstrate the system resiliency of the new routes and schedules via simulation. Our approach can be generalized to redesign public transit systems with social distancing requirement during the pandemic, to reduce passengers' infection risk.      
### 29.SSUE: Simultaneous State and Uncertainty Estimation for Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.10606.pdf)
>  Parameters of the mathematical model describing many practical dynamical systems are prone to vary due to aging or renewal, wear and tear, as well as changes in environmental or service conditions. These variabilities will adversely affect the accuracy of state estimation. In this paper, we introduce SSUE: Simultaneous State and Uncertainty Estimation for quantifying parameter uncertainty while simultaneously estimating the internal state of a system. Our approach involves the development of a Bayesian framework that recursively updates the posterior joint density of the unknown state vector and parameter uncertainty. To execute the framework for practical implementation, we develop a computational algorithm based on maximum a posteriori estimation and the numerical Newton's method. Observability analysis is conducted for linear systems, and its relation with the consistency of the estimation of the uncertainty's location is unveiled. Additional simulation results are provided to demonstrate the effectiveness of the proposed SSUE approach.      
### 30.Knowledge Transfer for Efficient On-device False Trigger Mitigation  [ :arrow_down: ](https://arxiv.org/pdf/2010.10591.pdf)
>  In this paper, we address the task of determining whether a given utterance is directed towards a voice-enabled smart-assistant device or not. An undirected utterance is termed as a "false trigger" and false trigger mitigation (FTM) is essential for designing a privacy-centric non-intrusive smart assistant. The directedness of an utterance can be identified by running automatic speech recognition (ASR) on it and determining the user intent by analyzing the ASR transcript. But in case of a false trigger, transcribing the audio using ASR itself is strongly undesirable. To alleviate this issue, we propose an LSTM-based FTM architecture which determines the user intent from acoustic features directly without explicitly generating ASR transcripts from the audio. The proposed models are small footprint and can be run on-device with limited computational resources. During training, the model parameters are optimized using a knowledge transfer approach where a more accurate self-attention graph neural network model serves as the teacher. Given the whole audio snippets, our approach mitigates 87% of false triggers at 99% true positive rate (TPR), and in a streaming audio scenario, the system listens to only 1.69s of the false trigger audio before rejecting it while achieving the same TPR.      
### 31.Stability Analysis of Gradient-Based Distributed Formation Control with Heterogeneous Sensing Mechanism: Two and Three Robot Case  [ :arrow_down: ](https://arxiv.org/pdf/2010.10559.pdf)
>  This paper focuses on the stability analysis of a formation shape displayed by a team of mobile robots that uses heterogeneous sensing mechanism. Depending on the convenience and reliability of the local information, each robot utilizes the popular gradient-based control law which, in this paper, is either the distance-based or the bearing-only formation control. For the two and three robot case, we show that the use of heterogeneous gradient-based control laws can give rise to an undesired invariant set where a distorted formation shape is moving at a constant velocity. The (in)stability of such an invariant set is dependent on the specified distance and bearing constraints. For the two robot case, we prove almost global stability of the desired equilibrium set while for the three robot case, we guarantee local asymptotic stability for the correct formation shape. We also derive conditions for the three robot case in which the undesired invariant set is locally attractive. Numerical simulations are presented for illustrating the theoretical results in the three robot case.      
### 32.Joint Blind Room Acoustic Characterization From Speech And Music Signals Using Convolutional Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.11167.pdf)
>  Acoustic environment characterization opens doors for sound reproduction innovations, smart EQing, speech enhancement, hearing aids, and forensics. Reverberation time, clarity, and direct-to-reverberant ratio are acoustic parameters that have been defined to describe reverberant environments. They are closely related to speech intelligibility and sound quality. As explained in the ISO3382 standard, they can be derived from a room measurement called the Room Impulse Response (RIR). However, measuring RIRs requires specific equipment and intrusive sound to be played. The recent audio combined with machine learning suggests that one could estimate those parameters blindly using speech or music signals. We follow these advances and propose a robust end-to-end method to achieve blind joint acoustic parameter estimation using speech and/or music signals. Our results indicate that convolutional recurrent neural networks perform best for this task, and including music in training also helps improve inference from speech.      
### 33.Sentence Boundary Augmentation For Neural Machine Translation Robustness  [ :arrow_down: ](https://arxiv.org/pdf/2010.11132.pdf)
>  Neural Machine Translation (NMT) models have demonstrated strong state of the art performance on translation tasks where well-formed training and evaluation data are provided, but they remain sensitive to inputs that include errors of various types. Specifically, in the context of long-form speech translation systems, where the input transcripts come from Automatic Speech Recognition (ASR), the NMT models have to handle errors including phoneme substitutions, grammatical structure, and sentence boundaries, all of which pose challenges to NMT robustness. Through in-depth error analysis, we show that sentence boundary segmentation has the largest impact on quality, and we develop a simple data augmentation strategy to improve segmentation robustness.      
### 34.One Model to Reconstruct Them All: A Novel Way to Use the Stochastic Noise in StyleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2010.11113.pdf)
>  Generative Adversarial Networks (GANs) have achieved state-of-the-art performance for several image generation and manipulation tasks. Different works have improved the limited understanding of the latent space of GANs by embedding images into specific GAN architectures to reconstruct the original images. We present a novel StyleGAN-based autoencoder architecture, which can reconstruct images with very high quality across several data domains. We demonstrate a previously unknown grade of generalizablility by training the encoder and decoder independently and on different datasets. Furthermore, we provide new insights about the significance and capabilities of noise inputs of the well-known StyleGAN architecture. Our proposed architecture can handle up to 40 images per second on a single GPU, which is approximately 28x faster than previous approaches. Finally, our model also shows promising results, when compared to the state-of-the-art on the image denoising task, although it was not explicitly designed for this task.      
### 35.WaveTransformer: A Novel Architecture for Audio Captioning Based on Learning Temporal and Time-Frequency Information  [ :arrow_down: ](https://arxiv.org/pdf/2010.11098.pdf)
>  Automated audio captioning (AAC) is a novel task, where a method takes as an input an audio sample and outputs a textual description (i.e. a caption) of its contents. Most AAC methods are adapted from from image captioning of machine translation fields. In this work we present a novel AAC novel method, explicitly focused on the exploitation of the temporal and time-frequency patterns in audio. We employ three learnable processes for audio encoding, two for extracting the local and temporal information, and one to merge the output of the previous two processes. To generate the caption, we employ the widely used Transformer decoder. We assess our method utilizing the freely available splits of Clotho dataset. Our results increase previously reported highest SPIDEr to 17.3, from 16.2.      
### 36.Adaptive Structured Sparse Network for Efficient CNNs with Feature Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2010.11083.pdf)
>  Neural networks have made great progress in pixel to pixel image processing tasks, e.g. super resolution, style transfer and image denoising. However, recent algorithms have a tendency to be too structurally complex to deploy on embedded systems. Traditional accelerating methods fix the options for pruning network weights to produce unstructured or structured sparsity. Many of them lack flexibility for different inputs. In this paper, we propose a Feature Regularization method that can generate input-dependent structured sparsity for hidden features. Our method can improve sparsity level in intermediate features by 60% to over 95% through pruning along the channel dimension for each pixel, thus relieving the computational and memory burden. On BSD100 dataset, the multiply-accumulate operations can be reduced by over 80% for super resolution tasks. In addition, we propose a method to quantitatively control the level of sparsity and design a way to train one model that supports multi-sparsity. We identify the effectiveness of our method for pixel to pixel tasks by qualitative theoretical analysis and experiments.      
### 37.Beamforming Optimization for IRS-Aided Communications with Transceiver Hardware Impairments  [ :arrow_down: ](https://arxiv.org/pdf/2010.11074.pdf)
>  In this paper, we focus on intelligent reflecting surface (IRS) assisted multi-antenna communications with transceiver hardware impairments encountered in practice. In particular, we aim to maximize the received signal-to-noise ratio (SNR) taking into account the impact of hardware impairments, where the source transmit beamforming and the IRS reflect beamforming are jointly designed under the proposed optimization framework. To circumvent the non-convexity of the formulated design problem, we first derive a closed-form optimal solution to the source transmit beamforming. Then, for the optimization of IRS reflect beamforming, we obtain an upper bound to the optimal objective value via solving a single convex problem. A low-complexity minorization-maximization (MM) algorithm was developed to approach the upper bound. Simulation results demonstrate that the proposed beamforming design is more robust to the hardware impairments than that of the conventional SNR maximized scheme. Moreover, compared to the scenario without deploying an IRS, the performance gain brought by incorporating the hardware impairments is more evident for the IRS-aided communications.      
### 38.Knowledge Distillation for Improved Accuracy in Spoken Question Answering  [ :arrow_down: ](https://arxiv.org/pdf/2010.11067.pdf)
>  Spoken question answering (SQA) is a challenging task that requires the machine to fully understand the complex spoken documents. Automatic speech recognition (ASR) plays a significant role in the development of QA systems. However, the recent work shows that ASR systems generate highly noisy transcripts, which critically limit the capability of machine comprehension on the SQA task. To address the issue, we present a novel distillation framework. Specifically, we devise a training strategy to perform knowledge distillation (KD) from spoken documents and written counterparts. Our work makes a step towards distilling knowledge from the language model as a supervision signal to lead to better student accuracy by reducing the misalignment between automatic and manual transcriptions. Experiments demonstrate that our approach outperforms several state-of-the-art language models on the Spoken-SQuAD dataset.      
### 39.Contextualized Attention-based Knowledge Transfer for Spoken Conversational Question Answering  [ :arrow_down: ](https://arxiv.org/pdf/2010.11066.pdf)
>  Spoken conversational question answering (SCQA) requires machines to model complex dialogue flow given the speech utterances and text corpora. Different from traditional text question answering (QA) tasks, SCQA involves audio signal processing, passage comprehension, and contextual understanding. However, ASR systems introduce unexpected noisy signals to the transcriptions, which result in performance degradation on SCQA. To overcome the problem, we propose CADNet, a novel contextualized attention-based distillation approach, which applies both cross-attention and self-attention to obtain ASR-robust contextualized embedding representations of the passage and dialogue history for performance improvements. We also introduce the spoken conventional knowledge distillation framework to distill the ASR-robust knowledge from the estimated probabilities of the teacher model to the student. We conduct extensive experiments on the Spoken-CoQA dataset and demonstrate that our approach achieves remarkable performance in this task.      
### 40.Complex data labeling with deep learning methods: Lessons from fisheries acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2010.11010.pdf)
>  Quantitative and qualitative analysis of acoustic backscattered signals from the seabed bottom to the sea surface is used worldwide for fish stocks assessment and marine ecosystem monitoring. Huge amounts of raw data are collected yet require tedious expert labeling. This paper focuses on a case study where the ground truth labels are non-obvious: echograms labeling, which is time-consuming and critical for the quality of fisheries and ecological analysis. We investigate how these tasks can benefit from supervised learning algorithms and demonstrate that convolutional neural networks trained with non-stationary datasets can be used to stress parts of a new dataset needing human expert correction. Further development of this approach paves the way toward a standardization of the labeling process in fisheries acoustics and is a good case study for non-obvious data labeling processes.      
### 41.Contrastive Learning of General-Purpose Audio Representations  [ :arrow_down: ](https://arxiv.org/pdf/2010.10915.pdf)
>  We introduce COLA, a self-supervised pre-training approach for learning a general-purpose representation of audio. Our approach is based on contrastive learning: it learns a representation which assigns high similarity to audio segments extracted from the same recording while assigning lower similarity to segments from different recordings. We build on top of recent advances in contrastive learning for computer vision and reinforcement learning to design a lightweight, easy-to-implement self-supervised model of audio. We pre-train embeddings on the large-scale Audioset database and transfer these representations to 9 diverse classification tasks, including speech, music, animal sounds, and acoustic scenes. We show that despite its simplicity, our method significantly outperforms previous self-supervised systems. We furthermore conduct ablation studies to identify key design choices and release a library to pre-train and fine-tune COLA models.      
### 42.On Information Asymmetry in Competitive Multi-Agent Reinforcement Learning: Convergence and Optimality  [ :arrow_down: ](https://arxiv.org/pdf/2010.10901.pdf)
>  In this work, we study the system of interacting non-cooperative two Q-learning agents, where one agent has the privilege of observing the other's actions. We show that this information asymmetry can lead to a stable outcome of population learning, which does not occur in an environment of general independent learners. Furthermore, we discuss the resulted post-learning policies, show that they are almost optimal in the underlying game sense, and provide numerical hints of almost welfare-optimal of the resulted policies.      
### 43.Deep learning based registration using spatial gradients and noisy segmentation labels  [ :arrow_down: ](https://arxiv.org/pdf/2010.10897.pdf)
>  Image registration is one of the most challenging problems in medical image analysis. In the recent years, deep learning based approaches became quite popular, providing fast and performing registration strategies. In this short paper, we summarise our work presented on Learn2Reg challenge 2020. The main contributions of our work rely on (i) a symmetric formulation, predicting the transformations from source to target and from target to source simultaneously, enforcing the trained representations to be similar and (ii) integration of variety of publicly available datasets used both for pretraining and for augmenting segmentation labels. Our method reports a mean dice of $0.64$ for task 3 and $0.85$ for task 4 on the test sets, taking third place on the challenge. Our code and models are publicly available at <a class="link-external link-https" href="https://github.com/TheoEst/abdominal_registration" rel="external noopener nofollow">this https URL</a> and \<a class="link-external link-https" href="https://github.com/TheoEst/hippocampus_registration" rel="external noopener nofollow">this https URL</a>.      
### 44.Coordinated Online Learning for Multi-Agent Systems with Coupled Constraints and Perturbed Utility Observations  [ :arrow_down: ](https://arxiv.org/pdf/2010.10878.pdf)
>  Competitive non-cooperative online decision-making agents whose actions increase congestion of scarce resources constitute a model for widespread modern large-scale applications. To ensure sustainable resource behavior, we introduce a novel method to steer the agents toward a stable population state, fulfilling the given coupled resource constraints. The proposed method is a decentralized resource pricing method based on the resource loads resulting from the augmentation of the game's Lagrangian. Assuming that the online learning agents have only noisy first-order utility feedback, we show that for a polynomially decaying agents' step size/learning rate, the population's dynamic will almost surely converge to generalized Nash equilibrium. A particular consequence of the latter is the fulfillment of resource constraints in the asymptotic limit. Moreover, we investigate the finite-time quality of the proposed algorithm by giving a nonasymptotic time decaying bound for the expected amount of resource constraint violation.      
### 45.Trends at NIME -- Reflections on Editing "A NIME Reader"  [ :arrow_down: ](https://arxiv.org/pdf/2010.10803.pdf)
>  This paper provides an overview of the process of editing the forthcoming anthology "A NIME Reader - Fifteen Years of New Interfaces for Musical Expression." The selection process is presented, and we reflect on some of the trends we have observed in re-discovering the collection of more than 1200 NIME papers published throughout the 15-year long history of the conference. An anthology is necessarily selective, and ours is no exception. As we present in this paper, the aim has been to represent the wide range of artistic, scientific, and technological approaches that characterize the NIME conference. The anthology also includes critical discourse, and through acknowledgment of the strengths and weaknesses of the NIME community, we propose activities that could further diversify and strengthen the field.      
### 46.Worst-case sensitivity  [ :arrow_down: ](https://arxiv.org/pdf/2010.10794.pdf)
>  We introduce the notion of Worst-Case Sensitivity, defined as the worst-case rate of increase in the expected cost of a Distributionally Robust Optimization (DRO) model when the size of the uncertainty set vanishes. We show that worst-case sensitivity is a Generalized Measure of Deviation and that a large class of DRO models are essentially mean-(worst-case) sensitivity problems when uncertainty sets are small, unifying recent results on the relationship between DRO and regularized empirical optimization with worst-case sensitivity playing the role of the regularizer. More generally, DRO solutions can be sensitive to the family and size of the uncertainty set, and reflect the properties of its worst-case sensitivity. We derive closed-form expressions of worst-case sensitivity for well known uncertainty sets including smooth $\phi$-divergence, total variation, "budgeted" uncertainty sets, uncertainty sets corresponding to a convex combination of expected value and CVaR, and the Wasserstein metric. These can be used to select the uncertainty set and its size for a given application.      
### 47.Emformer: Efficient Memory Transformer Based Acoustic Model For Low Latency Streaming Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.10759.pdf)
>  This paper proposes an efficient memory transformer Emformer for low latency streaming speech recognition. In Emformer, the long-range history context is distilled into an augmented memory bank to reduce self-attention's computation complexity. A cache mechanism saves the computation for the key and value in self-attention for the left context. Emformer applies a parallelized block processing in training to support low latency models. We carry out experiments on benchmark LibriSpeech data. Under average latency of 960 ms, Emformer gets WER $2.50\%$ on test-clean and $5.62\%$ on test-other. Comparing with a strong baseline augmented memory transformer (AM-TRF), Emformer gets $4.6$ folds training speedup and $18\%$ relative real-time factor (RTF) reduction in decoding with relative WER reduction $17\%$ on test-clean and $9\%$ on test-other. For a low latency scenario with an average latency of 80 ms, Emformer achieves WER $3.01\%$ on test-clean and $7.09\%$ on test-other. Comparing with the LSTM baseline with the same latency and model size, Emformer gets relative WER reduction $9\%$ and $16\%$ on test-clean and test-other, respectively.      
### 48.Safety Verification of Model Based Reinforcement Learning Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2010.10740.pdf)
>  Model-based reinforcement learning (RL) has emerged as a promising tool for developing controllers for real world systems (e.g., robotics, autonomous driving, etc.). However, real systems often have constraints imposed on their state space which must be satisfied to ensure the safety of the system and its environment. Developing a verification tool for RL algorithms is challenging because the non-linear structure of neural networks impedes analytical verification of such models or controllers. To this end, we present a novel safety verification framework for model-based RL controllers using reachable set analysis. The proposed frame-work can efficiently handle models and controllers which are represented using neural networks. Additionally, if a controller fails to satisfy the safety constraints in general, the proposed framework can also be used to identify the subset of initial states from which the controller can be safely executed.      
### 49.Markov Data-Based Reference Tracking of Tensegrity Morphing Airfoils  [ :arrow_down: ](https://arxiv.org/pdf/2010.10710.pdf)
>  This letter presents a data-based control design for reference tracking applications. This design finds the optimal control sequence, which minimizes a quadratic cost function consisting of tracking error and input increments over a finite interval [0,N]. The only information needed is the first N+1 Markov parameters of the system. This design is employed on a tensegrity morphing airfoil whose topology has been described in detail in this letter. A NACA 2412 airfoil with specified morphing targets is chosen to verify the developed design. The principle developed in this letter is also applicable to other structural control problems.      
### 50.Prediction of Object Geometry from Acoustic Scattering Using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.10691.pdf)
>  Acoustic scattering is strongly influenced by boundary geometry of objects over which sound scatters. The present work proposes a method to infer object geometry from scattering features by training convolutional neural networks. The training data is generated from a fast numerical solver developed on CUDA. The complete set of simulations is sampled to generate multiple datasets containing different amounts of channels and diverse image resolutions. The robustness of our approach in response to data degradation is evaluated by comparing the performance of networks trained using the datasets with varying levels of data degradation. The present work has found that the predictions made from our models match ground truth with high accuracy. In addition, accuracy does not degrade when fewer data channels or lower resolutions are used.      
### 51.The Secret Arithmetic of Patterns: A General Method for Designing Constrained Codes Based on Lexicographic Indexing  [ :arrow_down: ](https://arxiv.org/pdf/2010.10686.pdf)
>  Constrained codes are used to prevent errors from occurring in various data storage and data transmission systems. They can help in increasing the storage density of magnetic storage devices, in managing the lifetime of electronic storage devices, and in increasing the reliability of data transmission over wires. We recently introduced families of lexicographically-ordered constrained (LOCO) codes. These codes achieve capacity with simple encoding and decoding, and they are easy to reconfigure. In this paper, we generalize our work on LOCO codes by presenting a systematic method that guides the code designer to build any constrained code based on lexicographic indexing once the finite set of data patterns to forbid is known. In particular, we connect the set of forbidden patterns directly to the cardinality of the code and to the rule that uncovers the index associated with a codeword. By doing that, we reveal the secret arithmetic of patterns, and make the code design significantly easier. We design optimal (rate-wise) constrained codes for the new two-dimensional magnetic recording (TDMR) technology. We show notable performance gains as a result of solely applying the new codes. Moreover, we show how near-optimal constrained codes be designed and used to further reduce complexity.      
### 52.VENOMAVE: Clean-Label Poisoning Against Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.10682.pdf)
>  In the past few years, we observed a wide adoption of practical systems that use Automatic Speech Recognition (ASR) systems to improve human-machine interaction. Modern ASR systems are based on neural networks and prior research demonstrated that these systems are susceptible to adversarial examples, i.e., malicious audio inputs that lead to misclassification by the victim's network during the system's run time. The research question if ASR systems are also vulnerable to data poisoning attacks is still unanswered. In such an attack, a manipulation happens during the training phase of the neural network: an adversary injects malicious inputs into the training set such that the neural network's integrity and performance are compromised. In this paper, we present the first data poisoning attack in the audio domain, called VENOMAVE. Prior work in the image domain demonstrated several types of data poisoning attacks, but they cannot be applied to the audio domain. The main challenge is that we need to attack a time series of inputs. To enforce a targeted misclassification in an ASR system, we need to carefully generate a specific sequence of disturbed inputs for the target utterance, which will eventually be decoded to the desired sequence of words. More specifically, the adversarial goal is to produce a series of misclassification tasks and in each of them, we need to poison the system to misrecognize each frame of the target file. To demonstrate the practical feasibility of our attack, we evaluate VENOMAVE on an ASR system that detects sequences of digits from 0 to 9. When poisoning only 0.94% of the dataset on average, we achieve an attack success rate of 83.33%. We conclude that data poisoning attacks against ASR systems represent a real threat that needs to be considered.      
### 53.Private Weighted Sum Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2010.10640.pdf)
>  As large amounts of data are circulated both from users to a cloud server and between users, there is a critical need for privately aggregating the shared data. This paper considers the problem of private weighted sum aggregation with secret weights, where an aggregator wants to compute the weighted sum of the local data of some agents. Depending on the privacy requirements posed on the weights, there are different secure multi-party computation schemes exploiting the information structure. First, when each agent has a local private value and a local private weight, we review private sum aggregation schemes. Second, we discuss how to extend the previous schemes for when the agents have a local private value, but the aggregator holds the corresponding weights. Third, we treat a more general case where the agents have their local private values, but the weights are known neither by the agents nor by the aggregator; they are generated by a system operator, who wants to keep them private. We give a solution where aggregator obliviousness is achieved, even under collusion between the participants, and we show how to obtain a more efficient communication and computation strategy for multi-dimensional data, by batching the data into fewer ciphertexts. Finally, we implement our schemes and discuss the numerical results and efficiency improvements.      
### 54.ENSURE: Ensemble Stein's Unbiased Risk Estimator for Unsupervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.10631.pdf)
>  Deep learning accelerates the MR image reconstruction process after offline training of a deep neural network from a large volume of clean and fully sampled data. Unfortunately, fully sampled images may not be available or are difficult to acquire in several application areas such as high-resolution imaging. Previous studies have utilized Stein's Unbiased Risk Estimator (SURE) as a mean square error (MSE) estimate for the image denoising problem. Unrolled reconstruction algorithms, where the denoiser at each iteration is trained using SURE, has also been introduced. Unfortunately, the end-to-end training of a network using SURE remains challenging since the projected SURE loss is a poor approximation to the MSE, especially in the heavily undersampled setting. We propose an ENsemble SURE (ENSURE) approach to train a deep network only from undersampled measurements. In particular, we show that training a network using an ensemble of images, each acquired with a different sampling pattern, can closely approximate the MSE. Our preliminary experimental results show that the proposed ENSURE approach gives comparable reconstruction quality to supervised learning and a recent unsupervised learning method.      
### 55.Runtime Safety Assurance Using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.10618.pdf)
>  The airworthiness and safety of a non-pedigreed autopilot must be verified, but the cost to formally do so can be prohibitive. We can bypass formal verification of non-pedigreed components by incorporating Runtime Safety Assurance (RTSA) as mechanism to ensure safety. RTSA consists of a meta-controller that observes the inputs and outputs of a non-pedigreed component and verifies formally specified behavior as the system operates. When the system is triggered, a verified recovery controller is deployed. Recovery controllers are designed to be safe but very likely disruptive to the operational objective of the system, and thus RTSA systems must balance safety and efficiency. The objective of this paper is to design a meta-controller capable of identifying unsafe situations with high accuracy. High dimensional and non-linear dynamics in which modern controllers are deployed along with the black-box nature of the nominal controllers make this a difficult problem. Current approaches rely heavily on domain expertise and human engineering. We frame the design of RTSA with the Markov decision process (MDP) framework and use reinforcement learning (RL) to solve it. Our learned meta-controller consistently exhibits superior performance in our experiments compared to our baseline, human engineered approach.      
### 56.Convolutional 3D to 2D Patch Conversion for Pixel-wise Glioma Segmentation in MRI Scans  [ :arrow_down: ](https://arxiv.org/pdf/2010.10612.pdf)
>  Structural magnetic resonance imaging (MRI) has been widely utilized for analysis and diagnosis of brain diseases. Automatic segmentation of brain tumors is a challenging task for computer-aided diagnosis due to low-tissue contrast in the tumor subregions. To overcome this, we devise a novel pixel-wise segmentation framework through a convolutional 3D to 2D MR patch conversion model to predict class labels of the central pixel in the input sliding patches. Precisely, we first extract 3D patches from each modality to calibrate slices through the squeeze and excitation (SE) block. Then, the output of the SE block is fed directly into subsequent bottleneck layers to reduce the number of channels. Finally, the calibrated 2D slices are concatenated to obtain multimodal features through a 2D convolutional neural network (CNN) for prediction of the central pixel. In our architecture, both local inter-slice and global intra-slice features are jointly exploited to predict class label of the central voxel in a given patch through the 2D CNN classifier. We implicitly apply all modalities through trainable parameters to assign weights to the contributions of each sequence for segmentation. Experimental results on the segmentation of brain tumors in multimodal MRI scans (BraTS'19) demonstrate that our proposed method can efficiently segment the tumor regions.      
### 57.Incandescent Bulb and LED Brake Lights:Novel Analysis of Reaction Times  [ :arrow_down: ](https://arxiv.org/pdf/2010.10584.pdf)
>  Rear-end collision accounts for around 8% of all vehicle crashes in the UK, with the failure to notice or react to a brake light signal being a major contributory cause. Meanwhile traditional incandescent brake light bulbs on vehicles are increasingly being replaced by a profusion of designs featuring LEDs. In this paper, we investigate the efficacy of brake light design using a novel approach to recording subject reaction times in a simulation setting using physical brake light assemblies. The reaction times of 22 subjects were measured for ten pairs of LED and incandescent bulb brake lights. Three events were investigated for each subject, namely the latency of brake light activation to accelerator release (BrakeAcc), the latency of accelerator release to brake pedal depression (AccPdl), and the cumulative time from light activation to brake pedal depression (BrakePdl). To our knowledge, this is the first study in which reaction times have been split into BrakeAcc and AccPdl. Results indicate that the two brake lights containing incandescent bulbs led to significantly slower reaction times compared to the tested eight LED lights. BrakeAcc results also show that experienced subjects were quicker to respond to the activation of brake lights by releasing the accelerator pedal. Interestingly, the analysis also revealed that the type of brake light influenced the AccPdl time, although experienced subjects did not always act quicker than inexperienced subjects. Overall, the study found that different designs of brake light can significantly influence driver response times.      
### 58.Speaker Separation Using Speaker Inventories and Estimated Speech  [ :arrow_down: ](https://arxiv.org/pdf/2010.10556.pdf)
>  We propose speaker separation using speaker inventories and estimated speech (SSUSIES), a framework leveraging speaker profiles and estimated speech for speaker separation. SSUSIES contains two methods, speaker separation using speaker inventories (SSUSI) and speaker separation using estimated speech (SSUES). SSUSI performs speaker separation with the help of speaker inventory. By combining the advantages of permutation invariant training (PIT) and speech extraction, SSUSI significantly outperforms conventional approaches. SSUES is a widely applicable technique that can substantially improve speaker separation performance using the output of first-pass separation. We evaluate the models on both speaker separation and speech recognition metrics.      
### 59.Planning with Learned Dynamics: Guaranteed Safety and Reachability via Lipschitz Constants  [ :arrow_down: ](https://arxiv.org/pdf/2010.08993.pdf)
>  We present an approach for feedback motion planning of systems with unknown dynamics which provides guarantees on safety, reachability, and stability about the goal. Given a learned control-affine approximation of the true dynamics, we estimate the Lipschitz constant of the difference between the true and learned dynamics to determine a trusted domain for our learned model. Provided the system has at least as many controls as states, we further derive the conditions under which a one-step feedback law exists. This allows fora small bound on the tracking error when the trajectory is executed on the real system. Our method imposes a check for the existence of the feedback law as constraints in a sampling-based planner, which returns a feedback policy ensuring that under the true dynamics, the goal is reachable, the path is safe in execution, and the closed-loop system is invariant in a small set about the goal. We demonstrate our approach by planning using learned models of a 6D quadrotor and a 7DOF Kuka arm.We show that a baseline which plans using the same learned dynamics without considering the error bound or the existence of the feedback law can fail to stabilize around the plan and become unsafe.      
### 60.Beamforming Design with Fast Convergence for IRS-Aided Full-Duplex Communication  [ :arrow_down: ](https://arxiv.org/pdf/2008.00448.pdf)
>  We study the beamforming optimization for an intelligent reflecting surface (IRS)-aided full-duplex (FD) communication system in this letter. Specifically, we maximize the sum rate of bi-directional transmissions by jointly optimizing the transmit beamforming and the beamforming of the IRS reflection. A fast converging alternating algorithm is developed to tackle this problem. In each iteration of the proposed algorithm, the solutions to the transmit beamforming and the IRS reflect beamforming are obtained in a semi-closed form and a closed form, respectively. Compared to an existing method based on the Arimoto-Blahut algorithm, the proposed method achieves almost the same performance while enjoying much faster convergence and lower computational complexity.      

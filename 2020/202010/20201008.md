# ArXiv eess --Thu, 8 Oct 2020
### 1.An ADMM-based MIQP platform for the EV aggregation management  [ :arrow_down: ](https://arxiv.org/pdf/2010.03475.pdf)
>  Electric vehicle (EV) aggregation can significantly influence the EVs charging/discharging behavior. In this paper, we use a distributed algorithm based on the alternating direction method of multipliers (ADMM) to coordinate EV charging and discharging procedures for EVs with vehicle-to-grid (V2G) capabilities. The optimization model is formulated as a mixed-integer quadratic programming (MIQP) problem to consider the efficiency of EV batteries and different energy prices in both charging and discharging processes. Numerical tests using real-world data confirms that the implemented method allows obtaining both the electric vehicle aggregator (EVA) and individual EV goals while considering the power grid and each EV constraints. Moreover, we show the significant impact of our model on the final demand profile and computation time.      
### 2.Discriminative Cross-Modal Data Augmentation for Medical Imaging Applications  [ :arrow_down: ](https://arxiv.org/pdf/2010.03468.pdf)
>  While deep learning methods have shown great success in medical image analysis, they require a number of medical images to train. Due to data privacy concerns and unavailability of medical annotators, it is oftentimes very difficult to obtain a lot of labeled medical images for model training. In this paper, we study cross-modality data augmentation to mitigate the data deficiency issue in the medical imaging domain. We propose a discriminative unpaired image-to-image translation model which translates images in source modality into images in target modality where the translation task is conducted jointly with the downstream prediction task and the translation is guided by the prediction. Experiments on two applications demonstrate the effectiveness of our method.      
### 3.Pkwrap: a PyTorch Package for LF-MMI Training of Acoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2010.03466.pdf)
>  We present a simple wrapper that is useful to train acoustic models in PyTorch using Kaldi's LF-MMI training framework. The wrapper, called pkwrap (short form of PyTorch kaldi wrapper), enables the user to utilize the flexibility provided by PyTorch in designing model architectures. It exposes the LF-MMI cost function as an autograd function. Other capabilities of Kaldi have also been ported to PyTorch. This includes the parallel training ability when multi-GPU environments are unavailable and decode with graphs created in Kaldi. The package is available on Github at <a class="link-external link-https" href="https://github.com/idiap/pkwrap" rel="external noopener nofollow">this https URL</a>.      
### 4.3D beamforming and handover analysis for UAV networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.03413.pdf)
>  In future drone applications fast moving unmanned aerial vehicles (UAVs) will need to be connected via a high throughput ultra reliable wireless link. MmWave communication is assumed to be a promising technology for UAV communication, as the narrow beams cause little interference to and from the ground. A challenge for such networks is the beamforming requirement, and the fact that frequent handovers are required as the cells are small. In the UAV communication research community, mobility and especially handovers are often neglected, however when considering beamforming, antenna array sizes start to matter and the effect of azimuth and elevation should be studied, especially their impact on handover rate and outage capacity. This paper aims to fill some of this knowledge gap and to shed some light on the existing problems. This work will analyse the performance of 3D beamforming and handovers for UAV networks through a case study of a realistic 5G deployment using mmWave. We will look at the performance of a UAV flying over a city utilizing a beamformed mmWave link.      
### 5.Memory-efficient GAN-based Domain Translation of High Resolution 3D Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2010.03396.pdf)
>  Generative adversarial networks (GANs) are currently rarely applied on 3D medical images of large size, due to their immense computational demand. The present work proposes a multi-scale patch-based GAN approach for establishing unpaired domain translation by generating 3D medical image volumes of high resolution in a memory-efficient way. The key idea to enable memory-efficient image generation is to first generate a low-resolution version of the image followed by the generation of patches of constant sizes but successively growing resolutions. To avoid patch artifacts and incorporate global information, the patch generation is conditioned on patches from previous resolution scales. Those multi-scale GANs are trained to generate realistically looking images from image sketches in order to perform an unpaired domain translation. This allows to preserve the topology of the test data and generate the appearance of the training domain data. The evaluation of the domain translation scenarios is performed on brain MRIs of size 155x240x240 and thorax CTs of size up to 512x512x512. Compared to common patch-based approaches, the multi-resolution scheme enables better image quality and prevents patch artifacts. Also, it ensures constant GPU memory demand independent from the image size, allowing for the generation of arbitrarily large images.      
### 6.Space-Time Adaptive Detection at Low Sample Support  [ :arrow_down: ](https://arxiv.org/pdf/2010.03388.pdf)
>  An important problem in space-time adaptive detection is the estimation of the large p-by-p interference covariance matrix from training signals. When the number of training signals n is greater than 2p, existing estimators are generally considered to be adequate, as demonstrated by fixed-dimensional asymptotics. But in the low-sample-support regime (n &lt; 2p or even n &lt; p) fixed-dimensional asymptotics are no longer applicable. The remedy undertaken in this paper is to consider the "large dimensional limit" in which n and p go to infinity together. In this asymptotic regime, a new type of estimator is defined (Definition 2), shown to exist (Theorem 1), and shown to be detection-theoretically ideal (Theorem 2). Further, asymptotic conditional detection and false-alarm rates of filters formed from this type of estimator are characterized (Theorems 3 and 4) and shown to depend only on data that is given, even for non-Gaussian interference statistics. The paper concludes with several Monte Carlo simulations that compare the performance of the estimator in Theorem 1 to the predictions of Theorems 2-4, showing in particular higher detection probability than Steiner and Gerlach's Fast Maximum Likelihood estimator.      
### 7.The Environmental Potential of Hyper-Scale Data Centers: Using Locational Marginal CO$_2$ Emissions to Guide Geographical Load Shifting  [ :arrow_down: ](https://arxiv.org/pdf/2010.03379.pdf)
>  Increasing demand for computing has lead to the development of large-scale, highly optimized data centers, which represent large loads in the electric power network. Many major computing and internet companies operate multiple data centers spread geographically across the world. Thus, these companies have a unique ability to shift computing load, and thus electric load, geographically. This paper provides a "bottom-up" load shifting model which uses data centers' geographic load flexibility to lower CO$_2$ emissions. This model utilizes information about the locational marginal CO$_2$ footprint of the electricity at individual nodes, but does not require direct collaboration with the system operator. We demonstrate how to calculate marginal carbon emissions, and assess the efficacy of our approach compared to a setting where the data centers bid their flexibility into a centralized market. We find that data center load shifting can achieve substantial reductions in CO$_2$ emissions even with modest load shifting.      
### 8.Descriptive analysis of computational methods for automating mammograms with practical applications  [ :arrow_down: ](https://arxiv.org/pdf/2010.03378.pdf)
>  Mammography is a vital screening technique for early revealing and identification of breast cancer in order to assist to decrease mortality rate. Practical applications of mammograms are not limited to breast cancer revealing, identification ,but include task based lens design, image compression, image classification, content based image retrieval and a host of others. Mammography computational analysis methods are a useful tool for specialists to reveal hidden features and extract significant information in mammograms. Digital mammograms are mammography images available along with the conventional screen-film mammography to make automation of mammograms easier. In this paper, we descriptively discuss computational advancement in digital mammograms to serve as a compass for research and practice in the domain of computational mammography and related fields. The discussion focuses on research aiming at a variety of applications and automations of mammograms. It covers different perspectives on image pre-processing, feature extraction, application of mammograms, screen-film mammogram, digital mammogram and development of benchmark corpora for experimenting with digital mammograms.      
### 9.Secure 3D medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.03367.pdf)
>  Image segmentation has proved its importance and plays an important role in various domains such as health systems and satellite-oriented military applications. In this context, accuracy, image quality, and execution time deem to be the major issues to always consider. Although many techniques have been applied, and their experimental results have shown appealing achievements for 2D images in real-time environments, however, there is a lack of works about 3D image segmentation despite its importance in improving segmentation accuracy. Specifically, HMM was used in this domain. However, it suffers from the time complexity, which was updated using different accelerators. As it is important to have efficient 3D image segmentation, we propose in this paper a novel system for partitioning the 3D segmentation process across several distributed machines. The concepts behind distributed multi-media network segmentation were employed to accelerate the segmentation computational time of training Hidden Markov Model (HMMs). Furthermore, a secure transmission has been considered in this distributed environment and various bidirectional multimedia security algorithms have been applied. The contribution of this work lies in providing an efficient and secure algorithm for 3D image segmentation. Through a number of extensive experiments, it was proved that our proposed system is of comparable efficiency to the state of art methods in terms of segmentation accuracy, security and execution time.      
### 10.Interpreting Imagined Speech Waves with Machine Learning techniques  [ :arrow_down: ](https://arxiv.org/pdf/2010.03360.pdf)
>  This work explores the possibility of decoding Imagined Speech (IS) signals which can be used to create a new design of Human-Computer Interface (HCI). Since the underlying process generating EEG signals is unknown, various feature extraction methods, along with different neural network (NN) models, are used to approximate data distribution and classify IS signals. Based on the experimental results, feed-forward NN model with ensemble and covariance matrix transformed features showed the highest performance in comparison to other existing methods. For comparison, three publicly available datasets were used. We report a mean classification accuracy of 80% between rest and imagined state, 96% and 80% for decoding long and short words on two datasets. These results show that it is possible to differentiate brain signals (generated during rest state) from the IS brain signals. Based on the experimental results, we suggest that the word length and complexity can be used to decode IS signals with high accuracy, and a BCI system can be designed with IS signals for computer interaction. These ideas, and results give direction for the development of a commercial level IS based BCI system, which can be used for human-computer interaction in daily life.      
### 11.Reconfigurable Intelligent Surfaces and Machine Learning for Wireless Fingerprinting Localization  [ :arrow_down: ](https://arxiv.org/pdf/2010.03251.pdf)
>  Reconfigurable Intelligent Surfaces (RISs) promise improved, secure and more efficient wireless communications. We propose and demonstrate how to exploit the diversity offered by RISs to generate and select easily differentiable radio maps for use in wireless fingerprinting localization applications. Further, we apply machine learning feature selection methods to prune the large state space of the RIS, thus reducing complexity and enhancing localization accuracy and position acquisition time. We evaluate our proposed approach by generation of radio maps with a novel radio propagation modelling and simulations.      
### 12.Deep Learning-Based Grading of Ductal Carcinoma In Situ in Breast Histopathology Images  [ :arrow_down: ](https://arxiv.org/pdf/2010.03244.pdf)
>  Ductal carcinoma in situ (DCIS) is a non-invasive breast cancer that can progress into invasive ductal carcinoma (IDC). Studies suggest DCIS is often overtreated since a considerable part of DCIS lesions may never progress into IDC. Lower grade lesions have a lower progression speed and risk, possibly allowing treatment de-escalation. However, studies show significant inter-observer variation in DCIS grading. Automated image analysis may provide an objective solution to address high subjectivity of DCIS grading by pathologists. <br>In this study, we developed a deep learning-based DCIS grading system. It was developed using the consensus DCIS grade of three expert observers on a dataset of 1186 DCIS lesions from 59 patients. The inter-observer agreement, measured by quadratic weighted Cohen's kappa, was used to evaluate the system and compare its performance to that of expert observers. We present an analysis of the lesion-level and patient-level inter-observer agreement on an independent test set of 1001 lesions from 50 patients. <br>The deep learning system (dl) achieved on average slightly higher inter-observer agreement to the observers (o1, o2 and o3) ($\kappa_{o1,dl}=0.81, \kappa_{o2,dl}=0.53, \kappa_{o3,dl}=0.40$) than the observers amongst each other ($\kappa_{o1,o2}=0.58, \kappa_{o1,o3}=0.50, \kappa_{o2,o3}=0.42$) at the lesion-level. At the patient-level, the deep learning system achieved similar agreement to the observers ($\kappa_{o1,dl}=0.77, \kappa_{o2,dl}=0.75, \kappa_{o3,dl}=0.70$) as the observers amongst each other ($\kappa_{o1,o2}=0.77, \kappa_{o1,o3}=0.75, \kappa_{o2,o3}=0.72$). <br>In conclusion, we developed a deep learning-based DCIS grading system that achieved a performance similar to expert observers. We believe this is the first automated system that could assist pathologists by providing robust and reproducible second opinions on DCIS grade.      
### 13.Index-Modulated Circularly-Shifted Chirps for Dual-Function Radar &amp; Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.03231.pdf)
>  In this study, we analyze index modulation (IM) based on circularly-shifted chirps (CSCs) for dual-function radar &amp; communication (DFRC) systems. We develop a maximum likelihood (ML) range estimator that considers multiple scatters. To improve the correlation properties of the transmitted waveform and estimation accuracy, we propose index separation (IS) which separates the CSCs apart in time. We theoretically show that the separation can be large under certain conditions without losing the spectral efficiency (SE). Our numerical results show that the IS combined ML and linear minimum mean square error (LMMSE)-based estimators can provide approximately 3 dB signal-to-noise ratio (SNR) gain in some cases while improving estimation accuracy substantially without causing any bit-error ratio (BER) degradation at the communication receiver.      
### 14.M3Lung-Sys: A Deep Learning System for Multi-Class Lung Pneumonia Screening from CT Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.03201.pdf)
>  To counter the outbreak of COVID-19, the accurate diagnosis of suspected cases plays a crucial role in timely quarantine, medical treatment, and preventing the spread of the pandemic. Considering the limited training cases and resources (e.g, time and budget), we propose a Multi-task Multi-slice Deep Learning System (M3Lung-Sys) for multi-class lung pneumonia screening from CT imaging, which only consists of two 2D CNN networks, i.e., slice- and patient-level classification networks. The former aims to seek the feature representations from abundant CT slices instead of limited CT volumes, and for the overall pneumonia screening, the latter one could recover the temporal information by feature refinement and aggregation between different slices. In addition to distinguish COVID-19 from Healthy, H1N1, and CAP cases, our M 3 Lung-Sys also be able to locate the areas of relevant lesions, without any pixel-level annotation. To further demonstrate the effectiveness of our model, we conduct extensive experiments on a chest CT imaging dataset with a total of 734 patients (251 healthy people, 245 COVID-19 patients, 105 H1N1 patients, and 133 CAP patients). The quantitative results with plenty of metrics indicate the superiority of our proposed model on both slice- and patient-level classification tasks. More importantly, the generated lesion location maps make our system interpretable and more valuable to clinicians.      
### 15.WDN: A Wide and Deep Network to Divide-and-Conquer Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2010.03199.pdf)
>  Divide and conquer is an established algorithm design paradigm that has proven itself to solve a variety of problems efficiently. However, it is yet to be fully explored in solving problems with a neural network, particularly the problem of image super-resolution. In this work, we propose an approach to divide the problem of image super-resolution into multiple sub-problems and then solve/conquer them with the help of a neural network. Unlike a typical deep neural network, we design an alternate network architecture that is much wider (along with being deeper) than existing networks and is specially designed to implement the divide-and-conquer design paradigm with a neural network. Additionally, a technique to calibrate the intensities of feature map pixels is being introduced. Extensive experimentation on five datasets reveals that our approach towards the problem and the proposed architecture generate better and sharper results than current state-of-the-art methods.      
### 16.Comparison of Cooperative Driving Strategies for CAVs at Signal-Free Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2010.03148.pdf)
>  The properties of cooperative driving strategies for planning and controlling Connected and Automated Vehicles (CAVs) at intersections range from some that achieve highly efficient coordination performance to others whose implementation is computationally fast. This paper comprehensively compares the performance of four representative strategies in terms of travel time, energy consumption, computation time, and fairness under different conditions, including the geometric configuration of intersections, asymmetry in traffic arrival rates, and the relative magnitude of these rates. Our simulation-based study has led to the following conclusions: 1) the Monte Carlo Tree Search (MCTS)-based strategy achieves the best traffic efficiency, whereas the Dynamic Resequencing (DR)-based strategy is energy-optimal; both strategies perform well in all metrics of interest. If the computation budget is adequate, the MCTS strategy is recommended; otherwise, the DR strategy is preferable; 2) An asymmetric intersection has a noticeable impact on the strategies, whereas the influence of the arrival rates can be neglected. When the geometric shape is asymmetrical, the modified First-In-First-Out (FIFO) strategy significantly outperforms the FIFO strategy and works well when the traffic demand is moderate, but their performances are similar in other situations; and 3) Improving traffic efficiency sometimes comes at the cost of fairness, but the DR and MCTS strategies can be adjusted to realize a better trade-off between various performance metrics by appropriately designing their objective functions.      
### 17.Cognitive Learning-Aided Multi-Antenna Communications  [ :arrow_down: ](https://arxiv.org/pdf/2010.03131.pdf)
>  Cognitive communications have emerged as a promising solution to enhance, adapt, and invent new tools and capabilities that transcend conventional wireless networks. Deep learning (DL) is critical in enabling essential features of cognitive systems because of its fast prediction performance, adaptive behavior, and model-free structure. These features are especially significant for multi-antenna wireless communications systems, which generate and handle massive data. Multiple antennas may provide multiplexing, diversity, or antenna gains that, respectively, improve the capacity, bit error rate, or the signal-to-interference-plus-noise ratio. In practice, multi-antenna cognitive communications encounter challenges in terms of data complexity and diversity, hardware complexity, and wireless channel dynamics. The DL-based solutions tackle these problems at the various stages of communications processing such as channel estimation, hybrid beamforming, user localization, and sparse array design. There are research opportunities to address significant design challenges arising from insufficient data coverage, learning model complexity, and data transmission overheads. This article provides synopses of various DL-based methods to impart cognitive behavior to multi-antenna wireless communications.      
### 18.A Fast and Effective Method of Macula Automatic Detection for Retina Images  [ :arrow_down: ](https://arxiv.org/pdf/2010.03122.pdf)
>  Retina image processing is one of the crucial and popular topics of medical image processing. The macula fovea is responsible for sharp central vision, which is necessary for human behaviors where visual detail is of primary importance, such as reading, writing, driving, etc. This paper proposes a novel method to locate the macula through a series of morphological processing. On the premise of maintaining high accuracy, our approach is simpler and faster than others. Furthermore, for the hospital's real images, our method is also able to detect the macula robustly.      
### 19.Calibrating microscopic car following models for adaptive cruise control vehicles: a multi-objective approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.03109.pdf)
>  Adaptive cruise control (ACC) vehicles are the first step toward comprehensive vehicle automation. However, the impacts of such vehicles on the underlying traffic flow are not yet clear. Therefore, it is of interest to accurately model vehicle-level dynamics of commercially available ACC vehicles so that they may be used in further modeling efforts to quantify the impact of commercially available ACC vehicles on traffic flow. Importantly, not only model selection but also the calibration approach and error metric used for calibration are critical to accurately model ACC vehicle behavior. In this work, we explore the question of how to calibrate car following models to describe ACC vehicle dynamics. Specifically, we apply a multi-objective calibration approach to understand the tradeoff between calibrating model parameters to minimize speed error vs. spacing error. Three different car-following models are calibrated for data from six vehicles. The results are in line with recent literature and verify that targeting a low spacing error does not compromise the speed accuracy whether the opposite is not true for modeling ACC vehicle dynamics.      
### 20.Free Space Optics for Next-Generation Satellite Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.03098.pdf)
>  Free space optics (FSO) refers to optical wireless communications in outdoor environments. The aim of this paper is to analyze the role that FSO is envisaged to play in the creation of next-generation satellite networks. To begin with, the reader is introduced to the types of FSO links and functionalities of a basic FSO system. Next, a comparison of FSO and radio frequency (RF) technologies for inter-satellite links (ISLs) is provided, including a comparison between FSO and RF links when employed between low Earth orbit satellites. After that, the types of FSO or laser ISLs are considered, and the challenges in establishing laser ISLs, the properties of laser ISLs, and the capabilities of terminals for laser ISLs are discussed. Then, the parameters of a satellite constellation are highlighted, and different aspects of SpaceX's upcoming mega-constellation Starlink are explored. In addition, the optical wireless satellite network that is created by utilizing laser ISLs is examined. Finally, a use case is investigated for next-generation optical wireless satellite networks that are envisioned by the mid to late 2020s.      
### 21.Clustering-based Joint Channel Estimation and Signal Detection for Grant-free NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2010.03091.pdf)
>  We propose a joint channel estimation and signal detection technique for the uplink non-orthogonal multiple access using an unsupervised clustering approach. We apply the Gaussian mixture model to cluster received signals and accordingly optimize the decision regions to enhance the symbol error rate (SER). We show that when the received powers of the users are sufficiently different, the proposed clustering-based approach with no channel state information (CSI) at the receiver achieves an SER performance similar to that of the conventional maximum likelihood detector with full CSI. Since the accuracy of the utilized clustering algorithm depends on the number of the data points available at the receiver, the proposed technique delivers a tradeoff between the accuracy and block length.      
### 22.Optimal and resilient coordination of virtual batteries in distribution feeders  [ :arrow_down: ](https://arxiv.org/pdf/2010.03063.pdf)
>  This paper presents a novel hierarchical framework for real-time, network-admissible coordination of responsive grid resources aggregated into virtual batteries (VBs). In this context, a VB represents a local aggregation of directly controlled loads, such as smart inverters, electric water heaters, and air-conditioners. The coordination is achieved by solving an optimization problem to disaggregate a feeder's desired reference trajectory into constraint-aware set-points for the VBs. Specifically, a novel, provably-tight, convex relaxation of the AC optimal power flow (OPF) problem is presented to optimally dispatch the VBs to track the feeder's desired power trajectory. In addition to the optimal VB dispatch scheme, a real-time, corrective control scheme is designed, which is based on optimal proportional-integral (PI) control with anti-windup, to reject intra-feeder and inter-feeder disturbances that arise during operation of the power system. Simulation results conducted on a modified IEEE test system demonstrate the effectiveness of the proposed multi-layer VB coordination framework.      
### 23.Digital Voicing of Silent Speech  [ :arrow_down: ](https://arxiv.org/pdf/2010.02960.pdf)
>  In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography (EMG) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from EMG collected during vocalized speech, we are the first to train from EMG collected during silently articulated speech. We introduce a method of training on silent EMG by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent EMG compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64% to 4% in one data condition and 88% to 68% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial EMG measurements.      
### 24.BoMuDA: Boundless Multi-Source Domain Adaptive Segmentation in Unconstrained Environments  [ :arrow_down: ](https://arxiv.org/pdf/2010.03523.pdf)
>  We present an unsupervised multi-source domain adaptive semantic segmentation approach in unstructured and unconstrained traffic environments. We propose a novel training strategy that alternates between single-source domain adaptation (DA) and multi-source distillation, and also between setting up an improvised cost function and optimizing it. In each iteration, the single-source DA first learns a neural network on a selected source, which is followed by a multi-source fine-tuning step using the remaining sources. We call this training routine the Alternating-Incremental ("Alt-Inc") algorithm. Furthermore, our approach is also boundless i.e. it can explicitly classify categories that do not belong to the training dataset (as opposed to labeling such objects as "unknown"). We have conducted extensive experiments and ablation studies using the Indian Driving Dataset, CityScapes, Berkeley DeepDrive, GTA V, and the Synscapes datasets, and we show that our unsupervised approach outperforms other unsupervised and semi-supervised SOTA benchmarks by 5.17% - 42.9% with a reduced model size by up to 5.2x.      
### 25.A signal detection model for quantifying over-regularization in non-linear image reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2010.03472.pdf)
>  Purpose: Many useful image quality metrics for evaluating linear image reconstruction techniques do not apply to or are difficult to interpret for non-linear image reconstruction. The vast majority of metrics employed for evaluating non-linear image reconstruction are based on some form of global image fidelity, such as image root mean square error (RMSE). Use of such metrics can lead to over-regularization in the sense that they can favor removal of subtle details in the image. To address this shortcoming, we develop an image quality metric based on signal detection that serves as a surrogate to the qualitative loss of fine image details. Methods: The metric is demonstrated in the context of a breast CT simulation, where different equal-dose configurations are considered. The configurations differ in the number of projections acquired. Image reconstruction is performed with a non-linear algorithm based on total variation constrained least-squares (TV-LSQ). The images are evaluated visually, with image RMSE, and with the proposed signal-detection based metric. The latter uses a small signal, and computes detectability in the sinogram and in the reconstructed image. Loss of signal detectability through the image reconstruction process is taken as a quantitative measure of loss of fine details in the image. Results: Loss of signal detectability is seen to correlate well with the blocky or patchy appearance due to over-regularization with TV-LSQ, and this trend runs counter to the image RMSE metric, which tends to favor the over-regularized images. Conclusions: The proposed signal detection based metric provides an image quality assessment that is complimentary to that of image RMSE. Using the two metrics in concert may yield a useful prescription for determining CT algorithm and configuration parameters when non-linear image reconstruction is used.      
### 26.WER we are and WER we think we are  [ :arrow_down: ](https://arxiv.org/pdf/2010.03432.pdf)
>  Natural language processing of conversational speech requires the availability of high-quality transcripts. In this paper, we express our skepticism towards the recent reports of very low Word Error Rates (WERs) achieved by modern Automatic Speech Recognition (ASR) systems on benchmark datasets. We outline several problems with popular benchmarks and compare three state-of-the-art commercial ASR systems on an internal dataset of real-life spontaneous human conversations and HUB'05 public benchmark. We show that WERs are significantly higher than the best reported results. We formulate a set of guidelines which may aid in the creation of real-life, multi-domain datasets with high quality annotations for training and testing of robust ASR systems.      
### 27.Solvability of the Power Flow Problem in DC Overhead Wire Circuit  [ :arrow_down: ](https://arxiv.org/pdf/2010.03430.pdf)
>  Proper traffic simulation of electric vehicles, which draw energy from overhead wires, requires adequate modeling of traction infrastructure. Such vehicles include trains, trams or trolleybuses. Since the requested power demands depend on a traffic situation, the overhead wire DC electrical circuit is associated with a non-linear power flow problem. Although the Newton-Raphson method is well-known and widely accepted for seeking its solution, the existence of such a solution is not guaranteed. Particularly in situations where the vehicle power demands are too high (during acceleration), the solution of the studied problem may not exist. To deal with such cases, we introduce a numerical method which seeks maximal suppliable power demands for which the solution exists. This corresponds to introducing a scaling parameter to reduce the demanded power. The interpretation of the scaling parameter is the amount of energy which is absent in the system, and which needs to be provided by external sources such as on-board batteries. We propose an efficient two-stage algorithm to find the optimal scaling parameter and the resulting potentials in the overhead wire network. We perform a comparison with a naive approach and present a real-world simulation of part of the Pilsen city in the Czech Republic. These simulations are performed in the traffic micro-simulator SUMO, a popular open-source traffic simulation platform.      
### 28.A study on using image based machine learning methods to develop the surrogate models of stamp forming simulations  [ :arrow_down: ](https://arxiv.org/pdf/2010.03370.pdf)
>  In the design optimization of metal forming, it is increasingly significant to use surrogate models to analyse the finite element analysis (FEA) simulations. However, traditional surrogate models using scalar based machine learning methods (SBMLMs) fall in short of accuracy and generalizability. This is because SBMLMs fail to harness the location information of the simulations. To overcome these shortcomings, image based machine learning methods (IBMLMs) are leveraged in this paper. The underlying theory of location information, which supports the advantages of IBMLM, is qualitatively interpreted. Based on this theory, a Res-SE-U-Net IBMLM surrogate model is developed and compared with a multi-layer perceptron (MLP) as a referencing SBMLM surrogate model. It is demonstrated that the IBMLM model is advantageous over the MLP SBMLM model in accuracy, generalizability, robustness, and informativeness. This paper presents a promising methodology of leveraging IBMLMs in surrogate models to make maximum use of info from FEA results. Future prospective studies that inspired by this paper are also discussed.      
### 29.Controlling a CyberOctopus Soft Arm with Muscle-like Actuation  [ :arrow_down: ](https://arxiv.org/pdf/2010.03368.pdf)
>  This paper entails the application of the energy shaping methodology to control a flexible, elastic Cosserat rod model of a single octopus arm. The principal focus and novel contribution of this work is two-fold: (i) reduced order control oriented modeling of the realistic internal muscular architecture in an octopus arm; and (ii) incorporation of such models into the energy shaping methodology, extending our prior work by formally accounting for muscle constraints. Extension of the control scheme to the under-actuated muscle control case involves two steps: (i) design of a desired potential energy function whose static minimizer solves a given control task; and (ii) implementing the resulting energy shaping control input into the dynamic model. Due to the muscle actuator constraints, the desired potential energy function may not be arbitrarily chosen. Indeed, the desired energy must now satisfy a partial differential equation, known as the matching condition, which is derived for the infinite dimensional Hamiltonian control system. A particular solution to those matching conditions is described, paving the way to the application of energy shaping methodology. The overall control design methodology including muscle models is implemented and demonstrated in a dynamic simulation environment. Results of several bio-inspired numerical experiments involving the control of octopus arms are reported.      
### 30.A Study on the Splitting Strategy of Server Resources  [ :arrow_down: ](https://arxiv.org/pdf/2010.03346.pdf)
>  The paper is based on Noar's model of charged queues. We extend this model into multi-server systems with information about length and service rate disclosed for all the customers, and the customers can choose the optimal options. We discuss whether the splitting strategy of the server resource could bring more revenue for the service provider. We prove that any G/D/1 server supplier cannot earn more revenue by splitting his resource under the equal-toll limitations.      
### 31.Optimizing illumination for precise multi-parameter estimations in coherent diffractive imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.03306.pdf)
>  Coherent diffractive imaging (CDI) is widely used to characterize structured samples from measurements of diffracting intensity patterns. We introduce a numerical framework to quantify the precision that can be achieved when estimating any given set of parameters characterizing the sample from measured data. The approach, based on the calculation of the Fisher information matrix, provides a clear benchmark to assess the performance of CDI methods. Moreover, by optimizing the Fisher information metric using deep learning optimization libraries, we demonstrate how to identify the optimal illumination scheme that minimize the estimation error under specified experimental constrains. This work paves the way for an efficient characterization of structured samples at the sub-wavelength scale.      
### 32.Search-free DOA Estimation Method Based on Tensor Decomposition and Polynomial Rooting for Transmit Beamspace MIMO Radar  [ :arrow_down: ](https://arxiv.org/pdf/2010.03296.pdf)
>  In order to improve the accuracy and resolution for transmit beamspace multiple-input multiple-output (MIMO) radar, a search-free direction-of-arrival (DOA) estimation method based on tensor decomposition and polynomial rooting is proposed. In the proposed method, a 3-order tensor is firstly designed to model the received signal of MIMO radar on the basis of the multi-linear property. Then, the factor matrix with target DOA information is obtained by the tensor decomposition via alternating least squares (ALS) algorithm, and subsequently the DOA estimation is converted into independent minimization problem. In the following, a polynomial function is constructed by exploiting the Vandermonde structure of the transmit steering vector of MIMO radar. The factor matrix contained in the polynomial can be regarded as a block matrix in the generalized sidelobe canceller (GSC), which accordingly forms a unique deep null in the direction of target in the transmit beampattern. The proposed method can obtain the DOA estimation without the requirements of spectrum searching or transmit beamspace matrix design, which is different from the conventional DOA estimation techniques. The effectiveness and performance of proposed method is verified by the simulations.      
### 33.Less is more: Faster and better music version identification with embedding distillation  [ :arrow_down: ](https://arxiv.org/pdf/2010.03284.pdf)
>  Version identification systems aim to detect different renditions of the same underlying musical composition (loosely called cover songs). By learning to encode entire recordings into plain vector embeddings, recent systems have made significant progress in bridging the gap between accuracy and scalability, which has been a key challenge for nearly two decades. In this work, we propose to further narrow this gap by employing a set of data distillation techniques that reduce the embedding dimensionality of a pre-trained state-of-the-art model. We compare a wide range of techniques and propose new ones, from classical dimensionality reduction to more sophisticated distillation schemes. With those, we obtain 99% smaller embeddings that, moreover, yield up to a 3% accuracy increase. Such small embeddings can have an important impact in retrieval time, up to the point of making a real-world system practical on a standalone laptop.      
### 34.A Novel Face-tracking Mouth Controller and its Application to Interacting with Bioacoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2010.03265.pdf)
>  We describe a simple, computationally light, real-time system for tracking the lower face and extracting information about the shape of the open mouth from a video sequence. The system allows unencumbered control of audio synthesis modules by the action of the mouth. We report work in progress to use the mouth controller to interact with a physical model of sound production by the avian syrinx.      
### 35.Sonification of Facial Actions for Musical Expression  [ :arrow_down: ](https://arxiv.org/pdf/2010.03223.pdf)
>  The central role of the face in social interaction and non-verbal communication suggests we explore facial action as a means of musical expression. This paper presents the design, implementation, and preliminary studies of a novel system utilizing face detection and optic flow algorithms to associate facial movements with sound synthesis in a topographically specific fashion. We report on our experience with various gesture-to-sound mappings and applications, and describe our preliminary experiments at musical performance using the system.      
### 36.Modeling and analysis of driver behavior under shared control through weighted visual and haptic guidance  [ :arrow_down: ](https://arxiv.org/pdf/2010.03216.pdf)
>  For the optimum design of a driver-automation shared control system, an understanding of driver behavior based on measurements and modeling is crucial early in the development process. This paper presents a driver model through a weighting process of visual guidance from the road ahead and haptic guidance from a steering system for a lane-following task. The proposed weighting process describes the interaction of a driver with the haptic guidance steering and the driver reliance on it. A driving simulator experiment is conducted to identify the model parameters for driving manually and with haptic guidance. The proposed driver model matched the driver input torque with a satisfactory goodness of fit among fourteen participants after considering the individual differences. The validation results reveal that the simulated trajectory effectively followed the driving course by matching the measured trajectory, thereby indicating that the proposed driver model is capable of predicting driver behavior during haptic guidance. Furthermore, the effect of different degrees of driver reliance on driving performance is evaluated considering various driver states and with system failure via numerical analysis. The model evaluation results reveal the potential of the proposed driver model to be applied in the design and evaluation of a haptic guidance system.      
### 37.Designing, Playing, and Performing with a Vision-based Mouth Interface  [ :arrow_down: ](https://arxiv.org/pdf/2010.03213.pdf)
>  The role of the face and mouth in speech production as well asnon-verbal communication suggests the use of facial action tocontrol musical sound. Here we document work on theMouthesizer, a system which uses a headworn miniaturecamera and computer vision algorithm to extract shapeparameters from the mouth opening and output these as MIDIcontrol changes. We report our experience with variousgesture-to-sound mappings and musical applications, anddescribe a live performance which used the Mouthesizerinterface.      
### 38.Cardiac Arrhythmia Detection from ECG with Convolutional Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.03204.pdf)
>  Except for a few specific types, cardiac arrhythmias are not immediately life-threatening. However, if not treated appropriately, they can cause serious complications. In particular, atrial fibrillation, which is characterized by fast and irregular heart beats, increases the risk of stroke. We propose three neural network architectures to detect abnormal rhythms from single-lead ECG signals. These architectures combine convolutional layers to extract high-level features pertinent for arrhythmia detection from sliding windows and recurrent layers to aggregate these features over signals of varying durations. We applied the neural networks to the dataset used for the challenge of Computing in Cardiology 2017 and a dataset built by joining three databases available on PhysioNet. Our architectures achieved an accuracy of 86.23% on the first dataset, similar to the winning entries of the challenge, and an accuracy of 92.02% on the second dataset.      
### 39.Transformer Transducer: One Model Unifying Streaming and Non-streaming Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.03192.pdf)
>  In this paper we present a Transformer-Transducer model architecture and a training technique to unify streaming and non-streaming speech recognition models into one model. The model is composed of a stack of transformer layers for audio encoding with no lookahead or right context and an additional stack of transformer layers on top trained with variable right context. In inference time, the context length for the variable context layers can be changed to trade off the latency and the accuracy of the model. We also show that we can run this model in a Y-model architecture with the top layers running in parallel in low latency and high latency modes. This allows us to have streaming speech recognition results with limited latency and delayed speech recognition results with large improvements in accuracy (20% relative improvement for voice-search task). We show that with limited right context (1-2 seconds of audio) and small additional latency (50-100 milliseconds) at the end of decoding, we can achieve similar accuracy with models using unlimited audio right context. We also present optimizations for audio and label encoders to speed up the inference in streaming and non-streaming speech decoding.      
### 40.Generative Melody Composition with Human-in-the-Loop Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.03190.pdf)
>  Deep generative models allow even novice composers to generate various melodies by sampling latent vectors. However, finding the desired melody is challenging since the latent space is unintuitive and high-dimensional. In this work, we present an interactive system that supports generative melody composition with human-in-the-loop Bayesian optimization (BO). This system takes a mixed-initiative approach; the system generates candidate melodies to evaluate, and the user evaluates them and provides preferential feedback (i.e., picking the best melody among the candidates) to the system. This process is iteratively performed based on BO techniques until the user finds the desired melody. We conducted a pilot study using our prototype system, suggesting the potential of this approach.      
### 41.A Study on Trees's Knots Prediction from their Bark Outer-Shape  [ :arrow_down: ](https://arxiv.org/pdf/2010.03173.pdf)
>  In the industry, the value of wood-logs strongly depends on their internal structure and more specifically on the knots' distribution inside the trees. As of today, CT-scanners are the prevalent tool to acquire accurate images of the trees internal structure. However, CT-scanners are expensive, and slow, making their use impractical for most industrial applications. Knowing where the knots are within a tree could improve the efficiency of the overall tree industry by reducing waste and improving the quality of wood-logs by-products. In this paper we evaluate different deep-learning based architectures to predict the internal knots distribution of a tree from its outer-shape, something that has never been done before. Three types of techniques based on Convolutional Neural Networks (CNN) will be studied. <br>The architectures are tested on both real and synthetic CT-scanned trees. With these experiments, we demonstrate that CNNs can be used to predict internal knots distribution based on the external surface of the trees. The goal being to show that these inexpensive and fast methods could be used to replace the CT-scanners. <br>Additionally, we look into the performance of several off-the-shelf object-detectors to detect knots inside CT-scanned images. This method is used to autonomously label part of our real CT-scanned trees alleviating the need to manually segment the whole of the images.      
### 42.Adversarial attacks on audio source separation  [ :arrow_down: ](https://arxiv.org/pdf/2010.03164.pdf)
>  Despite the excellent performance of neural-network-based audio source separation methods and a wide range of applications, their robustness against intentional attacks has been largely neglected. In this work we reformulate a variety of adversarial-attack methods for the audio source separation problem and intensively investigate them under different attack conditions and target models. We further propose a simple yet effective regularization method to obtain imperceptible adversarial noise while maximizing the impact on separation quality with a low computational complexity. Experimental results show that it is possible to largely degrade the separation quality by adding imperceptibly small noise when the noise is crafted for the target model. We also show the robustness of source separation models against a black-box attack. This study provides potentially useful insights for developing content protection methods against the abuse of separated signals and improving the separation performance and robustness.      
### 43.Improving the efficiency of spectral features extraction by structuring the audio files  [ :arrow_down: ](https://arxiv.org/pdf/2010.03136.pdf)
>  The extraction of spectral features from a music clip is a computationally expensive task. As in order to extract accurate features, we need to process the clip for its whole length. This preprocessing task creates a large overhead and also makes the extraction process slower. We show how formatting a dataset in a certain way, can help make the process more efficient by eliminating the need for processing the clip for its whole duration, and still extract the features accurately. In addition, we discuss the possibility of defining set generic durations for analyzing a certain type of music clip while training. And in doing so we cut down the need of processing the clip duration to just 10% of the global average.      
### 44.A Matrix-Valued Inner Product for Matrix-Valued Signals  [ :arrow_down: ](https://arxiv.org/pdf/2010.03075.pdf)
>  A matrix-valued inner product was proposed before to construct orthonormal matrix-valued wavelets for matrix-valued signals. It introduces a weaker orthogonality for matrix-valued signals than the orthogonality of all components in a matrix that is commonly used in orthogonal multiwavelet constructions. With the weaker orthogonality, it is easier to construct orthonormal matrix-valued wavelets. In this paper, we re-study the matrix-valued inner product more from the inner product viewpoint that is more fundamental and propose a new but equivalent norm for matrix-valued signals. We show that although it is not scalar-valued, it maintains most of the scalar-valued inner product properties. We introduce a new linear independence concept for matrix-valued signals and present some related properties. We then present the Gram-Schmidt orthonormalization procedure for a set of linearly independent matrix-valued signals.      
### 45.The Distribution of the Number of Real Solutions to the Power Flow Equations  [ :arrow_down: ](https://arxiv.org/pdf/2010.03069.pdf)
>  In this paper we study the distributions of the number of real solutions to the power flow equations over varying electrical parameters. We introduce a new monodromy and parameter homotopy continuation method for quickly finding all solutions to the power flow equations. We apply this method to find distributions of the number of real solutions to the power flow equations and compare these distributions to those of random polynomials. It is observed that while the power flow equations tend to admit many fewer real-valued solutions than a bound on the total number of complex solutions, for low levels of load they tend to admit many more than a corresponding random polynomial. We show that for cycle graphs the number of real solutions can achieve the maximum bound for specific parameter values and for complete graphs with four or more vertices there are susceptance values that give infinitely many real solutions.      
### 46.Weakly-Supervised Feature Learning via Text and Image Matching  [ :arrow_down: ](https://arxiv.org/pdf/2010.03060.pdf)
>  When training deep neural networks for medical image classification, obtaining a sufficient number of manually annotated images is often a significant challenge. We propose to use textual findings, which are routinely written by clinicians during manual image analysis, to help overcome this problem. The key idea is to use a contrastive loss to train image and text feature extractors to recognize if a given image-finding pair is a true match. The learned image feature extractor is then fine-tuned, in a transfer learning setting, for a supervised classification task. This approach makes it possible to train using large datasets because pairs of images and textual findings are widely available in medical records. We evaluate our method on three datasets and find consistent performance improvements. The biggest gains are realized when fewer manually labeled examples are available. In some cases, our method achieves the same performance as the baseline even when using 70\%--98\% fewer labeled examples.      
### 47.A deep learning pipeline for identification of motor units in musculoskeletal ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2010.03028.pdf)
>  Ultrasound imaging provides information from a large part of the muscle. It has recently been shown that ultrafast ultrasound imaging can be used to record and analyze the mechanical response of individual MUs using blind source separation. In this work, we present an alternative method - a deep learning pipeline - to identify active MUs in ultrasound image sequences, including segmentation of their territories and signal estimation of their mechanical responses (twitch train). We train and evaluate the model using simulated data mimicking the complex activation pattern of tens of activated MUs with overlapping territories and partially synchronized activation patterns. Using a slow fusion approach (based on 3D CNNs), we transform the spatiotemporal image sequence data to 2D representations and apply a deep neural network architecture for segmentation. Next, we employ a second deep neural network architecture for signal estimation. The results show that the proposed pipeline can effectively identify individual MUs, estimate their territories, and estimate their twitch train signal at low contraction forces. The framework can retain spatio-temporal consistencies and information of the mechanical response of MU activity even when the ultrasound image sequences are transformed into a 2D representation for compatibility with more traditional computer vision and image processing techniques. The proposed pipeline is potentially useful to identify simultaneously active MUs in whole muscles in ultrasound image sequences of voluntary skeletal muscle contractions at low force levels.      
### 48.Optimizing Deep Neural Networks via Discretization of Finite-Time Convergent Flows  [ :arrow_down: ](https://arxiv.org/pdf/2010.02990.pdf)
>  In this paper, we investigate in the context of deep neural networks, the performance of several discretization algorithms for two first-order finite-time optimization flows. These flows are, namely, the rescaled-gradient flow (RGF) and the signed-gradient flow (SGF), and consist of non-Lipscthiz or discontinuous dynamical systems that converge locally in finite time to the minima of gradient-dominated functions. We introduce three discretization methods for these first-order finite-time flows, and provide convergence guarantees. We then apply the proposed algorithms in training neural networks and empirically test their performances on three standard datasets, namely, CIFAR10, SVHN, and MNIST. Our results show that our schemes demonstrate faster convergences against standard optimization alternatives, while achieving equivalent or better accuracy.      
### 49.VoiceGrad: Non-Parallel Any-to-Many Voice Conversion with Annealed Langevin Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2010.02977.pdf)
>  In this paper, we propose a non-parallel any-to-many voice conversion (VC) method termed VoiceGrad. Inspired by WaveGrad, a recently introduced novel waveform generation method, VoiceGrad is based upon the concepts of score matching and Langevin dynamics. It uses weighted denoising score matching to train a score approximator, a fully convolutional network with a U-Net structure designed to predict the gradient of the log density of the speech feature sequences of multiple speakers, and performs VC by using annealed Langevin dynamics to iteratively update an input feature sequence towards the nearest stationary point of the target distribution based on the trained score approximator network. Thanks to the nature of this concept, VoiceGrad enables any-to-many VC, a VC scenario in which the speaker of input speech can be arbitrary, and allows for non-parallel training, which requires no parallel utterances or transcriptions.      
### 50.Single Shot Diffractive Imaging with Randomized Illumination  [ :arrow_down: ](https://arxiv.org/pdf/2010.02948.pdf)
>  We introduce a single-frame diffractive imaging method called Randomized Probe Imaging (RPI). In RPI, a sample is illuminated by a structured probe field containing speckles smaller than the sample's typical feature size. Quantitative amplitude and phase images are then reconstructed from the resulting far-field diffraction pattern. The experimental geometry of RPI is straightforward to implement, requires no near-field optics, and is applicable to extended samples. When the resulting data are analyzed with a complimentary algorithm, reliable reconstructions which are robust to missing data are achieved. To realize these benefits, a resolution limit associated with the numerical aperture of the probe-forming optics is imposed. RPI therefore offers an attractive modality for quantitative X-ray phase imaging when temporal resolution and reliability are critical but spatial resolution in the tens of nanometers is sufficient. We discuss the method, introduce a reconstruction algorithm, and present two proof-of-concept experiments: one using visible light, and one using soft X-rays.      

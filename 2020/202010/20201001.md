# ArXiv eess --Thu, 1 Oct 2020
### 1.TorchRadon: Fast Differentiable Routines for Computed Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2009.14788.pdf)
>  This work presents TorchRadon -- an open source CUDA library which contains a set of differentiable routines for solving computed tomography (CT) reconstruction problems. The library is designed to help researchers working on CT problems to combine deep learning and model-based approaches. The package is developed as a PyTorch extension and can be seamlessly integrated into existing deep learning training code. Compared to the existing Astra Toolbox, TorchRadon is up to 125 faster. The operators implemented by TorchRadon allow the computation of gradients using PyTorch backward(), and can therefore be easily inserted inside existing neural networks architectures. Because of its speed and GPU support, TorchRadon can also be effectively used as a fast backend for the implementation of iterative algorithms. This paper presents the main functionalities of the library, compares results with existing libraries and provides examples of usage.      
### 2.Cooperative Path Integral Control for Stochastic Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.14775.pdf)
>  A distributed stochastic optimal control solution is presented for cooperative multi-agent systems. The network of agents is partitioned into multiple factorial subsystems, each of which consists of a central agent and neighboring agents. Local control actions that rely only on agents' local observations are designed to optimize the joint cost functions of subsystems. When solving for the local control actions, the joint optimality equation for each subsystem is cast as a linear partial differential equation and solved using the Feynman-Kac formula. The solution and the optimal control action are then formulated as path integrals and approximated by a Monte-Carlo method. Numerical verification is provided through a simulation example consisting of a team of cooperative UAVs.      
### 3.A Plausibility-based Fault Detection Method for High-level Fusion Perception Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.14756.pdf)
>  Trustworthy environment perception is the fundamental basis for the safe deployment of automated agents such as self-driving vehicles or intelligent robots. The problem remains that such trust is notoriously difficult to guarantee in the presence of systematic faults, e.g. non-traceable errors caused by machine learning functions. One way to tackle this issue without making rather specific assumptions about the perception process is plausibility checking. Similar to the reasoning of human intuition, the final outcome of a complex black-box procedure is verified against given expectations of an object's behavior. In this article, we apply and evaluate collaborative, sensor-generic plausibility checking as a mean to detect empirical perception faults from their statistical fingerprints. Our real use case is next-generation automated driving that uses a roadside sensor infrastructure for perception augmentation, represented here by test scenarios at a German highway and a city intersection. The plausibilization analysis is integrated naturally in the object fusion process, and helps to diagnose known and possibly yet unknown faults in distributed sensing systems.      
### 4.Enhanced Standard Compatible Image Compression Framework based on Auxiliary Codec Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.14754.pdf)
>  To enhance image compression performance, recent deep neural network-based research can be divided into three categories: a learnable codec, a postprocessing network, and a compact representation network. The learnable codec has been designed for an end-to-end learning beyond the conventional compression modules. The postprocessing network increases the quality of decoded images using an example-based learning. The compact representation network is learned to reduce the capacity of an input image to reduce the bitrate while keeping the quality of the decoded image. However, these approaches are not compatible with the existing codecs or not optimal to increase the coding efficiency. Specifically, it is difficult to achieve optimal learning in the previous studies using the compact representation network, due to the inaccurate consideration of the codecs. In this paper, we propose a novel standard compatible image compression framework based on Auxiliary Codec Networks (ACNs). ACNs are designed to imitate image degradation operations of the existing codec, which delivers more accurate gradients to the compact representation network. Therefore, the compact representation and the postprocessing networks can be learned effectively and optimally. We demonstrate that our proposed framework based on JPEG and High Efficiency Video Coding (HEVC) standard substantially outperforms existing image compression algorithms in a standard compatible manner.      
### 5.Terminal-Angle-Constrained Guidance based on Sliding Mode Control for UAV Soft Landing on Ground Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2009.14748.pdf)
>  In this paper the problem of guidance formulation for autonomous soft landing of unmanned aerial vehicles on stationary, moving, or accelerating / maneuvering ground vehicles at desired approach angles in both azimuth and elevation is considered. Nonlinear engagement kinematics have been used. While integrated nonlinear controllers have been developed in the literature for this purpose, in practical implementations the controller inputs often need modification of the existing autopilot structure, which is challenging. In order to avoid that a higher-level guidance algorithm is designed in this paper leveraging sliding mode control-based approach. In the presented guidance formulation, target-state-dependent singularity can be avoided in the guidance command. The effectiveness of the presented guidance law is verified with numerical simulation studies. However, since the algorithm in its basic form is found to demand high guidance command at large distances from maneuvering ground targets, a two-phase guidance is presented next to avoid this problem and validated with numerical simulations. Finally, the efficacy of the modified guidance algorithm is validated by Software-In-The-Loop simulations for a realistic testbed.      
### 6.EMR: A New Metric to Assess the Resilience of Directional mmWave Channels to Blockages  [ :arrow_down: ](https://arxiv.org/pdf/2009.14724.pdf)
>  Millimeter-wave (mmWave) communication systems require narrow beams to increase communication range. If the dominant communication direction is blocked by an obstacle, an alternative and reliable spatial communication path should be quickly identified to maintain connectivity. In this paper, we introduce a new metric to quantify the effective multipath richness (EMR) of a directional communication channel by considering the strength and spatial diversity of the resolved paths, while also taking into account beamwidth and blockage characteristics. The metric is defined as a weighted sum of the number of multipath component (MPC) clusters, where clustering is performed based on the cosine-distance between the MPCs that have power above a certain threshold. This process returns a single scalar value for a transmitter (TX)/receiver (RX) location pair in a given environment. It is also possible to represent the EMR of the whole environment with a probability distribution function of the metric by considering a set of TX/RX locations. Using this proposed metric, one can assess the scattering richness of different communication environments to achieve a particular quality of service (QoS). This metric is especially informative and useful at higher frequencies, such as mmWave and terahertz (THz), where the propagation path loss and penetration loss are high, and directional non-light-of-sight (NLOS) communication is critical for the success of the network. We evaluate the proposed metric using our channel measurements at 28 GHz in a large indoor environment at a library setting for LOS and NLOS scenarios.      
### 7.AutoBCS: Block-based Image Compressive Sensing with Data-driven Acquisition and Non-iterative Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2009.14706.pdf)
>  Block compressive sensing is a well-known signal acquisition and reconstruction paradigm with widespread application prospect of science, engineering and cybernetic systems. However, the state-of-the-art block-based image compressive sensing (BCS) generally suffer from two issues. The sparsifying domain and the sensing matrices widely used for image acquisition are not data-driven, thus ignoring both the features of the image and the relationship among sub-block images. Moreover, it requires to address high-dimensional optimization problem with extensive computational complexity for image reconstruction. In this paper, we provide a deep learning strategy for BCS, called AutoBCS, which takes into account the prior knowledge of image in the acquisition step and establishes a subsequent reconstruction model to obtain fast image reconstruction with low computational cost. More precisely, we present a learning-based sensing matrix (LSM) from training data so as to accomplish image acquisition, therefore capturing and preserving more image characteristics. In particular, the generated LSM is proved to satisfy the theoretical requirements, such as the so-called restricted isometry property. Additionally, we build a non-iterative reconstruction network, which provides an end-to-end BCS reconstruction to eliminate blocking artifacts and maximize image reconstruction accuracy, in our AutoBCS architecture. Furthermore, we investigate comprehensive comparison studies with both traditional BCS approaches as well as newly-developing deep learning methods. Compared with these approaches, our AutoBCS framework can not only provide superior performance in both image quality metrics (SSIM and PSNR) and visual perception, but also automatically benefit reconstruction speed.      
### 8.Transfer Learning from Monolingual ASR to Transcription-free Cross-lingual Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2009.14668.pdf)
>  Cross-lingual voice conversion (VC) is a task that aims to synthesize target voices with the same content while source and target speakers speak in different languages. Its challenge lies in the fact that the source and target data are naturally non-parallel, and it is even difficult to bridge the gaps between languages with no transcriptions provided. In this paper, we focus on knowledge transfer from monolin-gual ASR to cross-lingual VC, in order to address the con-tent mismatch problem. To achieve this, we first train a monolingual acoustic model for the source language, use it to extract phonetic features for all the speech in the VC dataset, and then train a Seq2Seq conversion model to pre-dict the mel-spectrograms. We successfully address cross-lingual VC without any transcription or language-specific knowledge for foreign speech. We experiment this on Voice Conversion Challenge 2020 datasets and show that our speaker-dependent conversion model outperforms the zero-shot baseline, achieving MOS of 3.83 and 3.54 in speech quality and speaker similarity for cross-lingual conversion. When compared to Cascade ASR-TTS method, our proposed one significantly reduces the MOS drop be-tween intra- and cross-lingual conversion.      
### 9.CAD Applications and Emerging Research Potential in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2009.14657.pdf)
>  Computer Aided Detection (CAD) is a valuable technique for precisely interpreting medical images and it has a global business opportunity of about USD 1.8 billion. The current aspects with reference to the four sub stages such as image pre-processing, segmentation, feature extraction and classification and the future scope of CAD in medical imaging has been discussed in this paper. Many reviewers have emphasized the need for synergy between engineers and medical professionals for successful development of CAD systems and the current work is a move in that direction. The engineering aspects of the above four stages in four imaging modalities viz. computed tomography, magnetic resonance imaging, mammography and bone scintigraphy used in the diagnosis of five critical diseases have been discussed with a clinical background. Automatic classification of image can play an important role in preliminary screening of very critical ailments bringing down the cost of health care. Another recent advancement is using artificial intelligence and machine learning techniques. This paper reviews these engineering aspects with a view to explore the opportunities to researchers as well as the medical industry to offer affordable medical services with accessibility in even remote locations.      
### 10.The Cubli: Modeling Utilizing Quaternions  [ :arrow_down: ](https://arxiv.org/pdf/2009.14626.pdf)
>  This paper performs the modeling of a Cubli, a cube with three reaction wheels mounted on orthogonal faces that becomes a reaction wheel based 3D inverted pendulum when positioned in one of its vertices. The approach novelty is that quaternions are used instead of Euler angles. One nice advantage of quaternions, besides the usual arguments to avoid singularities and trigonometric functions, is that it allows working out quite complex dynamic equations completely by hand utilizing vector notation. Modeling is performed utilizing Lagrange equations and it is validated through computer simulations and Poinsot trajectories analysis.      
### 11.The Cubli: Modeling and Nonlinear Control Utilizing Unit Complex Numbers  [ :arrow_down: ](https://arxiv.org/pdf/2009.14625.pdf)
>  This paper covers the modeling and nonlinear control of the Cubli, a cube with three reaction wheels mounted on orthogonal faces that becomes a reaction wheel-based 1D/3D inverted pendulum when positioned in one of its edges (1D) or vertices (3D). Instead of angles, unit complex numbers are used as control states for the 1D configuration. This approach is useful not only to get rid of trigonometric functions, but mainly because it is a specific case of the 3D configuration, that utilizes unit ultra-complex numbers (quaternions) as system states, and therefore facilitates its understanding. The derived nonlinear control law is equivalent to a linear one and is characterized by only three straightforward tuning parameters. Experiment results are presented to validate modeling and control.      
### 12.COVID-CT-MD: COVID-19 Computed Tomography (CT) Scan Dataset Applicable in Machine Learning and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.14623.pdf)
>  Novel Coronavirus (COVID-19) has drastically overwhelmed more than 200 countries affecting millions and claiming almost 1 million lives, since its emergence in late 2019. This highly contagious disease can easily spread, and if not controlled in a timely fashion, can rapidly incapacitate healthcare systems. The current standard diagnosis method, the Reverse Transcription Polymerase Chain Reaction (RT- PCR), is time consuming, and subject to low sensitivity. Chest Radiograph (CXR), the first imaging modality to be used, is readily available and gives immediate results. However, it has notoriously lower sensitivity than Computed Tomography (CT), which can be used efficiently to complement other diagnostic methods. This paper introduces a new COVID-19 CT scan dataset, referred to as COVID-CT-MD, consisting of not only COVID-19 cases, but also healthy and subjects infected by Community Acquired Pneumonia (CAP). COVID-CT-MD dataset, which is accompanied with lobe-level, slice-level and patient-level labels, has the potential to facilitate the COVID-19 research, in particular COVID-CT-MD can assist in development of advanced Machine Learning (ML) and Deep Neural Network (DNN) based solutions.      
### 13.Hidden Markov Models for Pipeline Damage Detection Using Piezoelectric Transducers  [ :arrow_down: ](https://arxiv.org/pdf/2009.14589.pdf)
>  Oil and gas pipeline leakages lead to not only enormous economic loss but also environmental disasters. How to detect the pipeline damages including leakages and cracks has attracted much research attention. One of the promising leakage detection method is to use lead zirconate titanate (PZT) transducers to detect the negative pressure wave when leakage occurs. PZT transducers can generate and detect guided stress waves for crack detection also. However, the negative pressure waves or guided stress waves may not be easily detected with environmental interference, e.g., the oil and gas pipelines in offshore environment. In this paper, a Gaussian mixture model based hidden Markov model (GMM-HMM) method is proposed to detect the pipeline leakage and crack depth in changing environment and time-varying operational conditions. Leakages in different sections or crack depths are considered as different states in hidden Markov models (HMM). Laboratory experiments show that the GMM-HMM method can recognize the crack depth and leakage of pipeline such as whether there is a leakage, where the leakage is.      
### 14.FAN: Frequency Aggregation Network for Real Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2009.14547.pdf)
>  Single image super-resolution (SISR) aims to recover the high-resolution (HR) image from its low-resolution (LR) input image. With the development of deep learning, SISR has achieved great progress. However, It is still a challenge to restore the real-world LR image with complicated authentic degradations. Therefore, we propose FAN, a frequency aggregation network, to address the real-world image super-resolu-tion problem. Specifically, we extract different frequencies of the LR image and pass them to a channel attention-grouped residual dense network (CA-GRDB) individually to output corresponding feature maps. And then aggregating these residual dense feature maps adaptively to recover the HR image with enhanced details and textures. We conduct extensive experiments quantitatively and qualitatively to verify that our FAN performs well on the real image super-resolution task of AIM 2020 challenge. According to the released final results, our team SR-IM achieves the fourth place on the X4 track with PSNR of 31.1735 and SSIM of 0.8728.      
### 15.Embedded Emotions -- A Data Driven Approach to Learn Transferable Feature Representations from Raw Speech Input for Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2009.14523.pdf)
>  Traditional approaches to automatic emotion recognition are relying on the application of handcrafted features. More recently however the advent of deep learning enabled algorithms to learn meaningful representations of input data automatically. In this paper, we investigate the applicability of transferring knowledge learned from large text and audio corpora to the task of automatic emotion recognition. To evaluate the practicability of our approach, we are taking part in this year's Interspeech ComParE Elderly Emotion Sub-Challenge, where the goal is to classify spoken narratives of elderly people with respect to the emotion of the speaker. Our results show that the learned feature representations can be effectively applied for classifying emotions from spoken language. We found the performance of the features extracted from the audio signal to be not as consistent as those that have been extracted from the transcripts. While the acoustic features achieved best in class results on the development set, when compared to the baseline systems, their performance dropped considerably on the test set of the challenge. The features extracted from the text form, however, are showing promising results on both sets and are outperforming the official baseline by 5.7 percentage points unweighted average recall.      
### 16.Discussions on Inverse Kinematics based on Levenberg-Marquardt Method and Model-Free Adaptive (Predictive) Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.14507.pdf)
>  In this brief, the current robust numerical solution to the inverse kinematics based on Levenberg-Marquardt (LM) method is reanalyzed through control theory instead of numerical method. Compared to current works, the robustness of computation and convergence performance of computational error are analyzed much more clearly by analyzing the control performance of the corrected model free adaptive control (MFAC). Then mainly motivated by minimizing the predictive tracking error, this study suggests a new method of model free adaptive predictive control (MFAPC) to solve the inverse kinematics problem. At last, we apply the MFAPC as a controller for the robotic kinematic control problem in simulation. It not only shows an excellent control performance but also efficiently acquires the solution to inverse kinematic.      
### 17.Robust method to provide exponential convergence of model parameters solving LTI plant identification problem  [ :arrow_down: ](https://arxiv.org/pdf/2009.14496.pdf)
>  The scope of this research is a problem of parameters identification of a linear time-invariant (LTI) plant, which 1) input signal is not frequency-rich, 2) is subjected to initial conditions and external disturbances. The memory regressor extension (MRE) scheme, in which a specially derived differential equation is used as a filter, is applied to solve the above-stated problem. Such a filter allows us to obtain a limited regressor value, for which a condition of the initial excitation (IE) is met. Using the MRE scheme, the recursive least-squares (RLS) method with the forgetting factor is used to derive an adaptation law. The following properties have been proved for the proposed approach. If the IE condition is met, then: 1) the parameter error of identification is a limited value and converges to zero exponentially (if there are no external disturbances) or to a bounded set (in the case of them) with an adjustable rate, 2) the parameters adaptation rate is a finite value. The above-mentioned properties are mathematically proved and demonstrated via simulation experiments.      
### 18.Forced variational integrator for distance-based shape control with flocking behavior of multi-agent systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.14495.pdf)
>  A multi-agent system designed to achieve distance-based shape control with flocking behavior can be seen as a mechanical system described by a Lagrangian function and subject to additional external forces. Forced variational integrators are given by the discretization of Lagrange-d'Alembert principle for systems subject to external forces, and have proved useful for numerical simulation studies of complex dynamical systems. We derive forced variational integrators that can be employed in the context of control algorithms for distance-based shape with velocity consensus. In particular, we provide an accurate numerical integrator with a lower computational cost than traditional solutions, while preserving the configuration space and symmetries. We also provide an explicit expression for the integration scheme in the case of an arbitrary number of agents with double integrator dynamics. For a numerical comparison of the performances, we use a planar formation consisting of three autonomous agents.      
### 19.Learning Image-adaptive 3D Lookup Tables for High Performance Photo Enhancement in Real-time  [ :arrow_down: ](https://arxiv.org/pdf/2009.14468.pdf)
>  Recent years have witnessed the increasing popularity of learning based methods to enhance the color and tone of photos. However, many existing photo enhancement methods either deliver unsatisfactory results or consume too much computational and memory resources, hindering their application to high-resolution images (usually with more than 12 megapixels) in practice. In this paper, we learn image-adaptive 3-dimensional lookup tables (3D LUTs) to achieve fast and robust photo enhancement. 3D LUTs are widely used for manipulating color and tone of photos, but they are usually manually tuned and fixed in camera imaging pipeline or photo editing tools. We, for the first time to our best knowledge, propose to learn 3D LUTs from annotated data using pairwise or unpaired learning. More importantly, our learned 3D LUT is image-adaptive for flexible photo enhancement. We learn multiple basis 3D LUTs and a small convolutional neural network (CNN) simultaneously in an end-to-end manner. The small CNN works on the down-sampled version of the input image to predict content-dependent weights to fuse the multiple basis 3D LUTs into an image-adaptive one, which is employed to transform the color and tone of source images efficiently. Our model contains less than 600K parameters and takes less than 2 ms to process an image of 4K resolution using one Titan RTX GPU. While being highly efficient, our model also outperforms the state-of-the-art photo enhancement methods by a large margin in terms of PSNR, SSIM and a color difference metric on two publically available benchmark datasets.      
### 20.DER Information Unaware Coordination via Day-ahead Dynamic Power Bounds  [ :arrow_down: ](https://arxiv.org/pdf/2009.14458.pdf)
>  Reliability and voltage quality in distribution networks have been achieved via a combination of transformer power rating satisfaction and voltage management asset control. To maintain reliable operation under this paradigm, however, future grids with deep DER penetrations would require costly equipment upgrades. These upgrades can be mitigated via judicious coordination of DER operation. Earlier work has assumed a hierarchical control architecture in which a global controller (GC) uses detailed power injection and DER data and knowledge of DER owners' objectives to determine setpoints that local controllers should follow in order to achieve reliable and cost effective grid operation. Having such data and assuming knowledge of DER owners' objectives, however, are often not desirable or possible. In an earlier work, a 2-layer DER coordination architecture was shown to achieve close to optimal performance despite infrequent communication to a global controller. Motivated by this work, this paper proposes a day-ahead coordination scheme that uses forecasted power profile ranges to generate day-ahead dynamic power rating bounds at each transformer. Novel features of this scheme include: (i) the GC knows only past node power injection data and does not impose or know DER owner objectives, (ii) we use bounds that ensure reliable operation to guide the local controllers rather than setpoint tracking, and (iii) we consider electric vehicle (EV) charging in addition to storage. Simulations using the IEEE 123-bus network show that with 50% solar, 50% EVs and 10% storage penetrations, the uncoordinated approach incurs rating violations at nearly all 86 transformers and results in 10 times higher voltage deviation, while our approach incurs only 12 rating violations and maintains almost the same voltage deviations as before the addition of solar and EVs.      
### 21.Numerical Predictive Control for Delay Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2009.14450.pdf)
>  We present a delay-compensating control method that transforms exponentially stabilizing controllers for an undelayed system into a sample-based predictive controller with numerical integration. Our method handles both first-order and transport delays in actuators and trades-off numerical accuracy with computation delay to guaranteed stability under hardware limitations. Through hybrid stability analysis and numerical simulation, we demonstrate the efficacy of our method from both theoretical and simulation perspectives.      
### 22.Efficient, Decentralized, and Collaborative Multi-Robot Exploration using Optimal Transport Theory  [ :arrow_down: ](https://arxiv.org/pdf/2009.14434.pdf)
>  An Optimal Transport (OT)-based decentralized collaborative multi-robot exploration strategy is proposed in this paper. This method is to achieve an efficient exploration with a predefined priority in the given domain. In this context, the efficiency indicates how a team of robots (agents) cover the domain reflecting the corresponding priority map (or degrees of importance) in the domain. The decentralized exploration implies that each agent carries out their exploration task independently in the absence of any supervisory agent/computer. When an agent encounters another agent within a communication range, each agent receives the information about which areas are already covered by other agents, yielding a collaborative exploration. The OT theory is employed to quantify the difference between the distribution formed by the robot trajectories and the given reference spatial distribution indicating the priority. A computationally feasible way is developed to measure the performance of the proposed exploration scheme. Further, the formal algorithm is provided for the efficient, decentralized, and collaborative exploration plan. Simulation results are presented to validate the proposed methods.      
### 23.Small Drone Classification with Light CNN and New Micro-Doppler Signature Extraction Method Based on A-SPC Technique  [ :arrow_down: ](https://arxiv.org/pdf/2009.14422.pdf)
>  As the threats of small drones increase, not only the detection but also the classification of small drones has become important. Many recent studies have applied an approach to utilize the micro-Doppler signature (MDS) for the small drone classification by using frequency modulated continuous wave (FMCW) radars. In this letter, we propose a novel method to extract the MDS images of the small drones with the FMCW radar. Moreover, we propose a light convolutional neural network (CNN) whose structure is straightforward, and the number of parameters is quite small for fast classification. The proposed method contributes to increasing the classification accuracy by improving the quality of MDS images. We classified the small drones with the MDS images extracted by the conventional method and the proposed method through the proposed CNN. The experimental results showed that the total classification accuracy was increased by 10.00 % due to the proposed method. The total classification accuracy was recorded at 97.14 % with the proposed MDS extraction method and the proposed light CNN.      
### 24.FMCW SAR with New Synthesis Method Based on A-SPC Technique  [ :arrow_down: ](https://arxiv.org/pdf/2009.14415.pdf)
>  Frequency modulated continuous wave (FMCW) radar is emerging as a trendy radar system for synthetic aperture radar (SAR). This letter proposes a novel method for the extraction of the SAR image with the FMCW radar. The proposed method can improve the quality of the SAR image. For the verification, we built an automobile SAR (AutoSAR) system and conducted experiments to extract the SAR map by using the AutoSAR system. Then, we synthesized SAR images through both the conventional method and the proposed method to demonstrate the performance of the proposed method. The experimental results show that the SAR image has been successfully improved by the proposed method.      
### 25.Relay Pursuit of an Evader by a Heterogeneous Group of Pursuers Using Potential Games  [ :arrow_down: ](https://arxiv.org/pdf/2009.14407.pdf)
>  We propose a decentralized solution for a pursuit-evasion game involving a heterogeneous group of rational (selfish) pursuers and a single evader based on the framework of potential games. In the proposed game, the evader aims to delay (or, if possible, avoid) capture by any of the pursuers whereas each pursuer tries to capture the latter only if this is to his best interest. Our approach resembles in principle the so-called relay pursuit strategy introduced in [1], in which only the pursuer that can capture the evader faster than the others is active. In sharp contrast with the latter approach, the active pursuer herein is not determined by a reactive ad-hoc rule but from the solution of a corresponding potential game. We assume that each pursuer has different capabilities and his decision whether to go after the evader or not is based on the maximization of his individual utility (conditional on the choices and actions of the other pursuers). The pursuers' utilities depend on both the rewards that they will receive by capturing the evader and the time of capture (cost of capturing the evader) so that a pursuer should only seek capture when the incurred cost is relatively small. The determination of the active pursuer-evader assignments (in other words, which pursuers should be active) is done iteratively by having the pursuers exchange information and updating their own actions by executing a learning algorithm for games known as Spatial Adaptive Play (SAP). We illustrate the performance of our algorithm by means of extensive numerical simulations.      
### 26.Learning to Beamform for Intelligent Reflecting Surface with Implicit Channel Estimate  [ :arrow_down: ](https://arxiv.org/pdf/2009.14404.pdf)
>  Intelligent reflecting surface (IRS), consisting of massive number of tunable reflective elements, is capable of boosting spectral efficiency between a base station (BS) and a user by intelligently tuning the phase shifters at the IRS according to the channel state information (CSI). However, due to the large number of passive elements which cannot transmit and receive signals, acquisition of CSI for IRS is a practically challenging task. Instead of using the received pilots to estimate the channels explicitly, this paper shows that it is possible to learn the effective IRS reflection pattern and beamforming at the BS directly based on the received pilots. This is achieved by parameterizing the mapping from the received pilots to the optimal configuration of IRS and the beamforming matrix at the BS by properly tuning a deep neural network using unsupervised training. Simulation results indicate that the proposed neural network can efficiently learn to maximize the system sum rate from much fewer received pilots as compared to the traditional channel estimation based solutions.      
### 27.Transfer Learning from Speech Synthesis to Voice Conversion with Non-Parallel Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2009.14399.pdf)
>  This paper presents a novel framework to build a voice conversion (VC) system by learning from a text-to-speech (TTS) synthesis system, that is called TTS-VC transfer learning. We first develop a multi-speaker speech synthesis system with sequence-to-sequence encoder-decoder architecture, where the encoder extracts robust linguistic representations of text, and the decoder, conditioned on target speaker embedding, takes the context vectors and the attention recurrent network cell output to generate target acoustic features. We take advantage of the fact that TTS system maps input text to speaker independent context vectors, and reuse such a mapping to supervise the training of latent representations of an encoder-decoder voice conversion system. In the voice conversion system, the encoder takes speech instead of text as input, while the decoder is functionally similar to TTS decoder. As we condition the decoder on speaker embedding, the system can be trained on non-parallel data for any-to-any voice conversion. During voice conversion training, we present both text and speech to speech synthesis and voice conversion networks respectively. At run-time, the voice conversion network uses its own encoder-decoder architecture. Experiments show that the proposed approach outperforms two competitive voice conversion baselines consistently, namely phonetic posteriorgram and variational autoencoder methods, in terms of speech quality, naturalness, and speaker similarity.      
### 28.Co-design of Control and Planning for Multi-rotor UAVs with Signal Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2009.14363.pdf)
>  Urban Air Mobility (UAM), or the scenario where multiple manned and Unmanned Aerial Vehicles (UAVs) carry out various tasks over urban airspaces, is a transportation concept of the future that is gaining prominence. UAM missions with complex spatial, temporal and reactive requirements can be succinctly represented using Signal Temporal Logic (STL), a behavioral specification language. However, planning and control of systems with STL specifications is computationally intensive, usually resulting in planning approaches that do not guarantee dynamical feasibility, or control approaches that cannot handle complex STL specifications. Here, we present an approach to co-design the planner and control such that a given STL specification (possibly over multiple UAVs) is satisfied with trajectories that are dynamically feasible and our controller can track them with a bounded tracking-error that the planner accounts for. The tracking controller is formulated for the non-linear dynamics of the individual UAVs, and the tracking error bound is computed for this controller when the trajectories satisfy some kinematic constraints. We also augment an existing multi-UAV STL-based trajectory generator in order to generate trajectories that satisfy such constraints. We show that this co-design allows for trajectories that satisfy a given STL specification, and are also dynamically feasible in the sense that they can be tracked with bounded error. The applicability of this approach is demonstrated through simulations of multi-UAV missions.      
### 29.Co-Located vs Distributed vs Semi-Distributed MIMO: Measurement-Based Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2009.14344.pdf)
>  With the growing interest in cell-free massive multiple-input multiple-output (MIMO) systems, the benefits of single-antenna access points (APs) versus multi-antenna APs must be analyzed in order to optimize deployment. In this paper, we compare various antenna system topologies based on achievable downlink spectral efficiency, using both measured and synthetic channel data in an indoor environment. We assume multi-user scenarios, analyzing both conjugate beamforming (or maximum-ratio transmission (MRT)) and zero-forcing (ZF) precoding methods. The results show that the semi-distributed multi-antenna APs can reduce the number of APs, and still achieve the comparable achievable rates as the fully-distributed single-antenna APs with the same total number of antennas.      
### 30.Learning an optimal PSF-pair for ultra-dense 3D localization microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2009.14303.pdf)
>  A long-standing challenge in multiple-particle-tracking is the accurate and precise 3D localization of individual particles at close proximity. One established approach for snapshot 3D imaging is point-spread-function (PSF) engineering, in which the PSF is modified to encode the axial information. However, engineered PSFs are challenging to localize at high densities due to lateral PSF overlaps. Here we suggest using multiple PSFs simultaneously to help overcome this challenge, and investigate the problem of engineering multiple PSFs for dense 3D localization. We implement our approach using a bifurcated optical system that modifies two separate PSFs, and design the PSFs using three different approaches including end-to-end learning. We demonstrate our approach experimentally by volumetric imaging of fluorescently labelled telomeres in cells.      
### 31.Investigation of Instabilities in Detumbling Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2009.14292.pdf)
>  Detumbling refers to the act of dampening the angular velocity of the satellite. This operation is of paramount importance since it is virtually impossible to nominally perform any other operation without some degree of attitude control. Common methods used to detumble satellites usually involve magnetic actuation, paired with different types of sensors which are used to provide angular velocity feedback. This paper presents the adverse effects of time-discretization on the stability of two detumbling algorithms. An extensive literature review revealed that both algorithms achieve absolute stability for systems involving continuous feedback and output. However, the physical components involved impose limitations on the maximum frequency of the algorithm, thereby making any such system inconceivable. This asserts the need to perform a discrete-time stability analysis, as it is better suited to reflect on the actual implementation and dynamics of these algorithms. The paper starts with the current theory and views on the stability of these algorithms. The next sections describe the continuous and discrete-time stability analysis performed by the team and the conclusions derived from it. Theoretical investigation led to the discovery of multiple conditions on angular velocity and operating frequencies of the hardware, for which the algorithms were unstable. These results were then verified through various simulations on MATLAB and Python3.6.7. The paper concludes with a discussion on the various instabilities posed by time-discretization and the conditions under which the detumbling algorithm would be infeasible.      
### 32.Improved Battery State Estimation Under Parameter Uncertainty Caused by Aging Using Expansion Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2009.14270.pdf)
>  Accurate tracking of the internal electrochemical states of lithium-ion battery during cycling enables advanced battery management systems to operate the battery safely and maintain high performance while minimizing battery degradation. To this end, techniques based on voltage measurement have shown promise for estimating the lithium surface concentration of active material particles, which is an important state for avoiding aging mechanisms such as lithium plating. However, methods relying on voltage often lead to large estimation errors when the model parameters change during aging. In this paper, we utilize the in-situ measurement of the battery expansion to augment the voltage and develop an observer to estimate the lithium surface concentration distribution in each electrode particle. We demonstrate that the addition of the expansion signal enables us to correct the negative electrode concentration states in addition to the positive electrode. As a result, compared to a voltage only observer, the proposed observer can successfully recover the surface concentration when the electrodes' stoichiometric window changes, which is a common occurrence under aging by loss of lithium inventory. With a 5% shift in the electrodes' stoichiometric window, the results indicate a reduction in state estimation error for the negative electrode surface concentration. Under this simulated aged condition, the voltage based observer had 9.3% error as compared to the proposed voltage and expansion observer which had 0.1% error in negative electrode surface concentration.      
### 33.Hybrid European MV-LV Network Models for Smart Distribution Network Modelling  [ :arrow_down: ](https://arxiv.org/pdf/2009.14240.pdf)
>  A pair of European-style, integrated MV-LV circuits are presented, created by combining generic MV and real LV networks. The two models have 86,000 and 113,000 nodes, and are made readily available for download in the OpenDSS file format. Primary substation tap change controls and MV-LV feeders are represented as three-phase unbalanced distribution network models, capturing the coupling of voltages at the MV level. The assumptions made in constructing the models are outlined, including a preconditioning step that reduces the number of nodes by more than five times without affecting the solution. Two flexibility-based case studies are presented, with TSO-DSO and peer-peer-based smart controls considered. The demonstration of the heterogeneous nature of these systems is corroborated by the analysis of measured LV voltage data. The models are intended to aid the development of algorithms for maximising the benefits of smart devices within the context of whole energy systems.      
### 34.Gradient Descent-Ascent Provably Converges to Strict Local Minmax Equilibria with a Finite Timescale Separation  [ :arrow_down: ](https://arxiv.org/pdf/2009.14820.pdf)
>  We study the role that a finite timescale separation parameter $\tau$ has on gradient descent-ascent in two-player non-convex, non-concave zero-sum games where the learning rate of player 1 is denoted by $\gamma_1$ and the learning rate of player 2 is defined to be $\gamma_2=\tau\gamma_1$. Existing work analyzing the role of timescale separation in gradient descent-ascent has primarily focused on the edge cases of players sharing a learning rate ($\tau =1$) and the maximizing player approximately converging between each update of the minimizing player ($\tau \rightarrow \infty$). For the parameter choice of $\tau=1$, it is known that the learning dynamics are not guaranteed to converge to a game-theoretically meaningful equilibria in general. In contrast, Jin et al. (2020) showed that the stable critical points of gradient descent-ascent coincide with the set of strict local minmax equilibria as $\tau\rightarrow\infty$. In this work, we bridge the gap between past work by showing there exists a finite timescale separation parameter $\tau^{\ast}$ such that $x^{\ast}$ is a stable critical point of gradient descent-ascent for all $\tau \in (\tau^{\ast}, \infty)$ if and only if it is a strict local minmax equilibrium. Moreover, we provide an explicit construction for computing $\tau^{\ast}$ along with corresponding convergence rates and results under deterministic and stochastic gradient feedback. The convergence results we present are complemented by a non-convergence result: given a critical point $x^{\ast}$ that is not a strict local minmax equilibrium, then there exists a finite timescale separation $\tau_0$ such that $x^{\ast}$ is unstable for all $\tau\in (\tau_0, \infty)$. Finally, we empirically demonstrate on the CIFAR-10 and CelebA datasets the significant impact timescale separation has on training performance.      
### 35.Byzantine Fault-Tolerance in Decentralized Optimization under Minimal Redundancy  [ :arrow_down: ](https://arxiv.org/pdf/2009.14763.pdf)
>  This paper considers the problem of Byzantine fault-tolerance in multi-agent decentralized optimization. In this problem, each agent has a local cost function. The goal of a decentralized optimization algorithm is to allow the agents to cooperatively compute a common minimum point of their aggregate cost function. We consider the case when a certain number of agents may be Byzantine faulty. Such faulty agents may not follow a prescribed algorithm, and they may share arbitrary or incorrect information with other non-faulty agents. Presence of such Byzantine agents renders a typical decentralized optimization algorithm ineffective. We propose a decentralized optimization algorithm with provable exact fault-tolerance against a bounded number of Byzantine agents, provided the non-faulty agents have a minimal redundancy.      
### 36.Deep Learning-based Pipeline for Module Power Prediction from EL Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2009.14712.pdf)
>  Automated inspection plays an important role in monitoring large-scale photovoltaic power plants. Commonly, electroluminescense measurements are used to identify various types of defects on solar modules but have not been used to determine the power of a module. However, knowledge of the power at maximum power point is important as well, since drops in the power of a single module can affect the performance of an entire string. By now, this is commonly determined by measurements that require to discontact or even dismount the module, rendering a regular inspection of individual modules infeasible. In this work, we bridge the gap between electroluminescense measurements and the power determination of a module. We compile a large dataset of 719 electroluminescense measurementsof modules at various stages of degradation, especially cell cracks and fractures, and the corresponding power at maximum power point. Here,we focus on inactive regions and cracks as the predominant type of defect. We set up a baseline regression model to predict the power from electroluminescense measurements with a mean absolute error of 9.0+/-3.7W (4.0+/-8.4%). Then, we show that deep-learning can be used to train a model that performs significantly better (7.3+/-2.7W or 3.2+/-6.5%). With this work, we aim to open a new research topic. Therefore, we publicly release the dataset, the code and trained models to empower other researchers to compare against our results. Finally, we present a thorough evaluation of certain boundary conditions like the dataset size and an automated preprocessing pipeline for on-site measurements showing multiple modules at once.      
### 37.SoRC -- Evaluation of Computational Molecular Co-Localization Analysis in Mass Spectrometry Images  [ :arrow_down: ](https://arxiv.org/pdf/2009.14677.pdf)
>  The computational analysis of Mass Spectrometry Imaging (MSI) data aims at the identification of interesting mass co-localizations and the visualization of their lateral distribution in the sample, usually a tissue cross section. But as the morphological structure of tissues and the different kinds of mass co-localization naturally show a huge diversity, the selection and tuning of the computational method is a time-consuming effort. In this work we address the special problem of computationally grouping mass channel images according to their similarities in their lateral distribution patterns. Such an analysis is driven by the idea, that groups of molecules that feature a similar distribution pattern may have a functional relation. But the selection of the similarity function and other parameters is often done by a time-consuming and unsatsifactory trial and error. We propose a new flexible workflow scheme called SoRC (sum of ranked cluster indices) for automating this tuning step and making it much more efficient. We test SoRC using three different data sets acquired from the lab for three different kinds of samples (barley seed, mouse bladder tissue, human PXE skin). We show, that SORC can be applied to score and visualize the results obtained with the applied methods in short time without too much effort. In our application example, the SoRC results for the three data sets reveal that a) some well-known similarity functions are suited to achieve good results for all three data sets and b) for the MSI data featuring a higher degree of irregularity improved results can be achieved by applying non-standard similarity functions. The SoRC scores computed with our approach indicate that an automated testing and scoring of different methods for mass channel image grouping can improve the final outcome of a study by finally selecting the methods of the highest scores.      
### 38.Facilitating Connected Autonomous Vehicle Operations Using Space-weighted Information Fusion and Deep Reinforcement Learning Based Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.14665.pdf)
>  The connectivity aspect of connected autonomous vehicles (CAV) is beneficial because it facilitates dissemination of traffic-related information to vehicles through Vehicle-to-External (V2X) communication. Onboard sensing equipment including LiDAR and camera can reasonably characterize the traffic environment in the immediate locality of the CAV. However, their performance is limited by their sensor range (SR). On the other hand, longer-range information is helpful for characterizing imminent conditions downstream. By contemporaneously coalescing the short- and long-range information, the CAV can construct comprehensively its surrounding environment and thereby facilitate informed, safe, and effective movement planning in the short-term (local decisions including lane change) and long-term (route choice). In this paper, we describe a Deep Reinforcement Learning based approach that integrates the data collected through sensing and connectivity capabilities from other vehicles located in the proximity of the CAV and from those located further downstream, and we use the fused data to guide lane changing, a specific context of CAV operations. In addition, recognizing the importance of the connectivity range (CR) to the performance of not only the algorithm but also of the vehicle in the actual driving environment, the paper carried out a case study. The case study demonstrates the application of the proposed algorithm and duly identifies the appropriate CR for each level of prevailing traffic density. It is expected that implementation of the algorithm in CAVs can enhance the safety and mobility associated with CAV driving operations. From a general perspective, its implementation can provide guidance to connectivity equipment manufacturers and CAV operators, regarding the default CR settings for CAVs or the recommended CR setting in a given traffic environment.      
### 39.Driver Anomaly Detection: A Dataset and Contrastive Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.14660.pdf)
>  Distracted drivers are more likely to fail to anticipate hazards, which result in car accidents. Therefore, detecting anomalies in drivers' actions (i.e., any action deviating from normal driving) contains the utmost importance to reduce driver-related accidents. However, there are unbounded many anomalous actions that a driver can do while driving, which leads to an 'open set recognition' problem. Accordingly, instead of recognizing a set of anomalous actions that are commonly defined by previous dataset providers, in this work, we propose a contrastive learning approach to learn a metric to differentiate normal driving from anomalous driving. For this task, we introduce a new video-based benchmark, the Driver Anomaly Detection (DAD) dataset, which contains normal driving videos together with a set of anomalous actions in its training set. In the test set of the DAD dataset, there are unseen anomalous actions that still need to be winnowed out from normal driving. Our method reaches 0.9673 AUC on the test set, demonstrating the effectiveness of the contrastive learning approach on the anomaly detection task. Our dataset, codes and pre-trained models are publicly available.      
### 40.Computational framework for real-time diagnostics and prognostics of aircraft actuation systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.14645.pdf)
>  Prognostics and Health Management (PHM) are emerging approaches to product life cycle that will maintain system safety and improve reliability, while reducing operating and maintenance costs. This is particularly relevant for aerospace systems, where high levels of integrity and high performances are required at the same time. We propose a novel strategy for the nearly real-time Fault Detection and Identification (FDI) of a dynamical assembly, and for the estimation of Remaining Useful Life (RUL) of the system. The availability of a timely estimate of the health status of the system will allow for an informed adaptive planning of maintenance and a dynamical reconfiguration of the mission profile, reducing operating costs and improving reliability. This work addresses the three phases of the prognostic flow - namely (1) signal acquisition, (2) Fault Detection and Identification, and (3) Remaining Useful Life estimation - and introduces a computationally efficient procedure suitable for real-time, on-board execution. To achieve this goal, we propose to combine information from physical models of different fidelity with machine learning techniques to obtain efficient representations (surrogate models) suitable for nearly real-time applications. Additionally, we propose an importance sampling strategy and a novel approach to model damage propagation for dynamical systems. The methodology is assessed for the FDI and RUL estimation of an aircraft electromechanical actuator (EMA) for secondary flight controls. The results show that the proposed method allows for a high precision in the evaluation of the system RUL, while outperforming common model-based techniques in terms of computational time.      
### 41.Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing  [ :arrow_down: ](https://arxiv.org/pdf/2009.14639.pdf)
>  Convolutional Neural Networks with 3D kernels (3D CNNs) currently achieve state-of-the-art results in video recognition tasks due to their supremacy in extracting spatiotemporal features within video frames. There have been many successful 3D CNN architectures surpassing the state-of-the-art results successively. However, nearly all of them are designed to operate offline creating several serious handicaps during online operation. Firstly, conventional 3D CNNs are not dynamic since their output features represent the complete input clip instead of the most recent frame in the clip. Secondly, they are not temporal resolution-preserving due to their inherent temporal downsampling. Lastly, 3D CNNs are constrained to be used with fixed temporal input size limiting their flexibility. In order to address these drawbacks, we propose dissected 3D CNNs, where the intermediate volumes of the network are dissected and propagated over depth (time) dimension for future calculations, substantially reducing the number of computations at online operation. For action classification, the dissected version of ResNet models performs 74-90% fewer computations at online operation while achieving $\sim$5% better classification accuracy on the Kinetics-600 dataset than conventional 3D ResNet models. Moreover, the advantages of dissected 3D CNNs are demonstrated by deploying our approach onto several vision tasks, which consistently improved the performance.      
### 42.Fast versus conventional HAADF-STEM tomography: advantages and challenges  [ :arrow_down: ](https://arxiv.org/pdf/2009.14512.pdf)
>  Electron tomography is a widely used experimental technique for analyzing nanometer-scale structures of a large variety of materials in three dimensions. Unfortunately, the acquisition of conventional electron tomography tilt series can easily take up one hour or more, depending on the complexity of the experiment. Using electron tomography, it is therefore far from straightforward to obtain statistically meaningful 3D data, to investigate samples that do not withstand long acquisition, or to perform in situ 3D characterization using this technique. Various acquisition strategies have been proposed to accelerate the tomographic acquisition, and reduce the required electron dose. These methods include tilting the holder continuously while acquiring a projection movie and a hybrid, incremental, methodology which combines the benefits of the conventional and continuous technique. In this paper, the different acquisition strategies will be experimentally compared in terms of speed, resolution and electron dose, based on experimental tilt series acquired for various metallic nanoparticles.      
### 43.Joint Mobility-Aware UAV Placement and Routing in Multi-Hop UAV Relaying Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.14446.pdf)
>  Unmanned Aerial Vehicles (UAVs) have been extensively utilized to provide wireless connectivity in rural and under-developed areas, enhance network capacity and provide support for peaks or unexpected surges in user demand, mainly due to their fast deployment, cost-efficiency and superior communication performance resulting from Line of Sight (LoS)-dominated wireless channels. In order to exploit the benefits of UAVs as base stations or relays in a mobile network, a major challenge is to determine the optimal UAV placement and relocation strategy with respect to the mobility and traffic patterns of the ground network nodes. Moreover, considering that the UAVs form a multi-hop aerial network, capacity and connectivity constraints have significant impacts on the end-to-end network performance. To this end, we formulate the joint UAV placement and routing problem as a Mixed Integer Linear Program (MILP) and propose an approximation that leads to a LP rounding algorithm and achieves a balance between time-complexity and optimality.      
### 44.Few-Mode Fiber Coupling Efficiency for Free-Space Optical Communication  [ :arrow_down: ](https://arxiv.org/pdf/2009.14392.pdf)
>  Few-mode fiber is a significant component of free-space optical communication at the receiver to obtain achievable high coupling efficiency. A theoretical coupling model from the free-space optical communication link to a few-mode fiber is proposed based on a scale-adapted set of Laguerre-Gaussian modes. It is found that the coupling efficiency of various modes behaves differently in the presence of atmospheric turbulence or random jitter. Based on this model, the optimal coupling geometry parameter is obtained to maximize the coupling efficiency of the selected mode of few-mode fiber. The communication performance with random jitter is investigated. It is shown that the few-mode fiber has better bit-error rate performance than single-mode fiber, especially in high signal-to-noise ratio regimes.      
### 45.Noise-free computational ghost imaging with pink noise speckle patterns  [ :arrow_down: ](https://arxiv.org/pdf/2009.14390.pdf)
>  Computational ghost imaging reconstructs an object by second order correlation measurement with the use of a single pixel detector. It normally requires a large number of speckle patterns to make an ensemble average to retrieve the desired images. In this work, we propose a pink noise speckle pattern illumination in the computational ghost imaging system. We then experimentally demonstrate high signal-to-noise ratio reconstructed images in the presence of a variety of noises. The results are also compared with the use of standard white noise. We show that under extreme noisy environment or pattern distortion, our method gives good quality image while traditional method fails.      
### 46.Secure Aggregation with Heterogeneous Quantization in Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.14388.pdf)
>  Secure model aggregation across many users is a key component of federated learning systems. The state-of-the-art protocols for secure model aggregation, which are based on additive masking, require all users to quantize their model updates to the same level of quantization. This severely degrades their performance due to lack of adaptation to available bandwidth at different users. We propose three schemes that allow secure model aggregation while using heterogeneous quantization. This enables the users to adjust their quantization proportional to their available bandwidth, which can provide a substantially better trade-off between the accuracy of training and the communication time. The proposed schemes are based on a grouping strategy by partitioning the network into groups, and partitioning the local model updates of users into segments. Instead of applying aggregation protocol to the entire local model update vector, it is applied on segments with specific coordination between users. We theoretically evaluate the quantization error for our schemes, and also demonstrate how our schemes can be utilized to overcome Byzantine users.      
### 47.End-to-End Spoken Language Understanding Without Full Transcripts  [ :arrow_down: ](https://arxiv.org/pdf/2009.14386.pdf)
>  An essential component of spoken language understanding (SLU) is slot filling: representing the meaning of a spoken utterance using semantic entity labels. In this paper, we develop end-to-end (E2E) spoken language understanding systems that directly convert speech input to semantic entities and investigate if these E2E SLU models can be trained solely on semantic entity annotations without word-for-word transcripts. Training such models is very useful as they can drastically reduce the cost of data collection. We created two types of such speech-to-entities models, a CTC model and an attention-based encoder-decoder model, by adapting models trained originally for speech recognition. Given that our experiments involve speech input, these systems need to recognize both the entity label and words representing the entity value correctly. For our speech-to-entities experiments on the ATIS corpus, both the CTC and attention models showed impressive ability to skip non-entity words: there was little degradation when trained on just entities versus full transcripts. We also explored the scenario where the entities are in an order not necessarily related to spoken order in the utterance. With its ability to do re-ordering, the attention model did remarkably well, achieving only about 2% degradation in speech-to-bag-of-entities F1 score.      
### 48.Rethinking Evaluation Methodology for Audio-to-Score Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2009.14374.pdf)
>  This paper offers a precise, formal definition of an audio-to-score alignment. While the concept of an alignment is intuitively grasped, this precision affords us new insight into the evaluation of audio-to-score alignment algorithms. Motivated by these insights, we introduce new evaluation metrics for audio-to-score alignment. Using an alignment evaluation dataset derived from pairs of KernScores and MAESTRO performances, we study the behavior of our new metrics and the standard metrics on several classical alignment algorithms.      
### 49.Attention-Driven Body Pose Encoding for Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2009.14326.pdf)
>  This article proposes a novel attention-based body pose encoding for human activity recognition that presents a enriched representation of body-pose that is learned. The enriched data complements the 3D body joint position data and improves model performance. In this paper, we propose a novel approach that learns enhanced feature representations from a given sequence of 3D body joints. To achieve this encoding, the approach exploits 1) a spatial stream which encodes the spatial relationship between various body joints at each time point to learn spatial structure involving the spatial distribution of different body joints 2) a temporal stream that learns the temporal variation of individual body joints over the entire sequence duration to present a temporally enhanced representation. Afterwards, these two pose streams are fused with a multi-head attention mechanism. % adapted from neural machine translation. We also capture the contextual information from the RGB video stream using a Inception-ResNet-V2 model combined with a multi-head attention and a bidirectional Long Short-Term Memory (LSTM) network. %Moreover, we whose performance is enhanced through the multi-head attention mechanism. Finally, the RGB video stream is combined with the fused body pose stream to give a novel end-to-end deep model for effective human activity recognition.      
### 50.Covariance Steering of Discrete-Time Stochastic Linear Systems Based on Distribution Distance Terminal Costs  [ :arrow_down: ](https://arxiv.org/pdf/2009.14252.pdf)
>  We consider a class of stochastic optimal control problems for discrete-time stochastic linear systems which seek for control policies that will steer the probability distribution of the terminal state of the system close to a desired Gaussian distribution. In our problem formulation, the closeness between the terminal state distribution and the desired (goal) distribution is measured in terms of the squared Wasserstein distance which is associated with a corresponding terminal cost term. We recast the stochastic optimal control problem as a finite-dimensional nonlinear program and we show that its performance index can be expressed as the difference of two convex functions. This representation of the performance index allows us to find local minimizers of the original nonlinear program via the so-called convex-concave procedure [1]. Subsequently, we consider a similar problem but this time we use a terminal cost that corresponds to the KL divergence. Finally, we present non-trivial numerical simulations to demonstrate the proposed techniques and compare them in terms of computation time.      
### 51.Trust-Aware Service Function Chain Embedding: A Path-Based Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.07343.pdf)
>  With the emergence of network function virtualization (NFV), and software-defined networking (SDN), the realization and implementation of service function chains (SFCs) have become much easier. An SFC is an ordered set of interconnected virtual network functions (VNFs). NFV allows for decoupling the network functions from proprietary hardware realizing a software-based implementation of VNFs on commodity hardware and SDN decouples the network control from its forwarding logic allowing for a more flexible and programmable traffic routing among the VNFs. The SFC embedding problem (i.e. placement of SFCs on a shared substrate and establishing the corresponding traffic routes between the VNFs), has been extensively studied in the literature. In this paper, we extend a previous work on trust-aware service chain embedding with generalizing the role of trust by incorporating the trustworthiness of the service network links and substrate network paths into the SFC embedding decision process. We first introduce and formulate the path-based trust-aware service chain embedding problem as a mixed integer-linear program (MILP), and then provide an approximate model-based on selecting k-shortest candidate substrate paths for hosting each virtual link, to reduce the complexity of the model. We validate the performance of our methods through simulations and conduct a discussion on evaluating the methods and some operation trade-offs.      

# ArXiv eess --Tue, 20 Oct 2020
### 1.Safety-Critical Protective Systems and Margins of Safety  [ :arrow_down: ](https://arxiv.org/pdf/2010.09674.pdf)
>  The design and operation of protective systems is an essential engineering responsibility. Ensuring public safety, while essential, must be accomplished at a feasible cost and within government regulation. Hence, protective system design and operational decisions must be evaluated with respect to benefit (both enterprise profit and social benefit) and cost (both enterprise and social costs). <br>Analytical arguments are made that establish the economic relationship between protective system margins of safety, regulatory authority, and the calculus of negligence. Within this risk-based analytical framework, protection efficacy is explored. In particular, the risk-economics of margins of safety are examined by identifying the reference efficacy with respect to which margins of safety are measured. Engineering design and operations decisions intended to improve protection efficacy can, thus, be gauged as the degree to which they advance a risk-based margin of safety. <br>Finally, our analytical framework is exercised to show how risk-based margins of safety reveal the relationship between uncertain costs and regulatory activity focused on ensuring public welfare that is backstopped by liability in the event of catastrophe. How both prescriptive and performance based regulations influence margins of safety with respect to protective system innovation can be identified here.      
### 2.Distributed control under compromised measurements:Resilient estimation, attack detection, and vehicle platooning  [ :arrow_down: ](https://arxiv.org/pdf/2010.09661.pdf)
>  We study how to design a secure observer-based distributed controller such that a group of vehicles can achieve accurate state estimates and formation control even if the measurements of a subset of vehicle sensors are compromised by a malicious attacker. We propose an architecture consisting of a resilient observer, an attack detector, and an observer-based distributed controller. The distributed detector is able to update three sets of vehicle sensors: the ones surely under attack, surely attack-free, and suspected to be under attack. The adaptive observer saturates the measurement innovation through a preset static or time-varying threshold, such that the potentially compromised measurements have limited influence on the estimation. Essential properties of the proposed architecture include: 1) The detector is fault-free, and the attacked and attack-free vehicle sensors can be identified in finite time; 2) The observer guarantees both real-time error bounds and asymptotic error bounds, with tighter bounds when more attacked or attack-free vehicle sensors are identified by the detector; 3) The distributed controller ensures closed-loop stability. The effectiveness of the proposed methods is evaluated through simulations by an application to vehicle platooning.      
### 3.Inferring respiratory and circulatory parameters from electrical impedance tomography with deep recurrent models  [ :arrow_down: ](https://arxiv.org/pdf/2010.09622.pdf)
>  Electrical impedance tomography (EIT) is a noninvasive imaging modality that allows a continuous assessment of changes in regional bioimpedance of different organs. One of its most common biomedical applications is monitoring regional ventilation distribution in critically ill patients treated in intensive care units. In this work, we put forward a proof-of-principle study that demonstrates how one can reconstruct synchronously measured respiratory or circulatory parameters from the EIT image sequence using a deep learning model trained in an end-to-end fashion. We demonstrate that one can accurately infer absolute volume, absolute flow, normalized airway pressure and within certain limitations even the normalized arterial blood pressure from the EIT signal alone, in a way that generalizes to unseen patients without prior calibration. As an outlook with direct clinical relevance, we furthermore demonstrate the feasibility of reconstructing the absolute transpulmonary pressure from a combination of EIT and absolute airway pressure, as a way to potentially replace the invasive measurement of esophageal pressure. With these results, we hope to stimulate further studies building on the framework put forward in this work.      
### 4.End-to-End Text-to-Speech using Latent Duration based on VQ-VAE  [ :arrow_down: ](https://arxiv.org/pdf/2010.09602.pdf)
>  Explicit duration modeling is a key to achieving robust and efficient alignment in text-to-speech synthesis (TTS). We propose a new TTS framework using explicit duration modeling that incorporates duration as a discrete latent variable to TTS and enables joint optimization of whole modules from scratch. We formulate our method based on conditional VQ-VAE to handle discrete duration in a variational autoencoder and provide a theoretical explanation to justify our method. In our framework, a connectionist temporal classification-based force aligner acts as the approximate posterior, and text-to-duration works as the prior in the variational autoencoder. We evaluated our proposed method with a listening test and compared it with other TTS methods based on soft-attention or explicit duration modeling. The result show that our systems rated between soft-attention-based methods (Transformer-TTS, Tacotron2) and explicit duration modeling-based methods (Fastspeech).      
### 5.GASNet: Weakly-supervised Framework for COVID-19 Lesion Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.09456.pdf)
>  Segmentation of infected areas in chest CT volumes is of great significance for further diagnosis and treatment of COVID-19 patients. Due to the complex shapes and varied appearances of lesions, a large number of voxel-level labeled samples are generally required to train a lesion segmentation network, which is a main bottleneck for developing deep learning based medical image segmentation algorithms. In this paper, we propose a weakly-supervised lesion segmentation framework by embedding the Generative Adversarial training process into the Segmentation Network, which is called GASNet. GASNet is optimized to segment the lesion areas of a COVID-19 CT by the segmenter, and to replace the abnormal appearance with a generated normal appearance by the generator, so that the restored CT volumes are indistinguishable from healthy CT volumes by the discriminator. GASNet is supervised by chest CT volumes of many healthy and COVID-19 subjects without voxel-level annotations. Experiments on three public databases show that when using as few as one voxel-level labeled sample, the performance of GASNet is comparable to fully-supervised segmentation algorithms trained on dozens of voxel-level labeled samples.      
### 6.Data-driven sparse sensor placement based on A-optimal design of experiment with ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2010.09329.pdf)
>  The present study proposes a sensor selection method based on the proximal splitting algorithm and the A-optimal design of experiment using the alternating direction method of multipliers (ADMM) algorithm. The performance of the proposed method was evaluated with a random sensor problem and compared with the previously proposed methods such as the greedy method and the convex relaxation. The performance of the proposed method is better than an existing method in terms of the A-optimality criterion. In addition, the proposed method requires longer computational time than the greedy method but it is quite shorter than the convex relaxation in large-scale problems. The proposed method was applied to the data-driven sparse-sensor-selection problem. A data set adopted is the NOAA OISST V2 mean sea surface temperature set. At the number of sensors larger than that of the latent state variables, the proposed method showed similar and better performances compared with previously proposed methods in terms of the A-optimality criterion and reconstruction error.      
### 7.Reduce and Reconstruct: Improving Low-resource End-to-end ASR Via Reconstruction Using Reduced Vocabularies  [ :arrow_down: ](https://arxiv.org/pdf/2010.09322.pdf)
>  End-to-end automatic speech recognition (ASR) systems are increasingly being favoured due to their direct treatment of the problem of speech to text conversion. However, these systems are known to be data hungry and hence underperform in low-resource settings. In this work, we propose a seemingly simple but effective technique to improve low-resource end-to-end ASR performance. We compress the output vocabulary of the end-to-end ASR system using linguistically meaningful reductions and then reconstruct the original vocabulary using a standalone module. Our objective is two-fold: to lessen the burden on the low-resource end-to-end ASR system by reducing the output vocabulary space and to design a powerful reconstruction module that recovers sequences in the original vocabulary from sequences in the reduced vocabulary. We present two reconstruction modules, an encoder decoder-based architecture and a finite state transducer-based model. We demonstrate the efficacy of our proposed techniques using ASR systems for two Indian languages, Gujarati and Telugu.      
### 8.Poisson Image Deconvolution by a Plug-and-Play Quantum Denoising Scheme  [ :arrow_down: ](https://arxiv.org/pdf/2010.09321.pdf)
>  This paper introduces a new Plug-and-Play (PnP) alternating direction of multipliers (ADMM) scheme based on a recently proposed denoiser using the Schroedinger equation solutions of quantum physics. The proposed algorithm referred to as QAB-PnP is well-adapted to Poisson noise, which is very common for imaging applications, such as, limited photon acquisition. In contrast to existing PnP approaches using a variance stabilizing transformation that is not invariant to deconvolution operation, the proposed method does not suffer from this theoretical problem. Moreover, numerical results show the superiority of the proposed scheme compared to recent state-of-the-art techniques, for both low and high signal-to-noise-ratio scenarios.      
### 9.A Universal Synchronization Theorem for Heterogeneous Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.09295.pdf)
>  Using the relative gain array (RGA) a stability guarantee for a heterogeneous ensemble of linear agents coupled through the output over a loss-less undirected network is formulated. The stability guarantee does not require any information about the network topology or of other agents. But, with knowledge about the eigenvalues of the network Laplacian, the proposed stability criteria allows us to be less conservative than passivity based methods. Thereby, we can guarantee stability also in a heterogeneous network with nonminimum phase (NMP) actuators.      
### 10.DiDiSpeech: A Large Scale Mandarin Speech Corpus  [ :arrow_down: ](https://arxiv.org/pdf/2010.09275.pdf)
>  This paper introduces a new open-sourced Mandarin speech corpus, called DiDiSpeech. It consists of about 800 hours of speech data at 48kHz sampling rate from 6000 speakers and the corresponding texts. All speech data in the corpus was recorded in quiet environment and is suitable for various speech processing tasks, such as voice conversion, multi-speaker text-to-speech and automatic speech recognition. We conduct experiments with multiple speech tasks and evaluate the performance, showing that it is promising to use the corpus for both academic research and practical application. The corpus is available at <a class="link-external link-https" href="https://outreach.didichuxing.com/research/opendata/en/" rel="external noopener nofollow">this https URL</a>.      
### 11.DeepWiPHY: Deep Learning-based Receiver Design and Dataset for IEEE 802.11ax Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.09268.pdf)
>  In this work, we develop DeepWiPHY, a deep learning-based architecture to replace the channel estimation, common phase error (CPE) correction, sampling rate offset (SRO) correction, and equalization modules of IEEE 802.11ax based orthogonal frequency division multiplexing (OFDM) receivers. We first train DeepWiPHY with a synthetic dataset, which is generated using representative indoor channel models and includes typical radio frequency (RF) impairments that are the source of nonlinearity in wireless systems. To further train and evaluate DeepWiPHY with real-world data, we develop a passive sniffing-based data collection testbed composed of Universal Software Radio Peripherals (USRPs) and commercially available IEEE 802.11ax products. The comprehensive evaluation of DeepWiPHY with synthetic and real-world datasets (110 million synthetic OFDM symbols and 14 million real-world OFDM symbols) confirms that, even without fine-tuning the neural network's architecture parameters, DeepWiPHY achieves comparable performance to or outperforms the conventional WLAN receivers, in terms of both bit error rate (BER) and packet error rate (PER), under a wide range of channel models, signal-to-noise (SNR) levels, and modulation schemes.      
### 12.Frequency-Hopping MIMO Radar-Based Communications: An Overview  [ :arrow_down: ](https://arxiv.org/pdf/2010.09257.pdf)
>  Enabled by the advancement in radio frequency technologies, the convergence of radar and communication systems becomes increasingly promising and is envisioned as a key feature of future 6G networks. Recently, the frequency-hopping (FH) MIMO radar is introduced to underlay dual-function radar-communication (DFRC) systems. Superior to many previous radar-centric DFRC designs, the symbol rate of FH-MIMO radar-based DFRC (FH-MIMO DFRC) can exceed the radar pulse repetition frequency. However, many practical issues, particularly those regarding effective data communications, are unexplored/unsolved. To promote the awareness and general understanding of the novel DFRC, this article is devoted to providing a timely introduction of FH-MIMO DFRC. We comprehensively review many essential aspects of the novel DFRC: channel/signal models, signaling strategies, modulation/demodulation processing and channel estimation methods, to name a few. We also highlight major remaining issues in FH-MIMO DFRC and suggest potential solutions to shed light on future research works.      
### 13.Multi-channel target speech extraction with channel decorrelation and target speaker adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2010.09191.pdf)
>  The end-to-end approaches for single-channel target speech extraction have attracted widespread attention. However, the studies for end-to-end multi-channel target speech extraction are still relatively limited. In this work, we propose two methods for exploiting the multi-channel spatial information to extract the target speech. The first one is using a target speech adaptation layer in a parallel encoder architecture. The second one is designing a channel decorrelation mechanism to extract the inter-channel differential information to enhance the multi-channel encoder representation. We compare the proposed methods with two strong state-of-the-art baselines. Experimental results on the multi-channel reverberant WSJ0 2-mix dataset demonstrate that our proposed methods achieve up to 11.2% and 11.5% relative improvements in SDR and SiSDR, respectively.      
### 14.Neural Network Architectures for Location Estimation in the Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2010.09187.pdf)
>  Artificial Intelligence (AI) solutions for wireless location estimation are likely to prevail in many real-world scenarios. In this work, we demonstrate for the first time how the Cramer-Rao upper bound on localization accuracy can facilitate efficient neural-network solutions for wireless location estimation. In particular, we demonstrate how the number of neurons for the network can be intelligently chosen, leading to AI location solutions that are not time-consuming to run and less likely to be plagued by over-fitting. Experimental verification of our approach is provided. Our new algorithms are directly applicable to location estimates in many scenarios including the Internet of Things, and vehicular networks where vehicular GPS coordinates are unreliable or need verifying. Our work represents the first successful AI solution for a communication problem whose neural-network design is based on fundamental information-theoretic constructs. We anticipate our approach will be useful for a wide range of communication problems beyond location estimation.      
### 15.Modified EP MIMO Detection Algorithm with Deep Learning Parameters Selection  [ :arrow_down: ](https://arxiv.org/pdf/2010.09183.pdf)
>  Expectation Propagation (EP)-based Multiple-Input Multiple-Output (MIMO) detector is regarded as a state-of-the-art MIMO detector because of its exceptional performance. However, we find that the EP MIMO detector cannot guarantee to achieve the optimal performance due to the empirical parameter selection, including initial variance and damping factors. According to the influence of the moment matching and parameter selection for the performance of the EP MIMO detector, we propose a modified EP MIMO detector (MEPD). In order to obtain the optimal initial variance and damping factors, we adopt a deep learning scheme, in which we unfold the iterative processing of MEPD to establish MEPNet for parameters training. The simulation results show that MEPD with off-line trained parameters outperforms the original one in various MIMO scenarios. Besides, the proposed MEPD with deep learning parameters selection is more robust than EPD in practical scenarios.      
### 16.Learnable Spectro-temporal Receptive Fields for Robust Voice Type Discrimination  [ :arrow_down: ](https://arxiv.org/pdf/2010.09151.pdf)
>  Voice Type Discrimination (VTD) refers to discrimination between regions in a recording where speech was produced by speakers that are physically within proximity of the recording device ("Live Speech") from speech and other types of audio that were played back such as traffic noise and television broadcasts ("Distractor Audio"). In this work, we propose a deep-learning-based VTD system that features an initial layer of learnable spectro-temporal receptive fields (STRFs). Our approach is also shown to provide very strong performance on a similar spoofing detection task in the ASVspoof 2019 challenge. We evaluate our approach on a new standardized VTD database that was collected to support research in this area. In particular, we study the effect of using learnable STRFs compared to static STRFs or unconstrained kernels. We also show that our system consistently improves a competitive baseline system across a wide range of signal-to-noise ratios on spoofing detection in the presence of VTD distractor noise.      
### 17.Multi-agent Bayesian Learning with Adaptive Strategies: Convergence and Stability  [ :arrow_down: ](https://arxiv.org/pdf/2010.09128.pdf)
>  We study learning dynamics induced by strategic agents who repeatedly play a game with an unknown payoff-relevant parameter. In each step, an information system estimates a belief distribution of the parameter based on the players' strategies and realized payoffs using Bayes' rule. Players adjust their strategies by accounting for an equilibrium strategy or a best response strategy based on the updated belief. We prove that beliefs and strategies converge to a fixed point with probability 1. We also provide conditions that guarantee local and global stability of fixed points. Any fixed point belief consistently estimates the payoff distribution given the fixed point strategy profile. However, convergence to a complete information Nash equilibrium is not always guaranteed. We provide a sufficient and necessary condition under which fixed point belief recovers the unknown parameter. We also provide a sufficient condition for convergence to complete information equilibrium even when parameter learning is incomplete.      
### 18.Wireless Control for Smart Manufacturing: Recent Approaches and Open Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2010.09087.pdf)
>  Smart manufacturing aims to overcome the limitations of today's rigid assembly lines by making the material flow and manufacturing process more flexible, versatile, and scalable. The main economic drivers are higher resource and cost efficiency as the manufacturers can more quickly adapt to changing market needs and also increase the lifespan of their production sites. The ability to close feedback loops fast and reliably over long distances among mobile robots, remote sensors, and human operators is a key enabler for smart manufacturing. Thus, this article provides a perspective on control and coordination over wireless networks. Based on an analysis of real-world use cases, we identify the main technical challenges that need to be solved to close the large gap between the current state of the art in industry and the vision of smart manufacturing. We discuss to what extent existing control-over-wireless solutions in the literature address those challenges, including our own approach toward a tight integration of control and wireless communication. In addition to a theoretical analysis of closed-loop stability, practical experiments on a cyber-physical testbed demonstrate that our approach supports relevant smart manufacturing scenarios. The article concludes with a discussion of open challenges and future research directions.      
### 19.Sparse Symmetric Linear Arrays with Contiguous Sum and Difference Co-array  [ :arrow_down: ](https://arxiv.org/pdf/2010.08977.pdf)
>  Sparse arrays can resolve significantly more scatterers or sources than sensor by utilizing the co-array - a virtual array structure consisting of pairwise differences or sums of sensor positions. Although several sparse array configurations have been developed for passive sensing applications, far fewer active array designs exist. In active sensing, the sum co-array is typically more relevant than the difference co-array, especially when the scatterers are fully coherent. This paper proposes a general symmetric array configuration suitable for both active and passive sensing. We first derive necessary and sufficient conditions for the sum and difference co-array of this array to be contiguous. We then study two specific instances based on the Nested array and the Kløve-Mossige basis, respectively. In particular, we establish the relationship between the minimum-redundancy solutions of the two resulting symmetric array configurations, and the previously proposed Concatenated Nested Array (CNA) and Kløve Array (KA). Both the CNA and KA have closed-form expressions for the sensor positions, which means that they can be easily generated for any desired array size. The two arrays structures also achieve low redundancy, and a contiguous sum and difference co-array, which allows resolving vastly more coherent scatterers or incoherent sources than sensors.      
### 20.Block Coordinate Descent Algorithms for Auxiliary-function-based Independent Vector Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2010.08959.pdf)
>  In this paper, we address the problem of extracting all super-Gaussian source signals from a linear mixture in which (i) the number of super-Gaussian sources $K$ is less than that of sensors $M$, and (ii) there are up to $M - K$ stationary Gaussian noises that do not need to be extracted. To solve this problem, independent vector extraction (IVE) using a majorization minimization and block coordinate descent (BCD) algorithms has been developed, attaining robust source extraction and low computational cost. We here improve the conventional BCDs for IVE by carefully exploiting the stationarity of the Gaussian noise components. We also newly develop a BCD for a semiblind IVE in which the transfer functions for several super-Gaussian sources are given a priori. Both algorithms consist of a closed-form formula and a generalized eigenvalue decomposition. In a numerical experiment of extracting speech signals from noisy mixtures, we show that when $K = 1$ in a blind case or at least $K - 1$ transfer functions are given in a semiblind case, the convergence speeds of the new BCDs are significantly faster than those of the conventional ones.      
### 21.Shape Constrained CNN for Cardiac MR Segmentation with Simultaneous Prediction of Shape and Pose Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2010.08952.pdf)
>  Semantic segmentation using convolutional neural networks (CNNs) is the state-of-the-art for many medical segmentation tasks including left ventricle (LV) segmentation in cardiac MR images. However, a drawback is that these CNNs lack explicit shape constraints, occasionally resulting in unrealistic segmentations. In this paper, we perform LV and myocardial segmentation by regression of pose and shape parameters derived from a statistical shape model. The integrated shape model regularizes predicted segmentations and guarantees realistic shapes. Furthermore, in contrast to semantic segmentation, it allows direct calculation of regional measures such as myocardial thickness. We enforce robustness of shape and pose prediction by simultaneously constructing a segmentation distance map during training. We evaluated the proposed method in a fivefold cross validation on a in-house clinical dataset with 75 subjects containing a total of 1539 delineated short-axis slices covering LV from apex to base, and achieved a correlation of 99% for LV area, 94% for myocardial area, 98% for LV dimensions and 88% for regional wall thicknesses. The method was additionally validated on the LVQuan18 and LVQuan19 public datasets and achieved state-of-the-art results.      
### 22.MyWear: A Smart Wear for Continuous Body Vital Monitoring and Emergency Alert  [ :arrow_down: ](https://arxiv.org/pdf/2010.08866.pdf)
>  Smart healthcare which is built as healthcare Cyber-Physical System (H-CPS) from Internet-of-Medical-Things (IoMT) is becoming more important than before. Medical devices and their connectivity through Internet with alongwith the electronics health record (EHR) and AI analytics making H-CPS possible. IoMT-end devices like wearables and implantables are key for H-CPS based smart healthcare. Smart garment is a specific wearable which can be used for smart healthcare. There are various smart garments that help users to monitor their body vitals in real-time. Many commercially available garments collect the vital data and transmit it to the mobile application for visualization. However, these don't perform real-time analysis for the user to comprehend their health conditions. Also, such garments are not included with an alert system to alert users and contacts in case of emergency. In MyWear, we propose a wearable body vital monitoring garment that captures physiological data and automatically analyses such heart rate, stress level, muscle activity to detect abnormalities. A copy of the physiological data is transmitted to the cloud for detecting any abnormalities in heart beats and predict any potential heart failure in future. We also propose a deep neural network (DNN) model that automatically classifies abnormal heart beat and potential heart failure. For immediate assistance in such a situation, we propose an alert system that sends an alert message to nearby medical officials. The proposed MyWear has an average accuracy of 96.9% and precision of 97.3% for detection of the abnormalities.      
### 23.Discriminability of Single-Layer Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.08847.pdf)
>  Network data can be conveniently modeled as a graph signal, where data values are assigned to nodes of a graph that describes the underlying network topology. Successful learning from network data is built upon methods that effectively exploit this graph structure. Graph neural networks (GNNs) are one such method that has exhibited promising performance. Understanding why GNNs work so well is of paramount importance, particularly in applications involving physical networks. We focus on the property of discriminability and establish conditions under which the inclusion of pointwise nonlinearities to a stable graph filter bank can potentially lead to an increased discriminability of high-eigenvalue content. We define a notion of discriminability tied to the stability of the architecture, show that GNNs are at least as discriminable as linear graph filter banks, and characterize the signals that cannot be discriminated by either.      
### 24.PLS for V2I Communications Using Friendly Jammer and Double kappa-mu Shadowed Fading  [ :arrow_down: ](https://arxiv.org/pdf/2010.08827.pdf)
>  The concept of intelligent transportation systems (ITS) is considered to be a highly promising area of research due to its diversity of unique features. It is based mainly on the wireless vehicular network (WVN), where vehicles can perform sophisticated services such as sharing real-time safety information. To ensure high-quality service, WVN needs to solve the security challenges like eavesdropping, where malicious entities try to intercept the confidential transmitted signal. In this paper, we are going to provide a security scheme under the Double kappa-mu Shadowed fading. Our solution is based on the use of a friendly jammer that will transmit an artificial noise (AN) to jam the attacker's link and decrease its eavesdropping performances. To evaluate the efficiency of our solution, we investigated the outage probability for two special cases: Nakagami-m and Rician shadowed while taking into consideration the density of the blockage and the shadowing effects. We also studied the average secrecy capacity via deriving closed-form expressions of the ergodic capacity at the legitimate receiver and the attacker for the special case: Nakagami-m fading distribution.      
### 25.About Robustness of Control Systems Embedding an Internal Model  [ :arrow_down: ](https://arxiv.org/pdf/2010.08794.pdf)
>  Robustness is a basic property of any control system. In the context of linear output regulation, it was proved that embedding an internal model of the exogenous signals is necessary and sufficient to achieve tracking of the desired reference signals in spite of external disturbances and parametric uncertainties. This result is commonly known as "internal model principle". A complete extension of such linear result to general nonlinear systems is still an open problem, which is exacerbated by the large number of alternative definitions of uncertainty and desired control goals that are possible in a nonlinear setting. In this paper, we develop a general framework in which all these different notions can be formally characterized in a unifying way. Classical results are reinterpreted in the proposed setting, and new results and insights are presented with a focus on robust rejection/tracking of arbitrary harmonic content. Moreover, we show by counter-example that, in the relevant case of continuous unstructured uncertainties, there are problems for which no smooth finite-dimensional robust regulator exists ensuring exact regulation.      
### 26.Exploring the Design Space of Lunar GNSS in Frozen Orbit Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2010.08706.pdf)
>  The past decade has witnessed a growing interest in lunar exploration missions. The autonomy of lunar surface and in-orbit missions is, however, dependent on accurate and instantaneous navigation services. These services can not be provided by current Global Navigation Satellite Systems (GNSS) whose signals suffer from poor geometry and coverage in the vicinity of the Moon. Preliminary results of a systems architecture study on a new satellite navigation system orbiting the moon are presented. Lunar frozen orbit conditions under J2, C22 and third-body perturbations are assumed. The formulation includes the following design decisions: (1) Orbit semi-major axis, (2) Number of satellites, (3) Number of orbital planes, (4) Satellite phasing in adjacent planes, (5) Orbit eccentricity and (6) Argument of periapsis.The Borg Multi-Objective Evolutionary Algorithm (MOEA) framework is used to optimize the satellite constellation design problem, with a fitness function that takes into account performance, cost, availability and station-keeping deltaV. The performance metric is based on the Geometric Dilution of Precision (GDOP), which is computed over a grid of 500 equidistant points on the lunar surface. Additionally, the input satellite orbits used in the GDOP computation are obtained from high-fidelity orbit propagation using NASA General Mission Analysis Toolbox. Finally, satellite costs are based on satellite dry mass estimates derived from the power budget analysis assuming a satellite lifetime of 10 years. Results show that Lunar GNSS constellation with 20 satellites at frozen orbits can achieve satisfactory performance at mid-latitudes but not at the poles.      
### 27.Reinforcement Learning for Efficient and Tuning-Free Link Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2010.08651.pdf)
>  Link adaptation (LA) optimizes the selection of modulation and coding schemes (MCS) for a stochastic wireless channel. The classical outer loop LA (OLLA) tracks the channel's signal-to-noise-and-interference ratio (SINR) based on the observed transmission outcomes. On the other hand, recent Reinforcement learning LA (RLLA) schemes sample the available MCSs to optimize the link performance objective. However, both OLLA and RLLA rely on tuning parameters that are challenging to configure. Further, OLLA optimizes for a target block error rate (BLER) that only indirectly relates to the common throughput-maximization objective, while RLLA does not fully exploit the inter-dependence between the MCSs. In this paper, we propose latent Thompson Sampling for LA (LTSLA), a RLLA scheme that does not require configuration tuning, and which fully exploits MCS inter-dependence for efficient learning. LTSLA models an SINR probability distribution for MCS selection, and refines this distribution through Bayesian updates with the transmission outcomes. LTSLA also automatically adapts to different channel fading profiles by utilizing their respective Doppler estimates. We perform simulation studies of LTSLA along with OLLA and RLLA schemes for frequency selective fading channels. Numerical results demonstrate that LTSLA improves the instantaneous link throughout by up to 50% compared to existing schemes.      
### 28.GFB-MRF: A parallel spatial and Bloch manifold regularized iterative reconstruction method for MR Fingerprinting  [ :arrow_down: ](https://arxiv.org/pdf/2010.08640.pdf)
>  Magnetic Resonance Fingerprinting (MRF) reconstructs tissue maps based on a sequence of very highly undersampled images. In order to be able to perform MRF reconstruction, state-of-the-art MRF methods rely on priors such as the MR physics (Bloch equations) and might also use some additional low-rank or spatial regularization. However to our knowledge these three regularizations are not applied together in a joint reconstruction. The reason is that it is indeed challenging to incorporate effectively multiple regularizations in a single MRF optimization algorithm. As a result most of these methods are not robust to noise especially when the sequence length is short. In this paper, we propose a family of new methods where spatial and low-rank regularizations, in addition to the Bloch manifold regularization, are applied on the images. We show on digital phantom and NIST phantom scans, as well as volunteer scans that the proposed methods bring significant improvement in the quality of the estimated tissue maps.      
### 29.Adaptive Gradient Search Beamforming for Full-Duplex mmWave MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.08630.pdf)
>  In this work, we present a framework analysis of full-duplex (FD) systems for Millimeter Wave (mmWave) analog architecture. Given that FD systems can double the ergodic capacity, such systems experience large losses caused by the loopback self-interference (SI). In addition, systems with analog architecture also suffer from other forms of losses mainly incurred by the constant amplitude (CA) constraint. For this purpose, we propose the projected Gradient Ascent algorithm to maximize the sum rate under the unit-norm and CA constraints. Unlike previous works, our approach achieves the best spectral efficiency while minimizing the losses incurred by the CA constraint. We also consider an adaptive step size to compensate for the perturbations that may affect the cost function during the optimization. The results will show that the proposed algorithm converges to the same optimal value for different initializations while the number of iterations required for the convergence changes for each case. In this context, we primarily consider the gradient search method for a two-nodes FD systems and then we extend the analysis for a dual-hop FD relaying systems. Finally, we evaluate the robustness of our method in terms of rate and outage probability and compare with previous approaches.      
### 30.Hierarchical Reinforcement Learning for Optimal Control of Linear Multi-Agent Systems: the Homogeneous Case  [ :arrow_down: ](https://arxiv.org/pdf/2010.08615.pdf)
>  Individual agents in a multi-agent system (MAS) may have decoupled open-loop dynamics, but a cooperative control objective usually results in coupled closed-loop dynamics thereby making the control design computationally expensive. The computation time becomes even higher when a learning strategy such as reinforcement learning (RL) needs to be applied to deal with the situation when the agents dynamics are not known. To resolve this problem, this paper proposes a hierarchical RL scheme for a linear quadratic regulator (LQR) design in a continuous-time linear MAS. The idea is to exploit the structural properties of two graphs embedded in the $Q$ and $R$ weighting matrices in the LQR objective to define an orthogonal transformation that can convert the original LQR design to multiple decoupled smaller-sized LQR designs. We show that if the MAS is homogeneous then this decomposition retains closed-loop optimality. Conditions for decomposability, an algorithm for constructing the transformation matrix, a hierarchical RL algorithm, and robustness analysis when the design is applied to non-homogeneous MAS are presented. Simulations show that the proposed approach can guarantee significant speed-up in learning without any loss in the cumulative value of the LQR cost.      
### 31.CT Image Segmentation for Inflamed and Fibrotic Lungs Using a Multi-Resolution Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2010.08582.pdf)
>  The purpose of this study was to develop a fully-automated segmentation algorithm, robust to various density enhancing lung abnormalities, to facilitate rapid quantitative analysis of computed tomography images. A polymorphic training approach is proposed, in which both specifically labeled left and right lungs of humans with COPD, and nonspecifically labeled lungs of animals with acute lung injury, were incorporated into training a single neural network. The resulting network is intended for predicting left and right lung regions in humans with or without diffuse opacification and consolidation. Performance of the proposed lung segmentation algorithm was extensively evaluated on CT scans of subjects with COPD, confirmed COVID-19, lung cancer, and IPF, despite no labeled training data of the latter three diseases. Lobar segmentations were obtained using the left and right lung segmentation as input to the LobeNet algorithm. Regional lobar analysis was performed using hierarchical clustering to identify radiographic subtypes of COVID-19. The proposed lung segmentation algorithm was quantitatively evaluated using semi-automated and manually-corrected segmentations in 87 COVID-19 CT images, achieving an average symmetric surface distance of $0.495 \pm 0.309$ mm and Dice coefficient of $0.985 \pm 0.011$. Hierarchical clustering identified four radiographical phenotypes of COVID-19 based on lobar fractions of consolidated and poorly aerated tissue. Lower left and lower right lobes were consistently more afflicted with poor aeration and consolidation. However, the most severe cases demonstrated involvement of all lobes. The polymorphic training approach was able to accurately segment COVID-19 cases with diffuse consolidation without requiring COVID-19 cases for training.      
### 32.Non-intrusive speech intelligibility prediction using automatic speech recognition derived measures  [ :arrow_down: ](https://arxiv.org/pdf/2010.08574.pdf)
>  The estimation of speech intelligibility is still far from being a solved problem. Especially one aspect is problematic: most of the standard models require a clean reference signal in order to estimate intelligibility. \delete{This is a problem in two respects. A reference signal is often unavailable in practice. Also, comparing the signal with a reference leads to unrealistic results when speech signals processing is carried out with the help of a recognize\&amp;synthesize approach, where the voice of the speaker is replaced by that of a synthesizer.} \add{This is an issue of some significance, as a reference signal is often unavailable in practice.} In this work, therefore a \delete{fully reference-free} \add{non-intrusive} speech intelligibility estimation framework is presented. In it, human listeners' performance in keyword recognition tasks is predicted using intelligibility measures that are derived from models trained for automatic speech recognition (ASR). One such ASR-based and one signal-based measure are combined into a full framework, the proposed \emph{NO-Reference Intelligibility} (\NORI{}) estimator, which is evaluated in predicting the performance of both normal-hearing and hearing-impaired listeners in multiple noise conditions. It is shown that the \NORI{} framework even outperforms the widely used reference-based \add{(or intrusive)} short-term objective intelligibility (STOI) measure in most considered scenarios, while being applicable in fully blind scenarios \add{with no reference signal or transcription}, creating perspectives for online and personalized optimization of speech enhancement systems.      
### 33.DAN -- An optimal Data Assimilation framework based on machine learning Recurrent Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.09694.pdf)
>  Data assimilation algorithms aim at forecasting the state of a dynamical system by combining a mathematical representation of the system with noisy observations thereof. We propose a fully data driven deep learning architecture generalizing recurrent Elman networks and data assimilation algorithms which provably reaches the same prediction goals as the latter. On numerical experiments based on the well-known Lorenz system and when suitably trained using snapshots of the system trajectory (i.e. batches of state trajectories) and observations, our architecture successfully reconstructs both the analysis and the propagation of probability density functions of the system state at a given time conditioned to past observations.      
### 34.MicAugment: One-shot Microphone Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2010.09658.pdf)
>  A crucial aspect for the successful deployment of audio-based models "in-the-wild" is the robustness to the transformations introduced by heterogeneous acquisition conditions. In this work, we propose a method to perform one-shot microphone style transfer. Given only a few seconds of audio recorded by a target device, MicAugment identifies the transformations associated to the input acquisition pipeline and uses the learned transformations to synthesize audio as if it were recorded under the same conditions as the target audio. We show that our method can successfully apply the style transfer to real audio and that it significantly increases model robustness when used as data augmentation in the downstream tasks.      
### 35.Agent-based Simulation Model and Deep Learning Techniques to Evaluate and Predict Transportation Trends around COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2010.09648.pdf)
>  The COVID-19 pandemic has affected travel behaviors and transportation system operations, and cities are grappling with what policies can be effective for a phased reopening shaped by social distancing. This edition of the white paper updates travel trends and highlights an agent-based simulation model's results to predict the impact of proposed phased reopening strategies. It also introduces a real-time video processing method to measure social distancing through cameras on city streets.      
### 36.LoRa Performance Analysis with Superposed Signal Decoding  [ :arrow_down: ](https://arxiv.org/pdf/2010.09625.pdf)
>  This paper considers the use of successive interference cancellation (SIC) to decode superposed signals in Long Range (LoRa) networks. We build over a known stochastic geometry model for LoRa networks and include the effect of recovering colliding packets through SIC. We derive closed-form expressions for the successful decoding of packets using SIC taking path loss, fading, noise, and interference into account, while we validate the model by means of Monte Carlo simulations. Results show that SIC-enabled LoRa networks improve worst-case reliability by up to 34%. We show that, for at least one test scenario, SIC increases by 159% the number of served users with the same worst-case reliability level.      
### 37.Aerial Mobile Manipulator System to Enable Dexterous Manipulations with Increased Precision  [ :arrow_down: ](https://arxiv.org/pdf/2010.09618.pdf)
>  Problems associated with physical interactions using aerial mobile manipulators (AMM) are being independently addressed with respect to mobility and manipulability. Multirotor unmanned aerial vehicles (UAV) are a common choice for mobility while on-board manipulators are increasingly be used for manipulability. However, the dynamic coordination between the UAV and on-board manipulator remains a significant obstacle to enable dexterous manipulation with high precision. This paper presents an AMM system configuration to addresses both the mobility and manipulability issues together. A fully-actuated UAV is chosen to achieve dexterous aerial mobile manipulation, but is limited by the actuation range of the UAV. An on-board manipulator is employed to enhance the performance in terms of dexterity and precision at the end-effector. Experimental results on position keeping of the dexterous hexrotor by withstanding the disturbances caused by the motions of the on-board manipulator and external wind disturbances are presented. Preliminary simulation results on end-point tracking in a simple planar on-board manipulator case is presented.      
### 38.Inspection-on-the-fly using Hybrid Physical Interaction Control for Aerial Manipulators  [ :arrow_down: ](https://arxiv.org/pdf/2010.09605.pdf)
>  Inspection for structural properties (surface stiffness and coefficient of restitution) is crucial for understanding and performing aerial manipulations in unknown environments, with little to no prior knowledge on their state. Inspection-on-the-fly is the uncanny ability of humans to infer states during manipulation, reducing the necessity to perform inspection and manipulation separately. This paper presents an infrastructure for inspection-on-the-fly method for aerial manipulators using hybrid physical interaction control. With the proposed method, structural properties (surface stiffness and coefficient of restitution) can be estimated during physical interactions. A three-stage hybrid physical interaction control paradigm is presented to robustly approach, acquire and impart a desired force signature onto a surface. This is achieved by combining a hybrid force/motion controller with a model-based feed-forward impact control as intermediate phase. The proposed controller ensures a steady transition from unconstrained motion control to constrained force control, while reducing the lag associated with the force control phase. And an underlying Operational Space dynamic configuration manager permits complex, redundant vehicle/arm combinations. Experiments were carried out in a mock-up of a Dept. of Energy exhaust shaft, to show the effectiveness of the inspection-on-the-fly method to determine the structural properties of the target surface and the performance of the hybrid physical interaction controller in reducing the lag associated with force control phase.      
### 39.Learning to Reconstruct and Segment 3D Objects  [ :arrow_down: ](https://arxiv.org/pdf/2010.09582.pdf)
>  To endow machines with the ability to perceive the real-world in a three dimensional representation as we do as humans is a fundamental and long-standing topic in Artificial Intelligence. Given different types of visual inputs such as images or point clouds acquired by 2D/3D sensors, one important goal is to understand the geometric structure and semantics of the 3D environment. Traditional approaches usually leverage hand-crafted features to estimate the shape and semantics of objects or scenes. However, they are difficult to generalize to novel objects and scenarios, and struggle to overcome critical issues caused by visual occlusions. By contrast, we aim to understand scenes and the objects within them by learning general and robust representations using deep neural networks, trained on large-scale real-world 3D data. To achieve these aims, this thesis makes three core contributions from object-level 3D shape estimation from single or multiple views to scene-level semantic understanding.      
### 40.Learning a Low-dimensional Representation of a Safe Region for Safe Reinforcement Learning on Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.09555.pdf)
>  For safely applying reinforcement learning algorithms on high-dimensional nonlinear dynamical systems, a simplified system model is used to formulate a safe reinforcement learning framework. Based on the simplified system model, a low-dimensional representation of the safe region is identified and is used to provide safety estimates for learning algorithms. However, finding a satisfying simplified system model for complex dynamical systems usually requires a considerable amount of effort. To overcome this limitation, we propose in this work a general data-driven approach that is able to efficiently learn a low-dimensional representation of the safe region. Through an online adaptation method, the low-dimensional representation is updated by using the feedback data such that more accurate safety estimates are obtained. The performance of the proposed approach for identifying the low-dimensional representation of the safe region is demonstrated with a quadcopter example. The results show that, compared to previous work, a more reliable and representative low-dimensional representation of the safe region is derived, which then extends the applicability of the safe reinforcement learning framework.      
### 41.CLAR: Contrastive Learning of Auditory Representations  [ :arrow_down: ](https://arxiv.org/pdf/2010.09542.pdf)
>  Learning rich visual representations using contrastive self-supervised learning has been extremely successful. However, it is still a major question whether we could use a similar approach to learn superior auditory representations. In this paper, we expand on prior work (SimCLR) to learn better auditory representations. We (1) introduce various data augmentations suitable for auditory data and evaluate their impact on predictive performance, (2) show that training with time-frequency audio features substantially improves the quality of the learned representations compared to raw signals, and (3) demonstrate that training with both supervised and contrastive losses simultaneously improves the learned representations compared to self-supervised pre-training followed by supervised fine-tuning. We illustrate that by combining all these methods and with substantially less labeled data, our framework (CLAR) achieves significant improvement on prediction performance compared to supervised approach. Moreover, compared to self-supervised approach, our framework converges faster with significantly better representations.      
### 42.Limit Behavior and the Role of Augmentation in Projected Saddle Flows for Convex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.09496.pdf)
>  In this paper, we study the stability and convergence of continuous-time Lagrangian saddle flows to solutions of a convex constrained optimization problem. Convergence of these flows is well-known when the underlying saddle function is either strictly convex in the primal or strictly concave in the dual variables. In this paper, we show convergence under non-strict convexity when a simple, unilateral augmentation term is added. For this purpose, we establish a novel, non-trivial characterization of the limit set of saddle-flow trajectories that allows us to preclude limit cycles. With our presentation we try to unify several existing problem formulations as a projected dynamical system that allows projection of both the primal and dual variables, thus complementing results available in the recent literature.      
### 43.Information-Theoretic Bounds on Transfer Generalization Gap Based on Jensen-Shannon Divergence  [ :arrow_down: ](https://arxiv.org/pdf/2010.09484.pdf)
>  In transfer learning, training and testing data sets are drawn from different data distributions. The transfer generalization gap is the difference between the population loss on the target data distribution and the training loss. The training data set generally includes data drawn from both source and target distributions. This work presents novel information-theoretic upper bounds on the average transfer generalization gap that capture (i) the domain shift between the target data distribution $P'_Z$ and and the source distribution $P_Z$ through Nielsen's family of $\alpha$-Jensen-Shannon (JS) divergences $D_{JS}^{\alpha}(P'_Z || P_Z)$; and (ii) the sensitivity of the transfer learner output $W$ to each individual sample of the data set $Z_i$ via the mutual information $I(W;Z_i)$. The $\alpha$-JS divergence is bounded even when the support of $P_Z$ is not included in that of $P'_Z$ . This contrasts the Kullback- Leibler (KL) divergence $D_{KL}(P_Z||P'_Z)$-based bounds of Wu et al. [1], which are vacuous under this assumption. Moreover, the obtained bounds hold for unbounded loss functions with bounded cumulant generating functions, unlike the $\phi$-divergence based bound of Wu et al. We also obtain new upper bounds on the average transfer excess risk in terms of the $\alpha$-JS divergence for empirical weighted risk minimization (EWRM), which minimizes the weighted average training losses over source and target data sets. Finally, we provide a numerical example to illustrate the merits of the introduced bounds.      
### 44.Chance-Constrained Control with Lexicographic Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.09468.pdf)
>  This paper proposes a lexicographic Deep Reinforcement Learning (DeepRL)-based approach to chance-constrained Markov Decision Processes, in which the controller seeks to ensure that the probability of satisfying the constraint is above a given threshold. Standard DeepRL approaches require i) the constraints to be included as additional weighted terms in the cost function, in a multi-objective fashion, and ii) the tuning of the introduced weights during the training phase of the Deep Neural Network (DNN) according to the probability thresholds. The proposed approach, instead, requires to separately train one constraint-free DNN and one DNN associated to each constraint and then, at each time-step, to select which DNN to use depending on the system observed state. The presented solution does not require any hyper-parameter tuning besides the standard DNN ones, even if the probability thresholds changes. A lexicographic version of the well-known DeepRL algorithm DQN is also proposed and validated via simulations.      
### 45.Fast accuracy estimation of deep learning based multi-class musical source separation  [ :arrow_down: ](https://arxiv.org/pdf/2010.09453.pdf)
>  Music source separation represents the task of extracting all the instruments from a given song. Recent breakthroughs on this challenge have gravitated around a single dataset, MUSDB, that is limited to four instrument classes only. New datasets are required to extend to other instruments and increase the performances. However larger datasets are costly and time-consuming in terms of collecting data and training deep networks. In this work, we propose a fast method for evaluating the separability of instruments in any dataset or song, and for any instrument without the need to train and tune a deep neural network. This separability measure helps selecting appropriate samples for the efficient training of neural networks. Our approach, based on the oracle principle with an ideal ratio mask, is a good proxy to estimate the separation performances of state-of-the-art deep learning approaches based on time-frequency masking such as TasNet or Open-Unmix. The proposed fast accuracy estimation method can significantly speed up the music source separation system's development process.      
### 46.Ensemble Chinese End-to-End Spoken Language Understanding for Abnormal Event Detection from audio stream  [ :arrow_down: ](https://arxiv.org/pdf/2010.09235.pdf)
>  Conventional spoken language understanding (SLU) consist of two stages, the first stage maps speech to text by automatic speech recognition (ASR), and the second stage maps text to intent by natural language understanding (NLU). End-to-end SLU maps speech directly to intent through a single deep learning model. Previous end-to-end SLU models are primarily used for English environment due to lacking large scale SLU dataset in Chines, and use only one ASR model to extract features from speech. With the help of Kuaishou technology, a large scale SLU dataset in Chinese is collected to detect abnormal event in their live audio stream. Based on this dataset, this paper proposed a ensemble end-to-end SLU model used for Chinese environment. This ensemble SLU models extracted hierarchies features using multiple pre-trained ASR models, leading to better representation of phoneme level and word level information. This proposed approached achieve 9.7% increase of accuracy compared to previous end-to-end SLU model.      
### 47.CT-CPP: 3D Coverage Path Planning for Unknown Terrain Reconstruction using Coverage Trees  [ :arrow_down: ](https://arxiv.org/pdf/2010.09231.pdf)
>  This letter addresses the 3D coverage path planning (CPP) problem for terrain reconstruction of unknown obstacle rich environments. Due to sensing limitations, the proposed method, called CT-CPP, performs layered scanning of the 3D region to collect terrain data, where the traveling sequence is optimized using the concept of a coverage tree (CT). A modified TSP-based tree traversal strategy is proposed, and compared with breadth-first search (BFS) and depth-first search (DFS) methods, with TSP providing the shortest trajectory lengths. The CT-CPP method is validated on a high-fidelity underwater simulator and the results are evaluated in comparison to an existing terrain following CPP method (TF-CPP). The CT-CPP with TSP optimizer yields significant improvements in trajectory length, energy consumption, and reconstruction error.      
### 48.Joint Analysis of Sound Events and Acoustic Scenes Using Multitask Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.09213.pdf)
>  Sound event detection (SED) and acoustic scene classification (ASC) are important research topics in environmental sound analysis. Many research groups have addressed SED and ASC using neural-network-based methods, such as the convolutional neural network (CNN), recurrent neural network (RNN), and convolutional recurrent neural network (CRNN). The conventional methods address SED and ASC separately even though sound events and acoustic scenes are closely related to each other. For example, in the acoustic scene "office," the sound events "mouse clicking" and "keyboard typing" are likely to occur. Therefore, it is expected that information on sound events and acoustic scenes will be of mutual aid for SED and ASC. In this paper, we propose multitask learning for joint analysis of sound events and acoustic scenes, in which the parts of the networks holding information on sound events and acoustic scenes in common are shared. Experimental results obtained using the TUT Sound Events 2016/2017 and TUT Acoustic Scenes 2016 datasets indicate that the proposed method improves the performance of SED and ASC by 1.31 and 1.80 percentage points in terms of the F-score, respectively, compared with the conventional CRNN-based method.      
### 49.Self-Attention Generative Adversarial Network for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2010.09132.pdf)
>  Existing generative adversarial networks (GANs) for speech enhancement solely rely on the convolution operation, which may obscure temporal dependencies across the sequence input. To remedy this issue, we propose a self-attention layer adapted from non-local attention, coupled with the convolutional and deconvolutional layers of a speech enhancement GAN (SEGAN) using raw signal input. Further, we empirically study the effect of placing the self-attention layer at the (de)convolutional layers with varying layer indices as well as at all of them when memory allows. Our experiments show that introducing self-attention to SEGAN leads to consistent improvement across the objective evaluation metrics of enhancement performance. Furthermore, applying at different (de)convolutional layers does not significantly alter performance, suggesting that it can be conveniently applied at the highest-level (de)convolutional layer with the smallest memory overhead.      
### 50.Fundamentals of Physical Layer Anonymous Communications: Sender Detection and Anonymous Precoding  [ :arrow_down: ](https://arxiv.org/pdf/2010.09122.pdf)
>  In the era of big data, anonymity is recognized as an important attribute in privacy-preserving communications. The existing anonymous authentication and routing are applied at higher layers of networks, ignoring physical layer (PHY) also contains privacy-critical information. In this paper, we introduce the concept of PHY anonymity, and reveal that the receiver can unmask the sender's identity by only analyzing the PHY information, i.e., the signaling patterns and the characteristics of channel. We investigate two practical scenarios, where the receiver has more antennas than the sender in the strong receiver case, and vice versa in the strong sender case. For each scenario, we first investigate sender detection strategy at the receiver, and then we develop corresponding anonymous precoding to address anonymity while guaranteeing high receive signal-to-interference-plus-noise-ratio (SINR) for communications. In particular, an interference suppression anonymous precoder is first proposed, assisted by a dedicated transmit phase equalizer for removing phase ambiguity. Afterwards, a constructive interference anonymous precoder is further investigated to utilize the inter-antenna interference as a beneficial element without loss of sender's anonymity. Simulation demonstrates the proposed anonymous precoders are able to preserve the sender's anonymity and simultaneously guarantee high receive SINR, opening a new dimension on PHY anonymous designs.      
### 51.Real-time Quadrotor Navigation Through Planning in Depth Space in Unstructured Environments  [ :arrow_down: ](https://arxiv.org/pdf/2010.09098.pdf)
>  This paper addresses the problem of real-time vision-based autonomous obstacle avoidance in unstructured environments for quadrotor UAVs. We assume that our UAV is equipped with a forward facing stereo camera as the only sensor to perceive the world around it. Moreover, all the computations are performed onboard. Feasible trajectory generation in this kind of problems requires rapid collision checks along with efficient planning algorithms. We propose a trajectory generation approach in the depth image space, which refers to the environment information as depicted by the depth images. In order to predict the collision in a look ahead robot trajectory, we create depth images from the sequence of robot poses along the path. We compare these images with the depth images of the actual world sensed through the forward facing stereo camera. We aim at generating fuel optimal trajectories inside the depth image space. In case of a predicted collision, a switching strategy is used to aggressively deviate the quadrotor away from the obstacle. For this purpose we use two closed loop motion primitives based on Linear Quadratic Regulator (LQR) objective functions. The proposed approach is validated through simulation and hardware experiments.      
### 52.Addressing Variance Shrinkage in Variational Autoencoders using Quantile Regression  [ :arrow_down: ](https://arxiv.org/pdf/2010.09042.pdf)
>  Estimation of uncertainty in deep learning models is of vital importance, especially in medical imaging, where reliance on inference without taking into account uncertainty could lead to misdiagnosis. Recently, the probabilistic Variational AutoEncoder (VAE) has become a popular model for anomaly detection in applications such as lesion detection in medical images. The VAE is a generative graphical model that is used to learn the data distribution from samples and then generate new samples from this distribution. By training on normal samples, the VAE can be used to detect inputs that deviate from this learned distribution. The VAE models the output as a conditionally independent Gaussian characterized by means and variances for each output dimension. VAEs can therefore use reconstruction probability instead of reconstruction error for anomaly detection. Unfortunately, joint optimization of both mean and variance in the VAE leads to the well-known problem of shrinkage or underestimation of variance. We describe an alternative approach that avoids this variance shrinkage problem by using quantile regression. Using estimated quantiles to compute mean and variance under the Gaussian assumption, we compute reconstruction probability as a principled approach to outlier or anomaly detection. Results on simulated and Fashion MNIST data demonstrate the effectiveness of our approach. We also show how our approach can be used for principled heterogeneous thresholding for lesion detection in brain images.      
### 53.Scenario-decomposition Solution Framework for Nonseparable Stochastic Control Problems  [ :arrow_down: ](https://arxiv.org/pdf/2010.08985.pdf)
>  When stochastic control problems do not possess separability and/or monotonicity, the dynamic programming pioneered by Bellman in 1950s fails to work as a time-decomposition solution method. Such cases have posted a great challenge to the control society in both theoretical foundation and solution methodologies for many years. With the help of the progressive hedging algorithm proposed by Rockafellar and Wets in 1991, we develop a novel scenario-decomposition solution framework for stochastic control problems which could be nonseparable and/or non-monotonic, thus extending the reach of stochastic optimal control. We discuss then some of its promising applications, including online quadratic programming problems and dynamic portfolio selection problems with smoothing properties.      
### 54.Nonlinear Interference Analysis of Probabilistic Shaping vs. 4D Geometrically Shaped Formats  [ :arrow_down: ](https://arxiv.org/pdf/2010.08981.pdf)
>  Performance trade-offs between linear shaping and nonlinear tolerance of the recently introduced 4D orthant-symmetric 128-ary modulation format are investigated. Numerical simulations show 9.3% reach increase with respect to the 7b4D-2A8PSK format and probabilistically-shaped 16QAM with short blocklength.      
### 55.Intelligent Reflecting Surface-Assisted Bistatic Backscatter Networks: Joint Beamforming and Reflection Design  [ :arrow_down: ](https://arxiv.org/pdf/2010.08947.pdf)
>  The passive communication of backscatter devices is a major limiting factor against its widespread deployment, as it requires the availability of a strong carrier signal. The recent uptake of intelligent reflecting surfaces (IRS), capable of significantly enhancing the performance of a range of communication systems, presents an opportunity to improve the flexibility of backscatter communication (BackCom). In this paper, we introduce a novel system setup where an IRS is utilized to assist a bistatic BackCom network consisting of a carrier emitter, one or more tags, and a reader. We study the transmit power minimization problem at the carrier emitter, wherein its transmit beamforming vector is jointly optimized with the IRS phase shifts, whilst guaranteeing a required BackCom performance. A unique feature in this system setup is the multiple IRS reflections experienced by signals traveling from the carrier emitter to the reader, which renders the optimization problem highly non-convex. Therefore, we propose algorithms based on the minorization-maximization and alternating optimization techniques to obtain approximate solutions for the joint design. We also propose low-complexity algorithms based on successive optimization of individual phase shifts. Our results indicate considerable transmit power savings for both single-tag and multi-tag systems, even with modest IRS sizes.      
### 56.Towards Data Distillation for End-to-end Spoken Conversational Question Answering  [ :arrow_down: ](https://arxiv.org/pdf/2010.08923.pdf)
>  In spoken question answering, QA systems are designed to answer questions from contiguous text spans within the related speech transcripts. However, the most natural way that human seek or test their knowledge is via human conversations. Therefore, we propose a new Spoken Conversational Question Answering task (SCQA), aiming at enabling QA systems to model complex dialogues flow given the speech utterances and text corpora. In this task, our main objective is to build a QA system to deal with conversational questions both in spoken and text forms, and to explore the plausibility of providing more cues in spoken documents with systems in information gathering. To this end, instead of adopting automatically generated speech transcripts with highly noisy data, we propose a novel unified data distillation approach, DDNet, which directly fuse audio-text features to reduce the misalignment between automatic speech recognition hypotheses and the reference transcriptions. In addition, to evaluate the capacity of QA systems in a dialogue-style interaction, we assemble a Spoken Conversational Question Answering (Spoken-CoQA) dataset with more than 120k question-answer pairs. Experiments demonstrate that our proposed method achieves superior performance in spoken conversational question answering.      
### 57.Disguising Personal Identity Information in EEG Signals  [ :arrow_down: ](https://arxiv.org/pdf/2010.08915.pdf)
>  There is a need to protect the personal identity information in public EEG datasets. However, it is challenging to remove such information that has infinite classes (open set). We propose an approach to disguise the identity information in EEG signals with dummy identities, while preserving the key features. The dummy identities are obtained by applying grand average on EEG spectrums across the subjects within a group that have common attributes. The personal identity information in original EEGs are transformed into disguised ones with a CycleGANbased EEG disguising model. With the constraints added to the model, the features of interest in EEG signals can be preserved. We evaluate the model by performing classification tasks on both the original and the disguised EEG and compare the results. For evaluation, we also experiment with ResNet classifiers, which perform well especially on the identity recognition task with an accuracy of 98.4%. The results show that our EEG disguising model can hide about 90% of personal identity information and can preserve most of the other key features.      
### 58.Prediction of daily maximum ozone levels using Lasso sparse modeling method  [ :arrow_down: ](https://arxiv.org/pdf/2010.08909.pdf)
>  This paper applies modern statistical methods in the prediction of the next-day maximum ozone concentration, as well as the maximum 8-hour-mean ozone concentration of the next day. The model uses a large number of candidate features, including the present day's hourly concentration level of various pollutants, as well as the meteorological variables of the present day's observation and the future day's forecast values. In order to solve such an ultra-high dimensional problem, the least absolute shrinkage and selection operator (Lasso) was applied. The $L_1$ nature of this methodology enables the automatic feature dimension reduction, and a resultant sparse model. The model trained by 3-years data demonstrates relatively good prediction accuracy, with RMSE= 5.63 ppb, MAE= 4.42 ppb for predicting the next-day's maximum $O_3$ concentration, and RMSE= 5.68 ppb, MAE= 4.52 ppb for predicting the next-day's maximum 8-hour-mean $O_3$ concentration. Our modeling approach is also compared with several other methods recently applied in the field and demonstrates superiority in the prediction accuracy.      
### 59.On the best choice of Lasso program given data parameters  [ :arrow_down: ](https://arxiv.org/pdf/2010.08884.pdf)
>  Generalized compressed sensing (GCS) is a paradigm in which a structured high-dimensional signal may be recovered from random, under-determined, and corrupted linear measurements. Generalized Lasso (GL) programs are effective for solving GCS problems due to their proven ability to leverage underlying signal structure. Three popular GL programs are equivalent in a sense and sometimes used interchangeably. Tuned by a governing parameter, each admit an optimal parameter choice. For sparse or low-rank signal structures, this choice yields minimax order-optimal error. While GCS is well-studied, existing theory for GL programs typically concerns this optimally tuned setting. However, the optimal parameter value for a GL program depends on properties of the data, and is typically unknown in practical settings. Performance in empirical problems thus hinges on a program's parameter sensitivity: it is desirable that small variation about the optimal parameter choice begets small variation about the optimal risk. We examine the risk for these three programs and demonstrate that their parameter sensitivity can differ for the same data. We prove a gauge-constrained GL program admits asymptotic cusp-like behaviour of its risk in the limiting low-noise regime. We prove that a residual-constrained Lasso program has asymptotically suboptimal risk for very sparse vectors. These results contrast observations about an unconstrained Lasso program, which is relatively less sensitive to its parameter choice. We support the asymptotic theory with numerical simulations, demonstrating that parameter sensitivity of GL programs is readily observed for even modest dimensional parameters. Importantly, these simulations demonstrate regimes in which a GL program exhibits sensitivity to its parameter choice, though the other two do not. We hope this work aids practitioners in selecting a GL program for their problem.      
### 60.Approximate information state for approximate planning and reinforcement learning in partially observed systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.08843.pdf)
>  We propose a theoretical framework for approximate planning and learning in partially observed systems. Our framework is based on the fundamental notion of information state. We provide two equivalent definitions of information state---i) a function of history which is sufficient to compute the expected reward and predict its next value; ii) equivalently, a function of the history which can be recursively updated and is sufficient to compute the expected reward and predict the next observation. An information state always leads to a dynamic programming decomposition. Our key result is to show that if a function of the history (called approximate information state (AIS)) approximately satisfies the properties of the information state, then there is a corresponding approximate dynamic program. We show that the policy computed using this is approximately optimal with bounded loss of optimality. We show that several approximations in state, observation and action spaces in literature can be viewed as instances of AIS. In some of these cases, we obtain tighter bounds. A salient feature of AIS is that it can be learnt from data. We present AIS based multi-time scale policy gradient algorithms. and detailed numerical experiments with low, moderate and high dimensional environments.      
### 61.Random Matrix Based Extended Target Tracking with Orientation: A New Model and Inference  [ :arrow_down: ](https://arxiv.org/pdf/2010.08820.pdf)
>  In this study, we propose a novel extended target tracking algorithm which is capable of representing the extent of dynamic objects as an ellipsoid with a time-varying orientation angle. A diagonal positive semi-definite matrix is defined to model objects' extent within the random matrix framework where the diagonal elements have inverse-Gamma priors. The resulting measurement equation is non-linear in the state variables, and it is not possible to find a closed-form analytical expression for the true posterior because of the absence of conjugacy. We use the variational Bayes technique to perform approximate inference, where the Kullback-Leibler divergence between the true and the approximate posterior is minimized by performing fixed-point iterations. The update equations are easy to implement, and the algorithm can be used in real-time tracking applications. We illustrate the performance of the method in simulations and experiments with real data. The proposed method outperforms the state-of-the-art methods when compared with respect to accuracy and robustness.      
### 62.Assessment of Reward Functions in Reinforcement Learning for Multi-Modal Urban Traffic Control under Real-World limitations  [ :arrow_down: ](https://arxiv.org/pdf/2010.08819.pdf)
>  Reinforcement Learning is proving a successful tool that can manage urban intersections with a fraction of the effort required to curate traditional traffic controllers. However, literature on the introduction and control of pedestrians to such intersections is scarce. Furthermore, it is unclear what traffic state variables should be used as reward to obtain the best agent performance. This paper robustly evaluates 30 different Reinforcement Learning reward functions for controlling intersections serving pedestrians and vehicles covering the main traffic state variables available via modern vision-based sensors. Some rewards proposed in previous literature solely for vehicular traffic are extended to pedestrians while new ones are introduced. We use a calibrated model in terms of demand, sensors, green times and other operational constraints of a real intersection in Greater Manchester, UK. The assessed rewards can be classified in 5 groups depending on the magnitudes used: queues, waiting time, delay, average speed and throughput in the junction. The performance of different agents, in terms of waiting time, is compared across different demand levels, from normal operation to saturation of traditional adaptive controllers. We find that those rewards maximising the speed of the network obtain the lowest waiting time for vehicles and pedestrians simultaneously, closely followed by queue minimisation, demonstrating better performance than other previously proposed methods.      
### 63.Modeling and Implementation of Quadcopter Autonomous Flight Based on Alternative Methods to Determine Propeller Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2010.08806.pdf)
>  To properly simulate and implement a quadcopter flight control for intended load and flight conditions, the quadcopter model must have parameters on various relationships including propeller thrust-torque, thrust-PWM, and thrust--angular speed to a certain level of accuracy. Thrust-torque modeling requires an expensive reaction torque measurement sensor. In the absence of sophisticated equipment, the study comes up with alternative methods to complete the quadcopter model. The study also presents a method of modeling the rotational aerodynamic drag on the quadcopter. Although the resulting model of the reaction torque generated by the quadcopter's propellers and the model of the drag torque acting on the quadcopter body that are derived using the methods in this study may not yield the true values of these quantities, the experimental modeling techniques presented in this work ensure that the derived dynamic model for the quadcopter will nevertheless behave identically with the true model for the quadcopter. The derived dynamic model is validated by basic flight controller simulation and actual flight implementation. The model is used as basis for a quadcopter design, which eventually is used for test purposes of basic flight control. This study serves as a baseline for fail-safe control of a quadcopter experiencing an unexpected motor failure.      
### 64.Studying the Similarity of COVID-19 Sounds based on Correlation Analysis of MFCC  [ :arrow_down: ](https://arxiv.org/pdf/2010.08770.pdf)
>  Recently there has been a formidable work which has been put up from the people who are working in the frontlines such as hospitals, clinics, and labs alongside researchers and scientists who are also putting tremendous efforts in the fight against COVID-19 pandemic. Due to the preposterous spread of the virus, the integration of the artificial intelligence has taken a considerable part in the health sector, by implementing the fundamentals of Automatic Speech Recognition (ASR) and deep learning algorithms. In this paper, we illustrate the importance of speech signal processing in the extraction of the Mel-Frequency Cepstral Coefficients (MFCCs) of the COVID-19 and non-COVID-19 samples and find their relationship using Pearson correlation coefficients. Our results show high similarity in MFCCs between different COVID-19 cough and breathing sounds, while MFCC of voice is more robust between COVID-19 and non-COVID-19 samples. Moreover, our results are preliminary, and there is a possibility to exclude the voices of COVID-19 patients from further processing in diagnosing the disease.      
### 65.Audio-based Near-Duplicate Video Retrieval with Audio Similarity Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.08737.pdf)
>  In this work, we address the problem of audio-based near-duplicate video retrieval. We propose the Audio Similarity Learning (AuSiL) approach that effectively captures temporal patterns of audio similarity between video pairs. For the robust similarity calculation between two videos, we first extract representative audio-based video descriptors by leveraging transfer learning based on a Convolutional Neural Network (CNN) trained on a large scale dataset of audio events, and then we calculate the similarity matrix derived from the pairwise similarity of these descriptors. The similarity matrix is subsequently fed to a CNN network that captures the temporal structures existing within its content. We train our network following a triplet generation process and optimizing the triplet loss function. To evaluate the effectiveness of the proposed approach, we have manually annotated two publicly available video datasets based on the audio duplicity between their videos. The proposed approach achieves very competitive results compared to three state-of-the-art methods. Also, unlike the competing methods, it is very robust to the retrieval of audio duplicates generated with speed transformations.      
### 66.MeshMVS: Multi-View Stereo Guided Mesh Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2010.08682.pdf)
>  Deep learning based 3D shape generation methods generally utilize latent features extracted from color images to encode the objects' semantics and guide the shape generation process. These color image semantics only implicitly encode 3D information, potentially limiting the accuracy of the generated shapes. In this paper we propose a multi-view mesh generation method which incorporates geometry information in the color images explicitly by using the features from intermediate 2.5D depth representations of the input images and regularizing the 3D shapes against these depth images. Our system first predicts a coarse 3D volume from the color images by probabilistically merging voxel occupancy grids from individual views. Depth images corresponding to the multi-view color images are predicted which along with the rendered depth images of the coarse shape are used as a contrastive input whose features guide the refinement of the coarse shape through a series of graph convolution networks. Attention-based multi-view feature pooling is proposed to fuse the contrastive depth features from different viewpoints which are fed to the graph convolution networks. <br>We validate the proposed multi-view mesh generation method on ShapeNet, where we obtain a significant improvement with 34% decrease in chamfer distance to ground truth and 14% increase in the F1-score compared with the state-of-the-art multi-view shape generation method.      
### 67.Wireless Localisation in WiFi using Novel Deep Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2010.08658.pdf)
>  This paper studies the indoor localisation of WiFi devices based on a commodity chipset and standard channel sounding. First, we present a novel shallow neural network (SNN) in which features are extracted from the channel state information (CSI) corresponding to WiFi subcarriers received on different antennas and used to train the model. The single-layer architecture of this localisation neural network makes it lightweight and easy-to-deploy on devices with stringent constraints on computational resources. We further investigate for localisation the use of deep learning models and design novel architectures for convolutional neural network (CNN) and long-short term memory (LSTM). We extensively evaluate these localisation algorithms for continuous tracking in indoor environments. Experimental results prove that even an SNN model, after a careful handcrafted feature extraction, can achieve accurate localisation. Meanwhile, using a well-organised architecture, the neural network models can be trained directly with raw data from the CSI and localisation features can be automatically extracted to achieve accurate position estimates. We also found that the performance of neural network-based methods are directly affected by the number of anchor access points (APs) regardless of their structure. With three APs, all neural network models proposed in this paper can obtain localisation accuracy of around 0.5 metres. In addition the proposed deep NN architecture reduces the data pre-processing time by 6.5 hours compared with a shallow NN using the data collected in our testbed. In the deployment phase, the inference time is also significantly reduced to 0.1 ms per sample. We also demonstrate the generalisation capability of the proposed method by evaluating models using different target movement characteristics to the ones in which they were trained.      
### 68.Ensembling Low Precision Models for Binary Biomedical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.08648.pdf)
>  Segmentation of anatomical regions of interest such as vessels or small lesions in medical images is still a difficult problem that is often tackled with manual input by an expert. One of the major challenges for this task is that the appearance of foreground (positive) regions can be similar to background (negative) regions. As a result, many automatic segmentation algorithms tend to exhibit asymmetric errors, typically producing more false positives than false negatives. In this paper, we aim to leverage this asymmetry and train a diverse ensemble of models with very high recall, while sacrificing their precision. Our core idea is straightforward: A diverse ensemble of low precision and high recall models are likely to make different false positive errors (classifying background as foreground in different parts of the image), but the true positives will tend to be consistent. Thus, in aggregate the false positive errors will cancel out, yielding high performance for the ensemble. Our strategy is general and can be applied with any segmentation model. In three different applications (carotid artery segmentation in a neck CT angiography, myocardium segmentation in a cardiovascular MRI and multiple sclerosis lesion segmentation in a brain MRI), we show how the proposed approach can significantly boost the performance of a baseline segmentation method.      
### 69.Robust autoregressive hidden semi-Markov models applied to EEG sleep spindles detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.08641.pdf)
>  We propose a generative model for single-channel EEG that incorporates the constraints experts actively enforce while visually scoring recordings. In particular, the framework takes the form of a robust hidden semi-Markov model that explicitly segments sequences into local, reoccurring dynamical regimes. Unlike typical detectors, our approach takes the raw data (up to resampling) without any filtering, windowing, nor thresholding. This not only makes the model appealing to real-time applications, but it also yields interpretable hyperparameters that are analogous to known clinical criteria. We validate the model on stage 2 non-REM sleep recordings that display characteristic sleep spindles. We derive tractable algorithms for exact inference and prove that more complex models are able to surpass state of the art detectors while being completely transparent, auditable, and generalizable.      
### 70.Horizon-independent Preconditioner Design for Linear Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.08572.pdf)
>  First-order optimization solvers, such as the Fast Gradient Method, are increasingly being used to solve Model Predictive Control problems in resource-constrained environments. Unfortunately, the convergence rate of these solvers is significantly affected by the conditioning of the problem data, with ill-conditioned problems requiring a large number of iterations. To reduce the number of iterations required, we present a simple method for computing a horizon-independent preconditioning matrix for the Hessian of the condensed problem. The preconditioner is based on the block Toeplitz structure of the Hessian. Horizon-independence allows one to use only the predicted system and cost matrices to compute the preconditioner, instead of the full Hessian. The proposed preconditioner has equivalent performance to an optimal preconditioner, producing up to a 6x speedup for the Fast Gradient Method in our numerical examples. Additionally, we derive horizon-independent spectral bounds for the Hessian in terms of the transfer function of the predicted system, and show how these can be used to compute a novel horizon-independent bound on the condition number for the preconditioned Hessian.      
### 71.Adversarial Patch Attacks on Monocular Depth Estimation Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.03072.pdf)
>  Thanks to the excellent learning capability of deep convolutional neural networks (CNN), monocular depth estimation using CNNs has achieved great success in recent years. However, depth estimation from a monocular image alone is essentially an ill-posed problem, and thus, it seems that this approach would have inherent vulnerabilities. To reveal this limitation, we propose a method of adversarial patch attack on monocular depth estimation. More specifically, we generate artificial patterns (adversarial patches) that can fool the target methods into estimating an incorrect depth for the regions where the patterns are placed. Our method can be implemented in the real world by physically placing the printed patterns in real scenes. We also analyze the behavior of monocular depth estimation under attacks by visualizing the activation levels of the intermediate layers and the regions potentially affected by the adversarial attack.      
### 72.An Ontological Metamodel for Cyber-Physical System Safety, Security, and Resilience Coengineering  [ :arrow_down: ](https://arxiv.org/pdf/2006.05304.pdf)
>  System complexity has become ubiquitous in the design, assessment, and implementation of practical and useful cyber-physical systems. This increased complexity is impacting the management of models necessary for designing cyber-physical systems that are able to take into account a number of ``-ilities'', such that they are safe and secure and ultimately resilient to disruption of service. We propose an ontological metamodel for system design that augments an already existing industry metamodel to capture the relationships between various model elements and safety, security, and resilient considerations. Employing this metamodel leads to more cohesive and structured modeling efforts with an overall increase in scalability, usability, and unification of already existing models. In turn, this leads to a mission-oriented perspective in designing security defenses and resilience mechanisms to combat undesirable behaviors. We illustrate this metamodel in an open-source GraphQL implementation, which can interface with a number of modeling languages. We support our proposed metamodel with a detailed demonstration using an oil and gas pipeline model.      
### 73.High-quality Panorama Stitching based on Asymmetric Bidirectional Optical Flow  [ :arrow_down: ](https://arxiv.org/pdf/2006.01201.pdf)
>  In this paper, we propose a panorama stitching algorithm based on asymmetric bidirectional optical flow. This algorithm expects multiple photos captured by fisheye lens cameras as input, and then, through the proposed algorithm, these photos can be merged into a high-quality 360-degree spherical panoramic image. For photos taken from a distant perspective, the parallax among them is relatively small, and the obtained panoramic image can be nearly seamless and undistorted. For photos taken from a close perspective or with a relatively large parallax, a seamless though partially distorted panoramic image can also be obtained. Besides, with the help of Graphics Processing Unit (GPU), this algorithm can complete the whole stitching process at a very fast speed: typically, it only takes less than 30s to obtain a panoramic image of 9000-by-4000 pixels, which means our panorama stitching algorithm is of high value in many real-time applications. Our code is available at <a class="link-external link-https" href="https://github.com/MungoMeng/Panorama-OpticalFlow" rel="external noopener nofollow">this https URL</a>.      
### 74.Small Satellite Constellation Separation using Linear Programming based Differential Drag Commands  [ :arrow_down: ](https://arxiv.org/pdf/1710.00104.pdf)
>  We study the optimal control of an arbitrarily large constellation of small satellites operating in low Earth orbit. Simulating the lack of on-board propulsion, we limit our actuation to the use of differential drag maneuvers to make in-plane changes to the satellite orbits. We propose an efficient method to separate a cluster of satellites into a desired constellation shape while respecting actuation constraints and maximizing the operational lifetime of the constellation. By posing the problem as a linear program, we solve for the optimal drag commands for each of the satellites on a daily basis with a shrinking-horizon model predictive control approach. We then apply this control strategy in a nonlinear orbital dynamics simulation with a simple, varying atmospheric density model. We demonstrate the ability to control a cluster of 100+ satellites starting at the same initial conditions in a circular low Earth orbit to form an equally spaced constellation (with a relative angular separation error tolerance of one-tenth a degree). The constellation separation task can be executed in 71 days, a time frame that is competitive for the state-of-the-practice. This method allows us to trade the time required to converge to the desired constellation with a sacrifice in the overall constellation lifetime, measured as the maximum altitude loss experienced by one of the satellites in the group after the separation maneuvers.      

# ArXiv eess --Mon, 26 Oct 2020
### 1.Non-convex Super-resolution of OCT images via sparse representation  [ :arrow_down: ](https://arxiv.org/pdf/2010.12576.pdf)
>  We propose a non-convex variational model for the super-resolution of Optical Coherence Tomography (OCT) images of the murine eye, by enforcing sparsity with respect to suitable dictionaries learnt from high-resolution OCT data. The statistical characteristics of OCT images motivate the use of {\alpha}-stable distributions for learning dictionaries, by considering the non-Gaussian case, {\alpha}=1. The sparsity-promoting cost function relies on a non-convex penalty - Cauchy-based or Minimax Concave Penalty (MCP) - which makes the problem particularly challenging. We propose an efficient algorithm for minimizing the function based on the forward-backward splitting strategy which guarantees at each iteration the existence and uniqueness of the proximal point. Comparisons with standard convex L1-based reconstructions show the better performance of non-convex models, especially in view of further OCT image analysis      
### 2.Performance Analysis of Intelligent Reflective Surface Aided Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2010.12544.pdf)
>  The fundamental performance metrics of an intelligent reflective surface (IRS)-aided wireless system are presented. By optimizing the IRS phase-shift matrix, the received signal-to-noise ratio (SNR) is maximized at the destination in the presence of both reflected and direct channels. The probability distributions of this maximum SNR are tightly approximated for the moderate-to-large reflective element regime. Thereby, the probability density function and cumulative distribution function of this tight SNR approximation are derived in closed-form for Nakagami-m fading to facilitate a statistical characterization of the performance metrics. The outage probability, average symbol error probability, and achievable rate bounds are derived. By virtue of an asymptotic analysis in the high SNR regime, the diversity order is quantified. Thereby, we reveal that the overall diversity order can be scaled as a function of the number of reflective elements (N) such that Gd = mv + min(mg;mh)N, where mv, mh and mg are the Nakagami-m parameters of the direct, source-to-IRS and IRS-to-destination channels, respectively. The asymptotic achievable rate is derived, and thereby, it is shown that the transmit power can be scaled inversely proportional to N2. The impact of quantized IRS phase-shifts is investigated by deriving the achievable rate bounds. Useful insights are obtained by analyzing the system performance for different severity of fading cases including spatially correlated fading. Our analysis and numerical results reveal that IRS is a promising technology for boosting the performance of wireless communications by intelligently controlling the propagation channels without employing additional active radio-frequency chains.      
### 3.Speech enhancement aided end-to-end multi-task learning for voice activity detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.12484.pdf)
>  Robust voice activity detection (VAD) is a challenging task in low signal-to-noise (SNR) environments. Recent studies show that speech enhancement is helpful to VAD, but the performance improvement is limited. To address this issue, here we propose a speech enhancement aided end-to-end multi-task model for VAD. The model has two decoders, one for speech enhancement and the other for VAD. The two decoders share the same encoder and speech separation network. Unlike the direct thought that takes two separated objectives for VAD and speech enhancement respectively, here we propose a new joint optimization objective---VAD-masked scale-invariant source-to-noise ratio (mSI-SDR). mSI-SDR uses VAD information to mask the output of the speech enhancement decoder in the training process. It makes the VAD and speech enhancement tasks jointly optimized not only at the shared encoder and separation network, but also at the objective level. Experimental results show that the multi-task method significantly outperforms its single-task VAD counterpart. Moreover, mSI-SDR outperforms SI-SDR in the same multi-task setting. Finally, the model performs well in real-time conditions.      
### 4.The IDLAB VoxCeleb Speaker Recognition Challenge 2020 System Description  [ :arrow_down: ](https://arxiv.org/pdf/2010.12468.pdf)
>  In this technical report we describe the IDLAB top-scoring submissions for the VoxCeleb Speaker Recognition Challenge 2020 (VoxSRC-20) in the supervised and unsupervised speaker verification tracks. For the supervised verification tracks we trained 6 state-of-the-art ECAPA-TDNN systems and 4 Resnet34 based systems with architectural variations. On all models we apply a large margin fine-tuning strategy, which enables the training procedure to use higher margin penalties by using longer training utterances. In addition, we use quality-aware score calibration which introduces quality metrics in the calibration system to generate more consistent scores across varying levels of utterance conditions. A fusion of all systems with both enhancements applied led to the first place on the open and closed supervised verification tracks. The unsupervised system is trained through contrastive learning. Subsequent pseudo-label generation by iterative clustering of the training embeddings allows the use of supervised techniques. This procedure led to the winning submission on the unsupervised track, and its performance is closing in on supervised training.      
### 5.A Regression-based Voltage Estimation Method for Distribution Volt-Var Control with Limited Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12456.pdf)
>  This paper presents a regression-based method for estimating voltages and voltage sensitivities for volt-var control on distribution circuits with limited data. The estimator uses power flow results for representative load and PV output scenarios as training data. Using linear regressions on power flow results, the voltages at critical nodes are calculated online based on power measurements at the feeder head and at each PV plant. The voltage sensitivity to changes in reactive power injection by each PV plant is also found online using regressions on power flow results. The estimator thus provides the estimated critical voltages and their sensitivities to each possible control action. The estimator is tested in conjunction with a volt-var optimization on real, unbalanced rural distribution feeder. The optimal control actions and voltage results using the estimator are compared to the optimal results assuming full visibility of the distribution system. Results show that the estimator can estimate voltages and sensitivities with adequate accuracy for successful centralized volt-var control.      
### 6.Estimation of Cardiac Valve Annuli Motion with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.12446.pdf)
>  Valve annuli motion and morphology, measured from non-invasive imaging, can be used to gain a better understanding of healthy and pathological heart function. Measurements such as long-axis strain as well as peak strain rates provide markers of systolic function. Likewise, early and late-diastolic filling velocities are used as indicators of diastolic function. Quantifying global strains, however, requires a fast and precise method of tracking long-axis motion throughout the cardiac cycle. Valve landmarks such as the insertion of leaflets into the myocardial wall provide features that can be tracked to measure global long-axis motion. Feature tracking methods require initialisation, which can be time-consuming in studies with large cohorts. Therefore, this study developed and trained a neural network to identify ten features from unlabeled long-axis MR images: six mitral valve points from three long-axis views, two aortic valve points and two tricuspid valve points. This study used manual annotations of valve landmarks in standard 2-, 3- and 4-chamber long-axis images collected in clinical scans to train the network. The accuracy in the identification of these ten features, in pixel distance, was compared with the accuracy of two commonly used feature tracking methods as well as the inter-observer variability of manual annotations. Clinical measures, such as valve landmark strain and motion between end-diastole and end-systole, are also presented to illustrate the utility and robustness of the method.      
### 7.Low-complexity decentralized algorithm for aggregate load control of thermostatic loads  [ :arrow_down: ](https://arxiv.org/pdf/2010.12443.pdf)
>  Thermostatically controlled loads such as refrigerators are exceptionally suitable as a flexible demand resource. This paper derives a decentralised load control algorithm for refrigerators. It is adapted from an existing continuous time control approach, with the aim to achieve low computational complexity and an ability to handle discrete time steps of variable length -- desirable features for embedding in appliances and high-throughput simulations. Simulation results of large populations of heterogeneous appliances illustrate the accurate aggregate control of power consumption and high computational efficiency. Tracking accuracy is quantified as a function of population size and time step size, and correlations in the tracking error are investigated. The controller is shown to be robust to errors in model specification and to sudden perturbations in the form of random refrigerator door openings.      
### 8.Training Noisy Single-Channel Speech Separation With Noisy Oracle Sources: A Large Gap and A Small Step  [ :arrow_down: ](https://arxiv.org/pdf/2010.12430.pdf)
>  As the performance of single-channel speech separation systems has improved, there has been a desire to move to more challenging conditions than the clean, near-field speech that initial systems were developed on. When training deep learning separation models, a need for ground truth leads to training on synthetic mixtures. As such, training in noisy conditions requires either using noise synthetically added to clean speech, preventing the use of in-domain data for a noisy-condition task, or training using mixtures of noisy speech, requiring the network to additionally separate the noise. We demonstrate the relative inseparability of noise and that this noisy speech paradigm leads to significant degradation of system performance. We also propose an SI-SDR-inspired training objective that tries to exploit the inseparability of noise to implicitly partition the signal and discount noise separation errors, enabling the training of better separation systems with noisy oracle sources.      
### 9.Progressive Training of Multi-level Wavelet Residual Networks for Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2010.12422.pdf)
>  Recent years have witnessed the great success of deep convolutional neural networks (CNNs) in image denoising. Albeit deeper network and larger model capacity generally benefit performance, it remains a challenging practical issue to train a very deep image denoising network. Using multilevel wavelet-CNN (MWCNN) as an example, we empirically find that the denoising performance cannot be significantly improved by either increasing wavelet decomposition levels or increasing convolution layers within each level. To cope with this issue, this paper presents a multi-level wavelet residual network (MWRN) architecture as well as a progressive training (PTMWRN) scheme to improve image denoising performance. In contrast to MWCNN, our MWRN introduces several residual blocks after each level of discrete wavelet transform (DWT) and before inverse discrete wavelet transform (IDWT). For easing the training difficulty, scale-specific loss is applied to each level of MWRN by requiring the intermediate output to approximate the corresponding wavelet subbands of ground-truth clean image. To ensure the effectiveness of scale-specific loss, we also take the wavelet subbands of noisy image as the input to each scale of the encoder. Furthermore, progressive training scheme is adopted for better learning of MWRN by beigining with training the lowest level of MWRN and progressively training the upper levels to bring more fine details to denoising results. Experiments on both synthetic and real-world noisy images show that our PT-MWRN performs favorably against the state-of-the-art denoising methods in terms both quantitative metrics and visual quality.      
### 10.Millimeter Wave MIMO Channel Estimation with 1-bit Spatial Sigma-delta Analog-to-Digital Converters  [ :arrow_down: ](https://arxiv.org/pdf/2010.12398.pdf)
>  This paper focuses on channel estimation for mmWave MIMO systems with 1-bit spatial sigma-delta analog-to-digital converters (ADCs). The channel estimation performance with 1-bit spatial sigma-delta ADCs depends on the quantization noise modeling. Therefore, we present a new method for modeling the quantization noise by leveraging the deterministic input-output relation of the 1-bit spatial sigma-delta ADC. Using this new noise model, we propose an algorithm for channel estimation for a narrowband single-user mmWave line-of-sight MIMO system by determining the unknown angles and path attenuation that characterize the flat fading channel. Through simulations, we demonstrate that the performance of the developed method is comparable to the traditional analog systems and significantly better than the conventional 1-bit quantized systems.      
### 11.Segmentation of the cortical plate in fetal brain MRI with a topological loss  [ :arrow_down: ](https://arxiv.org/pdf/2010.12391.pdf)
>  The fetal cortical plate undergoes drastic morphological changes throughout early in utero development that can be observed using magnetic resonance (MR) imaging. An accurate MR image segmentation, and more importantly a topologically correct delineation of the cortical gray matter, is a key baseline to perform further quantitative analysis of brain development. In this paper, we propose for the first time the integration of a topological constraint, as an additional loss function, to enhance the morphological consistency of a deep learning-based segmentation of the fetal cortical plate. We quantitatively evaluate our method on 18 fetal brain atlases ranging from 21 to 38 weeks of gestation, showing the significant benefits of our method through all gestational ages as compared to a baseline method. Furthermore, qualitative evaluation by three different experts on 130 randomly selected slices from 26 clinical MRIs evidences the out-performance of our method independently of the MR reconstruction quality.      
### 12.Calculate Center-of-Inertia Frequency and System RoCoF Using PMU Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12381.pdf)
>  The power system frequency is important for the system overall stability. However, there does not exist a single measurement point of the system frequency due to the distributed nature of the system inertia and the small inconsistency of different generator rotor electrical speeds in one synchronized system. This paper proposed a new approach to calculate the system center-of-inertia (COI) frequency and the rate-of-change-of-frequency (RoCoF) more accurately using PMU data at multiple locations. The COI frequency and the RoCoF value were further used to assist fast estimation of the imbalance MW amount of a frequency event. Test results using actual measurements in the U.S. Eastern Interconnection system validated the effectiveness of the proposed method.      
### 13.A Simulation-based Education Approach for the Electromagnetic and Electromechanical Transient Waves in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.12379.pdf)
>  Power systems usually go through electromagnetic and electromechanical transient processes after different disturbances. Learning the characteristics and the differences between them are important but not easy for students majoring in power systems. This paper presents a simulation-based approach to comprehensively study the two types of transient waves, constituting the experimental part of the power system transient and stability course. In this approach, three models with different levels of complexity are developed to simultaneously show the two types of transient waves in the time domain. The developed models are then demonstrated as testbeds for investigating various aspects related to the two types of transient, such as waveforms induced by different disturbances, influencing factors on the propagation speed, and the interaction between incident waves and the reflective waves. In addition, a theory-to-practice engineering research process is demonstrated through developing a power system event-location application, which is inspired by electromechanical wave propagation study. The proposed education process and models at various complexity levels provide a creative and interactive way for power system transients and dynamics study.      
### 14.Identification and Quantification of Aerosol Hot-spots over Lahore Region using MODIS Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12373.pdf)
>  The increased concentration of aerosols in the air caused by ever-rising urbanization and the development of various industries has horrendous consequences on human health, environment and climate. The first step to counter adverse effects of air pollution in any region is to identify locations with a high concentration of aerosols, termed aerosol hot-spots. We specifically focus on the region of Lahore, Pakistan, a city that has consistently been ranked among the top ten most polluted cities in the world. In order to identify aerosol hot-spots in the city, we utilize two-year (2017-18) Aerosol Optical Thickness (AOT) data from MODerate resolution Imaging Spectroradiometer (MODIS) on the Aqua satellite. We propose a method based on the Glowworm Swarm Optimization (GSO) algorithm that discovers several aerosol hot-spots over Lahore comprising of major highways and industrial areas. Furthermore, we formulate two quantification metrics to gauge the amount of aerosol content over each hot-spot. We also analyze the temporal variation of aerosol content that suggests the addition or suppression of pollution sources in the hot-spots. Unlike previous studies, our work provides novel insight into the regional aerosol concentration of Lahore and calls for maintenance of air quality of the regions falling under the identified aerosol hot-spots.      
### 15.Checkerboard-Artifact-Free Image-Enhancement Network Considering Local and Global Features  [ :arrow_down: ](https://arxiv.org/pdf/2010.12347.pdf)
>  In this paper, we propose a novel convolutional neural network (CNN) that never causes checkerboard artifacts, for image enhancement. In research fields of image-to-image translation problems, it is well-known that images generated by usual CNNs are distorted by checkerboard artifacts which mainly caused in forward-propagation of upsampling layers. However, checkerboard artifacts in image enhancement have never been discussed. In this paper, we point out that applying U-Net based CNNs to image enhancement causes checkerboard artifacts. In contrast, the proposed network that contains fixed convolutional layers can perfectly prevent the artifacts. In addition, the proposed network architecture, which can handle both local and global features, enables us to improve the performance of image enhancement. Experimental results show that the use of fixed convolutional layers can prevent checkerboard artifacts and the proposed network outperforms state-of-the-art CNN-based image-enhancement methods in terms of various objective quality metrics: PSNR, SSIM, and NIQE.      
### 16.Traffic Abstractions of Nonlinear Event-Triggered Control Systems with Disturbances and Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2010.12341.pdf)
>  Scheduling communication traffic in networks of event-triggered control (ETC) systems is a very challenging task, as the exact sampling time instants are generally unknown (as opposed to periodic sampling). In previous work, finite-state systems (abstractions) were created, capturing the traffic generated by linear time-invariant ETC systems with a specific type of triggering function. It has been shown that such abstractions can be used for scheduling traffic in networks of ETC loops. In this work, we significantly extend this framework, by proposing a methodology for abstracting general nonlinear ETC systems with disturbances, uncertainties and general triggering functions.      
### 17.A Modular Framework for Distributed Model Predictive Control of Nonlinear Continuous-Time Systems (GRAMPC-D)  [ :arrow_down: ](https://arxiv.org/pdf/2010.12315.pdf)
>  The modular open-source framework GRAMPC-D for model predictive control of distributed systems is presented in this paper. The modular concept allows to solve optimal control problems (OCP) in a centralized and distributed fashion using the same problem description. It is tailored to computational efficiency with the focus on embedded hardware. The distributed solution is based on the Alternating Direction Method of Multipliers (ADMM) and uses the concept of neighbor approximation to enhance convergence speed. The presented framework can be accessed through Cpp and Python and also supports plug-and-play and data exchange between agents over a network.      
### 18.Model-Based Machine Learning for Joint Digital Backpropagation and PMD Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2010.12313.pdf)
>  In this paper, we propose a model-based machine-learning approach for dual-polarization systems by parameterizing the split-step Fourier method for the Manakov-PMD equation. The resulting method combines hardware-friendly time-domain nonlinearity mitigation via the recently proposed learned digital backpropagation (LDBP) with distributed compensation of polarization-mode dispersion (PMD). We refer to the resulting approach as LDBP-PMD. We train LDBP-PMD on multiple PMD realizations and show that it converges within 1% of its peak dB performance after 428 training iterations on average, yielding a peak effective signal-to-noise ratio of only 0.30 dB below the PMD-free case. Similar to state-of-the-art lumped PMD compensation algorithms in practical systems, our approach does not assume any knowledge about the particular PMD realization along the link, nor any knowledge about the total accumulated PMD. This is a significant improvement compared to prior work on distributed PMD compensation, where knowledge about the accumulated PMD is typically assumed. We also compare different parameterization choices in terms of performance, complexity, and convergence behavior. Lastly, we demonstrate that the learned models can be successfully retrained after an abrupt change of the PMD realization along the fiber.      
### 19.Network Classifiers Based on Social Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.12306.pdf)
>  This work proposes a new way of combining independently trained classifiers over space and time. Combination over space means that the outputs of spatially distributed classifiers are aggregated. Combination over time means that the classifiers respond to streaming data during testing and continue to improve their performance even during this phase. By doing so, the proposed architecture is able to improve prediction performance over time with unlabeled data. Inspired by social learning algorithms, which require prior knowledge of the observations distribution, we propose a Social Machine Learning (SML) paradigm that is able to exploit the imperfect models generated during the learning phase. We show that this strategy results in consistent learning with high probability, and it yields a robust structure against poorly trained classifiers. Simulations with an ensemble of feedforward neural networks are provided to illustrate the theoretical results.      
### 20.State space models for building control: how deep should you go?  [ :arrow_down: ](https://arxiv.org/pdf/2010.12257.pdf)
>  Power consumption in buildings show non-linear behaviors that linear models cannot capture whereas recurrent neural networks (RNNs) can. This ability makes RNNs attractive alternatives for the model-predictive control (MPC) of buildings. However RNN models lack mathematical regularity which makes their use challenging in optimization problems. This work therefore systematically investigates whether using RNNs for building control provides net gains in an MPC framework. It compares the representation power and control performance of two architectures: a fully non-linear RNN architecture and a linear state-space model with non-linear regressor. The comparison covers five instances of each architecture over two months of simulated operation in identical conditions. The error on the one-hour forecast of temperature is 69% lower with the RNN model than with the linear one. In control the linear state-space model outperforms by 10% on the objective function, shows 2.8 times higher average temperature violations, and needs a third of the computation time the RNN model requires. This work therefore demonstrates that in their current form RNNs do improve accuracy but on balance well-designed linear state-space models with non-linear regressors are best in most cases of MPC.      
### 21.Any-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised Discrete Speech Representations  [ :arrow_down: ](https://arxiv.org/pdf/2010.12231.pdf)
>  We present a novel approach to any-to-one (A2O) voice conversion (VC) in a sequence-to-sequence (seq2seq) framework. A2O VC aims to convert any speaker, including those unseen during training, to a fixed target speaker. We utilize vq-wav2vec (VQW2V), a discretized self-supervised speech representation that was learned from massive unlabeled data, which is assumed to be speaker-independent and well corresponds to underlying linguistic contents. Given a training dataset of the target speaker, we extract VQW2V and acoustic features to estimate a seq2seq mapping function from the former to the latter. With the help of a pretraining method and a newly designed postprocessing technique, our model can be generalized to only 5 min of data, even outperforming the same model trained with parallel data.      
### 22.A Simulation Study on Turnpikes in Stochastic LQ Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.12201.pdf)
>  This paper presents a simulation study on turnpike phenomena in stochastic optimal control problems. We employ the framework of Polynomial Chaos Expansions (PCE) to investigate the presence of turnpikes in stochastic LQ problems. Our findings indicate that turnpikes can be observed in the evolution of PCE coefficients as well as in the evolution of statistical moments. Moreover, the turnpike phenomenon can be observed for optimal realization trajectories and with respect to the optimal stationary distribution. Finally, while adding variance penalization to the objective alters the turnpike, it does not destroy the phenomenon.      
### 23.Toward Expressive Singing Voice Correction: On Perceptual Validity of Evaluation Metrics for Vocal Melody Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2010.12196.pdf)
>  Singing voice correction (SVC) is an appealing application for amateur singers. Commercial products automate SVC by snapping pitch contours to equal-tempered scales, which could lead to deadpan modifications. Together with the neglect of rhythmic errors, extensive manual corrections are still necessary. In this paper, we present a streamlined system to automate expressive SVC for both pitch and rhythmic errors. Particularly, we extend a previous work by integrating advanced techniques for singing voice separation (SVS) and vocal melody extraction. SVC is achieved by temporally aligning the source-target pair, followed by replacing pitch and rhythm of the source with those of the target. We evaluate the framework by a comparative study for melody extraction which involves both subjective and objective evaluations, whereby we investigate perceptual validity of the standard metrics through the lens of SVC. The results suggest that the high pitch accuracy obtained by the metrics does not signify good perceptual scores.      
### 24.Estimation of Groundwater Storage Variations in Indus River Basin using GRACE Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12175.pdf)
>  The depletion and variations of groundwater storage~(GWS) are of critical importance for sustainable groundwater management. In this work, we use Gravity Recovery and Climate Experiment (GRACE) to estimate variations in the terrestrial water storage~(TWS) and use it in conjunction with the Global Land Data Assimilation System~(GLDAS) data to extract GWS variations over time for Indus river basin~(IRB). We present a data processing framework that processes and combines these data-sets to provide an estimate of GWS changes. We also present the design of a band-limited optimally concentrated window function for spatial localization of the data in the region of interest. We construct the so-called optimal window for the IRB region and use it in our processing framework to analyze the GWS variations from 2005 to 2015. Our analysis reveals the expected seasonal variations in GWS and signifies groundwater depletion on average over the time period. Our proposed processing framework can be used to analyze spatio-temporal variations in TWS and GWS for any region of interest.      
### 25.A Cross-Verification Approach for Protecting World Leaders from Fake and Tampered Audio  [ :arrow_down: ](https://arxiv.org/pdf/2010.12173.pdf)
>  This paper tackles the problem of verifying the authenticity of speech recordings from world leaders. Whereas previous work on detecting deep fake or tampered audio focus on scrutinizing an audio recording in isolation, we instead reframe the problem and focus on cross-verifying a questionable recording against trusted references. We present a method for cross-verifying a speech recording against a reference that consists of two steps: aligning the two recordings and then classifying each query frame as matching or non-matching. We propose a subsequence alignment method based on the Needleman-Wunsch algorithm and show that it significantly outperforms dynamic time warping in handling common tampering operations. We also explore several binary classification models based on LSTM and Transformer architectures to verify content at the frame level. Through extensive experiments on tampered speech recordings of Donald Trump, we show that our system can reliably detect audio tampering operations of different types and durations. Our best model achieves 99.7% accuracy for the alignment task at an error tolerance of 50 ms and a 0.43% equal error rate in classifying audio frames as matching or non-matching.      
### 26.Is Machine Learning Able to Detect and Classify Failure in Piezoresistive Bone Cement Based on Electrical Signals?  [ :arrow_down: ](https://arxiv.org/pdf/2010.12147.pdf)
>  At an estimated cost of $8 billion annually in the United States, revision surgeries to total joint replacements represent a substantial financial burden to the health care system. Fixation failures, such as implant loosening, wear, and mechanical instability of the poly(methyl methacrylate) (PMMA) cement, which bonds the implant to the bone, are the main causes of long-term implant failure. Early and accurate diagnosis of cement failure is critical for developing novel therapeutic strategies and reducing the high risk of a misjudged revision. Unfortunately, prevailing imaging modalities, notably plain radiographs, struggle to detect the precursors of implant failure and are often interpreted incorrectly. Our prior work has shown that the modification of PMMA bone cement with low concentrations of conductive fillers makes it piezoresistive and therefore self-sensing such that when combined with a conductivity imaging modality, such as electrical impedance tomography (EIT), it is possible to monitor load transfer across the PMMA using cost-effective, physiologically benign, and real-time electrical measurements. Herein, we expand upon these results by integrating machine learning techniques with EIT. We survey different machine learning algorithms and principal component analysis for application to this problem, including neural networks on voltage readings of an EIT phantom for tracking position of a sample, specifying defect location, and classifying defect types. Our results show advantage of neural network with more than 91.9 %, 95.5 %, and 98 % accuracy in interpreting EIT signals for location tracking, specifying defect location, and defect classification respectively. These preliminary results show that the combination of smart materials, EIT, and machine learning may be a powerful tool for diagnosing the origin and evolution of failure in joint replacement.      
### 27.Observer-based predictor for a SIR model with delays  [ :arrow_down: ](https://arxiv.org/pdf/2010.12106.pdf)
>  We propose an observer for a SIR epidemic model. The observer is then uplifted into a predictor to compensate for time delays in the input and the output. Tuning criteria are given for tuning gains of the predictor, while the estimation-error stability is ensured using Lyapunov-Krasovskii functionals. The predictor's performance is evaluated in combination with a time-optimal control. We show that the predictor nearly recovers the performance level of the delay-free system.      
### 28.How Phonotactics Affect Multilingual and Zero-shot ASR Performance  [ :arrow_down: ](https://arxiv.org/pdf/2010.12104.pdf)
>  The idea of combining multiple languages' recordings to train a single automatic speech recognition (ASR) model brings the promise of the emergence of universal speech representation. Recently, a Transformer encoder-decoder model has been shown to leverage multilingual data well in IPA transcriptions of languages presented during training. However, the representations it learned were not successful in zero-shot transfer to unseen languages. Because that model lacks an explicit factorization of the acoustic model (AM) and language model (LM), it is unclear to what degree the performance suffered from differences in pronunciation or the mismatch in phonotactics. To gain more insight into the factors limiting zero-shot ASR transfer, we replace the encoder-decoder with a hybrid ASR system consisting of a separate AM and LM. Then, we perform an extensive evaluation of monolingual, multilingual, and crosslingual (zero-shot) acoustic and language models on a set of 13 phonetically diverse languages. We show that the gain from modeling crosslingual phonotactics is limited, and imposing a too strong model can hurt the zero-shot transfer. Furthermore, we find that a multilingual LM hurts a multilingual ASR system's performance, and retaining only the target language's phonotactic data in LM training is preferable.      
### 29.Deep Image Prior for Sparse-sampling Photoacoustic Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2010.12041.pdf)
>  Photoacoustic microscopy (PAM) is an emerging method for imaging both structural and functional information without the need for exogenous contrast agents. However, state-of-the-art PAM faces a tradeoff between imaging speed and spatial sampling density within the same field-of-view (FOV). Limited by the pulsed laser's repetition rate, the imaging speed is inversely proportional to the total number of effective pixels. To cover the same FOV in a shorter amount of time with the same PAM hardware, there is currently no other option than to decrease spatial sampling density (i.e., sparse sampling). Deep learning methods have recently been used to improve sparsely sampled PAM images; however, these methods often require time-consuming pre-training and a large training dataset that has fully sampled, co-registered ground truth. In this paper, we propose using a method known as "deep image prior" to improve the image quality of sparsely sampled PAM images. The network does not need prior learning or fully sampled ground truth, making its implementation more flexible and much quicker. Our results show promising improvement in PA vasculature images with as few as 2% of the effective pixels. Our deep image prior approach produces results that outperform interpolation methods and can be readily translated to other high-speed, sparse-sampling imaging modalities.      
### 30.Automating Abnormality Detection in Musculoskeletal Radiographs through Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.12030.pdf)
>  This paper introduces MuRAD (Musculoskeletal Radiograph Abnormality Detection tool), a tool that can help radiologists automate the detection of abnormalities in musculoskeletal radiographs (bone X-rays). MuRAD utilizes a Convolutional Neural Network (CNN) that can accurately predict whether a bone X-ray is abnormal, and leverages Class Activation Map (CAM) to localize the abnormality in the image. MuRAD achieves an F1 score of 0.822 and a Cohen's kappa of 0.699, which is comparable to the performance of expert radiologists.      
### 31.Sequence-to-sequence Singing Voice Synthesis with Perceptual Entropy Loss  [ :arrow_down: ](https://arxiv.org/pdf/2010.12024.pdf)
>  The neural network (NN) based singing voice synthesis (SVS) systems require sufficient data to train well. However, due to high data acquisition and annotation cost, we often encounter data limitation problem in building SVS systems. The NN based models are prone to over-fitting due to data scarcity. In this work, we propose a Perceptual Entropy (PE) loss derived from a psycho-acoustic hearing model to regularize the network. With a one-hour open-source singing voice database, we explore the impact of the PE loss on various mainstream sequence-to-sequence models, including the RNN-based model, transformer-based model, and conformer-based model. Our experiments show that the PE loss can mitigate the over-fitting problem and significantly improve the synthesized singing quality reflected in objective and subjective evaluations. Furthermore, incorporating the PE loss in model training is shown to help the F0-contour and high-frequency-band spectrum prediction.      
### 32.CellCycleGAN: Spatiotemporal Microscopy Image Synthesis of Cell Populations using Statistical Shape Models and Conditional GANs  [ :arrow_down: ](https://arxiv.org/pdf/2010.12011.pdf)
>  Automatic analysis of spatio-temporal microscopy images is inevitable for state-of-the-art research in the life sciences. Recent developments in deep learning provide powerful tools for automatic analyses of such image data, but heavily depend on the amount and quality of provided training data to perform well. To this end, we developed a new method for realistic generation of synthetic 2D+t microscopy image data of fluorescently labeled cellular nuclei. The method combines spatiotemporal statistical shape models of different cell cycle stages with a conditional GAN to generate time series of cell populations and provides instance-level control of cell cycle stage and the fluorescence intensity of generated cells. We show the effect of the GAN conditioning and create a set of synthetic images that can be readily used for training and benchmarking of cell segmentation and tracking approaches.      
### 33.Deep Convolutional Neural Networks Model-based Brain Tumor Detection in Brain MRI Images  [ :arrow_down: ](https://arxiv.org/pdf/2010.11978.pdf)
>  Diagnosing Brain Tumor with the aid of Magnetic Resonance Imaging (MRI) has gained enormous prominence over the years, primarily in the field of medical science. Detection and/or partitioning of brain tumors solely with the aid of MR imaging is achieved at the cost of immense time and effort and demands a lot of expertise from engaged personnel. This substantiates the necessity of fabricating an autonomous model brain tumor diagnosis. Our work involves implementing a deep convolutional neural network (DCNN) for diagnosing brain tumors from MR images. The dataset used in this paper consists of 253 brain MR images where 155 images are reported to have tumors. Our model can single out the MR images with tumors with an overall accuracy of 96%. The model outperformed the existing conventional methods for the diagnosis of brain tumor in the test dataset (Precision = 0.93, Sensitivity = 1.00, and F1-score = 0.97). Moreover, the proposed model's average precision-recall score is 0.93, Cohen's Kappa 0.91, and AUC 0.95. Therefore, the proposed model can help clinical experts verify whether the patient has a brain tumor and, consequently, accelerate the treatment procedure.      
### 34.A modified Bayesian Convolutional Neural Network for Breast Histopathology Image Classification and Uncertainty Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2010.12575.pdf)
>  Convolutional neural network (CNN) based classification models have been successfully used on histopathological images for the detection of diseases. Despite its success, CNN may yield erroneous or overfitted results when the data is not sufficiently large or is biased. To overcome these limitations of CNN and to provide uncertainty quantification Bayesian CNN is recently proposed. However, we show that Bayesian-CNN still suffers from inaccuracies, especially in negative predictions. In the present work, we extend the Bayesian-CNN to improve accuracy and the rate of convergence. The proposed model is called modified Bayesian-CNN. The novelty of the proposed model lies in an adaptive activation function that contains a learnable parameter for each of the neurons. This adaptive activation function dynamically changes the loss function thereby providing faster convergence and better accuracy. The uncertainties associated with the predictions are obtained since the model learns a probability distribution on the network parameters. It reduces overfitting through an ensemble averaging over networks, which in turn improves accuracy on the unknown data. The proposed model demonstrates significant improvement by nearly eliminating overfitting and remarkably reducing (about 38%) the number of false-negative predictions. We found that the proposed model predicts higher uncertainty for images having features of both the classes. The uncertainty in the predictions of individual images can be used to decide when further human-expert intervention is needed. These findings have the potential to advance the state-of-the-art machine learning based automatic classification for histopathological images.      
### 35.Performance Analysis of Distributed Intelligent Reflective Surfaces for Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2010.12543.pdf)
>  In this paper, a comprehensive performance analysis of a distributed intelligent reflective surfaces (IRS)-aided communication system is presented. First, the optimal signal-to-noise ratio (SNR), which is attainable through the direct and reflected channels, is quantified by controlling the phase-shifts of the distributed IRS. Next, this optimal SNR is statistically characterized by deriving tight approximations to the exact probability density function (PDF) and cumulative distribution function (CDF) for Nakagami-$m$ fading.The accuracy/tightness of this statistical characterization is investigated by deriving the Kullback-Leibler divergence. Our PDF/CDF analysis is used to derive tight approximations/bounds for the outage probability, achievable rate, and average symbol error rate (SER) in closed-form. To obtain useful insights, the asymptotic outage probability and average SER are derived for the high SNR regime. Thereby, the achievable diversity order and array gains are quantified. Our asymptotic performance analysis reveals that the diversity order can be boosted by using distributed passive IRS without generating additional electromagnetic (EM) waves via active radio frequency chains. Our asymptotic rate analysis shows that the lower and upper rate bounds converge to an asymptotic limit in large reflective element regime in which the transmit power can be scaled inversely proportional to the square of the number of reflective elements.      
### 36.Graph and graphon neural network stability  [ :arrow_down: ](https://arxiv.org/pdf/2010.12529.pdf)
>  Graph neural networks (GNNs) are learning architectures that rely on knowledge of the graph structure to generate meaningful representations of large-scale network data. GNN stability is thus important as in real-world scenarios there are typically uncertainties associated with the graph. We analyze GNN stability using kernel objects called graphons. Graphons are both limits of convergent graph sequences and generating models for deterministic and stochastic graphs. Building upon the theory of graphon signal processing, we define graphon neural networks and analyze their stability to graphon perturbations. We then extend this analysis by interpreting the graphon neural network as a generating model for GNNs on deterministic and stochastic graphs instantiated from the original and perturbed graphons. We observe that GNNs are stable to graphon perturbations with a stability bound that decreases asymptotically with the size of the graph. This asymptotic behavior is further demonstrated in an experiment of movie recommendation.      
### 37.Detection of Replay Attacks to GNSS based on Partial Correlations and Authentication Data Unpredictability  [ :arrow_down: ](https://arxiv.org/pdf/2010.12502.pdf)
>  Intentional interference, and in particular GNSS spoofing, is currently one of the greatest concerns of the Positioning, Navigation and Timing (PNT) community. With the adoption of Open Service Navigation Message Authentication (OSNMA) in Galileo, the E1B signal component will continuously broadcast unpredictable cryptographic data. This allows GNSS receivers not only to ensure the data origin authenticity but also to detect replay spoofing attacks for receivers already tracking real signals with relatively good visibility conditions. As the spoofer needs to estimate with almost zero delay the unpredictable bits introduced by OSNMA in order to perform a Security Code Estimation and Replay (SCER) attack, the spoofer unavoidably introduces a slight distortion into the signal, which can be the basis of a spoofing detector. In this work, we propose five detectors based on partial correlations of GNSS signals obtained over predictable and unpredictable parts of the signals. We evaluate them in a wide set of scenarios including different types of receiver and spoofing conditions. Results show that one of the detectors is consistently superior to the others, and it is able to detect SCER attacks with a high probability even in favorable conditions for the spoofer. Finally, we discuss some practical considerations for implementing the proposed detector in receivers, in particular when the Galileo OSNMA message structure is used.      
### 38.EML System Description for VoxCeleb Speaker Diarization Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2010.12497.pdf)
>  This technical report describes the EML submission to the first VoxCeleb speaker diarization challenge. Although the aim of the challenge has been the offline processing of the signals, the submitted system is basically the EML online algorithm which decides about the speaker labels in runtime approximately every 1.2 sec. For the first phase of the challenge, only VoxCeleb2 dev dataset was used for training. The results on the provided VoxConverse dev set show much better accuracy in terms of both DER and JER compared to the offline baseline provided in the challenge. The real-time factor of the whole diarization process is about 0.01 using a single CPU machine.      
### 39.Divide and Conquer: One-Bit MIMO-OFDM Detection by Inexact Expectation Maximization  [ :arrow_down: ](https://arxiv.org/pdf/2010.12492.pdf)
>  Adopting one-bit analog-to-digital convertors (ADCs) for massive multiple-input multiple-output (MIMO) implementations has great potential in reducing the hardware cost and power consumption. However, distortions caused by quantization raise great challenges. In MIMO orthogonal frequency-division modulation (OFDM) detection, coarse quantization renders the orthogonal separation among subcarriers inapplicable, forcing us to deal with a problem that has a very large problem size. In this paper we study the expectation-maximization (EM) approach for one-bit MIMO-OFDM detection. The idea is to iteratively decouple the MIMO-OFDM detection problem among subcarriers. Using the perspective of block coordinate descent, we describe inexact variants of the classical EM method for providing more flexible and computationally efficient designs. Simulation results are provided to illustrate the potential of the divide-and-conquer strategy enabled by EM.      
### 40.Multi-UAV Path Planning for Wireless Data Harvesting with Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.12461.pdf)
>  Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number and position of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve by training a double deep Q-network (DDQN) to approximate the optimal UAV control policy. By exploiting global-local maps of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints.      
### 41.GraphSpeech: Syntax-Aware Graph Attention Network For Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2010.12423.pdf)
>  Attention-based end-to-end text-to-speech synthesis (TTS) is superior to conventional statistical methods in many ways. Transformer-based TTS is one of such successful implementations. While Transformer TTS models the speech frame sequence well with a self-attention mechanism, it does not associate input text with output utterances from a syntactic point of view at sentence level. We propose a novel neural TTS model, denoted as GraphSpeech, that is formulated under graph neural network framework. GraphSpeech encodes explicitly the syntactic relation of input lexical tokens in a sentence, and incorporates such information to derive syntactically motivated character embeddings for TTS attention mechanism. Experiments show that GraphSpeech consistently outperforms the Transformer TTS baseline in terms of spectrum and prosody rendering of utterances.      
### 42.On the Beamforming Design of Millimeter Wave UAV Networks: Power vs. Capacity Trade-Offs  [ :arrow_down: ](https://arxiv.org/pdf/2010.12380.pdf)
>  The millimeter wave (mmWave) technology enables unmanned aerial vehicles (UAVs) to offer broadband high-speed wireless connectivity in fifth generation (5G) and beyond (6G) networks. However, the limited footprint of a single UAV implementing analog beamforming (ABF) requires multiple aerial stations to operate in swarms to provide ubiquitous network coverage, thereby posing serious constraints in terms of battery power consumption and swarm management. A possible remedy is to investigate the concept of hybrid beamforming (HBF) transceivers, which use a combination of analog beamformers as a solution to achieve higher flexibility in the beamforming design. This approach permits multiple ground users to be served simultaneously by the same UAV station, despite involving higher energy consumption in the radio frequency (RF) domain than its ABF counterpart. This paper presents a tractable stochastic analysis to characterize the downlink ergodic capacity and power consumption of UAV mmWave networks in an urban scenario, focusing on the trade-off between ABF and HBF architectures. A multi-beam coverage model is derived as a function of several UAV-specific parameters, including the number of UAVs, the deployment altitude, the antenna configuration, and the beamforming design. Our results, validated by simulation, show that, while ABF achieves better ergodic capacity at high altitudes, an HBF configuration with multiple beams, despite the use of more power-hungry RF blocks, consumes less power all the time with limited capacity degradation.      
### 43.Fusion of Dual Spatial Information for Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2010.12337.pdf)
>  The inclusion of spatial information into spectral classifiers for fine-resolution hyperspectral imagery has led to significant improvements in terms of classification performance. The task of spectral-spatial hyperspectral image classification has remained challenging because of high intraclass spectrum variability and low interclass spectral variability. This fact has made the extraction of spatial information highly active. In this work, a novel hyperspectral image classification framework using the fusion of dual spatial information is proposed, in which the dual spatial information is built by both exploiting pre-processing feature extraction and post-processing spatial optimization. In the feature extraction stage, an adaptive texture smoothing method is proposed to construct the structural profile (SP), which makes it possible to precisely extract discriminative features from hyperspectral images. The SP extraction method is used here for the first time in the remote sensing community. Then, the extracted SP is fed into a spectral classifier. In the spatial optimization stage, a pixel-level classifier is used to obtain the class probability followed by an extended random walker-based spatial optimization technique. Finally, a decision fusion rule is utilized to fuse the class probabilities obtained by the two different stages. Experiments performed on three data sets from different scenes illustrate that the proposed method can outperform other state-of-the-art classification techniques. In addition, the proposed feature extraction method, i.e., SP, can effectively improve the discrimination between different land covers.      
### 44.Tele-operative Robotic Lung Ultrasound Scanning Platform for Triage of COVID-19 Patients  [ :arrow_down: ](https://arxiv.org/pdf/2010.12335.pdf)
>  Novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has become a pandemic of epic proportions and a global response to prepare health systems worldwide is of utmost importance. In addition to its cost-effectiveness in a resources-limited setting, lung ultrasound (LUS) has emerged as a rapid noninvasive imaging tool for the diagnosis of COVID-19 infected patients. Concerns surrounding LUS include the disparity of infected patients and healthcare providers, relatively small number of physicians and sonographers capable of performing LUS, and most importantly, the requirement for substantial physical contact between the patient and operator, increasing the risk of transmission. Mitigation of the spread of the virus is of paramount importance. A 2-dimensional (2D) tele-operative robotic platform capable of performing LUS in for COVID-19 infected patients may be of significant benefit. The authors address the aforementioned issues surrounding the use of LUS in the application of COVID- 19 infected patients. In addition, first time application, feasibility and safety were validated in three healthy subjects, along with 2D image optimization and comparison for overall accuracy. Preliminary results demonstrate that the proposed platform allows for successful acquisition and application of LUS in humans.      
### 45.A Computational Evaluation of Musical Pattern Discovery Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2010.12325.pdf)
>  Pattern discovery algorithms in the music domain aim to find meaningful components in musical compositions. Over the years, although many algorithms have been developed for pattern discovery in music data, it remains a challenging task. To gain more insight into the efficacy of these algorithms, we introduce three computational methods for examining their output: Pattern Polling, to combine the patterns; Comparative Classification, to differentiate the patterns; Synthetic Data, to inject predetermined patterns. In combining and differentiating the patterns extracted by algorithms, we expose how they differ from the patterns annotated by humans as well as between algorithms themselves, with rhythmic features contributing the most to the algorithm-human and algorithm-algorithm discrepancies. Despite the difficulty in reconciling and evaluating the divergent patterns extracted from algorithms, we identify some possibilities for addressing them. In particular, we generate controllable synthesised data with predetermined patterns planted into random data, thereby leaving us better able to inspect, compare, validate, and select the algorithms. We provide a concrete example of synthesising data for understanding the algorithms and expand our discussion to the potential and limitations of such an approach.      
### 46.Matching the Clinical Reality: Accurate OCT-Based Diagnosis From Few Labels  [ :arrow_down: ](https://arxiv.org/pdf/2010.12316.pdf)
>  Unlabeled data is often abundant in the clinic, making machine learning methods based on semi-supervised learning a good match for this setting. Despite this, they are currently receiving relatively little attention in medical image analysis literature. Instead, most practitioners and researchers focus on supervised or transfer learning approaches. The recently proposed MixMatch and FixMatch algorithms have demonstrated promising results in extracting useful representations while requiring very few labels. Motivated by these recent successes, we apply MixMatch and FixMatch in an ophthalmological diagnostic setting and investigate how they fare against standard transfer learning. We find that both algorithms outperform the transfer learning baseline on all fractions of labelled data. Furthermore, our experiments show that exponential moving average (EMA) of model parameters, which is a component of both algorithms, is not needed for our classification problem, as disabling it leaves the outcome unchanged. Our code is available online: <a class="link-external link-https" href="https://github.com/Valentyn1997/oct-diagn-semi-supervised" rel="external noopener nofollow">this https URL</a>      
### 47.Graph Learning for Clustering Multi-view Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12301.pdf)
>  In this paper, we focus on graph learning from multi-view data of shared entities for clustering. We can explain interactions between the entities in multi-view data using a multi-layer graph with a common vertex set representing the shared entities. The edges on different layers capture the relationships of the entities. Assuming a smoothness data model, we estimate the graph Laplacian matrices of the individual graph layers by constraining their ranks to obtain multi-component graph layers for clustering. We also learn low-dimensional node embeddings, common to all the views, that assimilate the complementary information present in the views. We propose an efficient solver based on alternating minimization to solve the proposed multi-layer multi-component graph learning problem. Numerical experiments on synthetic and real datasets demonstrate that the proposed algorithm outperforms state-of-the-art multi-view clustering techniques.      
### 48.Graph-Homomorphic Perturbations for Private Decentralized Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.12288.pdf)
>  Decentralized algorithms for stochastic optimization and learning rely on the diffusion of information as a result of repeated local exchanges of intermediate estimates. Such structures are particularly appealing in situations where agents may be hesitant to share raw data due to privacy concerns. Nevertheless, in the absence of additional privacy-preserving mechanisms, the exchange of local estimates, which are generated based on private data can allow for the inference of the data itself. The most common mechanism for guaranteeing privacy is the addition of perturbations to local estimates before broadcasting. These perturbations are generally chosen independently at every agent, resulting in a significant performance loss. We propose an alternative scheme, which constructs perturbations according to a particular nullspace condition, allowing them to be invisible (to first order in the step-size) to the network centroid, while preserving privacy guarantees. The analysis allows for general nonconvex loss functions, and is hence applicable to a large number of machine learning and signal processing problems, including deep learning.      
### 49.Speech Activity Detection Based on Multilingual Speech Recognition System  [ :arrow_down: ](https://arxiv.org/pdf/2010.12277.pdf)
>  To better model the contextual information and increase the generalization ability of a voice detection system, this paper leverages a multi-lingual Automatic Speech Recognition (ASR) system to perform Speech Activity Detection (SAD). Sequence-discriminative training of multi-lingual Acoustic Model (AM) using Lattice-Free Maximum Mutual Information (LF-MMI) loss function, effectively extracts the contextual information of the input acoustic frame. The index of maximum output posterior is considered as a frame-level speech/non-speech decision function. Majority voting and logistic regression are applied to fuse the language-dependent decisions. The leveraged multi-lingual ASR is trained on 18 languages of BABEL datasets and the built SAD is evaluated on 3 different languages. In out-of-domain datasets, the proposed SAD model shows significantly better performance w.r.t. baseline models. In the Ester2 dataset, without using any in-domain data, this model outperforms the WebRTC, phoneme recognizer based VAD (Phn\_Rec), and Pyannote baselines (respectively 7.1, 1.7, and 2.7% absolutely) in Detection Error Rate (DetER) metrics. Similarly, in the LiveATC dataset, this model outperforms the WebRTC, Phn\_Rec, and Pyannote baselines (respectively 6.4, 10.0, and 3.7% absolutely) in DetER metrics.      
### 50.VIRAL-Fusion: A Visual-Inertial-Ranging-Lidar Sensor Fusion Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.12274.pdf)
>  In recent years, Onboard Self Localization (OSL) methods based on cameras or Lidar have achieved many significant progresses. However, some issues such as estimation drift and feature-dependence still remain inherent limitations. On the other hand, infrastructure-based methods can generally overcome these issues, but at the expense of some installation cost. This poses an interesting problem of how to effectively combine these methods, so as to achieve localization with long-term consistency as well as flexibility compared to any single method. To this end, we propose a comprehensive optimization-based estimator for 15-dimensional state of an Unmanned Aerial Vehicle (UAV), fusing data from an extensive set of sensors: inertial measurement units (IMUs), Ultra-Wideband (UWB) ranging sensors, and multiple onboard Visual-Inertial and Lidar odometry subsystems. In essence, a sliding window is used to formulate a sequence of robot poses, where relative rotational and translational constraints between these poses are observed in the IMU preintegration and OSL observations, while orientation and position are coupled in body-offset UWB range observations. An optimization-based approach is developed to estimate the trajectory of the robot in this sliding window. We evaluate the performance of the proposed scheme in multiple scenarios, including experiments on public datasets, high-fidelity graphical-physical simulator, and field-collected data from UAV flight tests. The result demonstrates that our integrated localization method can effectively resolve the drift issue, while incurring minimal installation requirements.      
### 51.Don't shoot butterfly with rifles: Multi-channel Continuous Speech Separation with Early Exit Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2010.12180.pdf)
>  With its strong modeling capacity that comes from a multi-head and multi-layer structure, Transformer is a very powerful model for learning a sequential representation and has been successfully applied to speech separation recently. However, multi-channel speech separation sometimes does not necessarily need such a heavy structure for all time frames especially when the cross-talker challenge happens only occasionally. For example, in conversation scenarios, most regions contain only a single active speaker, where the separation task downgrades to a single speaker enhancement problem. It turns out that using a very deep network structure for dealing with signals with a low overlap ratio not only negatively affects the inference efficiency but also hurts the separation performance. To deal with this problem, we propose an early exit mechanism, which enables the Transformer model to handle different cases with adaptive depth. Experimental results indicate that not only does the early exit mechanism accelerate the inference, but it also improves the accuracy.      
### 52.Transformer-based End-to-End Speech Recognition with Local Dense Synthesizer Attention  [ :arrow_down: ](https://arxiv.org/pdf/2010.12155.pdf)
>  Recently, several studies reported that dot-product selfattention (SA) may not be indispensable to the state-of-theart Transformer models. Motivated by the fact that dense synthesizer attention (DSA), which dispenses with dot products and pairwise interactions, achieved competitive results in many language processing tasks, in this paper, we first propose a DSA-based speech recognition, as an alternative to SA. To reduce the computational complexity and improve the performance, we further propose local DSA (LDSA) to restrict the attention scope of DSA to a local range around the current central frame for speech recognition. Finally, we combine LDSA with SA to extract the local and global information simultaneously. Experimental results on the Ai-shell1 Mandarine speech recognition corpus show that the proposed LDSA-Transformer achieves a character error rate (CER) of 6.49%, which is slightly better than that of the SA-Transformer. Meanwhile, the LDSA-Transformer requires less computation than the SATransformer. The proposed combination method not only achieves a CER of 6.18%, which significantly outperforms the SA-Transformer, but also has roughly the same number of parameters and computational complexity as the latter. The implementation of the multi-head LDSA is available at <a class="link-external link-https" href="https://github.com/mlxu995/multihead-LDSA" rel="external noopener nofollow">this https URL</a>.      
### 53.Reliable Over-the-Air Computation by Amplify-and-Forward Based Relay  [ :arrow_down: ](https://arxiv.org/pdf/2010.12146.pdf)
>  In typical sensor networks, data collection and processing are separated. A sink collects data from each node, one by one, which is very time consuming. Over-the-air computation, as a new diagram of sensor networks, integrates data collection and processing in one slot: all nodes transmit their signals simultaneously in the analog wave, and the processing is done in the air, by the addition of electromagnetic wave. This is very efficient, but it requires that signals from all nodes arrive at the sink, aligned in signal magnitude so as to enable unbiased estimation. For a node far away from the sink with a low channel gain, misalignment in signal magnitude is unavoidable. To solve this problem and improve system reliability, in this paper, we investigate the amplify-and-forward based relay. This is different from conventional relay in that the relay node needs to amplify signals from many nodes at the same time, and the signals arriving at the sink should still be aligned in signal magnitude. We discuss the general case and solutions to several special cases. Simulation results confirm the effectiveness of the proposed methods in reducing the computation error.      
### 54.Enriching Under-Represented Named-Entities To Improve Speech Recognition Performance  [ :arrow_down: ](https://arxiv.org/pdf/2010.12143.pdf)
>  Automatic speech recognition (ASR) for under-represented named-entity (UR-NE) is challenging due to such named-entities (NE) have insufficient instances and poor contextual coverage in the training data to learn reliable estimates and representations. In this paper, we propose approaches to enriching UR-NEs to improve speech recognition performance. Specifically, our first priority is to ensure those UR-NEs to appear in the word lattice if there is any. To this end, we make exemplar utterances for those UR-NEs according to their categories (e.g. location, person, organization, etc.), ending up with an improved language model (LM) that boosts the UR-NE occurrence in the word lattice. With more UR-NEs appearing in the lattice, we then boost the recognition performance through lattice rescoring methods. We first enrich the representations of UR-NEs in a pre-trained recurrent neural network LM (RNNLM) by borrowing the embedding representations of the rich-represented NEs (RR-NEs), yielding the lattices that statistically favor the UR-NEs. Finally, we directly boost the likelihood scores of the utterances containing UR-NEs and gain further performance improvement.      
### 55.GSEP: A robust vocal and accompaniment separation system using gated CBHG module and loudness normalization  [ :arrow_down: ](https://arxiv.org/pdf/2010.12139.pdf)
>  In the field of audio signal processing research, source separation has been a popular research topic for a long time and the recent adoption of the deep neural networks have shown a significant improvement in performance. The improvement vitalizes the industry to productize audio deep learning based products and services including Karaoke in the music streaming apps and dialogue enhancement in the UHDTV. For these early markets, we defined a set of design principles of the vocal and accompaniment separation model in terms of robustness, quality, and cost. In this paper, we introduce GSEP (Gaudio source SEParation system), a robust vocal and accompaniment separation system using a Gated- CBHG module, mask warping, and loudness normalization and it was verified that the proposed system satisfies all three principles and outperforms the state-of-the-art systems both in objective measure and subjective assessment through experiments.      
### 56.An Inertial Block Majorization Minimization Framework for Nonsmooth Nonconvex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.12133.pdf)
>  In this paper, we introduce TITAN, a novel inerTial block majorIzation minimization framework for non-smooth non-convex opTimizAtioN problems. TITAN is a block coordinate method (BCM) that embeds inertial force to each majorization-minimization step of the block updates. The inertial force is obtained via an extrapolation operator that subsumes heavy-ball and Nesterov-type accelerations for block proximal gradient methods as special cases. By choosing various surrogate functions, such as proximal, Lipschitz gradient, Bregman, quadratic, and composite surrogate functions, and by varying the extrapolation operator, TITAN produces a rich set of inertial BCMs. We study sub-sequential convergence as well as global convergence for the generated sequence of TITAN. We illustrate the effectiveness of TITAN on two important machine learning problems, namely sparse non-negative matrix factorization and matrix completion.      
### 57.GPS-Denied Navigation Using SAR Images and Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.12108.pdf)
>  Unmanned aerial vehicles (UAV) often rely on GPS for navigation. GPS signals, however, are very low in power and easily jammed or otherwise disrupted. This paper presents a method for determining the navigation errors present at the beginning of a GPS-denied period utilizing data from a synthetic aperture radar (SAR) system. This is accomplished by comparing an online-generated SAR image with a reference image obtained a priori. The distortions relative to the reference image are learned and exploited with a convolutional neural network to recover the initial navigational errors, which can be used to recover the true flight trajectory throughout the synthetic aperture. The proposed neural network approach is able to learn to predict the initial errors on both simulated and real SAR image data.      
### 58.Improving Streaming Automatic Speech Recognition With Non-Streaming Model Distillation On Unsupervised Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.12096.pdf)
>  Streaming end-to-end automatic speech recognition (ASR) models are widely used on smart speakers and on-device applications. Since these models are expected to transcribe speech with minimal latency, they are constrained to be causal with no future context, compared to their non-streaming counterparts. Consequently, streaming models usually perform worse than non-streaming models. We propose a novel and effective learning method by leveraging a non-streaming ASR model as a teacher to generate transcripts on an arbitrarily large data set, which is then used to distill knowledge into streaming ASR models. This way, we scale the training of streaming models to up to 3 million hours of YouTube audio. Experiments show that our approach can significantly reduce the word error rate (WER) of RNNT models not only on LibriSpeech but also on YouTube data in four languages. For example, in French, we are able to reduce the WER by 16.4% relatively to a baseline streaming model by leveraging a non-streaming teacher model trained on the same amount of labeled data as the baseline.      
### 59.Learning Patterns in Imaginary Vowels for an Intelligent Brain Computer Interface (BCI) Design  [ :arrow_down: ](https://arxiv.org/pdf/2010.12066.pdf)
>  Technology advancements made it easy to measure non-invasive and high-quality electroencephalograph (EEG) signals from human's brain. Hence, development of robust and high-performance AI algorithms becomes crucial to properly process the EEG signals and recognize the patterns, which lead to an appropriate control signal. Despite the advancements in processing the motor imagery EEG signals, the healthcare applications, such as emotion detection, are still in the early stages of AI design. In this paper, we propose a modular framework for the recognition of vowels as the AI part of a brain computer interface system. We carefully designed the modules to discriminate the English vowels given the raw EEG signals, and meanwhile avoid the typical issued with the data-poor environments like most of the healthcare applications. The proposed framework consists of appropriate signal segmentation, filtering, extraction of spectral features, reducing the dimensions by means of principle component analysis, and finally a multi-class classification by decision-tree-based support vector machine (DT-SVM). The performance of our framework was evaluated by a combination of test-set and resubstitution (also known as apparent) error rates. We provide the algorithms of the proposed framework to make it easy for future researchers and developers who want to follow the same workflow.      
### 60.A generalized deep learning model for multi-disease Chest X-Ray diagnostics  [ :arrow_down: ](https://arxiv.org/pdf/2010.12065.pdf)
>  We investigate the generalizability of deep convolutional neural network (CNN) on the task of disease classification from chest x-rays collected over multiple sites. We systematically train the model using datasets from three independent sites with different patient populations: National Institute of Health (NIH), Stanford University Medical Centre (CheXpert), and Shifa International Hospital (SIH). We formulate a sequential training approach and demonstrate that the model produces generalized prediction performance using held out test sets from the three sites. Our model generalizes better when trained on multiple datasets, with the CheXpert-Shifa-NET model performing significantly better (p-values &lt; 0.05) than the models trained on individual datasets for 3 out of the 4 distinct disease classes. The code for training the model will be made available open source at: <a class="link-external link-http" href="http://www.github.com/link-to-code" rel="external noopener nofollow">this http URL</a> at the time of publication.      
### 61.Explaining Neural Network Predictions for Functional Data Using Principal Component Analysis and Feature Importance  [ :arrow_down: ](https://arxiv.org/pdf/2010.12063.pdf)
>  Optical spectral-temporal signatures extracted from videos of explosions provide information for identifying characteristics of the corresponding explosive devices. Currently, the identification is done using heuristic algorithms and direct subject matter expert review. An improvement in predictive performance may be obtained by using machine learning, but this application lends itself to high consequence national security decisions, so it is not only important to provide high accuracy but clear explanations for the predictions to garner confidence in the model. While much work has been done to develop explainability methods for machine learning models, not much of the work focuses on situations with input variables of the form of functional data such optical spectral-temporal signatures. We propose a procedure for explaining machine learning models fit using functional data that accounts for the functional nature the data. Our approach makes use of functional principal component analysis (fPCA) and permutation feature importance (PFI). fPCA is used to transform the functions to create uncorrelated functional principal components (fPCs). The model is trained using the fPCs as inputs, and PFI is applied to identify the fPCs important to the model for prediction. Visualizations are used to interpret the variability explained by the fPCs that are found to be important by PFI to determine the aspects of the functions that are important for prediction. We demonstrate the technique by explaining neural networks fit to explosion optical spectral-temporal signatures for predicting characteristics of the explosive devices.      
### 62.Combination of Deep Speaker Embeddings for Diarisation  [ :arrow_down: ](https://arxiv.org/pdf/2010.12025.pdf)
>  Recently, significant progress has been made in speaker diarisation after the introduction of d-vectors as speaker embeddings extracted from the neural network (NN) speaker classifiers for clustering speech segments. To extract better-performing and more robust speaker embeddings, this paper proposes a c-vector method by combining multiple sets of complementary d-vectors derived from systems with different NN components. Three structures are used to implement the c-vectors, namely 2D self-attentive, gated additive, and bilinear pooling structures, relying on attention mechanisms, a gating mechanism, and a low-rank bilinear pooling mechanism respectively. Furthermore, a neural-based single-pass speaker diarisation pipeline is also proposed in this paper, which uses NNs to achieve voice activity detection, speaker change point detection, and speaker embedding extraction. Experiments and detailed analyses are conducted on the challenging AMI and NIST RT05 datasets which consist of real meetings with 4--10 speakers and a wide range of acoustic conditions. Consistent improvements are obtained by using c-vectors instead of d-vectors, and similar relative improvements in diarisation error rates are observed on both AMI and RT05, which shows the robustness of the proposed methods.      
### 63.Listening to Sounds of Silence for Speech Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2010.12013.pdf)
>  We introduce a deep learning model for speech denoising, a long-standing challenge in audio analysis arising in numerous applications. Our approach is based on a key observation about human speech: there is often a short pause between each sentence or word. In a recorded speech signal, those pauses introduce a series of time periods during which only noise is present. We leverage these incidental silent intervals to learn a model for automatic speech denoising given only mono-channel audio. Detected silent intervals over time expose not just pure noise but its time-varying features, allowing the model to learn noise dynamics and suppress it from the speech signal. Experiments on multiple datasets confirm the pivotal role of silent interval detection for speech denoising, and our method outperforms several state-of-the-art denoising methods, including those that accept only audio input (like ours) and those that denoise based on audiovisual input (and hence require more information). We also show that our method enjoys excellent generalization properties, such as denoising spoken languages not seen during training.      
### 64.Unsupervised deep learning for grading of age-related macular degeneration using retinal fundus images  [ :arrow_down: ](https://arxiv.org/pdf/2010.11993.pdf)
>  Many diseases are classified based on human-defined rubrics that are prone to bias. Supervised neural networks can automate the grading of retinal fundus images, but require labor-intensive annotations and are restricted to the specific trained task. Here, we employed an unsupervised network with Non-Parametric Instance Discrimination (NPID) to grade age-related macular degeneration (AMD) severity using fundus photographs from the Age-Related Eye Disease Study (AREDS). Our unsupervised algorithm demonstrated versatility across different AMD classification schemes without retraining, and achieved unbalanced accuracies comparable to supervised networks and human ophthalmologists in classifying advanced or referable AMD, or on the 4-step AMD severity scale. Exploring the networks behavior revealed disease-related fundus features that drove predictions and unveiled the susceptibility of more granular human-defined AMD severity schemes to misclassification by both ophthalmologists and neural networks. Importantly, unsupervised learning enabled unbiased, data-driven discovery of AMD features such as geographic atrophy, as well as other ocular phenotypes of the choroid, vitreous, and lens, such as visually-impairing cataracts, that were not pre-defined by human labels.      
### 65.Atlas Fusion -- Modern Framework for Autonomous Agent Sensor Data Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2010.11991.pdf)
>  In this paper, we present our new sensor fusion framework for self-driving cars and other autonomous robots. We have designed our framework as a universal and scalable platform for building up a robust 3D model of the agent's surrounding environment by fusing a wide range of various sensors into the data model that we can use as a basement for the decision making and planning algorithms. Our software currently covers the data fusion of the RGB and thermal cameras, 3D LiDARs, 3D IMU, and a GNSS positioning. The framework covers a complete pipeline from data loading, filtering, preprocessing, environment model construction, visualization, and data storage. The architecture allows the community to modify the existing setup or to extend our solution with new ideas. The entire software is fully compatible with ROS (Robotic Operation System), which allows the framework to cooperate with other ROS-based software. The source codes are fully available as an open-source under the MIT license. See <a class="link-external link-https" href="https://github.com/Robotics-BUT/Atlas-Fusion" rel="external noopener nofollow">this https URL</a>.      
### 66.Developing Real-time Streaming Transformer Transducer for Speech Recognition on Large-scale Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2010.11395.pdf)
>  Recently, Transformer based end-to-end models have achieved great success in many areas including speech recognition. However, compared to LSTM models, the heavy computational cost of the Transformer during inference is a key issue to prevent their applications. In this work, we explored the potential of Transformer Transducer (T-T) models for the fist pass decoding with low latency and fast speed on a large-scale dataset. We combine the idea of Transformer-XL and chunk-wise streaming processing to design a streamable Transformer Transducer model. We demonstrate that T-T outperforms the hybrid model, RNN Transducer (RNN-T), and streamable Transformer attention-based encoder-decoder model in the streaming scenario. Furthermore, the runtime cost and latency can be optimized with a relatively small look-ahead.      

# ArXiv eess --Fri, 23 Oct 2020
### 1.Contrastive Self-Supervised Learning for Wireless Power Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.11909.pdf)
>  We propose a new approach for power control in wireless networks using self-supervised learning. We partition a multi-layer perceptron that takes as input the channel matrix and outputs the power control decisions into a backbone and a head, and we show how we can use contrastive learning to pre-train the backbone so that it produces similar embeddings at its output for similar channel matrices and vice versa, where similarity is defined in an information-theoretic sense by identifying the interference links that can be optimally treated as noise. The backbone and the head are then fine-tuned using a limited number of labeled samples. Simulation results show the effectiveness of the proposed approach, demonstrating significant gains over pure supervised learning methods in both sum-throughput and sample efficiency.      
### 2.Position-Agnostic Multi-Microphone Speech Dereverberation  [ :arrow_down: ](https://arxiv.org/pdf/2010.11875.pdf)
>  Neural networks (NNs) have been widely applied in speech processing tasks, and, in particular, those employing microphone arrays. Nevertheless, most of the existing NN architectures can only deal with fixed and position-specific microphone arrays. In this paper, we present an NN architecture that can cope with microphone arrays on which no prior knowledge is presumed, and demonstrate its applicability on the speech dereverberation problem. To this end, our approach harnesses recent advances in the Deep Sets framework to design an architecture that enhances the reverberant log-spectrum. We provide a setup for training and testing such a network. Our experiments, using REVERB challenge datasets, show that the proposed position-agnostic setup performs comparably with the position-aware framework and sometimes slightly better, even with fewer microphones. In addition, it substantially improves performance over a single microphone architecture.      
### 3.Parameter Reduction in Probabilistic Critical Time Evaluation Using Sensitivity Analysis and PCA  [ :arrow_down: ](https://arxiv.org/pdf/2010.11868.pdf)
>  In this paper, we discuss a method to find the most influential power system parameters to the probabilistic transient stability assessment problem---finding the probability distribution of the critical clearing time. We perform the parameter selection by employing a sensitivity analysis combined with a principal component analysis. First, we determine the sensitivity of the machine angles with respect to all system parameters. Second, we employ the principal component analysis algorithm to identify the most influential parameters in the transient stability problem. By identifying such parameters, we can reduce the number of uncertain parameters to only the influential ones in the probabilistic assessment of transient stability, providing a significant speed-up in the probabilistic analysis of large power systems. The proposed algorithm was tested in the IEEE 14 bus systems and the results obtained show that our method can effectively find the most influential parameters.      
### 4.Perceptual Loss based Speech Denoising with an ensemble of Audio Pattern Recognition and Self-Supervised Models  [ :arrow_down: ](https://arxiv.org/pdf/2010.11860.pdf)
>  Deep learning based speech denoising still suffers from the challenge of improving perceptual quality of enhanced signals. We introduce a generalized framework called Perceptual Ensemble Regularization Loss (PERL) built on the idea of perceptual losses. Perceptual loss discourages distortion to certain speech properties and we analyze it using six large-scale pre-trained models: speaker classification, acoustic model, speaker embedding, emotion classification, and two self-supervised speech encoders (PASE+, wav2vec 2.0). We first build a strong baseline (w/o PERL) using Conformer Transformer Networks on the popular enhancement benchmark called VCTK-DEMAND. Using auxiliary models one at a time, we find acoustic event and self-supervised model PASE+ to be most effective. Our best model (PERL-AE) only uses acoustic event model (utilizing AudioSet) to outperform state-of-the-art methods on major perceptual metrics. To explore if denoising can leverage full framework, we use all networks but find that our seven-loss formulation suffers from the challenges of Multi-Task Learning. Finally, we report a critical observation that state-of-the-art Multi-Task weight learning methods cannot outperform hand tuning, perhaps due to challenges of domain mismatch and weak complementarity of losses.      
### 5.Pushing The Limit of Type I Codebook For FDD Massive MIMO Beamforming: A Channel Covariance Reconstruction Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.11840.pdf)
>  There is a fundamental trade-off between the channel representation resolution of codebooks and the overheads of feedback communications in the fifth generation new radio (5G NR) frequency division duplex (FDD) massive multiple-input and multiple-output (MIMO) systems. In particular, two types of codebooks (namely Type I and Type II codebooks) are introduced with different resolution and overhead requirements. Although the Type I codebook based scheme requires lower feedback overhead, its channel state information (CSI) reconstruction and beamforming performance are not as good as those from the Type II codebook based scheme. However, since the Type I codebook based scheme has been widely used in 4G systems for many years, replacing it by the Type II codebook based scheme overnight is too costly to be an option. Therefore, in this paper, using Type I codebook, we leverage advances in cutting plane method to optimize the CSI reconstruction at the base station (BS), in order to close the gap between these two codebook based beamforming schemes. Numerical results based on channel samples from QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa) are presented to show the excellent performance of the proposed algorithm in terms of beamforming vector acquisition.      
### 6.Unsupervised Segmentation of B-Mode Echocardiograms  [ :arrow_down: ](https://arxiv.org/pdf/2010.11816.pdf)
>  We present a method for unsupervised segmentation of echocardiograms (echo). The method uses an iterative Dijkstra's algorithm, a strategic node selection, and a novel cost matrix formulation based on intensity peak prominence and is thus termed the "Prominence Iterative Dijkstra's" algorithm, or ProID. Although the current analysis focuses on the left ventricle (LV), ProID is applicable to all four heart chambers. ProID was tested using artificial echo images representing five different systems. Results showed accurate LV contours and volume estimations as compared to the ground-truth for all systems. Subsequently, ProID was used to analyze a clinical cohort of 66 pediatric patients, including both normal and diseased hearts. Output segmentations, end-diastolic, end-systolic volumes, and ejection fraction (EF) were compared against manual segmentations from two expert readers. ProID maintained an average Dice similarity score of 0.93 when comparing against manual segmentation. Comparing the two expert readers, the manual segmentations maintained a score of 0.93, which increased to 0.95 when they used ProID. Thus, ProID successfully reduced the inter-operator variability across the two expert readers. Overall, this work demonstrates that ProID yields accurate boundaries across all age groups, disease states, and echo platforms with low computation cost, thereby establishing its clinical usefulness.      
### 7.Iterative Decomposition of Joint Chance Constraints in OPF  [ :arrow_down: ](https://arxiv.org/pdf/2010.11746.pdf)
>  In chance-constrained OPF models, joint chance constraints (JCCs) offer a stronger guarantee on security compared to single chance constraints (SCCs). Using Boole's inequality or its improved versions to decompose JCCs into SCCs is popular, yet the conservativeness introduced is still significant. In this letter, a non-parametric iterative framework is proposed to achieve the decomposition of JCCs with negligible conservativeness. An adaptive risk allocation strategy is also proposed and embedded in the framework. Results on an IEEE test case show that the conservativeness using the framework is nearly eliminated, thereby reducing the generation cost considerably.      
### 8.Ultra-low power on-chip learning of speech commands with phase-change memories  [ :arrow_down: ](https://arxiv.org/pdf/2010.11741.pdf)
>  Embedding artificial intelligence at the edge (edge-AI) is an elegant solution to tackle the power and latency issues in the rapidly expanding Internet of Things. As edge devices typically spend most of their time in sleep mode and only wake-up infrequently to collect and process sensor data, non-volatile in-memory computing (NVIMC) is a promising approach to design the next generation of edge-AI devices. Recently, we proposed an NVIMC-based neuromorphic accelerator using the phase change memories (PCMs), which we call as Raven. In this work, we demonstrate the ultra-low-power on-chip training and inference of speech commands using Raven. We showed that Raven can be trained on-chip with power consumption as low as 30~uW, which is suitable for edge applications. Furthermore, we showed that at iso-accuracies, Raven needs 70.36x and 269.23x less number of computations to be performed than a deep neural network (DNN) during inference and training, respectively. Owing to such low power and computational requirements, Raven provides a promising pathway towards ultra-low-power training and inference at the edge.      
### 9.Analysis of the BUT Diarization System for VoxConverse Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2010.11718.pdf)
>  This paper describes the system developed by the BUT team for the fourth track of the VoxCeleb Speaker Recognition Challenge, focusing on diarization on the VoxConverse dataset. The system consists of signal pre-processing, voice activity detection, speaker embedding extraction, an initial agglomerative hierarchical clustering followed by diarization using a Bayesian hidden Markov model, a reclustering step based on per-speaker global embeddings and overlapped speech detection and handling. We provide comparisons for each of the steps and share the implementation of the most relevant modules of our system. Our system scored second in the challenge in terms of the primary metric (diarization error rate) and first according to the secondary metric (Jaccard error rate).      
### 10.A novel convolutional neural network model to remove muscle artifacts from EEG  [ :arrow_down: ](https://arxiv.org/pdf/2010.11709.pdf)
>  The recorded electroencephalography (EEG) signals are usually contaminated by many artifacts. In recent years, deep learning models have been used for denoising of electroencephalography (EEG) data and provided comparable performance with that of traditional techniques. However, the performance of the existing networks in electromyograph (EMG) artifact removal was limited and suffered from the over-fitting problem. Here we introduce a novel convolutional neural network (CNN) with gradually ascending feature dimensions and downsampling in time series for removing muscle artifacts in EEG data. Compared with other types of convolutional networks, this model largely eliminates the over-fitting and significantly outperforms four benchmark networks in EEGdenoiseNet. Our study suggested that the deep network architecture might help avoid overfitting and better remove EMG artifacts in EEG.      
### 11.OCT-GAN: Single Step Shadow and Noise Removal from Optical Coherence Tomography Images of the Human Optic Nerve Head  [ :arrow_down: ](https://arxiv.org/pdf/2010.11698.pdf)
>  Speckle noise and retinal shadows within OCT B-scans occlude important edges, fine textures and deep tissues, preventing accurate and robust diagnosis by algorithms and clinicians. We developed a single process that successfully removed both noise and retinal shadows from unseen single-frame B-scans within 10.4ms. Mean average gradient magnitude (AGM) for the proposed algorithm was 57.2% higher than current state-of-the-art, while mean peak signal to noise ratio (PSNR), contrast to noise ratio (CNR), and structural similarity index metric (SSIM) increased by 11.1%, 154% and 187% respectively compared to single-frame B-scans. Mean intralayer contrast (ILC) improvement for the retinal nerve fiber layer (RNFL), photoreceptor layer (PR) and retinal pigment epithelium (RPE) layers decreased from 0.362 \pm 0.133 to 0.142 \pm 0.102, 0.449 \pm 0.116 to 0.0904 \pm 0.0769, 0.381 \pm 0.100 to 0.0590 \pm 0.0451 respectively. The proposed algorithm reduces the necessity for long image acquisition times, minimizes expensive hardware requirements and reduces motion artifacts in OCT images.      
### 12.Automatic Data Augmentation for 3D Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.11695.pdf)
>  Data augmentation is an effective and universal technique for improving generalization performance of deep neural networks. It could enrich diversity of training samples that is essential in medical image segmentation tasks because 1) the scale of medical image dataset is typically smaller, which may increase the risk of overfitting; 2) the shape and modality of different objects such as organs or tumors are unique, thus requiring customized data augmentation policy. However, most data augmentation implementations are hand-crafted and suboptimal in medical image processing. To fully exploit the potential of data augmentation, we propose an efficient algorithm to automatically search for the optimal augmentation strategies. We formulate the coupled optimization w.r.t. network weights and augmentation parameters into a differentiable form by means of stochastic relaxation. This formulation allows us to apply alternative gradient-based methods to solve it, i.e. stochastic natural gradient method with adaptive step-size. To the best of our knowledge, it is the first time that differentiable automatic data augmentation is employed in medical image segmentation tasks. Our numerical experiments demonstrate that the proposed approach significantly outperforms existing build-in data augmentation of state-of-the-art models.      
### 13.PlenoptiCam v1.0: A light-field imaging framework  [ :arrow_down: ](https://arxiv.org/pdf/2010.11687.pdf)
>  Light-field cameras play a vital role for rich 3-D information retrieval in narrow range depth sensing applications. The key obstacle in composing light-fields from exposures taken by a plenoptic camera is to computationally calibrate, re-align and rearrange four-dimensional image data. Several attempts have been proposed to enhance the overall image quality by tailoring pipelines dedicated to particular plenoptic cameras and improving the color consistency across viewpoints at the expense of high computational loads. The framework presented herein advances prior outcomes thanks to its cost-effective color equalization from parallax-invariant probability distribution transfers and a novel micro image scale-space analysis for generic camera calibration independent of the lens specifications. Our framework compensates for hot-pixels, resampling artifacts, micro image grid rotations just as vignetting in an innovative way to enable superior quality in sub-aperture image extraction, computational refocusing and Scheimpflug rendering with sub-sampling capabilities. Benchmark comparisons using established image metrics suggest that our proposed pipeline outperforms state-of-the-art tool chains in the majority of cases. The software described in this paper is released under an open-source license offering cross-platform compatibility, few dependencies and a lean graphical user interface to make the reproduction of results and the experimentation with plenoptic camera technology convenient for peer researchers, developers, photographers, data scientists and everyone else working in this field.      
### 14.Lung Nodule Classification Using Biomarkers, Volumetric Radiomics and 3D CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2010.11682.pdf)
>  We present a hybrid algorithm to estimate lung nodule malignancy that combines imaging biomarkers from Radiologist's annotation with image classification of CT scans. Our algorithm employs a 3D Convolutional Neural Network (CNN) as well as a Random Forest in order to combine CT imagery with biomarker annotation and volumetric radiomic features. We analyze and compare the performance of the algorithm using only imagery, only biomarkers, combined imagery + biomarkers, combined imagery + volumetric radiomic features and finally the combination of imagery + biomarkers + volumetric features in order to classify the suspicion level of nodule malignancy. The National Cancer Institute (NCI) Lung Image Database Consortium (LIDC) IDRI dataset is used to train and evaluate the classification task. We show that the incorporation of semi-supervised learning by means of K-Nearest-Neighbors (KNN) can increase the available training sample size of the LIDC-IDRI thereby further improving the accuracy of malignancy estimation of most of the models tested although there is no significant improvement with the use of KNN semi-supervised learning if image classification with CNNs and volumetric features are combined with descriptive biomarkers. Unexpectedly, we also show that a model using image biomarkers alone is more accurate than one that combines biomarkers with volumetric radiomics, 3D CNNs, and semi-supervised learning. We discuss the possibility that this result may be influenced by cognitive bias in LIDC-IDRI because malignancy estimates were recorded by the same radiologist panel as biomarkers, as well as future work to incorporate pathology information over a subset of study participants.      
### 15.Python (deep learning and machine learning) for EEG signal processing on the example of recognizing the disease of alcoholism  [ :arrow_down: ](https://arxiv.org/pdf/2010.11667.pdf)
>  Alcoholism is one of the most common diseases in the world. This type of substance abuse leads to mental and physical dependence on ethanol-containing drinks. Alcoholism is accompanied by progressive degradation of the personality and damage to the internal organs. Today still not exists a quick diagnosis method to detect this disease. This article presents the method for the quick and anonymous alcoholism diagnosis by neural networks. For this method, don't need any private information about the subject. For the implementation, we considered various algorithms of machine learning and deep neural networks. In detail analyzed the correlation of the signals from electrodes by neural networks. The wavelet transforms and the fast Fourier transform was considered. The manuscript demonstrates that the deep neural network which operates only with a dataset of EEG correlation signals can anonymously classify the alcoholic and control groups with high accuracy. On the one hand, this method will allow subjects to be tested for alcoholism without any personal data, which will not cause inconvenience or shame in the subject, and on the other hand, the subject will not be able to deceive specialists who diagnose the subject for the presence of the disease.      
### 16.Symbolic Self-triggered Control of Continuous-time Non-deterministic Systems without Stability Assumptions for 2-LTL Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2010.11663.pdf)
>  We propose a symbolic self-triggered controller synthesis procedure for non-deterministic continuous-time nonlinear systems without stability assumptions. The goal is to compute a controller that satisfies two objectives. The first objective is represented as a specification in a fragment of LTL, which we call 2-LTL. The second one is an energy objective, in the sense that control inputs are issued only when necessary, which saves energy. To this end, we first quantise the state and input spaces, and then translate the controller synthesis problem to the computation of a winning strategy in a mean-payoff parity game. We illustrate the feasibility of our method on the example of a navigating nonholonomic robot.      
### 17.Online Time-Varying Topology Identification via Prediction-Correction Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2010.11634.pdf)
>  Signal processing and machine learning algorithms for data supported over graphs, require the knowledge of the graph topology. Unless this information is given by the physics of the problem (e.g., water supply networks, power grids), the topology has to be learned from data. Topology identification is a challenging task, as the problem is often ill-posed, and becomes even harder when the graph structure is time-varying. In this paper, we address the problem of dynamic topology identification by building on recent results from time-varying optimization, devising a general-purpose online algorithm operating in non-stationary environments. Because of its iteration-constrained nature, the proposed approach exhibits an intrinsic temporal-regularization of the graph topology without explicitly enforcing it. As a case-study, we specialize our method to the Gaussian graphical model (GGM) problem and corroborate its performance.      
### 18.Super-resolution of periodic signals from short sequences of samples  [ :arrow_down: ](https://arxiv.org/pdf/2010.11609.pdf)
>  Reconstruction of undersampled periodic signals of unknown period is an important signal processing operation. It is especially difficult operation when the sequences of samples are short and no information on the inter-sequence time distances are given. For such a case, there exist some algorithms that allow for approximation of the sampled signal. However, these algorithms require bandlimitedness of the signal or noiseless samples. In this paper we propose an algorithm, which relaxes these requirements. It does not require the signal to be bandlimited and it can cope with additive noise in the samples. The algorithm is illustrated and validated with real data.      
### 19.Flexibility management with virtual batteries of thermostatically controlled loads: real-time control system and potential in Spain  [ :arrow_down: ](https://arxiv.org/pdf/2010.11584.pdf)
>  Virtual batteries composed of aggregated thermostatically controlled loads are able to provide real-time frequency regulation to electrical grids. Load flexibility management can be helpful in solving the problem of balancing generation and demand, which is becoming more complex due to the variability of renewable energies. A real-time virtual battery control system is presented in this paper. As an example, a virtual battery of 1000 thermostatically controlled loads is operated. In order to quantify the potential of virtual batteries, a study focused on residential thermostatically controlled loads in Spain is reported.      
### 20.DBNET: DOA-driven beamforming network for end-to-end farfield sound source separation  [ :arrow_down: ](https://arxiv.org/pdf/2010.11566.pdf)
>  Many deep learning techniques are available to perform source separation and reduce background noise. However, designing an end-to-end multi-channel source separation method using deep learning and conventional acoustic signal processing techniques still remains challenging. In this paper we propose a direction-of-arrival-driven beamforming network (DBnet) consisting of direction-of-arrival (DOA) estimation and beamforming layers for end-to-end source separation. We propose to train DBnet using loss functions that are solely based on the distances between the separated speech signals and the target speech signals, without a need for the ground-truth DOAs of speakers. To improve the source separation performance, we also propose end-to-end extensions of DBnet which incorporate post masking networks. We evaluate the proposed DBnet and its extensions on a very challenging dataset, targeting realistic far-field sound source separation in reverberant and noisy environments. The experimental results show that the proposed extended DBnet using a convolutional-recurrent post masking network outperforms state-of-the-art source separation methods.      
### 21.Denoising Atmospheric Temperature Measurements Taken by the Mars Science Laboratory on the Martian Surface  [ :arrow_down: ](https://arxiv.org/pdf/2010.11557.pdf)
>  In the present article we analyze data from two temperature sensors of the Mars Science Laboratory, which has been active in Mars since August 2012. Temperature measurements received from the rover are noisy and must be processed and validated before being delivered to the scientific community. Currently, a simple Moving Average (MA) filter is used to perform signal denoising. The application of this basic method relies on the assumption that the noise is stationary and statistically independent from the underlying structure of the signal, an arguable assumption in this kind of harsh environment. In this paper, we analyze the application of two alternative methods to process the temperature sensor measurements: the Discrete Wavelet Transform (DWT) and the Hilbert-Huang Transform (HHT). We consider two different datasets, one belonging to the current Martian measurement campaigns, and the other to the Thermal Vacuum Tests. The processing of these datasets allows to separate the random noise from the interference created by other systems. The experiments show that the MA filter may provide useful results under given circumstances. However, the proposed methods allow a better fitting for all the realistic scenarios, while providing the possibility to identify and analyze other interesting signal features and artifacts that could be later studied and classified. The large amount of data to be processed makes computational efficiency an important requirement in this mission. Considering the computational cost and the filtering performance, we propose the method based on DWT as more suitable for this application.      
### 22.How Similar or Different Is Rakugo Speech Synthesizer to Professional Performers?  [ :arrow_down: ](https://arxiv.org/pdf/2010.11549.pdf)
>  We have been working on speech synthesis for rakugo (a traditional Japanese form of verbal entertainment similar to one-person stand-up comedy) toward speech synthesis that authentically entertains audiences. In this paper, we propose a novel evaluation methodology using synthesized rakugo speech and real rakugo speech uttered by professional performers of three different ranks. The naturalness of the synthesized speech was comparable to that of the human speech, but the synthesized speech entertained listeners less than the performers of any rank. However, we obtained some interesting insights into challenges to be solved in order to achieve a truly entertaining rakugo synthesizer. For example, naturalness was not the most important factor, even though it has generally been emphasized as the most important point to be evaluated in the conventional speech synthesis field. More important factors were the understandability of the content and distinguishability of the characters in the rakugo story, both of which the synthesized rakugo speech was relatively inferior at as compared with the professional performers. We also found that fundamental frequency fo modeling should be further improved to better entertain audiences. These results show important steps to reaching authentically entertaining speech synthesis.      
### 23.Graph Attention Networks for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2010.11543.pdf)
>  This work presents a novel back-end framework for speaker verification using graph attention networks. Segment-wise speaker embeddings extracted from multiple crops within an utterance are interpreted as node representations of a graph. The proposed framework inputs segment-wise speaker embeddings from an enrollment and a test utterance and directly outputs a similarity score. We first construct a graph using segment-wise speaker embeddings and then input these to graph attention networks. After a few graph attention layers with residual connections, each node is projected into a one-dimensional space using affine transform, followed by a readout operation resulting in a scalar similarity score. To enable successful adaptation for speaker verification, we propose techniques such as separating trainable weights for attention map calculations between segment-wise speaker embeddings from different utterances. The effectiveness of the proposed framework is validated using three different speaker embedding extractors trained with different architectures and objective functions. Experimental results demonstrate consistent improvement over various baseline back-end classifiers, with an average equal error rate improvement of 20% over the cosine similarity back-end without test time augmentation.      
### 24.Fault diagnosis for linear heterodirectional hyperbolic ODE-PDE systems using backstepping-based trajectory planning  [ :arrow_down: ](https://arxiv.org/pdf/2010.11526.pdf)
>  This paper is concerned with the fault diagnosis problem for general linear heterodirectional hyperbolic ODE-PDE systems. A systematic solution is presented for additive time-varying actuator, process and sensor faults in the presence of disturbances. The faults and disturbances are represented by the solutions of finite-dimensional signal models, which allow to take a large class of signals into account. For disturbances, that are only bounded, a threshold for secured fault diagnosis is derived. By applying integral transformations to the system an algebraic fault detection equation to detect faults in finite time is obtained. The corresponding integral kernels result from the realization of a finite-time transition between a non-equilibrium initial state and a vanishing final state of a hyperbolic ODE-PDE system. For this new challenging problem, a systematic trajectory planning approach is presented. In particular, this problem is facilitated by mapping the kernel equations into backstepping coordinates and tracing the solution of the transition problem back to a simple trajectory planning. The fault diagnosis for a $4\times 4$ heterodirectional hyperbolic system coupled with a second order ODE demonstrates the results of the paper.      
### 25.Malaria detection from RBC images using shallow Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.11521.pdf)
>  The advent of Deep Learning models like VGG-16 and Resnet-50 has considerably revolutionized the field of image classification, and by using these Convolutional Neural Networks (CNN) architectures, one can get a high classification accuracy on a wide variety of image datasets. However, these Deep Learning models have a very high computational complexity and so incur a high computational cost of running these algorithms as well as make it hard to interpret the results. In this paper, we present a shallow CNN architecture which gives the same classification accuracy as the VGG-16 and Resnet-50 models for thin blood smear RBC slide images for detection of malaria, while decreasing the computational run time by an order of magnitude. This can offer a significant advantage for commercial deployment of these algorithms, especially in poorer countries in Africa and some parts of the Indian subcontinent, where the menace of malaria is quite severe.      
### 26.Overview of Networked Supervisory Control with Imperfect Communication Channels  [ :arrow_down: ](https://arxiv.org/pdf/2010.11491.pdf)
>  This paper presents an overview of the networked supervisory control framework for discrete event systems with imperfect communication networks, which can be divided into the centralized supervisory control setup and the decentralized supervisory control setup. We review the state-of-art networked control frameworks with observation channel delays and control channel delays, for untimed and timed models. Data losses in communication channels are also considered. The review of the state-of-art networked control frameworks will be focused on the following parts: 1) the construction of the networked control closed-loop system 2) the condition to ensure the existence of a networked supervisor 3) the synthesis procedure for networked-delay resilient supervisor 4) the possibility of improving the synthesis efficiency.      
### 27.The NTU-AISG Text-to-speech System for Blizzard Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2010.11489.pdf)
>  We report our NTU-AISG Text-to-speech (TTS) entry systems for the Blizzard Challenge 2020 in this paper. There are two TTS tasks in this year's challenge, one is a Mandarin TTS task, the other is a Shanghai dialect TTS task. We have participated both. One of the main challenges is to build TTS systems with low-resource constraints, particularly for the case of Shanghai dialect, of which about three hours data are available to participants. To overcome the constraint, we adopt an average-speaker modeling method. That is, we first employ external Mandarin data to train both End-to-end acoustic model and WaveNet vocoder, then we use Shanghai dialect to tune the acoustic model and WaveNet vocoder respectively. Apart from this, we have no Shanghai dialect lexicon despite syllable transcripts are provided for the training data. Since we are not sure if similar syllable transcripts are provided for the evaluation data during the training stage, we use Mandarin lexicon for Shanghai dialect instead. With the letter, as decomposed from the corresponding Mandarin syllable, as input, though the naturalness and original speaker similarity of the synthesized speech are good, subjective evaluation results indicate the intelligibility of the synthesized speech is deeply undermined for the Shanghai dialect TTS system.      
### 28.A multilingual approach to joint Speech and Accent Recognition with DNN-HMM framework  [ :arrow_down: ](https://arxiv.org/pdf/2010.11483.pdf)
>  Human can perform multi-task recognition from speech. For instance, human can recognize speech, as well as a peculiar accent of the speech simultaneously. However, present state-of-the-art speech recognition system can rarely do that. In this paper, we propose a multilingual approach to recognizing English speech, as well as the related accent that the speakers convey using DNN-HMM framework. Specifically, we assume different accents of English as different languages. We then merge them together and train a multilingual speech recognition system. During decoding, we conduct two sets of experiments. One is a monolingual Automatic Speech Recognition (ASR) system, with the accent information only embedded at the phone level, realizing word-based accent recognition, and the other is a multilingual ASR system, with the accent information embedded at both word and phone level, realizing an approximated utterance-based accent recognition.      
### 29.Similarity Analysis of Self-Supervised Speech Representations  [ :arrow_down: ](https://arxiv.org/pdf/2010.11481.pdf)
>  Self-supervised speech representation learning has recently been a prosperous research topic. Many algorithms have been proposed for learning useful representations from large-scale unlabeled data, and their applications to a wide range of speech tasks have also been investigated. However, there has been little research focusing on understanding the properties of existing approaches. In this work, we aim to provide a comparative study of some of the most representative self-supervised algorithms. Specifically, we quantify the similarities between different self-supervised representations using existing similarity measures. We also design probing tasks to study the correlation between the models' pre-training loss and the amount of specific speech information contained in their learned representations. In addition to showing how various self-supervised models behave differently given the same input, our study also finds that the training objective has a higher impact on representation similarity than architectural choices such as building blocks (RNN/Transformer/CNN) and directionality (uni/bidirectional). Our results also suggest that there exists a strong correlation between pre-training loss and downstream performance for some self-supervised algorithms.      
### 30.Microsoft Speaker Diarization System for the VoxCeleb Speaker Recognition Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2010.11458.pdf)
>  This paper describes the Microsoft speaker diarization system for monaural multi-talker recordings in the wild, evaluated at the diarization track of the VoxCeleb Speaker Recognition Challenge(VoxSRC) 2020. We will first explain our system design to address issues in handling real multi-talker recordings. We then present the details of the components, which include Res2Net-based speaker embedding extractor, conformer-based continuous speech separation with leakage filtering, and a modified DOVER (short for Diarization Output Voting Error Reduction) method for system fusion. We evaluate the systems with the data set provided by VoxSRCchallenge 2020, which contains real-life multi-talker audio collected from YouTube. Our best system achieves 3.71% and 6.23% of the diarization error rate (DER) on development set and evaluation set, respectively, being ranked the 1st at the diarization track of the challenge.      
### 31.Momentum Contrast Speaker Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.11457.pdf)
>  Unsupervised representation learning has shown remarkable achievement by reducing the performance gap with supervised feature learning, especially in the image domain. In this study, to extend the technique of unsupervised learning to the speech domain, we propose the Momentum Contrast for VoxCeleb (MoCoVox) as a form of learning mechanism. We pre-trained the MoCoVox on the VoxCeleb1 by implementing instance discrimination. Applying MoCoVox for speaker verification revealed that it outperforms the state-of-the-art metric learning-based approach by a large margin. We also empirically demonstrate the features of contrastive learning in the speech domain by analyzing the distribution of learned representations. Furthermore, we explored which pretext task is adequate for speaker verification. We expect that learning speaker representation without human supervision helps to address the open-set speaker recognition.      
### 32.Statistical Properties of a Modified Welch Method That Uses Sample Percentiles  [ :arrow_down: ](https://arxiv.org/pdf/2010.11444.pdf)
>  We present and analyze an alternative, more robust approach to the Welch's overlapped segment averaging (WOSA) spectral estimator. Our method computes sample percentiles instead of averaging over multiple periodograms to estimate power spectral densities (PSDs). Bias and variance of the proposed estimator are derived for varying sample sizes and arbitrary percentiles. We have found excellent agreement between our expressions and data sampled from a white Gaussian noise process.      
### 33.Unsupervised Representation Learning for Speaker Recognition via Contrastive Equilibrium Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.11433.pdf)
>  In this paper, we propose a simple but powerful unsupervised learning method for speaker recognition, namely Contrastive Equilibrium Learning (CEL), which increases the uncertainty on nuisance factors latent in the embeddings by employing the uniformity loss. Also, to preserve speaker discriminability, a contrastive similarity loss function is used together. Experimental results showed that the proposed CEL significantly outperforms the state-of-the-art unsupervised speaker verification systems and the best performing model achieved 8.01% and 4.01% EER on VoxCeleb1 and VOiCES evaluation sets, respectively. On top of that, the performance of the supervised speaker embedding networks trained with initial parameters pre-trained via CEL showed better performance than those trained with randomly initialized parameters.      
### 34.Confidence Estimation for Attention-based Sequence-to-sequence Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.11428.pdf)
>  For various speech-related tasks, confidence scores from a speech recogniser are a useful measure to assess the quality of transcriptions. In traditional hidden Markov model-based automatic speech recognition (ASR) systems, confidence scores can be reliably obtained from word posteriors in decoding lattices. However, for an ASR system with an auto-regressive decoder, such as an attention-based sequence-to-sequence model, computing word posteriors is difficult. An obvious alternative is to use the decoder softmax probability as the model confidence. In this paper, we first examine how some commonly used regularisation methods influence the softmax-based confidence scores and study the overconfident behaviour of end-to-end models. Then we propose a lightweight and effective approach named confidence estimation module (CEM) on top of an existing end-to-end ASR model. Experiments on LibriSpeech show that CEM can mitigate the overconfidence problem and can produce more reliable confidence scores with and without shallow fusion of a language model. Further analysis shows that CEM generalises well to speech from a moderately mismatched domain and can potentially improve downstream tasks such as semi-supervised learning.      
### 35.DeepCSR: A 3D Deep Learning Approach for Cortical Surface Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2010.11423.pdf)
>  The study of neurodegenerative diseases relies on the reconstruction and analysis of the brain cortex from magnetic resonance imaging (MRI). Traditional frameworks for this task like FreeSurfer demand lengthy runtimes, while its accelerated variant FastSurfer still relies on a voxel-wise segmentation which is limited by its resolution to capture narrow continuous objects as cortical surfaces. Having these limitations in mind, we propose DeepCSR, a 3D deep learning framework for cortical surface reconstruction from MRI. Towards this end, we train a neural network model with hypercolumn features to predict implicit surface representations for points in a brain template space. After training, the cortical surface at a desired level of detail is obtained by evaluating surface representations at specific coordinates, and subsequently applying a topology correction algorithm and an isosurface extraction method. Thanks to the continuous nature of this approach and the efficacy of its hypercolumn features scheme, DeepCSR efficiently reconstructs cortical surfaces at high resolution capturing fine details in the cortical folding. Moreover, DeepCSR is as accurate, more precise, and faster than the widely used FreeSurfer toolbox and its deep learning powered variant FastSurfer on reconstructing cortical surfaces from MRI which should facilitate large-scale medical studies and new healthcare applications.      
### 36.Robust Text-Dependent Speaker Verification via Character-Level Information Preservation for the SdSV Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2010.11408.pdf)
>  This paper describes our submission to Task 1 of the Short-duration Speaker Verification (SdSV) challenge 2020. Task 1 is a text-dependent speaker verification task, where both the speaker and phrase are required to be verified. The submitted systems were composed of TDNN-based and ResNet-based front-end architectures, in which the frame-level features were aggregated with various pooling methods (e.g., statistical, self-attentive, ghostVLAD pooling). Although the conventional pooling methods provide embeddings with a sufficient amount of speaker-dependent information, our experiments show that these embeddings often lack phrase-dependent information. To mitigate this problem, we propose a new pooling and score compensation methods that leverage a CTC-based automatic speech recognition (ASR) model for taking the lexical content into account. Both methods showed improvement over the conventional techniques, and the best performance was achieved by fusing all the experimented systems, which showed 0.0785% MinDCF and 2.23% EER on the challenge's evaluation subset.      
### 37.Unfolding Neural Networks for Compressive Multichannel Blind Deconvolution  [ :arrow_down: ](https://arxiv.org/pdf/2010.11391.pdf)
>  We propose a learned-structured unfolding neural network for the problem of compressive sparse multichannel blind-deconvolution. In this problem, each channel's measurements are given as convolution of a common source signal and sparse filter. Unlike prior works where the compression is achieved either through random projections or by applying a fixed structured compression matrix, this paper proposes to learn the compression matrix from data. Given the full measurements, the proposed network is trained in an unsupervised fashion to learn the source and estimate sparse filters. Then, given the estimated source, we learn a structured compression operator while optimizing for signal reconstruction and sparse filter recovery. The efficient structure of the compression allows its practical hardware implementation. The proposed neural network is an autoencoder constructed based on an unfolding approach: upon training, the encoder maps the compressed measurements into an estimate of sparse filters using the compression operator and the source, and the linear convolutional decoder reconstructs the full measurements. We demonstrate that our method is superior to classical structured compressive sparse multichannel blind-deconvolution methods in terms of accuracy and speed of sparse filter recovery.      
### 38.Deep Learning for Distinguishing Normal versus Abnormal Chest Radiographs and Generalization to Unseen Diseases  [ :arrow_down: ](https://arxiv.org/pdf/2010.11375.pdf)
>  Chest radiography (CXR) is the most widely-used thoracic clinical imaging modality and is crucial for guiding the management of cardiothoracic conditions. The detection of specific CXR findings has been the main focus of several artificial intelligence (AI) systems. However, the wide range of possible CXR abnormalities makes it impractical to build specific systems to detect every possible condition. In this work, we developed and evaluated an AI system to classify CXRs as normal or abnormal. For development, we used a de-identified dataset of 248,445 patients from a multi-city hospital network in India. To assess generalizability, we evaluated our system using 6 international datasets from India, China, and the United States. Of these datasets, 4 focused on diseases that the AI was not trained to detect: 2 datasets with tuberculosis and 2 datasets with coronavirus disease 2019. Our results suggest that the AI system generalizes to new patient populations and abnormalities. In a simulated workflow where the AI system prioritized abnormal cases, the turnaround time for abnormal cases reduced by 7-28%. These results represent an important step towards evaluating whether AI can be safely used to flag cases in a general setting where previously unseen abnormalities exist.      
### 39.Social Bubbles and Superspreaders: Source Identification for Contagion Processes on Hypertrees  [ :arrow_down: ](https://arxiv.org/pdf/2010.11350.pdf)
>  Previous work has shown that for contagion processes on extended star networks (trees with exactly one node of degree &gt; 2), there is a simple, closed-form expression for a highly accurate approximation to the maximum likelihood infection source. Here, we generalize that result to a class of hypertrees which, although somewhat structurally analogous, provides a much richer representation space. In particular, this approach can be used to estimate patient zero sources, even when the infection has been propagated via large group gatherings rather than person-to-person spread, and when it is spreading through interrelated social bubbles with varying degrees of overlap. In contact tracing contexts, this estimator may be used to identify the source of a local outbreak, which can then be used for forward tracing or for further backward tracing (by similar or other means) to an upstream source.      
### 40.Correlation-aware Cooperative Multigroup Broadcast 360° Video Delivery Network: A Hierarchical Deep Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.11347.pdf)
>  With the stringent requirement of receiving video from unmanned aerial vehicle (UAV) from anywhere in the stadium of sports events and the significant-high per-cell throughput for video transmission to virtual reality (VR) users, a promising solution is a cell-free multi-group broadcast (CF-MB) network with cooperative reception and broadcast access points (AP). To explore the benefit of broadcasting user-correlated decode-dependent video resources to spatially correlated VR users, the network should dynamically schedule the video and cluster APs into virtual cells for a different group of VR users with overlapped video requests. By decomposition the problem into scheduling and association sub-problems, we first introduce the conventional non-learning-based scheduling and association algorithms, and a centralized deep reinforcement learning (DRL) association approach based on the rainbow agent with a convolutional neural network (CNN) to generate decisions from observation. To reduce its complexity, we then decompose the association problem into multiple sub-problems, resulting in a networked-distributed Partially Observable Markov decision process (ND-POMDP). To solve it, we propose a multi-agent deep DRL algorithm. To jointly solve the coupled association and scheduling problems, we further develop a hierarchical federated DRL algorithm with scheduler as meta-controller, and association as the controller. Our simulation results shown that our CF-MB network can effectively handle real-time video transmission from UAVs to VR users. Our proposed learning architectures is effective and scalable for a high-dimensional cooperative association problem with increasing APs and VR users. Also, our proposed algorithms outperform non-learning based methods with significant performance improvement.      
### 41.Photovoltaic (PV) Virtual Inertia and Fast Frequency Regulation in High PV Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2010.11340.pdf)
>  This paper studies the frequency response using PV. Multiple control strategies are considered and simulated in the high PV ERCOT model, including inertia control, synthetic governor control, and AGC control. The impact of different parameters in PV inertia control and their correlation and impact on frequency response are analyzed. The simulation results show that PV farm has potential to provide multiple types of grid service to support system frequency. This paper also proposed a distributed fast frequency control approach that can better leverage the PV headroom reserve to improve the system frequency nadir after contingencies.      
### 42.Meta-Learning Guarantees for Online Receding Horizon Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.11327.pdf)
>  In this paper we provide provable regret guarantees for an online meta-learning receding horizon control algorithm in an iterative control setting, where in each iteration the system to be controlled is a linear deterministic system that is different and unknown, the cost for the controller in an iteration is a general additive cost function and the control input is required to be constrained, which if violated incurs an additional cost. We prove (i) that the algorithm achieves a regret for the controller cost and constraint violation that are $O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy that satisfies the control input control constraints and (ii) that the average of the regret for the controller cost and constraint violation with respect to the same policy vary as $O((1+1/\sqrt{N})T^{3/4})$ with the number of iterations $N$, showing that the worst regret for the learning within an iteration continuously improves with experience of more iterations.      
### 43.Comprehensive Performance Analysis of Objective Quality Metrics for Digital Holography  [ :arrow_down: ](https://arxiv.org/pdf/2010.11306.pdf)
>  Objective quality assessment of digital holograms has proven to be a challenging task. While prediction of perceptual quality of the recorded 3D content from the holographic wavefield is an open problem; perceptual quality assessment from content after rendering, requires a time-consuming rendering step and a multitude of possible viewports. In this research, we use 96 Fourier holograms of the recently released HoloDB database to evaluate the performance of well-known and state-of-the-art image quality metrics on digital holograms. We compare the reference holograms with their distorted versions: (i) before rendering on the real and imaginary parts of the quantized complex-wavefield, (ii) after converting Fourier to Fresnel holograms, (iii) after rendering, on the quantized amplitude of the reconstructed data, and (iv) after subsequently removing speckle noise using a Wiener filter. For every experimental track, the quality metric predictions are compared to the Mean Opinion Scores (MOS) gathered on a 2D screen, light field display and a holographic display. Additionally, a statistical analysis of the results and a discussion on the performance of the metrics are presented. The tests demonstrate that while for each test track a few quality metrics present a highly correlated performance compared to the multiple sets of available MOS, none of them demonstrates a consistently high-performance across all four test-tracks.      
### 44.Frequency Response Study on the ERCOT under High Photovoltaic (PV) Penetration Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2010.11302.pdf)
>  Solar photovoltaic (PV) generation is growing rapidly around the world. However, PV generation, based on inverter, is fundamentally different from conventional synchronous generators. It is of vital importance to understand the impacts of increased penetration of PV generation on power system dynamic performance. This paper investigates frequency response of the Electric Reliability Council of Texas (ERCOT) with high PV penetration in the future year. In this work, a realistic baseline dynamic model is validated using synchrophasor measurements. Then, dynamic simulation is performed to evaluate the impacts of high PV generation on frequency response.      
### 45.Improving Audio Anomalies Recognition Using Temporal Convolutional Attention Network  [ :arrow_down: ](https://arxiv.org/pdf/2010.11286.pdf)
>  Anomalous audio in speech recordings is often caused by speaker voice distortion, external noise, or even electric interferences. These obstacles have become a serious problem in some fields, such as recording high-quality music and speech processing. In this paper, a novel approach using a temporal convolutional attention network (TCAN) is proposed to process this problem. The use of temporal conventional network (TCN) can capture long range patterns using a hierarchy of temporal convolutional filters. To enhance the ability to tackle audio anomalies in different acoustic conditions, an attention mechanism is used in TCN, where a self-attention block is added after each temporal convolutional layer. This aims to highlight the target related features and mitigate the interferences from irrelevant information. To evaluate the performance of the proposed model, audio recordings are collected from the TIMIT dataset, and are then changed by adding five different types of audio distortions: gaussian noise, magnitude drift, random dropout, reduction of temporal resolution, and time warping. Distortions are mixed at different signal-to-noise ratios (SNRs) (5dB, 10dB, 15dB, 20dB, 25dB, 30dB). The experimental results show that the use of proposed model can yield good classification performances and outperforms some strong baseline methods, such as the LSTM and TCN based models, by about 3$\sim$ 10\% relatively.      
### 46.Learning Speaker Embedding from Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2010.11221.pdf)
>  Zero-shot multi-speaker Text-to-Speech (TTS) generates target speaker voices given an input text and the corresponding speaker embedding. In this work, we investigate the effectiveness of the TTS reconstruction objective to improve representation learning for speaker verification. We jointly trained end-to-end Tacotron 2 TTS and speaker embedding networks in a self-supervised fashion. We hypothesize that the embeddings will contain minimal phonetic information since the TTS decoder will obtain that information from the textual input. TTS reconstruction can also be combined with speaker classification to enhance these embeddings further. Once trained, the speaker encoder computes representations for the speaker verification task, while the rest of the TTS blocks are discarded. We investigated training TTS from either manual or ASR-generated transcripts. The latter allows us to train embeddings on datasets without manual transcripts. We compared ASR transcripts and Kaldi phone alignments as TTS inputs, showing that the latter performed better due to their finer resolution. Unsupervised TTS embeddings improved EER by 2.06\% absolute with regard to i-vectors for the LibriTTS dataset. TTS with speaker classification loss improved EER by 0.28\% and 0.73\% absolutely from a model using only speaker classification loss in LibriTTS and Voxceleb1 respectively.      
### 47.DC Microgrid State Estimation and Sensor Placement Based on Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2010.11218.pdf)
>  This paper proposes a DC microgrid state estimation and sensor placement method based on compressive sensing. Formulations of various types of measurements and components are developed under the proposed framework. A measurement placing strategy to minimize the coherence of the measurement matrix and thus increase estimation accuracy is presented. Simulation results show that the proposed state estimation and sensor placing approach can effectively reduce the number of sensors to achieve a certain level of estimation accuracy.      
### 48.Source localization using particle filtering on FPGA for robotic navigation with imprecise binary measurement  [ :arrow_down: ](https://arxiv.org/pdf/2010.11911.pdf)
>  Particle filtering is a recursive Bayesian estimation technique that has gained popularity recently for tracking and localization applications. It uses Monte Carlo simulation and has proven to be a very reliable technique to model non-Gaussian and non-linear elements of physical systems. Particle filters outperform various other traditional filters like Kalman filters in non-Gaussian and non-linear settings due to their non-analytical and non-parametric nature. However, a significant drawback of particle filters is their computational complexity, which inhibits their use in real-time applications with conventional CPU or DSP based implementation schemes. This paper proposes a modification to the existing particle filter algorithm and presents a highspeed and dedicated hardware architecture. The architecture incorporates pipelining and parallelization in the design to reduce execution time considerably. The design is validated for a source localization problem wherein we estimate the position of a source in real-time using the particle filter algorithm implemented on hardware. The validation setup relies on an Unmanned Ground Vehicle (UGV) with a photodiode housing on top to sense and localize a light source. We have prototyped the design using Artix-7 field-programmable gate array (FPGA), and resource utilization for the proposed system is presented. Further, we show the execution time and estimation accuracy of the high-speed architecture and observe a significant reduction in computational time. Our implementation of particle filters on FPGA is scalable and modular, with a low execution time of about 5.62 us for processing 1024 particles and can be deployed for real-time applications.      
### 49.Neural Audio Fingerprint for High-specific Audio Retrieval based on Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.11910.pdf)
>  Most of existing audio fingerprinting systems have limitations to be used for high-specific audio retrieval at scale. In this work, we generate a low-dimensional representation from a short unit segment of audio, and couple this fingerprint with a fast maximum inner-product search. To this end, we present a contrastive learning framework that derives from the segment-level search objective. Each update in training uses a batch consisting of a set of pseudo labels, randomly selected original samples, and their augmented replicas. These replicas can simulate the degrading effects on original audio signals by applying small time offsets and various types of distortions, such as background noise and room/microphone impulse responses. In the segment-level search task, where the conventional audio fingerprinting systems used to fail, our system using 10x smaller storage has shown promising results. Codes and dataset will be available.      
### 50.Transcription Is All You Need: Learning to Separate Musical Mixtures with Score as Supervision  [ :arrow_down: ](https://arxiv.org/pdf/2010.11904.pdf)
>  Most music source separation systems require large collections of isolated sources for training, which can be difficult to obtain. In this work, we use musical scores, which are comparatively easy to obtain, as a weak label for training a source separation system. In contrast with previous score-informed separation approaches, our system does not require isolated sources, and score is used only as a training target, not required for inference. Our model consists of a separator that outputs a time-frequency mask for each instrument, and a transcriptor that acts as a critic, providing both temporal and frequency supervision to guide the learning of the separator. A harmonic mask constraint is introduced as another way of leveraging score information during training, and we propose two novel adversarial losses for additional fine-tuning of both the transcriptor and the separator. Results demonstrate that using score information outperforms temporal weak-labels, and adversarial structures lead to further improvements in both separation and transcription performance.      
### 51.Towards Listening to 10 People Simultaneously: An Efficient Permutation Invariant Training of Audio Source Separation Using Sinkhorn's Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2010.11871.pdf)
>  In neural network-based monaural speech separation techniques, it has been recently common to evaluate the loss using the permutation invariant training (PIT) loss. However, the ordinary PIT requires to try all $N!$ permutations between $N$ ground truths and $N$ estimates. Since the factorial complexity explodes very rapidly as $N$ increases, a PIT-based training works only when the number of source signals is small, such as $N = 2$ or $3$. To overcome this limitation, this paper proposes a SinkPIT, a novel variant of the PIT losses, which is much more efficient than the ordinary PIT loss when $N$ is large. The SinkPIT is based on Sinkhorn's matrix balancing algorithm, which efficiently finds a doubly stochastic matrix which approximates the best permutation in a differentiable manner. The author conducted an experiment to train a neural network model to decompose a single-channel mixture into 10 sources using the SinkPIT, and obtained promising results.      
### 52.Urban Sound Classification : striving towards a fair comparison  [ :arrow_down: ](https://arxiv.org/pdf/2010.11805.pdf)
>  Urban sound classification has been achieving remarkable progress and is still an active research area in audio pattern recognition. In particular, it allows to monitor the noise pollution, which becomes a growing concern for large cities. The contribution of this paper is two-fold. First, we present our DCASE 2020 task 5 winning solution which aims at helping the monitoring of urban noise pollution. It achieves a macro-AUPRC of 0.82 / 0.62 for the coarse / fine classification on validation set. Moreover, it reaches accuracies of 89.7% and 85.41% respectively on ESC-50 and US8k datasets. Second, it is not easy to find a fair comparison and to reproduce the performance of existing models. Sometimes authors copy-pasting the results of the original papers which is not helping reproducibility. As a result, we provide a fair comparison by using the same input representation, metrics and optimizer to assess performances. We preserve data augmentation used by the original papers. We hope this framework could help evaluate new architectures in this field. For better reproducibility, the code is available on our GitHub repository.      
### 53.Compositional embedding models for speaker identification and diarization with simultaneous speech from 2+ speakers  [ :arrow_down: ](https://arxiv.org/pdf/2010.11803.pdf)
>  We propose a new method for speaker diarization that can handle overlapping speech with 2+ people. Our method is based on compositional embeddings [1]: Like standard speaker embedding methods such as x-vector [2], compositional embedding models contain a function f that separates speech from different speakers. In addition, they include a composition function g to compute set-union operations in the embedding space so as to infer the set of speakers within the input audio. In an experiment on multi-person speaker identification using synthesized LibriSpeech data, the proposed method outperforms traditional embedding methods that are only trained to separate single speakers (not speaker sets). In a speaker diarization experiment on the AMI Headset Mix corpus, we achieve state-of-the-art accuracy (DER=22.93%), slightly higher than the previous best result (23.82% from [3]).      
### 54.Rethinking Evaluation in ASR: Are Our Models Robust Enough?  [ :arrow_down: ](https://arxiv.org/pdf/2010.11745.pdf)
>  Is pushing numbers on a single benchmark valuable in automatic speech recognition? Research results in acoustic modeling are typically evaluated based on performance on a single dataset. While the research community has coalesced around various benchmarks, we set out to understand generalization performance in acoustic modeling across datasets -- in particular, if models trained on a single dataset transfer to other (possibly out-of-domain) datasets. Further, we demonstrate that when a large enough set of benchmarks is used, average word error rate (WER) performance over them provides a good proxy for performance on real-world data. Finally, we show that training a single acoustic model on the most widely-used datasets -- combined -- reaches competitive performance on both research and real-world benchmarks.      
### 55.A Qualitative Analysis of Haptic Feedback in Music Focused Exercises  [ :arrow_down: ](https://arxiv.org/pdf/2010.11744.pdf)
>  We present the findings of a pilot-study that analysed the role of haptic feedback in a musical context. To examine the role of haptics in Digital Musical Instrument (DMI) design an experiment was formulated to measure the users' perception of device usability across four separate feedback stages: fully haptic (force and tactile combined), constant force only, vibrotactile only, and no feedback. The study was piloted over extended periods with the intention of exploring the application and integration of DMIs in real-world musical contexts. Applying a music orientated analysis of this type enabled the investigative process to not only take place over a comprehensive period, but allowed for the exploration of DMI integration in everyday compositional practices. As with any investigation that involves creativity, it was important that the participants did not feel rushed or restricted. That is, they were given sufficient time to explore and assess the different feedback types without constraint. This provided an accurate and representational set of qualitative data for validating the participants' experience with the different feedback types they were presented with.      
### 56.Identification of deep breath while moving forward based on multiple body regions and graph signal analysis  [ :arrow_down: ](https://arxiv.org/pdf/2010.11734.pdf)
>  This paper presents an unobtrusive solution that can automatically identify deep breath when a person is walking past the global depth camera. Existing non-contact breath assessments achieve satisfactory results under restricted conditions when human body stays relatively still. When someone moves forward, the breath signals detected by depth camera are hidden within signals of trunk displacement and deformation, and the signal length is short due to the short stay time, posing great challenges for us to establish models. To overcome these challenges, multiple region of interests (ROIs) based signal extraction and selection method is proposed to automatically obtain the signal informative to breath from depth video. Subsequently, graph signal analysis (GSA) is adopted as a spatial-temporal filter to wipe the components unrelated to breath. Finally, a classifier for identifying deep breath is established based on the selected breath-informative signal. In validation experiments, the proposed approach outperforms the comparative methods with the accuracy, precision, recall and F1 of 75.5%, 76.2%, 75.0% and 75.2%, respectively. This system can be extended to public places to provide timely and ubiquitous help for those who may have or are going through physical or mental trouble.      
### 57.Robust Audio-Based Vehicle Counting in Low-to-Moderate Traffic Flow  [ :arrow_down: ](https://arxiv.org/pdf/2010.11716.pdf)
>  The paper presents a method for audio-based vehicle counting (VC) in low-to-moderate traffic using one-channel sound. We formulate VC as a regression problem, i.e., we predict the distance between a vehicle and the microphone. Minima of the proposed distance function correspond to vehicles passing by the microphone. VC is carried out via local minima detection in the predicted distance. We propose to set the minima detection threshold at a point where the probabilities of false positives and false negatives coincide so they statistically cancel each other in total vehicle number. The method is trained and tested on a traffic-monitoring dataset comprising $422$ short, $20$-second one-channel sound files with a total of $ 1421 $ vehicles passing by the microphone. Relative VC error in a traffic location not used in the training is below $ 2 \%$ within a wide range of detection threshold values. Experimental results show that the regression accuracy in noisy environments is improved by introducing a novel high-frequency power feature.      
### 58.Joint Power Allocation and User Association Optimization for IRS-Assisted mmWave Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.11713.pdf)
>  Intelligent reflecting surface (IRS) is a potential technology to build programmable wireless environment in future communication systems. In this paper, we consider an IRS-assisted multi-base station (multi-BS) multi-user millimeter wave (mmWave) downlink communication system, exploiting IRS to extend mmWave signal coverage to blind spots. Considering the impact of IRS on user association in multi-BS mmWave systems, we formulate a sum rate maximization problem by jointly optimizing passive beamforming at IRS, power allocation and user association. This leads to an intractable nonconvex problem, for which to tackle we propose a computationally affordable iterative algorithm, capitalizing on alternating optimization, sequential fractional programming (SFP) and forward-reverse auction (FRA). In particular, passive beamforming at IRS is optimized by utilizing the SFP method, power allocation is solved through means of standard convex optimization method, and user association is handled by the network optimization based FRA algorithm. Simulation results demonstrate that the proposed algorithm can achieve significant performance gains, e.g., it can provide up to 175% higher sum rate compared with the benchmark and 140% higher energy efficiency compared with amplifyand-forward relay.      
### 59.Trajectory Tracking for Robotic Arms with Input Saturation and Only Position Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2010.11712.pdf)
>  In this work, we propose a passivity-based control approach that addresses the trajectory tracking problem for a class of mechanical systems that comprises a broad range of robotic arms. The resulting controllers can be naturally saturated and do not require velocity measurements. Moreover, the proposed methodology does not require the implementation of observers, and the structure of the closed-loop system permits the identification of a Lyapunov function, which eases the convergence analysis. To corroborate the effectiveness of the methodology, we perform experiments with the Philips Experimental Robot Arm.      
### 60.Using Conditional Generative Adversarial Networks to Reduce the Effects of Latency in Robotic Telesurgery  [ :arrow_down: ](https://arxiv.org/pdf/2010.11704.pdf)
>  The introduction of surgical robots brought about advancements in surgical procedures. The applications of remote telesurgery range from building medical clinics in underprivileged areas, to placing robots abroad in military hot-spots where accessibility and diversity of medical experience may be limited. Poor wireless connectivity may result in a prolonged delay, referred to as latency, between a surgeon's input and action a robot takes. In surgery, any micro-delay can injure a patient severely and in some cases, result in fatality. One was to increase safety is to mitigate the effects of latency using deep learning aided computer vision. While the current surgical robots use calibrated sensors to measure the position of the arms and tools, in this work we present a purely optical approach that provides a measurement of the tool position in relation to the patient's tissues. This research aimed to produce a neural network that allowed a robot to detect its own mechanical manipulator arms. A conditional generative adversarial networks (cGAN) was trained on 1107 frames of mock gastrointestinal robotic surgery data from the 2015 EndoVis Instrument Challenge and corresponding hand-drawn labels for each frame. When run on new testing data, the network generated near-perfect labels of the input images which were visually consistent with the hand-drawn labels and was able to do this in 299 milliseconds. These accurately generated labels can then be used as simplified identifiers for the robot to track its own controlled tools. These results show potential for conditional GANs as a reaction mechanism such that the robot can detect when its arms move outside the operating area within a patient. This system allows for more accurate monitoring of the position of surgical instruments in relation to the patient's tissue, increasing safety measures that are integral to successful telesurgery systems.      
### 61.Rapid parameter determination of discrete damped sinusoidal oscillations  [ :arrow_down: ](https://arxiv.org/pdf/2010.11690.pdf)
>  We present different computational approaches for the rapid extraction of the signal parameters of discretely sampled damped sinusoidal signals. We compare time- and frequency-domain-based computational approaches in terms of their accuracy and precision and computational time required in estimating the frequencies of such signals, and observe a general trade-off between precision and speed. Our motivation is precise and rapid analysis of damped sinusoidal signals as these become relevant in view of the recent experimental developments in cavity-enhanced polarimetry and ellipsometry, where the relevant time scales and frequencies are typically within the $\sim1-10\,\mu$s and $\sim1-100$MHz ranges, respectively. In such experimental efforts, single-shot analysis with high accuracy and precision becomes important when developing experiments that study dynamical effects and/or when developing portable instrumentations. Our results suggest that online, running-fashion, microsecond-resolved analysis of polarimetric/ellipsometric measurements with fractional uncertainties at the $10^{-6}$ levels, is possible, and using a proof-of-principle experimental demonstration we show that using a frequency-based analysis approach we can monitor and analyze signals at kHz rates and accurately detect signal changes at microsecond time-scales.      
### 62.Input-Shaping for Feed-Forward Control of Cable-Driven Parallel Robots  [ :arrow_down: ](https://arxiv.org/pdf/2010.11676.pdf)
>  This paper deals with the use of input-shaping filters in conjunction with a feed-forward control of Cable-Driven Parallel Robots (CDPRs), while integrating cable tension calculation to satisfy positive cable tensions along the prescribed trajectory of the moving-platform. This method aims to attenuate the oscillatory motions of the moving-platform. Thus, the input signal is modified to make it self-cancel residual vibrations. 5 The effectiveness, in terms of moving-platform oscillation attenuation, of the proposed closed-loop control method combined with shaping inputs is experimentally studied on a suspended and non-redundant CDPR prototype. This confirms residual vibration reduction improvement with respect to the unshaped control in terms of Peak-to-Peak amplitude of velocity error, which can achieve 72 % while using input-shaping filters.      
### 63.CycleGAN-VC3: Examining and Improving CycleGAN-VCs for Mel-spectrogram Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2010.11672.pdf)
>  Non-parallel voice conversion (VC) is a technique for learning mappings between source and target speeches without using a parallel corpus. Recently, cycle-consistent adversarial network (CycleGAN)-VC and CycleGAN-VC2 have shown promising results regarding this problem and have been widely used as benchmark methods. However, owing to the ambiguity of the effectiveness of CycleGAN-VC/VC2 for mel-spectrogram conversion, they are typically used for mel-cepstrum conversion even when comparative methods employ mel-spectrogram as a conversion target. To address this, we examined the applicability of CycleGAN-VC/VC2 to mel-spectrogram conversion. Through initial experiments, we discovered that their direct applications compromised the time-frequency structure that should be preserved during conversion. To remedy this, we propose CycleGAN-VC3, an improvement of CycleGAN-VC2 that incorporates time-frequency adaptive normalization (TFAN). Using TFAN, we can adjust the scale and bias of the converted features while reflecting the time-frequency structure of the source mel-spectrogram. We evaluated CycleGAN-VC3 on inter-gender and intra-gender non-parallel VC. A subjective evaluation of naturalness and similarity showed that for every VC pair, CycleGAN-VC3 outperforms or is competitive with the two types of CycleGAN-VC2, one of which was applied to mel-cepstrum and the other to mel-spectrogram. Audio samples are available at <a class="link-external link-http" href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc3/index.html" rel="external noopener nofollow">this http URL</a>.      
### 64.Neural Network-based Acoustic Vehicle Counting  [ :arrow_down: ](https://arxiv.org/pdf/2010.11659.pdf)
>  This paper addresses acoustic vehicle counting using one-channel audio. We predict the pass-by instants of vehicles from local minima of a vehicle-to-microphone distance predicted from audio. The distance is predicted via a two-stage (coarse-fine) regression, both realised using neural networks (NNs). Experiments show that the NN-based distance regression outperforms by far the previously proposed support vector regression. The $ 95\% $ confidence interval for the mean of vehicle counting error is within $[0.28\%, -0.55\%]$. Besides the minima-based counting, we propose a deep learning counting which operates on the predicted distance without detecting local minima. Results also show that removing low frequencies in features improves the counting performance.      
### 65.The HUAWEI Speaker Diarisation System for the VoxCeleb Speaker Diarisation Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2010.11657.pdf)
>  This paper describes the development of our system for the VoxCeleb Speaker Diarisation Challenge 2020. A well trained neural network based speech enhancement model is used for pre-processing and a neural network based voice activity detection (VAD) system is followed to remove background music and noise which are harmful for speaker diarisation system. The following diarisation system is built based on agglomerative hierarchical clustering (AHC) of x-vectors and a variational Bayesian hidden Markov Model (VB-HMM) based iterative clustering. Experimental results demonstrate that the proposed system yields substantial improvements compared with the baseline method for the diarisation task of the VoxCeleb Speaker Recognition Challenge 2020.      
### 66.Graph Neural Network for Large-Scale Network Localization  [ :arrow_down: ](https://arxiv.org/pdf/2010.11653.pdf)
>  Graph neural networks (GNNs) are popular to use for classifying structured data in the context of machine learning. But surprisingly, they are rarely applied to regression problems. In this work, we adopt GNN for a classic but challenging nonlinear regression problem, namely the network localization. Our main findings are in order. First, GNN is potentially the best solution to large-scale network localization in terms of accuracy, robustness and computational time. Second, thresholding of the communication range is essential to its superior performance. Simulation results corroborate that the proposed GNN based method outperforms all benchmarks by far. Such inspiring results are further justified theoretically in terms of data aggregation, non-line-of-sight (NLOS) noise removal and lowpass filtering effect, all affected by the threshold for neighbor selection. Code is available at <a class="link-external link-https" href="https://github.com/Yanzongzi/GNN-For-localization" rel="external noopener nofollow">this https URL</a>.      
### 67.Quaternion-Valued Variational Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2010.11647.pdf)
>  Deep probabilistic generative models have achieved incredible success in many fields of application. Among such models, variational autoencoders (VAEs) have proved their ability in modeling a generative process by learning a latent representation of the input. In this paper, we propose a novel VAE defined in the quaternion domain, which exploits the properties of quaternion algebra to improve performance while significantly reducing the number of parameters required by the network. The success of the proposed quaternion VAE with respect to traditional VAEs relies on the ability to leverage the internal relations between quaternion-valued input features and on the properties of second-order statistics which allow to define the latent variables in the augmented quaternion domain. In order to show the advantages due to such properties, we define a plain convolutional VAE in the quaternion domain and we evaluate it in comparison with its real-valued counterpart on the CelebA face dataset.      
### 68.Towards Low-Resource StarGAN Voice Conversion using Weight Adaptive Instance Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2010.11646.pdf)
>  Many-to-many voice conversion with non-parallel training data has seen significant progress in recent years. StarGAN-based models have been interests of voice conversion. However, most of the StarGAN-based methods only focused on voice conversion experiments for the situations where the number of speakers was small, and the amount of training data was large. In this work, we aim at improving the data efficiency of the model and achieving a many-to-many non-parallel StarGAN-based voice conversion for a relatively large number of speakers with limited training samples. In order to improve data efficiency, the proposed model uses a speaker encoder for extracting speaker embeddings and conducts adaptive instance normalization (AdaIN) on convolutional weights. Experiments are conducted with 109 speakers under two low-resource situations, where the number of training samples is 20 and 5 per speaker. An objective evaluation shows the proposed model is better than the baseline methods. Furthermore, a subjective evaluation shows that, for both naturalness and similarity, the proposed model outperforms the baseline method.      
### 69.Competitive Control with Delayed Imperfect Information  [ :arrow_down: ](https://arxiv.org/pdf/2010.11637.pdf)
>  This paper studies the impact of imperfect information in online control with adversarial disturbances. In particular, we consider both delayed state feedback and inexact predictions of future disturbances. We introduce a greedy, myopic policy that yields a constant competitive ratio against the offline optimal policy with delayed feedback and inexact predictions. A special case of our result is a constant competitive policy for the case of exact predictions and no delay, a previously open problem. We also analyze the fundamental limits of online control with limited information by showing that our competitive ratio bounds for the greedy, myopic policy in the adversarial setting match (up to lower-order terms) lower bounds in the stochastic setting.      
### 70.LaSAFT: Latent Source Attentive Frequency Transformation for Conditioned Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2010.11631.pdf)
>  Recent deep-learning approaches have shown that Frequency Transformation (FT) blocks can significantly improve spectrogram-based single-source separation models by capturing frequency patterns. The goal of this paper is to extend the FT block to fit the multi-source task. We propose the Latent Source Attentive Frequency Transformation (LaSAFT) block to capture source-dependent frequency patterns. We also propose the Gated Point-wise Convolutional Modulation (GPoCM), an extension of Feature-wise Linear Modulation (FiLM), to modulate internal features. By employing these two novel methods, we extend the Conditioned-U-Net (CUNet) for multi-source separation, and the experimental results indicate that our LaSAFT and GPoCM can improve the CUNet's performance, achieving state-of-the-art SDR performance on several MUSDB18 source separation tasks.      
### 71.DeepGalaxy: Deducing the Properties of Galaxy Mergers from Images Using Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.11630.pdf)
>  Galaxy mergers, the dynamical process during which two galaxies collide, are among the most spectacular phenomena in the Universe. During this process, the two colliding galaxies are tidally disrupted, producing significant visual features that evolve as a function of time. These visual features contain valuable clues for deducing the physical properties of the galaxy mergers. In this work, we propose DeepGalaxy, a visual analysis framework trained to predict the physical properties of galaxy mergers based on their morphology. Based on an encoder-decoder architecture, DeepGalaxy encodes the input images to a compressed latent space $z$, and determines the similarity of images according to the latent-space distance. DeepGalaxy consists of a fully convolutional autoencoder (FCAE) which generates activation maps at its 3D latent-space, and a variational autoencoder (VAE) which compresses the activation maps into a 1D vector, and a classifier that generates labels from the activation maps. The backbone of the FCAE can be fully customized according to the complexity of the images. DeepGalaxy demonstrates excellent scaling performance on parallel machines. On the Endeavour supercomputer, the scaling efficiency exceeds 0.93 when trained on 128 workers, and it maintains above 0.73 when trained with 512 workers. Without having to carry out expensive numerical simulations, DeepGalaxy makes inferences of the physical properties of galaxy mergers directly from images, and thereby achieves a speedup factor of $\sim 10^5$.      
### 72.Backdoor Attack against Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2010.11607.pdf)
>  Speaker verification has been widely and successfully adopted in many mission-critical areas for user identification. The training of speaker verification requires a large amount of data, therefore users usually need to adopt third-party data ($e.g.$, data from the Internet or third-party data company). This raises the question of whether adopting untrusted third-party data can pose a security threat. In this paper, we demonstrate that it is possible to inject the hidden backdoor for infecting speaker verification models by poisoning the training data. Specifically, we design a clustering-based attack scheme where poisoned samples from different clusters will contain different triggers ($i.e.$, pre-defined utterances), based on our understanding of verification tasks. The infected models behave normally on benign samples, while attacker-specified unenrolled triggers will successfully pass the verification even if the attacker has no information about the enrolled speaker. We also demonstrate that existing backdoor attacks can not be directly adopted in attacking speaker verification. Our attack not only provides a new perspective for designing novel attacks, but also serves as a strong baseline for improving the robustness of verification methods.      
### 73.A simulation-based evaluation of a Cargo-Hitching service for E-commerce using mobility-on-demand vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2010.11585.pdf)
>  Time-sensitive parcel deliveries, shipments requested for delivery in a day or less, are an increasingly important research subject. It is challenging to deal with these deliveries from a carrier perspective since it entails additional planning constraints, preventing an efficient consolidation of deliveries which is possible when demand is well known in advance. Furthermore, such time-sensitive deliveries are requested to a wider spatial scope than retail centers, including homes and offices. Therefore, an increase in such deliveries is considered to exacerbate negative externalities such as congestion and emissions. One of the solutions is to leverage spare capacity in passenger transport modes. This concept is often denominated as cargo-hitching. While there are various possible system designs, it is crucial that such solution does not deteriorate the quality of service of passenger trips. This research aims to evaluate the use of Mobility-On-Demand services to perform same-day parcel deliveries. For this purpose, we use SimMobility, a high-resolution agent-based simulation platform of passenger and freight flows, applied in Singapore. E-commerce demand carrier data are used to characterize simulated parcel delivery demand. Operational scenarios that aim to minimize the adverse effect of fulfilling deliveries with Mobility-On-Demand vehicles on Mobility-On-Demand passenger flows (fulfillment, wait and travel times) are explored. Results indicate that the Mobility-On-Demand services have potential to fulfill a considerable amount of parcel deliveries and decrease freight vehicle traffic and total vehicle-kilometers-travelled without compromising the quality of Mobility On-Demand for passenger travel.      
### 74.AISHELL-3: A Multi-speaker Mandarin TTS Corpus and the Baselines  [ :arrow_down: ](https://arxiv.org/pdf/2010.11567.pdf)
>  In this paper, we present AISHELL-3, a large-scale and high-fidelity multi-speaker Mandarin speech corpus which could be used to train multi-speaker Text-to-Speech (TTS) systems. The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in Chinese character-level and pinyin-level are provided along with the recordings. We present a baseline system that uses AISHELL-3 for multi-speaker Madarin speech synthesis. The multi-speaker speech synthesis system is an extension on Tacotron-2 where a speaker verification model and a corresponding loss regarding voice similarity are incorporated as the feedback constraint. We aim to use the presented corpus to build a robust synthesis model that is able to achieve zero-shot voice cloning. The system trained on this dataset also generalizes well on speakers that are never seen in the training process. Objective evaluation results from our experiments show that the proposed multi-speaker synthesis system achieves high voice similarity concerning both speaker embedding similarity and equal error rate measurement. The dataset, baseline system code and generated samples are available online.      
### 75.Mood Classification Using Listening Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.11512.pdf)
>  The mood of a song is a highly relevant feature for exploration and recommendation in large collections of music. These collections tend to require automatic methods for predicting such moods. In this work, we show that listening-based features outperform content-based ones when classifying moods: embeddings obtained through matrix factorization of listening data appear to be more informative of a track mood than embeddings based on its audio content. To demonstrate this, we compile a subset of the Million Song Dataset, totalling 67k tracks, with expert annotations of 188 different moods collected from AllMusic. Our results on this novel dataset not only expose the limitations of current audio-based models, but also aim to foster further reproducible research on this timely topic.      
### 76.A Framework for Contrastive and Generative Learning of Audio Representations  [ :arrow_down: ](https://arxiv.org/pdf/2010.11459.pdf)
>  In this paper, we present a framework for contrastive learning for audio representations, in a self supervised frame work without access to any ground truth labels. The core idea in self supervised contrastive learning is to map an audio signal and its various augmented versions (representative of salient aspects of audio like pitch, timbre etc.) to a space where they are close together, and are separated from other different signals. In addition we also explore generative models based on state of the art transformer based architectures for learning latent spaces for audio signals, without access to any labels. Here, we map audio signals on a smaller scale to discrete dictionary elements and train transformers to predict the next dictionary element. We only use data as a method of supervision, bypassing the need of labels needed to act as a supervision for training the deep neural networks. We then use a linear classifier head in order to evaluate the performance of our models, for both self supervised contrastive and generative transformer based representations that are learned. Our system achieves considerable performance, compared to a fully supervised method, with access to ground truth labels to train the neural network model. These representations, with avail-ability of large scale audio data show promise in various tasks for audio understanding tasks      
### 77.Parallel Tacotron: Non-Autoregressive and Controllable TTS  [ :arrow_down: ](https://arxiv.org/pdf/2010.11439.pdf)
>  Although neural end-to-end text-to-speech models can synthesize highly natural speech, there is still room for improvements to its efficiency and naturalness. This paper proposes a non-autoregressive neural text-to-speech model augmented with a variational autoencoder-based residual encoder. This model, called \emph{Parallel Tacotron}, is highly parallelizable during both training and inference, allowing efficient synthesis on modern parallel hardware. The use of the variational autoencoder relaxes the one-to-many mapping nature of the text-to-speech problem and improves naturalness. To further improve the naturalness, we use lightweight convolutions, which can efficiently capture local contexts, and introduce an iterative spectrogram loss inspired by iterative refinement. Experimental results show that Parallel Tacotron matches a strong autoregressive baseline in subjective evaluations with significantly decreased inference time.      
### 78.GAN based Unsupervised Segmentation: Should We Match the Exact Number of Objects  [ :arrow_down: ](https://arxiv.org/pdf/2010.11438.pdf)
>  The unsupervised segmentation is an increasingly popular topic in biomedical image analysis. The basic idea is to approach the supervised segmentation task as an unsupervised synthesis problem, where the intensity images can be transferred to the annotation domain using cycle-consistent adversarial learning. The previous studies have shown that the macro-level (global distribution level) matching on the number of the objects (e.g., cells, tissues, protrusions etc.) between two domains resulted in better segmentation performance. However, no prior studies have exploited whether the unsupervised segmentation performance would be further improved when matching the exact number of objects at micro-level (mini-batch level). In this paper, we propose a deep learning based unsupervised segmentation method for segmenting highly overlapped and dynamic sub-cellular microvilli. With this challenging task, both micro-level and macro-level matching strategies were evaluated. To match the number of objects at the micro-level, the novel fluorescence-based micro-level matching approach was presented. From the experimental results, the micro-level matching did not improve the segmentation performance, compared with the simpler macro-level matching.      
### 79.Self-training and Pre-training are Complementary for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.11430.pdf)
>  Self-training and unsupervised pre-training have emerged as effective approaches to improve speech recognition systems using unlabeled data. However, it is not clear whether they learn similar patterns or if they can be effectively combined. In this paper, we show that pseudo-labeling and pre-training with wav2vec 2.0 are complementary in a variety of labeled data setups. Using just 10 minutes of labeled data from Libri-light as well as 53k hours of unlabeled data from LibriVox achieves WERs of 3.0%/5.2% on the clean and other test sets of Librispeech - rivaling the best published systems trained on 960 hours of labeled data only a year ago. Training on all labeled data of Librispeech achieves WERs of 1.5%/3.1%.      
### 80.TeX-Graph: Coupled tensor-matrix knowledge-graph embedding for COVID-19 drug repurposing  [ :arrow_down: ](https://arxiv.org/pdf/2010.11367.pdf)
>  Knowledge graphs (KGs) are powerful tools that codify relational behaviour between entities in knowledge bases. KGs can simultaneously model many different types of subject-predicate-object and higher-order relations. As such, they offer a flexible modeling framework that has been applied to many areas, including biology and pharmacology -- most recently, in the fight against COVID-19. The flexibility of KG modeling is both a blessing and a challenge from the learning point of view. In this paper we propose a novel coupled tensor-matrix framework for KG embedding. We leverage tensor factorization tools to learn concise representations of entities and relations in knowledge bases and employ these representations to perform drug repurposing for COVID-19. Our proposed framework is principled, elegant, and achieves 100% improvement over the best baseline in the COVID-19 drug repurposing task using a recently developed biological KG.      
### 81.QISTA-Net: DNN Architecture to Solve $\ell_q$-norm Minimization Problem and Image Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2010.11363.pdf)
>  In this paper, we reformulate the non-convex $\ell_q$-norm minimization problem with $q\in(0,1)$ into a 2-step problem, which consists of one convex and one non-convex subproblems, and propose a novel iterative algorithm called QISTA ($\ell_q$-ISTA) to solve the $\left(\ell_q\right)$-problem. By taking advantage of deep learning in accelerating optimization algorithms, together with the speedup strategy that using the momentum from all previous layers in the network, we propose a learning-based method, called QISTA-Net-s, to solve the sparse signal reconstruction problem. Extensive experimental comparisons demonstrate that the QISTA-Net-s yield better reconstruction qualities than state-of-the-art $\ell_1$-norm optimization (plus learning) algorithms even if the original sparse signal is noisy. On the other hand, based on the network architecture associated with QISTA, with considering the use of convolution layers, we proposed the QISTA-Net-n for solving the image CS problem, and the performance of the reconstruction still outperforms most of the state-of-the-art natural images reconstruction methods. QISTA-Net-n is designed in unfolding QISTA and adding the convolutional operator as the dictionary. This makes QISTA-Net-s interpretable. We provide complete experimental results that QISTA-Net-s and QISTA-Net-n contribute the better reconstruction performance than the competing.      
### 82.NU-GAN: High resolution neural upsampling with GAN  [ :arrow_down: ](https://arxiv.org/pdf/2010.11362.pdf)
>  In this paper, we propose NU-GAN, a new method for resampling audio from lower to higher sampling rates (upsampling). Audio upsampling is an important problem since productionizing generative speech technology requires operating at high sampling rates. Such applications use audio at a resolution of 44.1 kHz or 48 kHz, whereas current speech synthesis methods are equipped to handle a maximum of 24 kHz resolution. NU-GAN takes a leap towards solving audio upsampling as a separate component in the text-to-speech (TTS) pipeline by leveraging techniques for audio generation using GANs. ABX preference tests indicate that our NU-GAN resampler is capable of resampling 22 kHz to 44.1 kHz audio that is distinguishable from original audio only 7.4% higher than random chance for single speaker dataset, and 10.8% higher than chance for multi-speaker dataset.      
### 83.Class-Conditional Defense GAN Against End-to-End Speech Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2010.11352.pdf)
>  In this paper we propose a novel defense approach against end-to-end adversarial attacks developed to fool advanced speech-to-text systems such as DeepSpeech and Lingvo. Unlike conventional defense approaches, the proposed approach does not directly employ low-level transformations such as autoencoding a given input signal aiming at removing potential adversarial perturbation. Instead of that, we find an optimal input vector for a class conditional generative adversarial network through minimizing the relative chordal distance adjustment between a given test input and the generator network. Then, we reconstruct the 1D signal from the synthesized spectrogram and the original phase information derived from the given input signal. Hence, this reconstruction does not add any extra noise to the signal and according to our experimental results, our defense-GAN considerably outperforms conventional defense algorithms both in terms of word error rate and sentence level recognition accuracy.      
### 84.Network topology change-point detection from graph signals with prior spectral signatures  [ :arrow_down: ](https://arxiv.org/pdf/2010.11345.pdf)
>  We consider the problem of sequential graph topology change-point detection from graph signals. We assume that signals on the nodes of the graph are regularized by the underlying graph structure via a graph filtering model, which we then leverage to distill the graph topology change-point detection problem to a subspace detection problem. We demonstrate how prior information on the spectral signature of the post-change graph can be incorporated to implicitly denoise the observed sequential data, thus leading to a natural CUSUM-based algorithm for change-point detection. Numerical experiments illustrate the performance of our proposed approach, particularly underscoring the benefits of (potentially noisy) prior information.      
### 85.Full-Duplex and Dynamic-TDD: Pushing the Limits of Spectrum Reuse in Multi-Cell Communications  [ :arrow_down: ](https://arxiv.org/pdf/2010.11317.pdf)
>  Although in cellular networks full-duplex and dynamic time-division duplexing promise increased spectrum efficiency, their potential is so far challenged by increased interference. While previous studies have shown that self-interference can be suppressed to a sufficient level, we show that the cross-link interference for both duplexing modes, especially from base station to base station, is the remaining challenge in multi-cell networks, restricting the uplink performance. Using beamforming techniques of low-complexity, we show that this interference can be mitigated, and that full-duplex and dynamic time-division duplexing can substantially increase the capacity of multi-cell networks. Our results suggest that if we can control the cross link interference in full-duplex, then we can almost double the multi cell network capacity as well as user throughput. Therefore, the techniques in this paper have the potentiality to enable a smooth introduction of full-duplex into cellular systems.      
### 86.Uncertainty-Aware Deep Ensembles for Reliable and Explainable Predictions of Clinical Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2010.11310.pdf)
>  Deep learning-based support systems have demonstrated encouraging results in numerous clinical applications involving the processing of time series data. While such systems often are very accurate, they have no inherent mechanism for explaining what influenced the predictions, which is critical for clinical tasks. However, existing explainability techniques lack an important component for trustworthy and reliable decision support, namely a notion of uncertainty. In this paper, we address this lack of uncertainty by proposing a deep ensemble approach where a collection of DNNs are trained independently. A measure of uncertainty in the relevance scores is computed by taking the standard deviation across the relevance scores produced by each model in the ensemble, which in turn is used to make the explanations more reliable. The class activation mapping method is used to assign a relevance score for each time step in the time series. Results demonstrate that the proposed ensemble is more accurate in locating relevant time steps and is more consistent across random initializations, thus making the model more trustworthy. The proposed methodology paves the way for constructing trustworthy and dependable support systems for processing clinical time series for healthcare related tasks.      
### 87.System Design and Control of an Apple Harvesting Robot  [ :arrow_down: ](https://arxiv.org/pdf/2010.11296.pdf)
>  There is a growing need for robotic apple harvesting due to decreasing availability and rising cost in labor. Towards the goal of developing a viable robotic system for apple harvesting, this paper presents synergistic mechatronic design and motion control of a robotic apple harvesting prototype, which lays a critical foundation for future advancements. Specifically, we develop a deep learning-based fruit detection and localization system using an RGB-D camera. A three degree-of-freedom manipulator is then designed with a hybrid pneumatic/motor actuation mechanism to achieve fast and dexterous movements. A vacuum-based end-effector is used for apple detaching. These three components are integrated into a robotic apple harvesting prototype with simplicity, compactness, and robustness. Moreover, a nonlinear velocity-based control scheme is developed for the manipulator to achieve accurate and agile motion control. Test experiments are conducted to demonstrate the performance of the developed apple harvesting robot.      
### 88.Bidirectional Microrocker Bots with Sharp Tips Actuated by a Single Electromagnet  [ :arrow_down: ](https://arxiv.org/pdf/2010.11295.pdf)
>  The recent advancements in nanoscale 3D printing and microfabrication techniques have reinvigorated research on microrobotics and nanomachines. However, precise control of the robot motion and navigation on biological environments have remained challenging to date. This work presents the first demonstration of magnetic microscale rocker robot (microrocker bot) capable of bidirectional movement on flat as well as biological surfaces, when actuated by a single compact electromagnet. The 100um by 113um by 36um robot was 3D printed via two-photon lithography and subsequently coated with a nickel (Ni) thin film. When actuated by an externally applied magnetic sawtooth field, the robot demonstrated stick-slip motion enabled by its rockers. The controllable bidirectional motion is enabled by adjusting the DC offset of the waveform, which tilts the robot and biases it towards either forward or backward motion. The microrocker bots are further equipped with sharp tips that can get engaged via application of DC-only or low frequency magnetic fields. This novel control method offers an attractive solution to replace the multiple bulky coils traditionally used for magnetic actuation and control, as well as allows for a more flexible and simple approach towards microrobotics motion control. When the frequency and offset of the sawtooth waveform are optimized, the robot travels up to 87ums (0.87 body length per second) forward and backward with minor deviance from linear trajectories. Finally, to prove the robot's capabilities in direct contact with biological environments, we demonstrate the microbot's ability to traverse forward and backward on the surface of a Dracaena Fragrans (corn plant), as well as upend on its mechanical tip.      
### 89.Decentralized optimization over noisy, rate-constrained networks: How to agree by talking about how we disagree  [ :arrow_down: ](https://arxiv.org/pdf/2010.11292.pdf)
>  In decentralized optimization, multiple nodes in a network collaborate to minimize the sum of their local loss functions. The information exchange between nodes required for the task is often limited by network connectivity. We consider a generalization of this setting in which communication is further hindered by (i) a finite data-rate constraint on the signal transmitted by any node, and (ii) an additive noise corruption of the signal received by any node. We develop a novel algorithm for this scenario: Decentralized Lazy Mirror Descent with Differential Exchanges (DLMD-DiffEx), which guarantees convergence of the local estimates to the optimal solution under the given communication constraints. A salient feature of DLMD-DiffEx is the careful design of the evolution of proxy variables which are maintained to account for the disagreement in estimates at the nodes due to channel noise and data-rate constraints. We investigate the performance of DLMD-DiffEx both from a theoretical perspective as well as through numerical evaluations.      
### 90.Unrolling of Deep Graph Total Variation for Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2010.11290.pdf)
>  While deep learning (DL) architectures like convolutional neural networks (CNNs) have enabled effective solutions in image denoising, in general their implementations overly rely on training data, lack interpretability, and require tuning of a large parameter set. In this paper, we combine classical graph signal filtering with deep feature learning into a competitive hybrid design---one that utilizes interpretable analytical low-pass graph filters and employs 80% fewer network parameters than state-of-the-art DL denoising scheme DnCNN. Specifically, to construct a suitable similarity graph for graph spectral filtering, we first adopt a CNN to learn feature representations per pixel, and then compute feature distances to establish edge weights. Given a constructed graph, we next formulate a convex optimization problem for denoising using a graph total variation (GTV) prior. Via a $l_1$ graph Laplacian reformulation, we interpret its solution in an iterative procedure as a graph low-pass filter and derive its frequency response. For fast filter implementation, we realize this response using a Lanczos approximation. Experimental results show that in the case of statistical mistmatch, our algorithm outperformed DnCNN by up to 3dB in PSNR.      
### 91.Deep-Reinforcement-Learning-Based Scheduling with Contiguous Resource Allocation for Next-Generation Cellular Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.11269.pdf)
>  In this work, we propose a novel scheduling algorithm with contiguous frequency-domain resource allocation (FDRA) based on deep reinforcement learning (DRL) that jointly selects users and allocates resource blocks (RBs). The scheduling problem is modeled as a Markov decision process, and a DRL agent determines which user and how many consecutive RBs for that user should be scheduled at each RB allocation step. The state, action, and reward sets are delicately designed to train the DRL network. More specifically, the originally quasicontinuous action space, which is inherent to contiguous FDRA, is refined into a finite and discrete action space to obtain a tradeoff between the inference latency and system performance. Simulation results show that the proposed DRL-based algorithm outperforms other representative baseline schemes while having lower online computational complexity.      
### 92.An Efficient Real-Time NMPC for Quadrotor Position Control under Communication Time-Delay  [ :arrow_down: ](https://arxiv.org/pdf/2010.11264.pdf)
>  The advances in computer processor technology have enabled the application of nonlinear model predictive control (NMPC) to agile systems, such as quadrotors. These systems are characterized by their underactuation, nonlinearities, bounded inputs, and time-delays. Classical control solutions fall short in overcoming these difficulties and fully exploiting the capabilities offered by such platforms. This paper presents the design and implementation of an efficient position controller for quadrotors based on real-time NMPC with time-delay compensation and bounds enforcement on the actuators. To deal with the limited computational resources onboard, an offboard control architecture is proposed. It is implemented using the high-performance software package acados, which solves optimal control problems and implements a real-time iteration (RTI) variant of a sequential quadratic programming (SQP) scheme with Gauss-Newton Hessian approximation. The quadratic subproblems (QP) in the SQP scheme are solved with HPIPM, an interior-point method solver, built on top of the linear algebra library BLASFEO, finely tuned for multiple CPU architectures. Solution times are further reduced by reformulating the QPs using the efficient partial condensing algorithm implemented in HPIPM. We demonstrate the capabilities of our architecture using the Crazyflie 2.1 nanoquadrotor.      
### 93.The IDLAB VoxSRC-20 Submission: Large Margin Fine-Tuning and Quality-Aware Score Calibration in DNN Based Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2010.11255.pdf)
>  In this paper we propose and analyse a large margin fine-tuning strategy and a quality-aware score calibration in text-independent speaker verification. Large margin fine-tuning is a secondary training stage for DNN based speaker verification systems trained with margin-based loss functions. It enables the network to create more robust speaker embeddings by enabling the use of longer training utterances in combination with a more aggressive margin penalty. Score calibration is a common practice in speaker verification systems to map output scores to well-calibrated log-likelihood-ratios, which can be converted to interpretable probabilities. By including quality features in the calibration system, the decision thresholds of the evaluation metrics become quality-dependent and more consistent across varying trial conditions. Applying both enhancements on the ECAPA-TDNN architecture leads to state-of-the-art results on all publicly available VoxCeleb1 test sets and contributed to our winning submissions in the supervised verification tracks of the VoxCeleb Speaker Recognition Challenge 2020.      
### 94.Learning Quadrupedal Locomotion over Challenging Terrain  [ :arrow_down: ](https://arxiv.org/pdf/2010.11251.pdf)
>  Some of the most challenging environments on our planet are accessible to quadrupedal animals but remain out of reach for autonomous machines. Legged locomotion can dramatically expand the operational domains of robotics. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have escalated in complexity while falling short of the generality and robustness of animal locomotion. Here we present a radically robust controller for legged locomotion in challenging natural environments. We present a novel solution to incorporating proprioceptive feedback in locomotion control and demonstrate remarkable zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. It is based on a neural network that acts on a stream of proprioceptive signals. The trained controller has taken two generations of quadrupedal ANYmal robots to a variety of natural environments that are beyond the reach of prior published work in legged locomotion. The controller retains its robustness under conditions that have never been encountered during training: deformable terrain such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work opens new frontiers for robotics and indicates that radical robustness in natural environments can be achieved by training in much simpler domains.      
### 95.Dynamic Layer Customization for Noise Robust Speech Emotion Recognition in Heterogeneous Condition Training  [ :arrow_down: ](https://arxiv.org/pdf/2010.11226.pdf)
>  Robustness to environmental noise is important to creating automatic speech emotion recognition systems that are deployable in the real world. Prior work on noise robustness has assumed that systems would not make use of sample-by-sample training noise conditions, or that they would have access to unlabelled testing data to generalize across noise conditions. We avoid these assumptions and introduce the resulting task as heterogeneous condition training. We show that with full knowledge of the test noise conditions, we can improve performance by dynamically routing samples to specialized feature encoders for each noise condition, and with partial knowledge, we can use known noise conditions and domain adaptation algorithms to train systems that generalize well to unseen noise conditions. We then extend these improvements to the multimodal setting by dynamically routing samples to maintain temporal ordering, resulting in significant improvements over approaches that do not specialize or generalize based on noise type.      
### 96.AttendAffectNet: Self-Attention based Networks for Predicting Affective Responses from Movies  [ :arrow_down: ](https://arxiv.org/pdf/2010.11188.pdf)
>  In this work, we propose different variants of the self-attention based network for emotion prediction from movies, which we call AttendAffectNet. We take both audio and video into account and incorporate the relation among multiple modalities by applying self-attention mechanism in a novel manner into the extracted features for emotion prediction. We compare it to the typically temporal integration of the self-attention based model, which in our case, allows to capture the relation of temporal representations of the movie while considering the sequential dependencies of emotion responses. We demonstrate the effectiveness of our proposed architectures on the extended COGNIMUSE dataset [1], [2] and the MediaEval 2016 Emotional Impact of Movies Task [3], which consist of movies with emotion annotations. Our results show that applying the self-attention mechanism on the different audio-visual features, rather than in the time domain, is more effective for emotion prediction. Our approach is also proven to outperform many state-ofthe-art models for emotion prediction. The code to reproduce our results with the models' implementation is available at: <a class="link-external link-https" href="https://github.com/ivyha010/AttendAffectNet" rel="external noopener nofollow">this https URL</a>.      

# ArXiv eess --Mon, 12 Oct 2020
### 1.Unsupervised 3D Brain Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.04717.pdf)
>  Anomaly detection (AD) is the identification of data samples that do not fit a learned data distribution. As such, AD systems can help physicians to determine the presence, severity, and extension of a pathology. Deep generative models, such as Generative Adversarial Networks (GANs), can be exploited to capture anatomical variability. Consequently, any outlier (i.e., sample falling outside of the learned distribution) can be detected as an abnormality in an unsupervised fashion. By using this method, we can not only detect expected or known lesions, but we can even unveil previously unrecognized biomarkers. To the best of our knowledge, this study exemplifies the first AD approach that can efficiently handle volumetric data and detect 3D brain anomalies in one single model. Our proposal is a volumetric and high-detail extension of the 2D f-AnoGAN model obtained by combining a state-of-the-art 3D GAN with refinement training steps. In experiments using non-contrast computed tomography images from traumatic brain injury (TBI) patients, the model detects and localizes TBI abnormalities with an area under the ROC curve of ~75%. Moreover, we test the potential of the method for detecting other anomalies such as low quality images, preprocessing inaccuracies, artifacts, and even the presence of post-operative signs (such as a craniectomy or a brain shunt). The method has potential for rapidly labeling abnormalities in massive imaging datasets, as well as identifying new biomarkers.      
### 2.PathoNet: Deep learning assisted evaluation of Ki-67 and tumor infiltrating lymphocytes (TILs) as prognostic factors in breast cancer; A large dataset and baseline  [ :arrow_down: ](https://arxiv.org/pdf/2010.04713.pdf)
>  The nuclear protein Ki-67 and Tumor infiltrating lymphocytes (TILs) have been introduced as prognostic factors in predicting tumor progression and its treatment response. The value of the Ki-67 index and TILs in approach to heterogeneous tumors such as Breast cancer (BC), known as the most common cancer in women worldwide, has been highlighted in the literature. Due to the indeterminable and subjective nature of Ki-67 as well as TILs scoring, automated methods using machine learning, specifically approaches based on deep learning, have attracted attention. Yet, deep learning methods need considerable annotated data. In the absence of publicly available benchmarks for BC Ki-67 stained cell detection and further annotated classification of cells, we propose SHIDC-BC-Ki-67 as a dataset for the aforementioned purpose. We also introduce a novel pipeline and a backend, namely PathoNet for Ki-67 immunostained cell detection and classification and simultaneous determination of intratumoral TILs score. Further, we show that despite facing challenges, our proposed backend, PathoNet, outperforms the state of the art methods proposed to date in the harmonic mean measure.      
### 3.Attaining Real-Time Super-Resolution for Microscopic Images Using GAN  [ :arrow_down: ](https://arxiv.org/pdf/2010.04634.pdf)
>  In the last few years, several deep learning models, especially Generative Adversarial Networks have received a lot of attention for the task of Single Image Super-Resolution (SISR). These methods focus on building an end-to-end framework, which produce a high resolution(SR) image from a given low resolution(LR) image in a single step to achieve state-of-the-art performance. This paper focuses on improving an existing deep-learning based method to perform Super-Resolution Microscopy in real-time using a standard GPU. For this, we first propose a tiling strategy, which takes advantage of parallelism provided by a GPU to speed up the network training process. Further, we suggest simple changes to the architecture of the generator and the discriminator of SRGAN. Subsequently, We compare the quality and the running time for the outputs produced by our model, opening its applications in different areas like low-end benchtop and even mobile microscopy. Finally, we explore the possibility of the trained network to produce High-Resolution HR outputs for different domains.      
### 4.Adaptive Control of Linear Parameter-Varying Systems with Unmatched Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2010.04600.pdf)
>  This paper presents an adaptive control solution for linear parameter-varying (LPV) systems with unknown input gain and unmatched nonlinear (state- and time-dependent) uncertainties based on the $\mathcal{L}_1$ adaptive control architecture. Specifically, we introduce new tools for stability and performance analysis leveraging the peak-to-peak gain (PPG) bound of an LPV system that is computed using linear matrix inequality (LMI) techniques. A piecewise-constant adaptive law is introduced to estimate the lumped uncertainty with quantifiable error bounds, which can be systematically improved by reducing the adaptation sampling time. We also present a new approach to attenuate the unmatched uncertainty based on the PPG minimization that is applicable to a broad class of systems with linear nominal dynamics. In addition, we derive transient and steady-state performance bounds in terms of the input and output signals of the adaptive closed-loop system as compared to the same signals of a non-adaptive reference system that represents the possibly best achievable performance. Under mild assumptions, we prove that the transient and steady-state performance bounds can be uniformly reduced by decreasing the adaptation sampling time, which is subject only to hardware limitations. The theoretical development is validated by extensive simulations on the short-period dynamics of an F-16 aircraft.      
### 5.Computing Dynamic User Equilibrium on Large-Scale Networks Without Knowing Global Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2010.04597.pdf)
>  Dynamic user equilibrium (DUE) is a Nash-like solution concept describing an equilibrium in dynamic traffic systems over a fixed planning period. DUE is a challenging class of equilibrium problems, connecting network loading models and notions of system equilibrium in one concise mathematical framework. Recently, Friesz and Han introduced an integrated framework for DUE computation on large-scale networks, featuring a basic fixed-point algorithm for the effective computation of DUE. In the same work, they present an open-source MATLAB toolbox which allows researchers to test and validate new numerical solvers. This paper builds on this seminal contribution, and extends it in several important ways. At a conceptual level, we provide new strongly convergent algorithms designed to compute a DUE directly in the infinite-dimensional space of path flows. An important feature of our algorithms is that they give provable convergence guarantees without knowledge of global parameters. In fact, the algorithms we propose are adaptive, in the sense that they do not need a priori knowledge of global parameters of the delay operator, and which are provable convergent even for delay operators which are non-monotone. We implement our numerical schemes on standard test instances, and compare them with the numerical solution strategy employed by Friesz and Han.      
### 6.Secrecy Rate Maximization for Reconfigurable Intelligent Surface Aided Millimeter Wave System with Low-resolution DAC  [ :arrow_down: ](https://arxiv.org/pdf/2010.04569.pdf)
>  In this letter, we investigate the secrecy rate of an reconfigurable intelligent surface (RIS)-aided millimeter-wave (mmWave) system with hardware limitations. Compared to the RIS-aided systems in most existing works, we consider the case of the RIS-aided mmWave system with low-resolution digital-to-analog converters (LDACs). We formulate a secrecy rate maximization problem hardware constraints. Then by optimizing the RIS phase shift and the transmit beamforming to maximize the secrecy rate. Due to the nonconvexity of the problem, the formulated problem is intractable. To handle the problem, an alternating optimization (AO)-based algorithm is proposed. Specifically, we first use the successive convex approximation (SCA) method to obtain the transmit beamforming. Then the element-wise block coordinate descent (BCD) method is used to obtain the RIS phase shift. Numerical results demonstrate that the RIS can mitigate the hardware loss, and the proposed AO-based algorithm with low complexity outperformances the baselines.      
### 7.Audio-Visual Speech Inpainting with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.04556.pdf)
>  In this paper, we present a deep-learning-based framework for audio-visual speech inpainting, i.e., the task of restoring the missing parts of an acoustic speech signal from reliable audio context and uncorrupted visual information. Recent work focuses solely on audio-only methods and generally aims at inpainting music signals, which show highly different structure than speech. Instead, we inpaint speech signals with gaps ranging from 100 ms to 1600 ms to investigate the contribution that vision can provide for gaps of different duration. We also experiment with a multi-task learning approach where a phone recognition task is learned together with speech inpainting. Results show that the performance of audio-only speech inpainting approaches degrades rapidly when gaps get large, while the proposed audio-visual approach is able to plausibly restore missing information. In addition, we show that multi-task learning is effective, although the largest contribution to performance comes from vision.      
### 8.Conditional GAN for Prediction of Glaucoma Progression with Macular Optical Coherence Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2010.04552.pdf)
>  The estimation of glaucoma progression is a challenging task as the rate of disease progression varies among individuals in addition to other factors such as measurement variability and the lack of standardization in defining progression. Structural tests, such as thickness measurements of the retinal nerve fiber layer or the macula with optical coherence tomography (OCT), are able to detect anatomical changes in glaucomatous eyes. Such changes may be observed before any functional damage. In this work, we built a generative deep learning model using the conditional GAN architecture to predict glaucoma progression over time. The patient's OCT scan is predicted from three or two prior measurements. The predicted images demonstrate high similarity with the ground truth images. In addition, our results suggest that OCT scans obtained from only two prior visits may actually be sufficient to predict the next OCT scan of the patient after six months.      
### 9.Study on Leveraging Wind Farm Reactive Power Potential for Uncertain Power System Reactive Power Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2010.04545.pdf)
>  This paper suggests leveraging reactive power potential (RPP) embedded in wind farms to improve power system operational safety and optimality. First, three typical RPP provision approaches are analyzed and a two-stage robust linear optimization based RPP evaluation method is proposed. This approach yields an RPP range that ensures the security of wind farm operations under any realization of uncertainty regarding the wind farm. Simplified DistFlow equations are employed here for a compromise between computational accuracy and cost. Next, an uncertain RPP-involved reactive power optimization problem is introduced, through which system operators ensure system-wide security and optimality regarding the base case and against any possible deviation caused by uncertain lumped loads and renewable generation. Steady-state models of automatic generation control and local voltage control are also captured in this uncertain reactive power optimization, which is then transformed through Soyster's method into a deterministic optimization problem that is readily solvable. Case studies have conceptually validated that even with notable uncertainty, wind farms are still a competent reactive power resource providing considerable RPP. Also, simulation confirms positive and notable improvement of leveraging wind-farm RPP on system-wide operational security and optimality, especially for power systems with high wind penetration.      
### 10.Upper Esophageal Sphincter Opening Segmentation with Convolutional Recurrent Neural Networks in High Resolution Cervical Auscultation  [ :arrow_down: ](https://arxiv.org/pdf/2010.04541.pdf)
>  Upper esophageal sphincter is an important anatomical landmark of the swallowing process commonly observed through the kinematic analysis of radiographic examinations that are vulnerable to subjectivity and clinical feasibility issues. Acting as the doorway of esophagus, upper esophageal sphincter allows the transition of ingested materials from pharyngeal into esophageal stages of swallowing and a reduced duration of opening can lead to penetration/aspiration and/or pharyngeal residue. Therefore, in this study we consider a non-invasive high resolution cervical auscultation-based screening tool to approximate the human ratings of upper esophageal sphincter opening and closure. Swallows were collected from 116 patients and a deep neural network was trained to produce a mask that demarcates the duration of upper esophageal sphincter opening. The proposed method achieved more than 90\% accuracy and similar values of sensitivity and specificity when compared to human ratings even when tested over swallows from an independent clinical experiment. Moreover, the predicted opening and closure moments surprisingly fell within an inter-human comparable error of their human rated counterparts which demonstrates the clinical significance of high resolution cervical auscultation in replacing ionizing radiation-based evaluation of swallowing kinematics.      
### 11.Multipath-Enhanced Device-Free Localization in Wideband Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.04531.pdf)
>  State-of-the-art device-free localization systems infer presence and location of users based on received signal strength measurements of line-of-sight links in wireless networks. In this letter, we propose to enhance device-free localization systems by exploiting multipath propagation between the individual network nodes. Particularly indoors, wireless propagation channels are characterized by multipath propagation, i.e., received signals comprise multipath components due to reflection and scattering. Given prior information about the surrounding environment, e.g., a floor plan, the individual propagation paths of multipath components can be derived geometrically. Inherently, these propagation paths differ spatially from the line-of-sight propagation path and can be considered as additional links in the wireless network. This extended network determines the novel multipath-enhanced device-free localization system. Using theoretical performance bounds on the localization error, we show that including multipath components into device-free localization systems improves the overall localization performance and extends the effective observation area significantly.      
### 12.Phase-aware music super-resolution using generative adversarial networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.04506.pdf)
>  Audio super-resolution is a challenging task of recovering the missing high-resolution features from a low-resolution signal. To address this, generative adversarial networks (GAN) have been used to achieve promising results by training the mappings between magnitudes of the low and high-frequency components. However, phase information is not well-considered for waveform reconstruction in conventional methods. In this paper, we tackle the problem of music super-resolution and conduct a thorough investigation on the importance of phase for this task. We use GAN to predict the magnitudes of the high-frequency components. The corresponding phase information can be extracted using either a GAN-based waveform synthesis system or a modified Griffin-Lim algorithm. Experimental results show that phase information plays an important role in the improvement of the reconstructed music quality. Moreover, our proposed method significantly outperforms other state-of-the-art methods in terms of objective evaluations.      
### 13.MIMO ILC for Precision SEA robots using Input-weighted Complex-Kernel Regression  [ :arrow_down: ](https://arxiv.org/pdf/2010.04487.pdf)
>  This work improves the positioning precision of lightweight robots with series elastic actuators (SEAs). Lightweight SEA robots, along with low-impedance control, can maneuver without causing damage in uncertain, confined spaces such as inside an aircraft wing during aircraft assembly. Nevertheless, substantial modeling uncertainties in SEA robots reduce the precision achieved by model-based approaches such as inversion-based feedforward. Therefore, this article improves the precision of SEA robots around specified operating points, through a multi-input multi-output (MIMO), iterative learning control (ILC) approach. The main contributions of this article are to (i) introduce an input-weighted complex kernel to estimate local MIMO models using complex Gaussian process regression (c-GPR) (ii) develop Geršgorin-theorem-based conditions on the iteration gains for ensuring ILC convergence to precision within noise-related limits, even with errors in the estimated model; and (iii) demonstrate precision positioning with an experimental SEA robot. Comparative experimental results, with and without ILC, show around 90% improvement in the positioning precision (close to the repeatability limit of the robot) and a 10-times increase in the SEA robot's operating speed with the use of the MIMO ILC.      
### 14.The NU Voice Conversion System for the Voice Conversion Challenge 2020: On the Effectiveness of Sequence-to-sequence Models and Autoregressive Neural Vocoders  [ :arrow_down: ](https://arxiv.org/pdf/2010.04446.pdf)
>  In this paper, we present the voice conversion (VC) systems developed at Nagoya University (NU) for the Voice Conversion Challenge 2020 (VCC2020). We aim to determine the effectiveness of two recent significant technologies in VC: sequence-to-sequence (seq2seq) models and autoregressive (AR) neural vocoders. Two respective systems were developed for the two tasks in the challenge: for task 1, we adopted the Voice Transformer Network, a Transformer-based seq2seq VC model, and extended it with synthetic parallel data to tackle nonparallel data; for task 2, we used the frame-based cyclic variational autoencoder (CycleVAE) to model the spectral features of a speech waveform and the AR WaveNet vocoder with additional fine-tuning. By comparing with the baseline systems, we confirmed that the seq2seq modeling can improve the conversion similarity and that the use of AR vocoders can improve the naturalness of the converted speech.      
### 15.Rethinking the Extraction and Interaction of Multi-Scale Features for Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.04428.pdf)
>  Analyzing the morphological attributes of blood vessels plays a critical role in the computer-aided diagnosis of many cardiovascular and ophthalmologic diseases. Although being extensively studied, segmentation of blood vessels, particularly thin vessels and capillaries, remains challenging mainly due to the lack of an effective interaction between local and global features. In this paper, we propose a novel deep learning model called PC-Net to segment retinal vessels and major arteries in 2D fundus image and 3D computed tomography angiography (CTA) scans, respectively. In PC-Net, the pyramid squeeze-and-excitation (PSE) module introduces spatial information to each convolutional block, boosting its ability to extract more effective multi-scale features, and the coarse-to-fine (CF) module replaces the conventional decoder to enhance the details of thin vessels and process hard-to-classify pixels again. We evaluated our PC-Net on the Digital Retinal Images for Vessel Extraction (DRIVE) database and an in-house 3D major artery (3MA) database against several recent methods. Our results not only demonstrate the effectiveness of the proposed PSE module and CF module, but also suggest that our proposed PC-Net sets new state of the art in the segmentation of retinal vessels (AUC: 98.31%) and major arteries (AUC: 98.35%) on both databases, respectively.      
### 16.WHO 2016 subtyping and automated segmentation of glioma using multi-task deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.04425.pdf)
>  Accurate characterization of glioma is crucial for clinical decision making. A delineation of the tumor is also desirable in the initial decision stages but is a time-consuming task. Leveraging the latest GPU capabilities, we developed a single multi-task convolutional neural network that uses the full 3D, structural, pre-operative MRI scans to can predict the IDH mutation status, the 1p/19q co-deletion status, and the grade of a tumor, while simultaneously segmenting the tumor. We trained our method using the largest, most diverse patient cohort to date containing 1508 glioma patients from 16 institutes. We tested our method on an independent dataset of 240 patients from 13 different institutes, and achieved an IDH-AUC of 0.90, 1p/19q-AUC of 0.85, grade-AUC of 0.81, and a mean whole tumor DICE score of 0.84. Thus, our method non-invasively predicts multiple, clinically relevant parameters and generalizes well to the broader clinical population.      
### 17.Convolutional Recurrent Residual U-Net Embedded with Attention Mechanism and Focal Tversky Loss Function for Cancerous Nuclei Detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.04416.pdf)
>  Since the beginning of this decade, CNN has been a very successful tool in the field of Computer Vision tasks.The invention of CNN was inspired from neuroscience and it shares a lot of anatomical similarities with our visual system.Inspired by the anatomyof humanvisual system, wearguethat the existing U-Net architecture can be improvedin many ways. As human visual system uses attention mechanism, we have used attention concatenation in place of normalconcatenation.Although, CNN is purely feed-forward in nature but anatomical evidences show that our brain contains recurrent synapses and they often outnumber feed-forward and top-down connections. Thisfact inspiresus to userecurrent convolution connectionsin place of normalconvolution blocksin U-Net.Thispaper also addressesthe class imbalance issuein the field of medical image analysis. The paperresolvestheproblem of class imbalanceswith the help of state-of-the-art loss functions.Weargue thatourproposed architecturecan be trained end to end with a few training data and it outperforms the other variantsof U-Net.      
### 18.Collision Prediction from UWB Range Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2010.04313.pdf)
>  The ability to predict, and thus react to, oncoming collisions among a set of mobile agents is a fundamental requirement for safe autonomous movement, both human and robotic. This paper addresses systems that use range measurements between mobile agents for the purpose of collision prediction, which involves prediction of the agents' future paths to know if they will collide at any time. One straightforward system would use known-location static anchors to estimate agent coordinates over time, and use the track to predict collision. Fundamentally, no fixed coordinate system is required for collision prediction, so using only the pairwise range between two agents can be used to predict collision. We present lower bound analysis which shows the limitations of this pairwise method. As an alternative anchor-free method, we propose the friend-based autonomous collision prediction and tracking (FACT) method that uses all measured ranges between nearby (unknown location mobile) agents, in a distributed algorithm, to estimate their relative locations and velocities and predict future collisions between agents. Using analysis and simulation, we show the potential for FACT to achieve equal or better collision detection performance compared to other methods, while avoiding the need for anchors. We then build a network of $N$ ultra wideband (UWB) devices and an efficient multi-node protocol which allows all ${\cal O}(N^2)$ pairwise ranges to be measured in $N$ slots. We run experiments with up to six independent robot agents moving and colliding in a 2D plane and up to four anchor nodes to compare the performance of the collision prediction methods. We show that the FACT method can perform better than either other method but without the need for a fixed infrastructure of anchor nodes.      
### 19.Band Assignment in Ultra-Narrowband (UNB) Systems for Massive IoT Access  [ :arrow_down: ](https://arxiv.org/pdf/2010.04307.pdf)
>  In this work, we consider a novel type of Internet of Things (IoT) ultra-narrowband (UNB) network architecture that involves multiple multiplexing bands or channels for uplink transmission. An IoT device can randomly choose any of the multiplexing bands and transmit its packet. Due to hardware constraints, a base station (BS) is able to listen to only one multiplexing band. The hardware constraint is mainly due to the complexity of performing fast Fourier transform (FFT) at a very small sampling interval over the multiplexing bands in order to counter the uncertainty of IoT device frequency and synchronize onto transmissions. The objective is to find an assignment of BSs to multiplexing bands in order to maximize the packet decoding probability (PDP). We develop a learning-based algorithm based on a sub-optimal solution to PDP maximization. The simulation results show that our approach to band assignment achieves near-optimal performance in terms of PDP, while at the same time, significantly exceeding the performance of random assignment. We also develop a heuristic algorithm with no learning overhead based on the locations of the BSs that also outperforms random assignment and serves as a performance reference to our learning-based algorithm.      
### 20.Randomized Overdrive Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.04237.pdf)
>  By processing audio signals in the time-domain with randomly weighted temporal convolutional networks (TCNs), we uncover a wide range of novel, yet controllable overdrive effects. We discover that architectural aspects, such as the depth of the network, the kernel size, the number of channels, the activation function, as well as the weight initialization, all have a clear impact on the sonic character of the resultant effect, without the need for training. In practice, these effects range from conventional overdrive and distortion, to more extreme effects, as the receptive field grows, similar to a fusion of distortion, equalization, delay, and reverb. To enable use by musicians and producers, we provide a real-time plugin implementation. This allows users to dynamically design networks, listening to the results in real-time. We provide a demonstration and code at <a class="link-external link-https" href="https://ronn.ml" rel="external noopener nofollow">this https URL</a>.      
### 21.All for One and One for All: Improving Music Separation by Bridging Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.04228.pdf)
>  This paper proposes two novel loss functions, a multi domain loss (MDL) and a combination loss (CL), for music source separation with deep neural networks (DNNs). In particular, by using MDL we take advantage of the frequency and time domain representation of audio signals and by using CL we consider the relationship among output source instruments, respectively. MDL and CL can easily be applied to many existing DNN-based methods since they are merely loss functions which are used during training and which do not affect the inference step. Experimental results show that the performance of Open-Unmix (UMX), which is a well-known and state-of-the-art open source library for music source separation, could be improved by utilizing our two new loss functions MDL and CL.      
### 22.Gender domain adaptation for automatic speech recognition task  [ :arrow_down: ](https://arxiv.org/pdf/2010.04224.pdf)
>  This paper is focused on the finetuning of acoustic models for speaker adap-tation based on a given gender. We pretrained the Transformer baseline model on Librispeech-960 and conduct experiments with finetuning on the gender-specific test subsets. Our approach leads to 5% lower word error rate on the male subset if the layers in the encoder and decoder are not frozen, but the tuning is started from the last checkpoints. Moreover, we adapted our general model on the full L2 Arctic dataset of accented speech and finetuned it for particular speakers and male and female genders separately. The models trained on the gender subsets obtained 1-2% higher accuracy when compared to the model tuned on the whole L2 Arctic dataset. Finally, we tested the concatenation of the pretrained x-vector voice embeddings and embeddings from conventional encoder, but its gain in accuracy is not significant.      
### 23.FastVC: Fast Voice Conversion with non-parallel data  [ :arrow_down: ](https://arxiv.org/pdf/2010.04185.pdf)
>  This paper introduces FastVC, an end-to-end model for fast Voice Conversion (VC). The proposed model can convert speech of arbitrary length from multiple source speakers to multiple target speakers. FastVC is based on a conditional AutoEncoder (AE) trained on non-parallel data and requires no annotations at all. This model's latent representation is shown to be speaker-independent and similar to phonemes, which is a desirable feature for VC systems. While the current VC systems primarily focus on achieving the highest overall speech quality, this paper tries to balance the development concerning resources needed to run the systems. Despite the simple structure of the proposed model, it outperforms the VC Challenge 2020 baselines on the cross-lingual task in terms of naturalness.      
### 24.Adaptive Robust Quadratic Programs using Control Lyapunov and Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2010.04699.pdf)
>  This paper presents adaptive robust quadratic program (QP) based control using control Lyapunov and barrier functions for nonlinear systems subject to time-varying and state-dependent uncertainties. An adaptive estimation law is proposed to estimate the pointwise value of the uncertainties with pre-computable estimation error bounds. The estimated uncertainty and the error bounds are then used to formulate a robust QP, which ensures that the actual uncertain system will not violate the safety constraints defined by the control barrier function. Additionally, the accuracy of the uncertainty estimation can be systematically improved by reducing the estimation sampling time, leading subsequently to reduced conservatism of the formulated robust QP. The proposed approach is validated in simulations on an adaptive cruise control problem and through comparisons with existing approaches.      
### 25.Quantifying the multi-objective cost of uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2010.04653.pdf)
>  Various real-world applications involve modeling complex systems with immense uncertainty and optimizing multiple objectives based on the uncertain model. Quantifying the impact of the model uncertainty on the given operational objectives is critical for designing optimal experiments that can most effectively reduce the uncertainty that affect the objectives pertinent to the application at hand. In this paper, we propose the concept of mean multi-objective cost of uncertainty (multi-objective MOCU) that can be used for objective-based quantification of uncertainty for complex uncertain systems considering multiple operational objectives. We provide several illustrative examples that demonstrate the concept and strengths of the proposed multi-objective MOCU.      
### 26.Hyperspectral Unmixing via Nonnegative Matrix Factorization with Handcrafted and Learnt Priors  [ :arrow_down: ](https://arxiv.org/pdf/2010.04611.pdf)
>  Nowadays, nonnegative matrix factorization (NMF) based methods have been widely applied to blind spectral unmixing. Introducing proper regularizers to NMF is crucial for mathematically constraining the solutions and physically exploiting spectral and spatial properties of images. Generally, properly handcrafting regularizers and solving the associated complex optimization problem are non-trivial tasks. In our work, we propose an NMF based unmixing framework which jointly uses a handcrafting regularizer and a learnt regularizer from data. we plug learnt priors of abundances where the associated subproblem can be addressed using various image denoisers, and we consider an l_2,1-norm regularizer to the abundance matrix to promote sparse unmixing results. The proposed framework is flexible and extendable. Both synthetic data and real airborne data are conducted to confirm the effectiveness of our method.      
### 27.Physics-Informed Gaussian Process Regression for Probabilistic States Estimation and Forecasting in Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2010.04591.pdf)
>  Real-time state estimation and forecasting is critical for efficient operation of power grids. In this paper, a physics-informed Gaussian process regression (PhI-GPR) method is presented and used for probabilistic forecasting and estimating the phase angle, angular speed, and wind mechanical power of a three-generator power grid system using sparse measurements. In standard data-driven Gaussian process regression (GPR), parameterized models for the prior statistics are fit by maximizing the marginal likelihood of observed data, whereas in PhI-GPR, we compute the prior statistics by solving stochastic equations governing power grid dynamics. The short-term forecast of a power grid system dominated by wind generation is complicated by the stochastic nature of the wind and the resulting uncertain mechanical wind power. Here, we assume that the power-grid dynamic is governed by the swing equations, and we treat the unknown terms in the swing equations (specifically, the mechanical wind power) as random processes, which turns these equations into stochastic differential equations. We solve these equations for the mean and variance of the power grid system using the Monte Carlo simulations method. We demonstrate that the proposed PhI-GPR method can accurately forecast and estimate both observed and unobserved states, including the mean behavior and associated uncertainty. For observed states, we show that PhI-GPR provides a forecast comparable to the standard data-driven GPR, with both forecasts being significantly more accurate than the autoregressive integrated moving average (ARIMA) forecast. We also show that the ARIMA forecast is much more sensitive to observation frequency and measurement errors than the PhI-GPR forecast.      
### 28.Dataset Augmentation and Dimensionality Reduction of Pinna-Related Transfer Functions  [ :arrow_down: ](https://arxiv.org/pdf/2010.04546.pdf)
>  Efficient modeling of the inter-individual variations of head-related transfer functions (HRTFs) is a key matterto the individualization of binaural synthesis. In previous work, we augmented a dataset of 119 pairs of earshapes and pinna-related transfer functions (PRTFs), thus creating a wide dataset of 1005 ear shapes and PRTFsgenerated by random ear drawings (WiDESPREaD) and acoustical simulations. In this article, we investigate thedimensionality reduction capacity of two principal component analysis (PCA) models of magnitude PRTFs, trainedon WiDESPREaD and on the original dataset, respectively. We find that the model trained on the WiDESPREaDdataset performs best, regardless of the number of retained principal components.      
### 29.Sickle-cell disease diagnosis support selecting the most appropriate machinelearning method: Towards a general and interpretable approach for cellmorphology analysis from microscopy images  [ :arrow_down: ](https://arxiv.org/pdf/2010.04511.pdf)
>  In this work we propose an approach to select the classification method and features, based on the state-of-the-art, with best performance for diagnostic support through peripheral blood smear images of red blood cells. In our case we used samples of patients with sickle-cell disease which can be generalized for other study cases. To trust the behavior of the proposed system, we also analyzed the interpretability. <br>We pre-processed and segmented microscopic images, to ensure high feature quality. We applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. Next, we searched for their best parameters from the resulting data in the feature extraction phase. Then, we found the best parameters for every classifier using Randomized and Grid search. <br>For the sake of scientific progress, we published parameters for each classifier, the implemented code library, the confusion matrices with the raw data, and we used the public erythrocytesIDB dataset for validation. We also defined how to select the most important features for classification to decrease the complexity and the training time, and for interpretability purpose in opaque models. Finally, comparing the best performing classification methods with the state-of-the-art, we obtained better results even with interpretable model classifiers.      
### 30.Baseline System of Voice Conversion Challenge 2020 with Cyclic Variational Autoencoder and Parallel WaveGAN  [ :arrow_down: ](https://arxiv.org/pdf/2010.04429.pdf)
>  In this paper, we present a description of the baseline system of Voice Conversion Challenge (VCC) 2020 with a cyclic variational autoencoder (CycleVAE) and Parallel WaveGAN (PWG), i.e., CycleVAEPWG. CycleVAE is a nonparallel VAE-based voice conversion that utilizes converted acoustic features to consider cyclically reconstructed spectra during optimization. On the other hand, PWG is a non-autoregressive neural vocoder that is based on a generative adversarial network for a high-quality and fast waveform generator. In practice, the CycleVAEPWG system can be straightforwardly developed with the VCC 2020 dataset using a unified model for both Task 1 (intralingual) and Task 2 (cross-lingual), where our open-source implementation is available at <a class="link-external link-https" href="https://github.com/bigpon/vcc20_baseline_cyclevae" rel="external noopener nofollow">this https URL</a>. The results of VCC 2020 have demonstrated that the CycleVAEPWG baseline achieves the following: 1) a mean opinion score (MOS) of 2.87 in naturalness and a speaker similarity percentage (Sim) of 75.37% for Task 1, and 2) a MOS of 2.56 and a Sim of 56.46% for Task 2, showing an approximately or nearly average score for naturalness and an above average score for speaker similarity.      
### 31.Once Quantized for All: Progressively Searching for Quantized Efficient Models  [ :arrow_down: ](https://arxiv.org/pdf/2010.04354.pdf)
>  Automatic search of Quantized Neural Networks has attracted a lot of attention. However, the existing quantization aware Neural Architecture Search (NAS) approaches inherit a two-stage search-retrain schema, which is not only time-consuming but also adversely affected by the unreliable ranking of architectures during the search. To avoid the undesirable effect of the search-retrain schema, we present Once Quantized for All (OQA), a novel framework that searches for quantized efficient models and deploys their quantized weights at the same time without additional post-process. While supporting a huge architecture search space, our OQA can produce a series of ultra-low bit-width(e.g. 4/3/2 bit) quantized efficient models. A progressive bit inheritance procedure is introduced to support ultra-low bit-width. Our discovered model family, OQANets, achieves a new state-of-the-art (SOTA) on quantized efficient models compared with various quantization methods and bit-widths. In particular, OQA2bit-L achieves 64.0% ImageNet Top-1 accuracy, outperforming its 2-bit counterpart EfficientNet-B0@QKD by a large margin of 14% using 30% less computation budget. Code is available at <a class="link-external link-https" href="https://github.com/LaVieEnRoseSMZ/OQA" rel="external noopener nofollow">this https URL</a>.      
### 32.HydroDeep -- A Knowledge Guided Deep Neural Network for Geo-Spatiotemporal Data Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2010.04328.pdf)
>  Floods are one of the major climate-related disasters, leading to substantial economic loss and social safety issue. However, the confidence in predicting changes in fluvial floods remains low due to limited evidence and complex causes of regional climate change. The recent development in machine learning techniques has the potential to improve traditional hydrological models by using monitoring data. Although Recurrent Neural Networks (RNN) perform remarkably with multivariate time series data, these models are blinded to the underlying mechanisms represented in a process-based model for flood prediction. While both process-based models and deep learning networks have their strength, understanding the fundamental mechanisms intrinsic to geo-spatiotemporal information is crucial to improve the prediction accuracy of flood occurrence. This paper demonstrates a neural network architecture (HydroDeep) that couples a process-based hydro-ecological model with a combination of Deep Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) Network to build a hybrid baseline model. HydroDeep outperforms the performance of both the independent networks by 4.8% and 31.8% respectively in Nash-Sutcliffe efficiency. A trained HydroDeep can transfer its knowledge and can learn the Geo-spatiotemporal features of any new region in minimal training iterations.      
### 33.Proactive Serverless Function Resource Management  [ :arrow_down: ](https://arxiv.org/pdf/2010.04312.pdf)
>  This paper introduces a new primitive to serverless language runtimes called freshen. With freshen, developers or providers specify functionality to perform before a given function executes. This proactive technique allows for overheads associated with serverless functions to be mitigated at execution time, which improves function responsiveness. We show various predictive opportunities exist to run freshen within reasonable time windows. A high-level design and implementation are described, along with preliminary results to show the potential benefits of our scheme.      
### 34.Performance Analysis of a Two-Tile Reconfigurable Intelligent Surface Assisted $2\times 2$ MIMO System  [ :arrow_down: ](https://arxiv.org/pdf/2010.04294.pdf)
>  We consider a two--tile reconfigurable intelligent surface (RIS) assisted wireless network with a two-antenna transmitter and receiver over Rayleigh fading. We show that the average received signal-to-noise-ratio (SNR) optimal transmission and combining vectors are given by the left and right singular spaces of the RIS-receiver and transmit-RIS channel matrices, respectively. Moreover, the optimal phases at the two tiles of the RIS are determined by the phases of the elements of the latter spaces. To further study the effect of phase compensation, we statistically characterize the average SNR of all possible combinations of transmission and combining directions pertaining to the latter singular spaces by deriving novel expressions for the outage probability and throughput of each of those modes. Furthermore, for comparison, we derive the corresponding expressions in the absence of RIS. Our results show an approximate SNR improvement of $2$\,dB due to the phase compensation at the RIS.      
### 35.Leveraging Unpaired Text Data for Training End-to-End Speech-to-Intent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.04284.pdf)
>  Training an end-to-end (E2E) neural network speech-to-intent (S2I) system that directly extracts intents from speech requires large amounts of intent-labeled speech data, which is time consuming and expensive to collect. Initializing the S2I model with an ASR model trained on copious speech data can alleviate data sparsity. In this paper, we attempt to leverage NLU text resources. We implemented a CTC-based S2I system that matches the performance of a state-of-the-art, traditional cascaded SLU system. We performed controlled experiments with varying amounts of speech and text training data. When only a tenth of the original data is available, intent classification accuracy degrades by 7.6% absolute. Assuming we have additional text-to-intent data (without speech) available, we investigated two techniques to improve the S2I system: (1) transfer learning, in which acoustic embeddings for intent classification are tied to fine-tuned BERT text embeddings; and (2) data augmentation, in which the text-to-intent data is converted into speech-to-intent data using a multi-speaker text-to-speech system. The proposed approaches recover 80% of performance lost due to using limited intent-labeled speech.      
### 36.interface : Electronic Chamber Ensemble  [ :arrow_down: ](https://arxiv.org/pdf/2010.04276.pdf)
>  This paper presents the interface developments and music of the duo "interface," formed by Curtis Bahn and Dan Trueman. We describe gestural instrument design, interactive performance interfaces for improvisational music, spherical speakers (multi-channel, outward-radiating geodesic speaker arrays) and Sensor-Speaker-Arrays (SenSAs: combinations of various sensor devices with spherical speaker arrays). We discuss the concept, design and construction of these systems, and, give examples from several newly published CDs of work by Bahn and Trueman.      
### 37.Synthetic MRI-aided Head-and-Neck Organs-at-Risk Auto-Delineation for CBCT-guided Adaptive Radiotherapy  [ :arrow_down: ](https://arxiv.org/pdf/2010.04275.pdf)
>  Purpose: Organ-at-risk (OAR) delineation is a key step for cone-beam CT (CBCT) based adaptive radiotherapy planning that can be a time-consuming, labor-intensive, and subject-to-variability process. We aim to develop a fully automated approach aided by synthetic MRI for rapid and accurate CBCT multi-organ contouring in head-and-neck (HN) cancer patients. MRI has superb soft-tissue contrasts, while CBCT offers bony-structure contrasts. Using the complementary information provided by MRI and CBCT is expected to enable accurate multi-organ segmentation in HN cancer patients. In our proposed method, MR images are firstly synthesized using a pre-trained cycle-consistent generative adversarial network given CBCT. The features of CBCT and synthetic MRI are then extracted using dual pyramid networks for final delineation of organs. CBCT images and their corresponding manual contours were used as pairs to train and test the proposed model. Quantitative metrics including Dice similarity coefficient (DSC) were used to evaluate the proposed method. The proposed method was evaluated on a cohort of 65 HN cancer patients. CBCT images were collected from those patients who received proton therapy. Overall, DSC values of 0.87, 0.79/0.79, 0.89/0.89, 0.90, 0.75/0.77, 0.86, 0.66, 0.78/0.77, 0.96, 0.89/0.89, 0.832, and 0.84 for commonly used OARs for treatment planning including brain stem, left/right cochlea, left/right eye, larynx, left/right lens, mandible, optic chiasm, left/right optic nerve, oral cavity, left/right parotid, pharynx, and spinal cord, respectively, were achieved. In this study, we developed a synthetic MRI-aided HN CBCT auto-segmentation method based on deep learning. It provides a rapid and accurate OAR auto-delineation approach, which can be used for adaptive radiation therapy.      
### 38.Fast Fourier Transformation for Optimizing Convolutional Neural Networks in Object Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.04257.pdf)
>  This paper proposes to use Fast Fourier Transformation-based U-Net (a refined fully convolutional networks) and perform image convolution in neural networks. Leveraging the Fast Fourier Transformation, it reduces the image convolution costs involved in the Convolutional Neural Networks (CNNs) and thus reduces the overall computational costs. The proposed model identifies the object information from the images. We apply the Fast Fourier transform algorithm on an image data set to obtain more accessible information about the image data, before segmenting them through the U-Net architecture. More specifically, we implement the FFT-based convolutional neural network to improve the training time of the network. The proposed approach was applied to publicly available Broad Bioimage Benchmark Collection (BBBC) dataset. Our model demonstrated improvement in training time during convolution from $600-700$ ms/step to $400-500$ ms/step. We evaluated the accuracy of our model using Intersection over Union (IoU) metric showing significant improvements.      
### 39.Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in Grape Leaves  [ :arrow_down: ](https://arxiv.org/pdf/2010.04225.pdf)
>  The large data size and dimensionality of hyperspectral data demands complex processing and data analysis. Multispectral data do not suffer the same limitations, but are normally restricted to blue, green, red, red edge, and near infrared bands. This study aimed to identify the optimal set of spectral bands for nitrogen detection in grape leaves using ensemble feature selection on hyperspectral data from over 3,000 leaves from 150 Flame Seedless table grapevines. Six machine learning base rankers were included in the ensemble: random forest, LASSO, SelectKBest, ReliefF, SVM-RFE, and chaotic crow search algorithm (CCSA). The pipeline identified less than 0.45% of the bands as most informative about grape nitrogen status. The selected violet, yellow-orange, and shortwave infrared bands lie outside of the typical blue, green, red, red edge, and near infrared bands of commercial multispectral cameras, so the potential improvement in remote sensing of nitrogen in grapevines brought forth by a customized multispectral sensor centered at the selected bands is promising and worth further investigation. The proposed pipeline may also be used for application-specific multispectral sensor design in domains other than agriculture.      

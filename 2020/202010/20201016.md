# ArXiv eess --Fri, 16 Oct 2020
### 1.Dataset artefacts in anti-spoofing systems: a case study on the ASVspoof 2017 benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2010.07913.pdf)
>  The Automatic Speaker Verification Spoofing and Countermeasures Challenges motivate research in protecting speech biometric systems against a variety of different access attacks. The 2017 edition focused on replay spoofing attacks, and involved participants building and training systems on a provided dataset (ASVspoof 2017). More than 60 research papers have so far been published with this dataset, but none have sought to answer why countermeasures appear successful in detecting spoofing attacks. This article shows how artefacts inherent to the dataset may be contributing to the apparent success of published systems. We first inspect the ASVspoof 2017 dataset and summarize various artefacts present in the dataset. Second, we demonstrate how countermeasure models can exploit these artefacts to appear successful in this dataset. Third, for reliable and robust performance estimates on this dataset we propose discarding nonspeech segments and silence before and after the speech utterance during training and inference. We create speech start and endpoint annotations in the dataset and demonstrate how using them helps countermeasure models become less vulnerable from being manipulated using artefacts found in the dataset. Finally, we provide several new benchmark results for both frame-level and utterance-level models that can serve as new baselines on this dataset.      
### 2.Network Topology Inference with Graphon Spectral Penalties  [ :arrow_down: ](https://arxiv.org/pdf/2010.07872.pdf)
>  We consider the problem of inferring the unobserved edges of a graph from data supported on its nodes. In line with existing approaches, we propose a convex program for recovering a graph Laplacian that is approximately diagonalizable by a set of eigenvectors obtained from the second-order moment of the observed data. Unlike existing work, we incorporate prior knowledge about the distribution from where the underlying graph was drawn. In particular, we consider the case where the graph was drawn from a graphon model, and we supplement our convex optimization problem with a provably-valid regularizer on the spectrum of the graph to be recovered. We present the cases where the graphon model is assumed to be known and the more practical setting where the relevant features of the model are inferred from auxiliary network observations. Numerical experiments on synthetic and real-world data illustrate the advantage of leveraging the proposed graphon prior, even when the prior is imperfect.      
### 3.Performance Analysis of Reconfigurable Intelligent Surfaces over Nakagami-m Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2010.07841.pdf)
>  This letter studies the performance of reconfigurable intelligent surface (RIS)-aided networks over Nakagami-m fading channels. First, we derive accurate closed-form approximations for the system channel distributions, and then, use them in deriving closed-form approximations for the outage probability, average symbol error probability (ASEP), and average channel capacity. In addition, to get more insights at the system performance, we derive asymptotic expression for the outage probability at high signal-to-noise ratio (SNR) regime, and provide closed-form expressions for the system diversity order and coding gain. Results show that the considered RIS scenario can provide a diversity order of (a+1)/2, where a is a function of the Nakagami-m fading parameter m and the number of reflecting elements N. Furthermore, results illustrate that m is more impactful on the diversity order and the system performance than N. Finally, the provided results are valid for arbitrary number of reflecting elements N and non-integer m.      
### 4.Multiscale Optimal Filtering on the Sphere  [ :arrow_down: ](https://arxiv.org/pdf/2010.07809.pdf)
>  We present a framework for the optimal filtering of spherical signals contaminated by realizations of zero-mean anisotropic noise processes. Filtering is performed in the wavelet domain given by the scale-discretized wavelet transform on the sphere. The proposed filter is optimal in the sense that it minimizes the mean square error between the filtered wavelet representation and wavelet representation of the noise-free signal. We also present a simplified formulation of the filter for the case when azimuthally symmetric wavelet functions are used. We demonstrate the use of the proposed optimal filter for denoising of an Earth topography map in the presence of uncorrelated, zero-mean, White Gaussian noise. The proposed filter is found to be superior to the hard thresholding method, particularly in the high noise regime.      
### 5.A Bayesian method for inference of effective connectivity in brain networks for detecting the Mozart effect  [ :arrow_down: ](https://arxiv.org/pdf/2010.07801.pdf)
>  Several studies claim that listening to Mozart music affects cognition and can be used to treat neurological conditions like epilepsy. Research into this Mozart effect has not addressed how dynamic interactions between brain networks, i.e. effective connectivity, are affected. The Granger-causality analysis is often used to infer effective connectivity. First, we investigate if a new method, Bayesian topology identification, can be used as an alternative. Both methods are evaluated on simulation data, where the Bayesian method outperforms the Granger-causality analysis in the inference of connectivity graphs of dynamic networks, especially for short data lengths. In the second part, the Bayesian method is extended to enable the inference of changes in effective connectivity between groups of subjects. Next, we apply both methods to fMRI scans of 16 healthy subjects, who were scanned before and after exposure to Mozart's sonata K448 at least 2 hours a day for 7 days. Here, we investigate if the effective connectivity of the subjects significantly changed after listening to Mozart music. The Bayesian method detected changes in effective connectivity between networks related to cognitive processing and control: First, in the connection from the central executive to the superior sensori-motor network. Second, in the connection from the posterior default mode to the fronto-parietal right network. Finally, in the connection from the anterior default mode to the dorsal attention network, but only in a subgroup of subjects with a longer listening duration. Only in this last connection an effect was found by the Granger-causality analysis.      
### 6.Muse: Multi-modal target speaker extraction with visual cues  [ :arrow_down: ](https://arxiv.org/pdf/2010.07775.pdf)
>  Speaker extraction algorithm relies on a reference speech to focus its attention on a target speaker. The reference speech is typically pre-registered as a speaker embedding. We believe that temporal synchronization between speech and lip movement is a useful cue, and target speaker embedding is also equally important. Motivated by this belief, we study a novel technique to use visual cues as the reference to extract target speaker embedding, without the need of pre-registered reference speech. We propose a multi-modal speaker extraction network, named MuSE, that is conditioned only on a lip image sequence for target speaker extraction. MuSE not only improves over AV-ConvTasnet baseline in terms of SI-SDR and PESQ, but also shows superior robustness in cross-domain evaluations.      
### 7.A simulation framework for particle magnetization dynamics of large ensembles of single domain particles: Numerical treatment of Brown/Néel dynamics and parameter identification problems in magnetic particle imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.07772.pdf)
>  Magnetic nanoparticles and their magnetization dynamics play an important role in many applications. We focus on magnetization dynamics in large ensembles of single domain nanoparticles being characterized by either Brownian or Néel rotation mechanisms. Simulations of the respective behavior are obtained by solving advection-diffusion equations on the sphere, for which a unified computational framework is developed and investigated. This builds the basis for solving two parameter identification problems, which are formulated in the context of the chosen application, magnetic particle imaging. The functionality of the computational framework is illustrated by numerical results in the parameter identification problems either compared quantitatively or qualitatively to measured data.      
### 8.The Benefit of Distraction: Denoising Remote Vitals Measurements using Inverse Attention  [ :arrow_down: ](https://arxiv.org/pdf/2010.07770.pdf)
>  Attention is a powerful concept in computer vision. End-to-end networks that learn to focus selectively on regions of an image or video often perform strongly. However, other image regions, while not necessarily containing the signal of interest, may contain useful context. We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations. We apply this to the task of camera-based physiological measurement. A convolutional attention network is used to learn which regions of a video contain the physiological signal and generate a preliminary estimate. A noise estimate is obtained by using the pixel intensities in the inverse regions of the learned attention mask, this in turn is used to refine the estimate of the physiological signal. We perform experiments on two large benchmark datasets and show that this approach produces state-of-the-art results, increasing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation error by as much as 30%, recovering subtle pulse waveform dynamics, and generalizing from RGB to NIR videos without retraining.      
### 9.A Patch-based Image Denoising Method Using Eigenvectors of the Geodesics' Gramian Matrix  [ :arrow_down: ](https://arxiv.org/pdf/2010.07769.pdf)
>  With the sophisticated modern technology in the camera industry, the demand for accurate and visually pleasing images is increasing. However, the quality of images captured by cameras are inevitably degraded by noise. Thus, some processing on images is required to filter out the noise without losing vital image features such as edges, corners, etc. Even though the current literature offers a variety of denoising methods, fidelity and efficiency of their denoising are sometimes uncertain. Thus, here we propose a novel and computationally efficient image denoising method that is capable of producing an accurate output. This method inputs patches partitioned from the image rather than pixels that are well known for preserving image smoothness. Then, it performs denoising on the manifold underlying the patch-space rather than that in the image domain to better preserve the features across the whole image. We validate the performance of this method against benchmark image processing methods.      
### 10.High resolution single shot phase shifting interference microscopy using deep neural network  [ :arrow_down: ](https://arxiv.org/pdf/2010.07768.pdf)
>  White light phase shifting interference (WL-PSI) microscopy is a prominent technique for high-resolution quantitative phase imaging (QPI) of industrial and biological specimens. Highly sensitive and accurate phase measurement is possible using WL-PSI because of low coherence properties of light source and the phase shifting algorithm. Multiple phase-shifted interferograms with accurate phase shift is obligatory in WL-PSI for measuring accurate phase map of the object. However, phase error occurs during the experimentation due to environmental perturbation and recording multiple frames. Here, we present a single-shot phase shifting interferometric technique for accurate phase measurement using filtered WL-PSI and deep neural network (DNN). The method is implemented by training the DNN to generate the phase shifted frames from a single recorded interferogram that are equivalent to experimentally recorded phase shifted interferograms. We simulate and experimentally demonstrate the robustness of the proposed framework on strip step-like waveguide structure. The results show precise matching of reconstructed phase map from the DNN generated phase shifted interferograms and experimentally recorded interferograms. The current WLPSI+DNN approach may further strengthen QPI techniques by high resolution phase recovery using single frame for different biomedical applications      
### 11.Short-term Wind Speed Forecasting based on LSSVM Optimized by Elitist QPSO  [ :arrow_down: ](https://arxiv.org/pdf/2010.07757.pdf)
>  Nowadays, wind power is considered as one of the most widely used renewable energy applications due to its efficient energy use and low pollution. In order to maintain high integration of wind power into the electricity market, efficient models for wind speed forecasting are in high demand. The non-stationary and nonlinear characteristics of wind speed, however, makes the task of wind speed forecasting challenging. LSSVM has proven to be a good forecasting algorithm mainly for time-series applications such as wind data. To boost the learning performance and generalization capability of the algorithm, LSSVM has two hyperparameters, known as the regularization and kernel parameters, that require careful tuning. In this paper, a modified QPSO algorithm is proposed that uses the principle of transposon operators to breed the personal best and global best particles of QPSO and improve global searching capabilities. The optimization algorithm is then used to generate optimum values for the LSSVM hyperparameters. Finally, the performance of the proposed model is compared with previously known PSO and QPSO optimized LSSVM models. Empirical results show that the proposed model displayed improved performance compared to the competitive methods.      
### 12.Real-Time Refocusing using an FPGA-based Standard Plenoptic Camera  [ :arrow_down: ](https://arxiv.org/pdf/2010.07746.pdf)
>  Plenoptic cameras are receiving increasing attention in scientific and commercial applications because they capture the entire structure of light in a scene, enabling optical transforms (such as focusing) to be applied computationally after the fact, rather than once and for all at the time a picture is taken. In many settings, real-time interactive performance is also desired, which in turn requires significant computational power due to the large amount of data required to represent a plenoptic image. Although GPUs have been shown to provide acceptable performance for real-time plenoptic rendering, their cost and power requirements make them prohibitive for embedded uses (such as in-camera). On the other hand, the computation to accomplish plenoptic rendering is well-structured, suggesting the use of specialized hardware. Accordingly, this paper presents an array of switch-driven Finite Impulse Response (FIR) filters, implemented with FPGA to accomplish high-throughput spatial-domain rendering. The proposed architecture provides a power-efficient rendering hardware design suitable for full-video applications as required in broadcasting or cinematography. A benchmark assessment of the proposed hardware implementation shows that real-time performance can readily be achieved, with a one order of magnitude performance improvement over a GPU implementation and three orders of magnitude performance improvement over a general-purpose CPU implementation.      
### 13.LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2010.07726.pdf)
>  Deep learning methods have shown considerable potential for hyperspectral image (HSI) classification, which can achieve high accuracy compared with traditional methods. However, they often need a large number of training samples and have a lot of parameters and high computational overhead. To solve these problems, this paper proposes a new network architecture, LiteDepthwiseNet, for HSI classification. Based on 3D depthwise convolution, LiteDepthwiseNet can decompose standard convolution into depthwise convolution and pointwise convolution, which can achieve high classification performance with minimal parameters. Moreover, we remove the ReLU layer and Batch Normalization layer in the original 3D depthwise convolution, which significantly improves the overfitting phenomenon of the model on small sized datasets. In addition, focal loss is used as the loss function to improve the model's attention on difficult samples and unbalanced data, and its training performance is significantly better than that of cross-entropy loss or balanced cross-entropy loss. Experiment results on three benchmark hyperspectral datasets show that LiteDepthwiseNet achieves state-of-the-art performance with a very small number of parameters and low computational cost.      
### 14.Combining Scatter Transform and Deep Neural Networks for Multilabel Electrocardiogram Signal Classification  [ :arrow_down: ](https://arxiv.org/pdf/2010.07639.pdf)
>  An essential part for the accurate classification of electrocardiogram (ECG) signals is the extraction of informative yet general features, which are able to discriminate diseases. Cardiovascular abnormalities manifest themselves in features on different time scales: small scale morphological features, such as missing P-waves, as well as rhythmical features apparent on heart rate scales. For this reason we incorporate a variant of the complex wavelet transform, called a scatter transform, in a deep residual neural network (ResNet). The former has the advantage of being derived from theory, making it well behaved under certain transformations of the input. The latter has proven useful in ECG classification, allowing feature extraction and classification to be learned in an end-to-end manner. Through the incorporation of trainable layers in between scatter transforms, the model gains the ability to combine information from different channels, yielding more informative features for the classification task and adapting them to the specific domain. For evaluation, we submitted our model in the official phase in the PhysioNet/Computing in Cardiology Challenge 2020. Our (Team Triage) approach achieved a challenge validation score of 0.640, and full test score of 0.485, placing us 4th out of 41 in the official ranking.      
### 15.Vehicular Networks for Combating a Worldwide Pandemic: Preventing the Spread of COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2010.07602.pdf)
>  As a worldwide pandemic, the coronavirus disease-19 (COVID-19) has caused serious restrictions in people's social life, along with the loss of lives, the collapse of economies and the disruption of humanitarian aids. Despite the advance of technological developments, we, as researchers, have witnessed that several issues need further investigation for a better response to a pandemic outbreak. With this motivation, researchers recently started developing ideas to stop or at least reduce the spread of the pandemic. While there have been some prior works on wireless networks for combating a pandemic scenario, vehicular networks and their potential bottlenecks have not yet been fully examined. This article provides an extensive discussion on vehicular networking for combating a pandemic. We provide the major applications of vehicular networking for combating COVID-19 in public transportation, in-vehicle diagnosis, border patrol and social distance monitoring. Next, we identify the unique characteristics of the collected data in terms of privacy, flexibility and coverage, then highlight corresponding future directions in privacy preservation, resource allocation, data caching and data routing. We believe that this work paves the way for the development of new products and algorithms that can facilitate the social life and help controlling the spread of the pandemic.      
### 16.Modeling electricity demand, welfare function and elasticity of electricity demand based on the customers risk aversion behavior  [ :arrow_down: ](https://arxiv.org/pdf/2010.07600.pdf)
>  Nowadays, attitudes towards electricity customers have been changed, so that they are no longer considered static players. The customers behavior identification is vital for establishing modern power systems. This paper utilizes the customers risk aversion coefficient to model their consumption behavior. Through the coefficients, the value of electricity consumption is measured employing the concept of the utility function. The utility function is an essential concept in microeconomics that measures customers preferences and interprets how a rational consumer would make consumption decisions. Based on the utility function, an economic load model and the customers welfare function are formulated. The load model is utilized to estimate price elasticity, and income elasticity of electricity demand. The results illustrated as the risk aversion coefficient increases, the consumers achieve more satisfaction from the consumption. Electricity consumption will be complement (substitute) if the risk aversion coefficient is greater (lower) than the unit. For the unit risk aversion coefficient, the cross-price elasticity will be zero, which means the consumption is independent of the other period demand. The results illustrated electricity price increment neutralizes the income increment effect on consumption. Hence, to study electricity consumption, the price and income variations should be considered, simultaneously.      
### 17.Lightweight End-to-End Speech Recognition from Raw Audio Data Using Sinc-Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2010.07597.pdf)
>  Many end-to-end Automatic Speech Recognition (ASR) systems still rely on pre-processed frequency-domain features that are handcrafted to emulate the human hearing. Our work is motivated by recent advances in integrated learnable feature extraction. For this, we propose Lightweight Sinc-Convolutions (LSC) that integrate Sinc-convolutions with depthwise convolutions as a low-parameter machine-learnable feature extraction for end-to-end ASR systems. <br>We integrated LSC into the hybrid CTC/attention architecture for evaluation. The resulting end-to-end model shows smooth convergence behaviour that is further improved by applying SpecAugment in time-domain. % data augmentation in the time-domain. We also discuss filter-level improvements, such as using log-compression as activation function. Our model achieves a word error rate of 10.7% on the TEDlium v2 test dataset, surpassing the corresponding architecture with log-mel filterbank features by an absolute 1.9%, but only has 21% of its model size.      
### 18.Investigating the Role of Renewable Energies in Integrated Energy-water Nexus Planning under Uncertainty Using Fuzzy Logic  [ :arrow_down: ](https://arxiv.org/pdf/2010.07588.pdf)
>  Energy and water systems are highly interconnected. Energy is required to extract, transmit, and treat water and wastewater, and water is needed for cooling energy systems. There is a rapid increase in demand for energy and water due to factors such as population and economic growth. In less than 30 years, the need for energy and water will nearly double globally. As the energy and water resources are limited, it is critical to have a sustainable energy-water nexus framework to meet these growing demands. Renewable energies provide substantial opportunities in energy-water nexuses by boosting energy and water reliability and sustainability and can be less water-intensive than conventional technologies. These resources, such as wind and solar power, do not need water inputs. As a result, they can be used as a supplement to the energy-water nexus portfolio. In this paper, renewable energies in energy-water nexus have been investigated for a range of possible scenarios. As renewable energy resources are not deterministic, fuzzy logic is used to model the uncertainty. The results show that renewable energies can significantly improve the energy-water nexus planning; however, the power grid reliability on renewable energy should be aligned with the level of systems uncertainty. The gap between the decisions extracted from the Fuzzy model and the deterministic model amplifies the importance of considering uncertainty to generate reliable decisions. Keywords: Energy-water Nexus, Renewable Energies, Optimization under Uncertainty, Fuzzy Logic.      
### 19.A Mathematical Approach to Improve Energy-Water Nexus Reliability Using a Novel Multi-Stage Adjustable Fuzzy Robust Approach  [ :arrow_down: ](https://arxiv.org/pdf/2010.07582.pdf)
>  A system of a systems approach that analyzes energy and water systems simultaneously is called energy-water nexus. Neglecting the interrelationship between energy and water drives vulnerabilities whereby limits on one resource can cause constraints on the other resource. Power plant energy production directly depends on water availability, and an outage of the power systems will affect the wastewater treatment facility processes. Therefore, it is essential to integrate energy and water planning models. As mathematical energy-water nexus problems are complex, involve many uncertain parameters, and are large-scale, we proposed a novel multi-stage adjustable Fuzzy robust approach that balances the solutions' robustness against the budget-constraints. Scenario-based analysis indicates that the proposed approach generates flexible and robust decisions that avoid excessive costs compared to conservative methods. Keywords: Energy-water Nexus, Renewable Energy, Optimization under Uncertainty, Fuzzy logic, Robust Optimization      
### 20.Encoder-decoder semantic segmentation models for electroluminescence images of thin-film photovoltaic modules  [ :arrow_down: ](https://arxiv.org/pdf/2010.07556.pdf)
>  We consider a series of image segmentation methods based on the deep neural networks in order to perform semantic segmentation of electroluminescence (EL) images of thin-film modules. We utilize the encoder-decoder deep neural network architecture. The framework is general such that it can easily be extended to other types of images (e.g. thermography) or solar cell technologies (e.g. crystalline silicon modules). The networks are trained and tested on a sample of images from a database with 6000 EL images of Copper Indium Gallium Diselenide (CIGS) thin film modules. We selected two types of features to extract, shunts and so called "droplets". The latter feature is often observed in the set of images. Several models are tested using various combinations of encoder-decoder layers, and a procedure is proposed to select the best model. We show exemplary results with the best selected model. Furthermore, we applied the best model to the full set of 6000 images and demonstrate that the automated segmentation of EL images can reveal many subtle features which cannot be inferred from studying a small sample of images. We believe these features can contribute to process optimization and quality control.      
### 21.Multi-Objective PMU Allocation for Resilient Power System Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2010.07540.pdf)
>  Phasor measurement units (PMUs) enable better system monitoring and security enhancement in smart grids. In order to enhance power system resilience against outages and blackouts caused by extreme weather events or man-made attacks, it remains a major challenge to determine the optimal number and location of PMUs. In this paper, a multi-objective resilient PMU placement (MORPP) problem is formulated, and solved by a modified Teaching-Learning-Based Optimization (MO-TLBO) algorithm. Three objectives are considered in the MORPP problem, minimizing the number of PMUs, maximizing the system observability, and minimizing the voltage stability index. The effectiveness of the proposed method is validated through testing on IEEE 14-bus, 30-bus, and 118-bus test systems. The advantage of the MO-TLBO-based MORPP is demonstrated through the comparison with other methods in the literature, in terms of iteration number, optimality and time of convergence.      
### 22.Optimal Dispatch in Emergency Service System via Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.07513.pdf)
>  In the United States, medical responses by fire departments over the last four decades increased by 367%. This had made it critical to decision makers in emergency response departments that existing resources are efficiently used. In this paper, we model the ambulance dispatch problem as an average-cost Markov decision process and present a policy iteration approach to find an optimal dispatch policy. We then propose an alternative formulation using post-decision states that is shown to be mathematically equivalent to the original model, but with a much smaller state space. We present a temporal difference learning approach to the dispatch problem based on the post-decision states. In our numerical experiments, we show that our obtained temporal-difference policy outperforms the benchmark myopic policy. Our findings suggest that emergency response departments can improve their performance with minimal to no cost.      
### 23.Determining minimum number of required accelerometer for output-only structural identification of frames  [ :arrow_down: ](https://arxiv.org/pdf/2010.07490.pdf)
>  Operational modal analysis (OMA) aims at identifying the modal properties of a structure based on response data of the structure excited by ambient sources. Modal parameters of the ambient vibration structures consist of natural frequencies, mode shapes, and modal damping ratios. In this paper, a typical frame with arbitrary loading has been modeled in finite element software, ANSYS, and the responses (accelerations of nodes) have been achieved. By using these data and the codes written in MATLAB, the modal parameters (natural frequencies, mode shapes) of the beams are identified with FDD (Frequency Domain Decomposition) and PP (Peak Picking) methods and then justified with the results of input-output method which was determined by modal analysis. The results indicate that there is a good agreement between three methods for determining the dynamic characteristics of frames. Then, the minimum number of required accelerometer has been determined that recording the acceleration in that location leads to identifying all the natural frequencies of the frame.      
### 24.CS2-Net: Deep Learning Segmentation of Curvilinear Structures in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.07486.pdf)
>  Automated detection of curvilinear structures, e.g., blood vessels or nerve fibres, from medical and biomedical images is a crucial early step in automatic image interpretation associated to the management of many diseases. Precise measurement of the morphological changes of these curvilinear organ structures informs clinicians for understanding the mechanism, diagnosis, and treatment of e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this work, we propose a generic and unified convolution neural network for the segmentation of curvilinear structures and illustrate in several 2D/3D medical imaging modalities. We introduce a new curvilinear structure segmentation network (CS2-Net), which includes a self-attention mechanism in the encoder and decoder to learn rich hierarchical representations of curvilinear structures. Two types of attention modules - spatial attention and channel attention - are utilized to enhance the inter-class discrimination and intra-class responsiveness, to further integrate local features with their global dependencies and normalization, adaptively. Furthermore, to facilitate the segmentation of curvilinear structures in medical images, we employ a 1x3 and a 3x1 convolutional kernel to capture boundary features. ...      
### 25.Minimizing Pumping Energy Cost in Real-time Operations of Water Distribution Systems using Economic Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.07477.pdf)
>  Optimizing pump operations is a challenging task for real-time management of water distribution systems (WDSs). With suitable pump scheduling, pumping costs can be significantly reduced. In this research, a novel economic model predictive control (EMPC) framework for real-time management of WDSs is proposed. Optimal pump operations are selected based on predicted system behavior even in receding time horizon with the aim to minimize the total pumping energy cost. Time-varying electricity tariffs are considered while all the required water demands are satisfied. The novelty of this framework is to choose the number of pumps to operate in each pump station as decision variables in order to optimize the total pumping energy costs. By using integer programming, the proposed EMPC is applied to a benchmark case study, the Richmond Pruned network. The simulation with an EPANET hydraulic simulator is implemented. Moreover, a comparison of the results obtained from using the proposed EMPC with those obtained from using trigger-level control demonstrates significant economic benefits of the proposed EMPC.      
### 26.Plant and Controller Optimization for Power and Energy Systems with Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.07415.pdf)
>  This article explores the optimization of plant characteristics and controller parameters for electrified mobility. Electrification of mobile transportation systems, such as automobiles and aircraft, presents the ability to improve key performance metrics such as efficiency and cost. However, the strong bidirectional coupling between electrical and thermal dynamics within new components creates integration challenges, increasing component degradation and reducing performance. Diminishing these issues requires novel plant designs and control strategies. The electrified mobility literature provides prior studies on plant and controller optimization, known as control co-design (CCD). A void within these studies is the lack of model predictive control (MPC), recognized to manage multi-domain dynamics for electrified systems, within CCD frameworks. This article addresses this through three contributions. First, a thermo-electro-mechanical hybrid electric vehicle (HEV) model is developed that is suitable for both plant optimization and MPC. Second, simultaneous plant and controller optimization is performed for this multi-domain system. Third, MPC is integrated within a CCD framework using the candidate HEV model. Results indicate that optimizing both the plant and MPC parameters simultaneously can reduce physical component sizes by over 60% and key performance metric errors by over 50%.      
### 27.Harnessing Uncertainty in Domain Adaptation for MRI Prostate Lesion Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.07411.pdf)
>  The need for training data can impede the adoption of novel imaging modalities for learning-based medical image analysis. Domain adaptation methods partially mitigate this problem by translating training data from a related source domain to a novel target domain, but typically assume that a one-to-one translation is possible. Our work addresses the challenge of adapting to a more informative target domain where multiple target samples can emerge from a single source sample. In particular we consider translating from mp-MRI to VERDICT, a richer MRI modality involving an optimized acquisition protocol for cancer characterization. We explicitly account for the inherent uncertainty of this mapping and exploit it to generate multiple outputs conditioned on a single input. Our results show that this allows us to extract systematically better image representations for the target domain, when used in tandem with both simple, CycleGAN-based baselines, as well as more powerful approaches that integrate discriminative segmentation losses and/or residual adapters. When compared to its deterministic counterparts, our approach yields substantial improvements across a broad range of dataset sizes, increasingly strong baselines, and evaluation measures.      
### 28.Reconfigurable Intelligent Surface: Design the Channel -- a New Opportunity for Future Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.07408.pdf)
>  In this paper, we survey state-of-the-art research outcomes in the burgeoning field of reconfigurable intelligent surface (RIS) in view of its potential for significant performance enhancement for next generation wireless communication networks by means of adapting the propagation environment. Emphasis has been placed on several aspects gating the commercially viability of a future network deployment. Comprehensive summaries are provided for practical hardware design considerations and broad implications of artificial intelligence techniques, so are in-depth outlooks on salient aspects of system models, use cases, and physical layer optimization techniques.      
### 29.Decomposing complicated signals with time-varying wave-shape functions and its biomedical application  [ :arrow_down: ](https://arxiv.org/pdf/2010.07394.pdf)
>  Modern time series are usually composed of multiple oscillatory components, with time-varying frequency and amplitude. The signal processing mission is further challenged if each component has oscillatory pattern far from a sinusoidal function. In biomedical field, the oscillatory pattern is even changing from time to time and contaminated by noise. In practice, if multiple components exist, it is desirable to robustly decompose the signal into each component for various purposes, and extract desired information. Such challenge have raised a significant amount of interest in the past decade, but a satisfactory solution is still lacking. We propose a novel nonlinear regression scheme to handle such challenge. In addition to simulated signals, we show its applicability to two physiological signals, impedance pneumography and photoplethysmogram, and examine how acutely the proposed decomposition scheme help extract physiological information. Comparisons with existing solutions, including linear regression, recursive diffeomorphism-based regression and multiresolution mode decomposition, supports the advantages for our proposal.      
### 30.Deep Learning in Ultrasound Elastography Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2010.07360.pdf)
>  It is known that changes in the mechanical properties of tissues are associated with the onset and progression of certain diseases. Ultrasound elastography is a technique to characterize tissue stiffness using ultrasound imaging either by measuring tissue strain using quasi-static elastography or natural organ pulsation elastography, or by tracing a propagated shear wave induced by a source or a natural vibration using dynamic elastography. In recent years, deep learning has begun to emerge in ultrasound elastography research. In this review, several common deep learning frameworks in the computer vision community, such as multilayer perceptron, convolutional neural network, and recurrent neural network are described. Then, recent advances in ultrasound elastography using such deep learning techniques are revisited in terms of algorithm development and clinical diagnosis. Finally, the current challenges and future developments of deep learning in ultrasound elastography are prospected.      
### 31.XPDNet for MRI Reconstruction: an Application to the fastMRI 2020 Brain Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2010.07290.pdf)
>  We present a modular cross-domain neural network the XPDNet and its application to the MRI reconstruction task. This approach consists in unrolling the PDHG algorithm as well as learning the acceleration scheme between steps. We also adopt state-of-the-art techniques specific to Deep Learning for MRI reconstruction. At the time of writing, this approach is the best performer in PSNR on the fastMRI leaderboards for both knee and brain at acceleration factor 4.      
### 32.Spatial Registration Evaluation of [18F]-MK6240 PET  [ :arrow_down: ](https://arxiv.org/pdf/2010.07897.pdf)
>  Image registration is an important preprocessing step in neuroimaging which allows for the matching of anatomical and functional information between modalities and subjects. This can be challenging if there are gross differences in image geometry or in signal intensity, such as in the case of some molecular PET radioligands, where control subjects display relative lack of signal relative to noise within intracranial regions, and may have off target binding that may be confused as other regions, and may vary depending on subject. The use of intermediary images or volumes have been shown to aide registration in such cases. <br>To account for this phenomena within our own longitudinal aging cohort, we generated a population specific MRI and PET template from a broad distribution of 30 amyloid negative subjects. We then registered the PET image of each of these subjects, as well as a holdout set of thirty 'template-naive' subjects to their corresponding MRI images using the template image as an intermediate using three different sets of registration parameters and procedures. To evaluate the performance of both conventional registration and our method, we compared these to the registration of the attenuation CT (acquired at time of PET acquisition) to MRI as the reference. We then used our template to directly derive SUVR values without the use of MRI. <br>We found that conventional registration was comparable to an existing CT based standard, and there was no significant difference in errors collectively amongst all methods tested. In addition, there were no significant differences between existing and MR-less tau PET quantification methods. We conclude that a template-based method is a feasible alternative to, or salvage for, direct registration and MR-less quantification; and, may be preferred in cases where there is doubt about the similarity between two image modalities.      
### 33.Deep Convolutional Neural Network-based Inverse Filtering Approach for Speech De-reverberation  [ :arrow_down: ](https://arxiv.org/pdf/2010.07895.pdf)
>  In this paper, we introduce a spectral-domain inverse filtering approach for single-channel speech de-reverberation using deep convolutional neural network (CNN). The main goal is to better handle realistic reverberant conditions where the room impulse response (RIR) filter is longer than the short-time Fourier transform (STFT) analysis window. To this end, we consider the convolutive transfer function (CTF) model for the reverberant speech signal. In the proposed framework, the CNN architecture is trained to directly estimate the inverse filter of the CTF model. Among various choices for the CNN structure, we consider the U-net which consists of a fully-convolutional auto-encoder network with skip-connections. Experimental results show that the proposed method provides better de-reverberation performance than the prevalent benchmark algorithms under various reverberation conditions.      
### 34.Combining Spectral CT Acquisition Methods for High-Sensitivity Material Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2010.07829.pdf)
>  Quantitative estimation of contrast agent concentration is made possible by spectral CT and material decomposition. There are several approaches to modulate the sensitivity of the imaging system to obtain the different spectral channels required for decomposition. Spectral CT technologies that enable this varied sensitivity include source kV-switching, dual-layer detectors, and source-side filtering (e.g., tiled spatial-spectral filters). In this work, we use an advanced physical model to simulate these three spectral CT strategies as well as hybrid acquisitions using all combinations of two or three strategies. We apply model-based material decomposition to a water-iodine phantom with iodine concentrations from 0.1 to 5.0 mg/mL. We present bias-noise plots for the different combinations of spectral techniques and show that combined approaches permit diversity in spectral sensitivity and improve low concentration imaging performance relative to the those strategies applied individually. Better ability to estimate low concentrations of contrast agent has the potential to reduce risks associated with contrast administration (by lowering dosage) or to extend imaging applications into targets with much lower uptake.      
### 35.Optimized Spatial-Spectral CT for Multi-Material Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2010.07823.pdf)
>  Spectral CT is an emerging modality that uses a data acquisition scheme with varied spectral responses to provide enhanced material discrimination in addition to the structural information of conventional CT. Existing clinical and preclinical designs with this capability include kV-switching, split-filtration, and dual-layer detector systems to provide two spectral channels of projection data. In this work, we examine an alternate design based on a spatial-spectral filter. This source-side filter is made up a linear array of materials that divide the incident x-ray beam into spectrally varied beamlets. This design allows for any number of spectral channels; however, each individual channel is sparse in the projection domain. Model-based iterative reconstruction methods can accommodate such sparse spatial-spectral sampling patterns and allow for the incorporation of advanced regularization. With the goal of an optimized physical design, we characterize the effects of design parameters including filter tile order and filter tile width and their impact on material decomposition performance. We present results of numerical simulations that characterize the impact of each design parameter using a realistic CT geometry and noise model to demonstrate feasibility. Results for filter tile order show little change indicating that filter order is a low-priority design consideration. We observe improved performance for narrower filter widths; however, the performance drop-off is relatively flat indicating that wider filter widths are also feasible designs.      
### 36.A Transformer Based Pitch Sequence Autoencoder with MIDI Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2010.07758.pdf)
>  Algorithms based on deep learning have been widely put forward for automatic music generated. However, few objective approaches have been proposed to assess whether a melody was created by automatons or Homo sapiens. Conference of Sound and Music Technology (2020) provides us a great opportunity to cope with the problem. In this paper, a masked language model based on ALBERT trained with AI-composed single-track MIDI is demonstrated for composers classification tasks. Besides, music tune transposition and MIDI sequence truncation is applied for data augments. To prevent from over-fitting, a refined loss function is proposed and the amount of parameters is reduced. This work provides a new approach to tackle the problem on obtaining features from tiny dataset which is common in music signal analysis and deserve more attention.      
### 37.Music Classification in MIDI Format based on LSTM Mdel  [ :arrow_down: ](https://arxiv.org/pdf/2010.07739.pdf)
>  Music classification between music made by AI or human composers can be done by deep learning networks. We first transformed music samples in midi format to natural language sequences, then classified these samples by mLSTM (multiplicative Long Short Term Memory) + logistic regression. The accuracy of the result evaluated by 10-fold cross validation can reach 90%. Our work indicates that music generated by AI and human composers do have different characteristics, which can be learned by deep learning networks.      
### 38.The NeteaseGames System for Voice Conversion Challenge 2020 with Vector-quantization Variational Autoencoder and WaveNet  [ :arrow_down: ](https://arxiv.org/pdf/2010.07630.pdf)
>  This paper presents the description of our submitted system for Voice Conversion Challenge (VCC) 2020 with vector-quantization variational autoencoder (VQ-VAE) with WaveNet as the decoder, i.e., VQ-VAE-WaveNet. VQ-VAE-WaveNet is a nonparallel VAE-based voice conversion that reconstructs the acoustic features along with separating the linguistic information with speaker identity. The model is further improved with the WaveNet cycle as the decoder to generate the high-quality speech waveform, since WaveNet, as an autoregressive neural vocoder, has achieved the SoTA result of waveform generation. In practice, our system can be developed with VCC 2020 dataset for both Task 1 (intra-lingual) and Task 2 (cross-lingual). However, we only submit our system for the intra-lingual voice conversion task. The results of VCC 2020 demonstrate that our system VQ-VAE-WaveNet achieves: 3.04 mean opinion score (MOS) in naturalness and a 3.28 average score in similarity ( the speaker similarity percentage (Sim) of 75.99%) for Task 1. The subjective evaluations also reveal that our system gives top performance when no supervised learning is involved. What's more, our system performs well in some objective evaluations. Specifically, our system achieves an average score of 3.95 in naturalness in automatic naturalness prediction and ranked the 6th and 8th, respectively in ASV-based speaker similarity and spoofing countermeasures.      
### 39.Design Ontology Supporting Model-based Systems-engineering Formalisms  [ :arrow_down: ](https://arxiv.org/pdf/2010.07627.pdf)
>  Model-based systems engineering (MBSE) provides an important capability for managing the complexities of system development. MBSE empowers the formalisms of system architectures for supporting model-based requirement elicitation, specification, design, development, testing, fielding, etc. However, the modeling languages and techniques are quite heterogeneous, even within the same enterprise system, which creates difficulties for data interoperability. The discrepancies among data structures and language syntaxes make information exchange among MBSE models even more difficult, resulting in considerable information deviations when connecting data flows across the enterprise. For this reason, this paper presents an ontology based upon graphs, objects, points, properties, roles, and relationships with entensions (GOPPRRE), providing meta models that support the various lifecycle stages of MBSE formalisms. In particular, knowledge-graph models are developed to support unified model representations to further implement ontological data integration based on GOPPRRE throughout the entire lifecycle. The applicability of the MBSE formalism is verified using quantitative and qualitative approaches. Moreover, the GOPPRRE ontologies are generated from the MBSE language formalisms in a domain-specific modeling tool, \textit{MetaGraph} in order to evaluate its availiablity. The results demonstrate that the proposed ontology supports both formal structures and the descriptive logic of the systems engineering lifecycle.      
### 40.Interactive Latent Interpolation on MNIST Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2010.07581.pdf)
>  This paper will discuss the potential of dimensionality reduction with a web-based use of GANs. Throughout a variety of experiments, we show synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with latent vectors. GANs have proved to be a remarkable technique to produce computer-generated images, very similar to an original image. This is primarily useful when coupled with dimensionality reduction as an effective application of our algorithm. We proposed a new architecture for GANs, which ended up not working for mathematical reasons later explained. We then proposed a new web-based GAN that still takes advantage of dimensionality reduction to speed generation in the browser to .2 milliseconds. Lastly, we made a modern UI with linear interpolation to present the work. With the speedy generation, we can generate so fast that we can create an animation type effect that we have never seen before that works on both web and mobile.      
### 41.A Robust Deep Unfolded Network for Sparse Signal Recovery from Noisy Binary Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2010.07564.pdf)
>  We propose a novel deep neural network, coined DeepFPC-$\ell_2$, for solving the 1-bit compressed sensing problem. The network is designed by unfolding the iterations of the fixed-point continuation (FPC) algorithm with one-sided $\ell_2$-norm (FPC-$\ell_2$). The DeepFPC-$\ell_2$ method shows higher signal reconstruction accuracy and convergence speed than the traditional FPC-$\ell_2$ algorithm. Furthermore, we compare its robustness to noise with the previously proposed DeepFPC network---which stemmed from unfolding the FPC-$\ell_1$ algorithm---for different signal to noise ratio (SNR) and sign-flipped ratio (flip ratio) scenarios. We show that the proposed network has better noise immunity than the previous DeepFPC method. This result indicates that the robustness of a deep-unfolded neural network is related with that of the algorithm it stems from.      
### 42.Melody Classification based on Performance Event Vector and BRNN  [ :arrow_down: ](https://arxiv.org/pdf/2010.07562.pdf)
>  We proposed a model for the CSMT2020 data challenge of melody classification. Our model used the Performance Event Vector as the input sequence to build a Bidirectional RNN network for classfication. The model achieved a satisfying performance on the development dataset and Wikifonia dataset. We also discussed the effect of several hyper-parameters, and created multiple prediction outputs for the evaluation dataset.      
### 43.Deep Learning of Koopman Representation for Control  [ :arrow_down: ](https://arxiv.org/pdf/2010.07546.pdf)
>  We develop a data-driven, model-free approach for the optimal control of the dynamical system. The proposed approach relies on the Deep Neural Network (DNN) based learning of Koopman operator for the purpose of control. In particular, DNN is employed for the data-driven identification of basis function used in the linear lifting of nonlinear control system dynamics. The controller synthesis is purely data-driven and does not rely on a priori domain knowledge. The OpenAI Gym environment, employed for Reinforcement Learning-based control design, is used for data generation and learning of Koopman operator in control setting. The method is applied to two classic dynamical systems on OpenAI Gym environment to demonstrate the capability.      
### 44.Adversarial Images through Stega Glasses  [ :arrow_down: ](https://arxiv.org/pdf/2010.07542.pdf)
>  This paper explores the connection between steganography and adversarial images. On the one hand, ste-ganalysis helps in detecting adversarial perturbations. On the other hand, steganography helps in forging adversarial perturbations that are not only invisible to the human eye but also statistically undetectable. This work explains how to use these information hiding tools for attacking or defending computer vision image classification. We play this cat and mouse game with state-of-art classifiers, steganalyzers, and steganographic embedding schemes. It turns out that steganography helps more the attacker than the defender.      
### 45.Automatic Analysis and Influence of Hierarchical Structure on Melody, Rhythm and Harmony in Popular Music  [ :arrow_down: ](https://arxiv.org/pdf/2010.07518.pdf)
>  Repetition is a basic indicator of musical structure. This study introduces new algorithms for identifying musical phrases based on repetition. Phrases combine to form sections yielding a two-level hierarchical structure. Automatically detected hierarchical repetition structures reveal significant interactions between structure and chord progressions, melody and rhythm. Different levels of hierarchy interact differently, providing evidence that structural hierarchy plays an important role in music beyond simple notions of repetition or similarity. Our work suggests new applications for music generation and music evaluation.      
### 46.RetiNerveNet: Using Recursive Deep Learning to Estimate Pointwise 24-2 Visual Field Data based on Retinal Structure  [ :arrow_down: ](https://arxiv.org/pdf/2010.07488.pdf)
>  Glaucoma is the leading cause of irreversible blindness in the world, affecting over 70 million people. The cumbersome Standard Automated Perimetry (SAP) test is most frequently used to detect visual loss due to glaucoma. Due to the SAP test's innate difficulty and its high test-retest variability, we propose the RetiNerveNet, a deep convolutional recursive neural network for obtaining estimates of the SAP visual field. RetiNerveNet uses information from the more objective Spectral-Domain Optical Coherence Tomography (SDOCT). RetiNerveNet attempts to trace-back the arcuate convergence of the retinal nerve fibers, starting from the Retinal Nerve Fiber Layer (RNFL) thickness around the optic disc, to estimate individual age-corrected 24-2 SAP values. Recursive passes through the proposed network sequentially yield estimates of the visual locations progressively farther from the optic disc. The proposed network is able to obtain more accurate estimates of the individual visual field values, compared to a number of baselines, implying its utility as a proxy for SAP. We further augment RetiNerveNet to additionally predict the SAP Mean Deviation values and also create an ensemble of RetiNerveNets that further improves the performance, by increasingly weighting-up underrepresented parts of the training data.      
### 47.Design of Spatial-Spectral Filters for CT Material Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2010.07483.pdf)
>  Spectral CT has shown promise for high-sensitivity quantitative imaging and material decomposition. This work presents a new device called a spatial-spectral filter (SSF) which consists of a tiled array of filter materials positioned near the x-ray source that is used to modulate the spectral shape of the x-ray beam. The filter is moved to obtain projection data that is sparse in each spectral channel. To process this sparse data, we employ a direct model-based material decomposition (MBMD)to reconstruct basis material density images directly from the SSF CT data. To evaluate different possible SSF designs, we define a new Fisher-information-based predictive image quality metric called separability index which characterizes the ability of a spectral CT system to distinguish between the signals from two or more materials. This predictive metric is used to define a system design optimization framework. We have applied this framework to find optimized combinations of filter materials, filter tile widths, and source settings for SSF CT. We conducted simulation-based design optimization study and separability-optimized filter designs are presented for water/iodine imaging and water/iodine/gadolinium/gold imaging for different patient sizes. Finally, we present MBMD results using simulated SSFCT data using the optimized designs to demonstrate the ability to reconstruct basis material density images and to show the benefits of the optimized designs.      
### 48.Locomotion Design for an Internally Actuated Cubic Robot for Exploration of Low Gravity Bodies in the Solar System  [ :arrow_down: ](https://arxiv.org/pdf/2010.07476.pdf)
>  The exploration of asteroids and comets is important in the quest for the formation of the Solar System and it is an important step for human space travel. Moving on the surface of asteroids is challenging for future robotic explorers due to the weak gravity force. In this research, an approach that is based on a new kind of jumping rovers is presented. This robotic platform has internal masses and by spinning up these flywheels and suddenly stopping them, it is feasible to perform a hop from a few meters up to hundreds of meters. In contrast to related works where robotic explorers usually stop a flywheel instantaneously, the INAHOPPER prototype takes advantage of on stopping a flywheel by voltage inversion in a short lapse to modify the launch angle, a very useful action over terrains with different degrees of inclination. This article discusses, first, the dynamics of the rover for a 2D model, second, the control algorithm executed in the prototype for braking the flywheel, and third, the analysis of the performance of the flywheel to make simulations of the trajectories over an asteroid.      
### 49.Promise and Challenges of a Data-Driven Approach for Battery Lifetime Prognostics  [ :arrow_down: ](https://arxiv.org/pdf/2010.07460.pdf)
>  Recent data-driven approaches have shown great potential in early prediction of battery cycle life by utilizing features from the discharge voltage curve. However, these studies caution that data-driven approaches must be combined with specific design of experiments in order to limit the range of aging conditions, since the expected life of Li-ion batteries is a complex function of various aging factors. In this work, we investigate the performance of the data-driven approach for battery lifetime prognostics with Li-ion batteries cycled under a variety of aging conditions, in order to determine when the data-driven approach can successfully be applied. Results show a correlation between the variance of the discharge capacity difference and the end-of-life for cells aged under a wide range of charge/discharge C-rates and operating temperatures. This holds despite the different conditions being used not only to cycle the batteries but also to obtain the features: the features are calculated directly from cycling data without separate slow characterization cycles at a controlled temperature. However, the correlation weakens considerably when the voltage data window for feature extraction is reduced, or when features from the charge voltage curve instead of discharge are used. As deep constant-current discharges rarely happen in practice, this imposes new challenges for applying this method in a real-world system.      
### 50.AI-based BMI Inference from Facial Images: An Application to Weight Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2010.07442.pdf)
>  Self-diagnostic image-based methods for healthy weight monitoring is gaining increased interest following the alarming trend of obesity. Only a handful of academic studies exist that investigate AI-based methods for Body Mass Index (BMI) inference from facial images as a solution to healthy weight monitoring and management. To promote further research and development in this area, we evaluate and compare the performance of five different deep-learning based Convolutional Neural Network (CNN) architectures i.e., VGG19, ResNet50, DenseNet, MobileNet, and lightCNN for BMI inference from facial images. Experimental results on the three publicly available BMI annotated facial image datasets assembled from social media, namely, VisualBMI, VIP-Attributes, and Bollywood datasets, suggest the efficacy of the deep learning methods in BMI inference from face images with minimum Mean Absolute Error (MAE) of $1.04$ obtained using ResNet50.      
### 51.A Model-Based Approach to Security Analysis for Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/1710.11442.pdf)
>  Evaluating the security of cyber-physical systems throughout their life cycle is necessary to assure that they can be deployed and operated in safety-critical applications, such as infrastructure, military, and transportation. Most safety and security decisions that can have major effects on mitigation strategy options after deployment are made early in the system's life cycle. To allow for a vulnerability analysis before deployment, a sufficient well-formed model has to be constructed. To construct such a model we produce a taxonomy of attributes; that is, a generalized schema for system attributes. This schema captures the necessary specificity that characterizes a possible real system and can also map to the attack vector space associated with the model's attributes. In this way, we can match possible attack vectors and provide architectural mitigation at the design phase. We present a model of a flight control system encoded in the Systems Modeling Language, commonly known as SysML, but also show agnosticism with respect to the modeling language or tool used.      
### 52.Online Simultaneous State and Parameter Estimation  [ :arrow_down: ](https://arxiv.org/pdf/1703.07068.pdf)
>  In this paper, a concurrent learning based adaptive observer is developed for a class of second-order nonlinear time-invariant systems with uncertain dynamics. The developed technique results in uniformly ultimately bounded state and parameter estimation errors. As opposed to persistent excitation which is required for parameter convergence in traditional adaptive control methods, the developed technique only requires excitation over a finite time interval to achieve parameter convergence. Simulation results in both noise-free and noisy environments are presented to validate the design.      

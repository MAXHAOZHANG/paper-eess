# ArXiv eess --Thu, 29 Oct 2020
### 1.Forgery Blind Inspection for Detecting Manipulations of Gel Electrophoresis Images  [ :arrow_down: ](https://arxiv.org/pdf/2010.15086.pdf)
>  Recently, falsified images have been found in papers involved in research misconducts. However, although there have been many image forgery detection methods, none of them was designed for molecular-biological experiment images. In this paper, we proposed a fast blind inquiry method, named FBI$_{GEL}$, for integrity of images obtained from two common sorts of molecular experiments, i.e., western blot (WB) and polymerase chain reaction (PCR). Based on an optimized pseudo-background capable of highlighting local residues, FBI$_{GEL}$ can reveal traceable vestiges suggesting inappropriate local modifications on WB/PCR images. Additionally, because the optimized pseudo-background is derived according to a closed-form solution, FBI$_{GEL}$ is computationally efficient and thus suitable for large scale inquiry tasks for WB/PCR image integrity. We applied FBI$_{GEL}$ on several papers questioned by the public on \textbf{PUBPEER}, and our results show that figures of those papers indeed contain doubtful unnatural patterns.      
### 2.Speech Synthesis and Control Using Differentiable DSP  [ :arrow_down: ](https://arxiv.org/pdf/2010.15084.pdf)
>  Modern text-to-speech systems are able to produce natural and high-quality speech, but speech contains factors of variation (e.g. pitch, rhythm, loudness, timbre)\ that text alone cannot contain. In this work we move towards a speech synthesis system that can produce diverse speech renditions of a text by allowing (but not requiring) explicit control over the various factors of variation. We propose a new neural vocoder that offers control of such factors of variation. This is achieved by employing differentiable digital signal processing (DDSP) (previously used only for music rather than speech), which exposes these factors of variation. The results show that the proposed approach can produce natural speech with realistic timbre, and individual factors of variation can be freely controlled.      
### 3.OTFS Channel Estimation And Data Detection Designs With Superimposed Pilots  [ :arrow_down: ](https://arxiv.org/pdf/2010.15066.pdf)
>  This work proposes a superimposed pilot (SP)-based channel estimation and data detection framework for orthogonal time-frequency space (OTFS) scheme, wherein low-powered pilots are superimposed on to data symbols in the delay-Doppler domain. We propose two channel estimation and data detection designs for SP-OTFS systems which, unlike the existing OTFS designs, do not designate any slots for pilots, which improves their spectral efficiency (SE). The first SP design estimates channel by treating data as interference, which degrades its performance at high signal to noise ratio. The second SP design alleviates this problem by iterating between channel estimation and data detection. Both these designs detect data using message passing algorithm which exploits OTFS channel sparsity, and consequently has low computational complexity. We also derive a lower bound on the signal-to-interference-plus-noise ratio of the proposed designs, and maximize it by optimally allocating power between data and pilot symbols. We numerically validate the derived analytical results, and show that the proposed designs have superior SE than the two state-of-the-art OTFS channel estimation and data detection designs.      
### 4.Optimizing Short-Time Fourier Transform Parameters via Gradient Descent  [ :arrow_down: ](https://arxiv.org/pdf/2010.15049.pdf)
>  The Short-Time Fourier Transform (STFT) has been a staple of signal processing, often being the first step for many audio tasks. A very familiar process when using the STFT is the search for the best STFT parameters, as they often have significant side effects if chosen poorly. These parameters are often defined in terms of an integer number of samples, which makes their optimization non-trivial. In this paper we show an approach that allows us to obtain a gradient for STFT parameters with respect to arbitrary cost functions, and thus enable the ability to employ gradient descent optimization of quantities like the STFT window length, or the STFT hop size. We do so for parameter values that stay constant throughout an input, but also for cases where these parameters have to dynamically change over time to accommodate varying signal characteristics.      
### 5.Frequency-Undersampled Short-Time Fourier Transform  [ :arrow_down: ](https://arxiv.org/pdf/2010.15029.pdf)
>  The short-time Fourier transform (STFT) usually computes the same number of frequency components as the frame length while overlapping adjacent time frames by more than half. As a result, the number of components of a spectrogram matrix becomes more than twice the signal length, and hence STFT is hardly used for signal compression. In addition, even if we modify the spectrogram into a desired one by spectrogram-based signal processing, it is re-changed during the inversion as long as it is outside the range of STFT. In this paper, to reduce the number of components of a spectrogram while maintaining the analytical ability, we propose the frequency-undersampled STFT (FUSTFT), which computes only half the frequency components. We also present the inversions with and without the periodic condition, including their different properties. In simple numerical examples of audio signals, we confirm the validity of FUSTFT and the inversions.      
### 6.Replay and Synthetic Speech Detection with Res2net Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2010.15006.pdf)
>  Existing approaches for replay and synthetic speech detection still lack generalizability to unseen spoofing attacks. This work proposes to leverage a novel model structure, so-called Res2Net, to improve the anti-spoofing countermeasure's generalizability. Res2Net mainly modifies the ResNet block to enable multiple feature scales. Specifically, it splits the feature maps within one block into multiple channel groups and designs a residual-like connection across different channel groups. Such connection increases the possible receptive fields, resulting in multiple feature scales. This multiple scaling mechanism significantly improves the countermeasure's generalizability to unseen spoofing attacks. It also decreases the model size compared to ResNet-based models. Experimental results show that the Res2Net model consistently outperforms ResNet34 and ResNet50 by a large margin in both physical access (PA) and logical access (LA) of the ASVspoof 2019 corpus. Moreover, integration with the squeeze-and-excitation (SE) block can further enhance performance. For feature engineering, we investigate the generalizability of Res2Net combined with different acoustic features, and observe that the constant-Q transform (CQT) achieves the most promising performance in both PA and LA scenarios. Our best single system outperforms other state-of-the-art single systems in both PA and LA of the ASVspoof 2019 corpus.      
### 7.Accelerated Probabilistic Power Flow via Model Order Reduction and Neumann Series Expansion  [ :arrow_down: ](https://arxiv.org/pdf/2010.14995.pdf)
>  This paper develops a computationally efficient algorithm which speeds up the probabilistic power flow (PPF) problem by exploiting the inherently low-rank nature of the voltage profile in electrical power distribution networks. The algorithm is accordingly termed the Accelerated-PPF (APPF), since it can accelerate "any" sampling-based PPF solver. As the APPF runs, it concurrently generates a low-dimensional subspace of orthonormalized solution vectors. This subspace is used to construct and update a reduced order model (ROM) of the full nonlinear system, resulting in a highly efficient simulation for future voltage profiles. When constructing/updating the subspace, the power flow problem must still be solved on the full nonlinear system. In order to speed up also those system solves, a Neumann expansion of a modified power flow Jacobian is implemented. Applicable when load currents are small, this Neumann expansion allows for a considerable speed up of Jacobian solves during the standard Newton iterations. APPF test results, from experiments run on the full IEEE 8500-node test feeder, are finally presented.      
### 8.Exploiting Angular Multiplexing for Polarization-diversity in Off-axis Digital Holography  [ :arrow_down: ](https://arxiv.org/pdf/2010.14968.pdf)
>  Digital holography measures the complex optical field and transfer matrix of a device, polarization-diversity is often achieved through spatial multiplexing. We introduce angular multiplexing, to increase flexibility in the optical setup. Comparatively, similar values for cross-talk and mode-dependent loss are measured for a photonic lantern.      
### 9.Galvanalyser: A Battery Test Database  [ :arrow_down: ](https://arxiv.org/pdf/2010.14959.pdf)
>  Performance and lifetime testing of batteries requires considerable effort and expensive specialist equipment. A wide range of potentiostats and battery testers are available on the market, but there is no standardisation of data exchange and data storage between them. To address this, we present Galvanalyser, a battery test database developed to manage the growing challenges of collating, managing and accessing data produced by multiple different battery testers. Collation is managed by a client-side application, the `Harvester', which pushes new data up to a PostgreSQL database on a server. Data access is possible in two ways: firstly, a web application allows data to be searched and viewed in a browser, with the option to plot data; secondly, a Python application programming interface (API) can connect directly to the database and pull requested data sets into Python. We hope to make Galvanalyser openly available soon. If you wish to test the system, please contact us for early access.      
### 10.An Approach for GCI Fusion With Labeled Multitarget Densities  [ :arrow_down: ](https://arxiv.org/pdf/2010.14943.pdf)
>  This paper addresses the Generalized Covariance Intersection (GCI) fusion method for labeled random finite sets. We propose a joint label space for the support of fused labeled random finite sets to represent the label association between different agents, avoiding the label consistency condition for the label-wise GCI fusion algorithm. Specifically, we devise the joint label space by the direct product of all label spaces for each agent. Then we apply the GCI fusion method to obtain the joint labeled multi-target density. The joint labeled RFS is then marginalized into a general labeled RFS, providing that each target is represented by a single Bernoulli component with a unique label. The joint labeled GCI (JL-GCI) for fusing LMB RFSs from different agents is demonstrated. We also propose the simplified JL-GCI method given the assumption that targets are well-separated in the scenario. The simulation result presents the effectiveness of label inconsistency and excellent performance in challenging tracking scenarios.      
### 11.Generative Tomography Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2010.14933.pdf)
>  We propose an end-to-end differentiable architecture for tomography reconstruction that directly maps a noisy sinogram into a denoised reconstruction. Compared to existing approaches our end-to-end architecture produces more accurate reconstructions while using less parameters and time. We also propose a generative model that, given a noisy sinogram, can sample realistic reconstructions. This generative model can be used as prior inside an iterative process that, by taking into consideration the physical model, can reduce artifacts and errors in the reconstructions.      
### 12.Medical Deep Learning -- A systematic Meta-Review  [ :arrow_down: ](https://arxiv.org/pdf/2010.14881.pdf)
>  Deep learning had a remarkable impact in different scientific disciplines during the last years. This was demonstrated in numerous tasks, where deep learning algorithms were able to outperform the state-of-art methods, also in image processing and analysis. Moreover, deep learning delivers good results in tasks like autonomous driving, which could not have been performed automatically before. There are even applications where deep learning outperformed humans, like object recognition or games. Another field in which this development is showing a huge potential is the medical domain. With the collection of large quantities of patient records and data, and a trend towards personalized treatments, there is a great need for an automatic and reliable processing and analysis of this information. Patient data is not only collected in clinical centres, like hospitals, but it relates also to data coming from general practitioners, healthcare smartphone apps or online websites, just to name a few. This trend resulted in new, massive research efforts during the last years. In Q2/2020, the search engine PubMed returns already over 11.000 results for the search term $'$deep learning$'$, and around 90% of these publications are from the last three years. Hence, a complete overview of the field of $'$medical deep learning$'$ is almost impossible to obtain and getting a full overview of medical sub-fields gets increasingly more difficult. Nevertheless, several review and survey articles about medical deep learning have been presented within the last years. They focused, in general, on specific medical scenarios, like the analysis of medical images containing specific pathologies. With these surveys as foundation, the aim of this contribution is to provide a very first high-level, systematic meta-review of medical deep learning surveys.      
### 13.Model-Free Adaptive Control for MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2010.14847.pdf)
>  We design the model-free adaptive control (MFAC) for multivariable systems in the paper.      
### 14.RIS-aided Joint Localization and Synchronization with a Single-Antenna MmWave Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2010.14825.pdf)
>  MmWave multiple-input single-output (MISO) systems using a single-antenna receiver are regarded as promising solution for the near future, before the full-fledged 5G MIMO will be widespread. However, for MISO systems synchronization cannot be performed jointly with user localization unless two-way transmissions are used. In this paper we show that thanks to the use of a reconfigurable intelligent surface (RIS), joint localization and synchronization is possible with only downlink MISO transmissions. The direct maximum likelihood (ML) estimator for the position and clock offset is derived. To obtain a good initialization for the ML optimization, a decoupled, relaxed estimator of position and delays is also devised, which does not require knowledge of the clock offset. Results show that the proposed approach attains the Cramér-Rao lower bound even for moderate values of the system parameters.      
### 15.Enhanced Blind Calibration of Uniform Linear Arrays with One-Bit Quantization by Kullback-Leibler Divergence Covariance Fitting  [ :arrow_down: ](https://arxiv.org/pdf/2010.14803.pdf)
>  One-bit quantization has recently become an attractive option for data acquisition in cutting edge applications, due to the increasing demand for low power and higher sampling rates. Subsequently, the rejuvenated one-bit array processing field is now receiving more attention, as "classical" array processing techniques are adapted / modified accordingly. However, array calibration, often an instrumental preliminary stage in array processing, has so far received little attention in its one-bit form. In this paper, we present a novel solution approach for the blind calibration problem, namely, without using known calibration signals. In order to extract information within the second-order statistics of the quantized measurements, we propose to estimate the unknown sensors' gains and phases offsets according to a Kullback-Leibler Divergence (KLD) covariance fitting criterion. We then provide a quasi-Newton solution algorithm, with a consistent initial estimate, and demonstrate the improved accuracy of our KLD-based estimates in simulations.      
### 16.Non-Iterative Blind Calibration of Nested Arrays with Asymptotically Optimal Weighting  [ :arrow_down: ](https://arxiv.org/pdf/2010.14799.pdf)
>  Blind calibration of sensors arrays (without using calibration signals) is an important, yet challenging problem in array processing. While many methods have been proposed for "classical" array structures, such as uniform linear arrays, not as many are found in the context of the more "modern" sparse arrays. In this paper, we present a novel blind calibration method for $2$-level nested arrays. Specifically, and despite recent contradicting claims in the literature, we show that the Least-Squares (LS) approach can in fact be used for this purpose with such arrays. Moreover, the LS approach gives rise to optimally-weighted LS joint estimation of the sensors' gains and phases offsets, which leads to more accurate calibration, and in turn, to higher accuracy in subsequent estimation tasks (e.g., direction-of-arrival). Our method, which can be extended to $K$-level arrays ($K&gt;2$), is superior to the current state of the art both in terms of accuracy and computational efficiency, as we demonstrate in simulation.      
### 17.One in a hundred: Select the best predicted sequence from numerous candidates for streaming speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.14791.pdf)
>  The RNN-Transducers and improved attention-based sequence-to-sequence models are widely applied to streaming speech recognition. Compared with these two end-to-end models, the CTC model is more efficient in training and inference. However, it cannot capture the dependencies between the output tokens. We assume that we can pick out the best sequence among the first N candidates predicted by the CTC model. Enough number and enough diversity of candidates can compensate it for the lack of language modeling ability. Therefore, we improve the hybrid CTC and attention model, and introduce a two-stage inference method named one-in-a-hundred (OAH). During inference, we first generate many candidates by the CTC decoder in a streaming fashion. Then the transformer decoder selects the best candidate based on the corresponding acoustic encoded states. All the experiments are conducted on a Chinese Mandarin dataset AISHELL-1. The results show that our proposed model can implement stream decoding in a fast and straightforward way. Our model can achieve up to 20% reduction in the character error rate than the baseline CTC model. In addition, our model can also perform non-streaming decoding.      
### 18.Age of Information Analysis in Hyperledger Fabric Blockchain-enabled Monitoring Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.14783.pdf)
>  Age of information (AoI) is a recently proposed metric for quantifying data freshness in real-time status monitoring systems where timeliness is of importance. In this paper, we explore the data freshness in the Hyperledger Fabric Blockchain-enabled monitoring network (HeMN) by leveraging the AoI metric. In HeMN, status updates from sources are transmitted through an uplink and recorded in a Hyperledger Fabric (HLF) network. To provide a stochastic guarantee of data freshness, we derive a closed-form of AoI violation probability by considering the transmission latency and the consensus latency. Then, we validate our analytic results through the implemented HLF platform. We also investigate the effect of the target successful transmission probability (STP) on the AoI violation probability.      
### 19.Classification Beats Regression: Counting of Cells from Greyscale Microscopic Images based on Annotation-free Training Samples  [ :arrow_down: ](https://arxiv.org/pdf/2010.14782.pdf)
>  Modern methods often formulate the counting of cells from microscopic images as a regression problem and more or less rely on expensive, manually annotated training images (e.g., dot annotations indicating the centroids of cells or segmentation masks identifying the contours of cells). This work proposes a supervised learning framework based on classification-oriented convolutional neural networks (CNNs) to count cells from greyscale microscopic images without using annotated training images. In this framework, we formulate the cell counting task as an image classification problem, where the cell counts are taken as class labels. This formulation has its limitation when some cell counts in the test stage do not appear in the training data. Moreover, the ordinal relation among cell counts is not utilized. To deal with these limitations, we propose a simple but effective data augmentation (DA) method to synthesize images for the unseen cell counts. We also introduce an ensemble method, which can not only moderate the influence of unseen cell counts but also utilize the ordinal information to improve the prediction accuracy. This framework outperforms many modern cell counting methods and won the data analysis competition (Case Study 1: Counting Cells From Microscopic Images <a class="link-external link-https" href="https://ssc.ca/en/case-study/case-study-1-counting-cells-microscopic-images" rel="external noopener nofollow">this https URL</a>) of the 47th Annual Meeting of the Statistical Society of Canada (SSC). Our code is available at <a class="link-external link-https" href="https://github.com/anno2020/CellCount_TinyBBBC005" rel="external noopener nofollow">this https URL</a>.      
### 20.Effective Decoder Masking for Transformer Based End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.14764.pdf)
>  The attention-based encoder-decoder modeling paradigm has achieved promising results on a variety of speech processing tasks like automatic speech recognition (ASR), text-to-speech (TTS) and among others. This paradigm takes advantage of the generalization ability of neural networks to learn a direct mapping from an input sequence to an output sequence, without recourse to prior knowledge such as audio-text alignments or pronunciation lexicons. However, ASR models stemming from this paradigm are prone to overfitting, especially when the training data is limited. Inspired by SpecAugment and BERT-like masked language modeling, we propose in the paper a decoder masking based training approach for end-to-end (E2E) ASR models. During the training phase we randomly replace some portions of the decoder's historical text input with the symbol [mask], in order to encourage the decoder to robustly output a correct token even when parts of its decoding history are masked or corrupted. The proposed approach is instantiated with the top-of-the-line transformer-based E2E ASR model. Extensive experiments on the Librispeech960h and TedLium2 benchmark datasets demonstrate the superior performance of our approach in comparison to some existing strong E2E ASR systems.      
### 21.An iterative framework for self-supervised deep speaker representation learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.14751.pdf)
>  In this paper, we propose an iterative framework for self-supervised speaker representation learning based on a deep neural network (DNN). The framework starts with training a self-supervision speaker embedding network by maximizing agreement between different segments within an utterance via a contrastive loss. Taking advantage of DNN's ability to learn from data with label noise, we propose to cluster the speaker embedding obtained from the previous speaker network and use the subsequent class assignments as pseudo labels to train a new DNN. Moreover, we iteratively train the speaker network with pseudo labels generated from the previous step to bootstrap the discriminative power of a DNN. Speaker verification experiments are conducted on the VoxCeleb dataset. The results show that our proposed iterative self-supervised learning framework outperformed previous works using self-supervision. The speaker network after 5 iterations obtains a 61% performance gain over the speaker embedding model trained with contrastive loss.      
### 22.Continuous Chaotic Nonlinear System and Lyapunov controller Optimization using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.14746.pdf)
>  The introduction of unexpected system disturbances and new system dynamics does not allow initially selected static system and controller parameters to guarantee continued system stability and performance. In this research we present a novel approach for detecting early failure indicators of non-linear highly chaotic system and accordingly predict the best parameter calibrations to offset such instability using deep machine learning regression model. The approach proposed continuously monitors the system and controller signals. The Re-calibration of the system and controller parameters is triggered according to a set of conditions designed to maintain system stability without compromise to the system speed, intended outcome or required processing power. The deep neural model predicts the parameter values that would best counteract the expected system in-stability. To demonstrate the effectiveness of the proposed approach, it is applied to the non-linear complex combination of Duffing Van der pol oscillators. The approach is also tested under different scenarios the system and controller parameters are initially chosen incorrectly or the system parameters are changed while running or new system dynamics are introduced while running to measure effectiveness and reaction time.      
### 23.CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.14725.pdf)
>  We propose a CTC alignment-based single step non-autoregressive transformer (CASS-NAT) for speech recognition. Specifically, the CTC alignment contains the information of (a) the number of tokens for decoder input, and (b) the time span of acoustics for each token. The information are used to extract acoustic representation for each token in parallel, referred to as token-level acoustic embedding which substitutes the word embedding in autoregressive transformer (AT) to achieve parallel generation in decoder. During inference, an error-based alignment sampling method is proposed to be applied to the CTC output space, reducing the WER and retaining the parallelism as well. Experimental results show that the proposed method achieves WERs of 3.8%/9.1% on Librispeech test clean/other dataset without an external LM, and a CER of 5.8% on Aishell1 Mandarin corpus, respectively1. Compared to the AT baseline, the CASS-NAT has a performance reduction on WER, but is 51.2x faster in terms of RTF. When decoding with an oracle CTC alignment, the lower bound of WER without LM reaches 2.3% on the test-clean set, indicating the potential of the proposed method.      
### 24.Equivariant Filter (EqF)  [ :arrow_down: ](https://arxiv.org/pdf/2010.14666.pdf)
>  The kinematics of many systems encountered in robotics, mechatronics, and avionics are naturally posed on homogeneous spaces, that is, their state lies in a smooth manifold equipped with a transitive Lie-group symmetry. This paper shows that all such systems can be embedded in an equivariant system using a velocity extension. We propose a novel filter, the Equivariant Filter (EqF), by linearising global error dynamics derived from the equivariance of the embedding system and applying a Riccati observer to these error dynamics. In cases where the system output is also equivariant the EqF leads to linearised dynamics with a constant output matrix. The work is motivated by an example application that is intractable to prior published invariant filter design methodologies.      
### 25.Cascaded encoders for unifying streaming and non-streaming ASR  [ :arrow_down: ](https://arxiv.org/pdf/2010.14606.pdf)
>  End-to-end (E2E) automatic speech recognition (ASR) models, by now, have shown competitive performance on several benchmarks. These models are structured to either operate in streaming or non-streaming mode. This work presents cascaded encoders for building a single E2E ASR model that can operate in both these modes simultaneously. The proposed model consists of streaming and non-streaming encoders. Input features are first processed by the streaming encoder; the non-streaming encoder operates exclusively on the output of the streaming encoder. A single decoder then learns to decode either using the output of the streaming or the non-streaming encoder. Results show that this model achieves similar word error rates (WER) as a standalone streaming model when operating in streaming mode, and obtains 10% -- 27% relative improvement when operating in non-streaming mode. Our results also show that the proposed approach outperforms existing E2E two-pass models, especially on long-form speech.      
### 26.Nonlinear State-Space Generalizations of Graph Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2010.14585.pdf)
>  Graph convolutional neural networks (GCNNs) learn compositional representations from network data by nesting linear graph convolutions into nonlinearities. In this work, we approach GCNNs from a state-space perspective revealing that the graph convolutional module is a minimalistic linear state-space model, in which the state update matrix is the graph shift operator. We show this state update may be problematic because it is nonparametric, and depending on the graph spectrum it may explode or vanish. Therefore, the GCNN has to trade its degrees of freedom between extracting features from data and handling these instabilities. To improve such trade-off, we propose a novel family of nodal aggregation rules that aggregates node features within a layer in a nonlinear state-space parametric fashion and allowing for a better trade-off. We develop two architectures within this family inspired by the recursive ideas with and without nodal gating mechanisms. The proposed solutions generalize the GCNN and provide an additional handle to control the state update and learn from the data. Numerical results on source localization and authorship attribution show the superiority of the nonlinear state-space generalization models over the baseline GCNN.      
### 27.A Fully Integrated Sensor-Brain-Machine Interface System for Restoring Somatosensation  [ :arrow_down: ](https://arxiv.org/pdf/2010.15081.pdf)
>  Sensory feedback is critical to the performance of neural prostheses that restore movement control after neurological injury. Recent advances in direct neural control of paralyzed arms present new requirements for miniaturized, low-power sensor systems. To address this challenge, we developed a fully-integrated wireless sensor-brain-machine interface (SBMI) system for communicating key somatosensory signals, fingertip forces and limb joint angles, to the brain. The system consists of a tactile force sensor, an electrogoniometer, and a neural interface. The tactile force sensor features a novel optical waveguide on CMOS design for sensing. The electrogoniometer integrates an ultra low-power digital signal processor (DSP) for real-time joint angle measurement. The neural interface enables bidirectional neural stimulation and recording. Innovative designs of sensors and sensing interfaces, analog-to-digital converters (ADC) and ultra wide-band (UWB) wireless transceivers have been developed. The prototypes have been fabricated in 180nm standard CMOS technology and tested on the bench and in vivo. The developed system provides a novel solution for providing somatosensory feedback to next-generation neural prostheses.      
### 28.Generative Adversarial Networks in Human Emotion Synthesis:A Review  [ :arrow_down: ](https://arxiv.org/pdf/2010.15075.pdf)
>  Synthesizing realistic data samples is of great value for both academic and industrial communities. Deep generative models have become an emerging topic in various research areas like computer vision and signal processing. Affective computing, a topic of a broad interest in computer vision society, has been no exception and has benefited from generative models. In fact, affective computing observed a rapid derivation of generative models during the last two decades. Applications of such models include but are not limited to emotion recognition and classification, unimodal emotion synthesis, and cross-modal emotion synthesis. As a result, we conducted a review of recent advances in human emotion synthesis by studying available databases, advantages, and disadvantages of the generative models along with the related training strategies considering two principal human communication modalities, namely audio and video. In this context, facial expression synthesis, speech emotion synthesis, and the audio-visual (cross-modal) emotion synthesis is reviewed extensively under different application scenarios. Gradually, we discuss open research problems to push the boundaries of this research area for future works.      
### 29.Self-awareness in Intelligent Vehicles: Experience Based Abnormality Detection  [ :arrow_down: ](https://arxiv.org/pdf/2010.15056.pdf)
>  The evolution of Intelligent Transportation System in recent times necessitates the development of self-driving agents: the self-awareness consciousness. This paper aims to introduce a novel method to detect abnormalities based on internal cross-correlation parameters of the vehicle. Before the implementation of Machine Learning, the detection of abnormalities were manually programmed by checking every variable and creating huge nested conditions that are very difficult to track. Nowadays, it is possible to train a Dynamic Bayesian Network (DBN) model to automatically evaluate and detect when the vehicle is potentially misbehaving. In this paper, different scenarios have been set in order to train and test a switching DBN for Perimeter Monitoring Task using a semantic segmentation for the DBN model and Hellinger Distance metric for abnormality measurements.      
### 30.Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input  [ :arrow_down: ](https://arxiv.org/pdf/2010.15025.pdf)
>  Non-autoregressive (NAR) transformer models have achieved significantly inference speedup but at the cost of inferior accuracy compared to autoregressive (AR) models in automatic speech recognition (ASR). Most of the NAR transformers take a fixed-length sequence filled with MASK tokens or a redundant sequence copied from encoder states as decoder input, they cannot provide efficient target-side information thus leading to accuracy degradation. To address this problem, we propose a CTC-enhanced NAR transformer, which generates target sequence by refining predictions of the CTC module. Experimental results show that our method outperforms all previous NAR counterparts and achieves 50x faster decoding speed than a strong AR baseline with only 0.0 ~ 0.3 absolute CER degradation on Aishell-1 and Aishell-2 datasets.      
### 31.Measurement-based coexistence studies of LAA &amp; Wi-Fi deployments in Chicago  [ :arrow_down: ](https://arxiv.org/pdf/2010.15012.pdf)
>  LTE-Licensed Assisted Access (LAA) networks are beginning to be deployed widely in major metropolitan areas in the US in the unlicensed 5 GHz bands, which have existing dense deployments of Wi-Fi as well. Various aspects of the coexistence scenarios such deployments give rise to have been considered ina vast body of academic and industry research. However, there is very little data and research on how these coexisting networks will behave in practice. The question of fair coexistence between Wi-Fi and LAA has moved from a theoretical question to reality. The recent roll-out of LAA deployments provides an opportunity to collect data on the operation of these networks as well as studying coexistence issues on the ground. In this paper we describe the first results of a measurement campaign conducted over many months, using custom apps as well as off-the-shelf tools, in several areas of Chicago where the major carriers have been expanding LAA deployments. The measurements reveal that coexistence between LAA and Wi-Fi in dense, urban environments where both systems aggregate multiple channels, continues to be a challenging problem that requires further research.      
### 32.Real-time Tropical Cyclone Intensity Estimation by Handling Temporally Heterogeneous Satellite Data  [ :arrow_down: ](https://arxiv.org/pdf/2010.14977.pdf)
>  Analyzing big geophysical observational data collected by multiple advanced sensors on various satellite platforms promotes our understanding of the geophysical system. For instance, convolutional neural networks (CNN) have achieved great success in estimating tropical cyclone (TC) intensity based on satellite data with fixed temporal frequency (e.g., 3 h). However, to achieve more timely (under 30 min) and accurate TC intensity estimates, a deep learning model is demanded to handle temporally-heterogeneous satellite observations. Specifically, infrared (IR1) and water vapor (WV) images are available under every 15 minutes, while passive microwave rain rate (PMW) is available for about every 3 hours. Meanwhile, the visible (VIS) channel is severely affected by noise and sunlight intensity, making it difficult to be utilized. Therefore, we propose a novel framework that combines generative adversarial network (GAN) with CNN. The model utilizes all data, including VIS and PMW information, during the training phase and eventually uses only the high-frequent IR1 and WV data for providing intensity estimates during the predicting phase. Experimental results demonstrate that the hybrid GAN-CNN framework achieves comparable precision to the state-of-the-art models, while possessing the capability of increasing the maximum estimation frequency from 3 hours to less than 15 minutes.      
### 33.Collective Awareness for Abnormality Detection in Connected Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2010.14908.pdf)
>  The advancements in connected and autonomous vehicles in these times demand the availability of tools providing the agents with the capability to be aware and predict their own states and context dynamics. This article presents a novel approach to develop an initial level of collective awareness in a network of intelligent agents. A specific collective self awareness functionality is considered, namely, agent centered detection of abnormal situations present in the environment around any agent in the network. Moreover, the agent should be capable of analyzing how such abnormalities can influence the future actions of each agent. Data driven dynamic Bayesian network (DBN) models learned from time series of sensory data recorded during the realization of tasks (agent network experiences) are here used for abnormality detection and prediction. A set of DBNs, each related to an agent, is used to allow the agents in the network to each synchronously aware possible abnormalities occurring when available models are used on a new instance of the task for which DBNs have been learned. A growing neural gas (GNG) algorithm is used to learn the node variables and conditional probabilities linking nodes in the DBN models; a Markov jump particle filter (MJPF) is employed for state estimation and abnormality detection in each agent using learned DBNs as filter parameters. Performance metrics are discussed to asses the algorithms reliability and accuracy. The impact is also evaluated by the communication channel used by the network to share the data sensed in a distributed way by each agent of the network. The IEEE 802.11p protocol standard has been considered for communication among agents. Real data sets are also used acquired by autonomous vehicles performing different tasks in a controlled environment.      
### 34.A convex relaxation approach for the optimized pulse pattern problem  [ :arrow_down: ](https://arxiv.org/pdf/2010.14853.pdf)
>  Optimized Pulse Patterns (OPPs) are gaining increasing popularity in the power electronics community over the well-studied pulse width modulation due to their inherent ability to provide the switching instances that optimize current harmonic distortions. In particular, the OPP problem minimizes current harmonic distortions under a cardinality constraint on the number of switching instances per fundamental wave period. The OPP problem is, however, non-convex involving both polynomials and trigonometric functions. In the existing literature, the OPP problem is solved using off-the-shelf solvers with local convergence guarantees. To obtain guarantees of global optimality, we employ and extend techniques from polynomial optimization literature and provide a solution with a global convergence guarantee. Specifically, we propose a polynomial approximation to the OPP problem to then utilize well-studied globally convergent convex relaxation hierarchies, namely, semi-definite programming and relative entropy relaxations. The resulting hierarchy is proven to converge to the global optimal solution. Our method exhibits a strong performance for OPP problems up to 50 switching instances per quarter wave.      
### 35.INT8 Winograd Acceleration for Conv1D Equipped ASR Models Deployed on Mobile Devices  [ :arrow_down: ](https://arxiv.org/pdf/2010.14841.pdf)
>  The intensive computation of Automatic Speech Recognition (ASR) models obstructs them from being deployed on mobile devices. In this paper, we present a novel quantized Winograd optimization pipeline, which combines the quantization and fast convolution to achieve efficient inference acceleration on mobile devices for ASR models. To avoid the information loss due to the combination of quantization and Winograd convolution, a Range-Scaled Quantization (RSQ) training method is proposed to expand the quantized numerical range and to distill knowledge from high-precision values. Moreover, an improved Conv1D equipped DFSMN (ConvDFSMN) model is designed for mobile deployment. We conduct extensive experiments on both ConvDFSMN and Wav2letter models. Results demonstrate the models can be effectively optimized with the proposed pipeline. Especially, Wav2letter achieves 1.48* speedup with an approximate 0.07% WER decrease on ARMv7-based mobile devices.      
### 36.Large-Scale MIDI-based Composer Classification  [ :arrow_down: ](https://arxiv.org/pdf/2010.14805.pdf)
>  Music classification is a task to classify a music piece into labels such as genres or composers. We propose large-scale MIDI based composer classification systems using GiantMIDI-Piano, a transcription-based dataset. We propose to use piano rolls, onset rolls, and velocity rolls as input representations and use deep neural networks as classifiers. To our knowledge, we are the first to investigate the composer classification problem with up to 100 composers. By using convolutional recurrent neural networks as models, our MIDI based composer classification system achieves a 10-composer and a 100-composer classification accuracies of 0.648 and 0.385 (evaluated on 30-second clips) and 0.739 and 0.489 (evaluated on music pieces), respectively. Our MIDI based composer system outperforms several audio-based baseline classification systems, indicating the effectiveness of using compact MIDI representations for composer classification.      
### 37.PPG-based singing voice conversion with adversarial representation learning  [ :arrow_down: ](https://arxiv.org/pdf/2010.14804.pdf)
>  Singing voice conversion (SVC) aims to convert the voice of one singer to that of other singers while keeping the singing content and melody. On top of recent voice conversion works, we propose a novel model to steadily convert songs while keeping their naturalness and intonation. We build an end-to-end architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating mel spectrograms. Specifically, we implement two separate encoders: one encodes PPGs as content, and the other compresses mel spectrograms to supply acoustic and musical information. To improve the performance on timbre and melody, an adversarial singer confusion module and a mel-regressive representation learning module are designed for the model. Objective and subjective experiments are conducted on our private Chinese singing corpus. Comparing with the baselines, our methods can significantly improve the conversion performance in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based method is proved to be robust for noisy sources.      
### 38.Decoupling Pronunciation and Language for End-to-end Code-switching Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.14798.pdf)
>  Despite the recent significant advances witnessed in end-to-end (E2E) ASR system for code-switching, hunger for audio-text paired data limits the further improvement of the models' performance. In this paper, we propose a decoupled transformer model to use monolingual paired data and unpaired text data to alleviate the problem of code-switching data shortage. The model is decoupled into two parts: audio-to-phoneme (A2P) network and phoneme-to-text (P2T) network. The A2P network can learn acoustic pattern scenarios using large-scale monolingual paired data. Meanwhile, it generates multiple phoneme sequence candidates for single audio data in real-time during the training process. Then the generated phoneme-text paired data is used to train the P2T network. This network can be pre-trained with large amounts of external unpaired text data. By using monolingual data and unpaired text data, the decoupled transformer model reduces the high dependency on code-switching paired training data of E2E model to a certain extent. Finally, the two networks are optimized jointly through attention fusion. We evaluate the proposed method on the public Mandarin-English code-switching dataset. Compared with our transformer baseline, the proposed method achieves 18.14% relative mix error rate reduction.      
### 39.Seen and Unseen emotional style transfer for voice conversion with a new emotional speech dataset  [ :arrow_down: ](https://arxiv.org/pdf/2010.14794.pdf)
>  Emotional voice conversion aims to transform emotional prosody in speech while preserving the linguistic content and speaker identity. Prior studies show that it is possible to disentangle emotional prosody using an encoder-decoder network conditioned on discrete representation, such as one-hot emotion labels. Such networks learn to remember a fixed set of emotional styles. In this paper, we propose a novel framework based on variational auto-encoding Wasserstein generative adversarial network (VAW-GAN), which makes use of a pre-trained speech emotion recognition (SER) model to transfer emotional style during training and at run-time inference. In this way, the network is able to transfer both seen and unseen emotional style to a new utterance. We show that the proposed framework achieves remarkable performance by consistently outperforming the baseline framework. This paper also marks the release of an emotional speech dataset (ESD) for voice conversion, which has multiple speakers and languages.      
### 40.Stochastic Geometry Analysis of Uplink Cellular Networks with FSO Backhauling: Cooperative Relaying Vs. Reflecting Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2010.14779.pdf)
>  In this work, we consider the performance analysis of the uplink cellular networks with free space optics (FSO) backhauling. The user equipment (UE) communicates with the nearest Base Station (BS) in first slot while in second slot, the BS converts the received radio frequency (RF) signal into FSO pulse and transmits to the data center. We adopt the Rayleigh fading for the uplink channels while the FSO backhaul encompasses the turbulence-induced fading which follows the Málaga distribution, the weather pathloss, and the pointing errors fading which is distributed following the generalized Beckmann model. Further, we will compare the performances when the BS behaves as either a decode-and-forward (DF) relay or an intelligent reflecting surface (IRS). Next, we will propose an optimal design of the phase shifters of the IRS to minimize the interference and improve the rate to beat relaying. Capitalizing on this framework, we will derive the system performance metrics such as the coverage probability as well as the spectral efficiency. Focusing on high SNR, we will obtain the diversity gain to get engineering insights into the system performance and limitations. Finally, the analytical results are confirmed by Monte Carlo simulations.      
### 41.Melody-Conditioned Lyrics Generation with SeqGANs  [ :arrow_down: ](https://arxiv.org/pdf/2010.14709.pdf)
>  Automatic lyrics generation has received attention from both music and AI communities for years. Early rule-based approaches have~---due to increases in computational power and evolution in data-driven models---~mostly been replaced with deep-learning-based systems. Many existing approaches, however, either rely heavily on prior knowledge in music and lyrics writing or oversimplify the task by largely discarding melodic information and its relationship with the text. We propose an end-to-end melody-conditioned lyrics generation system based on Sequence Generative Adversarial Networks (SeqGAN), which generates a line of lyrics given the corresponding melody as the input. Furthermore, we investigate the performance of the generator with an additional input condition: the theme or overarching topic of the lyrics to be generated. We show that the input conditions have no negative impact on the evaluation metrics while enabling the network to produce more meaningful results.      
### 42.System Identification via Meta-Learning in Linear Time-Varying Environments  [ :arrow_down: ](https://arxiv.org/pdf/2010.14664.pdf)
>  System identification is a fundamental problem in reinforcement learning, control theory and signal processing, and the non-asymptotic analysis of the corresponding sample complexity is challenging and elusive, even for linear time-varying (LTV) systems. To tackle this challenge, we develop an episodic block model for the LTV system where the model parameters remain constant within each block but change from block to block. Based on the observation that the model parameters across different blocks are related, we treat each episodic block as a learning task and then run meta-learning over many blocks for system identification, using two steps, namely offline meta-learning and online adaptation. We carry out a comprehensive non-asymptotic analysis of the performance of meta-learning based system identification. To deal with the technical challenges rooted in the sample correlation and small sample sizes in each block, we devise a new two-scale martingale small-ball approach for offline meta-learning, for arbitrary model correlation structure across blocks. We then quantify the finite time error of online adaptation by leveraging recent advances in linear stochastic approximation with correlated samples.      
### 43.CopyPaste: An Augmentation Method for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2010.14602.pdf)
>  Data augmentation is a widely used strategy for training robust machine learning models. It partially alleviates the problem of limited data for tasks like speech emotion recognition (SER), where collecting data is expensive and challenging. This study proposes CopyPaste, a perceptually motivated novel augmentation procedure for SER. Assuming that the presence of emotions other than neutral dictates a speaker's overall perceived emotion in a recording, concatenation of an emotional (emotion E) and a neutral utterance can still be labeled with emotion E. We hypothesize that SER performance can be improved using these concatenated utterances in model training. To verify this, three CopyPaste schemes are tested on two deep learning models: one trained independently and another using transfer learning from an x-vector model, a speaker recognition model. We observed that all three CopyPaste schemes improve SER performance on all the three datasets considered: MSP-Podcast, Crema-D, and IEMOCAP. Additionally, CopyPaste performs better than noise augmentation and, using them together improves the SER performance further. Our experiments on noisy test sets suggested that CopyPaste is effective even in noisy test conditions.      
### 44.Learning Time Reduction Using Warm Start Methods for a Reinforcement Learning Based Supervisory Control in Hybrid Electric Vehicle Applications  [ :arrow_down: ](https://arxiv.org/pdf/2010.14575.pdf)
>  Reinforcement Learning (RL) is widely utilized in the field of robotics, and as such, it is gradually being implemented in the Hybrid Electric Vehicle (HEV) supervisory control. Even though RL exhibits excellent performance in terms of fuel consumption minimization in simulation, the large learning iteration number needs a long learning time, making it hardly applicable in real-world vehicles. In addition, the fuel consumption of initial learning phases is much worse than baseline controls. This study aims to reduce the learning iterations of Q-learning in HEV application and improve fuel consumption in initial learning phases utilizing warm start methods. Different from previous studies, which initiated Q-learning with zero or random Q values, this study initiates the Q-learning with different supervisory controls (i.e., Equivalent Consumption Minimization Strategy control and heuristic control), and detailed analysis is given. The results show that the proposed warm start Q-learning requires 68.8% fewer iterations than cold start Q-learning. The trained Q-learning is validated in two different driving cycles, and the results show 10-16% MPG improvement when compared to Equivalent Consumption Minimization Strategy control. Furthermore, real-time feasibility is analyzed, and the guidance of vehicle implementation is provided. The results of this study can be used to facilitate the deployment of RL in vehicle supervisory control applications.      
### 45.Remixing Music with Visual Conditioning  [ :arrow_down: ](https://arxiv.org/pdf/2010.14565.pdf)
>  We propose a visually conditioned music remixing system by incorporating deep visual and audio models. The method is based on a state of the art audio-visual source separation model which performs music instrument source separation with video information. We modified the model to work with user-selected images instead of videos as visual input during inference to enable separation of audio-only content. Furthermore, we propose a remixing engine that generalizes the task of source separation into music remixing. The proposed method is able to achieve improved audio quality compared to remixing performed by the separate-and-add method with a state-of-the-art audio-visual source separation model.      
### 46.Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics  [ :arrow_down: ](https://arxiv.org/pdf/1701.06078.pdf)
>  Most of the previous approaches to lyrics-to-audio alignment used a pre-developed automatic speech recognition (ASR) system that innately suffered from several difficulties to adapt the speech model to individual singers. A significant aspect missing in previous works is the self-learnability of repetitive vowel patterns in the singing voice, where the vowel part used is more consistent than the consonant part. Based on this, our system first learns a discriminative subspace of vowel sequences, based on weighted symmetric non-negative matrix factorization (WS-NMF), by taking the self-similarity of a standard acoustic feature as an input. Then, we make use of canonical time warping (CTW), derived from a recent computer vision technique, to find an optimal spatiotemporal transformation between the text and the acoustic sequences. Experiments with Korean and English data sets showed that deploying this method after a pre-developed, unsupervised, singing source separation achieved more promising results than other state-of-the-art unsupervised approaches and an existing ASR-based system.      
### 47.A pairwise approach to simultaneous onset/offset detection for singing voice using correntropy  [ :arrow_down: ](https://arxiv.org/pdf/1603.06065.pdf)
>  In this paper, we propose a novelmethod to search for precise locations of paired note onset and offset in a singing voice signal. In comparison with the existing onset detection algorithms,our approach differs in two key respects. First, we employ Correntropy, a generalized correlation function inspired from Reyni's entropy, as a detection function to capture the instantaneous flux while preserving insensitiveness to outliers. Next, a novel peak picking algorithm is specially designed for this detection function. By calculating the fitness of a pre-defined inverse hyperbolic kernel to a detection function, it is possible to find an onset and its corresponding offset simultaneously. Experimental results show that the proposed method achieves performance significantly better than or comparable to other state-of-the-art techniques for onset detection in singing voice.      

# ArXiv eess --Fri, 11 Dec 2020
### 1.Spatial noise-aware temperature retrieval from infrared sounder data  [ :arrow_down: ](https://arxiv.org/pdf/2012.05839.pdf)
>  In this paper we present a combined strategy for the retrieval of atmospheric profiles from infrared sounders. The approach considers the spatial information and a noise-dependent dimensionality reduction approach. The extracted features are fed into a canonical linear regression. We compare Principal Component Analysis (PCA) and Minimum Noise Fraction (MNF) for dimensionality reduction, and study the compactness and information content of the extracted features. Assessment of the results is done on a big dataset covering many spatial and temporal situations. PCA is widely used for these purposes but our analysis shows that one can gain significant improvements of the error rates when using MNF instead. In our analysis we also investigate the relationship between error rate improvements when including more spectral and spatial components in the regression model, aiming to uncover the trade-off between model complexity and error rates.      
### 2.Analysis of multipath channel delay estimation using subspace fitting  [ :arrow_down: ](https://arxiv.org/pdf/2012.05790.pdf)
>  The presence of rich scattering in indoor and urban radio propagation scenarios may cause a high arrival density of multipath components (MPCs). Often the MPCs arrive in clusters at the receiver, where MPCs within one cluster have similar angles and delays. The MPCs arriving within a single cluster are typically unresolvable in the delay domain. In this paper, we analyze the effects of unresolved MPCs on the bias of the delay estimation with a multiband subspace fitting algorithm. We treat the unresolved MPCs as a model error that results in perturbed subspace estimation. Starting from the first-order approximation of the perturbations, we derive the bias of the delay estimate of the line-of-sight (LOS) component. We show that it depends on the power and relative delay of the unresolved MPCs in the first cluster compared to the LOS component. Numerical experiments are included to show that the derived expression for the bias well describes the effects of unresolved MPCs on the delay estimation.      
### 3.Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein Segmentation in CT  [ :arrow_down: ](https://arxiv.org/pdf/2012.05767.pdf)
>  Training convolutional neural networks (CNNs) for segmentation of pulmonary airway, artery, and vein is challenging due to sparse supervisory signals caused by the severe class imbalance between tubular targets and background. We present a CNNs-based method for accurate airway and artery-vein segmentation in non-contrast computed tomography. It enjoys superior sensitivity to tenuous peripheral bronchioles, arterioles, and venules. The method first uses a feature recalibration module to make the best use of features learned from the neural networks. Spatial information of features is properly integrated to retain relative priority of activated regions, which benefits the subsequent channel-wise recalibration. Then, attention distillation module is introduced to reinforce representation learning of tubular objects. Fine-grained details in high-resolution attention maps are passing down from one layer to its previous layer recursively to enrich context. Anatomy prior of lung context map and distance transform map is designed and incorporated for better artery-vein differentiation capacity. Extensive experiments demonstrated considerable performance gains brought by these components. Compared with state-of-the-art methods, our method extracted much more branches while maintaining competitive overall segmentation performance. Codes and models will be available later at <a class="link-external link-http" href="http://www.pami.sjtu.edu.cn" rel="external noopener nofollow">this http URL</a>.      
### 4.Modeling, Control and Human-In-The-Loop Stability Analysis of an Elastic Quadrotor  [ :arrow_down: ](https://arxiv.org/pdf/2012.05747.pdf)
>  This paper introduces an analytical framework for the derivation of hybrid equations of motion of a flexible quadrotor. This approach helps obtain rigid and elastic equations of motion simultaneously, in a decoupled form, which facilitates the controller design. A delay-dependent stability condition is obtained for the overall system dynamics, including the operator with reaction time delay, the adaptive controller and the flexible quadrotor dynamics. Two different adaptive controllers are implemented to address the uncertainties. It is demonstrated via simulations that the flexible arm tip oscillations are mitigated when a closed loop reference model adaptive controller is used, compared to a conventional model reference adaptive controller.      
### 5.3D Bounding Box Detection in Volumetric Medical Image Data: A Systematic Literature Review  [ :arrow_down: ](https://arxiv.org/pdf/2012.05745.pdf)
>  This paper discusses current methods and trends for 3D bounding box detection in volumetric medical image data. For this purpose, an overview of relevant papers from recent years is given. 2D and 3D implementations are discussed and compared. Multiple identified approaches for localizing anatomical structures are presented. The results show that most research recently focuses on Deep Learning methods, such as Convolutional Neural Networks vs. methods with manual feature engineering, e.g. Random-Regression-Forests. An overview of bounding box detection options is presented and helps researchers to select the most promising approach for their target objects.      
### 6.Peer-to-Peer Localization for Single-Antenna Devices  [ :arrow_down: ](https://arxiv.org/pdf/2012.05720.pdf)
>  Some important indoor localization applications, such as localizing a lost kid in a shopping mall, call for a new peer-to-peer localization technique that can localize an individual's smartphone or wearables by directly using another's on-body devices in unknown indoor environments. However, current localization solutions either require pre-deployed infrastructures or multiple antennas in both transceivers, impending their wide-scale application. In this paper, we present P2PLocate, a peer-to-peer localization system that enables a single-antenna device co-located with a batteryless backscatter tag to localize another single-antenna device with decimeter-level accuracy. P2PLocate leverages the multipath variations intentionally created by an on-body backscatter tag, coupled with spatial information offered by user movements, to accomplish this objective without relying on any pre-deployed infrastructures or pre-training. P2PLocate incorporates novel algorithms to address two major challenges: (i) interference with strong direct-path signal while extracting multipath variations, and (ii) lack of direction information while using single-antenna transceivers. We implement P2PLocate on commercial off-the-shelf Google Nexus 6p, Intel 5300 WiFi card, and Raspberry Pi B4. Real-world experiments reveal that P2PLocate can localize both static and mobile targets with a median accuracy of 0.88 m.      
### 7.Effect of the regularization hyperparameter on deep learning-based segmentation in LGE-MRI  [ :arrow_down: ](https://arxiv.org/pdf/2012.05661.pdf)
>  In this preliminary evaluation, the author demonstrates the extent to which the arbitrary selection of the L2 regularization hyperparameter can affect the outcome of deep learning-based segmentation in LGE-MRI. Also, the author adopts the manual adjustment or tunning, of other deep learning hyperparameters, to be done only when 10% of all epochs are reached before attaining the 90% validation accuracy. With the arbitrary L2 regularization values, used in the experiments, the results showed that the smaller L2 regularization number can lead to better segmentation of the myocardium and/or higher accuracy.      
### 8.Internet of Buoys: An Internet of Things Implementation at Sea  [ :arrow_down: ](https://arxiv.org/pdf/2012.05653.pdf)
>  Internet of Things (IoT) applications are emerging in many different areas, including maritime environments. One of the applications in this area is the monitoring of buoys at sea. To realize wireless tracking of buoys, an accurate prediction of the path loss in an open-sea environment is essential. So far, channel measurements at sea have mainly been conducted with antennas placed a couple of meters above the sea surface, which is higher than the buoys themselves. Therefore, we investigated the validity of the published channel models at sea by means of path loss measurements using a LoRa link with a transmitter antenna height of 0.35 m and a base station antenna height of 2.65 m and 5.2 m. Our results show that the round earth loss model is not accurate at these antenna heights. The ITU-R P.2001-3 model and a model by Bullington show a better agreement with our measurements. However, the difference between our two measurement campaigns shows that more investigation is needed on the dependence of the path loss on the sea state. Additionally, the availability of Sigfox, Narrowband Internet of Things (NB-IoT), and The Things Network at sea has been explored. We found that NB-IoT and Sigfox can be used for IoT applications in the tested area at low antenna heights.      
### 9.Control Analysis and Synthesis of Data-Driven Learning: A Kalman State-Space Approach  [ :arrow_down: ](https://arxiv.org/pdf/2012.05643.pdf)
>  This paper aims to deal with the control analysis and synthesis problem of data-driven learning, regardless of unknown plant models and iteration-varying uncertainties. For the tracking of any desired target, a Kalman state-space approach is presented to transform it into two robust stability problems, which bridges a connection between data-driven control and model-based control. This approach also makes it possible to employ the extended state observer (ESO) in the design of data-driven learning to overcome the effect of iteration-varying uncertainties. It is shown that ESO-based data-driven learning ensures model-free systems to achieve the tracking of any desired target. In particular, our results apply to iterative learning control, which is verified by an example.      
### 10.Performance Comparison of Balanced and Unbalanced Cancer Datasets using Pre-Trained Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.05585.pdf)
>  Cancer disease is one of the leading causes of death all over the world. Breast cancer, which is a common cancer disease especially in women, is quite common. The most important tool used for early detection of this cancer type, which requires a long process to establish a definitive diagnosis, is histopathological images taken by biopsy. These obtained images are examined by pathologists and a definitive diagnosis is made. It is quite common to detect this process with the help of a computer. Detection of benign or malignant tumors, especially by using data with different magnification rates, takes place in the literature. In this study, two different balanced and unbalanced study groups have been formed by using the histopathological data in the BreakHis data set. We have examined how the performances of balanced and unbalanced data sets change in detecting tumor type. In conclusion, in the study performed using the InceptionV3 convolution neural network model, 93.55% accuracy, 99.19% recall and 87.10% specificity values have been obtained for balanced data, while 89.75% accuracy, 82.89% recall and 91.51% specificity values have been obtained for unbalanced data. According to the results obtained in two different studies, the balance of the data increases the overall performance as well as the detection performance of both benign and malignant tumors. It can be said that the model trained with the help of data sets created in a balanced way will give pathology specialists higher and accurate results.      
### 11.Effect of Different Batch Size Parameters on Predicting of COVID19 Cases  [ :arrow_down: ](https://arxiv.org/pdf/2012.05534.pdf)
>  The new coronavirus 2019, also known as COVID19, is a very serious epidemic that has killed thousands or even millions of people since December 2019. It was defined as a pandemic by the world health organization in March 2020. It is stated that this virus is usually transmitted by droplets caused by sneezing or coughing, or by touching infected surfaces. The presence of the virus is detected by real-time reverse transcriptase polymerase chain reaction (rRT-PCR) tests with the help of a swab taken from the nose or throat. In addition, X-ray and CT imaging methods are also used to support this method. Since it is known that the accuracy sensitivity in rRT-PCR test is low, auxiliary diagnostic methods have a very important place. Computer-aided diagnosis and detection systems are developed especially with the help of X-ray and CT images. Studies on the detection of COVID19 in the literature are increasing day by day. In this study, the effect of different batch size (BH=3, 10, 20, 30, 40, and 50) parameter values on their performance in detecting COVID19 and other classes was investigated using data belonging to 4 different (Viral Pneumonia, COVID19, Normal, Bacterial Pneumonia) classes. The study was carried out using a pre-trained ResNet50 convolutional neural network. According to the obtained results, they performed closely on the training and test data. However, it was observed that the steady state in the test data was delayed as the batch size value increased. The highest COVID19 detection was 95.17% for BH = 3, while the overall accuracy value was 97.97% with BH = 20. According to the findings, it can be said that the batch size value does not affect the overall performance significantly, but the increase in the batch size value delays obtaining stable results.      
### 12.Data-Efficient Framework for Real-world Multiple Sound Source 2D Localization  [ :arrow_down: ](https://arxiv.org/pdf/2012.05533.pdf)
>  Deep neural networks have recently led to promising results for the task of multiple sound source localization. Yet, they require a lot of training data to cover a variety of acoustic conditions and microphone array layouts. One can leverage acoustic simulators to inexpensively generate labeled training data. However, models trained on synthetic data tend to perform poorly with real-world recordings due to the domain mismatch. Moreover, learning for different microphone array layouts makes the task more complicated due to the infinite number of possible layouts. We propose to use adversarial learning methods to close the gap between synthetic and real domains. Our novel ensemble-discrimination method significantly improves the localization performance without requiring any label from the real data. Furthermore, we propose a novel explicit transformation layer to be embedded in the localization architecture. It enables the model to be trained with data from specific microphone array layouts while generalizing well to unseen layouts during inference.      
### 13.Detection of Covid-19 Patients with Convolutional Neural Network Based Features on Multi-class X-ray Chest Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.05525.pdf)
>  Covid-19 is a very serious deadly disease that has been announced as a pandemic by the world health organization (WHO). The whole world is working with all its might to end Covid-19 pandemic, which puts countries in serious health and economic problems, as soon as possible. The most important of these is to correctly identify those who get the Covid-19. Methods and approaches to support the reverse transcription polymerase chain reaction (RT-PCR) test have begun to take place in the literature. In this study, chest X-ray images, which can be accessed easily and quickly, were used because the covid-19 attacked the respiratory systems. Classification performances with support vector machines have been obtained by using the features extracted with residual networks (ResNet-50), one of the convolutional neural network models, from these images. While Covid-19 detection is obtained with support vector machines (SVM)-quadratic with the highest sensitivity value of 96.35% with the 5-fold cross-validation method, the highest overall performance value has been detected with both SVM-quadratic and SVM-cubic above 99%. According to these high results, it is thought that this method, which has been studied, will help radiology specialists and reduce the rate of false detection.      
### 14.Learning Multiple Sound Source 2D Localization  [ :arrow_down: ](https://arxiv.org/pdf/2012.05515.pdf)
>  In this paper, we propose novel deep learning based algorithms for multiple sound source localization. Specifically, we aim to find the 2D Cartesian coordinates of multiple sound sources in an enclosed environment by using multiple microphone arrays. To this end, we use an encoding-decoding architecture and propose two improvements on it to accomplish the task. In addition, we also propose two novel localization representations which increase the accuracy. Lastly, new metrics are developed relying on resolution-based multiple source association which enables us to evaluate and compare different localization approaches. We tested our method on both synthetic and real world data. The results show that our method improves upon the previous baseline approach for this problem.      
### 15.COVID-MTL: Multitask Learning with Shift3D and Random-weighted Loss for Diagnosis and Severity Assessment of COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2012.05509.pdf)
>  The outbreak of COVID-19 has resulted in over 67 million infections with over 1.5 million deaths worldwide so far. Both computer tomography (CT) diagnosis and nucleic acid test (NAT) have their pros and cons. Here we present a multitask-learning (MTL) framework, termed COVID-MTL, which is capable of simultaneously detecting COVID-19 against both radiology and NAT as well as assessing infection severity. We proposed an active-contour based method to refine lung segmentation results on COVID-19 CT scans and a Shift3D real-time 3D augmentation algorithm to improve the convergence and accuracy of state-of-the-art 3D CNNs. A random-weighted multitask loss function was then proposed, which made simultaneous learning of different COVID-19 tasks more stable and accurate. By only using CT data and extracting lung imaging features, COVID-MTL was trained on 930 CT scans and tested on another 399 cases, which yielded AUCs of 0.939 and 0.846, and accuracies of 90.23% and 79.20% for detection of COVID-19 against radiology and NAT, respectively, and outperformed state-of-the-art models. COVID-MTL yielded AUC of 0.800 $\pm$ 0.020 and 0.813 $\pm$ 0.021 (with transfer learning) for classifying control/suspected (AUC of 0.841), mild/regular (AUC of 0.808), and severe/critically-ill (AUC of 0.789) cases. Besides, we identified top imaging biomarkers that are significantly related (P &lt; 0.001) to the positivity and severity of COVID-19.      
### 16.Deep learning methods for SAR image despeckling: trends and perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2012.05508.pdf)
>  Synthetic aperture radar (SAR) images are affected by a spatially-correlated and signal-dependent noise called speckle, which is very severe and may hinder image exploitation. Despeckling is an important task that aims at removing such noise, so as to improve the accuracy of all downstream image processing tasks. The first despeckling methods date back to the 1970's, and several model-based algorithms have been developed in the subsequent years. The field has received growing attention, sparkled by the availability of powerful deep learning models that have yielded excellent performance for inverse problems in image processing. This paper surveys the literature on deep learning methods applied to SAR despeckling, covering both the supervised and the more recent self-supervised approaches. We provide a critical analysis of existing methods with the objective to recognize the most promising research lines, to identify the factors that have limited the success of deep models, and to propose ways forward in an attempt to fully exploit the potential of deep learning for SAR despeckling.      
### 17.Machine learning for nocturnal diagnosis of chronic obstructive pulmonary disease using digital oximetry biomarkers  [ :arrow_down: ](https://arxiv.org/pdf/2012.05492.pdf)
>  Objective: Chronic obstructive pulmonary disease (COPD) is a highly prevalent chronic condition. COPD is a major source of morbidity, mortality and healthcare costs. Spirometry is the gold standard test for a definitive diagnosis and severity grading of COPD. However, a large proportion of individuals with COPD are undiagnosed and untreated. Given the high prevalence of COPD and its clinical importance, it is critical to develop new algorithms to identify undiagnosed COPD, especially in specific groups at risk, such as those with sleep disorder breathing. To our knowledge, no research has looked at the feasibility of COPD diagnosis from the nocturnal oximetry time series. Approach: We hypothesize that patients with COPD will exert certain patterns and/or dynamics of their overnight oximetry time series that are unique to this condition. We introduce a novel approach to nocturnal COPD diagnosis using 44 oximetry digital biomarkers and 5 demographic features and assess its performance in a population sample at risk of sleep-disordered breathing. A total of n=350 unique patients polysomnography (PSG) recordings. A random forest (RF) classifier is trained using these features and evaluated using the nested cross-validation procedure. Significance: Our research makes a number of novel scientific contributions. First, we demonstrated for the first time, the feasibility of COPD diagnosis from nocturnal oximetry time series in a population sample at risk of sleep disordered breathing. We highlighted what digital oximetry biomarkers best reflect how COPD manifests overnight. The results motivate that overnight single channel oximetry is a valuable pathway for COPD diagnosis.      
### 18.Structure Preserving Reduced Attitude Control of Gyroscopes  [ :arrow_down: ](https://arxiv.org/pdf/2012.05468.pdf)
>  We design a reduced attitude controller for reorienting the spin axis of a gyroscope in a geometric control framework. The proposed controller preserves the inherent gyroscopic stability associated with a spinning axis-symmetric rigid body. The equations of motion are derived in two frames: a non-spinning frame to show the gyroscopic stability, and a body-fixed spinning frame for deriving the controller. The proposed controller is designed such that it retains the gyroscopic stability structure in the closed loop and renders the desired equilibrium almost-globally asymptotically stable. Due to the time-critical nature of the control input, in particular its sensitivity with respect to delays/neglected dynamics, the controller is extended to incorporate the effect of actuator dynamics for practical implementation. Thereafter, a comparison in performance is shown between the proposed controller and a conventional reduced attitude geometric controller with numerical simulation. The controller is validated experimentally on a spinning tricopter.      
### 19.T-WaveNet: Tree-Structured Wavelet Neural Network for Sensor-Based Time Series Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2012.05456.pdf)
>  Sensor-based time series analysis is an essential task for applications such as activity recognition and brain-computer interface. Recently, features extracted with deep neural networks (DNNs) are shown to be more effective than conventional hand-crafted ones. However, most of these solutions rely solely on the network to extract application-specific information carried in the sensor data. Motivated by the fact that usually a small subset of the frequency components carries the primary information for sensor data, we propose a novel tree-structured wavelet neural network for sensor data analysis, namely \emph{T-WaveNet}. To be specific, with T-WaveNet, we first conduct a power spectrum analysis for the sensor data and decompose the input signal into various frequency subbands accordingly. Then, we construct a tree-structured network, and each node on the tree (corresponding to a frequency subband) is built with an invertible neural network (INN) based wavelet transform. By doing so, T-WaveNet provides more effective representation for sensor information than existing DNN-based techniques, and it achieves state-of-the-art performance on various sensor datasets, including UCI-HAR for activity recognition, OPPORTUNITY for gesture recognition, BCICIV2a for intention recognition, and NinaPro DB1 for muscular movement recognition.      
### 20.Automatic Generation of Interpretable Lung Cancer Scoring Models from Chest X-Ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.05447.pdf)
>  Lung cancer is the leading cause of cancer death and morbidity worldwide with early detection being the key to a positive patient prognosis. Although a multitude of studies have demonstrated that machine learning, and particularly deep learning, techniques are effective at automatically diagnosing lung cancer, these techniques have yet to be clinically approved and accepted/adopted by the medical community. Rather than attempting to provide an artificial 'second reading' we instead focus on the automatic creation of viable decision tree models from publicly available data using computer vision and machine learning techniques. For a small inferencing dataset, this method achieves a best accuracy over 84% with a positive predictive value of 83% for the malignant class. Furthermore, the decision trees created by this process may be considered as a starting point for refinement by medical experts into clinically usable multi-variate lung cancer scoring and diagnostic models.      
### 21.Plasma Switch-Based Technology for High-Speed and High-Power Impedance Tuning  [ :arrow_down: ](https://arxiv.org/pdf/2012.05411.pdf)
>  This paper introduces a new technology for a high-speed, high-power mobile form-factor tuner utilizing gas discharge tube plasma cells as switching components. To the best of our knowledge, this represents the first plasma-enabled RF matching network. Technology development is reviewed, the fabrication and measurement of a proof-of-concept switched stub impedance tuner are presented, and techniques for improvement are discussed. The proof-of-concept impedance tuner functions with a 27% bandwidth from 3 to almost 4 GHz and shows a power gain better than -2.5 dB across all switching state-frequency combinations at a 50 W input power level with spread coverage of the Smith chart. State change transient timing is measured to be on the order of 500 ns. This technology demonstration highlights the potential of miniaturized, rapidly-tunable, high-power, plasma-based RF devices.      
### 22.Calibrationless MRI Reconstruction with a Plug-in Denoiser  [ :arrow_down: ](https://arxiv.org/pdf/2012.05393.pdf)
>  Magnetic Resonance Imaging (MRI) is a noninvasive imaging technique that provides excellent soft-tissue contrast without using ionizing radiation. MRI's clinical application may be limited by long data acquisition time; therefore, MR image reconstruction from highly under-sampled k-space data has been an active research area. Calibrationless MRI not only enables a higher acceleration rate but also increases flexibility for sampling pattern design. To leverage non-linear machine learning priors, we pair our High-dimensional Fast Convolutional Framework (HICU) with a plug-in denoiser and demonstrate its feasibility using 2D brain data.      
### 23.A Database of Dorsal Hand Vein Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.05383.pdf)
>  The dorsal hand vein has been demonstrated as a useful biometric for identity verification. This work details the procedure taken to collect two databases of dorsal hand veins in a biometric recognition project. The purpose of this work is to serve as a reference for the databases that are being shared with the public.      
### 24.Semantic Communications for Speech Signals  [ :arrow_down: ](https://arxiv.org/pdf/2012.05369.pdf)
>  We consider a semantic communication system for speech signals, named SCS. Motivated by the breakthroughs in deep learning, we explore the speech semantic to recover semantic meaning of the speech at the receiver, which aims to minimize the speech semantic error rather than the bit-error rate or symbol-error rate in traditional communications. Particularly, based on the attention mechanism squeeze-and-excitation (SE) networks, we design the transceiver as an end-to-end (E2E) system, which extracts and learns the essential speech information. Furthermore, in order to facilitate the E2E speech semantic communication system to work well on various practical communication scenarios, we find a model yielding good performance when coping with various channel environments without retraining process. The simulation results demonstrate that our proposed SCS is more robust to channel variations and outperforms traditional communication systems, especially in the low signal-to-noise (SNR) regime.      
### 25.Generation of global vegetation products from EUMETSAT AVHRR/METOP satellites  [ :arrow_down: ](https://arxiv.org/pdf/2012.05367.pdf)
>  We describe the methodology applied for the retrieval of global LAI, FAPAR and FVC from Advanced Very High Resolution Radiometer (AVHRR) onboard the Meteorological-Operational (MetOp) polar orbiting satellites also known as EUMETSAT Polar System (EPS). A novel approach has been developed for the joint retrieval of three parameters (LAI, FVC, and FAPAR) instead of training one model per parameter. The method relies on multi-output Gaussian Processes Regression (GPR) trained over PROSAIL EPS simulations. A sensitivity analysis is performed to assess several sources of uncertainties in retrievals and maximize the positive impact of modeling the noise in training simulations. We describe the main features of the operational processing chain along with the current status of the global EPS vegetation products, including details about its overall quality and preliminary assessment of the products based on intercomparison with equivalent (MODIS, PROBA-V) satellite vegetation products.      
### 26.Electric Vehicle Battery Remaining Charging Time Estimation Considering Charging Accuracy and Charging Profile Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2012.05352.pdf)
>  Electric vehicles (EVs) have been growing rapidly in popularity in recent years and have become a future trend. It is an important aspect of user experience to know the Remaining Charging Time (RCT) of an EV with confidence. However, it is difficult to find an algorithm that accurately estimates the RCT for vehicles in the current EV market. The maximum RCT estimation error of the Tesla Model X can be as high as 60 minutes from a 10 % to 99 % state-of-charge (SOC) while charging at direct current (DC). A highly accurate RCT estimation algorithm for electric vehicles is in high demand and will continue to be as EVs become more popular. There are currently two challenges to arriving at an accurate RCT estimate. First, most commercial chargers cannot provide requested charging currents during a constant current (CC) stage. Second, it is hard to predict the charging current profile in a constant voltage (CV) stage. To address the first issue, this study proposes an RCT algorithm that updates the charging accuracy online in the CC stage by considering the confidence interval between the historical charging accuracy and real-time charging accuracy data. To solve the second issue, this study proposes a battery resistance prediction model to predict charging current profiles in the CV stage, using a Radial Basis Function (RBF) neural network (NN). The test results demonstrate that the RCT algorithm proposed in this study achieves an error rate improvement of 73.6 % and 84.4 % over the traditional method in the CC and CV stages, respectively.      
### 27.Tube-based Guaranteed Cost Robust Model Predictive Control for Linear Systems Subject to Parametric Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2012.05349.pdf)
>  We propose a tube-based guaranteed cost model predictive controller considering a homothetic formulation for constrained linear systems subject to multiplicative structured norm-bounded uncertainties. It provides an upper bound to the general min-max model predictive control. The invariance property of the proposed tube holds for any arbitrary scaling. It yields a second-order cone programming problem which is less computationally expensive than standard semi-definite programming problems. We also present a numerical example with a comparative study among the proposed approach, an open-loop guaranteed cost model predictive controller, and a homothetic tube model predictive controller for linear difference inclusion systems.      
### 28.Tube-based Guaranteed Cost Model Predictive Control Applied to Autonomous Driving Up to the Limits of Handling  [ :arrow_down: ](https://arxiv.org/pdf/2012.05334.pdf)
>  The development of control techniques to maintain vehicle stability under possible loss-of-control scenarios is essential to the safe deployment of autonomous ground vehicles in public scenarios. In this paper, we propose a tube-based guaranteed cost model predictive controller for autonomous vehicles able to avoid front and rear tire saturation and to track a provided reference trajectory up to the limits of handling of the vehicle. Such an approach ensures the vehicle will remain within its safe operational envelope; therefore, guaranteeing both stability and performance of the vehicle, including highly dynamic maneuvers that may be necessary for emergency conditions. We also propose a new conservative approximation of the nonlinear vehicle dynamics to a linear system subject to norm bounded multiplicative uncertainties and a new maximal robust controllable invariant set for vehicle dynamics. It consists of a larger feasible state-space region when compared to previously proposed invariant sets. Finally, we present both simulation and in-vehicle results of the performance of the proposed approach.      
### 29.Unsupervised Adversarial Domain Adaptation For Barrett's Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2012.05316.pdf)
>  Barrett's oesophagus (BE) is one of the early indicators of esophageal cancer. Patients with BE are monitored and undergo ablation therapies to minimise the risk, thereby making it eminent to identify the BE area precisely. Automated segmentation can help clinical endoscopists to assess and treat BE area more accurately. Endoscopy imaging of BE can include multiple modalities in addition to the conventional white light (WL) modality. Supervised models require large amount of manual annotations incorporating all data variability in the training data. However, it becomes cumbersome, tedious and labour intensive work to generate manual annotations, and additionally modality specific expertise is required. In this work, we aim to alleviate this problem by applying an unsupervised domain adaptation technique (UDA). Here, UDA is trained on white light endoscopy images as source domain and are well-adapted to generalise to produce segmentation on different imaging modalities as target domain, namely narrow band imaging and post acetic-acid WL imaging. Our dataset consists of a total of 871 images consisting of both source and target domains. Our results show that the UDA-based approach outperforms traditional supervised U-Net segmentation by nearly 10% on both Dice similarity coefficient and intersection-over-union.      
### 30.Distributed and Scalable Uplink Processing for LIS: Algorithm, Architecture, and Design Trade-offs  [ :arrow_down: ](https://arxiv.org/pdf/2012.05296.pdf)
>  The Large Intelligent Surface (LIS) is a promising technology in the areas of wireless communication, remote sensing and positioning. It consists of a continuous radiating surface located in the proximity of the users, with the capability to communicate by transmission and reception (replacing base stations). Despite of its potential, there are numerous challenges from implementation point of view, being the interconnection data-rate, computational complexity, and storage the most relevant ones. In order to address those challenges, hierarchical architectures with distributed processing techniques are envisioned to to be relevant for this task, while ensuring scalability. In this work we perform algorithm-architecture codesign to propose two distributed interference cancellation algorithms, and a tree-based interconnection topology for uplink processing. We also analyze the performance, hardware requirements, and architecture tradeoffs for a discrete LIS, in order to provide concrete case studies and guidelines for efficient implementation of LIS systems.      
### 31.Revisiting the Water Quality Sensor Placement Problem: Optimizing Network Observability and State Estimation Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2012.05268.pdf)
>  Real-time water quality (WQ) sensors in water distribution networks (WDN) have the potential to enable network-wide observability of water quality indicators, contamination event detection, and closed-loop feedback control of WQ dynamics. To that end, prior research has investigated a wide range of methods that guide the geographic placement of WQ sensors. These methods assign a metric for fixed sensor placement (SP) followed by \textit{metric-optimization} to obtain optimal SP. These metrics include minimizing intrusion detection time, minimizing the expected population and amount of contaminated water affected by an intrusion event. In contrast to the literature, the objective of this paper is to provide a computational method that considers the overlooked metric of state estimation and network-wide observability of the WQ dynamics. This metric finds the optimal WQ sensor placement that minimizes the state estimation error via the Kalman filter for noisy WQ dynamics -- a metric that quantifies WDN observability. To that end, the state-space dynamics of WQ states for an entire WDN are given and the observability-driven sensor placement algorithm is presented. The algorithm takes into account the time-varying nature of WQ dynamics due to changes in the hydraulic profile -- a collection of hydraulic states including heads (pressures) at nodes and flow rates in links which are caused by a demand profile over a certain period of time. Thorough case studies are given, highlighting key findings, observations, and recommendations for WDN operators. Github codes are included for reproducibility.      
### 32.Sylvester Matrix Based Similarity Estimation Method for Automation of Defect Detection in Textile Fabrics  [ :arrow_down: ](https://arxiv.org/pdf/2012.05800.pdf)
>  Fabric defect detection is a crucial quality control step in the textile manufacturing industry. In this article, machine vision system based on the Sylvester Matrix Based Similarity Method (SMBSM) is proposed to automate the defect detection process. The algorithm involves six phases, namely resolution matching, image enhancement using Histogram Specification and Median-Mean Based Sub-Image-Clipped Histogram Equalization, image registration through alignment and hysteresis process, image subtraction, edge detection, and fault detection by means of the rank of the Sylvester matrix. The experimental results demonstrate that the proposed method is robust and yields an accuracy of 93.4%, precision of 95.8%, with 2275 ms computational speed.      
### 33.Efficient Nonlinear RX Anomaly Detectors  [ :arrow_down: ](https://arxiv.org/pdf/2012.05799.pdf)
>  Current anomaly detection algorithms are typically challenged by either accuracy or efficiency. More accurate nonlinear detectors are typically slow and not scalable. In this letter, we propose two families of techniques to improve the efficiency of the standard kernel Reed-Xiaoli (RX) method for anomaly detection by approximating the kernel function with either {\em data-independent} random Fourier features or {\em data-dependent} basis with the Nyström approach. We compare all methods for both real multi- and hyperspectral images. We show that the proposed efficient methods have a lower computational cost and they perform similar (or outperform) the standard kernel RX algorithm thanks to their implicit regularization effect. Last but not least, the Nyström approach has an improved power of detection.      
### 34.Packaging of Thick Membranes using a Multi-Spiral Folding Approach: Flat and Curved Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2012.05723.pdf)
>  Elucidating versatile configurations of spiral folding, and investigating the deployment performance is of relevant interest to extend the applicability of deployable membranes towards large-scale and functional configurations. <br>In this paper we propose new schemes to package flat and curved membranes of finite thickness by using multiple spirals, whose governing equations render folding lines by juxtaposing spirals and by accommodating membrane thickness. Our experiments using a set of topologically distinct flat and curved membranes deployed by tensile forces applied in the radial and circumferential directions have shown that (1) the multi-spiral approach with prismatic folding lines offered the improved deployment performance, and (2) the deployment of curved surfaces progresses rapidly within a finite load domain. Furthermore, we confirmed the high efficiency of membranes folded by multi-spiral patterns. <br>From viewpoints of configuration and deployment performance, the multi-spiral approach is potential to extend the versatility and maneuverability of spiral folding mechanisms.      
### 35.TFPnP: Tuning-free Plug-and-Play Proximal Algorithm with Applications to Inverse Imaging Problems  [ :arrow_down: ](https://arxiv.org/pdf/2012.05703.pdf)
>  Plug-and-Play (PnP) is a non-convex framework that combines proximal algorithms, for example alternating direction method of multipliers (ADMM), with advanced denoiser priors. Over the past few years, great empirical success has been obtained by PnP algorithms, especially for the ones integrated with deep learning-based denoisers. However, a crucial issue of PnP approaches is the need of manual parameter tweaking. As it is essential to obtain high-quality results across the high discrepancy in terms of imaging conditions and varying scene content. In this work, we present a tuning-free PnP proximal algorithm, which can automatically determine the internal parameters including the penalty parameter, the denoising strength and the termination time. A core part of our approach is to develop a policy network for automatic search of parameters, which can be effectively learned via mixed model-free and model-based deep reinforcement learning. We demonstrate, through a set of numerical and visual experiments, that the learned policy can customize different parameters for different states, and often more efficient and effective than existing handcrafted criteria. Moreover, we discuss the practical considerations of the plugged denoisers, which together with our learned policy yield to state-of-the-art results. This is prevalent on both linear and nonlinear exemplary inverse imaging problems, and in particular, we show promising results on compressed sensing MRI, sparse-view CT and phase retrieval.      
### 36.Increased performance in DDM analysis by calculating structure functions through Fourier transform in time  [ :arrow_down: ](https://arxiv.org/pdf/2012.05695.pdf)
>  Differential Dynamic Microscopy (DDM) is the combination of optical microscopy to statistical analysis to obtain information about the dynamical behaviour of a variety of samples spanning from soft matter physics to biology. In DDM, the dynamical evolution of the samples is investigated separately at different length scales and extracted from a set of images recorded at different times. A specific result of interest is the structure function that can be computed via spatial Fourier transforms and differences of signals. In this work, we present an algorithm to efficiently process a set of images according to the DDM analysis scheme. We bench-marked the new approach against the state-of-the-art algorithm reported in previous work. The new implementation computes the DDM analysis faster, thanks to an additional Fourier transform in time instead of performing differences of signals. This allows obtaining very fast analysis also in CPU based machine. In order to test the new code, we performed the DDM analysis over sets of more than 1000 images with and without the help of GPU hardware acceleration. As an example, for images of $512 \times 512$ pixels, the new algorithm is 10 times faster than the previous GPU code. Without GPU hardware acceleration and for the same set of images, we found that the new algorithm is 300 faster than the old one both running only on the CPU.      
### 37.Analytical phase optical transfer function for Gaussian illumination and the optimized profiles  [ :arrow_down: ](https://arxiv.org/pdf/2012.05690.pdf)
>  The imaging performance of tomographic deconvolution phase microscopy can be described in terms of the phase optical transfer function (POTF) which, in turn, depends on the illumination profile. To facilitate the optimization of the illumination profile, an analytical calculation method based on polynomial fitting is developed to describe the POTF for general non-uniform axially-symmetric illumination. This is then applied to Gaussian and related profiles. Compared to numerical integration methods that integrate over a series of annuli, the present analytical method is much faster and is equally accurate. Further, a balanced distribution criterion for the POTF and a least-squares minimization are presented to optimize the uniformity of the POTF. An optimum general profile is found analytically by relaxed optimal search and an optimum Gaussian profile is found through a tree search. Numerical simulations confirm the performance of these optimum profiles and support the balanced distribution criterion introduced.      
### 38.Direct multimodal few-shot learning of speech and images  [ :arrow_down: ](https://arxiv.org/pdf/2012.05680.pdf)
>  We propose direct multimodal few-shot models that learn a shared embedding space of spoken words and images from only a few paired examples. Imagine an agent is shown an image along with a spoken word describing the object in the picture, e.g. pen, book and eraser. After observing a few paired examples of each class, the model is asked to identify the "book" in a set of unseen pictures. Previous work used a two-step indirect approach relying on learned unimodal representations: speech-speech and image-image comparisons are performed across the support set of given speech-image pairs. We propose two direct models which instead learn a single multimodal space where inputs from different modalities are directly comparable: a multimodal triplet network (MTriplet) and a multimodal correspondence autoencoder (MCAE). To train these direct models, we mine speech-image pairs: the support set is used to pair up unlabelled in-domain speech and images. In a speech-to-image digit matching task, direct models outperform indirect models, with the MTriplet achieving the best multimodal five-shot accuracy. We show that the improvements are due to the combination of unsupervised and transfer learning in the direct models, and the absence of two-step compounding errors.      
### 39.On the MIMO Secrecy Capacity of MIMO Wiretap Channels: Convex Reformulation and Efficient Numerical Methods  [ :arrow_down: ](https://arxiv.org/pdf/2012.05667.pdf)
>  This paper presents novel numerical approaches to finding the secrecy capacity of the multiple-input multiple-output (MIMO) wiretap channel subject to multiple linear transmit covariance constraints, including sum power constraint, per antenna power constraints and interference power constraint. An analytical solution to this problem is not known and existing numerical solutions suffer from slow convergence rate and/or high per-iteration complexity. Deriving computationally efficient solutions to the secrecy capacity problem is challenging since the secrecy rate is expressed as a difference of convex functions (DC) of the transmit covariance matrix, for which its convexity is only known for some special cases. In this paper we propose two low-complexity methods to compute the secrecy capacity along with a convex reformulation for degraded channels. In the first method we capitalize on the accelerated DC algorithm which requires solving a sequence of convex subproblems, for which we propose an efficient iterative algorithm where each iteration admits a closed-form solution. In the second method, we rely on the concave-convex equivalent reformulation of the secrecy capacity problem which allows us to derive the so-called partial best response algorithm to obtain an optimal solution. Notably, each iteration of the second method can also be done in closed form. The simulation results demonstrate a faster convergence rate of our methods compared to other known solutions. We carry out extensive numerical experiments to evaluate the impact of various parameters on the achieved secrecy capacity.      
### 40.Experimental phase control of a 100 laser beam array with quasi-reinforcement learning of a neural network in an error reduction loop  [ :arrow_down: ](https://arxiv.org/pdf/2012.05647.pdf)
>  An innovative scheme is proposed for the dynamic control of phase in two-dimensional laser beam array. It is based on a simple neural network that predicts the complex field array from the intensity of the induced scattered pattern through a phase intensity transformer made of a diffuser. Iterated phase corrections are applied on the laser field array by phase modulators via a feedback loop to set the array to prescribed phase values. A crucial feature is the use of a kind of reinforcement learning approach for the neural network training which takes account of the iterated corrections. Experiments on a proof of concept system demonstrated the high performance and scalability of the scheme with an array of up to 100 laser beams and a phase setting at 1/30 of the wavelength.      
### 41.Intelligent Reflecting Surface-Aided SWIPT: Joint Waveform, Active and Passive Beamforming Design  [ :arrow_down: ](https://arxiv.org/pdf/2012.05646.pdf)
>  The performance of Simultaneous Wireless Information and Power Transfer (SWIPT) is severely restricted by the strength of the received Radio-Frequency (RF) signal. To tackle this problem, we introduce a low-power Intelligent Reflecting Surface (IRS) that compensates the propagation loss and boosts the transmission efficiency by a passive beamforming gain. This paper investigates an efficient IRS-aided SWIPT architecture where a multi-carrier multi-antenna Access Point (AP) transmits information and power simultaneously to a single-antenna user under the assist of an IRS. Considering energy harvester nonlinearity, we aim to maximize the Rate-Energy (R-E) tradeoff through a joint optimization of the transmit waveform and active beamforming at the AP, the reflection coefficients at the IRS, and the power splitting ratio at the user. Stationary solutions are achieved by the Alternating Optimization (AO) technique, where the optimal active beamforming is obtained in closed form, the passive beamforming is optimized by the Successive Convex Approximation (SCA) technique, and the waveform and splitting ratio are optimized by the Geometric Programming (GP) technique. Although practical IRS is limited to Frequency-Flat (FF) reflection, results demonstrate significant benefits of the proposed architecture based on a joint waveform and beamforming design to enlarge the R-E region of IRS-aided SWIPT.      
### 42.Weakly Supervised Arrhythmia Detection Based on Deep Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.05641.pdf)
>  Supervised deep learning has been widely used in the studies of automatic ECG classification, which largely benefits from sufficient annotation of large datasets. However, most of the existing large ECG datasets are roughly annotated, so the classification model trained on them can only detect the existence of abnormalities in a whole recording, but cannot determine their exact occurrence time. In addition, it may take huge time and economic cost to construct a fine-annotated ECG dataset. Therefore, this study proposes weakly supervised deep learning models for detecting abnormal ECG events and their occurrence time. The available supervision information for the models is limited to the event types in an ECG record, excluding the specific occurring time of each event. By leverage of feature locality of deep convolution neural network, the models first make predictions based on the local features, and then aggregate the local predictions to infer the existence of each event during the whole record. Through training, the local predictions are expected to reflect the specific occurring time of each event. To test their potentials, we apply the models for detecting cardiac rhythmic and morphological arrhythmias by using the AFDB and MITDB datasets, respectively. The results show that the models achieve beat-level accuracies of 99.09% in detecting atrial fibrillation, and 99.13% in detecting morphological arrhythmias, which are comparable to that of fully supervised learning models, demonstrating their effectiveness. The local prediction maps revealed by this method are also helpful to analyze and diagnose the decision logic of record-level classification models.      
### 43.An Overview of 5G System Accessibility Control and Differentiation  [ :arrow_down: ](https://arxiv.org/pdf/2012.05520.pdf)
>  5G system is characterized by its capability to support a wide range of use cases and services. Supporting accessibility differentiation becomes therefore essential to preserve a stable network condition during high traffic load, while ensuring connection and service quality to prioritized devices and services. In this article, we describe some use cases and requirements that impact the 3GPP design of the 5G accessibility differentiation framework. We then provide an overview of the supported mechanisms for accessibility control in 5G Stand Alone (SA) system, including cell barring and reservation, unified access control, paging control, random access control and admission control. We discuss how these functionalities can be used to maintain the service quality and selectively limit the incoming traffic to the network at high load situations, leveraging different connection-type indicators and connection-priority identifiers.      
### 44.Monetizing Customer Load Data for an Energy Retailer: A Cooperative Game Approach  [ :arrow_down: ](https://arxiv.org/pdf/2012.05519.pdf)
>  When energy customers schedule loads ahead of time, this information, if acquired by their energy retailer, can improve the retailer's load forecasts. Better forecasts lead to wholesale purchase decisions that are likely to result in lower energy imbalance costs, and thus higher profits for the retailer. Therefore, this paper monetizes the value of the customer schedulable load data by quantifying the retailer's profit gain from adjusting the wholesale purchase based on such data. Using a cooperative game theoretic approach, the retailer translates their increased profit in expectation into the value of cooperation, and redistributes a portion of it among the customers as monetary incentives for them to continue providing their load data. Through case studies, this paper demonstrates the significance of the additional profit for the retailer from using the proposed framework, and evaluates the long-term monetary benefits to the customers based on different payoff allocation methods.      
### 45.Edge Computing Assisted Autonomous Flight for UAV: Synergies between Vision and Communications  [ :arrow_down: ](https://arxiv.org/pdf/2012.05517.pdf)
>  Autonomous flight for UAVs relies on visual information for avoiding obstacles and ensuring a safe collision-free flight. In addition to visual clues, safe UAVs often need connectivity with the ground station. In this paper, we study the synergies between vision and communications for edge computing-enabled UAV flight. By proposing a framework of Edge Computing Assisted Autonomous Flight (ECAAF), we illustrate that vision and communications can interact with and assist each other with the aid of edge computing and offloading, and further speed up the UAV mission completion. ECAAF consists of three functionalities that are discussed in detail: edge computing for 3D map acquisition, radio map construction from the 3D map, and online trajectory planning. During ECAAF, the interactions of communication capacity, video offloading, 3D map quality, and channel state of the trajectory form a positive feedback loop. Simulation results verify that the proposed method can improve mission performance by enhancing connectivity. Finally, we conclude with some future research directions.      
### 46.SE-ECGNet: A Multi-scale Deep Residual Network with Squeeze-and-Excitation Module for ECG Signal Classification  [ :arrow_down: ](https://arxiv.org/pdf/2012.05510.pdf)
>  The classification of electrocardiogram (ECG) signals, which takes much time and suffers from a high rate of misjudgment, is recognized as an extremely challenging task for cardiologists. The major difficulty of the ECG signals classification is caused by the long-term sequence dependencies. Most existing approaches for ECG signal classification use Recurrent Neural Network models, e.g., LSTM and GRU, which are unable to extract accurate features for such long sequences. Other approaches utilize 1-Dimensional Convolutional Neural Network (CNN), such as ResNet or its variant, and they can not make good use of the multi-lead information from ECG signals.Based on the above observations, we develop a multi-scale deep residual network for the ECG signal classification task. We are the first to propose to treat the multi-lead signal as a 2-dimensional matrix and combines multi-scale 2-D convolution blocks with 1-D convolution blocks for feature extraction. Our proposed model achieves 99.2% F1-score in the MIT-BIH dataset and 89.4% F1-score in Alibaba dataset and outperforms the state-of-the-art performance by 2% and 3%, respectively, view related code and data at <a class="link-external link-https" href="https://github.com/Amadeuszhao/SE-ECGNet" rel="external noopener nofollow">this https URL</a>      
### 47.Analysis of Outage Latency and Throughput Performance in Industrial Factory 5G TDD Deployments  [ :arrow_down: ](https://arxiv.org/pdf/2012.05507.pdf)
>  The fifth generation (5G) new radio supports a diversity of network deployments. The industrial factory (InF) wireless automation use cases are emerging and drawing an increasing attention of the 5G new radio standardization groups. Therefore, in this paper, we propose a service-aware time division duplexing (TDD) frame selection framework for multi-traffic deployments. We evaluate the performance of the InF network deployments with the state-of-the-art 3GPP modeling assumptions. In particular, we consider the dynamic TDD mode along with optimized uplink power control settings. Multi-traffic coexistence scenarios are also incorporated such that quality of service (QoS) aware dynamic user scheduling and TDD link selection are introduced. Extensive system level simulations are performed in order to evaluate the performance of the proposed solutions, where the proposed QoS-aware scheme shows 68% URLLC outage latency reduction compared to the QoS-unaware solutions. Finally, the paper offers insightful conclusions and design recommendations on the TDD radio frame selection, uplink power control settings and the best QoS-coexistence practices, in order to achieve a decent URLLC outage latency performance in the state-of-the-art InF deployments.      
### 48.Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2012.05481.pdf)
>  In this paper, we present a novel two-pass approach to unify streaming and non-streaming end-to-end (E2E) speech recognition in a single model. Our model adopts the hybrid CTC/attention architecture, in which the conformer layers in the encoder are modified. We propose a dynamic chunk-based attention strategy to allow arbitrary right context length. At inference time, the CTC decoder generates n-best hypotheses in a streaming way. The inference latency could be easily controlled by only changing the chunk size. The CTC hypotheses are then rescored by the attention decoder to get the final result. This efficient rescoring process causes very little sentence-level latency. Our experiments on the open 170-hour AISHELL-1 dataset show that, the proposed method can unify the streaming and non-streaming model simply and efficiently. On the AISHELL-1 test set, our unified model achieves 5.60% relative character error rate (CER) reduction in non-streaming ASR compared to a standard non-streaming transformer. The same model achieves 5.42% CER with 640ms latency in a streaming ASR system.      
### 49.Neural-Swarm2: Planning and Control of Heterogeneous Multirotor Swarms using Learned Interactions  [ :arrow_down: ](https://arxiv.org/pdf/2012.05457.pdf)
>  We present Neural-Swarm2, a learning-based method for motion planning and control that allows heterogeneous multirotors in a swarm to safely fly in close proximity. Such operation for drones is challenging due to complex aerodynamic interaction forces, such as downwash generated by nearby drones and ground effect. Conventional planning and control methods neglect capturing these interaction forces, resulting in sparse swarm configuration during flight. Our approach combines a physics-based nominal dynamics model with learned Deep Neural Networks (DNNs) with strong Lipschitz properties. We evolve two techniques to accurately predict the aerodynamic interactions between heterogeneous multirotors: i) spectral normalization for stability and generalization guarantees of unseen data and ii) heterogeneous deep sets for supporting any number of heterogeneous neighbors in a permutation-invariant manner without reducing expressiveness. The learned residual dynamics benefit both the proposed interaction-aware multi-robot motion planning and the nonlinear tracking control designs because the learned interaction forces reduce the modelling errors. Experimental results demonstrate that Neural-Swarm2 is able to generalize to larger swarms beyond training cases and significantly outperforms a baseline nonlinear tracking controller with up to three times reduction in worst-case tracking errors.      
### 50.Accelerated Randomized Methods for Receiver Design in Extra-Large Scale MIMO Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2012.05409.pdf)
>  Recent interest has been cast on accelerated versions of the randomized Kaczmarz (RK) algorithm due to the increase in applications that consider sparse linear systems. In particular, considering the context of massive multiple-input-multiple-output (M-MIMO) communication systems, a low complexity naive RK-based receiver has recently been proposed. This method can take advantage of non-stationarities emerging from extra-large M-MIMO systems, but it performs poorly on highly spatially correlated channels. To address this problem, in this paper, we propose a new class of accelerated RK-based receiver designs, where convergence acceleration is based on the residual information. However, we show that the cost of obtaining this knowledge on an iteration basis is not worth it due to the lousy convergence effects caused by system and channel parameters. Inspired by this observation, we further propose a RK-based receiver with sampling without replacement, referred to as RK-RZF. This simple technique is more effective in performing signal detection under reduced complexity. Future works suggest advantage of RK-based receivers to improve current 5G commercial systems and solve the problem of signal detection in other paradigms beyond 5G.      
### 51.Data-Driven Intersection Management Solutions for Mixed Traffic of Human-Driven and Connected and Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2012.05402.pdf)
>  This dissertation proposes two solutions for urban traffic control in the presence of connected and automated vehicles. First a centralized platoon-based controller is proposed for the cooperative intersection management problem that takes advantage of the platooning systems and V2I communication to generate fast and smooth traffic flow at a single intersection. <br>Second, a data-driven approach is proposed for adaptive signal control in the presence of connected vehicles. The proposed system relies on a data-driven method for optimal signal timing and a data-driven heuristic method for estimating routing decisions. It requires no additional sensors to be installed at the intersection, reducing the installation costs compared to typical settings of state-of-the-practice adaptive signal controllers. <br>The proposed traffic controller contains an optimal signal timing module and a traffic state estimator. The signal timing module is a neural network model trained on microscopic simulation data to achieve optimal results according to a given performance metric such as vehicular delay or average queue length. The traffic state estimator relies on connected vehicles' information to estimate the traffic's routing decisions. A heuristic method is proposed to minimize the estimation error. With sufficient parameter tuning, the estimation error decreases as the market penetration rate (MPR) of connected vehicles grows. Estimation error is below 30% for an MPR of 10% and it shrinks below 20% when MPR grows larger than 30%. <br>Simulations showed that the proposed traffic controller outperforms Highway Capacity Manual's methodology and given proper offline parameter tuning, it can decrease average vehicular delay by up to 25%.      
### 52.Facial expressions can detect Parkinson's disease: preliminary evidence from videos collected online  [ :arrow_down: ](https://arxiv.org/pdf/2012.05373.pdf)
>  One of the symptoms of Parkinson's disease (PD) is hypomimia or reduced facial expressions. In this paper, we present a digital biomarker for PD that utilizes the study of micro-expressions. We analyzed the facial action units (AU) from 1812 videos of 604 individuals (61 with PD and 543 without PD, mean age 63.9 yo, sd 7.8 ) collected online using a web-based tool (<a class="link-external link-http" href="http://www.parktest.net" rel="external noopener nofollow">this http URL</a>). In these videos, participants were asked to make three facial expressions (a smiling, disgusted, and surprised face) followed by a neutral face. Using techniques from computer vision and machine learning, we objectively measured the variance of the facial muscle movements and used it to distinguish between individuals with and without PD. The prediction accuracy using the facial micro-expressions was comparable to those methodologies that utilize motor symptoms. Logistic regression analysis revealed that participants with PD had less variance in AU6 (cheek raiser), AU12 (lip corner puller), and AU4 (brow lowerer) than non-PD individuals. An automated classifier using Support Vector Machine was trained on the variances and achieved 95.6% accuracy. Using facial expressions as a biomarker for PD could be potentially transformative for patients in need of physical separation (e.g., due to COVID) or are immobile.      
### 53.Informationally Overcomplete POVMs for Quantum State Estimation and Binary Detection  [ :arrow_down: ](https://arxiv.org/pdf/2012.05355.pdf)
>  It is well-known in classical frame theory that overcomplete representations of a given vector space provide robustness to additive noise on the frame coefficients of an unknown vector. We describe how the same robustness can be shown to exist in the context of quantum state estimation. A key element of the discussion is the application of classical frame theory to operator-valued vector spaces, or operator spaces, which arise naturally in quantum mechanics. Specifically, in the problem we describe the frame vectors are represented by the elements of an informationally complete or overcomplete (IC or IOC) POVM, the frame coefficients are represented by the outcome probabilities of a quantum measurement made on an unknown state, and the error on the frame coefficients arises from finite sample size estimations of the probabilities. We show that with this formulation of the problem, there is a tradeoff in estimation performance between the number of copies of the unknown system and the number of POVM elements. Lastly, we present evidence through simulation that the same tradeoff is present in the context of quantum binary state detection -- the probability of error can be reduced either by increasing the number of copies of the unknown system or by increasing the number of POVM elements.      
### 54.Automatic Diagnosis of Malaria from Thin Blood Smear Images using Deep Convolutional Neural Network with Multi-Resolution Feature Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2012.05350.pdf)
>  Malaria, a life-threatening disease, infects millions of people every year throughout the world demanding faster diagnosis for proper treatment before any damages occur. In this paper, an end-to-end deep learning-based approach is proposed for faster diagnosis of malaria from thin blood smear images by making efficient optimizations of features extracted from diversified receptive fields. Firstly, an efficient, highly scalable deep neural network, named as DilationNet, is proposed that incorporates features from a large spectrum by varying dilation rates of convolutions to extract features from different receptive areas. Next, the raw images are resampled to various resolutions to introduce variations in the receptive fields that are used for independently optimizing different forms of DilationNet scaled for different resolutions of images. Afterward, a feature fusion scheme is introduced with the proposed DeepFusionNet architecture for jointly optimizing the feature space of these individually trained networks operating on different levels of observations. All the convolutional layers of various forms of DilationNets that are optimized to extract spatial features from different resolutions of images are directly transferred to provide a variegated feature space from any image. Later, joint optimization of these spatial features is carried out in the DeepFusionNet to extract the most relevant representation of the sample image. This scheme offers the opportunity to explore the feature space extensively by varying the observation level to accurately diagnose the abnormality. Intense experimentations on a publicly available dataset show outstanding performance with accuracy over 99.5% outperforming other state-of-the-art approaches.      
### 55.A Photonic Integrated Circuit based Compressive Sensing Radio Frequency Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2012.05341.pdf)
>  A photonic integrated circuit comprised of an 11 cm multimode speckle waveguide, a 1x32 splitter, and a linear grating coupler array is fabricated and utilized to receive 2 GHz of RF signal bandwidth from 2.5 to 4.5 GHz using a 35 MHz mode locked laser.      

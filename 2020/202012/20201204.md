# ArXiv eess --Fri, 4 Dec 2020
### 1.Individually amplified text-to-speech  [ :arrow_down: ](https://arxiv.org/pdf/2012.02174.pdf)
>  Text-to-speech (TTS) offers the opportunity to compensate for a hearing loss at the source rather than correcting for it at the receiving end. This removes limitations such as time constraints for algorithms that amplify a sound individually and can lead to higher speech quality for hearing-impaired listeners. We propose an algorithm that restores loudness to normal perception at a high resolution in time, frequency and level, and embed it in a TTS system that uses Tacotron2 and WaveGlow to produce individually amplified speech. Subjective evaluations of speech quality showed that the proposed algorithm led to high-quality audio. Mean opinion scores were predicted well by the STOI metric. Transfer learning led to a quick adaption of the produced spectra from original speech to individually amplified speech and gives us a way to train an individual TTS system efficiently.      
### 2.A Review of Phasor Measurement Unit Requirements and Monitoring Architecture Practices for State Estimation at Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02171.pdf)
>  Distribution system and market operators will need or be required to monitor closely distribution systems, due to the presence of multiple actors, such as generating and storage units, as also active loads. The reason for this is the effect of these latter actors to system operation as also to ensure they follow their commitments in the deregulated market frameworks. This paper discusses why the traditional approach to state estimation as this has been developed for transmission systems cannot be extended to distribution systems. Some preliminary proposals are made, and a high-level architecture is presented as part of an on-going research work on the matter.      
### 3.Channel Effects on Surrogate Models of Adversarial Attacks against Wireless Signal Classifiers  [ :arrow_down: ](https://arxiv.org/pdf/2012.02160.pdf)
>  We consider a wireless communication system that consists of a background emitter, a transmitter, and an adversary. The transmitter is equipped with a deep neural network (DNN) classifier for detecting the ongoing transmissions from the background emitter and transmits a signal if the spectrum is idle. Concurrently, the adversary trains its own DNN classifier as the surrogate model by observing the spectrum to detect the ongoing transmissions of the background emitter and generate adversarial attacks to fool the transmitter into misclassifying the channel as idle. This surrogate model may differ from the transmitter's classifier significantly because the adversary and the transmitter experience different channels from the background emitter and therefore their classifiers are trained with different distributions of inputs. This system model may represent a setting where the background emitter is a primary, the transmitter is a secondary, and the adversary is trying to fool the secondary to transmit even though the channel is occupied by the primary. We consider different topologies to investigate how different surrogate models that are trained by the adversary (depending on the differences in channel effects experienced by the adversary) affect the performance of the adversarial attack. The simulation results show that the surrogate models that are trained with different distributions of channel-induced inputs severely limit the attack performance and indicate that the transferability of adversarial attacks is neither readily available nor straightforward to achieve since surrogate models for wireless applications may significantly differ from the target model depending on channel effects.      
### 4.Strategies for Network-Safe Load Control with a Third-Party Aggregator and a Distribution Operator  [ :arrow_down: ](https://arxiv.org/pdf/2012.02152.pdf)
>  When providing bulk power system services, a third-party aggregator could inadvertently cause operational issues at the distribution level. We propose a coordination architecture in which an aggregator and distribution operator coordinate to avoid distribution network constraint violations, while preserving private information. The aggregator controls thermostatic loads to provide frequency regulation, while the distribution operator overrides the aggregator's control actions when necessary to ensure safe network operation. Using this architecture, we propose two control strategies, which differ in terms of measurement and communication requirements, as well as model complexity and scalability. The first uses an aggregate model and blocking controller, while the second uses individual load models and a mode-count controller. Both outperform a benchmark strategy in terms of tracking accuracy. Furthermore, the second strategy performs better than the first, with only 0.10% average RMS error (compared to 0.70%). The second is also able to maintain safe operation of the distribution network while overriding less than 1% of the aggregator's control actions (compared to approximately 15% by the first strategy). However, the second strategy has significantly more measurement, communication, and computational requirements, and therefore would be more complex and expensive to implement than the first strategy.      
### 5.Decoupled Reference Governors: A Constraint Management Technique for MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02020.pdf)
>  This paper presents a computationally efficient solution for constraint management of multi-input and multi-output (MIMO) systems. The solution, referred to as the Decoupled Reference Governor (DRG), maintains the highly-attractive computational features of Scalar Reference Governors (SRG) while having performance comparable to Vector Reference Governors (VRG). DRG is based on decoupling the input-output dynamics of the system, followed by the deployment of a bank of SRGs for each decoupled channel. We present two formulations of DRG: DRG-tf, which is based on system decoupling using transfer functions, and DRG-ss, which is built on state feedback decoupling. A detailed set-theoretic analysis of DRG, which highlights its main characteristics, is presented. We also show a quantitative comparison between DRG and the VRG to illustrate the computational advantages of DRG. The robustness of this approach to disturbances and uncertainties is also investigated.      
### 6.Scenario-based Nonlinear Model Predictive Control for Building Heating Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02011.pdf)
>  State-of-the-art Model Predictive Control (MPC) applications for building heating adopt either a deterministic controller together with a nonlinear model or a linearized model with a stochastic MPC controller. However, deterministic MPC only considers one single realization of the disturbances and its performance strongly depends on the quality of the forecast of the disturbances, possibly leading to low performance. On the other hand, a linearized model can fail to capture some dynamics and behavior of the building under control. In this article, we combine a stochastic scenario-based MPC (SBMPC) controller together with a nonlinear Modelica model that is able to capture the dynamics of the building more accurately than linear models. The adopted SBMPC controller considers multiple realizations of the external disturbances obtained through a statistically accurate model, so as to consider different possible disturbance evolutions and to robustify the control action. We show the benefits of our proposed approach through several simulations in which we compare our method against the standard ones from the literature. We show how our approach outperforms both an SBMPC controller that uses a linearized model and a deterministic MPC controller that uses a nonlinear Modelica model.      
### 7.Fundamental Stealthiness-Distortion Tradeoffs in Dynamical (Control) Systems under Injection Attacks: A Power Spectral Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2012.02009.pdf)
>  In this paper, we analyze the fundamental stealthiness-distortion tradeoffs of linear Gaussian open-loop dynamical systems and (closed-loop) feedback control systems under data injection attacks using a power spectral analysis, whereas the Kullback-Leibler (KL) divergence is employed as the stealthiness measure. Particularly, we obtain explicit formulas in terms of power spectra that characterize analytically the stealthiness-distortion tradeoffs as well as the properties of the worst-case attacks. Furthermore, it is seen in general that the attacker only needs to know the input-output behaviors of the systems in order to carry out the worst-case attacks.      
### 8.Localization of Malaria Parasites and White Blood Cells in Thick Blood Smears  [ :arrow_down: ](https://arxiv.org/pdf/2012.01994.pdf)
>  Effectively determining malaria parasitemia is a critical aspect in assisting clinicians to accurately determine the severity of the disease and provide quality treatment. Microscopy applied to thick smear blood smears is the de facto method for malaria parasitemia determination. However, manual quantification of parasitemia is time consuming, laborious and requires considerable trained expertise which is particularly inadequate in highly endemic and low resourced areas. This study presents an end-to-end approach for localisation and count of malaria parasites and white blood cells (WBCs) which aid in the effective determination of parasitemia; the quantitative content of parasites in the blood. On a dataset of slices of images of thick blood smears, we build models to analyse the obtained digital images. To improve model performance due to the limited size of the dataset, data augmentation was applied. Our preliminary results show that our deep learning approach reliably detects and returns a count of malaria parasites and WBCs with a high precision and recall. We also evaluate our system against human experts and results indicate a strong correlation between our deep learning model counts and the manual expert counts (p=0.998 for parasites, p=0.987 for WBCs). This approach could potentially be applied to support malaria parasitemia determination especially in settings that lack sufficient Microscopists.      
### 9.An Improved Iterative Neural Network for High-Quality Image-Domain Material Decomposition in Dual-Energy CT  [ :arrow_down: ](https://arxiv.org/pdf/2012.01986.pdf)
>  Dual-energy computed tomography (DECT) has been widely used in many applications that need material decomposition. Image-domain methods directly decompose material images from high- and low-energy attenuation images, and thus, are susceptible to noise and artifacts on attenuation images. To obtain high-quality material images, various data-driven methods have been proposed. Iterative neural network (INN) methods combine regression NNs and model-based image reconstruction algorithm. INNs reduced the generalization error of (noniterative) deep regression NNs, and achieved high-quality reconstruction in diverse medical imaging applications. BCD-Net is a recent INN architecture that incorporates imaging refining NNs into the block coordinate descent (BCD) model-based image reconstruction algorithm. We propose a new INN architecture, distinct cross-material BCD-Net, for DECT material decomposition. The proposed INN architecture uses distinct cross-material convolutional neural network (CNN) in image refining modules, and uses image decomposition physics in image reconstruction modules. The distinct cross-material CNN refiners incorporate distinct encoding-decoding filters and cross-material model that captures correlations between different materials. We interpret the distinct cross-material CNN refiner with patch perspective. Numerical experiments with extended cardiactorso (XCAT) phantom and clinical data show that proposed distinct cross-material BCD-Net significantly improves the image quality over several image-domain material decomposition methods, including a conventional model-based image decomposition (MBID) method using an edge-preserving regularizer, a state-of-the-art MBID method using pre-learned material-wise sparsifying transforms, and a noniterative deep CNN denoiser.      
### 10.Deep Multi-Scale Features Learning for Distorted Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2012.01980.pdf)
>  Image quality assessment (IQA) aims to estimate human perception based image visual quality. Although existing deep neural networks (DNNs) have shown significant effectiveness for tackling the IQA problem, it still needs to improve the DNN-based quality assessment models by exploiting efficient multi-scale features. In this paper, motivated by the human visual system (HVS) combining multi-scale features for perception, we propose to use pyramid features learning to build a DNN with hierarchical multi-scale features for distorted image quality prediction. Our model is based on both residual maps and distorted images in luminance domain, where the proposed network contains spatial pyramid pooling and feature pyramid from the network structure. Our proposed network is optimized in a deep end-to-end supervision manner. To validate the effectiveness of the proposed method, extensive experiments are conducted on four widely-used image quality assessment databases, demonstrating the superiority of our algorithm.      
### 11.A Novel Robust 3-D Path Following Control for Keplerian Orbits  [ :arrow_down: ](https://arxiv.org/pdf/2012.01954.pdf)
>  This work proposes a novel path following control inspired in the famous two-body problem. In recognizing the mathematical structure of the two-body problem, we derive a robust path following law that is able to achieve any conic section, even for problems that do not involve inverse squared distance forces. In order to do so, we use the framework of the sliding mode control theory, which is only possible after we propose and prove asymptotic convergence of a new kind of sliding surface, specially suitable for this path following problem. With this new sliding surface, we are able to derive our control law, showing that it is asymptotic stable. The far range of applicability of this new path following is exemplified for three examples. A moving path following problem, in which a particle is requested to orbit an accelerated moving point, a patched hyperboles example, and an orbit keeping problem around the asteroid Itokawa. The control law derivation and the illustrative examples suggest that this path following strategy could have far reaching consequences in theoretical and practical researches.      
### 12.Convergence time estimate and tuning of twisting algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2012.01924.pdf)
>  Gain tuning is given for the twisting controller to ensure that the closed-loop trajectories of the perturbed double integrator, initialized within a bounded domain and affected by uniformly bounded disturbances, settle at the origin in prescribed time.      
### 13.Internal Calibration Process Using Chirp Pulses with Application of the Adam Learning Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2012.01919.pdf)
>  We propose a new internal calibration process using chirp pulses. Our method is utilized to mitigate thermal drift, which is unwanted changes and usually occurs in active elements such as a high power amplifier and low noise amplifier. The proposed method has advantages from two distinct aspects: calibration signal and algorithm. In respect to the calibration signal, our method does not contain an additional signal source because chirp pulses, which are normally used for remote sensing, are used as calibration signals. Moreover, our methods solve the ambiguity problem of analyzing a phase shift which occurs when sinusoidal signals are used as calibration signals. In regards to the algorithm, the Adam learning algorithm avoids learning in the wrong direction, unlike the conventional gradient descent. <br>Using our method, mathematical forms of received signals are acquired successfully. Our method shows better effectivity compared to the conventional gradient descent algorithm. After compensation, the maximum differences of gain and phase become 0.06 dB and 2.42 degrees, respectively.      
### 14.Light-field view synthesis using convolutional block attention module  [ :arrow_down: ](https://arxiv.org/pdf/2012.01900.pdf)
>  Consumer light-field (LF) cameras suffer from a low or limited resolution because of the angular-spatial trade-off. To alleviate this drawback, we propose a novel learning-based approach utilizing attention mechanism to synthesize novel views of a light-field image using a sparse set of input views (i.e., 4 corner views) from a camera array. In the proposed method, we divide the process into three stages, stereo-feature extraction, disparity estimation, and final image refinement. We use three sequential convolutional neural networks for each stage. A residual convolutional block attention module (CBAM) is employed for final adaptive image refinement. Attention modules are helpful in learning and focusing more on the important features of the image and are thus sequentially applied in the channel and spatial dimensions. Experimental results show the robustness of the proposed method. Our proposed network outperforms the state-of-the-art learning-based light-field view synthesis methods on two challenging real-world datasets by 0.5 dB on average. Furthermore, we provide an ablation study to substantiate our findings.      
### 15.Analysis of the Coherent Contributions to Nonlinear Interference Generation within Disaggregated Optical Line Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.01896.pdf)
>  Through a physical layer simulation study we highlight that the coherent accumulation of nonlinear interference becomes non-negligible for optical networks operating within high symbol rate transmission scenarios. This initiates a discussion on how to accurately plan and model optical networks, starting from the physical layer.      
### 16.How to Exploit the Transferability of Learned Image Compression to Conventional Codecs  [ :arrow_down: ](https://arxiv.org/pdf/2012.01874.pdf)
>  Lossy image compression is often limited by the simplicity of the chosen loss measure. Recent research suggests that generative adversarial networks have the ability to overcome this limitation and serve as a multi-modal loss, especially for textures. Together with learned image compression, these two techniques can be used to great effect when relaxing the commonly employed tight measures of distortion. However, convolutional neural network based algorithms have a large computational footprint. Ideally, an existing conventional codec should stay in place, which would ensure faster adoption and adhering to a balanced computational envelope. <br>As a possible avenue to this goal, in this work, we propose and investigate how learned image coding can be used as a surrogate to optimize an image for encoding. The image is altered by a learned filter to optimise for a different performance measure or a particular task. Extending this idea with a generative adversarial network, we show how entire textures are replaced by ones that are less costly to encode but preserve sense of detail. <br>Our approach can remodel a conventional codec to adjust for the MS-SSIM distortion with over 20% rate improvement without any decoding overhead. On task-aware image compression, we perform favourably against a similar but codec-specific approach.      
### 17.Simplifying Karnaugh Maps by Making Groups of a Non-Power-of-Two Number of Elements  [ :arrow_down: ](https://arxiv.org/pdf/2012.01861.pdf)
>  When we study the Karnaugh map in the switching theory course, we learn that the ones in the map must be combined in groups of $a \times b$ elements, being $a$ and $b$ powers of two. The result is the logic function described as a sum of products. This paper shows that we can also make groups where $a$ and/or $b$ are equal to three. This does not result in a sum of products, but in a logic function that is simpler than the sum of products in terms of logic gates. This idea is extended later in the paper to groups of $2^n-1$ elements.      
### 18.Structural Identifiability of a Pseudo-2D Li-ion Battery Electrochemical Model  [ :arrow_down: ](https://arxiv.org/pdf/2012.01853.pdf)
>  Growing demand for fast charging and optimised battery designs is fuelling significant interest in electrochemical models of Li-ion batteries. However, estimating parameter values for these models remains a major challenge. In this paper, a structural identifiability analysis was applied to a pseudo-2D Li-ion electrochemical battery model that can be considered as a linearised and decoupled form of the benchmark Doyle-Fuller-Newman model. From an inspection of the impedance function, it was shown that this model is uniquely parametrised by 21 parameters, being combinations of the electrochemical parameters like the conductivities and diffusion coefficients. The well-posedness of the parameter estimation problem with these parameters was then established. This result could lead to more realistic predictions about the internal state of the battery by identifying the parameter set that can be uniquely identified from the data.      
### 19.Energy Neutral Devices: Can Hybrid RF Acoustic Signals Point Them Out?  [ :arrow_down: ](https://arxiv.org/pdf/2012.01846.pdf)
>  We present a hybrid signaling approach to position energy-neutral devices. Our method combines the best of two worlds: instant RF signals for both communication and energy transfer, and slower propagating acoustic waves for accurate distance measurements. We introduce advanced energy loading of an 'E-buffer' through beamformed RF signals. The scientific contribution of our approach is twofold, advancing both the positioning performance and the energy harvesting efficiency. On the one hand, we overcome current distance limitations in RF backscattering-based indoor localization. On the other hand, it enhances the energy harvesting by using the calculated position and beamforming a higher amount of directed RF energy into the mobile node. We provide a functional architecture for both sides of the system and present a proof-of-concept. Practical measurements in representative use cases show an update rate of 10 positions per hour within the regulatory constraints in the 868MHz band for distances up to 4.5 m. An energy and power model are drawn up to provide insights into the performance trade-offs.      
### 20.Partially Connected Automated Vehicle Cooperative Control Strategy with a Deep Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2012.01841.pdf)
>  This paper proposes a cooperative strategy of connected and automated vehicles (CAVs) longitudinal control for partially connected and automated traffic environment based on deep reinforcement learning (DRL) algorithm, which enhances the string stability of mixed traffic, car following efficiency, and energy efficiency. Since the sequences of mixed traffic are combinatory, to reduce the training dimension and alleviate communication burdens, we decomposed mixed traffic into multiple subsystems where each subsystem is comprised of human-driven vehicles (HDV) followed by cooperative CAVs. Based on that, a cooperative CAV control strategy is developed based on a deep reinforcement learning algorithm, enabling CAVs to learn the leading HDV's characteristics and make longitudinal control decisions cooperatively to improve the performance of each subsystem locally and consequently enhance performance for the whole mixed traffic flow. For training, a distributed proximal policy optimization is applied to ensure the training convergence of the proposed DRL. To verify the effectiveness of the proposed method, simulated experiments are conducted, which shows the performance of our proposed model has a great generalization capability of dampening oscillations, fulfilling the car following and energy-saving tasks efficiently under different penetration rates and various leading HDVs behaviors. <br>Keywords: partially connected automated traffic environment, cooperative control, deep reinforcement learning, traffic oscillation dampening, energy efficiency      
### 21.SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2012.01829.pdf)
>  Deep learning (DL) based hyperspectral images (HSIs) denoising approaches directly learn the nonlinear mapping between observed noisy images and underlying clean images. They normally do not consider the physical characteristics of HSIs, therefore making them lack of interpretability that is key to understand their denoising mechanism.. In order to tackle this problem, we introduce a novel model guided interpretable network for HSI denoising. Specifically, fully considering the spatial redundancy, spectral low-rankness and spectral-spatial properties of HSIs, we first establish a subspace based multi-dimensional sparse model. This model first projects the observed HSIs into a low-dimensional orthogonal subspace, and then represents the projected image with a multidimensional dictionary. After that, the model is unfolded into an end-to-end network named SMDS-Net whose fundamental modules are seamlessly connected with the denoising procedure and optimization of the model. This makes SMDS-Net convey clear physical meanings, i.e., learning the low-rankness and sparsity of HSIs. Finally, all key variables including dictionaries and thresholding parameters are obtained by the end-to-end training. Extensive experiments and comprehensive analysis confirm the denoising ability and interpretability of our method against the state-of-the-art HSI denoising methods.      
### 22.Massive MIMO goes Sub-GHz: Implementation and Experimental Exploration for LPWANs  [ :arrow_down: ](https://arxiv.org/pdf/2012.01803.pdf)
>  Low-Power Wide-Area Networks operating in the unlicensed bands are being deployed to connect a rapidly growing number of Internet-of-Things devices. While the unlicensed sub-GHz band offers favorable propagation for long-range connections, measurements show that the energy consumption of the nodes is still mostly dominated by the wireless transmission affecting their autonomy. We investigate the potential benefits of deploying massive MIMO technology to increase system reliability and at the same time support low-energy devices with good coverage at sub-GHz frequencies. The impact of different antenna configurations and propagation conditions is analyzed. Both actual average experienced array gain and channel hardening are examined. The assessment demonstrates the effect of channel hardening as well as the potential benefits of the experienced array gain. These measurements serve as a first assessment of the channel conditions of massive MIMO at sub-GHz frequencies and are, to the best of our knowledge, the first of its kind.      
### 23.Flow-based Deformation Guidance for Unpaired Multi-Contrast MRI Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2012.01777.pdf)
>  Image synthesis from corrupted contrasts increases the diversity of diagnostic information available for many neurological diseases. Recently the image-to-image translation has experienced significant levels of interest within medical research, beginning with the successful use of the Generative Adversarial Network (GAN) to the introduction of cyclic constraint extended to multiple domains. However, in current approaches, there is no guarantee that the mapping between the two image domains would be unique or one-to-one. In this paper, we introduce a novel approach to unpaired image-to-image translation based on the invertible architecture. The invertible property of the flow-based architecture assures a cycle-consistency of image-to-image translation without additional loss functions. We utilize the temporal information between consecutive slices to provide more constraints to the optimization for transforming one domain to another in unpaired volumetric medical images. To capture temporal structures in the medical images, we explore the displacement between the consecutive slices using a deformation field. In our approach, the deformation field is used as a guidance to keep the translated slides realistic and consistent across the translation. The experimental results have shown that the synthesized images using our proposed approach are able to archive a competitive performance in terms of mean squared error, peak signal-to-noise ratio, and structural similarity index when compared with the existing deep learning-based methods on three standard datasets, i.e. HCP, MRBrainS13, and Brats2019.      
### 24.Cross-Correlation Based Discriminant Criterion for Channel Selection in Motor Imagery BCI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.01749.pdf)
>  Many electroencephalogram (EEG)-based brain-computer interface (BCI) systems use a large amount of channels for higher performance, which is time-consuming to set up and inconvenient for practical applications. Finding an optimal subset of channels without compromising the performance is a necessary and challenging task. In this article, we proposed a cross-correlation based discriminant criterion (XCDC) which assesses the importance of a channel for discriminating the mental states of different motor imagery (MI) tasks. The performance of XCDC is evaluated on two motor imagery EEG datasets. In both datasets, XCDC significantly reduces the amount of channels without compromising classification accuracy compared to the all-channel setups. Under the same constraint of accuracy, the proposed method requires fewer channels than existing channel selection methods based on Pearson's correlation coefficient and common spatial pattern. Visualization of XCDC shows consistent results with neurophysiological principles.      
### 25.Ultra-Wideband Radar and Wireless Human Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2012.01746.pdf)
>  This study presents the progress of our recent research regarding wireless measurements of the human body. First, we explain radar imaging algorithms for screening passengers at security checkpoints that can process data faster than existing algorithms to generate accurate and high-resolution images of human bodies. Second, we introduce signal processing techniques for accurately measuring radar micro-Doppler signals associated with human motions and activities. Finally, we present radar signal processing algorithms for measuring human respiration, heartbeat, and other types of motion. Such algorithms can be applied in various fields including healthcare, security, biometric identification, and man-machine interfaces. These fields have one thing in common: prior knowledge about the human shape, motion, and physiology are effectively exploited to improve performance by optimizing the radar systems and signal processing algorithms.      
### 26.Unsupervised Alternating Optimization for Blind Hyperspectral Imagery Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2012.01745.pdf)
>  Despite the great success of deep model on Hyperspectral imagery (HSI) super-resolution(SR) for simulated data, most of them function unsatisfactory when applied to the real data, especially for unsupervised HSI SR methods. One of the main reason comes from the fact that the predefined degeneration models (e.g. blur in spatial domain) utilized by most HSI SR methods often exist great discrepancy with the real one, which results in these deep models overfit and ultimately degrade their performance on real data. To well mitigate such a problem, we explore the unsupervised blind HSI SR method. Specifically, we investigate how to effectively obtain the degeneration models in spatial and spectral domain, respectively, and makes them can well compatible with the fusion based SR reconstruction model. To this end, we first propose an alternating optimization based deep framework to estimate the degeneration models and reconstruct the latent image, with which the degeneration models estimation and HSI reconstruction can mutually promotes each other. Then, a meta-learning based mechanism is further proposed to pre-train the network, which can effectively improve the speed and generalization ability adapting to different complex degeneration. Experiments on three benchmark HSI SR datasets report an excellent superiority of the proposed method on handling blind HSI fusion problem over other competing methods.      
### 27.A 3D Non-Stationary Channel Model for 6G Wireless Systems Employing Intelligent Reflecting Surface  [ :arrow_down: ](https://arxiv.org/pdf/2012.01726.pdf)
>  As one of the key technologies for the sixth generation (6G) mobile communications, intelligent reflecting surface IRS) has the advantages of low power consumption, low cost, and simple design methods. But channel modeling is still an open issue in this field currently. In this paper, we propose a three-dimensional (3D) geometry based stochastic model (GBSM) for a massive multiple-input multiple-output (MIMO) communication system employing IRS. The model supports the movements of the transmitter, the receiver, and clusters. The evolution of clusters on the linear array and planar array is also considered in the proposed model. In addition, the generation of reflecting coefficient is incorporated into the model and the path loss of the sub-channel assisted by IRS is also proposed. The steering vector is set up at the base station for the cooperation with IRS. Through studying statistical properties such as the temporal autocorrelation function and space correlation function, the nonstationary properties are verified. The good agreement between the simulation results and the analytical results illustrates the correctness of the proposed channel model.      
### 28.A Spectral Estimation Framework for Phase Retrieval via Bregman Divergence Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2012.01652.pdf)
>  In this paper, we develop a novel framework to optimally design spectral estimators for phase retrieval given measurements realized from an arbitrary model. We begin by deconstructing spectral methods, and identify the fundamental mechanisms that inherently promote the accuracy of estimates. We then propose a general formalism for spectral estimation as approximate Bregman loss minimization in the range of the lifted forward model that is tractable by a search over rank-1, PSD matrices. Essentially, by the Bregman loss approach we transcend the Euclidean sense alignment based similarity measure between phaseless measurements in favor of appropriate divergence metrics over $\mathbb{R}^M_+$. To this end, we derive spectral methods that perform approximate minimization of KL-divergence, and the Itakura-Saito distance over phaseless measurements by using element-wise sample processing functions. As a result, our formulation relates and extends existing results on model dependent design of optimal sample processing functions in the literature to a model independent sense of optimality. Numerical simulations confirm the effectiveness of our approach in problem settings under synthetic and real data sets.      
### 29.Extraction Of Fractional Inspiratory Time And Respiration Rate FromElectrocardiogram Signals  [ :arrow_down: ](https://arxiv.org/pdf/2012.01585.pdf)
>  At-home monitoring of lung health enables the early detection and treatment of respiratory diseases like asthma and chronic obstructive pulmonary disease (COPD). To allow for discreet continuous monitoring, various approaches have been proposed to estimate the respiratory rate from an electrocardiogram (ECG) signal. Unfortunately, respiratory rate can only provide a non-specific, incomplete picture of lung health. This paper introduces an algorithm to extract more respiratory information from the ECG signal: in addition to respiratory rate, the algorithm also derives the fractional inspiratory time(FIT), which is a direct measure of airway obstruction. The algorithm is based on a gated recurrent neural network that infers vital respiratory information from a two-lead ECG signal. The network is trained and tested on different test subjects and reports up to 0.099, and 0.243 normalized root mean squared error in the computation of FIT and respiration rate, respectively.      
### 30.Millimeter-Wave Massive MIMO Testbed with Hybrid Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2012.01584.pdf)
>  Massive multiple-input multiple-out (MIMO) technology is vital in millimeter-wave (mmWave) bands to obtain large array gains. However, there are practical challenges, such as high hardware cost and power consumption in such systems. A promising solution to these problems is to adopt a hybrid beamforming architecture. This architecture has a much lower number of transceiver (TRx) chains than the total antenna number, resulting in cost- and energy-efficient systems. In this paper, we present a real-time mmWave (28 GHz) massive MIMO testbed with hybrid beamforming. This testbed has a 64-antenna/16-TRx unit for beam-selection, which can be expanded to larger array sizes in a modular way. For testing everything from baseband processing algorithms to scheduling and beam-selection in real propagation environments, we extend the capability of an existing 100-antenna/100-TRx massive MIMO testbed (below 6 GHz), built upon software-defined radio technology, to a flexible mmWave massive MIMO system.      
### 31.Generation of Multimodal Ground Truth Datasets for Abdominal Medical Image Registration Using CycleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2012.01582.pdf)
>  Sparsity of annotated data is a major limitation in medical image processing tasks such as registration. Registered multimodal image data are essential for the success of various medical procedures. To overcome the shortage of data, we present a method which allows the generation of annotated, multimodal 4D datasets. We use a CycleGAN network architecture to generate multimodal synthetic data from a digital body phantom and real patient data. The generated T1-weighted MRI, CT, and CBCT images are inherently co-registered. Because organ masks are also provided by the digital body phantom, the generated dataset serves as a ground truth for image segmentation and registration. Realistic simulation of respiration and heartbeat is possible within the framework. Compared to real patient data the synthetic data showed good agreement regarding the image voxel intensity distribution and the noise characteristics. To underline the usability as a registration ground truth, a proof of principle registration was performed. We were able to optimize the registration parameters of the multimodal non-rigid registration in the process, utilizing the liver organ masks for evaluation purposes. The best performing registration setting was able to reduce the average symmetric surface distance (ASSD) of the liver masks from 8.7mm to 0.8mm. Thus, we could demonstrate the applicability of synthetic data for the development of medical image registration algorithms. This approach can be readily adapted for multimodal image segmentation.      
### 32.A Study of Few-Shot Audio Classification  [ :arrow_down: ](https://arxiv.org/pdf/2012.01573.pdf)
>  Advances in deep learning have resulted in state-of-the-art performance for many audio classification tasks but, unlike humans, these systems traditionally require large amounts of data to make accurate predictions. Not every person or organization has access to those resources, and the organizations that do, like our field at large, do not reflect the demographics of our country. Enabling people to use machine learning without significant resource hurdles is important, because machine learning is an increasingly useful tool for solving problems, and can solve a broader set of problems when put in the hands of a broader set of people. Few-shot learning is a type of machine learning designed to enable the model to generalize to new classes with very few examples. In this research, we address two audio classification tasks (speaker identification and activity classification) with the Prototypical Network few-shot learning algorithm, and assess performance of various encoder architectures. Our encoders include recurrent neural networks, as well as one- and two-dimensional convolutional neural networks. We evaluate our model for speaker identification on the VoxCeleb dataset and ICSI Meeting Corpus, obtaining 5-shot 5-way accuracies of 93.5% and 54.0%, respectively. We also evaluate for activity classification from audio using few-shot subsets of the Kinetics~600 dataset and AudioSet, both drawn from Youtube videos, obtaining 51.5% and 35.2% accuracy, respectively.      
### 33.Joint gender and age estimation based on speech signals using x-vectors and transfer learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.01551.pdf)
>  In this paper we extend the x-vector framework for the task of speaker's age estimation and gender classification. In particular, we replace the baseline multilayer-TDNN architecture with QuartzNet, a convolutional architecture that has gained success in the field of speech recognition. We further propose a two-staged transfer learning scheme, utilizing large scale speech datasets: VoxCeleb and Common Voice, and usage of multitask learning to allow for joint age estimation and gender classification with a single system. We train and evaluate the performance on the TIMIT dataset. The proposed transfer learning scheme yields consecutive performance improvements in terms of both age estimation error and gender classification accuracy and the best performing system achieves new state-of-the-art results on the task of age estimation on the TIMIT TEST dataset with MAE of 5.12 and 5.29 years and RMSE of 7.24 and 8.12 years for male and female speakers respectively while maintaining a gender classification accuracy of 99.6%.      
### 34.Distributed User Association in B5G Networks Using Early Acceptance Matching Games  [ :arrow_down: ](https://arxiv.org/pdf/2012.01510.pdf)
>  We study distributed user association in 5G and beyond millimeter-wave enabled heterogeneous networks using matching theory. We propose a novel and efficient distributed matching game, called early acceptance (EA), which allows users to apply for association with their ranked-preference base station in a distributed fashion and get accepted as soon as they are in the base station's preference list with available quota. Several variants of the EA matching game with preference list updating and reapplying are compared with the original and stability-optimal deferred acceptance (DA) matching game, which implements a waiting list at each base station and delays user association until the game finishes. We show that matching stability needs not lead to optimal performance in other metrics such as throughput. Analysis and simulations show that compared to DA, the proposed EA matching games achieve higher network throughput while exhibiting a significantly faster association process. Furthermore, the EA games either playing once or multiple times can reach closely the network utility of a centralized user association while having much lower complexity.      
### 35.The Third DIHARD Diarization Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2012.01477.pdf)
>  This paper introduces the third DIHARD challenge, the third in a series of speaker diarization challenges intended to improve the robustness of diarization systems to variation in recording equipment, noise conditions, and conversational domain. Speaker diarization is evaluated under two segmentation conditions (diarization from a reference speech segmentation vs. diarization from scratch) and 11 diverse domains. The domains span a range of recording conditions and interaction types, including read audiobooks, meeting speech, clinical interviews, web videos, and, for the first time, conversational telephone speech. We describe the task and metrics, challenge design, datasets, and baseline systems for speech speech activity detection and diarization.      
### 36.CovSegNet: A Multi Encoder-Decoder Architecture for Improved Lesion Segmentation of COVID-19 Chest CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2012.01473.pdf)
>  Automatic lung lesions segmentation of chest CT scans is considered a pivotal stage towards accurate diagnosis and severity measurement of COVID-19. Traditional U-shaped encoder-decoder architecture and its variants suffer from diminutions of contextual information in pooling/upsampling operations with increased semantic gaps among encoded and decoded feature maps as well as instigate vanishing gradient problems for its sequential gradient propagation that result in sub-optimal performance. Moreover, operating with 3D CT-volume poses further limitations due to the exponential increase of computational complexity making the optimization difficult. In this paper, an automated COVID-19 lesion segmentation scheme is proposed utilizing a highly efficient neural network architecture, namely CovSegNet, to overcome these limitations. Additionally, a two-phase training scheme is introduced where a deeper 2D-network is employed for generating ROI-enhanced CT-volume followed by a shallower 3D-network for further enhancement with more contextual information without increasing computational burden. Along with the traditional vertical expansion of Unet, we have introduced horizontal expansion with multi-stage encoder-decoder modules for achieving optimum performance. Additionally, multi-scale feature maps are integrated into the scale transition process to overcome the loss of contextual information. Moreover, a multi-scale fusion module is introduced with a pyramid fusion scheme to reduce the semantic gaps between subsequent encoder/decoder modules while facilitating the parallel optimization for efficient gradient propagation. Outstanding performances have been achieved in three publicly available datasets that largely outperform other state-of-the-art approaches. The proposed scheme can be easily extended for achieving optimum segmentation performances in a wide variety of applications.      
### 37.Generating private data with user customization  [ :arrow_down: ](https://arxiv.org/pdf/2012.01467.pdf)
>  Personal devices such as mobile phones can produce and store large amounts of data that can enhance machine learning models; however, this data may contain private information specific to the data owner that prevents the release of the data. We want to reduce the correlation between user-specific private information and the data while retaining the useful information. Rather than training a large model to achieve privatization from end to end, we first decouple the creation of a latent representation, and then privatize the data that allows user-specific privatization to occur in a setting with limited computation and minimal disturbance on the utility of the data. We leverage a Variational Autoencoder (VAE) to create a compact latent representation of the data that remains fixed for all devices and all possible private labels. We then train a small generative filter to perturb the latent representation based on user specified preferences regarding the private and utility information. The small filter is trained via a GAN-type robust optimization that can take place on a distributed device such as a phone or tablet. Under special conditions of our linear filter, we disclose the connections between our generative approach and renyi differential privacy. We conduct experiments on multiple datasets including MNIST, UCI-Adult, and CelebA, and give a thorough evaluation including visualizing the geometry of the latent embeddings and estimating the empirical mutual information to show the effectiveness of our approach.      
### 38.Manifold Learning and Deep Clustering with Local Dictionaries  [ :arrow_down: ](https://arxiv.org/pdf/2012.02134.pdf)
>  We introduce a novel clustering algorithm for data sampled from a union of nonlinear manifolds. Our algorithm extends a popular manifold clustering framework, which first computes a sparse similarity graph over the input data and then uses spectral methods to find clusters in this graph. While previous manifold learning algorithms directly compute similarity scores between pairs of data points, our algorithm first augments the data set with a small handful of representative atoms and then computes similarity scores between data points and atoms. To measure similarity, we express each data point as sparse convex combination of nearby atoms. To learn the atoms, we employ algorithm unrolling, an increasingly popular technique for structured deep learning. Ultimately, this departure from established manifold learning techniques leads to improvements in clustering accuracy and scalability.      
### 39.SuperOCR: A Conversion from Optical Character Recognition to Image Captioning  [ :arrow_down: ](https://arxiv.org/pdf/2012.02033.pdf)
>  Optical Character Recognition (OCR) has many real world applications. The existing methods normally detect where the characters are, and then recognize the character for each detected location. Thus the accuracy of characters recognition is impacted by the performance of characters detection. In this paper, we propose a method for recognizing characters without detecting the location of each character. This is done by converting the OCR task into an image captioning task. One advantage of the proposed method is that the labeled bounding boxes for the characters are not needed during training. The experimental results show the proposed method outperforms the existing methods on both the license plate recognition and the watermeter character recognition tasks. The proposed method is also deployed into a low-power (300mW) CNN accelerator chip connected to a Raspberry Pi 3 for on-device applications.      
### 40.End to End ASR System with Automatic Punctuation Insertion  [ :arrow_down: ](https://arxiv.org/pdf/2012.02012.pdf)
>  Recent Automatic Speech Recognition systems have been moving towards end-to-end systems that can be trained together. Numerous techniques that have been proposed recently enabled this trend, including feature extraction with CNNs, context capturing and acoustic feature modeling with RNNs, automatic alignment of input and output sequences using Connectionist Temporal Classifications, as well as replacing traditional n-gram language models with RNN Language Models. Historically, there has been a lot of interest in automatic punctuation in textual or speech to text context. However, there seems to be little interest in incorporating automatic punctuation into the emerging neural network based end-to-end speech recognition systems, partially due to the lack of English speech corpus with punctuated transcripts. In this study, we propose a method to generate punctuated transcript for the TEDLIUM dataset using transcripts available from <a class="link-external link-http" href="http://ted.com" rel="external noopener nofollow">this http URL</a>. We also propose an end-to-end ASR system that outputs words and punctuations concurrently from speech signals. Combining Damerau Levenshtein Distance and slot error rate into DLev-SER, we enable measurement of punctuation error rate when the hypothesis text is not perfectly aligned with the reference. Compared with previous methods, our model reduces slot error rate from 0.497 to 0.341.      
### 41.On spike-and-slab priors for Bayesian equation discovery of nonlinear dynamical systems via sparse linear regression  [ :arrow_down: ](https://arxiv.org/pdf/2012.01937.pdf)
>  This paper presents the use of spike-and-slab (SS) priors for discovering governing differential equations of motion of nonlinear structural dynamic systems. The problem of discovering governing equations is cast as that of selecting relevant variables from a predetermined dictionary of basis variables and solved via sparse Bayesian linear regression. The SS priors, which belong to a class of discrete-mixture priors and are known for their strong sparsifying (or shrinkage) properties, are employed to induce sparse solutions and select relevant variables. Three different variants of SS priors are explored for performing Bayesian equation discovery. As the posteriors with SS priors are analytically intractable, a Markov chain Monte Carlo (MCMC)-based Gibbs sampler is employed for drawing posterior samples of the model parameters; the posterior samples are used for variable selection and parameter estimation in equation discovery. The proposed algorithm has been applied to four systems of engineering interest, which include a baseline linear system, and systems with cubic stiffness, quadratic viscous damping, and Coulomb damping. The results demonstrate the effectiveness of the SS priors in identifying the presence and type of nonlinearity in the system. Additionally, comparisons with the Relevance Vector Machine (RVM) - that uses a Student's-t prior - indicate that the SS priors can achieve better model selection consistency, reduce false discoveries, and derive models that have superior predictive accuracy. Finally, the Silverbox experimental benchmark is used to validate the proposed methodology.      
### 42.COVID-19 Cough Classification using Machine Learning and Global Smartphone Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2012.01926.pdf)
>  We present a machine learning based COVID-19 cough classifier which is able to discriminate COVID-19 positive coughs from both COVID-19 negative and healthy coughs recorded on a smartphone. This type of screening is non-contact and easily applied, and could help reduce workload in testing centers as well as limit transmission by recommending early self-isolation to those who have a cough suggestive of COVID-19. The two dataset used in this study include subjects from all six continents and contain both forced and natural coughs. The publicly available Coswara dataset contains 92 COVID-19 positive and 1079 healthy subjects, while the second smaller dataset was collected mostly in South Africa and contains 8 COVID-19 positive and 13 COVID-19 negative subjects who have undergone a SARS-CoV laboratory test. Dataset skew was addressed by applying synthetic minority oversampling (SMOTE) and leave-p-out cross validation was used to train and evaluate classifiers. Logistic regression (LR), support vector machines (SVM), multilayer perceptrons (MLP), convolutional neural networks (CNN), long-short term memory (LSTM) and a residual-based neural network architecture (Resnet50) were considered as classifiers. Our results show that the Resnet50 classifier was best able to discriminate between the COVID-19 positive and the healthy coughs with an area under the ROC curve (AUC) of 0.98 while a LSTM classifier was best able to discriminate between the COVID-19 positive and COVID-19 negative coughs with an AUC of 0.94. The LSTM classifier achieved these results using 13 features selected by sequential forward search (SFS). Since it can be implemented on a smartphone, cough audio classification is cost-effective and easy to apply and deploy, and therefore is potentially a useful and viable means of non-contact COVID-19 screening.      
### 43.Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via Adversarial Training  [ :arrow_down: ](https://arxiv.org/pdf/2012.01837.pdf)
>  This paper describes an end-to-end adversarial singing voice conversion (EA-SVC) approach. It can directly generate arbitrary singing waveform by given phonetic posteriorgram (PPG) representing content, F0 representing pitch, and speaker embedding representing timbre, respectively. Proposed system is composed of three modules: generator $G$, the audio generation discriminator $D_{A}$, and the feature disentanglement discriminator $D_F$. The generator $G$ encodes the features in parallel and inversely transforms them into the target waveform. In order to make timbre conversion more stable and controllable, speaker embedding is further decomposed to the weighted sum of a group of trainable vectors representing different timbre clusters. Further, to realize more robust and accurate singing conversion, disentanglement discriminator $D_F$ is proposed to remove pitch and timbre related information that remains in the encoded PPG. Finally, a two-stage training is conducted to keep a stable and effective adversarial training process. Subjective evaluation results demonstrate the effectiveness of our proposed methods. Proposed system outperforms conventional cascade approach and the WaveNet based end-to-end approach in terms of both singing quality and singer similarity. Further objective analysis reveals that the model trained with the proposed two-stage training strategy can produce a smoother and sharper formant which leads to higher audio quality.      
### 44.Image inpainting using frequency domain priors  [ :arrow_down: ](https://arxiv.org/pdf/2012.01832.pdf)
>  In this paper, we present a novel image inpainting technique using frequency domain information. Prior works on image inpainting predict the missing pixels by training neural networks using only the spatial domain information. However, these methods still struggle to reconstruct high-frequency details for real complex scenes, leading to a discrepancy in color, boundary artifacts, distorted patterns, and blurry textures. To alleviate these problems, we investigate if it is possible to obtain better performance by training the networks using frequency domain information (Discrete Fourier Transform) along with the spatial domain information. To this end, we propose a frequency-based deconvolution module that enables the network to learn the global context while selectively reconstructing the high-frequency components. We evaluate our proposed method on the publicly available datasets CelebA, Paris Streetview, and DTD texture dataset, and show that our method outperforms current state-of-the-art image inpainting techniques both qualitatively and quantitatively.      
### 45.Singularity-free Guiding Vector Field for Robot Navigation  [ :arrow_down: ](https://arxiv.org/pdf/2012.01826.pdf)
>  Most of the existing path-following navigation algorithms cannot guarantee global convergence to desired paths or enable following self-intersected desired paths due to the existence of singular points where navigation algorithms return unreliable or even no solutions. One typical example arises in vector-field guided path-following (VF-PF) navigation algorithms. These algorithms are based on a vector field, and the singular points are exactly where the vector field diminishes. In this paper, we show that it is mathematically impossible for conventional VF-PF algorithms to achieve global convergence to desired paths that are self-intersected or even just simple closed (precisely, homeomorphic to the unit circle). Motivated by this new impossibility result, we propose a novel method to transform self-intersected or simple closed desired paths to non-self-intersected and unbounded (precisely, homeomorphic to the real line) counterparts in a higher-dimensional space. Corresponding to this new desired path, we construct a singularity-free guiding vector field on a higher-dimensional space. The integral curves of this new guiding vector field is thus exploited to enable global convergence to the higher-dimensional desired path, and therefore the projection of the integral curves on a lower-dimensional subspace converge to the physical (lower-dimensional) desired path. Rigorous theoretical analysis is carried out for the theoretical results using dynamical systems theory. In addition, we show both by theoretical analysis and numerical simulations that our proposed method is an extension combining conventional VF-PF algorithms and trajectory tracking algorithms. Finally, to show the practical value of our proposed approach for complex engineering systems, we conduct outdoor experiments with a fixed-wing airplane in windy environment to follow both 2D and 3D desired paths.      
### 46.A Novel 3D Non-Stationary Multi-Frequency Multi-Link Wideband MIMO Channel Model  [ :arrow_down: ](https://arxiv.org/pdf/2012.01728.pdf)
>  In this paper, a multi-frequency multi-link three-dimensional (3D) non-stationary wideband multiple-input multiple-output (MIMO) channel model is proposed. The spatial consistency and multi-frequency correlation are considered in parameters initialization of every single-link and different frequencies, including large scale parameters (LSPs) and small scale parameters (SSPs). Moreover, SSPs are time-variant and updated when scatterers and the receiver (Rx) are moving. The temporal evolution of clusters is modeled by birth and death processes. The single-link channel model which has considered the inter-correlation can be easily extended to multi-link channel model. Statistical properties, including spatial cross-correlation function (CCF), power delay profile (PDP), and correlation matrix collinearity (CMC) are investigated and compared with the 3rd generation partner project (3GPP) TR 38.901 and quasi deterministic radio channel generator (QuaDRiGa) channel models. Besides, the CCF is validated against measurement data.      
### 47.MelGlow: Efficient Waveform Generative Network Based on Location-Variable Convolution  [ :arrow_down: ](https://arxiv.org/pdf/2012.01684.pdf)
>  Recent neural vocoders usually use a WaveNet-like network to capture the long-term dependencies of the waveform, but a large number of parameters are required to obtain good modeling capabilities. In this paper, an efficient network, named location-variable convolution, is proposed to model the dependencies of waveforms. Different from the use of unified convolution kernels in WaveNet to capture the dependencies of arbitrary waveforms, location-variable convolutions utilizes a kernel predictor to generate multiple sets of convolution kernels based on the mel-spectrum, where each set of convolution kernels is used to perform convolution operations on the associated waveform intervals. Combining WaveGlow and location-variable convolutions, an efficient vocoder, named MelGlow, is designed. Experiments on the LJSpeech dataset show that MelGlow achieves better performance than WaveGlow at small model sizes, which verifies the effectiveness and potential optimization space of location-variable convolutions.      
### 48.A Single Sensor Based Multispectral Imaging Camera using a Narrow Spectral Band Colour Mosaic Integrated on the Monochrome CMOS Image Sensor  [ :arrow_down: ](https://arxiv.org/pdf/2012.01630.pdf)
>  A multispectral image camera captures image data within specific wavelength ranges in narrow wavelength bands across the electromagnetic spectrum. Images from a multispectral camera can extract additional information that the human eye or a normal camera fails to capture and thus may have important applications in precision agriculture, forestry, medicine and object identification. Conventional multispectral cameras are made up of multiple image sensors each fitted with a narrow passband wavelength filter and optics, which makes them heavy, bulky, power hungry and very expensive. The multiple optics also create image co-registration problem. Here, we demonstrate a single sensor based three band multispectral camera using a narrow spectral band RGB colour mosaic in a Bayer pattern integrated on a monochrome CMOS sensor. The narrow band colour mosaic is made of a hybrid combination of plasmonic colour filters and heterostructured dielectric multilayer. The demonstrated camera technology has reduced cost, weight, size and power by almost n times (where n is the number of bands) compared to a conventional multispectral camera.      
### 49.Matrix Completion Methods for the Total Electron Content Video Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2012.01618.pdf)
>  The total electron content (TEC) maps can be used to estimate the signal delay of GPS due to the ionospheric electron content between a receiver and satellite. This delay can result in GPS positioning error. Thus it is important to monitor the TEC maps. The observed TEC maps have big patches of missingness in the ocean and scattered small areas of missingness on the land. In this paper, we propose several extensions of existing matrix completion algorithms to achieve TEC map reconstruction, accounting for spatial smoothness and temporal consistency while preserving important structures of the TEC maps. We call the proposed method Video Imputation with SoftImpute, Temporal smoothing and Auxiliary data (VISTA). Numerical simulations that mimic patterns of real data are given. We show that our proposed method achieves better reconstructed TEC maps as compared to existing methods in literature. Our proposed computational algorithm is general and can be readily applied for other problems besides TEC map reconstruction.      
### 50.Position Information from Single-Bounce Reflections  [ :arrow_down: ](https://arxiv.org/pdf/2012.01597.pdf)
>  In the context of positioning a target with a single-anchor, this contribution focuses on the Fisher information about the position, orientation and clock offset of the target provided by single-bounce reflections. The availability of prior knowledge of the target's environment is taken into account via a prior distribution of the position of virtual anchors, and the rank, intensity and direction of provided information is studied. We show that when no prior knowledge is available, single-bounce reflections offer position information in the direction parallel to the reflecting surface, irrespective of the target's and anchor's locations. We provide a geometrically intuitive explanation of the results and present numerical examples demonstrating their potential implications.      
### 51.Power Allocation and Parameter Estimation for Multipath-based 5G Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2012.01590.pdf)
>  We consider a single-anchor multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) system with imperfectly synchronized transmitter (Tx) and receiver (Rx) clocks, where the Rx estimates its position based on the received reference signals. The Tx, having (imperfect) prior knowledge about the Rx location and the surrounding geometry, transmits the reference signals based on a set of fixed beams. In this work, we develop strategies for the power allocation among the beams aiming to minimize the expected Cramér-Rao lower bound (CRLB) for Rx positioning. Additional constraints on the design are included to ensure that the line-of-sight (LOS) path is detected with high probability. Furthermore, the effect of clock asynchronism on the resulting allocation strategies is also studied. We also propose a gridless compressed sensing-based position estimation algorithm, which exploits the information on the clock offset provided by non-line-of-sight paths, and show that it is asymptotically efficient.      
### 52.Enhancement of Spatial Clustering-Based Time-Frequency Masks using LSTM Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.01576.pdf)
>  Recent works have shown that Deep Recurrent Neural Networks using the LSTM architecture can achieve strong single-channel speech enhancement by estimating time-frequency masks. However, these models do not naturally generalize to multi-channel inputs from varying microphone configurations. In contrast, spatial clustering techniques can achieve such generalization but lack a strong signal model. Our work proposes a combination of the two approaches. By using LSTMs to enhance spatial clustering based time-frequency masks, we achieve both the signal modeling performance of multiple single-channel LSTM-DNN speech enhancers and the signal separation performance and generality of multi-channel spatial clustering. We compare our proposed system to several baselines on the CHiME-3 dataset. We evaluate the quality of the audio from each system using SDR from the BSS\_eval toolkit and PESQ. We evaluate the intelligibility of the output of each system using word error rate from a Kaldi automatic speech recognizer.      
### 53.From a Fourier-Domain Perspective on Adversarial Examples to a Wiener Filter Defense for Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2012.01558.pdf)
>  Despite recent advancements, deep neural networks are not robust against adversarial perturbations. Many of the proposed adversarial defense approaches use computationally expensive training mechanisms that do not scale to complex real-world tasks such as semantic segmentation, and offer only marginal improvements. In addition, fundamental questions on the nature of adversarial perturbations and their relation to the network architecture are largely understudied. In this work, we study the adversarial problem from a frequency domain perspective. More specifically, we analyze discrete Fourier transform (DFT) spectra of several adversarial images and report two major findings: First, there exists a strong connection between a model architecture and the nature of adversarial perturbations that can be observed and addressed in the frequency domain. Second, the observed frequency patterns are largely image- and attack-type independent, which is important for the practical impact of any defense making use of such patterns. Motivated by these findings, we additionally propose an adversarial defense method based on the well-known Wiener filters that captures and suppresses adversarial frequencies in a data-driven manner. Our proposed method not only generalizes across unseen attacks but also beats five existing state-of-the-art methods across two models in a variety of attack settings.      
### 54.Second-Order Guarantees in Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.01474.pdf)
>  Federated learning is a useful framework for centralized learning from distributed data under practical considerations of heterogeneity, asynchrony, and privacy. Federated architectures are frequently deployed in deep learning settings, which generally give rise to non-convex optimization problems. Nevertheless, most existing analysis are either limited to convex loss functions, or only establish first-order stationarity, despite the fact that saddle-points, which are first-order stationary, are known to pose bottlenecks in deep learning. We draw on recent results on the second-order optimality of stochastic gradient algorithms in centralized and decentralized settings, and establish second-order guarantees for a class of federated learning algorithms.      
### 55.Video Anomaly Detection by Estimating Likelihood of Representations  [ :arrow_down: ](https://arxiv.org/pdf/2012.01468.pdf)
>  Video anomaly detection is a challenging task not only because it involves solving many sub-tasks such as motion representation, object localization and action recognition, but also because it is commonly considered as an unsupervised learning problem that involves detecting outliers. Traditionally, solutions to this task have focused on the mapping between video frames and their low-dimensional features, while ignoring the spatial connections of those features. Recent solutions focus on analyzing these spatial connections by using hard clustering techniques, such as K-Means, or applying neural networks to map latent features to a general understanding, such as action attributes. In order to solve video anomaly in the latent feature space, we propose a deep probabilistic model to transfer this task into a density estimation problem where latent manifolds are generated by a deep denoising autoencoder and clustered by expectation maximization. Evaluations on several benchmarks datasets show the strengths of our model, achieving outstanding performance on challenging datasets.      
### 56.Cycloidal Trajectory Realization on Staircase with Optimal Trajectory Tracking Control based on Neural Network Temporal Quantized Lagrange Dynamics (NNTQLD)  [ :arrow_down: ](https://arxiv.org/pdf/2012.01417.pdf)
>  In this paper, a novel optimal technique for joint angles trajectory tracking control of a biped robot with toe foot is proposed. For the task of climbing stairs by a 9 link biped model, a cycloid trajectory for swing phase is proposed in such a way that the cycloid variables depend on the staircase dimensions. Zero Moment Point(ZMP) criteria is taken for satisfying stability constraint. This paper mainly can be divided into 4 steps: 1) Planning stable cycloid trajectory for initial step and subsequent step for climbing upstairs. 2) Inverse Kinematics using unsupervised artificial neural network with knot shifting procedure for jerk minimization. 3) Modeling Dynamics for Toe foot biped model using Lagrange Dynamics along with contact modeling using spring damper system , and finally 4) Real time joint angle trajectory tracking optimization using Temporal Quantized Lagrange Dynamics which takes inverse kinematics output from neural network as its inputs. Generated patterns have been simulated in MATLAB.      
### 57.Adaptive Bit Partitioning for Reconfigurable Intelligent Surface Assisted FDD Systems with Limited Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2011.14748.pdf)
>  In frequency division duplexing systems, the base station (BS) acquires downlink channel state information (CSI) via channel feedback, which has not been adequately investigated in the presence of RIS. In this study, we examine the limited channel feedback scheme by proposing a novel cascaded codebook and an adaptive bit partitioning strategy. The RIS segments the channel between the BS and mobile station into two sub-channels, each with line-of-sight (LoS) and non-LoS (NLoS) paths. To quantize the path gains, the cascaded codebook is proposed to be synthesized by two sub-codebooks whose codeword is cascaded by LoS and NLoS components. This enables the proposed cascaded codebook to cater the different distributions of LoS and NLoS path gains by flexibly using different feedback bits to design the codeword structure. On the basis of the proposed cascaded codebook, we derive an upper bound on ergodic rate loss with maximum ratio transmission and show that the rate loss can be cut down by optimizing the feedback bit allocation during codebook generation. To minimize the upper bound, we propose a bit partitioning strategy that is adaptive to diverse environment and system parameters. Extensive simulations are presented to show the superiority and robustness of the cascaded codebook and the efficiency of the adaptive bit partitioning scheme.      

# ArXiv eess --Wed, 2 Dec 2020
### 1.Learning with Knowledge of Structure: A Neural Network-Based Approach for MIMO-OFDM Detection  [ :arrow_down: ](https://arxiv.org/pdf/2012.00711.pdf)
>  In this paper, we explore neural network-based strategies for performing symbol detection in a MIMO-OFDM system. Building on a reservoir computing (RC)-based approach towards symbol detection, we introduce a symmetric and decomposed binary decision neural network to take advantage of the structure knowledge inherent in the MIMO-OFDM system. To be specific, the binary decision neural network is added in the frequency domain utilizing the knowledge of the constellation. We show that the introduced symmetric neural network can decompose the original $M$-ary detection problem into a series of binary classification tasks, thus significantly reducing the neural network detector complexity while offering good generalization performance with limited training overhead. Numerical evaluations demonstrate that the introduced hybrid RC-binary decision detection framework performs close to maximum likelihood model-based symbol detection methods in terms of symbol error rate in the low SNR regime with imperfect channel state information (CSI).      
### 2.Phase of Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.00692.pdf)
>  In this paper, we propose a definition of phase for a class of stable nonlinear systems called semi-sectorial systems from an input-output perspective. The definition involves the Hilbert transform as a key tool to complexify real-valued signals since the notion of phase arises most naturally in the complex domain. The proposed nonlinear system phase, serving as a counterpart of $\mathcal{L}_2$-gain, quantifies the passivity and is highly related to the dissipativity. It also possesses a nice physical interpretation which quantifies the tradeoff between the real energy and reactive energy. A nonlinear small phase theorem is then established for feedback stability analysis of semi-sectorial systems. Additionally, its generalized version is proposed via the use of multipliers. The nonlinear small theorems generalize a version of the classical passivity theorem and a recently appeared linear time-invariant small phase theorem.      
### 3.Distributed state estimation: a novel stopping criterion  [ :arrow_down: ](https://arxiv.org/pdf/2012.00647.pdf)
>  Power System State Estimation (PSSE) has been a research area of interest for power engineers for a long period of time. Due to the intermittent nature of renewable energy sources, which are applied in the power network more than before, the importance of state estimation has been increased as well. Centralized state estimation due to the complexity of new networks and growing size of power network will face problems such as communication bottleneck in real-time analyzing of the system or reliability issues. Distributed state estimation is a solution for the mentioned issues. There are different implementation methods introduced for it. The results of the paper are twofold. First, we examined different approaches to distributed PSSE (DPSSE) problem, according to most important factors like iteration number, convergence rate, data needed to be transferred to/from each area and so on. Next, we proposed and discussed a new distributed stopping criterion for the methods and above-mentioned factors are obtained as well. Finally, a comparison between the total efficiency of all applied methods is done.      
### 4.On hallucinations in tomographic image reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2012.00646.pdf)
>  Tomographic image reconstruction is generally an ill-posed linear inverse problem. Such ill-posed inverse problems are typically regularized using prior knowledge of the sought-after object property. Recently, deep neural networks have been actively investigated for regularizing image reconstruction problems by learning a prior for the object properties from training images. However, an analysis of the prior information learned by these deep networks and their ability to generalize to data that may lie outside the training distribution is still being explored. An inaccurate prior might lead to false structures being hallucinated in the reconstructed image and that is a cause for serious concern in medical imaging. In this work, we propose to illustrate the effect of the prior imposed by a reconstruction method by decomposing the image estimate into generalized measurement and null components. The concept of a hallucination map is introduced for the general purpose of understanding the effect of the prior in regularized reconstruction methods. Numerical studies are conducted corresponding to a stylized tomographic imaging modality. The behavior of different reconstruction methods under the proposed formalism is discussed with the help of the numerical studies.      
### 5.Effects of Solar Radio Emissions on Outdoor Propagation Path Loss Models at 60 GHz Bands for Access/Backhaul Links and D2D Communications  [ :arrow_down: ](https://arxiv.org/pdf/2012.00639.pdf)
>  This paper presents analytical and empirical data documenting the effects of solar radio emissions on outdoor propagation path loss at 60 GHz bands. Both line-of-sight (LOS) and non-LOS scenarios were considered. The setup used in the empirical studies emulates the future fifth-generation cellular systems for both access and backhaul services, as well as for device-to-device communications. Based on the measurement data collected in sunny weather with intense solar activities, we developed large-scale propagation path loss models at 60 GHz, and observed the effects of solar radio emissions on the path loss data. It is shown that solar radio emission can decrease carrier-to-noise ratio, and that this translates into a corresponding increase in the path loss exponent (PLE) values for the large-scale propagation path loss channel models. Empirical data show that 9.0%-15.6% higher PLE values were observed in hot and sunny weather during the day (41째-42 째C) compared with the counterpart measurements taken at night in cool and clear weather (20째-38 째C). This translates into a corresponding decrease in 60 GHz radio coverage in hot and sunny weather during the day. The empirical data are closely corroborated by analytical estimates presented.      
### 6.Directional Radio Propagation Path Loss Models for Millimeter-Wave Wireless Networks in the 28-, 60-, and 73-GHz Bands  [ :arrow_down: ](https://arxiv.org/pdf/2012.00636.pdf)
>  Fifth-generation (5G) cellular systems are likely to operate in the centimeter-wave (3-30 GHz) and millimeter-wave (30-300 GHz) frequency bands, where a vast amount of underutilized bandwidth exists world-wide. To assist in the research and development of these emerging wireless systems, a myriad of measurement studies have been conducted to characterize path loss in urban environments at these frequencies. The standard theoretical free space (FS) and Stanford University Interim (SUI) empirical path loss models were recently modified to fit path loss models obtained from measurements performed at 28 GHz and 38 GHz, using simple correction factors. In this paper, we provide similar correction factors for models at 60 GHz and 73 GHz. By imparting slope correction factors on the FS and SUI path loss models to closely match the close-in (CI) free space reference distance path loss models, millimeter-wave path loss can be accurately estimated (with popular models) for 5G cellular planning at 60 GHz and 73 GHz. Additionally, new millimeter-wave beam combining path loss models are provided at 28 GHz and 73 GHz by considering the simultaneous combination of signals from multiple antenna pointing directions between the transmitter and receiver that result in the strongest received power. Such directional channel models are important for future adaptive array systems at millimeter-wave frequencies.      
### 7.Overcoming the limitations of patch-based learning to detect cancer in whole slide images  [ :arrow_down: ](https://arxiv.org/pdf/2012.00617.pdf)
>  Whole slide images (WSIs) pose unique challenges when training deep learning models. They are very large which makes it necessary to break each image down into smaller patches for analysis, image features have to be extracted at multiple scales in order to capture both detail and context, and extreme class imbalances may exist. Significant progress has been made in the analysis of these images, thanks largely due to the availability of public annotated datasets. We postulate, however, that even if a method scores well on a challenge task, this success may not translate to good performance in a more clinically relevant workflow. Many datasets consist of image patches which may suffer from data curation bias; other datasets are only labelled at the whole slide level and the lack of annotations across an image may mask erroneous local predictions so long as the final decision is correct. In this paper, we outline the differences between patch or slide-level classification versus methods that need to localize or segment cancer accurately across the whole slide, and we experimentally verify that best practices differ in both cases. We apply a binary cancer detection network on post neoadjuvant therapy breast cancer WSIs to find the tumor bed outlining the extent of cancer, a task which requires sensitivity and precision across the whole slide. We extensively study multiple design choices and their effects on the outcome, including architectures and augmentations. Furthermore, we propose a negative data sampling strategy, which drastically reduces the false positive rate (7% on slide level) and improves each metric pertinent to our problem, with a 15% reduction in the error of tumor extent.      
### 8.MEG Source Localization via Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.00588.pdf)
>  We present a deep learning solution to the problem of localization of magnetoencephalography (MEG) brain signals. The proposed deep model architectures are tuned for single and multiple time point MEG data, and can estimate varying numbers of dipole sources. Results from simulated MEG data on the cortical surface of a real human subject demonstrated improvements against the popular RAP-MUSIC localization algorithm in specific scenarios with varying SNR levels, inter-source correlation values, and number of sources. Importantly, the deep learning models had robust performance to forward model errors and a significant reduction in computation time, to a fraction of 1 ms, paving the way to real-time MEG source localization.      
### 9.Trade-offs in Decentralized Multi-Antenna Architectures: The WAX Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2012.00572.pdf)
>  With the rise of technologies such as massive mutiple-input multiple-output (MIMO), or large intelligent surface (LIS), we can notice that the current research on multi-antenna architectures is trending towards increasing the amount of antennas in the base stations (BSs) so as to increase the spectral efficiency. As the number of antennas increases the interconnection bandwidth and computational complexity required to process the data using centralized architectures become prohibitively high. Decentralized architectures can reduce these requirements by pre-processing the data before it arrives at a central processing unit (CPU). However, performing decentralized processing introduces also cost in complexity/interconnection bandwidth at the antenna end which is in general being ignored. This paper aims at studying the interplay between level of decentralization and the associated complexity/interconnection bandwidth requirement at the antenna end. To do so, we propose a general framework for centralized/decentralized architectures that can explore said interplay by adjusting some system parameters, namely the number of connections to the CPU (level of decentralization), and the number of multiplications/outputs per antenna (complexity/interconnection bandwidth). We define a novel matrix decomposition, the WAX decomposition, that allows information-lossless processing within our proposed framework, and we use it to obtain the operational limits of the interplay under study. We also look into some of the limitations of the WAX decomposition, as well as the case where it is not available.      
### 10.Deep Sequence Learning for Accurate Gestational Age Estimation from a $\$$25 Doppler Device  [ :arrow_down: ](https://arxiv.org/pdf/2012.00553.pdf)
>  Assessing fetal development is usually carried out by techniques such as ultrasound imaging, which is generally unavailable in rural areas due to the high cost, maintenance, skills and training needed to operate the devices effectively. In this work, we propose a low-cost one-dimensional Doppler-based method for estimating gestational age (GA). Doppler time series were collected from 401 pregnancies between 5 and 9 months GA using a smartphone. The proposed model for GA estimation is based on sequence learning by forming a temporally dependent model using a convolutional long-short-term memory network. Time-frequency features are extracted from Doppler signals and regularized before feeding to the network. The overall mean absolute GA error with respect to the last menstrual period was found to be 0.71 month, which outperforms all previous works.      
### 11.A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech Data  [ :arrow_down: ](https://arxiv.org/pdf/2012.00486.pdf)
>  This paper proposes a unified deep speaker embedding framework for modeling speech data with different sampling rates. Considering the narrowband spectrogram as a sub-image of the wideband spectrogram, we tackle the joint modeling problem of the mixed-bandwidth data in an image classification manner. From this perspective, we elaborate several mixed-bandwidth joint training strategies under different training and test data scenarios. The proposed systems are able to flexibly handle the mixed-bandwidth speech data in a single speaker embedding model without any additional downsampling, upsampling, bandwidth extension, or padding operations. We conduct extensive experimental studies on the VoxCeleb1 dataset. Furthermore, the effectiveness of the proposed approach is validated by the SITW and NIST SRE 2016 datasets.      
### 12.Electric Vehicle Fleet Relocation Management for Sharing Systems based on Incentive Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2012.00471.pdf)
>  This paper deals with the electric vehicle fleet relocation management in a sharing system. The mobility sharing systems efficiency depends on the vehicles relocation task that strongly affect the company operating cost, and consequently the service price for users. The proposed approach aims at minimizing the cost of vehicles relocation for a sharing company by involving users through an innovative incentive scheme. The idea is to request users of the sharing service to relocate the EVs, e.g. through an IT application, incentivizing them by free-of-charge travels and rewards. The proposed incentive mechanism is based on the application of different levels of incentive proposal. In addition, in case of user unavailability, the vehicle relocation is guaranteed by the company staff. To this aim, a first ILP is formalized to manage the relocation task by the company staff. Moreover, a second ILP allows the company to involve users in the relocation process by the proposed incentive mechanism. Finally, a case study is presented to show the application of the proposed methodology on the relocation of electric cars and light electric vehicles.      
### 13.The effect of price-based demand response on carbon emissions in European electricity markets: The importance of adequate carbon prices  [ :arrow_down: ](https://arxiv.org/pdf/2012.00375.pdf)
>  Price-based demand response (PBDR) has recently been attributed great economic but also environmental potential. However, the determination of its short-term effects on carbon emissions requires the knowledge of marginal emission factors (MEFs), which compared to grid mix emission factors (XEFs), are cumbersome to calculate due to the complex characteristics of national electricity markets. This study, therefore, proposes two merit order-based methods to approximate hourly MEFs and applies it to readily available datasets from 20 European countries for the years 2017-2019. Based on the resulting electricity prices, MEFs, and XEFs, standardized daily load shifts were simulated to quantify their effects on marginal costs and carbon emissions. Finally, by repeating the load shift simulations for different carbon price levels, the impact of the carbon price on the resulting carbon emissions was analyzed. Interestingly, the simulated price-based load shifts led to increases in operational carbon emissions for 8 of the 20 countries and to an average increase of 2.1% across all 20 countries. Switching from price-based to MEF-based load shifts reduced the corresponding carbon emissions to a decrease of 35%, albeit with 56% lower monetary cost savings compared to the price-based load shifts. Under specific circumstances, PBDR leads to an increase in carbon emissions, mainly due to the economic advantage fuel sources such as lignite and coal have in the merit order. However, as the price of carbon is increased, the correlation between the carbon intensity and the marginal cost of the fuels substantially increases. Therefore, with adequate carbon prices, PBDR can be an effective tool for both economical and environmental improvement.      
### 14.Comparison of security margin estimation methods under various load configurations  [ :arrow_down: ](https://arxiv.org/pdf/2012.00336.pdf)
>  The post-contingency loadability limit (PCLL) and the secure operating limit (SOL) are the two main approaches used in computing the security margins of an electric power system. While the SOL is significantly more computationally demanding than the PCLL, it can account for the dynamic response after a disturbance and generally provides a better measure of the security margin. In this study, the difference between these two methods is compared and analyzed for a range of different contingency and load model scenarios. A methodology to allow a fair comparison between the two security margins is developed and tested on a modified version of the Nordic32 test system. The study shows that the SOL can differ significantly from the PCLL, especially when the system has a high penetration of loads with constant power characteristics, or a large share of induction motor loads with fast load restoration. The difference between the methods is also tested for different contingencies, where longer fault clearing times are shown to significantly increase the difference between the two margins.      
### 15.Enhanced Sufficient Battery Model for Aggregate Flexibility of Thermostatically Controlled Loads Considering Coupling Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2012.00331.pdf)
>  This letter proposes an enhanced sufficient battery model (ESBM) as well as a binary search algorithm for a sharp inner-approximation of the aggregate flexibility of thermostatically controlled load (TCL) arrays. Compared with the previous work on generalized battery models, this ESBM preserves the merits of being sufficient and mitigates the conservativity. Moreover, unlike the work ignoring the coupling constraints that may also restrict TCLs' aggregate flexibility, our ESBM can readily handle these constraints. Numerical tests validate the merits of using the ESBM and its significance for power system operations.      
### 16.Constrained Optimization for Falsification and Conjunctive Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2012.00319.pdf)
>  The synthesis problem of a cyber-physical system (CPS) is to find an input signal under which the system's behavior satisfies a given specification. Our setting is that the specification is a formula of signal temporal logic, and furthermore, that the specification is a conjunction of different and often conflicting requirements. Conjunctive specifications are often challenging for optimization-based falsification -- an established method for CPS analysis that can also be used for synthesis -- since the usual framework (especially how its robust semantics handles Boolean connectives) is not suited for finding delicate trade-offs between different requirements. Our proposed method consists of the combination of optimization-based falsification and constrained optimization. Specifically, we show that the state-of-the-art multiple constraint ranking method can be combined with falsification powered by CMA-ES optimization; its performance advantage is demonstrated in experiments.      
### 17.Embedded Deep Learning for Neural Implants  [ :arrow_down: ](https://arxiv.org/pdf/2012.00307.pdf)
>  Implanted devices providing real-time neural activity classification and control are increasingly used to treat neurological disorders, such as epilepsy and Parkinson's disease. Classification performance is critical to identifying brain states appropriate for the therapeutic action (e.g. neural stimulation). However, advanced algorithms that have shown promise in offline studies, in particular deep learning (DL) methods, have not been deployed on resource-restrained neural implants. Here, we designed and optimized three embedded DL models of commonly adopted architectures and evaluated their inference performance in a case study of seizure detection. A deep neural network (DNN), a convolutional neural network (CNN), and a long short-term memory (LSTM) network were designed to classify ictal, preictal, and interictal phases from the CHB-MIT scalp EEG database. After iterative model compression and quantization, the algorithms were deployed on a general-purpose, off-the-shelf microcontroller. Inference sensitivity, false positive rate (FPR), execution time, memory size, and power consumption were quantified. For seizure event detection, the sensitivity and FPR (h-1) for the DNN, CNN, and LSTM models were 96.96%/0.147, 98.79%/0.080, and 99.11%/0.048, respectively. The implemented compression and quantization achieved a significant saving of power and memory with an accuracy degradation of less than 0.5%. Inference with embedded DL models achieved performance comparable to many prior implementations that had no time or computational resource limitations. Generic microcontrollers can provide the required memory and computational resources, while model designs can be migrated to ASICs for further optimization. The results suggest that embedded DL inference is a feasible option for future neural implants to improve classification performance and therapeutic outcomes.      
### 18.Effects of Intermediate Frequency Bandwidth on Stepped Frequency Ground Penetrating Radar  [ :arrow_down: ](https://arxiv.org/pdf/2012.00291.pdf)
>  A stepped frequency ground penetrating radar (GPR) system is used for detecting objects buried under high permittivity soil. Different intermediate frequency bandwidth (IFBW) of the mixing receiver is used and measurement results are compared. It is shown that the IFBW can affect the system's signal-to-noise ratio (SNR). Experimental results show that objects of different materials can clearly be detected when the appropriate IFBW is used.      
### 19.The Optimal Location and Size of an Intermediate Coil in a Magnetic Resonant Coupling Wireless Power Transfer System  [ :arrow_down: ](https://arxiv.org/pdf/2012.00244.pdf)
>  To increase the transmission distance of Wireless Power Transfer (WPT) systems, we provide guidelines on choosing the optimal location of an Intermediate Coil with respect to size within a standard five-coil axially aligned experimental setup. From our results, for maximum magnitude of S21 at the resonant frequency we found the optimal location to exist where the coupling coefficient between the Transmitter and the Intermediate Coil and the coupling coefficient between the Receiver and the Intermediate Coil are identical. Additionally, the optimal outer diameter for the maximum magnitude of S21 at the resonant frequency of the Intermediate Coil in the given symmetric and asymmetric setup are found to be larger than both TX and RX.      
### 20.Deep Residual Network Empowered Channel Estimation for IRS-Assisted Multi-User Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.00241.pdf)
>  Channel estimation is of great importance in realizing practical intelligent reflecting surface-assisted multi-user communication (IRS-MC) systems. However, different from traditional communication systems, an IRS-MC system generally involves a cascaded channel with a sophisticated statistical distribution, which hinders the implementations of the Bayesian estimators. To further improve the channel estimation performance, in this paper, we model the channel estimation as a denoising problem and adopt a data-driven approach to realize the channel estimation. Specifically, we propose a convolutional neural network (CNN)-based deep residual network (CDRN) to implicitly learn the residual noise for recovering the channel coefficients from the noisy pilot-based observations. In the proposed CDRN, a CNN denoising block equipped with an element-wise subtraction structure is designed to exploit both the spatial features of the noisy channel matrices and the additive nature of the noise simultaneously, which further improves the estimation accuracy. Simulation results demonstrate that the proposed method can almost achieve the same estimation accuracy as that of the optimal minimum mean square error (MMSE) estimator requiring the knowledge of the channel distribution.      
### 21.A Mean-Field Team Approach to Minimize the Spread of Infection in a Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.00232.pdf)
>  In this paper, a stochastic dynamic control strategy is presented to prevent the spread of an infection over a homogeneous network. The infectious process is persistent, i.e., it continues to contaminate the network once it is established. It is assumed that there is a finite set of network management options available such as degrees of nodes and promotional plans to minimize the number of infected nodes while taking the implementation cost into account. The network is modeled by an exchangeable controlled Markov chain, whose transition probability matrices depend on three parameters: the selected network management option, the state of the infectious process, and the empirical distribution of infected nodes (with not necessarily a linear dependence). Borrowing some techniques from mean-field team theory the optimal strategy is obtained for any finite number of nodes using dynamic programming decomposition and the convolution of some binomial probability mass functions. For infinite-population networks, the optimal solution is described by a Bellman equation. It is shown that the infinite-population strategy is a meaningful sub-optimal solution for finite-population networks if a certain condition holds. The theoretical results are verified by an example of rumor control in social networks.      
### 22.Seizing Opportunity: Maintenance Optimization in Offshore Wind Farms Considering Dispatch, Accessibility, and Production  [ :arrow_down: ](https://arxiv.org/pdf/2012.00213.pdf)
>  Operations and Maintenance (O&amp;M) constitute a major contributor to offshore wind's cost of energy. Due to the harsh and remote environment in which offshore turbines operate, there has been a growing interest in opportunistic maintenance scheduling for offshore wind farms, wherein grouping maintenance tasks is incentivized at times of opportunity. Our survey of the literature, however, reveals that there is no unified consensus on what constitutes an "opportunity" for offshore maintenance. We therefore propose an opportunistic maintenance scheduling approach which defines an opportunity as either dispatch-based (initiated by a maintenance crew already dispatched to a neighboring turbine), production-based (initiated by projected low production levels), or access-based (initiated by a provisionally open window of turbine access). We formulate the problem as a rolling-horizon mixed integer linear program, and propose an iterative solution algorithm to identify the optimal hourly maintenance schedule, which is found to be drastically different, yet substantially better, than those obtained using offshore-insensitive strategies. Extensive evaluations on actual wind, wave, and power data demonstrate substantial margins of improvement achieved by our proposed approach, across a wide variety of key O&amp;M metrics.      
### 23.Research on Intelligent Charging System Technology of Automobile Group  [ :arrow_down: ](https://arxiv.org/pdf/2012.00185.pdf)
>  This paper analyzes the smart charging system for dealing with issues related to large parking garages, and analyzes the relevant technical standards of intelligent charging piles application and comprehensive transportation hubs. It mainly includes the number, area and charging method of the charging piles installed in the garages. New forms of construction management is conceived, and the investment and construction are reinforced, apportioning all charging system property rights to investment parties. Simultaneously, the investors take full responsibility for the future management and operation, mainly including the collection of service fees and charging fees.      
### 24.SuperCell: A Wide-Area Coverage Solution Using High-Gain, High-Order Sectorized Antennas on Tall Towers  [ :arrow_down: ](https://arxiv.org/pdf/2012.00161.pdf)
>  In this article we introduce a novel solution called SuperCell, which can improve the return on investment (ROI) for rural area network coverage. SuperCell offers two key technical features: it uses tall towers with high-gain antennas for wide coverage and high-order sectorization for high capacity. We show that a solution encompassing a high-elevation platform in excess of 200 meters increases coverage by 5x. Combined with dense frequency reuse by using as many as 36 azimuthal sectors from a single location, our solution can adequately serve the rural coverage and capacity demands. We validate this through propagation analysis, modeling, and experiments. The article gives a design perspective using different classes of antennas: Luneburg lens, active/passive phased array, and spatial multiplexing solutions. For each class, the corresponding analytical model of the resulting signal-to-interference plus noise ratio (SINR) based range and capacity prediction is presented. The spatial multiplexing solution is also validated through field measurements and additional 3D ray-tracing simulation. Finally, in this article we also shed light on two recent SuperCell field trials performed using a Luneburg lens antenna system. The trials took place in rural New Mexico and Mississippi. In the trials, we quantified the coverage and capacity of SuperCell in barren land and in a densely forested location, respectively. In the article, we demonstrate the results obtained in the trials and share the lessons learned regarding green-field and brown-field deployments.      
### 25.Plane-Wave Ultrasound Beamforming Through Independent Component Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2012.00151.pdf)
>  Beamforming in plane-wave imaging (PWI) is an essential step in creating images with optimal quality. Adaptive methods estimate the apodization weights from echo traces acquired by several transducer elements. Herein, we formulate plane-wave beamforming as a blind source separation problem. The output of each transducer element is considered as a non-independent observation of the field. As such, beamforming can be formulated as the estimation of an independent component out of the observations. We then adapt the independent component analysis (ICA) algorithm to solve this problem and reconstruct the final image. The proposed method is evaluated on a set of simulation, real phantom, and in vivo data available from the PWI challenge in medical ultrasound. The performance of the proposed beamforming approach is also evaluated in different imaging settings. The proposed algorithm improves lateral resolution by as much as $36.5\%$ and contrast by $10\%$ as compared to the classical delay and sum. Moreover, results are compared with other well-known adaptive methods. Finally, the robustness of the proposed method to noise is investigated.      
### 26.Model Adaptation for Inverse Problems in Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2012.00139.pdf)
>  Deep neural networks have been applied successfully to a wide variety of inverse problems arising in computational imaging. These networks are typically trained using a forward model that describes the measurement process to be inverted, which is often incorporated directly into the network itself. However, these approaches lack robustness to drift of the forward model: if at test time the forward model varies (even slightly) from the one the network was trained for, the reconstruction performance can degrade substantially. Given a network trained to solve an initial inverse problem with a known forward model, we propose two novel procedures that adapt the network to a perturbed forward model, even without full knowledge of the perturbation. Our approaches do not require access to more labeled data (i.e., ground truth images), but only a small set of calibration measurements. We show these simple model adaptation procedures empirically achieve robustness to changes in the forward model in a variety of settings, including deblurring, super-resolution, and undersampled image reconstruction in magnetic resonance imaging.      
### 27.Stability and Performance Analysis for SISO Incremental Flight Control  [ :arrow_down: ](https://arxiv.org/pdf/2012.00129.pdf)
>  Incremental Nonlinear Dynamic Inversion (INDI) control has attracted increasing research attention for it retains the high-performance of NDI and has enhanced robustness. However, when actual elements of the flight control system and real-world phenomena (such as actuator dynamics, sensor noise, time delay, etc.) are considered, the INDI control may have degraded performance or even lose stability. This paper analyzed the stability and performance of an incremental controller for a SISO linear plant based on transfer functions. Besides, the theoretical analysis results are verified through numerical evaluations for the incremental controller of the short-period aircraft model using comprehensive metrics.      
### 28.A Data-Driven Study to Discover, Characterize, and Classify Convergence Bidding Strategies in California ISO Energy Market  [ :arrow_down: ](https://arxiv.org/pdf/2012.00076.pdf)
>  Convergence bidding has been adopted in recent years by most Independent System Operators (ISOs) in the United States as a relatively new market mechanism to enhance market efficiency. Convergence bidding affects many aspects of the operation of the electricity markets and there is currently a gap in the literature on understanding how the market participants strategically select their convergence bids in practice. To address this open problem, in this paper, we study three years of real-world market data from the California ISO energy market. First, we provide a data-driven overview of all submitted convergence bids (CBs) and analyze the performance of each individual convergence bidder based on the number of their submitted CBs, the number of locations that they placed the CBs, the percentage of submitted supply or demand CBs, the amount of cleared CBs, and their gained profit or loss. Next, we scrutinize the bidding strategies of the 13 largest market players that account for 75\% of all CBs in the California ISO market. We identify quantitative features to characterize and distinguish their different convergence bidding strategies. This analysis results in revealing three different classes of CB strategies that are used in practice. We identify the differences between these strategic bidding classes and compare their advantages and disadvantages. We also explain how some of the most active market participants are using bidding strategies that do not match any of the strategic bidding methods that currently exist in the literature.      
### 29.Detecting expressions with multimodal transformers  [ :arrow_down: ](https://arxiv.org/pdf/2012.00063.pdf)
>  Developing machine learning algorithms to understand person-to-person engagement can result in natural user experiences for communal devices such as Amazon Alexa. Among other cues such as voice activity and gaze, a person's audio-visual expression that includes tone of the voice and facial expression serves as an implicit signal of engagement between parties in a dialog. This study investigates deep-learning algorithms for audio-visual detection of user's expression. We first implement an audio-visual baseline model with recurrent layers that shows competitive results compared to current state of the art. Next, we propose the transformer architecture with encoder layers that better integrate audio-visual features for expressions tracking. Performance on the Aff-Wild2 database shows that the proposed methods perform better than baseline architecture with recurrent layers with absolute gains approximately 2% for arousal and valence descriptors. Further, multimodal architectures show significant improvements over models trained on single modalities with gains of up to 3.6%. Ablation studies show the significance of the visual modality for the expression detection on the Aff-Wild2 database.      
### 30.A Novel Finite Time Stability Analysis of Nonlinear Fractional-Order Time Delay Systems: A Fixed Point Approach  [ :arrow_down: ](https://arxiv.org/pdf/2012.00007.pdf)
>  In this article, a novel Finite Time Stability (FTS) analysis of Fractional-Order Time Delay Systems (FOTDSs) is proposed. By using the fixed point approach, sufficient conditions for the robust FTS of FOTDSs have been established. Two illustrative examples are provided to prove the validity of the main result.      
### 31.Navigator-Free Submillimeter Diffusion Imaging using Multishot-encoded Simultaneous Multi-slice (MUSIUM)  [ :arrow_down: ](https://arxiv.org/pdf/2012.00664.pdf)
>  The ability to achieve submillimter isotropic resolution diffusion MR imaging (dMRI) is critically important to study fine-scale brain structures, particularly in the cortex. One of the major challenges in performing submillimeter dMRI is the inherently low signal-to-noise ratio (SNR). While approaches capable of mitigating the low SNR in high resolution dMRI have been proposed, namely simultaneous multi-slab (SMSlab) and generalized slice dithered enhanced resolution with simultaneous multislice (gSlider-SMS), limitations are associated with these approaches. The SMSlab sequences suffer from the slab boundary artifacts and require additional navigators for phase estimation. On the other hand, gSlider sequences require relatively high RF power and peak amplitude, which increase the SAR and complicate the RF excitation. In this work, we developed a navigator-free multishot-encoded simultaneous multi-slice (MUSIUM) imaging approach on a 3T MR scanner, achieving enhanced SNR, low RF power and peak amplitude, and being free from slab boundary artifacts. The dMRI with ultrahigh resolution (0.86 mm isotropic resolution), whole brain coverage and ~12.5 minute acquisition time were achieved, revealing detailed structures at cortical and white matter areas. The simulated and in vivo results also demonstrated that the MUSIUM imaging was minimally affected by the motion. Taken together, the MUSIUM imaging is a promising approach to achieve submillimeter diffusion imaging on 3T MR scanners within clinically feasible scan time.      
### 32.Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A Neural Exploration via Resolution-Adaptive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.00650.pdf)
>  Inspired by the facts that retinal cells actually segregate the visual scene into different attributes (e.g., spatial details, temporal motion) for respective neuronal processing, we propose to first decompose the input video into respective spatial texture frames (STF) at its native spatial resolution that preserve the rich spatial details, and the other temporal motion frames (TMF) at a lower spatial resolution that retain the motion smoothness; then compress them together using any popular video coder; and finally synthesize decoded STFs and TMFs for high-fidelity video reconstruction at the same resolution as its native input. This work simply applies the bicubic resampling in decomposition and HEVC compliant codec in compression, and puts the focus on the synthesis part. For resolution-adaptive synthesis, a motion compensation network (MCN) is devised on TMFs to efficiently align and aggregate temporal motion features that will be jointly processed with corresponding STFs using a non-local texture transfer network (NL-TTN) to better augment spatial details, by which the compression and resolution resampling noises can be effectively alleviated with better rate-distortion efficiency. Such "Decomposition, Compression, Synthesis (DCS)" based scheme is codec agnostic, currently exemplifying averaged $\approx$1 dB PSNR gain or $\approx$25% BD-rate saving, against the HEVC anchor using reference software. In addition, experimental comparisons to the state-of-the-art methods and ablation studies are conducted to further report the efficiency and generalization of DCS algorithm, promising an encouraging direction for future video coding.      
### 33.A Multi-intersection Vehicular Cooperative Control based on End-Edge-Cloud Computing  [ :arrow_down: ](https://arxiv.org/pdf/2012.00500.pdf)
>  Cooperative Intelligent Transportation Systems (C-ITS) will change the modes of road safety and traffic management, especially at intersections without traffic lights, namely unsignalized intersections. Existing researches focus on vehicle control within a small area around an unsignalized intersection. In this paper, we expand the control domain to a large area with multiple intersections. In particular, we propose a Multi-intersection Vehicular Cooperative Control (MiVeCC) to enable cooperation among vehicles in a large area with multiple unsignalized intersections. Firstly, a vehicular end-edge-cloud computing framework is proposed to facilitate end-edge-cloud vertical cooperation and horizontal cooperation among vehicles. Then, the vehicular cooperative control problems in the cloud and edge layers are formulated as Markov Decision Process (MDP) and solved by two-stage reinforcement learning. Furthermore, to deal with high-density traffic, vehicle selection methods are proposed to reduce the state space and accelerate algorithm convergence without performance degradation. A multi-intersection simulation platform is developed to evaluate the proposed scheme. Simulation results show that the proposed MiVeCC can improve travel efficiency at multiple intersections by up to 4.59 times without collision compared with existing methods.      
### 34.Problems of representation of electrocardiograms in convolutional neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.00493.pdf)
>  Using electrocardiograms as an example, we demonstrate the characteristic problems that arise when modeling one-dimensional signals containing inaccurate repeating pattern by means of standard convolutional networks. We show that these problems are systemic in nature. They are due to how convolutional networks work with composite objects, parts of which are not fixed rigidly, but have significant mobility. We also demonstrate some counterintuitive effects related to generalization in deep networks.      
### 35.Adaptive Coding and Channel Shaping Through Reconfigurable Intelligent Surfaces: An Information-Theoretic Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2012.00407.pdf)
>  A communication link aided by a reconfigurable intelligent surface (RIS) is studied in which the transmitter can control the state of the RIS via a finite-rate control link. Channel state information (CSI) is acquired at the receiver based on pilot-assisted channel estimation, and it may or may not be shared with the transmitter. Considering quasi-static fading channels with imperfect CSI, capacity-achieving signalling is shown to implement joint encoding of the transmitted signal and of the response of the RIS. This demonstrates the information-theoretic optimality of RIS-based modulation, or "single-RF MIMO" systems. In addition, a novel signalling strategy based on separate layered encoding that enables practical successive cancellation-type decoding at the receiver is proposed. Numerical experiments show that the conventional scheme that fixes the reflection pattern of the RIS, irrespective of the transmitted information, as to maximize the achievable rate is strictly suboptimal, and is outperformed by the proposed adaptive coding strategies at all practical signal-to-noise ratio (SNR) levels.      
### 36.Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2012.00403.pdf)
>  Recently, the research on ad-hoc microphone arrays with deep learning has drawn much attention, especially in speech enhancement and separation. Because an ad-hoc microphone array may cover such a large area that multiple speakers may locate far apart and talk independently, target-dependent speech separation, which aims to extract a target speaker from a mixed speech, is important for extracting and tracing a specific speaker in the ad-hoc array. However, this technique has not been explored yet. In this paper, we propose deep ad-hoc beamforming based on speaker extraction, which is to our knowledge the first work for target-dependent speech separation based on ad-hoc microphone arrays and deep learning. The algorithm contains three components. First, we propose a supervised channel selection framework based on speaker extraction, where the estimated utterance-level SNRs of the target speech are used as the basis for the channel selection. Second, we apply the selected channels to a deep learning based MVDR algorithm, where a single-channel speaker extraction algorithm is applied to each selected channel for estimating the mask of the target speech. We conducted an extensive experiment on a WSJ0-adhoc corpus. Experimental results demonstrate the effectiveness of the proposed method.      
### 37.Deep Learning-Based Arrhythmia Detection Using RR-Interval Framed Electrocardiograms  [ :arrow_down: ](https://arxiv.org/pdf/2012.00348.pdf)
>  Deep learning applied to electrocardiogram (ECG) data can be used to achieve personal authentication in biometric security applications, but it has not been widely used to diagnose cardiovascular disorders. We developed a deep learning model for the detection of arrhythmia in which time-sliced ECG data representing the distance between successive R-peaks are used as the input for a convolutional neural network (CNN). The main objective is developing the compact deep learning based detect system which minimally uses the dataset but delivers the confident accuracy rate of the Arrhythmia detection. This compact system can be implemented in wearable devices or real-time monitoring equipment because the feature extraction step is not required for complex ECG waveforms, only the R-peak data is needed. The results of both tests indicated that the Compact Arrhythmia Detection System (CADS) matched the performance of conventional systems for the detection of arrhythmia in two consecutive test runs. All features of the CADS are fully implemented and publicly available in MATLAB.      
### 38.NHSS: A Speech and Singing Parallel Database  [ :arrow_down: ](https://arxiv.org/pdf/2012.00337.pdf)
>  We present a database of parallel recordings of speech and singing, collected and released by the Human Language Technology (HLT) laboratory at the National University of Singapore (NUS), that is called NUS-HLT Speak-Sing (NHSS) database. We release this database to the public to support research activities, that include, but not limited to comparative studies of acoustic attributes of speech and singing signals, cooperative synthesis of speech and singing voices, and speech-to-singing conversion. This database consists of recordings of sung vocals of English pop songs, the spoken counterpart of lyrics of the songs read by the singers in their natural reading manner, and manually prepared utterance-level and word-level annotations. The audio recordings in the NHSS database correspond to 100 songs sung and spoken by 10 singers, resulting in a total of 7 hours of audio data. There are 5 male and 5 female singers, singing and reading the lyrics of 10 songs each. In this paper, we discuss the design methodology of the database, analyze the similarities and dissimilarities in characteristics of speech and singing voices, and provide some strategies to address relationships between these characteristics for converting one to another. We develop benchmark systems for speech-to-singing alignment, spectral mapping and conversion using the NHSS database.      
### 39.Reconsideration of feasibility of Hall amplifier  [ :arrow_down: ](https://arxiv.org/pdf/2012.00304.pdf)
>  In 1955, it was first suggested that Hall effect can be employed for amplification purposes by using semiconductor material with very high mobility. While this idea was limited at that time, yet it was not entirely discarded expecting eventual progress. We revisit this idea and discuss it in the light of current literature. This manuscript kindles this 65 year old amazing idea and views it with modern understanding, which will aid in realizing Hall amplifiers.      
### 40.Tracking Ensemble Performance on Touch-Screens with Gesture Classification and Transition Matrices  [ :arrow_down: ](https://arxiv.org/pdf/2012.00296.pdf)
>  We present and evaluate a novel interface for tracking ensemble performances on touch-screens. The system uses a Random Forest classifier to extract touch-screen gestures and transition matrix statistics. It analyses the resulting gesture-state sequences across an ensemble of performers. A series of specially designed iPad apps respond to this real-time analysis of free-form gestural performances with calculated modifications to their musical interfaces. We describe our system and evaluate it through cross-validation and profiling as well as concert experience.      
### 41.MTM Dataset for Joint Representation Learning among Sheet Music, Lyrics, and Musical Audio?  [ :arrow_down: ](https://arxiv.org/pdf/2012.00290.pdf)
>  We introduce the music Ternary Modalities Dataset (MTM Dataset), which is created by our group to learn joint representations among music three modalities in music information retrieval (MIR), including three types of cross-modal retrieval. Learning joint representations for cross-modal retrieval among three modalities has been limited because of the limited availability of large dataset including three or more modalities. The goal of MTM Dataset collection is to overcome the constraints by extending music notes to sheet music and music audio, and build music-note and syllable fine grained alignment, such that the dataset can be used to learn joint representation across multimodal music data. The MTM Dataset provides three modalities: sheet music, lyrics and music audio and their feature extracted by pre-trained models. In this paper, we describe the dataset and how it was built, and evaluate some baselines for cross-modal retrieval tasks. The dataset and usage examples are available at <a class="link-external link-https" href="https://github.com/MorningBooks/MTM-Dataset" rel="external noopener nofollow">this https URL</a>.      
### 42.CycleGAN without checkerboard artifacts for counter-forensics of fake-image detection  [ :arrow_down: ](https://arxiv.org/pdf/2012.00287.pdf)
>  In this paper, we propose a novel CycleGAN without checkerboard artifacts for counter-forensics of fake-image detection. Recent rapid advances in image manipulation tools and deep image synthesis techniques, such as Generative Adversarial Networks (GANs) have easily generated fake images, so detecting manipulated images has become an urgent issue. Most state-of-the-art forgery detection methods assume that images include checkerboard artifacts which are generated by using DNNs. Accordingly, we propose a novel CycleGAN without any checkerboard artifacts for counter-forensics of fake-mage detection methods for the first time, as an example of GANs without checkerboard artifacts.      
### 43.MILP-based Imitation Learning for HVAC control  [ :arrow_down: ](https://arxiv.org/pdf/2012.00286.pdf)
>  To optimize the operation of a HVAC system with advanced techniques such as artificial neural network, previous studies usually need forecast information in their method. However, the forecast information inevitably contains errors all the time, which degrade the performance of the HVAC operation. Hence, in this study, we propose MILP-based imitation learning method to control a HVAC system without using the forecast information in order to reduce energy cost and maintain thermal comfort at a given level. Our proposed controller is a deep neural network (DNN) trained by using data labeled by a MILP solver with historical data. After training, our controller is used to control the HVAC system with real-time data. For comparison, we also develop a second method named forecast-based MILP which control the HVAC system using the forecast information. The performance of the two methods is verified by using real outdoor temperatures and real day-ahead prices in Detroit city, Michigan, United States. Numerical results clearly show that the performance of the MILP-based imitation learning is better than that of the forecast-based MILP method in terms of hourly power consumption, daily energy cost, and thermal comfort. Moreover, the difference between results of the MILP-based imitation learning method and optimal results is almost negligible. These optimal results are achieved only by using the MILP solver at the end of a day when we have full information on the weather and prices for the day.      
### 44.Physical Layer Security Enhancement with Large Intelligent Surface-Assisted Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.00269.pdf)
>  Large intelligent surface (LIS)-aided wireless communications have drawn significant attention recently. We study the physical layer security of the downlink LIS-aided transmission framework for randomly located users in the presence of a multiple-antenna eavesdropper. To show the advantages of LIS-aided networks, we consider two practice scenarios: Communication with and without LIS. In both cases, we apply the stochastic geometry theory to derive exact probability density function (PDF) and cumulative distribution function (CDF) of signal-to-interference plus noise ratio. Furthermore, the obtained PDF and CDF are used to evaluate important security performance of wireless communication including the secrecy outage probability, the probability of nonzero secrecy capacity, and the average secrecy rate. In order to validate the accuracy of our analytical results, extensive Monte-Carlo simulations are subsequently conducted which provide interesting insights on how the secrecy performance is influenced by various important network parameters. Our results show that compared with the communication scenario without an LIS, the deployment of LIS can improve the performance and enhance the communication security substantially. In particular, the security performance of the system can be significantly improved by increasing the number of reflecting elements equipped in an LIS.      
### 45.Reconfigurable Intelligent Surface Aided TeraHertz Communications Under Misalignment and Hardware Impairments  [ :arrow_down: ](https://arxiv.org/pdf/2012.00267.pdf)
>  TeraHertz (THz) communications are envisioned to help satisfy the ever high data rates demand with massive bandwidth in the future wireless communication systems. However, severe path attenuation, transceiver antenna misalignment, and hardware imperfection greatly alleviate the performance of THz communications. To solve this challenge, we utilize the recently proposed reconfigurable intelligent surface (RIS) technology and provide a comprehensive analytical framework of RIS-aided THz communications. More specifically, we first prove that the small-scale amplitude fading of THz signals can be exactly modeled by the fluctuating two-ray distribution based on recent measurements. Exact statistical characterizations of end-to-end signal-to-noise plus distortion ratio (SNDR) and signal-to-noise ratio (SNR) are derived. Moreover, we propose a novel method of optimizing the phase-shifts at the RIS elements under discrete phase constraints. Finally, we derive analytical expressions for the outage probability and ergodic capacity, respectively. The tight upper bounds of ergodic capacity for both ideal and non-ideal radio frequency chains are obtained. We provided Monte-Carlo simulations to validate the accuracy of our results. It is interesting to find that the impact of path loss is more pronounced compared to others, and increasing the number of elements at the RIS can significantly improve the THz communication system performance.      
### 46.Performing with a Mobile Computer System for Vibraphone  [ :arrow_down: ](https://arxiv.org/pdf/2012.00265.pdf)
>  This paper describes the development of an Apple iPhone based mobile computer system for vibraphone and its use in a series of the author's performance projects in 2011 and 2012. This artistic research was motivated by a desire to develop an alternative to laptop computers for the author's existing percussion and computer performance practice. The aims were to develop a light, compact and flexible system using mobile devices that would allow computer music to infiltrate solo and ensemble performance situations where it is difficult to use a laptop computer. The project began with a system that brought computer elements to Nordlig Vinter, a suite of percussion duos, using an iPhone, RjDj, Pure Data and a home-made pickup system. This process was documented with video recordings and analysed using ethnographic methods. The mobile computer music setup proved to be elegant and convenient in performance situations with very little time and space to set up, as well as in performance classes and workshops. The simple mobile system encouraged experimentation and the platforms used enabled sharing with a wider audience.      
### 47.Strike on Stage: a percussion and media performance  [ :arrow_down: ](https://arxiv.org/pdf/2012.00250.pdf)
>  This paper describes Strike on Stage, an interface and corresponding audio-visual performance work developed and performed in 2010 by percussionists and media artists Chi-Hsia Lai and Charles Martin. The concept of Strike on Stage is to integrate computer visuals and sound into an improvised percussion performance. A large projection surface is positioned directly behind the performers, while a computer vision system tracks their movements. The setup allows computer visualisation and sonification to be directly responsive and unified with the performers' gestures.      
### 48.Cross-artform performance using networked interfaces: Last Man to Die's Vital LMTD  [ :arrow_down: ](https://arxiv.org/pdf/2012.00249.pdf)
>  In 2009 the cross artform group, Last Man to Die, presented a series of performances using new interfaces and networked performance to integrate the three artforms of its members (actor, Hanna Cormick, visual artist, Benjamin Forster and percussionist, Charles Martin). This paper explains our artistic motivations and design for a computer vision surface and networked heartbeat sensor as well as the experience of mounting our first major work, Vital LMTD.      
### 49.Analysis on viewing angle of holographic image reconstructed from digital Fourier hologram in holographic display  [ :arrow_down: ](https://arxiv.org/pdf/2012.00248.pdf)
>  We analyze the viewing angle of holographic image reconstructed from the digital Fourier hologram with an enhanced numerical aperture (NA). The viewing angle of reconstructed image depends on the NA of digital hologram that is determined by a focal length of Fourier lens and hologram size. The enhanced-NA digital hologram reconstructs the image with an angle larger than a diffraction angle of hologram pixel. We also characterize the aliasing effect of digital Fourier hologram, and find that the alias-free region exists even at a high numerical aperture. Numerical simulation and optical experiments are conducted to verify this interpretation of viewing angle of holographic images.      
### 50.Optimal Distributed Control for Leader-Follower Networks: A Scalable Design  [ :arrow_down: ](https://arxiv.org/pdf/2012.00239.pdf)
>  The focus of this paper is directed towards optimal control of multi-agent systems consisting of one leader and a number of followers in the presence of noise. The dynamics of every agent is assumed to be linear, and the performance index is a quadratic function of the states and actions of the leader and followers. The leader and followers are coupled in both dynamics and cost. The state of the leader and the average of the states of all followers (called mean-field) are common information and known to all agents; however, the local state of the followers are private information and unknown to other agents. It is shown that the optimal distributed control strategy is linear time-varying, and its computational complexity is independent of the number of followers. This strategy can be computed in a distributed manner, where the leader needs to solve one Riccati equation to determine its optimal strategy while each follower needs to solve two Riccati equations to obtain its optimal strategy. <br>This result is subsequently extended to the case of the infinite horizon discounted and undiscounted cost functions, where the optimal distributed strategy is shown to be stationary. A numerical example with $100$ followers is provided to demonstrate the efficacy of the results.      
### 51.Crowd-Sourced Road Quality Mapping in the Developing World  [ :arrow_down: ](https://arxiv.org/pdf/2012.00179.pdf)
>  Road networks are among the most essential components of a country's infrastructure. By facilitating the movement and exchange of goods, people, and ideas, they support economic and cultural activity both within and across borders. Up-to-date mapping of the the geographical distribution of roads and their quality is essential in high-impact applications ranging from land use planning to wilderness conservation. Mapping presents a particularly pressing challenge in developing countries, where documentation is poor and disproportionate amounts of road construction are expected to occur in the coming decades. We present a new crowd-sourced approach capable of assessing road quality and identify key challenges and opportunities in the transferability of deep learning based methods across domains.      
### 52.A Contemporary Survey on Free Space Optical Communication: Potential, Technical Challenges, Recent Advances and Research Direction  [ :arrow_down: ](https://arxiv.org/pdf/2012.00155.pdf)
>  Optical wireless communication (OWC) covering an ultra-wide range of unlicensed spectrum has emerged as an extent efficient solution to mitigate conventional RF spectrum scarcity ranging from communication distances from nm to several kilometers. Free space optical (FSO) systems operating near IR (NIR) band in OWC links has received substantial attention for enormous data transmission between fixed transceivers covering few kilometers path distance due to high optical bandwidth and higher bit rate as well. Despite the potential benefits of FSO technology, its widespread link reliability suffers especially in the long-range deployment due to atmospheric turbulence, cloud induced fading, some other environmental factors such as fog, aerosol, temperature variations, storms, heavy rain, cloud, pointing error, and scintillation. FSO has the potential to offloading massive traffic demands from RF networks, consequently the combined application of FSO/RF and radio over FSO (RoFSO) systems is regarded as an excellent solution to support 5G and beyond for improving the limitations of an individual system. This survey presents the overview of several key technologies and implications of state-of-the-art criteria in terms of spectrum reuse, classification, architecture and applications are described for understanding FSO. This paper provides principle, significance, demonstration, and recent technological development of FSO technology among different appealing optical wireless technologies. The opportunities in the near future, the potential challenges that need to be addressed to realize the successful deployment of FSO schemes are outlined.      
### 53.Robust error bounds for quantised and pruned neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.00138.pdf)
>  With the rise of smartphones and the internet-of-things, data is increasingly getting generated at the edge on local, personal devices. For privacy, latency and energy saving reasons, this shift is causing machine learning algorithms to move towards a decentralised approach, with the data and algorithms stored and even trained locally on devices. The device hardware becomes the main bottleneck for model performance in this set-up, creating a need for slimmed down, more efficient neural networks. Neural network pruning and quantisation are two methods that have been developed to achieve this, with both approaches demonstrating impressive results in reducing the computational cost without sacrificing too much on model performance. However, our understanding behind these methods remains underdeveloped. To address this issue, a semi-definite program to robustly bound the error caused by pruning and quantising a neural network is introduced in this paper. The method can be applied to generic neural networks, accounts for the many nonlinearities of the problem and holds robustly for all inputs in specified sets. It is hoped that the computed bounds will give certainty to software/control/machine learning engineers implementing these algorithms efficiently on limited hardware.      
### 54.Improving accuracy of rare words for RNN-Transducer through unigram shallow fusion  [ :arrow_down: ](https://arxiv.org/pdf/2012.00133.pdf)
>  End-to-end automatic speech recognition (ASR) systems, such as recurrent neural network transducer (RNN-T), have become popular, but rare word remains a challenge. In this paper, we propose a simple, yet effective method called unigram shallow fusion (USF) to improve rare words for RNN-T. In USF, we extract rare words from RNN-T training data based on unigram count, and apply a fixed reward when the word is encountered during decoding. We show that this simple method can improve performance on rare words by 3.7% WER relative without degradation on general test set, and the improvement from USF is additive to any additional language model based rescoring. Then, we show that the same USF does not work on conventional hybrid system. Finally, we reason that USF works by fixing errors in probability estimates of words due to Viterbi search used during decoding with subword-based RNN-T.      
### 55.Utilizing UNet for the future traffic map prediction task Traffic4cast challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2012.00125.pdf)
>  This paper describes our UNet based experiments on the Traffic4cast challenge 2020. Similar to the Traffic4cast challenge 2019, the task is to predict traffic flow volume, direction and speed on a high resolution map of three large cities worldwide. We mainly experimented with UNet based deep convolutional networks with various compositions of densely connected convolution layers, average pooling layers and max pooling layers. Three base UNet model types are tried and predictions are combined by averaging prediction scores or taking median value. Our method achieved best performance in this years newly built challenge dataset.      
### 56.A Cognitive Radio Enabled RF/FSO Communication Model for Aerial Relay Networks: Possible Configurations and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2012.00092.pdf)
>  Two emerging technologies, cognitive radio (CR) and free-space optical (FSO) communication, have created much interest both in academia and industry recently as they can fully utilize the spectrum while providing cost-efficient secure communication. In this article, motivated by the mounting interest in CR and FSO systems and by their ability to be rapidly deployed for civil and military applications, particularly in emergency situations, we propose a CR enabled radio frequency (RF)/FSO communication model for an aerial relay network. In the proposed model, CR enabled RF communication is employed for a ground-to-air channel to exploit the advantages of CR, including spectrum efficiency, multi-user connectivity, and spatial diversity. For an air-to-air channel, FSO communication is used, since the air-to-air path can provide perfect line-of-sight connectivity, which is vital for FSO systems. Finally, for an air-to-ground channel, a hybrid RF/FSO communication system is employed, where the RF communication functions as a backup for the FSO communication in the presence of adverse weather conditions. The proposed communication model is shown to be capable of fully utilizing the frequency spectrum, while effectively dealing with RF network problems of spectrum mobility and underutilization, especially for emergency conditions when multiple unmanned aerial vehicles (UAVs) are deployed.      
### 57.Time-Constant-Domain Spectroscopy: An Impedance-based Method for Sensing Biological Cells in Suspension  [ :arrow_down: ](https://arxiv.org/pdf/2012.00084.pdf)
>  Impedance measurement is a common technique to characterize and detect the electrical properties of biological cells. However, to decode the underlying physical processes, it requires complex electrical models alongside prior knowledge of the sample under study. In this work, we introduce an attractive label-free method for sensing biological cells in suspension based on the measurement of electrical impedance and the distribution of relaxation times (DRT) model. The DRT maps impedance data from the frequency-domain to a time-constant-domain spectrum (TCDS) being a useful and robust method for data analysis. We perform impedance measurements in the range from 1 kHz to 1 MHz to obtain the TCDS for sensing mimic samples as well as HeLa cells in suspension. Results show that the TCDS can be seen as an electrical fingerprint for the sample, as it can decode useful information about the composition and structure with high sensitivity and resolution.      

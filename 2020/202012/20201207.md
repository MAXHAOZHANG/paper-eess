# ArXiv eess --Mon, 7 Dec 2020
### 1.Energy-Efficient Design of Broad Beams for Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02768.pdf)
>  Massive MIMO is a promising air interface technique for 5G wireless communications. Such antennas offers capabilities to utilize channel correlations to create beams suitable for user specific transmissions. Most of the prior research is devoted to user-specific transmission in such systems, where a narrow beam is formed towards a user to improve its reception. Meanwhile, public-channel transmission to multiple users at once by means of broad beams has been understudied. In this paper, we introduce the concept of array-size invariant (ASI) beamforming, enabling generation of broad beams from very large antenna arrays where all elements are transmitting at maximum power. The ASI technique offers the possibility to achieve a perfectly flat array factor by exploiting the additional degree of freedom coming from polarization diversity. The technique is applicable to uniform linear and rectangular arrays and is characterized by low-complexity beam synthesis. The usefulness of the ASI beamforming is illustrated by means of a numerical example showing the design of a cell-specific broad beam for publicchannel transmission in a realistic network deployment.      
### 2.Statistical inference of the inter-sample Dice distribution for discriminative CNN brain lesion segmentation models  [ :arrow_down: ](https://arxiv.org/pdf/2012.02755.pdf)
>  Discriminative convolutional neural networks (CNNs), for which a voxel-wise conditional Multinoulli distribution is assumed, have performed well in many brain lesion segmentation tasks. For a trained discriminative CNN to be used in clinical practice, the patient's radiological features are inputted into the model, in which case a conditional distribution of segmentations is produced. Capturing the uncertainty of the predictions can be useful in deciding whether to abandon a model, or choose amongst competing models. In practice, however, we never know the ground truth segmentation, and therefore can never know the true model variance. In this work, segmentation sampling on discriminative CNNs is used to assess a trained model's robustness by analyzing the inter-sample dice distribution on a new patient solely based on their magnetic resonance (MR) images. Furthermore, by demonstrating the inter-sample Dice observations are independent and identically distributed with a finite mean and variance under certain conditions, a rigorous confidence based decision rule is proposed to decide whether to reject or accept a CNN model for a particular patient. Applied to the ISLES 2015 (SISS) dataset, the model identified 7 predictions as non-robust, and the average Dice coefficient calculated on the remaining brains improved by 12 percent.      
### 3.Model-plant mismatch learning offset-free model predictive control  [ :arrow_down: ](https://arxiv.org/pdf/2012.02753.pdf)
>  We propose model-plant mismatch learning offset-free model predictive control (MPC), which learns and applies the intrinsic model-plant mismatch, to effectively exploit the advantages of model-based and data-driven control strategies and overcome the limitations of each approach. In this study, the model-plant mismatch map on steady-state manifold in the controlled variable space is approximated via a general regression neural network from the steady-state data for each setpoint. Though the learned model-plant mismatch map can provide the information at the equilibrium point (i.e., setpoint), it cannot provide model-plant mismatch information during the transient state. Moreover, the intrinsic model-plant mismatch can vary due to system characteristics changes during operation. Therefore, we additionally apply a supplementary disturbance variable which is updated from the disturbance estimator based on the nominal offset-free MPC scheme. Then, the combined disturbance signal is applied to the target problem and finite-horizon optimal control problem of offset-free MPC to improve the prediction accuracy and closed-loop performance of the controller. By this, we can exploit both the learned model-plant mismatch information and the stabilizing property of the nominal disturbance estimator approach. The closed-loop simulation results demonstrate that the developed scheme can properly learn the intrinsic model-plant mismatch and efficiently improve the model-plant mismatch compensating performance in offset-free MPC. Moreover, we examine the robust asymptotic stability of the developed offset-free MPC scheme, which is known to be difficult to analyze in nominal offset-free MPC, by exploiting the learned model-plant mismatch information.      
### 4.Ultrasound Scatterer Density Classification Using Convolutional Neural Networks by Exploiting Patch Statistics  [ :arrow_down: ](https://arxiv.org/pdf/2012.02738.pdf)
>  Quantitative ultrasound (QUS) can reveal crucial information on tissue properties such as scatterer density. If the scatterer density per resolution cell is above or below 10, the tissue is considered as fully developed speckle (FDS) or low-density scatterers (LDS), respectively. Conventionally, the scatterer density has been classified using estimated statistical parameters of the amplitude of backscattered echoes. However, if the patch size is small, the estimation is not accurate. These parameters are also highly dependent on imaging settings. In this paper, we propose a convolutional neural network (CNN) architecture for QUS, and train it using simulation data. We further improve the network performance by utilizing patch statistics as additional input channels. We evaluate the network using simulation data, experimental phantoms and in vivo data. We also compare our proposed network with different classic and deep learning models, and demonstrate its superior performance in classification of tissues with different scatterer density values. The results also show that the proposed network is able to work with different imaging parameters with no need for a reference phantom. This work demonstrates the potential of CNNs in classifying scatterer density in ultrasound images.      
### 5.An Approach to State Signal Shaping by Limit Cycle Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2012.02697.pdf)
>  A novel nonlinear model predictive control approach for state signal shaping is proposed. The control strategy introduces a residual shape cost kernel based on the dynamics of circular limit cycles from a supercritical Neimark-Sacker bifurcation normal form. This allows the controller to impose a fundamental harmonic state signal shape with a specific frequency and amplitude. An application example for harmonic compensation in distribution grids integrated with renewable energies is presented. The controller is tasked with the calculation of the reference current for an active power filter used for load compensation. The results achieved are successful, reducing the harmonic distortion to satisfactory levels while ensuring the correct frequency and amplitude.      
### 6.Adaptive Charging Networks: A Framework for Smart Electric Vehicle Charging  [ :arrow_down: ](https://arxiv.org/pdf/2012.02636.pdf)
>  We describe the architecture and algorithms of the Adaptive Charging Network (ACN), which was first deployed on the Caltech campus in early 2016 and is currently operating at over 100 other sites in the United States. The architecture enables real-time monitoring and control and supports electric vehicle (EV) charging at scale. The ACN adopts a flexible Adaptive Scheduling Algorithm based on convex optimization and model predictive control and allows for significant over-subscription of electrical infrastructure. We describe some of the practical challenges in real-world charging systems, including unbalanced three-phase infrastructure, non-ideal battery charging behavior, and quantized control signals. We demonstrate how the Adaptive Scheduling Algorithm handles these challenges, and compare its performance against baseline algorithms from the deadline scheduling literature using real workloads recorded from the Caltech ACN and accurate system models. We find that in these realistic settings, our scheduling algorithm can improve operator profit by 3.4 times over uncontrolled charging and consistently outperforms baseline algorithms when delivering energy in highly congested systems.      
### 7.New Class K_infinity Function-Based Adaptive Sliding Mode Control Design  [ :arrow_down: ](https://arxiv.org/pdf/2012.02633.pdf)
>  To reduce the chattering and overestimation phenomena existing in classical adaptive sliding mode control, this paper presents a new class K_infinity function-based adaptive sliding mode control scheme. Two controllers are proposed in terms of concave and convex barrier functions to implement this kind of control methodology. To avoid large initial control magnitudes, two modified control schemes are provided, which extend the proposed methodology to different scenarios. It is proven that the proposed controllers yield finite-time convergence to a real sliding mode. Finally, simulations and discussions are presented to show the advantages and effectiveness of the proposed control methodology.      
### 8.GraphPB: Graphical Representations of Prosody Boundary in Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2012.02626.pdf)
>  This paper introduces a graphical representation approach of prosody boundary (GraphPB) in the task of Chinese speech synthesis, intending to parse the semantic and syntactic relationship of input sequences in a graphical domain for improving the prosody performance. The nodes of the graph embedding are formed by prosodic words, and the edges are formed by the other prosodic boundaries, namely prosodic phrase boundary (PPH) and intonation phrase boundary (IPH). Different Graph Neural Networks (GNN) like Gated Graph Neural Network (GGNN) and Graph Long Short-term Memory (G-LSTM) are utilised as graph encoders to exploit the graphical prosody boundary information. Graph-to-sequence model is proposed and formed by a graph encoder and an attentional decoder. Two techniques are proposed to embed sequential information into the graph-to-sequence text-to-speech model. The experimental results show that this proposed approach can encode the phonetic and prosody rhythm of an utterance. The mean opinion score (MOS) of these GNN models shows comparative results with the state-of-the-art sequence-to-sequence models with better performance in the aspect of prosody. This provides an alternative approach for prosody modelling in end-to-end speech synthesis.      
### 9.On Attitude Recovery of Spacecraft using Nonlinear Control  [ :arrow_down: ](https://arxiv.org/pdf/2012.02593.pdf)
>  The general objective of this Ph.D. thesis is to study the dynamics and control of rigid and flexible spacecraft supported by a high-fidelity numerical simulation environment. The demand for greater attitude pointing precision, attitude maneuvering or recovery with the increased use of lightweight and flexible materials necessitates the consideration of flexible dynamics in the control strategy. These highly nonlinear dynamics which increase the order of the system are extremely difficult to model with high degree of accuracy. A general model for attitude and flexible dynamics for a class of spacecraft is hence derived in detail based on the so-called hybrid coordinates approach. The spacecraft considered has a star topology with a rigid central bus and flexible plate-type appendages. Given that the flexible spacecraft is under-actuated, the input-output feedback linearization technique is specifically used to partition the system into two distinct parts, namely an external linear system and an internal unobservable nonlinear system. A general internal/zero dynamics theorem for a class of nonlinear systems is proved and then applied to a flexible spacecraft which results in a linear asymptotically stable zero dynamics. The overall closed-loop stability of the flexible spacecraft is also analyzed rigorously and shown to be locally asymptotically stable using the Lyapunov theory. The robustness of the controller against modeling and parametric uncertainties is examined through extensive numerical simulations. Overall, the feedback linearization control scheme has been proven to be feasible and efficient for the attitude recovery of a spacecraft and has also become front and center in other application areas in the recent years.      
### 10.Deep Interference Mitigation and Denoising of Real-World FMCW Radar Signals  [ :arrow_down: ](https://arxiv.org/pdf/2012.02529.pdf)
>  Radar sensors are crucial for environment perception of driver assistance systems as well as autonomous cars. Key performance factors are a fine range resolution and the possibility to directly measure velocity. With a rising number of radar sensors and the so far unregulated automotive radar frequency band, mutual interference is inevitable and must be dealt with. Sensors must be capable of detecting, or even mitigating the harmful effects of interference, which include a decreased detection sensitivity. In this paper, we evaluate a Convolutional Neural Network (CNN)-based approach for interference mitigation on real-world radar measurements. We combine real measurements with simulated interference in order to create input-output data suitable for training the model. We analyze the performance to model complexity relation on simulated and measurement data, based on an extensive parameter search. Further, a finite sample size performance comparison shows the effectiveness of the model trained on either simulated or real data as well as for transfer learning. A comparative performance analysis with the state of the art emphasizes the potential of CNN-based models for interference mitigation and denoising of real-world measurements, also considering resource constraints of the hardware.      
### 11.Distributed Optimization using Reduced Network Equivalents for Radial Power Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02473.pdf)
>  The limitations of centralized optimization methods for power systems operation have led to the distributed computing paradigm, particularly in power distribution systems. The existing techniques reported in recent literature for solving distributed optimization problems are not viable for power distribution systems applications. The essential drawback remains a large number of required communication rounds, i.e., macro-iterations among the computing agents to solve one instance of the optimization problem; the typical number of macro-iterations are in the order of 10^2~10^3. In this paper, a new and scalable distributed optimization method based on Equivalent Network Approximation (ENApp) is proposed to solve optimal power flow (OPF) for a balanced radial distribution system. Specifically, the distribution system's radial topology is leveraged to reduce the decomposed systems into upstream and downstream network equivalents. The proposed innovations reduce the required number of macro-iterations/communication-rounds for convergence by order of magnitude. The approach is validated using IEEE 123-bus and IEEE 8500-node test systems and is shown to converge to the same optimal solution as obtained using an equivalent centralized OPF (C-OPF) model.      
### 12.Offset Curves Loss for Imbalanced Problem in Medical Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2012.02463.pdf)
>  Medical image segmentation has played an important role in medical analysis and widely developed for many clinical applications. Deep learning-based approaches have achieved high performance in semantic segmentation but they are limited to pixel-wise setting and imbalanced classes data problem. In this paper, we tackle those limitations by developing a new deep learning-based model which takes into account both higher feature level i.e. region inside contour, intermediate feature level i.e. offset curves around the contour and lower feature level i.e. contour. Our proposed Offset Curves (OsC) loss consists of three main fitting terms. The first fitting term focuses on pixel-wise level segmentation whereas the second fitting term acts as attention model which pays attention to the area around the boundaries (offset curves). The third terms plays a role as regularization term which takes the length of boundaries into account. We evaluate our proposed OsC loss on both 2D network and 3D network. Two common medical datasets, i.e. retina DRIVE and brain tumor BRATS 2018 datasets are used to benchmark our proposed loss performance. The experiments have shown that our proposed OsC loss function outperforms other mainstream loss functions such as Cross-Entropy, Dice, Focal on the most common segmentation networks Unet, FCN.      
### 13.XraySyn: Realistic View Synthesis From a Single Radiograph Through CT Priors  [ :arrow_down: ](https://arxiv.org/pdf/2012.02407.pdf)
>  A radiograph visualizes the internal anatomy of a patient through the use of X-ray, which projects 3D information onto a 2D plane. Hence, radiograph analysis naturally requires physicians to relate the prior about 3D human anatomy to 2D radiographs. Synthesizing novel radiographic views in a small range can assist physicians in interpreting anatomy more reliably; however, radiograph view synthesis is heavily ill-posed, lacking in paired data, and lacking in differentiable operations to leverage learning-based approaches. To address these problems, we use Computed Tomography (CT) for radiograph simulation and design a differentiable projection algorithm, which enables us to achieve geometrically consistent transformations between the radiography and CT domains. Our method, XraySyn, can synthesize novel views on real radiographs through a combination of realistic simulation and finetuning on real radiographs. To the best of our knowledge, this is the first work on radiograph view synthesis. We show that by gaining an understanding of radiography in 3D space, our method can be applied to radiograph bone extraction and suppression without groundtruth bone labels.      
### 14.Cross-Layer Coordinated Attacks on Cyber-Physical Systems: A LQG Game Framework with Controlled Observations  [ :arrow_down: ](https://arxiv.org/pdf/2012.02384.pdf)
>  In this work, we establish a game-theoretic framework to study cross-layer coordinated attacks on cyber-physical systems (CPSs), where the attacker can simultaneously interfere the physical process and launch jamming attacks on the communication channels while the defender can dodge the jamming by dispensing with observations. The generic framework captures a wide variety of classic attack models on CPSs. Leveraging dynamic programming techniques, we fully characterize the Subgame Perfect Equilibrium (SPE) control strategies. We also specify the SPE observation and jamming strategies through dynamic programming equations and provide efficient computational methods to compute them. The results demonstrate that the physical and the cyber attacks are coordinated and depend on each other. On one hand, the control strategies are linear in the estimate, and the large estimate error caused by jamming will induce performance degradation. On the other hand, the capability in the physical layer has a significant impact on the observation and jamming strategies. Numerical examples illustrate the interesting interactions between the defender and the attacker through their observation and jamming strategies.      
### 15.Multi-Objective Digital PID Controller Design in Parameter Space  [ :arrow_down: ](https://arxiv.org/pdf/2012.02373.pdf)
>  This paper presents a multi-objective digital PID controller design method using the parameter space approach of robust control. Absolute stability is treated first by finding the digital PID controller gain parameter space corresponding to closed loop poles being inside the unit circle. Phase margin, gain margin and a mixed sensitivity bound are treated as frequency domain constraints. Determination of digital PID controller parameter space regions satisfying these constraints is presented. All of these regions are superimposed to obtain a multi-objective digital PID controller gain parameter space solution region. The path following controller design of an automated driving vehicle is used as an example to illustrate the method.      
### 16.Granger-faithfulness and link orientation in network reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2012.02332.pdf)
>  Networked dynamic systems are often abstracted as directed graphs, where the observed system processes form the vertex set and directed edges are used to represent non-zero transfer functions. Recovering the exact underlying graph structure of such a networked dynamic system, given only observational data, is a challenging task. Under relatively mild well-posedness assumptions on the network dynamics, there are state-of-the-art methods which can guarantee the absence of false positives. However, in this article we prove that under the same well-posedness assumptions, there are instances of networks for which any method is susceptible to inferring false negative edges or false positive edges. Borrowing a terminology from the theory of graphical models, we say those systems are unfaithful to their networks. We formalize a variant of faithfulness for dynamic systems, called Granger-faithfulness, and for a large class of dynamic networks, we show that Granger-unfaithful systems constitute a Lebesgue zero-measure set. For the same class of networks, under the Granger-faithfulness assumption, we provide an algorithm that reconstructs the network topology with guarantees for no false positive and no false negative edges in its output. We augment the topology reconstruction algorithm with orientation rules for some of the inferred edges, and we prove the rules are consistent under the Granger-faithfulness assumption.      
### 17.Fully Convolutional Network Bootstrapped by Word Encoding and Embedding for Activity Recognition in Smart Homes  [ :arrow_down: ](https://arxiv.org/pdf/2012.02300.pdf)
>  Activity recognition in smart homes is essential when we wish to propose automatic services for the inhabitants. However, it poses challenges in terms of variability of the environment, sensorimotor system, but also user habits. Therefore, endto-end systems fail at automatically extracting key features, without extensive pre-processing. We propose to tackle feature extraction for activity recognition in smart homes by merging methods from the Natural Language Processing (NLP) and the Time Series Classification (TSC) domains. We evaluate the performance of our method on two datasets issued from the Center for Advanced Studies in Adaptive Systems (CASAS). Moreover, we analyze the contributions of the use of NLP encoding Bag-Of-Word with Embedding as well as the ability of the FCN algorithm to automatically extract features and classify. The method we propose shows good performance in offline activity classification. Our analysis also shows that FCN is a suitable algorithm for smart home activity recognition and hightlights the advantages of automatic feature extraction.      
### 18.Low-Power Wireless Wearable ECG Monitoring Chestbelt Based on Ferroelectric Microprocessor  [ :arrow_down: ](https://arxiv.org/pdf/2012.02290.pdf)
>  Since cadiovascular disease (CVD) posts a heavy threat to people's health, long-term electrocardiogram (ECG) monitoring is of great value for the improvement of treatment. To realize remote long-term ECG monitoring, a low-power wireless wearable ECG monitoring device is proposed in this paper. The ECG monitoring device, abbreviated as ECGM, is designed based on ferroelectric microprocessor which provides ultra-low power consumption and contains four parts-MCU, BLE, Sensors and Power. The MCU part means circuit of MSP430FR2433, the core of ECGM. The BLE part is the CC2640R2F module applied for wireless transmission of the collected bio-signal data. And the sensors part includes several sensors like BMD101 used for monitoring bio-signals and motion of the wearer, while the Power part consists of battery circuit, charging circuit and 3.3V/1.8V/4.4V power supply circuit. The ECGM first collects ECG signals from the fabric electrodes adhered to wearers' chest, preprocesses the signals to eliminate the injected noise, and then transmit the output data to wearers' hand-held mobile phones through Bluetooth low energy (BLE). The wearers are enabled to acquire ECGs and other physiological parameters on their phones as well as some corresponding suggestions. The novelty of the system lies in the combination of low-power ECG sensor chip with ferroelectric microprocessor, thus achieving ultra-low power consumption and high signal quality.      
### 19.Digital Twin of Distribution Power Transformer for Real-Time Monitoring of Medium Voltage from Low Voltage Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2012.02286.pdf)
>  Real-time monitoring of distribution systems has be-come necessary, due to the deregulation of electricity markets and the wide deployment of distributed energy resources. To monitor voltage and current at sub-cycle detail, requires, typically, major investment undertaking and disruptions to the operation of the grid. In this work, measurements of the low voltage (LV) side of distribution transformers (T/F) are used to calculate in real time the waveforms of their medium voltage (MV) sides, based on a mathematical model of said T/F. This model is, essentially, the dig-ital twin of the MV side of the T/F. The method calculates T/F MV waveforms of voltage and current, and active and reactive power as accurately as an instrument T/F, captures all harmonics con-tent, is unaffected by asymmetrical loading and identifies most sys-tem faults on the MV side of the T/F. The digital twin method en-ables monitoring of distribution T/F that avoids MV instrumenta-tion, does not suffer in accuracy and may be readily deployable. Field data from an actual MV-LV T/F, agree with simulation re-sults showcasing the efficacy of the digital twin method.      
### 20.A Practical Proposal for State Estimation at Balanced, Radial Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02283.pdf)
>  The ever-increasing deployment of distributed resources and the opportunities offered to loads for more active roles has changed the previously unidirectional and relatively straight-forward operating profile of distribution systems (DS). DS will be required to be monitored closely for robustness and sufficient power quality. State estimation of transmission systems has consistently served as a monitoring tool, which drives system-wide control actions and, thus, ensures the operational integrity of the electric grid. An update to the classic state estimation for the case of DS is offered in this work, based on a power flow formulation for radial networks that does not require measurements or estimate of the voltage angles.      
### 21.Multiscale Attention Guided Network for COVID-19 Detection Using Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.02278.pdf)
>  Coronavirus disease 2019 (COVID-19) is one of the most destructive pandemic after millennium, forcing the world to tackle a health crisis. Automated classification of lung infections from chest X-ray (CXR) images strengthened traditional healthcare strategy to handle COVID-19. However, classifying COVID-19 from pneumonia cases using CXR image is challenging because of shared spatial characteristics, high feature variation in infections and contrast diversity between cases. Moreover, massive data collection is impractical for a newly emerged disease, which limited the performance of common deep learning models. To address this challenging topic, Multiscale Attention Guided deep network with Soft Distance regularization (MAG-SD) is proposed to automatically classify COVID-19 from pneumonia CXR images. In MAG-SD, MA-Net is used to produce prediction vector and attention map from multiscale feature maps. To relieve the shortage of training data, attention guided augmentations along with a soft distance regularization are posed, which requires a few labeled data to generate meaningful augmentations and reduce noise. Our multiscale attention model achieves better classification performance on our pneumonia CXR image dataset. Plentiful experiments are proposed for MAG-SD which demonstrates that it has its unique advantage in pneumonia classification over cuttingedge models. The code is available at <a class="link-external link-https" href="https://github.com/" rel="external noopener nofollow">this https URL</a> JasonLeeGHub/MAG-SD.      
### 22.Algorithm To Calculate Pulse from PPG Signal After Eliminating Touch Errors from the Fingertip Video Captured by Smartphone Camera  [ :arrow_down: ](https://arxiv.org/pdf/2012.02263.pdf)
>  With the ongoing heart problems of the population worldwide, the medical requirements of the people are expected to increase. Electrocardiogram (ECG) is one of the proven to capture the heart response signal to assess the electrical and muscular functions of the heart. The ECG setup is expensive and needs proper training, and of course, it is not instant. For fast, accurate heart parameter monitoring, scientists pay attention to the photoplethysmogram signal (PPG), based on the light intensity of a particular wavelength. Android smartphone with a good quality camera has come to ordinary people's reach and has become one of the most necessary and rugged devices for today and future generations. We can use its powerful features to solve or assess heart state monitoring by capturing the image's necessary data. The mobile camera has a photo emitting diode and a photodetector. The light source illuminates the tissue. The photodetector calculates the small variation in light intensity associated with blood volume change in the vessels (mainly fingertips, toes, and ears). We have captured unfocused contact video to capture PPG using an Android Smartphone. Then, we removed a certain percent of camera touch errors based on average pixel intensity count in the red plane, and it is a new approach that has been introduced in this research. We used a 2nd order Butterworth (IIR) band pass filter for noise removal, FFT Hann Window for frequency analysis and leakage reduction. We have developed an algorithm using MATLAB as a development platform, for accurate pulse (BPM) measurement. Moreover, we have done a comparative analysis of developed algorithm with other available algorithms for PPG-based pulse calculation. In this study, the fingertip video was captured when the body was at rest      
### 23.Toe-Heal-Air-Injection Thermal Recovery Production Prediction and Modelling Using Quadratic Poisson Polynomial Regression  [ :arrow_down: ](https://arxiv.org/pdf/2012.02262.pdf)
>  This research paper explores application of multivariable regression models using only reservoir temperatures for predicting oil and gas production in a Toe-Heal-Air-Injection (THAI) enhanced oil recovery process. This paper discusses effects of statistical interaction between thermocouples by using second degree quadratic polynomials, which showed significant production forecast accuracy. Interactions among thermocouples statistically include temperature of larger reservoir areas, hence improving the predictive models. The interaction of two thermocouples can be interpreted as temperature gradient of combustion zone as moving forward during THAI operations life cycle. <br>Second degree polynomial regression including interactions showed major prediction improvement for both oil and natural gas productions compare to simple regression models. Application of Poisson regression slightly improved prediction accuracy for oil production and was less effective on improving natural gas production predictions. Quadratic Poisson regression models showed realistic production prediction method for both oil and gas production values, due to the nature of Poisson probability distribution which is non-negative for rates and count values.      
### 24.Creating a Baseline for Robust Energy Savings Estimation in Households  [ :arrow_down: ](https://arxiv.org/pdf/2012.02257.pdf)
>  In this paper we present a methodology appropriate for establishing a user-specific hourly-based benchmark period of energy consumption. Such values can be used as reference for explicitly calculating energy savings. The required equipment is limited to low cost sensors. The so-called baseline allows for an explicit comparison of the household consumption now and then, once appropriate adjustments are made to handle the different conditions (e.g. temperature variation). When involving user motivation strategies, hourly based energy savings can provide multiple advantages. However, there are two major factors affecting the baseline construction: corrupted or missing data values and unordinary patterns. In this paper we provide an analytical methodology to handle such scenarios and create year-long hourly-based consumption baseline.      
### 25.A Novel Approach to Radiometric Identification  [ :arrow_down: ](https://arxiv.org/pdf/2012.02256.pdf)
>  This paper demonstrates that highly accurate radiometric identification is possible using CAPoNeF feature engineering method. We tested basic ML classification algorithms on experimental data gathered by SDR. The statistical and correlational properties of suggested features were analyzed first with the help of Point Biserial and Pearson Correlation Coefficients and then using P-values. The most relevant features were highlighted. Random Forest provided 99% accuracy. We give LIME description of model behavior. It turns out that even if the dimension of the feature space is reduced to 3, it is still possible to classify devices with 99% accuracy.      
### 26.Efficient power allocation using graph neural networks and deep algorithm unfolding  [ :arrow_down: ](https://arxiv.org/pdf/2012.02250.pdf)
>  We study the problem of optimal power allocation in a single-hop ad hoc wireless network. In solving this problem, we propose a hybrid neural architecture inspired by the algorithmic unfolding of the iterative weighted minimum mean squared error (WMMSE) method, that we denote as unfolded WMMSE (UWMMSE). The learnable weights within UWMMSE are parameterized using graph neural networks (GNNs), where the time-varying underlying graphs are given by the fading interference coefficients in the wireless network. These GNNs are trained through a gradient descent approach based on multiple instances of the power allocation problem. Once trained, UWMMSE achieves performance comparable to that of WMMSE while significantly reducing the computational complexity. This phenomenon is illustrated through numerical experiments along with the robustness and generalization to wireless networks of different densities and sizes.      
### 27.Exploring the Effect of Image Enhancement Techniques on COVID-19 Detection using Chest X-rays Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.02238.pdf)
>  The use of computer-aided diagnosis in the reliable and fast detection of coronavirus disease (COVID-19) has become a necessity to prevent the spread of the virus during the pandemic to ease the burden on the medical infrastructure. Chest X-ray (CXR) imaging has several advantages over other imaging techniques as it is cheap, easily accessible, fast and portable. This paper explores the effect of various popular image enhancement techniques and states the effect of each of them on the detection performance. We have compiled the largest X-ray dataset called COVQU-20, consisting of 18,479 normal, non-COVID lung opacity and COVID-19 CXR images. To the best of our knowledge, this is the largest public COVID positive database. Ground glass opacity is the common symptom reported in COVID-19 pneumonia patients and so a mixture of 3616 COVID-19, 6012 non-COVID lung opacity, and 8851 normal chest X-ray images were used to create this dataset. Five different image enhancement techniques: histogram equalization, contrast limited adaptive histogram equalization, image complement, gamma correction, and Balance Contrast Enhancement Technique were used to improve COVID-19 detection accuracy. Six different Convolutional Neural Networks (CNNs) were investigated in this study. Gamma correction technique outperforms other enhancement techniques in detecting COVID-19 from standard and segmented lung CXR images. The accuracy, precision, sensitivity, f1-score, and specificity in the detection of COVID-19 with gamma correction on CXR images were 96.29%, 96.28%, 96.29%, 96.28% and 96.27% respectively. The accuracy, precision, sensitivity, F1-score, and specificity were 95.11 %, 94.55 %, 94.56 %, 94.53 % and 95.59 % respectively for segmented lung images. The proposed approach with very high and comparable performance will boost the fast and robust COVID-19 detection using chest X-ray images.      
### 28.COVID-CLNet: COVID-19 Detection with Compressive Deep Learning Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2012.02234.pdf)
>  One of the most serious global health threat is COVID-19 pandemic. The emphasis on improving diagnosis and increasing the diagnostic capability helps stopping its spread significantly. Therefore, to assist the radiologist or other medical professional to detect and identify the COVID-19 cases in the shortest possible time, we propose a computer-aided detection (CADe) system that uses the computed tomography (CT) scan images. This proposed boosted deep learning network (CLNet) is based on the implementation of Deep Learning (DL) networks as a complementary to the Compressive Learning (CL). We utilize our inception feature extraction technique in the measurement domain using CL to represent the data features into a new space with less dimensionality before accessing the Convolutional Neural Network. All original features have been contributed equally in the new space using a sensing matrix. Experiments performed on different compressed methods show promising results for COVID-19 detection. In addition, our novel weighted method based on different sensing matrices that used to capture boosted features demonstrates an improvement in the performance of the proposed method.      
### 29.A Correspondence Variational Autoencoder for Unsupervised Acoustic Word Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2012.02221.pdf)
>  We propose a new unsupervised model for mapping a variable-duration speech segment to a fixed-dimensional representation. The resulting acoustic word embeddings can form the basis of search, discovery, and indexing systems for low- and zero-resource languages. Our model, which we refer to as a maximal sampling correspondence variational autoencoder (MCVAE), is a recurrent neural network (RNN) trained with a novel self-supervised correspondence loss that encourages consistency between embeddings of different instances of the same word. Our training scheme improves on previous correspondence training approaches through the use and comparison of multiple samples from the approximate posterior distribution. In the zero-resource setting, the MCVAE can be trained in an unsupervised way, without any ground-truth word pairs, by using the word-like segments discovered via an unsupervised term discovery system. In both this setting and a semi-supervised low-resource setting (with a limited set of ground-truth word pairs), the MCVAE outperforms previous state-of-the-art models, such as Siamese-, CAE- and VAE-based RNNs.      
### 30.Learning to Fuse Asymmetric Feature Maps in Siamese Trackers  [ :arrow_down: ](https://arxiv.org/pdf/2012.02776.pdf)
>  In recent years, Siamese-based trackers have achieved promising performance in visual tracking. Most recent Siamese-based trackers typically employ a depth-wise cross-correlation (DW-XCorr) to obtain multi-channel correlation information from the two feature maps (target and search region). However, DW-XCorr has several limitations within Siamese-based tracking: it can easily be fooled by distractors, has fewer activated channels, and provides weak discrimination of object boundaries. Further, DW-XCorr is a handcrafted parameter-free module and cannot fully benefit from offline learning on large-scale data. <br>We propose a learnable module, called the asymmetric convolution (ACM), which learns to better capture the semantic correlation information in offline training on large-scale data. Different from DW-XCorr and its predecessor (XCorr), which regard a single feature map as the convolution kernel, our ACM decomposes the convolution operation on a concatenated feature map into two mathematically equivalent operations, thereby avoiding the need for the feature maps to be of the same size (width and height) during concatenation. Our ACM can incorporate useful prior information, such as bounding-box size, with standard visual features. Furthermore, ACM can easily be integrated into existing Siamese trackers based on DW-XCorr or XCorr. To demonstrate its generalization ability, we integrate ACM into three representative trackers: SiamFC, SiamRPN++, and SiamBAN. Our experiments reveal the benefits of the proposed ACM, which outperforms existing methods on six tracking benchmarks. On the LaSOT test set, our ACM-based tracker obtains a significant improvement of 5.8% in terms of success (AUC), over the baseline.      
### 31.Massive MIMO with Dense Arrays and 1-bit Data Converters  [ :arrow_down: ](https://arxiv.org/pdf/2012.02680.pdf)
>  We consider wireless communication systems with compact planar arrays having densely spaced antenna elements in conjunction with one-bit analog-to-digital and digital-to-analog converters (ADCs/DACs). We provide closed-form expressions for the achievable rates with simple linear processing techniques for the uplink as well as the downlink scenarios while taking into account the effects of antenna mutual coupling. In the downlink case, we introduce the concept of non-radiating dithering to combat correlations of the quantization errors. Under higher antenna element density, we show that the performance of the quantized system can be made close to the ideal performance regardless of the operating signal-to-noise ratio.      
### 32.Detecting 32 Pedestrian Attributes for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2012.02647.pdf)
>  Pedestrians are arguably one of the most safety-critical road users to consider for autonomous vehicles in urban areas. In this paper, we address the problem of jointly detecting pedestrians and recognizing 32 pedestrian attributes. These encompass visual appearance and behavior, and also include the forecasting of road crossing, which is a main safety concern. For this, we introduce a Multi-Task Learning (MTL) model relying on a composite field framework, which achieves both goals in an efficient way. Each field spatially locates pedestrian instances and aggregates attribute predictions over them. This formulation naturally leverages spatial context, making it well suited to low resolution scenarios such as autonomous driving. By increasing the number of attributes jointly learned, we highlight an issue related to the scales of gradients, which arises in MTL with numerous tasks. We solve it by normalizing the gradients coming from different objective functions when they join at the fork in the network architecture during the backward pass, referred to as fork-normalization. Experimental validation is performed on JAAD, a dataset providing numerous attributes for pedestrian analysis from autonomous vehicles, and shows competitive detection and attribute recognition results, as well as a more stable MTL training.      
### 33.Predicting Emotions Perceived from Sounds  [ :arrow_down: ](https://arxiv.org/pdf/2012.02643.pdf)
>  Sonification is the science of communication of data and events to users through sounds. Auditory icons, earcons, and speech are the common auditory display schemes utilized in sonification, or more specifically in the use of audio to convey information. Once the captured data are perceived, their meanings, and more importantly, intentions can be interpreted more easily and thus can be employed as a complement to visualization techniques. Through auditory perception it is possible to convey information related to temporal, spatial, or some other context-oriented information. An important research question is whether the emotions perceived from these auditory icons or earcons are predictable in order to build an automated sonification platform. This paper conducts an experiment through which several mainstream and conventional machine learning algorithms are developed to study the prediction of emotions perceived from sounds. To do so, the key features of sounds are captured and then are modeled using machine learning algorithms using feature reduction techniques. We observe that it is possible to predict perceived emotions with high accuracy. In particular, the regression based on Random Forest demonstrated its superiority compared to other machine learning algorithms.      
### 34.Reviewing the role of the extinction coefficient in radar remote sensing  [ :arrow_down: ](https://arxiv.org/pdf/2012.02609.pdf)
>  This report revisits the role of the extinction coefficient in radar backscattering-based models for forest monitoring. A review of a number of works dealing with this issue has revealed a diversity of extinction values being unclear its dependence on the sensor frequency and the forest type. In addition, a backscattering model directly derived from the RVoG formulation is employed to analyse the saturation of backscattering level as a function of vegetation height and the presence of a decreasing trend of backscatter beyond the saturation point as suggested in previous works in the literature. According to this analysis it seems reasonable to think that further research specially focused on dedicated experimental measurements of the extinction coefficient should be carried out.      
### 35.A high performance approach to detecting small targets in long range low quality infrared videos  [ :arrow_down: ](https://arxiv.org/pdf/2012.02579.pdf)
>  Since targets are small in long range infrared (IR) videos, it is challenging to accurately detect targets in those videos. In this paper, we propose a high performance approach to detecting small targets in long range and low quality infrared videos. Our approach consists of a video resolution enhancement module, a proven small target detector based on local intensity and gradient (LIG), a connected component (CC) analysis module, and a track association module to connect detections from multiple frames. Extensive experiments using actual mid-wave infrared (MWIR) videos in ranges between 3500 m and 5000 m from a benchmark dataset clearly demonstrated the efficacy of the proposed approach.      
### 36.Deep Learning for Wrist Fracture Detection: Are We There Yet?  [ :arrow_down: ](https://arxiv.org/pdf/2012.02577.pdf)
>  Wrist Fracture is the most common type of fracture with a high incidence rate. Conventional radiography (i.e. X-ray imaging) is used for wrist fracture detection routinely, but occasionally fracture delineation poses issues and an additional confirmation by computed tomography (CT) is needed for diagnosis. Recent advances in the field of Deep Learning (DL), a subfield of Artificial Intelligence (AI), have shown that wrist fracture detection can be automated using Convolutional Neural Networks. However, previous studies did not pay close attention to the difficult cases which can only be confirmed via CT imaging. In this study, we have developed and analyzed a state-of-the-art DL-based pipeline for wrist (distal radius) fracture detection -- DeepWrist, and evaluated it against one general population test set, and one challenging test set comprising only cases requiring confirmation by CT. Our results reveal that a typical state-of-the-art approach, such as DeepWrist, while having a near-perfect performance on the general independent test set, has a substantially lower performance on the challenging test set -- average precision of 0.99 (0.99-0.99) vs 0.64 (0.46-0.83), respectively. Similarly, the area under the ROC curve was of 0.99 (0.98-0.99) vs 0.84 (0.72-0.93), respectively. Our findings highlight the importance of a meticulous analysis of DL-based models before clinical use, and unearth the need for more challenging settings for testing medical AI systems.      
### 37.Joint Channel Estimation and Data Decoding using SVM-based Receivers  [ :arrow_down: ](https://arxiv.org/pdf/2012.02523.pdf)
>  Modern communication systems organize receivers in blocks in order to simplify their analysis and design. However, an approach that considers the receiver design from a wider perspective rather than treating it block-by-block may take advantage of the impacts of these blocks on each other and provide better performance. Herein, we can benefit from machine learning and compose a receiver model implementing supervised learning techniques. With this motivation, we consider a one-to-one transmission system over a flat fast fading wireless channel and propose a support vector machines (SVM)-based receiver that combines the pilot-based channel estimation, data demodulation and decoding processes in one joint operation. We follow two techniques in the receiver design. We first design one SVM-based classifier that outputs the class of the encoding codeword that enters the encoder at the transmitter side. Then, we put forward a model with one SVM-based classifier per one bit in the encoding codeword, where each classifier assigns the value of the corresponding bit in the encoding vector. With the second technique, we simplify the receiver design especially for longer encoding codewords. We show that the SVM-based receiver performs very closely to the maximum likelihood decoder, which is known to be the optimal decoding strategy when the encoding vectors at the transmitter are equally likely. We further show that the SVM-based receiver outperforms the conventional receivers that perform channel estimation, data demodulation and decoding in blocks. Finally, we show that we can train the SVM-based receiver with 1-bit analog-to-digital converter (ADC) outputs and the SVM-based receiver can perform very closely to the conventional receivers that take 32-bit ADC outputs as inputs.      
### 38.AuthNet: A Deep Learning based Authentication Mechanism using Temporal Facial Feature Movements  [ :arrow_down: ](https://arxiv.org/pdf/2012.02515.pdf)
>  Biometric systems based on Machine learning and Deep learning are being extensively used as authentication mechanisms in resource-constrained environments like smartphones and other small computing devices. These AI-powered facial recognition mechanisms have gained enormous popularity in recent years due to their transparent, contact-less and non-invasive nature. While they are effective to a large extent, there are ways to gain unauthorized access using photographs, masks, glasses, etc. In this paper, we propose an alternative authentication mechanism that uses both facial recognition and the unique movements of that particular face while uttering a password, that is, the temporal facial feature movements. The proposed model is not inhibited by language barriers because a user can set a password in any language. When evaluated on the standard MIRACL-VC1 dataset, the proposed model achieved an accuracy of 98.1\%, underscoring its effectiveness as an effective and robust system. The proposed method is also data efficient, since the model gave good results even when trained with only 10 positive video samples. The competence of the training of the network is also demonstrated by benchmarking the proposed system against various compounded Facial recognition and Lip reading models.      
### 39.Reconfigurable Intelligent Surface Aided Secure Transmission Exploiting Statistical CSI of Eavesdropper  [ :arrow_down: ](https://arxiv.org/pdf/2012.02466.pdf)
>  We investigate the reconfigurable intelligent surface (RIS) aided downlink secure transmission where only the statistical channel of eavesdropper is available. To handle the stochastic ergodic secrecy rate (ESR) maximization problem, a deterministic lower bound of ESR (LESR) is derived. We aim to maximize the LESR by jointly designing the transmit beamforming at the access point (AP) and reflect beamforming by the phase shifts at the RIS. Based on penalty dual decomposition (PDD) framework and block successive convex approximation (BSCA) algorithm, a penalty dual convex approximation (PDCA) algorithm with low computational complexity is proposed and a Karush-Kuhn-Tucker (KKT) solution of this non-convex LESR maximization problem is guaranteed. Simulation results show that the proposed PDCA scheme is better than the commonly used alternating optimization (AO) scheme with the knowledge of statistical channel of eavesdropper.      
### 40.Entanglement and quantum strategies reduce congestion costs in quantum Pigou networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.02465.pdf)
>  Pigou's problem has many applications in real life scenarios like traffic networks, graph theory, data transfer in internet networks, etc. The two player classical Pigou's network has an unique Nash equilibrium with the Price of Stability and Price of Anarchy agreeing with each other. The situation changes for the $k-$person classical Pigou's network with $n$ being the total number of people. If we fix the behaviour of $(n-2)$ people and assume that $k-$persons take path $P_2$ where $k&lt;(n-2)$ and the remaining take path $P_1$, the minimum cost of Nash equilibrium becomes $k$ dependent and we find a particular $k$ for which the cost is an absolute minimum. In contrast to the two person classical Pigou's network, the quantum two qubit Pigou's network with maximal entanglement gives a lower cost for the Nash equilibrium, while in contrast to $k-$person classical Pigou's network, it's quantum version gives reduced cost for the Nash equilibrium strategy. This has major implications for information transfer in both classical as well as quantum data networks. By employing entanglement and quantum strategies, one can significantly reduce congestion costs in quantum data networks.      
### 41.Acoustic Hologram Optimisation Using Automatic Differentiation  [ :arrow_down: ](https://arxiv.org/pdf/2012.02431.pdf)
>  Acoustic holograms are the keystone of modern acoustics. It encodes three-dimensional acoustic fields in two dimensions, and its quality determine the performance of acoustic systems. Optimisation methods that control only the phase of an acoustic wave are considered inferior to methods that control both the amplitude and phase of the wave. In this paper, we present Diff-PAT, an acoustic hologram optimisation algorithm with automatic differentiation. We demonstrate that our method achieves superior accuracy than conventional methods. The performance of Diff-PAT was evaluated by randomly generating 1000 sets of up to 32 control points for single-sided arrays and single-axis arrays. The improved acoustic hologram can be used in wide range of applications of PATs without introducing any changes to existing systems that control the PATs. In addition, we applied Diff-PAT to acoustic metamaterial and achieved an &gt;8 dB increase in the peak noise-to-signal ratio of acoustic hologram.      
### 42.Constrained Risk-Averse Markov Decision Processes  [ :arrow_down: ](https://arxiv.org/pdf/2012.02423.pdf)
>  We consider the problem of designing policies for Markov decision processes (MDPs) with dynamic coherent risk objectives and constraints. We begin by formulating the problem in a Lagrangian framework. Under the assumption that the risk objectives and constraints can be represented by a Markov risk transition mapping, we propose an optimization-based method to synthesize Markovian policies that lower-bound the constrained risk-averse problem. We demonstrate that the formulated optimization problems are in the form of difference convex programs (DCPs) and can be solved by the disciplined convex-concave programming (DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. Finally, we illustrate the effectiveness of the proposed method with numerical experiments on a rover navigation problem involving conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent risk measures.      
### 43.Generator Pyramid for High-Resolution Image Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2012.02381.pdf)
>  Inpainting high-resolution images with large holes challenges existing deep learning based image inpainting methods. We present a novel framework -- PyramidFill for high-resolution image inpainting task, which explicitly disentangles content completion and texture synthesis. PyramidFill attempts to complete the content of unknown regions in a lower-resolution image, and synthesis the textures of unknown regions in a higher-resolution image, progressively. Thus, our model consists of a pyramid of fully convolutional GANs, wherein the content GAN is responsible for completing contents in the lowest-resolution masked image, and each texture GAN is responsible for synthesizing textures in a higher-resolution image. Since completing contents and synthesising textures demand different abilities from generators, we customize different architectures for the content GAN and texture GAN. Experiments on multiple datasets including CelebA-HQ, Places2 and a new natural scenery dataset (NSHQ) with different resolutions demonstrate that PyramidFill generates higher-quality inpainting results than the state-of-the-art methods. To better assess high-resolution image inpainting methods, we will release NSHQ, high-quality natural scenery images with high-resolution 1920$\times$1080.      
### 44.Optical Wavelength Guided Self-Supervised Feature Learning For Galaxy Cluster Richness Estimate  [ :arrow_down: ](https://arxiv.org/pdf/2012.02368.pdf)
>  Most galaxies in the nearby Universe are gravitationally bound to a cluster or group of galaxies. Their optical contents, such as optical richness, are crucial for understanding the co-evolution of galaxies and large-scale structures in modern astronomy and cosmology. The determination of optical richness can be challenging. We propose a self-supervised approach for estimating optical richness from multi-band optical images. The method uses the data properties of the multi-band optical images for pre-training, which enables learning feature representations from a large but unlabeled dataset. We apply the proposed method to the Sloan Digital Sky Survey. The result shows our estimate of optical richness lowers the mean absolute error and intrinsic scatter by 11.84% and 20.78%, respectively, while reducing the need for labeled training data by up to 60%. We believe the proposed method will benefit astronomy and cosmology, where a large number of unlabeled multi-band images are available, but acquiring image labels is costly.      
### 45.Deep Learning for Medical Anomaly Detection -- A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2012.02364.pdf)
>  Machine learning-based medical anomaly detection is an important problem that has been extensively studied. Numerous approaches have been proposed across various medical application domains and we observe several similarities across these distinct applications. Despite this comparability, we observe a lack of structured organisation of these diverse research applications such that their advantages and limitations can be studied. The principal aim of this survey is to provide a thorough theoretical analysis of popular deep learning techniques in medical anomaly detection. In particular, we contribute a coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms. Furthermore, we provide a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions. In addition, we outline the key limitations of existing deep medical anomaly detection techniques and propose key research directions for further investigation.      
### 46.Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data  [ :arrow_down: ](https://arxiv.org/pdf/2012.02334.pdf)
>  The last few years have witnessed an increased interest in incorporating physics-informed inductive bias in deep learning frameworks. In particular, a growing volume of literature has been exploring ways to enforce energy conservation while using neural networks for learning dynamics from observed time-series data. In this work, we present a comparative analysis of the energy-conserving neural networks - for example, deep Lagrangian network, Hamiltonian neural network, etc. - wherein the underlying physics is encoded in their computation graph. We focus on ten neural network models and explain the similarities and differences between the models. We compare their performance in 4 different physical systems. Our result highlights that using a high-dimensional coordinate system and then imposing restrictions via explicit constraints can lead to higher accuracy in the learned dynamics. We also point out the possibility of leveraging some of these energy-conserving models to design energy-based controllers.      
### 47.A Laptop Ensemble Performance System using Recurrent Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.02322.pdf)
>  The popularity of applying machine learning techniques in musical domains has created an inherent availability of freely accessible pre-trained neural network (NN) models ready for use in creative applications. This work outlines the implementation of one such application in the form of an assistance tool designed for live improvisational performances by laptop ensembles. The primary intention was to leverage off-the-shelf pre-trained NN models as a basis for assisting individual performers either as musical novices looking to engage with more experienced performers or as a tool to expand musical possibilities through new forms of creative expression. The system expands upon a variety of ideas found in different research areas including new interfaces for musical expression, generative music and group performance to produce a networked performance solution served via a web-browser interface. The final implementation of the system offers performers a mixture of high and low-level controls to influence the shape of sequences of notes output by locally run NN models in real time, also allowing performers to define their level of engagement with the assisting generative models. Two test performances were played, with the system shown to feasibly support four performers over a four minute piece while producing musically cohesive and engaging music. Iterations on the design of the system exposed technical constraints on the use of a JavaScript environment for generative models in a live music context, largely derived from inescapable processing overheads.      
### 48.Sonic Sculpture: Activating Engagement with Head-Mounted Augmented Reality  [ :arrow_down: ](https://arxiv.org/pdf/2012.02311.pdf)
>  This work examines how head-mounted AR can be used to build an interactive sonic landscape to engage with a public sculpture. We describe a sonic artwork, "Listening To Listening", that has been designed to accompany a real-world sculpture with two prototype interaction schemes. Our artwork is created for the HoloLens platform so that users can have an individual experience in a mixed reality context. Personal head-mounted AR systems have recently become available and practical for integration into public art projects, however research into sonic sculpture works has yet to account for the affordances of current portable and mainstream AR systems. In this work, we take advantage of the HoloLens' spatial awareness to build sonic spaces that have a precise spatial relationship to a given sculpture and where the sculpture itself is modelled in the augmented scene as an "invisible hologram". We describe the artistic rationale for our artwork, the design of the two interaction schemes, and the technical and usability feedback that we have obtained from demonstrations during iterative development.      
### 49.Balanced Reduced-Order Models for Iterative Nonlinear Control of Large-Scale Systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.02305.pdf)
>  We propose a new framework to design controllers for high-dimensional nonlinear systems. The control is designed through the iterative linear quadratic regulator (ILQR), an algorithm that computes control by iteratively applying the linear quadratic regulator on the local linearization of the system at each time step. Since ILQR is computationally expensive, we propose to first construct reduced-order models (ROMs) of the high-dimensional nonlinear system. We derive nonlinear ROMs via projection, where the basis is computed via balanced truncation (BT) and LQG balanced truncation (LQG-BT). Numerical experiments are performed on a semi-discretized nonlinear Burgers equation. We find that the ILQR algorithm produces good control on ROMs constructed either by BT or LQG-BT, with BT-ROM based controllers outperforming LQG-BT slightly for very low-dimensional systems.      
### 50.Deep Learning for Road Traffic Forecasting: Does it Make a Difference?  [ :arrow_down: ](https://arxiv.org/pdf/2012.02260.pdf)
>  Deep Learning methods have been proven to be flexible to model complex phenomena. This has also been the case of Intelligent Transportation Systems (ITS), in which several areas such as vehicular perception and traffic analysis have widely embraced Deep Learning as a core modeling technology. Particularly in short-term traffic forecasting, the capability of Deep Learning to deliver good results has generated a prevalent inertia towards using Deep Learning models, without examining in depth their benefits and downsides. This paper focuses on critically analyzing the state of the art in what refers to the use of Deep Learning for this particular ITS research area. To this end, we elaborate on the findings distilled from a review of publications from recent years, based on two taxonomic criteria. A posterior critical analysis is held to formulate questions and trigger a necessary debate about the issues of Deep Learning for traffic forecasting. The study is completed with a benchmark of diverse short-term traffic forecasting methods over traffic datasets of different nature, aimed to cover a wide spectrum of possible scenarios. Our experimentation reveals that Deep Learning could not be the best modeling technique for every case, which unveils some caveats unconsidered to date that should be addressed by the community in prospective studies. These insights reveal new challenges and research opportunities in road traffic forecasting, which are enumerated and discussed thoroughly, with the intention of inspiring and guiding future research efforts in this field.      
### 51.EVRNet: Efficient Video Restoration on Edge Devices  [ :arrow_down: ](https://arxiv.org/pdf/2012.02228.pdf)
>  Video transmission applications (e.g., conferencing) are gaining momentum, especially in times of global health pandemic. Video signals are transmitted over lossy channels, resulting in low-quality received signals. To restore videos on recipient edge devices in real-time, we introduce an efficient video restoration network, EVRNet. EVRNet efficiently allocates parameters inside the network using alignment, differential, and fusion modules. With extensive experiments on video restoration tasks (deblocking, denoising, and super-resolution), we demonstrate that EVRNet delivers competitive performance to existing methods with significantly fewer parameters and MACs. For example, EVRNet has 260 times fewer parameters and 958 times fewer MACs than enhanced deformable convolution-based video restoration network (EDVR) for 4 times video super-resolution while its SSIM score is 0.018 less than EDVR. We also evaluated the performance of EVRNet under multiple distortions on unseen dataset to demonstrate its ability in modeling variable-length sequences under both camera and object motion.      
### 52.Scan2Cap: Context-aware Dense Captioning in RGB-D Scans  [ :arrow_down: ](https://arxiv.org/pdf/2012.02206.pdf)
>  We introduce the task of dense captioning in 3D scans from commodity RGB-D sensors. As input, we assume a point cloud of a 3D scene; the expected output is the bounding boxes along with the descriptions for the underlying objects. To address the 3D object detection and description problems, we propose Scan2Cap, an end-to-end trained method, to detect objects in the input scene and describe them in natural language. We use an attention mechanism that generates descriptive tokens while referring to the related components in the local context. To reflect object relations (i.e. relative spatial relations) in the generated captions, we use a message passing graph module to facilitate learning object relation features. Our method can effectively localize and describe 3D objects in scenes from the ScanRefer dataset, outperforming 2D baseline methods by a significant margin (27.61% CiDEr@0.5IoUimprovement).      
### 53.Improved MVDR Beamforming Using LSTM Speech Models to Clean Spatial Clustering Masks  [ :arrow_down: ](https://arxiv.org/pdf/2012.02191.pdf)
>  Spatial clustering techniques can achieve significant multi-channel noise reduction across relatively arbitrary microphone configurations, but have difficulty incorporating a detailed speech/noise model. In contrast, LSTM neural networks have successfully been trained to recognize speech from noise on single-channel inputs, but have difficulty taking full advantage of the information in multi-channel recordings. This paper integrates these two approaches, training LSTM speech models to clean the masks generated by the Model-based EM Source Separation and Localization (MESSL) spatial clustering method. By doing so, it attains both the spatial separation performance and generality of multi-channel spatial clustering and the signal modeling performance of multiple parallel single-channel LSTM speech enhancers. Our experiments show that when our system is applied to the CHiME-3 dataset of noisy tablet recordings, it increases speech quality as measured by the Perceptual Evaluation of Speech Quality (PESQ) algorithm and reduces the word error rate of the baseline CHiME-3 speech recognizer, as compared to the default BeamformIt beamformer.      
### 54.Archiver System Management for Belle II Detector Operation  [ :arrow_down: ](https://arxiv.org/pdf/2010.16278.pdf)
>  The Belle II experiment is a high-energy physics experiment at the SuperKEKB electron-positron collider. Using Belle II data, high precision measurement of rare decays and CP-violation in heavy quarks and leptons can be performed to probe New Physics. In this paper, we present the archiver system used to store the monitoring data of the Belle II detector and discuss in particular how we maintain the system that archives the monitoring process variables of the subdetectors. We currently save about 26 thousand variables including the temperature of various subdetectors components, status of water leak sensors, high voltage power supply status, data acquisition status, and luminosity information of the colliding beams. For stable data taking, it is essential to collect and archive these variables. We ensure the availability and consistency of all the variables from the subdetector and other systems, as well as the status of the archiver itself are consistent and regularly updated. To cope with a possible hardware failure, we prepared a backup archiver that is synchronized with the main archiver.      

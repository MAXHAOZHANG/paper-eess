# ArXiv eess --Thu, 10 Dec 2020
### 1.Sneak Preview: PowerDynamics.jl -= An Open-Source library for analyzing dynamic stability in power grids with high shares of renewable energy  [ :arrow_down: ](https://arxiv.org/pdf/2012.05175.pdf)
>  PowerDynamics.jl is an Open-Source library for dynamic power grid modeling built in the latest scientific programming language, Julia. It provides all the tools necessary to analyze the dynamical stability of power grids with high share of renewable energy. In contrast to conventional tools, it makes full use of the simplicity and generality that Julia combines with highly-optimized just-in-time compiled Code. Additionally, its ecosystem provides DifferentialEquations.jl, a high-performance library for solving differential equations with built-in solvers and interfaces to industrial grade solvers like Sundials. PowerDynamics.jl provides a multitude of dynamics for different node/bus-types, e.g. rotating masses, droop-control in inverters, and is able to explicitly model time delays of inverters. Furthermore, it includes realistic models of fluctuations from renewable energy sources. In this paper, we demonstrate how to use PowerDynamics.jl for the IEEE 14-bus distribution grid feeder.      
### 2.Bad-Data Sequence Detection for Power System State Estimation via ICA-GAN  [ :arrow_down: ](https://arxiv.org/pdf/2012.05163.pdf)
>  A deep learning approach to the detection of bad-data sequences in power systems is proposed. The bad-data model is nonparametric that includes arbitrary natural and adversarial data anomalies. No historical samples of data anomaly are assumed. The probability distribution of data in anomaly-free system operations is also non-parametric, unknown, but with historical training samples. A uniformity test is proposed based on a generative adversarial network (GAN) that extracts independent components of the measurement sequence via independent component analysis (ICA). Referred to as ICA-GAN, the developed approach to bad-data sequence detection can be applied at the individual sensor level or jointly at the system level. Numerical results demonstrate significant improvement over the state-of-the-art solutions for a variety of bad-data cases using PMU measurements from the EPFL smart grid testbed and that from the synthetic Northern Texas grid.      
### 3.Cooperative System Identification via Correctional Learning  [ :arrow_down: ](https://arxiv.org/pdf/2012.05161.pdf)
>  We consider a cooperative system identification scenario in which an expert agent (teacher) knows a correct, or at least a good, model of the system and aims to assist a learner-agent (student), but cannot directly transfer its knowledge to the student. For example, the teacher's knowledge of the system might be abstract or the teacher and student might be employing different model classes, which renders the teacher's parameters uninformative to the student. In this paper, we propose correctional learning as an approach to the above problem: Suppose that in order to assist the student, the teacher can intercept the observations collected from the system and modify them to maximize the amount of information the student receives about the system. We formulate a general solution as an optimization problem, which for a multinomial system instantiates itself as an integer program. Furthermore, we obtain finite-sample results on the improvement that the assistance from the teacher results in (as measured by the reduction in the variance of the estimator) for a binomial system.      
### 4.Derivation of global vegetation biophysical parameters from EUMETSAT Polar System  [ :arrow_down: ](https://arxiv.org/pdf/2012.05151.pdf)
>  This paper presents the algorithm developed in LSA-SAF (Satellite Application Facility for Land Surface Analysis) for the derivation of global vegetation parameters from the AVHRR (Advanced Very High-Resolution Radiometer) sensor onboard MetOp (Meteorological-Operational) satellites forming the EUMETSAT (European Organization for the Exploitation of Meteorological Satellites) Polar System (EPS). The suite of LSA-SAF EPS vegetation products includes the leaf area index (LAI), the fractional vegetation cover (FVC), and the fraction of absorbed photosynthetically active radiation (FAPAR). LAI, FAPAR, and FVC characterize the structure and the functioning of vegetation and are key parameters for a wide range of land-biosphere applications. The algorithm is based on a hybrid approach that blends the generalization capabilities offered by physical radiative transfer models with the accuracy and computational efficiency of machine learning methods. One major feature is the implementation of multi-output retrieval methods able to jointly and more consistently estimate all the biophysical parameters at the same time. We propose a multi-output Gaussian process regression (GPRmulti), which outperforms other considered methods over PROSAIL (coupling of PROSPECT and SAIL (Scattering by Arbitrary Inclined Leaves) radiative transfer models) EPS simulations. The global EPS products include uncertainty estimates taking into account the uncertainty captured by the retrieval method and input error propagation. The consistent generation and distribution of the EPS vegetation products will constitute a valuable tool for monitoring of earth surface dynamic processes.      
### 5.Statistical Learning for End-to-End Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2012.05133.pdf)
>  End-to-end mission performance simulators (E2ES) are suitable tools to accelerate satellite mission development from concet to deployment. One core element of these E2ES is the generation of synthetic scenes that are observed by the various instruments of an Earth Observation mission. The generation of these scenes rely on Radiative Transfer Models (RTM) for the simulation of light interaction with the Earth surface and atmosphere. However, the execution of advanced RTMs is impractical due to their large computation burden. Classical interpolation and statistical emulation methods of pre-computed Look-Up Tables (LUT) are therefore common practice to generate synthetic scenes in a reasonable time. This work evaluates the accuracy and computation cost of interpolation and emulation methods to sample the input LUT variable space. The results on MONDTRAN-based top-of-atmosphere radiance data show that Gaussian Process emulators produced more accurate output spectra than linear interpolation at a fraction of its time. It is concluded that emulation can function as a fast and more accurate alternative to interpolation for LUT parameter space sampling.      
### 6.COVID-19 Detection in Chest X-Ray Images using a New Channel Boosted CNN  [ :arrow_down: ](https://arxiv.org/pdf/2012.05073.pdf)
>  COVID-19 is a highly contagious respiratory infection that has affected a large population across the world and continues with its devastating consequences. It is imperative to detect COVID-19 at the earliest to limit the span of infection. In this work, a new classification technique CB-STM-RENet based on deep Convolutional Neural Network (CNN) and Channel Boosting is developed for the detection of COVID-19 from chest X-Rays. In this connection, to learn the COVID-19 specific radiographic patterns, a new convolution block based on split-transform-merge (STM) is developed. This new block systematically incorporates region and edge base operations at each branch to capture the diverse set of features at various levels, especially those related to region homogeneity, textural variations, and boundaries of the infected region. We further enhanced the learning and discrimination capability of the proposed CNN architecture by exploiting the Channel Boosting idea that concatenates the auxiliary channels along with the original channels. The auxiliary channels are generated by employing Transfer Learning-based domain adaption of the pre-trained CNN architectures. The effectiveness of the proposed technique CB-STM-RENet is evaluated on three different datasets containing CoV-Healthy-6k, CoV-NonCoV-10k, and CoV-NonCoV-15k Chest X-Ray images, respectively. The performance comparison of the proposed deep CB-STM-RENet with the existing techniques exhibits high classification performance both in discriminating COVID-19 chest infections from healthy, as well as, other types of chest infections. CB-STM-RENet provides the highest performance on all these three datasets; especially on the stringent CoV-NonCoV-15k dataset. The good detection rate (97%), and high precision (93%) of the proposed technique suggest that it can be adapted for the diagnosis of COVID-19 infected patients.      
### 7.Full C-Band WDM Transmission of Nonlinearity-Tolerant Probabilistically Shaped QAM over 2824-km Dispersion-Managed Fiber  [ :arrow_down: ](https://arxiv.org/pdf/2012.05058.pdf)
>  By tailoring probabilistic constellation shaping (PCS) for nonlinearity tolerance, we experimentally demonstrate up to 1.1 dB increase in signal-to-noise ratio (SNR) and 6.4% increase in total net data rate (NDR) compared to linear-channel-optimized PCS on a 2824-km dispersion-managed wavelength-division multiplexed (WDM) optical fiber link.      
### 8.Frequency Separation based Adaptive Feedforward Control for Rejecting Wideband Vibration with Application to Hard Disk Drives  [ :arrow_down: ](https://arxiv.org/pdf/2012.05049.pdf)
>  In this paper, a frequency separation based adaptive feedforward control algorithm is developed with the ability to identify the plant and do compensation region by region. In this algorithm, the accelerometer signal is filtered by a series of uniformly distributed bandpass filters to generate a bunch of subband signals which are mutually exclusive in spectrum. In each subband, the corresponding subband signal acts as the feedforward signal and only the frequency response of system in that region needs to be identified, thus a pretty low order model can be expected to have efficient compensation. Starting from the first region, the feedforward control parameters are learned simultaneously with the low order plant model in the same region and then moves to the next region until all the regions are performed.      
### 9.Fusion of rain radar images and wind forecasts in a deep learning model applied to rain nowcasting  [ :arrow_down: ](https://arxiv.org/pdf/2012.05015.pdf)
>  Short or mid-term rainfall forecasting is a major task for several environmental applications, such as agricultural management or monitoring flood risks. Existing data-driven approaches, especially deep learning models, have shown significant skill at this task, using only rain radar images as inputs. In order to determine whether using other meteorological parameters such as wind would improve forecasts, we trained a deep learning model on a fusion of rain radar images and wind velocity produced by a weather forecast model. The network was compared to a similar architecture trained only on rainfall data, to a basic persistence model and to an approach based on optical flow. Our network outperforms the F1-score calculated for the optical flow on moderate and higher rain events for forecasts at a horizon time of 30 minutes by 8%. Furthermore, it outperforms the same architecture trained using only rainfalls by 7%.      
### 10.Modeling and Identification of Low Rank Vector Processes  [ :arrow_down: ](https://arxiv.org/pdf/2012.05004.pdf)
>  We study modeling and identification of processes with a spectral density matrix of low rank. Equivalently, we consider processes having an innovation of reduced dimension for which PEM algorithms are not directly applicable. We show that these processes admit a special feedback structure with a deterministic feedback channel which can be used to split the identification in two steps, one of which can be based on standard algorithms while the other is based on a deterministic least squares fit.      
### 11.Automated Scoring of Nuclear Pleomorphism Spectrum with Pathologist-level Performance in Breast Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2012.04974.pdf)
>  Nuclear pleomorphism is the degree of change in nuclear morphology, one of the components of the three-tiered breast cancer grading, along with tubular differentiation and mitotic counting. We consider the degree of nuclear pleomorphism as a continuum; a continuous spectrum of change in tumor morphology. We train a deep learning network on a large variety of tumor regions from the collective knowledge of several pathologists without constraining the network to the traditional three-category classification. We also motivate an additional approach in which we discuss the additional benefit of normal epithelium as baseline, following the routine clinical practice where pathologists are trained to score nuclear pleomorphism in tumor, having the normal breast epithelium as baseline. In multiple experiments, our fully-automated approach could achieve top pathologist-level performance in select regions of interest as well as at whole slide images, compared to ten and four pathologists, respectively.      
### 12.Magnetic Field Energy Harvesting in Railway  [ :arrow_down: ](https://arxiv.org/pdf/2012.04965.pdf)
>  Magnetic field energy harvesting (MFEH) is a method by which a system can harness an ambient, alternating magnetic field in order to scavenge energy. Presented in this paper is a prototype energy harvesting solution aimed at the magnetic fields circulating the rail current in electrified railway. Due to its non-invasive nature, the solution may be deployed as part of a low-cost trackside condition monitoring system, in order to increase lifetime and reduce maintenance requirements. Two different configurations are assessed in a controlled laboratory environment, and it is demonstrated that at a distance of $25 \, \text{cm}$ from a typical rail current of $120 \, \text{A}$, the system can harvest $340 \, \mu\text{W}$ and $912 \, \mu\text{W}$ at $16 \, 2/3 \, \text{Hz}$ and $50 \, \text{Hz}$, respectively. A prototype system tested in situ at two points along Norwegian railway validates the performance in real-world conditions. In the field, the system is able to harvest $109 \, \text{mJ}$ from a single freight train, rendering an estimated daily energy output of $1.14 \, \text{J}$. It is argued that the approach could indeed eliminate the need for battery replacements, and potentially increase the lifetime of an energy-efficient, battery-powered condition monitoring system indefinitely.      
### 13.Distributed Dual Objective Control of A Flywheel Energy Storage Matrix System Under Jointly Connected Communication Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.04950.pdf)
>  This paper studies the distributed dual objective control problem of a heterogenous flywheel energy storage matrix system aiming at simultaneous reference power track-ing and state-of-energy balancing. We first prove that the solution to this problem exists by showing the existence of a common state-of-energy trajectory for all the flywheel systems on which the dual control objectives can be achieved simultaneously. Next, based on this common state-of-energy trajectory, the distributed dual objective control problem is converted into a double layer distributed tracking problem, which is then solved by the adaptive distributed observer approach. Simulation results are provided to validate the effectiveness of the proposed control scheme.      
### 14.A Lightweight Neural Network for Inferring ECG and Diagnosing Cardiovascular Diseases from PPG  [ :arrow_down: ](https://arxiv.org/pdf/2012.04949.pdf)
>  The prevalence of smart devices has extended cardiac monitoring beyond the hospital setting. It is currently possible to obtain instant Electrocardiogram (ECG) test anywhere by tapping a built-in bio-sensor of a smartwatch with a hand. However, such user participation is infeasible for long-term continuous cardiac monitoring in order to capture the intermittent and asymptomatic abnormalities of the heart that short-term ECG tests often miss. In this paper, we present a computational solution for automated and continuous cardiac monitoring. A neural network is designed to jointly infer ECG and diagnose cardiovascular diseases (CVDs) from photoplethysmogram (PPG). PPG measures the variations of blood volume driven by heartbeats, and the signal can be sensed at the wrist or finger via an optical sensor. To minimize the memory consumption on mobile devices, we devise a model compression scheme for the proposed architecture. For higher trustworthiness and transparency, this study also addresses the problem of model interpretation. We analyze the latent connection between PPG and ECG as well as the CVDs-related features of PPG learned by the neural network, aiming at obtaining clinical insights from data. The quantitative comparison with prior methods on a benchmark dataset shows that our algorithm can make more accurate ECG inference. It achieves an average $F_1$ score of 0.96 in diagnosing major CVDs.      
### 15.Distributed Dynamic Pricing in Peer-to-Peer Transactive Energy Systems in Smart Grid  [ :arrow_down: ](https://arxiv.org/pdf/2012.04917.pdf)
>  The rapid growth of proactive consumers with distributed power generation and storage capacity, empowered by Internet of Things (IoT) devices, is transforming modern power markets into an independent, flexible, and distributed structure. In particular, the recent trend is peer-to-peer (P2P) transactive energy systems, wherein the traditional consumers became prosumers (producer+consumer) and can maximize their energy utilization by sharing with neighbors without any conventional intermediary intervention in the transactions. However, the competitive dynamic energy pricing scheme is inevitable in such systems to make the optimal decision. It is very challenging when the prosumers have limited access to the fellow prosumer's system information (i.e., load profile, generation, and so on). This paper presents a privacy-preserving distributed dynamic pricing strategy for P2P transactive energy systems in the smart grid using Fast Alternating Direction Method of Multipliers (F-ADMM) algorithm. The result shows that the algorithm converges very fast and facilitates easy implementation. Moreover, a closed-form solution for a P2P transactive energy system was presented, which accelerate the overall computation time.      
### 16.Optimal Unbiased Linear Sensor Fusion over Multiple Lossy Channels with Collective Observability  [ :arrow_down: ](https://arxiv.org/pdf/2012.04896.pdf)
>  In this paper, we consider optimal linear sensor fusion for obtaining a remote state estimate of a linear process based on the sensor data transmitted over lossy channels. There is no local observability guarantee for any of the sensors. It is assumed that the state of the linear process is collectively observable. We transform the problem of finding the optimal linear sensor fusion coefficients as a convex optimization problem which can be efficiently solved. Moreover, the closed-form expression is also derived for the optimal coefficients. Simulation results are presented to illustrate the performance of the developed algorithm.      
### 17.Multiscale Phase Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2012.04891.pdf)
>  While characterization of coherent wavefields is essential to laser, x-ray and electron imaging, sensors measure the squared magnitude of the field, rather than the field itself. Holography or phase retrieval must be used to characterize the field. The need for a reference severely restricts the utility of holography. Phase retrieval, in contrast, is theoretically consistent with sensors that directly measure coherent or partially coherent fields with no prior assumptions. Unfortunately, phase retrieval has not yet been successfully implemented for large-scale fields. Here we show that both holography and phase retrieval are capable of quantum-limited coherent signal estimation and we describe phase retrieval strategies that approach the quantum limit for &gt;1 megapixel fields. These strategies rely on group testing using networks of interferometers, such as might be constructed using emerging integrated photonic, plasmonic and/or metamaterial devices. Phase-sensitive sensor planes using such devices could eliminate the need both for lenses and reference signals, creating a path to large aperture diffraction limited laser imaging.      
### 18.AIDE: Annotation-efficient deep learning for automatic medical image segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2012.04885.pdf)
>  Accurate image segmentation is crucial for medical imaging applications, including disease diagnosis and treatment planning$^{1-4}$. The prevailing deep learning approaches typically rely on very large training datasets with high-quality manual annotations$^{5,6}$, which are often not available in medical imaging. We introduce Annotation-effIcient Deep lEarning (AIDE) to progressively correct low-quality annotations by better exploring the image contents. AIDE improves the segmentation Dice scores of conventional deep learning models on open datasets possessing scarce or noisy annotations by up to 30%. For three clinical datasets containing 11,852 breast images of 872 patients from three medical centers, AIDE consistently produces segmentation maps comparable to those generated by the fully supervised counterparts as well as the manual annotations of independent radiologists by utilizing only 10% training annotations. Such a 10-fold improvement of efficiency in utilizing experts' labels has the potential to promote a wide range of biomedical applications.      
### 19.A Framework for Current-State Opacity under Dynamic Information Release Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2012.04874.pdf)
>  Opacity is an important information-flow security property that characterizes the plausible deniability of a dynamic system for its "secret" against eavesdropping attacks. As an information-flow property, the underlying observation model is the key in the modeling and analysis of opacity. In this paper, we investigate the verification of current-state opacity for discrete-event systems under Orwellian-type observations, i.e., the system is allowed to re-interpret the observation of an event based on its future suffix. First, we propose a new Orwellian-type observation model called the dynamic information release mechanism (DIRM). In the DIRM, when to release previous "hold on" events is state-dependent. Then we propose a new definition of opacity based on the notion of history-equivalence rather than the standard projection-equivalence. This definition is more suitable for observations that are not prefix-closed. Finally, we show that by constructing a new structure called the DIRM-observer, current-state opacity can be effectively verified under the DIRM. Computational complexity analysis as well as illustrative examples for the proposed approach are also provided. Compared with the existing Orwellian-type observation model, the proposed framework is more general in the sense that the information-release-mechanism is state-dependent and the corresponding definition of opacity is more suitable for non-prefix-closed observations.      
### 20.Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2012.04830.pdf)
>  Cataract is one of the leading causes of reversible visual impairment and blindness globally. Over the years, researchers have achieved significant progress in developing state-of-the-art artificial intelligence techniques for automatic cataract classification and grading, helping clinicians prevent and treat cataract in time. This paper provides a comprehensive survey of recent advances in machine learning for cataract classification and grading based on ophthalmic images. We summarize existing literature from two research directions: conventional machine learning techniques and deep learning techniques. This paper also provides insights into existing works of both merits and limitations. In addition, we discuss several challenges of automatic cataract classification and grading based on machine learning techniques and present possible solutions to these challenges for future research.      
### 21.Day-ahead Operational Planning with Enhanced Flexible Ramping Product: Design and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2012.04799.pdf)
>  New resource mix, e.g., renewable resources, are imposing operational complexities to modern power systems by intensifying uncertainty and variability in the system net load. This issue has motivated independent system operators (ISOs), e.g., California ISO (CAISO), to add the flexible ramping product (FRP) to their day-ahead (DA) market models. Such structural changes in the DA market formulation require further analyses and detailed design to ensure adequate operational flexibility, market efficiency, and reliability. This paper conducts a comprehensive study to: (a) augment existing DA market models with enhanced FRP design in order to schedule ramp capabilities that are more adaptive with respect to the real-time (RT) condition, and (b) design corresponding market payment policies that accurately reflect the value of the added flexibility through enhanced FRP design. The proposed FRP design can be implemented in present-day system operations with minimal disruption to existing DA market models. Performance of the proposed DA market model, which includes the enhanced FRP design, is compared against the DA market model with existing FRP design through a validation methodology based on RT unit commitment model. This validation methodology mimics fifteen-minute market of CAISO. The proposed method is tested on an IEEE 118-bus test system.      
### 22.An Explicit Parametrization of Closed Loops for Spatially Distributed Controllers with Sparsity Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2012.04792.pdf)
>  We study the linear time-invariant state-feedback controller design problem for distributed systems. We follow the recently developed System Level Synthesis (SLS) approach and impose locality structure on the resulting closed-loop mappings; the corresponding controller implementation inherits this prescribed structure. In contrast to existing SLS results, we derive an explicit (rather than implicit) parameterization of all achievable stabilized closed-loops. This admits more efficient IIR representations of the temporal part of the closed-loop dynamics, and allows for the H2 design problem with closed-loop spatial sparsity constraints to be converted to a standard model matching problem, with the number of transfer function parameters scaling linearly with the closed-loop spatial extent constraint. We illustrate our results with two applications: consensus of first-order subsystems and the vehicular platoons problem. In the case of first-order consensus, we provide analytic solutions and further analyze the architecture of the resulting controller implementation. Results for infinite extent spatially-invariant systems are presented to provide insight to the case of a large but finite number of subsystems.      
### 23.UAVs with Reconfigurable Intelligent Surfaces: Applications, Challenges, and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2012.04775.pdf)
>  A reconfigurable intelligent surface (RIS) is a metamaterial that can be integrated into walls and influence the propagation of electromagnetic waves. This, typically passive radio frequency (RF) technology is emerging for indoor and outdoor use with the potential of making wireless communications more reliable in increasingly challenging radio environments. This paper goes one step further and introduces mobile RIS, specifically, RIS carried by unmanned aerial vehicles (UAVs) to support cellular communications networks and services of the future. We elaborate on several use cases, challenges, and future research opportunities for designing and optimizing wireless systems at low cost and with low energy footprint.      
### 24.Conditional Generation of Medical Images via Disentangled Adversarial Inference  [ :arrow_down: ](https://arxiv.org/pdf/2012.04764.pdf)
>  Synthetic medical image generation has a huge potential for improving healthcare through many applications, from data augmentation for training machine learning systems to preserving patient privacy. Conditional Adversarial Generative Networks (cGANs) use a conditioning factor to generate images and have shown great success in recent years. Intuitively, the information in an image can be divided into two parts: 1) content which is presented through the conditioning vector and 2) style which is the undiscovered information missing from the conditioning vector. Current practices in using cGANs for medical image generation, only use a single variable for image generation (i.e., content) and therefore, do not provide much flexibility nor control over the generated image. In this work we propose a methodology to learn from the image itself, disentangled representations of style and content, and use this information to impose control over the generation process. In this framework, style is learned in a fully unsupervised manner, while content is learned through both supervised learning (using the conditioning vector) and unsupervised learning (with the inference mechanism). We undergo two novel regularization steps to ensure content-style disentanglement. First, we minimize the shared information between content and style by introducing a novel application of the gradient reverse layer (GRL); second, we introduce a self-supervised regularization method to further separate information in the content and style variables. We show that in general, two latent variable models achieve better performance and give more control over the generated image. We also show that our proposed model (DRAI) achieves the best disentanglement score and has the best overall performance.      
### 25.2-Step Sparse-View CT Reconstruction with a Domain-Specific Perceptual Network  [ :arrow_down: ](https://arxiv.org/pdf/2012.04743.pdf)
>  Computed tomography is widely used to examine internal structures in a non-destructive manner. To obtain high-quality reconstructions, one typically has to acquire a densely sampled trajectory to avoid angular undersampling. However, many scenarios require a sparse-view measurement leading to streak-artifacts if unaccounted for. Current methods do not make full use of the domain-specific information, and hence fail to provide reliable reconstructions for highly undersampled data. We present a novel framework for sparse-view tomography by decoupling the reconstruction into two steps: First, we overcome its ill-posedness using a super-resolution network, SIN, trained on the sparse projections. The intermediate result allows for a closed-form tomographic reconstruction with preserved details and highly reduced streak-artifacts. Second, a refinement network, PRN, trained on the reconstructions reduces any remaining artifacts. We further propose a light-weight variant of the perceptual-loss that enhances domain-specific information, boosting restoration accuracy. Our experiments demonstrate an improvement over current solutions by 4 dB.      
### 26.Yaw Stability Control System Development and Implementation for a Fully Electric Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2012.04719.pdf)
>  There is growing interest in fully electric vehicles in the automotive industry as it becomes increasingly more difficult to meet new and upcoming emission regulations based on internal combustion engines. Fully electric vehicles do not have an internal combustion engine. Hence, drive torque change for a traction control system and for a yaw stability control system has to be through the electric motor used for traction. The regenerative braking capability of fully electric vehicles has to be taken into account in designing braking controllers like ABS and yaw stability control through differential braking. Fully electric vehicles are usually lighter vehicles with different dynamic characteristics than that of their predecessors using internal combustion engines. As such, their yaw stability control systems have to be re-designed and tested. This paper reports the initial results of ongoing work on yaw stability controller design for a fully electric vehicle. Two different implementations on a research prototype fully electric light commercial vehicle are considered. The first implementation uses the production yaw stability control system in the internal combustion engine powered conventional vehicle. The drive torque change commands from the production ECU are read, modified and sent to the electric motor driver in trying to mimic the conventional vehicle. The differential braking commands are the same as in the conventional vehicle. In the second implementation, a generic yaw stability control system that calculates and issues its own drive torque change commands and differential braking commands is designed and implemented. Offline simulations on a validated model and a hardware-in-the-loop simulation system are used in designing the yaw stability control system.      
### 27.3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management  [ :arrow_down: ](https://arxiv.org/pdf/2012.04701.pdf)
>  The pancreatic disease taxonomy includes ten types of masses (tumors or cysts)[20,8]. Previous work focuses on developing segmentation or classification methods only for certain mass types. Differential diagnosis of all mass types is clinically highly desirable [20] but has not been investigated using an automated image understanding approach. We exploit the feasibility to distinguish pancreatic ductal adenocarcinoma (PDAC) from the nine other nonPDAC masses using multi-phase CT imaging. Both image appearance and the 3D organ-mass geometry relationship are critical. We propose a holistic segmentation-mesh-classification network (SMCN) to provide patient-level diagnosis, by fully utilizing the geometry and location information, which is accomplished by combining the anatomical structure and the semantic detection-by-segmentation network. SMCN learns the pancreas and mass segmentation task and builds an anatomical correspondence-aware organ mesh model by progressively deforming a pancreas prototype on the raw segmentation mask (i.e., mask-to-mesh). A new graph-based residual convolutional network (Graph-ResNet), whose nodes fuse the information of the mesh model and feature vectors extracted from the segmentation network, is developed to produce the patient-level differential classification results. Extensive experiments on 661 patients' CT scans (five phases per patient) show that SMCN can improve the mass segmentation and detection accuracy compared to the strong baseline method nnUNet (e.g., for nonPDAC, Dice: 0.611 vs. 0.478; detection rate: 89% vs. 70%), achieve similar sensitivity and specificity in differentiating PDAC and nonPDAC as expert radiologists (i.e., 94% and 90%), and obtain results comparable to a multimodality test [20] that combines clinical, imaging, and molecular testing for clinical management of patients.      
### 28.Maximum Likelihood Signal Matrix Model for Data-Driven Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2012.04678.pdf)
>  The paper presents a data-driven predictive control framework based on an implicit input-output mapping derived directly from the signal matrix of collected data. This signal matrix model is derived by maximum likelihood estimation with noise-corrupted data. By linearizing online, the implicit model can be used as a linear constraint to characterize possible trajectories of the system in receding horizon control. The signal matrix can also be updated online with new measurements. This algorithm can be applied to large datasets and slowly time-varying systems, possibly with high noise levels. An additional regularization term on the prediction error can be introduced to enhance the predictability and thus the control performance. Numerical results demonstrate that the proposed signal matrix model predictive control algorithm is effective in multiple applications and performs better than existing data-driven predictive control algorithm.      
### 29.Synthesis to Deployment: Cyber-Physical Control Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2012.05211.pdf)
>  We consider the problem of how to deploy a controller to a (networked) cyber-physical system (CPS). Controlling a CPS is an involved task, and synthesizing a controller to respect sensing, actuation, and communication constraints is only part of the challenge. In addition to controller synthesis, one should also consider how the controller will be incorporated within the CPS. Put another way, the cyber layer and its interaction with the physical layer need to be taken into account. <br>In this work, we aim to bridge the gap between theoretical controller synthesis and practical CPS deployment. We adopt the system level synthesis (SLS) framework to synthesize a controller, either state-feedback or output-feedback, and provide deployment architectures for the standard SLS controllers. Furthermore, we derive new controller realizations for open-loop stable systems and introduce different state-feedback and output-feedback architectures for deployment, ranging from fully centralized to fully distributed. Finally, we compare the trade-offs among them in terms of robustness, memory, computation, and communication overhead.      
### 30.Convex Regularization Behind Neural Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2012.05169.pdf)
>  Neural networks have shown tremendous potential for reconstructing high-resolution images in inverse problems. The non-convex and opaque nature of neural networks, however, hinders their utility in sensitive applications such as medical imaging. To cope with this challenge, this paper advocates a convex duality framework that makes a two-layer fully-convolutional ReLU denoising network amenable to convex optimization. The convex dual network not only offers the optimum training with convex solvers, but also facilitates interpreting training and prediction. In particular, it implies training neural networks with weight decay regularization induces path sparsity while the prediction is piecewise linear filtering. A range of experiments with MNIST and fastMRI datasets confirm the efficacy of the dual network optimization problem.      
### 31.SongMASS: Automatic Song Writing with Pre-training and Alignment Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2012.05168.pdf)
>  Automatic song writing aims to compose a song (lyric and/or melody) by machine, which is an interesting topic in both academia and industry. In automatic song writing, lyric-to-melody generation and melody-to-lyric generation are two important tasks, both of which usually suffer from the following challenges: 1) the paired lyric and melody data are limited, which affects the generation quality of the two tasks, considering a lot of paired training data are needed due to the weak correlation between lyric and melody; 2) Strict alignments are required between lyric and melody, which relies on specific alignment modeling. In this paper, we propose SongMASS to address the above challenges, which leverages masked sequence to sequence (MASS) pre-training and attention based alignment modeling for lyric-to-melody and melody-to-lyric generation. Specifically, 1) we extend the original sentence-level MASS pre-training to song level to better capture long contextual information in music, and use a separate encoder and decoder for each modality (lyric or melody); 2) we leverage sentence-level attention mask and token-level attention constraint during training to enhance the alignment between lyric and melody. During inference, we use a dynamic programming strategy to obtain the alignment between each word/syllable in lyric and note in melody. We pre-train SongMASS on unpaired lyric and melody datasets, and both objective and subjective evaluations demonstrate that SongMASS generates lyric and melody with significantly better quality than the baseline method without pre-training or alignment constraint.      
### 32.Quantum Discrimination of Two Noisy Displaced Number States  [ :arrow_down: ](https://arxiv.org/pdf/2012.05165.pdf)
>  The quantum discrimination of two non-coherent states draws much attention recently. In this letter, we first consider the quantum discrimination of two noiseless displaced number states. Then we derive the Fock representation of noisy displaced number states and address the problem of discriminating between two noisy displaced number states. We further prove that the optimal quantum discrimination of two noisy displaced number states can be achieved by the Kennedy receiver with threshold detection. Simulation results verify the theoretical derivations and show that the error probability of on-off keying modulation using a displaced number state is significantly less than that of on-off keying modulation using a coherent state with the same average energy.      
### 33.Causal Inference in Geoscience and Remote Sensing from Observational Data  [ :arrow_down: ](https://arxiv.org/pdf/2012.05150.pdf)
>  Establishing causal relations between random variables from observational data is perhaps the most important challenge in today's \blue{science}. In remote sensing and geosciences this is of special relevance to better understand the Earth's system and the complex interactions between the governing processes. In this paper, we focus on observational causal inference, thus we try to estimate the correct direction of causation using a finite set of empirical data. In addition, we focus on the more complex bivariate scenario that requires strong assumptions and no conditional independence tests can be used. In particular, we explore the framework of (non-deterministic) additive noise models, which relies on the principle of independence between the cause and the generating mechanism. A practical algorithmic instantiation of such principle only requires 1) two regression models in the forward and backward directions, and 2) the estimation of {\em statistical independence} between the obtained residuals and the observations. The direction leading to more independent residuals is decided to be the cause. We instead propose a criterion that uses the {\em sensitivity} (derivative) of the dependence estimator, the sensitivity criterion allows to identify samples most affecting the dependence measure, and hence the criterion is robust to spurious detections. We illustrate performance in a collection of 28 geoscience causal inference problems, in a database of radiative transfer models simulations and machine learning emulators in vegetation parameter modeling involving 182 problems, and in assessing the impact of different regression models in a carbon cycle problem. The criterion achieves state-of-the-art detection rates in all cases, it is generally robust to noise sources and distortions.      
### 34.Robotic Communications for 5G and Beyond: Challenges and Research Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2012.05093.pdf)
>  The ongoing surge in applications of robotics brings both opportunities and challenges for the fifth-generation (5G) and beyond (B5G) of communication networks. This article focuses on 5G/B5G-enabled terrestrial robotic communications with an emphasis on distinct characteristics of such communications. Firstly, signal and spatial modeling for robotic communications are presented. To elaborate further, both the benefits and challenges derived from robots' mobility are discussed. As a further advance, a novel simultaneous localization and radio mapping (SLARM) framework is proposed for integrating localization and communications into robotic networks. Furthermore, dynamic trajectory design and resource allocation for both indoor and outdoor robots are provided to verify the performance of robotic communications in the context of typical robotic application scenarios.      
### 35.DeepTalk: Vocal Style Encoding for Speaker Recognition and Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2012.05084.pdf)
>  Automatic speaker recognition algorithms typically use physiological speech characteristics encoded in the short term spectral features for characterizing speech audio. Such algorithms do not capitalize on the complementary and discriminative speaker-dependent characteristics present in the behavioral speech features. In this work, we propose a prosody encoding network called DeepTalk for extracting vocal style features directly from raw audio data. The DeepTalk method outperforms several state-of-the-art physiological speech characteristics-based speaker recognition systems across multiple challenging datasets. The speaker recognition performance is further improved by combining DeepTalk with a state-of-the-art physiological speech feature-based speaker recognition system. We also integrate the DeepTalk method into a current state-of-the-art speech synthesizer to generate synthetic speech. A detailed analysis of the synthetic speech shows that the DeepTalk captures F0 contours essential for vocal style modeling. Furthermore, DeepTalk-based synthetic speech is shown to be almost indistinguishable from real speech in the context of speaker recognition.      
### 36.Variational Nonlinear System Identification  [ :arrow_down: ](https://arxiv.org/pdf/2012.05072.pdf)
>  This paper considers parameter estimation for nonlinear state-space models, which is an important but challenging problem. We address this challenge by employing a variational inference (VI) approach, which is a principled method that has deep connections to maximum likelihood estimation. This VI approach ultimately provides estimates of the model as solutions to an optimisation problem, which is deterministic, tractable and can be solved using standard optimisation tools. A specialisation of this approach for systems with additive Gaussian noise is also detailed. The proposed method is examined numerically on a range of simulation and real examples with a focus on robustness to parameter initialisations; we additionally perform favourable comparisons against state-of-the-art alternatives.      
### 37.Finite-dimensional observer-based PI regulation control of a reaction-diffusion equation  [ :arrow_down: ](https://arxiv.org/pdf/2012.05062.pdf)
>  This paper investigates the output regulation control of a reaction-diffusion equation by means of boundary control. The considered reaction-diffusion plant may be open-loop unstable. The proposed control strategy consists of the coupling of a finite-dimensional observer and a PI controller in order to achieve the boundary regulation control of various system outputs such as the Dirichlet and Neumann traces. In this context, it is shown that the order of the finite-dimensional observer can always be selected large enough, with explicit criterion, to achieve both the stabilization of the plant and the regulation of the system output.      
### 38.On the theory and applications of mechanism design and coalitional games in electricity markets  [ :arrow_down: ](https://arxiv.org/pdf/2012.05047.pdf)
>  Although the specific structures of electricity markets are diverse around the world, they were all conceived on the premise of predictable, controllable generation with nonnegligible marginal costs. Recent changes, specifically, the increasing renewable integration, have challenged such assumptions. In light of this shift, this thesis intends to devise new frameworks and advance our understanding of the future markets. The first part focuses on mechanism design when the model fully reflects the physics of the grid and the participants. We consider a market that involves continuous goods, general nonconvex constraints, and second stage costs. We then design the payments and conditions under which coalitions cannot influence the outcome. Under the incentive-compatible VCG mechanism, we prove that coalition-proof outcomes are achieved if bids are convex and constraints are polymatroids. By relaxing incentive-compatibility, we investigate core-selecting mechanisms that are coalition-proof without conditions. We show that they generalize the economic rationale of the LMP mechanism, and can approximate truthfulness without the price-taking assumption. Finally, they are budget-balanced. The second part coordinates regional markets to exploit the geographic diversification of renewables. In Europe, reserves remain an exclusive responsibility of regional operators. This limited coordination and the sequential structure hinder the utilization of generation and transmission. To promote reserve exchange, a preemptive model can optimally withdraw inter-area transmission capacity from day-ahead energy for reserves. This bilevel program however does not suggest costs that guarantee coordination. We formulate a new preemptive model that allows us to obtain stable benefits immune to deviations. Our proposal, least-core benefits, achieves minimal stability violation with a tractable computation.      
### 39.A multi-objective optimization framework for on-line ridesharing systems  [ :arrow_down: ](https://arxiv.org/pdf/2012.05046.pdf)
>  The ultimate goal of ridesharing systems is to matchtravelers who do not have a vehicle with those travelers whowant to share their vehicle. A good match can be found amongthose who have similar itineraries and time schedules. In thisway each rider can be served without any delay and also eachdriver can earn as much as possible without having too muchdeviation from their original route. We propose an algorithmthat leverages biogeography-based optimization to solve a multi-objective optimization problem for online ridesharing. It isnecessary to solve the ridesharing problem as a multi-objectiveproblem since there are some important objectives that must beconsidered simultaneously. We test our algorithm by evaluatingperformance on the Beijing ridesharing dataset. The simulationresults indicate that BBO provides competitive performancerelative to state-of-the-art ridesharing optimization algorithms.      
### 40.Development of Autonomous Quadcopter  [ :arrow_down: ](https://arxiv.org/pdf/2012.05042.pdf)
>  The main objective of this work is demonstrated through two main aspects. The first is the design of an adaptive neuro-fuzzy inference system (ANFIS) controller to develop the attitude and altitude of a quadcopter. The second is to establish the linearized mathematical model of the quadcopter in a simple and clear way. To show the effectiveness of the ANFIS approach, the performance of a well-trained ANFIS controller is compared to a classical proportional-derivative (PD) controller and a properly tuned fuzzy logic controller.      
### 41.Conjugate Mixture Models for Clustering Multimodal Data  [ :arrow_down: ](https://arxiv.org/pdf/2012.04951.pdf)
>  The problem of multimodal clustering arises whenever the data are gathered with several physically different sensors. Observations from different modalities are not necessarily aligned in the sense there there is no obvious way to associate or to compare them in some common space. A solution may consist in considering multiple clustering tasks independently for each modality. The main difficulty with such an approach is to guarantee that the unimodal clusterings are mutually consistent. In this paper we show that multimodal clustering can be addressed within a novel framework, namely conjugate mixture models. These models exploit the explicit transformations that are often available between an unobserved parameter space (objects) and each one of the observation spaces (sensors). We formulate the problem as a likelihood maximization task and we derive the associated conjugate expectation-maximization algorithm. The convergence properties of the proposed algorithm are thoroughly investigated. Several local/global optimization techniques are proposed in order to increase its convergence speed. Two initialization strategies are proposed and compared. A consistent model-selection criterion is proposed. The algorithm and its variants are tested and evaluated within the task of 3D localization of several speakers using both auditory and visual data.      
### 42.Anomaly Detection in Time Series with Triadic Motif Fields and Application in Atrial Fibrillation ECG Classification  [ :arrow_down: ](https://arxiv.org/pdf/2012.04936.pdf)
>  In the time-series analysis, the time series motifs and the order patterns in time series can reveal general temporal patterns and dynamic features. Triadic Motif Field (TMF) is a simple and effective time-series image encoding method based on triadic time series motifs. Electrocardiography (ECG) signals are time-series data widely used to diagnose various cardiac anomalies. The TMF images contain the features characterizing the normal and Atrial Fibrillation (AF) ECG signals. Considering the quasi-periodic characteristics of ECG signals, the dynamic features can be extracted from the TMF images with the transfer learning pre-trained convolutional neural network (CNN) models. With the extracted features, the simple classifiers, such as the Multi-Layer Perceptron (MLP), the logistic regression, and the random forest, can be applied for accurate anomaly detection. With the test dataset of the PhysioNet Challenge 2017 database, the TMF classification model with the VGG16 transfer learning model and MLP classifier demonstrates the best performance with the 95.50% ROC-AUC and 88.43% F1 score in the AF classification. Besides, the TMF classification model can identify AF patients in the test dataset with high precision. The feature vectors extracted from the TMF images show clear patient-wise clustering with the t-distributed Stochastic Neighbor Embedding technique. Above all, the TMF classification model has very good clinical interpretability. The patterns revealed by symmetrized Gradient-weighted Class Activation Mapping have a clear clinical interpretation at the beat and rhythm levels.      
### 43.Generative Data Augmentation for Vehicle Detection in Aerial Images  [ :arrow_down: ](https://arxiv.org/pdf/2012.04902.pdf)
>  Scarcity of training data is one of the prominent problems for deep networks which require large amounts data. Data augmentation is a widely used method to increase the number of training samples and their variations. In this paper, we focus on improving vehicle detection performance in aerial images and propose a generative augmentation method which does not need any extra supervision than the bounding box annotations of the vehicle objects in the training dataset. The proposed method increases the performance of vehicle detection by allowing detectors to be trained with higher number of instances, especially when there are limited number of training instances. The proposed method is generic in the sense that it can be integrated with different generators. The experiments show that the method increases the Average Precision by up to 25.2% and 25.7% when integrated with Pluralistic and DeepFill respectively.      
### 44.LQG Mean Field Games with a Major Agent: Nash Certainty Equivalence versus Probabilistic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2012.04866.pdf)
>  Mean field game systems consisting of a major agent and a large population of minor agents were introduced in (Huang, 2010) in an LQG setup. In the past years several approaches towards major-minor mean field games have been developed, principally (i) the Nash certainty equivalence (Huang, 2010), (ii) master equations, (iii) asymptotic solvability, and (iv) the probabilistic approach. In a recent work (Huang, 2020), for the LQG case the equivalence of the solutions obtained via approaches (i)-(iii) was established. In this work we demonstrate that the closed-loop Nash equilibrium derived in the infinite-population limit through approaches (i) and (iv) are identical.      
### 45.A multi-period multi-product stochastic inventory problem with order-based loan  [ :arrow_down: ](https://arxiv.org/pdf/2012.04850.pdf)
>  This paper investigates a multi-product stochastic inventory problem in which a cash-constrained online retailer can adopt order-based loan provided by some Chinese e-commerce platforms to speed up its cash recovery for deferred revenue. We first build deterministic models for the problem and then develop the corresponding stochastic programming models to maximize the retailers' expected profit over the planning horizon. The uncertainty of customer demand is represented by scenario trees, and a scenario reduction technique is used to solve the problem when the scenario trees are too large. We conduct numerical tests based on real data crawling from an online store. The results show that the stochastic model outperforms the deterministic model, especially when the retailer is less cash-constrained. Moreover, the retailer tends to choose using order-based loan when its initial available cash is small or facing long receipt delay length.      
### 46.Energy Efficient Robust Beamforming and Cooperative Jamming Design for IRS-Assisted MISO Networks  [ :arrow_down: ](https://arxiv.org/pdf/2012.04843.pdf)
>  Energy-efficient design and secure communications are of crucial importance in wireless communication networks. However, the energy efficiency achieved by using physical layer security can be limited by the channel conditions. In order to tackle this problem, an intelligent reflecting surface (IRS) assisted multiple input single output (MISO) network with independent cooperative jamming is studied. The energy efficiency is maximized by jointly designing the transmit and jamming beamforming and IRS phase-shift matrix under both the perfect channel state information (CSI) and the imperfect CSI. <br>In order to tackle the challenging non-convex fractional problems, an algorithm based on semidefinite programming (SDP) relaxation is proposed for solving energy efficiency maximization problem under the perfect CSI case while an alternate optimization algorithm based on $\mathcal{S}$-procedure is used for solving the problem under the imperfect CSI case. <br>Simulation results demonstrate that the proposed design outperforms the benchmark schemes in term of energy efficiency. Moreover, the tradeoff between energy efficiency and the secrecy rate is found in the IRS-assisted MISO network. Furthermore, it is shown that IRS can help improve energy efficiency even with the uncertainty of the CSI.      
### 47.Steady-State Rate-Optimal Power Adaptation in Energy Harvesting Opportunistic Cognitive Radios with Spectrum Sensing and Channel Estimation Errors  [ :arrow_down: ](https://arxiv.org/pdf/2012.04826.pdf)
>  We consider an uplink cognitive radio (CR) network that can access a wideband spectrum licensed to a primary network, which is divided into non-overlapping narrowband channels. The secondary users (SUs) are equipped with rechargeable batteries of finite capacity that solely powered by energy harvesting from the ambient environment. The SUs which are aware of the available energy in their batteries, sense the activity of the primary transmitter. If the result of spectrum sensing is idle, SUs send pilot symbols to the secondary access point (AP) and AP estimates the secondary channel power. Then, AP feeds back the channel gain to SUs. Knowing the battery state and the feedback information, SUs optimally adapt their transmit power to AP such that the steady-state sum rate of SU-AP link is maximized, subject to average interference constraint (AIC) imposed on the primary receiver and the causality constraint of the batteries. We illustrate the effect of the AIC, energy arrival rate and battery capacity on the steady-state distribution of battery, CR network rate, battery energy outage probability, and transmission outage probability via simulation.      
### 48.You Only Need Adversarial Supervision for Semantic Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2012.04781.pdf)
>  Despite their recent successes, GAN models for semantic image synthesis still suffer from poor image quality when trained with only adversarial supervision. Historically, additionally employing the VGG-based perceptual loss has helped to overcome this issue, significantly improving the synthesis quality, but at the same time limiting the progress of GAN models for semantic image synthesis. In this work, we propose a novel, simplified GAN model, which needs only adversarial supervision to achieve high quality results. We re-design the discriminator as a semantic segmentation network, directly using the given semantic label maps as the ground truth for training. By providing stronger supervision to the discriminator as well as to the generator through spatially- and semantically-aware discriminator feedback, we are able to synthesize images of higher fidelity with better alignment to their input label maps, making the use of the perceptual loss superfluous. Moreover, we enable high-quality multi-modal image synthesis through global and local sampling of a 3D noise tensor injected into the generator, which allows complete or partial image change. We show that images synthesized by our model are more diverse and follow the color and texture distributions of real images more closely. We achieve an average improvement of $6$ FID and $5$ mIoU points over the state of the art across different datasets using only adversarial supervision.      
### 49.Simultaneous Grouping and Denoising via Sparse Convex Wavelet Clustering  [ :arrow_down: ](https://arxiv.org/pdf/2012.04762.pdf)
>  Clustering is a ubiquitous problem in data science and signal processing. In many applications where we observe noisy signals, it is common practice to first denoise the data, perhaps using wavelet denoising, and then to apply a clustering algorithm. In this paper, we develop a sparse convex wavelet clustering approach that simultaneously denoises and discovers groups. Our approach utilizes convex fusion penalties to achieve agglomeration and group-sparse penalties to denoise through sparsity in the wavelet domain. In contrast to common practice which denoises then clusters, our method is a unified, convex approach that performs both simultaneously. Our method yields denoised (wavelet-sparse) cluster centroids that both improve interpretability and data compression. We demonstrate our method on synthetic examples and in an application to NMR spectroscopy.      
### 50.Recent Advances in Computer Audition for Diagnosing COVID-19: An Overview  [ :arrow_down: ](https://arxiv.org/pdf/2012.04650.pdf)
>  Computer audition (CA) has been demonstrated to be efficient in healthcare domains for speech-affecting disorders (e.g., autism spectrum, depression, or Parkinson's disease) and body sound-affecting abnormalities (e. g., abnormal bowel sounds, heart murmurs, or snore sounds). Nevertheless, CA has been underestimated in the considered data-driven technologies for fighting the COVID-19 pandemic caused by the SARS-CoV-2 coronavirus. In this light, summarise the most recent advances in CA for COVID-19 speech and/or sound analysis. While the milestones achieved are encouraging, there are yet not any solid conclusions that can be made. This comes mostly, as data is still sparse, often not sufficiently validated and lacking in systematic comparison with related diseases that affect the respiratory system. In particular, CA-based methods cannot be a standalone screening tool for SARS-CoV-2. We hope this brief overview can provide a good guidance and attract more attention from a broader artificial intelligence community.      

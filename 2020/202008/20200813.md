# ArXiv eess --Thu, 13 Aug 2020
### 1.Deep Learning Based Load Forecasting: from Research to Deployment -- Opportunities and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2008.05458.pdf)
>  Electricity load forecasting for buildings and campuses is becoming increasingly important as the penetration of distributed energy resources grows. Efficient operation and dispatch of DERs requires reasonably accurate prediction of future energy consumption in order to conduct near-real-time optimized dispatch of on-site generation and storage assets. Load forecasting has traditionally been done by electric utilities for load pockets spanning large geographic areas and therefore has not been a common practice in the buildings' and campuses' operational arena. Given the growing trends of research and prototyping in the grid-interactive efficient buildings domain, characteristics beyond simple algorithm forecast accuracy are important in determining the algorithm's true utility for the smart buildings. These other characteristics include the overall design of the deployed architecture and the operational efficiency of the forecasting system. In this work, we present a deep-learning-based load forecasting system that predicts the building load at one-hour interval for 18 hours in the future. We also present the challenges associated with the real-time deployment of such systems as well as the research opportunities presented by a fully functional forecasting system that has been developed within the National Renewable Energy Laboratory's Intelligent Campus program.      
### 2.Probabilistic Resilience of DER systems -- A Simulation Assisted Optimization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.05455.pdf)
>  Energy systems resilience is becoming increasingly important as the frequency of major grid outages increases. In this work, we present a methodology to optimize a behind-the-meter distributed energy resource system to sustain a site's critical loads during a pre-defined utility outage period. With the fixed system design, we then propose an outage simulation approach to estimate the resilience potential of the DER system to sustain loads beyond the fixed outage period - a yearlong resilience performance analysis. We apply statistical analysis to assess the system's resilience performance over a broader parametric problem space on an hourly, monthly, and yearly basis. We present a case study to demonstrate the impact of the pre-defined outage period on the resilience performance of the system. The case study shows that the probability of surviving a random outage of a given duration changes from 20 percent to 95 percent when the outage is modeled for a weekday instead of a weekend for the case study building.      
### 3.Chernoff Bounds and Saddlepoint Approximations for the Outage Probability in Intelligent Reflecting Surface Assisted Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.05447.pdf)
>  We analyze the outage probability of an intelligent reflecting surface (IRS)-assisted communication network. A tight upper bound on the outage probability is formulated based on the Chernoff inequality. Furthermore, through an exact asymptotic (a large number of reflecting elements) analysis based on a saddlepoint approximation, we derive closed-form expressions of the outage probability for systems with and without a direct link and obtain the corresponding diversity orders. Simulation results corroborate our theoretical analysis and show the inaccuracies inherent in using the central limit theorem (CLT) to analyze system performance. Our analysis is accurate even for a small number of IRS elements in the high signal-to-noise ratio (SNR) regime.      
### 4.Using convolution neural networks to learn enhanced fiber orientation distribution models from commercially available diffusion magnetic resonance imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.05409.pdf)
>  Accurate local fiber orientation distribution (FOD) modeling based on diffusion magnetic resonance imaging (dMRI) capable of resolving complex fiber configurations benefit from specific acquisition protocols that impose a high number of gradient directions (b-vecs), a high maximum b-value (b-vals) and multiple b-values (multi-shell). However, acquisition time is limited in a clinical setting and commercial scanners may not provide robust state-of-the-art dMRI sequences. Therefore, dMRI is often acquired as single-shell (SS) (single b-value). Here, we learn improved FODs for commercially acquired dMRI. We evaluate the use of 3D convolutional neural networks (CNNs) to regress multi-shell FOS representations from single-shell representations, using the spherical harmonics basis obtained from constrained spherical deconvolution (CSD) to model FODs. We use U-Net and HighResNet 3D CNN architectures and data from the publicly available Human Connectome Dataset and a dataset acquired at National Hospital For Neurology and Neurosurgery Queen Square. We evaluate how well the CNN models can resolve local fiber orientation 1) when training and testing on datasets with same dMRI acquisition protocol; 2) when testing on dataset with a different dMRI acquisition protocol than used training the CNN models; and 3) when testing on datasets with a fewer number dMRI gradient directions than used training the CNN models. Our approach may enable robust CSD model estimation on dMRI acquisition protocols which are single shell and with a few gradient directions, reducing acquisition times, and thus, facilitating translation to time-limited clinical environments.      
### 5.Downlink Transmit Design in Massive MIMO LEO Satellite Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.05343.pdf)
>  Low earth orbit (LEO) satellite communication systems have attracted extensive attention due to their smaller pathloss, shorter round-trip delay and lower launch cost compared with geostationary counterparts. In this paper, the downlink transmit design for massive multiple-input multiple-output (MIMO) LEO satellite communications is investigated. First, we establish the massive MIMO LEO satellite channel model where the satellite and user terminals (UTs) are both equipped with the uniform planar arrays. Then, the rank of transmit covariance matrix of each UT is shown to be no larger than one to maximize ergodic sum rate, which reveals the optimality of single-stream precoding for each UT. The minorization-maximization algorithm is used to compute the precoding vectors. To reduce the computation complexity, an upper bound of ergodic sum rate is resorted to produce a simplified transmit design, where the rank of optimal transmit covariance matrix of each UT is also shown to not exceed one. To tackle the simplified precoder design, we derive the structure of precoding vectors, and formulate a Lagrange multiplier optimization (LMO) problem building on the structure. Then, a low-complexity algorithm is devised to solve the LMO, which takes much less computation effort. Simulation results verify the performance of proposed approaches.      
### 6.Renal Cell Carcinoma Detection and Subtyping with Minimal Point-Based Annotation in Whole-Slide Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.05332.pdf)
>  Obtaining a large amount of labeled data in medical imaging is laborious and time-consuming, especially for histopathology. However, it is much easier and cheaper to get unlabeled data from whole-slide images (WSIs). Semi-supervised learning (SSL) is an effective way to utilize unlabeled data and alleviate the need for labeled data. For this reason, we proposed a framework that employs an SSL method to accurately detect cancerous regions with a novel annotation method called Minimal Point-Based annotation, and then utilize the predicted results with an innovative hybrid loss to train a classification model for subtyping. The annotator only needs to mark a few points and label them are cancer or not in each WSI. Experiments on three significant subtypes of renal cell carcinoma (RCC) proved that the performance of the classifier trained with the Min-Point annotated dataset is comparable to a classifier trained with the segmentation annotated dataset for cancer region detection. And the subtyping model outperforms a model trained with only diagnostic labels by 12% in terms of f1-score for testing WSIs.      
### 7.Motion Optimization for Musculoskeletal Dynamics: A Flatness-Based Polynomial Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.05318.pdf)
>  A new approach for trajectory optimization of musculoskeletal dynamic models is introduced. The model combines rigid body and muscle dynamics described with a Hill-type model driven by neural control inputs. The objective is to find input and state trajectories which are optimal with respect to a minimum-effort objective and meet constraints associated with musculoskeletal models. The measure of effort is given by the integral of pairwise average forces of the agonist-antagonist muscles. The concepts of flat parameterization of nonlinear systems and sum-of-squares optimization are combined to yield a method that eliminates the numerous set of dynamic constraints present in collocation methods. With terminal equilibrium, optimization reduces to a feasible linear program, and a recursive feasibility proof is given for more general polynomial optimization cases. The methods of the paper can be used as a basis for fast and efficient solvers for hierarchical and receding-horizon control schemes. Two simulation examples are included to illustrate the proposed methods      
### 8.Speaker Conditional WaveRNN: Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2008.05289.pdf)
>  Recent advancements in deep learning led to human-level performance in single-speaker speech synthesis. However, there are still limitations in terms of speech quality when generalizing those systems into multiple-speaker models especially for unseen speakers and unseen recording qualities. For instance, conventional neural vocoders are adjusted to the training speaker and have poor generalization capabilities to unseen speakers. In this work, we propose a variant of WaveRNN, referred to as speaker conditional WaveRNN (SC-WaveRNN). We target towards the development of an efficient universal vocoder even for unseen speakers and recording conditions. In contrast to standard WaveRNN, SC-WaveRNN exploits additional information given in the form of speaker embeddings. Using publicly-available data for training, SC-WaveRNN achieves significantly better performance over baseline WaveRNN on both subjective and objective metrics. In MOS, SC-WaveRNN achieves an improvement of about 23% for seen speaker and seen recording condition and up to 95% for unseen speaker and unseen condition. Finally, we extend our work by implementing a multi-speaker text-to-speech (TTS) synthesis similar to zero-shot speaker adaptation. In terms of performance, our system has been preferred over the baseline TTS system by 60% over 15.5% and by 60.9% over 32.6%, for seen and unseen speakers, respectively.      
### 9.Modeling Prosodic Phrasing with Multi-Task Learning in Tacotron-based TTS  [ :arrow_down: ](https://arxiv.org/pdf/2008.05284.pdf)
>  Tacotron-based end-to-end speech synthesis has shown remarkable voice quality. However, the rendering of prosody in the synthesized speech remains to be improved, especially for long sentences, where prosodic phrasing errors can occur frequently. In this paper, we extend the Tacotron-based speech synthesis framework to explicitly model the prosodic phrase breaks. We propose a multi-task learning scheme for Tacotron training, that optimizes the system to predict both Mel spectrum and phrase breaks. To our best knowledge, this is the first implementation of multi-task learning for Tacotron based TTS with a prosodic phrasing model. Experiments show that our proposed training scheme consistently improves the voice quality for both Chinese and Mongolian systems.      
### 10.Emotion Profile Refinery for Speech Emotion Classification  [ :arrow_down: ](https://arxiv.org/pdf/2008.05259.pdf)
>  Human emotions are inherently ambiguous and impure. When designing systems to anticipate human emotions based on speech, the lack of emotional purity must be considered. However, most of the current methods for speech emotion classification rest on the consensus, e.g., one single hard label for an utterance. This labeling principle imposes challenges for system performance considering emotional impurity. In this paper, we recommend the use of emotional profiles (EPs), which provides a time series of segment-level soft labels to capture the subtle blends of emotional cues present across a specific speech utterance. We further propose the emotion profile refinery (EPR), an iterative procedure to update EPs. The EPR method produces soft, dynamically-generated, multiple probabilistic class labels during successive stages of refinement, which results in significant improvements in the model accuracy. Experiments on three well-known emotion corpora show noticeable gain using the proposed method.      
### 11.Trajectory Tracking of Optimal Social Distancing Strategieswith Application to a CoVid-19 Scenario  [ :arrow_down: ](https://arxiv.org/pdf/2008.05245.pdf)
>  This letter proposes the use of nonlinear feedback control to produce robust and reactive social distancing policies that can be adapted in response to an epidemic outbreak. A trajectory tracking algorithm is proposed, and its effectiveness is analytically proven when acting on a low-dimensional approximation of the epidemics. Means of mapping the inputs and output of this controller to the real network dynamics of the pandemics are introduced. The strategy is tested with extensive simulations in a CoVid-19 inspired scenario, with particular focus on the case of Codogno - a small city in Northen Italy that has been among the most harshly hit by the pandemics. The proposed algorithm generates dramatic reductions of epidemic levels, while maintaining a total level of social distancing close to the nominal optimum.      
### 12.Large-Scale Analysis of Iliopsoas Muscle Volumes in the UK Biobank  [ :arrow_down: ](https://arxiv.org/pdf/2008.05217.pdf)
>  Psoas muscle measurements are frequently used as markers of sarcopenia and predictors of health. Manually measured cross-sectional areas are most commonly used, but there is a lack of consistency regarding the position of the measurementand manual annotations are not practical for large population studies. We have developed a fully automated method to measure iliopsoas muscle volume (comprised of the psoas and iliacus muscles) using a convolutional neural network. Magnetic resonance images were obtained from the UK Biobank for 5,000 male and female participants, balanced for age, gender and BMI. Ninety manual annotations were available for model training and validation. The model showed excellent performance against out-of-sample data (dice score coefficient of 0.912 +/- 0.018). Iliopsoas muscle volumes were successfully measured in all 5,000 participants. Iliopsoas volume was greater in male compared with female subjects. There was a small but significant asymmetry between left and right iliopsoas muscle volumes. We also found that iliopsoas volume was significantly related to height, BMI and age, and that there was an acceleration in muscle volume decrease in men with age. Our method provides a robust technique for measuring iliopsoas muscle volume that can be applied to large cohorts.      
### 13.Channel-wise Subband Input for Better Voice and Accompaniment Separation on High Resolution Music  [ :arrow_down: ](https://arxiv.org/pdf/2008.05216.pdf)
>  This paper presents a new input format, channel-wise subband input (CWS), for convolutional neural networks (CNN) based music source separation (MSS) models in the frequency domain. We aim to address the major issues in CNN-based high-resolution MSS model: high computational cost and weight sharing between distinctly different bands. Specifically, in this paper, we decompose the input mixture spectra into several bands and concatenate them channel-wise as the model input. The proposed approach enables effective weight sharing in each subband and introduces more flexibility between channels. For comparison purposes, we perform voice and accompaniment separation (VAS) on models with different scales, architectures, and CWS settings. Experiments show that the CWS input is beneficial in many aspects. We evaluate our method on musdb18hq test set, focusing on SDR, SIR and SAR metrics. Among all our experiments, CWS enables models to obtain 6.9% performance gain on the average metrics. With even a smaller number of parameters, less training data, and shorter training time, our MDenseNet with 8-bands CWS input still surpasses the original MMDenseNet with a large margin. Moreover, CWS also reduces computational cost and training time to a large extent.      
### 14.Mask Detection and Breath Monitoring from Speech: on Data Augmentation, Feature Representation and Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2008.05175.pdf)
>  This paper introduces our approaches for the Mask and Breathing Sub-Challenge in the Interspeech COMPARE Challenge 2020. For the mask detection task, we train deep convolutional neural networks with filter-bank energies, gender-aware features, and speaker-aware features. Support Vector Machines follows as the back-end classifiers for binary prediction on the extracted deep embeddings. Several data augmentation schemes are used to increase the quantity of training data and improve our models' robustness, including speed perturbation, SpecAugment, and random erasing. For the speech breath monitoring task, we investigate different bottleneck features based on the Bi-LSTM structure. Experimental results show that our proposed methods outperform the baselines and achieve 0.746 PCC and 78.8% UAR on the Breathing and Mask evaluation set, respectively.      
### 15.Caching Placement and Resource Allocation for Cache-Enabling UAV NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05168.pdf)
>  This article investigates the cache-enabling unmanned aerial vehicle (UAV) cellular networks with massive access capability supported by non-orthogonal multiple access (NOMA). The delivery of a large volume of multimedia contents for ground users is assisted by a mobile UAV base station, which caches some popular contents for wireless backhaul link traffic offloading. In cache-enabling UAV NOMA networks, the caching placement of content caching phase and radio resource allocation of content delivery phase are crucial for network performance. To cope with the dynamic UAV locations and content requests in practical scenarios, we formulate the long-term caching placement and resource allocation optimization problem for content delivery delay minimization as a Markov decision process (MDP). The UAV acts as an agent to take actions for caching placement and resource allocation, which includes the user scheduling of content requests and the power allocation of NOMA users. In order to tackle the MDP, we propose a Q-learning based caching placement and resource allocation algorithm, where the UAV learns and selects action with \emph{soft ${\varepsilon}$-greedy} strategy to search for the optimal match between actions and states. Since the action-state table size of Q-learning grows with the number of states in the dynamic networks, we propose a function approximation based algorithm with combination of stochastic gradient descent and deep neural networks, which is suitable for large-scale networks. Finally, the numerical results show that the proposed algorithms provide considerable performance compared to benchmark algorithms, and obtain a trade-off between network performance and calculation complexity.      
### 16.Identification of MISO systems in Minimal Realization Form  [ :arrow_down: ](https://arxiv.org/pdf/2008.05150.pdf)
>  The paper is concerned with identifying transfer functions of individual input channels in minimal realization form of a Multi-Input Single Output (MISO) from the input-output data corrupted by the error in all the variables. Such a framework is commonly referred to as error-in-variables (EIV). A common approach in the existing methods for identification of MISO systems is to estimate a non-minimal order transfer function under a subset of simplistic assumptions like homoskedastic error variances, known order, and delay. In this work, we deal with the challenging problem of identifying order, delay in each input of minimal realization form separately while estimating the transfer functions. We also estimate the heteroskedastic noise variances in each of the multiple inputs and output variables. An automated approach for the identification of MISO systems of minimal realization form in the EIV framework is proposed. Numerical case studies are presented to illustrate the efficacy of the proposed algorithm in identifying the transfer function along with the order, delay, and noise variances.      
### 17.An Inter- and Intra-Band Loss for Pansharpening Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05133.pdf)
>  Pansharpening aims to fuse panchromatic and multispectral images from the satellite to generate images with both high spatial and spectral resolution. With the successful applications of deep learning in the computer vision field, a lot of scholars have proposed many convolutional neural networks (CNNs) to solve the pansharpening task. These pansharpening networks focused on various distinctive structures of CNNs, and most of them are trained by L2 loss between fused images and simulated desired multispectral images. However, L2 loss is designed to directly minimize the difference of spectral information of each band, which does not consider the inter-band relations in the training process. In this letter, we propose a novel inter- and intra-band (IIB) loss to overcome the drawback of original L2 loss. Our proposed IIB loss can effectively preserve both inter- and intra-band relations and can be directly applied to different pansharpening CNNs.      
### 18.Comments on Mathematical Modeling of Current Source Matrix Converter with Venturini and SVM  [ :arrow_down: ](https://arxiv.org/pdf/2008.05128.pdf)
>  In this paper, authors want to comment on a recently published article describing the Mathematical Modeling of Current Source Matrix Converter (CSMC) with two modulation strategies, namely: Venturini and Space Vector Modulation (SVM). Reported flaws are broadly classified into two (2) categories; namely: (1) Technical Flaws and (2) Rubric and Grammar Flaws. This paper not only reports these flaws but also provides suggestive rectifications for correction and improvement of the published article.      
### 19.Invariant learning based multi-stage identification for Lithium-ion battery performance degradation  [ :arrow_down: ](https://arxiv.org/pdf/2008.05123.pdf)
>  By informing accurate performance (e.g., capacity), health state management plays a significant role in safeguarding battery and its powered system. While most current approaches are primarily based on data-driven methods, lacking in-depth analysis of battery performance degradation mechanism may discount their performances. To fill in the research gap about data-driven battery performance degradation analysis, an invariant learning based method is proposed to investigate whether the battery performance degradation follows a fixed behavior. First, to unfold the hidden dynamics of cycling battery data, measurements are reconstructed in phase subspace. Next, a novel multi-stage division strategy is put forward to judge the existent of multiple degradation behaviors. Then the whole aging procedure is sequentially divided into several segments, among which cycling data with consistent degradation speed are assigned in the same stage. Simulations on a well-know benchmark verify the efficacy of the proposed multi-stages identification strategy. The proposed method not only enables insights into degradation mechanism from data perspective, but also will be helpful to related topics, such as stage of health.      
### 20.A Longitudinal Method for Simultaneous Whole-Brain and Lesion Segmentation in Multiple Sclerosis  [ :arrow_down: ](https://arxiv.org/pdf/2008.05117.pdf)
>  In this paper we propose a novel method for the segmentation of longitudinal brain MRI scans of patients suffering from Multiple Sclerosis. The method builds upon an existing cross-sectional method for simultaneous whole-brain and lesion segmentation, introducing subject-specific latent variables to encourage temporal consistency between longitudinal scans. It is very generally applicable, as it does not make any prior assumptions on the scanner, the MRI protocol, or the number and timing of longitudinal follow-up scans. Preliminary experiments on three longitudinal datasets indicate that the proposed method produces more reliable segmentations and detects disease effects better than the cross-sectional method it is based upon.      
### 21.Rate-Splitting Multiple Access for Multigroup Multicast and Multibeam Satellite Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.05091.pdf)
>  This work focuses on the promising Rate-Splitting Multiple Access (RSMA) and its beamforming design problem to achieve max-min fairness (MMF) among multiple co-channel multicast groups with imperfect channel state information at the transmitter (CSIT). Contrary to the conventional linear precoding (NoRS) that relies on fully treating any residual interference as noise, we consider a novel multigroup multicast beamforming strategy based on RSMA. RSMA relies on linearly precoded Rate-Splitting (RS) at the transmitter and Successive Interference Cancellation (SIC) at the receivers, and has recently been shown to enable a flexible framework for non-orthogonal transmission and robust interference management in multi-antenna wireless networks. In this work, we characterize the MMF Degrees-of-Freedom (DoF) achieved by RS and NoRS in multigroup multicast with imperfect CSIT and demonstrate the benefits of RS strategies for both underloaded and overloaded scenarios. Motivated by the DoF analysis, we then formulate a generic transmit power constrained optimization problem to achieve MMF rate performance. The superiority of RS-based multigroup multicast beamforming compared with NoRS is demonstrated via simulations in both terrestrial and multibeam satellite systems. In particular, due to the characteristics and challenges of multibeam satellite communications, our proposed RS strategy is shown promising to manage its interbeam interference.      
### 22.Transfer Learning Approaches for Streaming End-to-End Speech Recognition System  [ :arrow_down: ](https://arxiv.org/pdf/2008.05086.pdf)
>  Transfer learning (TL) is widely used in conventional hybrid automatic speech recognition (ASR) system, to transfer the knowledge from source to target language. TL can be applied to end-to-end (E2E) ASR system such as recurrent neural network transducer (RNN-T) models, by initializing the encoder and/or prediction network of the target language with the pre-trained models from source language. In the hybrid ASR system, transfer learning is typically done by initializing the target language acoustic model (AM) with source language AM. Several transfer learning strategies exist in the case of the RNN-T framework, depending upon the choice of the initialization model for encoder and prediction networks. This paper presents a comparative study of four different TL methods for RNN-T framework. We show 17% relative word error rate reduction with different TL methods over randomly initialized RNN-T model. We also study the impact of TL with varying amount of training data ranging from 50 hours to 1000 hours and show the efficacy of TL for languages with a very small amount of training data.      
### 23.Self-supervised Light Field View Synthesis Using Cycle Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2008.05084.pdf)
>  High angular resolution is advantageous for practical applications of light fields. In order to enhance the angular resolution of light fields, view synthesis methods can be utilized to generate dense intermediate views from sparse light field input. Most successful view synthesis methods are learning-based approaches which require a large amount of training data paired with ground truth. However, collecting such large datasets for light fields is challenging compared to natural images or videos. To tackle this problem, we propose a self-supervised light field view synthesis framework with cycle consistency. The proposed method aims to transfer prior knowledge learned from high quality natural video datasets to the light field view synthesis task, which reduces the need for labeled light field data. A cycle consistency constraint is used to build bidirectional mapping enforcing the generated views to be consistent with the input views. Derived from this key concept, two loss functions, cycle loss and reconstruction loss, are used to fine-tune the pre-trained model of a state-of-the-art video interpolation method. The proposed method is evaluated on various datasets to validate its robustness, and results show it not only achieves competitive performance compared to supervised fine-tuning, but also outperforms state-of-the-art light field view synthesis methods, especially when generating multiple intermediate views. Besides, our generic light field view synthesis framework can be adopted to any pre-trained model for advanced video interpolation.      
### 24.Deep Reinforcement Learning for Smart Building Energy Management: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2008.05074.pdf)
>  Global buildings consumed 30\% of total energy and generated 28\% of total carbon emission in 2018, which leads to economic and environmental concerns. Therefore, it is of great significance to reduce energy consumption, energy cost and carbon emission of buildings while maintaining user comfort. To this end, several challenges have to be addressed. Firstly, it is very challenging to develop a building thermal dynamics model that is both accurate and efficient enough for building control. Secondly, there are many kinds of uncertainties. Thirdly, there are many spatially and temporally operational constraints. Fourthly, building energy optimization problems may have extremely large solution spaces, which can not be solved in real-time by traditional methods. Fifthly, traditional building energy management methods have respective applicable premises, which means that they have low versatility when confronted with varying building environments. Since deep reinforcement learning (DRL) is a promising tool to address the above challenges, this paper presents a comprehensive literature review on DRL for smart building energy management (SBEM). To be specific, we first introduce the fundamentals of DRL and provide the classification of DRL methods used in existing works related to SBEM. Then, we review the applications of DRL in a single building energy subsystem, multiple energy subsystems of buildings, and building microgrids, respectively. Furthermore, we identify the unsolved issues and point out the possible research directions of applying DRL. Finally, we summarize the lessons learned from this survey.      
### 25.Research on the construction method of vehicle driving cycle based on Mean Shift clustering  [ :arrow_down: ](https://arxiv.org/pdf/2008.05070.pdf)
>  In this study, a novel method for the construction of a driving cycle based on Mean Shift clustering is proposed to solve the problems existing in the traditional micro-trips method. Firstly, 1701 kinematic segments are obtained by processing and dividing the driving data in real road conditions. Secondly, 12 kinematic parameters are calculated for each segment, and the dimensionality of parameters is reduced through principal component analysis (PCA). Three principal components are chosen to classify all cycles into three types by the Mean Shift algorithm. Finally, according to the principle of minimum deviation, representative micro-trips are selected from each type of cycle to complete the construction of the final driving cycle. Further, the construction method in this paper is compared with the micro-trips construction method by the K-Means clustering. The results show that the construction method by Mean Shift clustering can more effectively reflect the real driving data. This study realizes the innovation in the construction method of micro-trips and provides a preliminary theoretical basis for the formulation of automobile working condition standards, energy management of new-energy vehicles, and optimal control of vehicle dynamics in driverless vehicles.      
### 26.Real-Time Cardiac Cine MRI with Residual Convolutional Recurrent Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.05044.pdf)
>  Real-time cardiac cine MRI does not require ECG gating in the data acquisition and is more useful for patients who can not hold their breaths or have abnormal heart rhythms. However, to achieve fast image acquisition, real-time cine commonly acquires highly undersampled data, which imposes a significant challenge for MRI image reconstruction. We propose a residual convolutional RNN for real-time cardiac cine reconstruction. To the best of our knowledge, this is the first work applying deep learning approach to Cartesian real-time cardiac cine reconstruction. Based on the evaluation from radiologists, our deep learning model shows superior performance than compressed sensing.      
### 27.End-to-End Rate-Distortion Optimization for Bi-Directional Learned Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2008.05028.pdf)
>  Conventional video compression methods employ a linear transform and block motion model, and the steps of motion estimation, mode and quantization parameter selection, and entropy coding are optimized individually due to combinatorial nature of the end-to-end optimization problem. Learned video compression allows end-to-end rate-distortion optimized training of all nonlinear modules, quantization parameter and entropy model simultaneously. While previous work on learned video compression considered training a sequential video codec based on end-to-end optimization of cost averaged over pairs of successive frames, it is well-known in conventional video compression that hierarchical, bi-directional coding outperforms sequential compression. In this paper, we propose for the first time end-to-end optimization of a hierarchical, bi-directional motion compensated learned codec by accumulating cost function over fixed-size groups of pictures (GOP). Experimental results show that the rate-distortion performance of our proposed learned bi-directional {\it GOP coder} outperforms the state-of-the-art end-to-end optimized learned sequential compression as expected.      
### 28.Learned Proximal Networks for Quantitative Susceptibility Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2008.05024.pdf)
>  Quantitative Susceptibility Mapping (QSM) estimates tissue magnetic susceptibility distributions from Magnetic Resonance (MR) phase measurements by solving an ill-posed dipole inversion problem. Conventional single orientation QSM methods usually employ regularization strategies to stabilize such inversion, but may suffer from streaking artifacts or over-smoothing. Multiple orientation QSM such as calculation of susceptibility through multiple orientation sampling (COSMOS) can give well-conditioned inversion and an artifact free solution but has expensive acquisition costs. On the other hand, Convolutional Neural Networks (CNN) show great potential for medical image reconstruction, albeit often with limited interpretability. Here, we present a Learned Proximal Convolutional Neural Network (LP-CNN) for solving the ill-posed QSM dipole inversion problem in an iterative proximal gradient descent fashion. This approach combines the strengths of data-driven restoration priors and the clear interpretability of iterative solvers that can take into account the physical model of dipole convolution. During training, our LP-CNN learns an implicit regularizer via its proximal, enabling the decoupling between the forward operator and the data-driven parameters in the reconstruction algorithm. More importantly, this framework is believed to be the first deep learning QSM approach that can naturally handle an arbitrary number of phase input measurements without the need for any ad-hoc rotation or re-training. We demonstrate that the LP-CNN provides state-of-the-art reconstruction results compared to both traditional and deep learning methods while allowing for more flexibility in the reconstruction process.      
### 29.Compact Speaker Embedding: lrx-vector  [ :arrow_down: ](https://arxiv.org/pdf/2008.05011.pdf)
>  Deep neural networks (DNN) have recently been widely used in speaker recognition systems, achieving state-of-the-art performance on various benchmarks. The x-vector architecture is especially popular in this research community, due to its excellent performance and manageable computational complexity. In this paper, we present the lrx-vector system, which is the low-rank factorized version of the x-vector embedding network. The primary objective of this topology is to further reduce the memory requirement of the speaker recognition system. We discuss the deployment of knowledge distillation for training the lrx-vector system and compare against low-rank factorization with SVD. On the VOiCES 2019 far-field corpus we were able to reduce the weights by 28% compared to the full-rank x-vector system while keeping the recognition rate constant (1.83% EER).      
### 30.MOVESTAR: An Open-Source Vehicle Fuel andEmission Model based on USEPA MOVES  [ :arrow_down: ](https://arxiv.org/pdf/2008.04986.pdf)
>  In this paper, we introduce an open-source model "MOVESTAR" to calculate the fuel consumption and pollutant emissions of motor vehicles. This model is developed based on U.S. Environmental Protection Agency's (EPA) Motor Vehicle Emission Simulator (MOVES), which provides an accurate estimate of vehicle emissions under a wide range of user-defined conditions. Originally, MOVES requires users to specify many parameters through its software, including vehicle types, time periods, geographical areas, pollutants, vehicle operating characteristics, and road types. In this paper, MOVESTAR is developed as a simplified version, which only takes the second-by-second vehicle speed data and vehicle type as inputs. To enable easy integration of this model, its source code is provided in various languages, including MATLAB and C++. A case study is introduced in this paper to illustrate the effectiveness of the model in the development of advanced vehicle technology.      
### 31.Robust Model Predictive Control with Recursive State Estimation under Set-Membership Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2008.04980.pdf)
>  The robustness against uncertainties is a critical part in control system design. While robust control typically incorporates process noise into the formulation, state estimate error is neglected, which may cause the controller to fail in real-world applications. This paper presents a robust model predictive controller with state estimation for constrained linear systems. Unknown but bounded disturbances and partial state information are considered. To handle the partial observability of the system states, a recursive state estimator is utilized to provide the state feedback and the bounds on state estimate error. The resulting controller is guaranteed to satisfy the hard constraints for all possible realizations of the process and measurement noise within the given sets. The effectiveness of the proposed algorithm is illustrated in a numerical example.      
### 32.Demand side management impacts on electricity network vulnerability  [ :arrow_down: ](https://arxiv.org/pdf/2008.04954.pdf)
>  The demand for electricity is undergoing considerable spatial and temporal change. With the uptake of efficient technologies and increased electrification, a better understanding of how potential changes in demand patterns can affect network reliability is necessary. We quantify the macro-economic impacts of potential future changes in demand profiles for an electricity network undergoing generation shortages. Applied to Great Britain, potential savings or losses are assessed for changes to peak demands under four different load profiles: (i) current day, (ii) widespread uptake of efficient appliances, (iii) deployment of heat pumps, and (iv) moving to an idealised fully balanced load profile. Considerable variation in economic disruption is observed both between different demand profiles and across Great Britain. When the networks generation capacity is severely disrupted, we estimate hourly macro-economic impacts to increase by up to £1.23 million per additional GW of national electricity demand. A similar reduction in impacts can be achieved if peak demands are reduced by demand side management. We conclude that risk-related economic impacts are directly linked to the temporal pattern of energy demands and need to be included in the decision-making around demand side measures. We find that decarbonisation strategies without accompanying demand side management may lead to increased economic losses without supply side interventions.      
### 33.PneumoXttention: A CNN compensating for Human Fallibility when Detecting Pneumonia through CXR images with Attention  [ :arrow_down: ](https://arxiv.org/pdf/2008.04907.pdf)
>  Automatic Chest Radiograph X-ray (CXR) interpretation by machines is an important research topic of Artificial Intelligence. As part of my journey through the California Science Fair, I have developed an algorithm that can detect pneumonia from a CXR image to compensate for human fallibility. My algorithm, PneumoXttention, is an ensemble of two 13 layer convolutional neural network trained on the RSNA dataset, a dataset provided by the Radiological Society of North America, containing 26,684 frontal X-ray images split into the categories of pneumonia and no pneumonia. The dataset was annotated by many professional radiologists in North America. It achieved an impressive F1 score, 0.82, on the test set (20% random split of RSNA dataset) and completely compensated Human Radiologists on a random set of 25 test images drawn from RSNA and NIH. I don't have a direct comparison but Stanford's Chexnet has a F1 score of 0.435 on the NIH dataset for category Pneumonia.      
### 34.Analyzing Upper Bounds on Mean Absolute Errors for Deep Neural Network Based Vector-to-Vector Regression  [ :arrow_down: ](https://arxiv.org/pdf/2008.05459.pdf)
>  In this paper, we show that, in vector-to-vector regression utilizing deep neural networks (DNNs), a generalized loss of mean absolute error (MAE) between the predicted and expected feature vectors is upper bounded by the sum of an approximation error, an estimation error, and an optimization error. Leveraging upon error decomposition techniques in statistical learning theory and non-convex optimization theory, we derive upper bounds for each of the three aforementioned errors and impose necessary constraints on DNN models. Moreover, we assess our theoretical results through a set of image de-noising and speech enhancement experiments. Our proposed upper bounds of MAE for DNN based vector-to-vector regression are corroborated by the experimental results and the upper bounds are valid with and without the "over-parametrization" technique.      
### 35.More Diverse Means Better: Multimodal Deep Learning Meets Remote Sensing Imagery Classification  [ :arrow_down: ](https://arxiv.org/pdf/2008.05457.pdf)
>  Classification and identification of the materials lying over or beneath the Earth's surface have long been a fundamental but challenging research topic in geoscience and remote sensing (RS) and have garnered a growing concern owing to the recent advancements of deep learning techniques. Although deep networks have been successfully applied in single-modality-dominated classification tasks, yet their performance inevitably meets the bottleneck in complex scenes that need to be finely classified, due to the limitation of information diversity. In this work, we provide a baseline solution to the aforementioned difficulty by developing a general multimodal deep learning (MDL) framework. In particular, we also investigate a special case of multi-modality learning (MML) -- cross-modality learning (CML) that exists widely in RS image classification applications. By focusing on "what", "where", and "how" to fuse, we show different fusion strategies as well as how to train deep networks and build the network architecture. Specifically, five fusion architectures are introduced and developed, further being unified in our MDL framework. More significantly, our framework is not only limited to pixel-wise classification tasks but also applicable to spatial information modeling with convolutional neural networks (CNNs). To validate the effectiveness and superiority of the MDL framework, extensive experiments related to the settings of MML and CML are conducted on two different multimodal RS datasets. Furthermore, the codes and datasets will be available at <a class="link-external link-https" href="https://github.com/danfenghong/IEEE_TGRS_MDL-RS" rel="external noopener nofollow">this https URL</a>, contributing to the RS community.      
### 36.Improving Stability of LS-GANs for Audio and Speech Signals  [ :arrow_down: ](https://arxiv.org/pdf/2008.05454.pdf)
>  In this paper we address the instability issue of generative adversarial network (GAN) by proposing a new similarity metric in unitary space of Schur decomposition for 2D representations of audio and speech signals. We show that encoding departure from normality computed in this vector space into the generator optimization formulation helps to craft more comprehensive spectrograms. We demonstrate the effectiveness of binding this metric for enhancing stability in training with less mode collapse compared to baseline GANs. Experimental results on subsets of UrbanSound8k and Mozilla common voice datasets have shown considerable improvements on the quality of the generated samples measured by the Fréchet inception distance. Moreover, reconstructed signals from these samples, have achieved higher signal to noise ratio compared to regular LS-GANs.      
### 37.Anomaly localization by modeling perceptual features  [ :arrow_down: ](https://arxiv.org/pdf/2008.05369.pdf)
>  Although unsupervised generative modeling of an image dataset using a Variational AutoEncoder (VAE) has been used to detect anomalous images, or anomalous regions in images, recent works have shown that this method often identifies images or regions that do not concur with human perception, even questioning the usability of generative models for robust anomaly detection. Here, we argue that those issues can emerge from having a simplistic model of the anomaly distribution and we propose a new VAE-based model expressing a more complex anomaly model that is also closer to human perception. This Feature-Augmented VAE is trained by not only reconstructing the input image in pixel space, but also in several different feature spaces, which are computed by a convolutional neural network trained beforehand on a large image dataset. It achieves clear improvement over state-of-the-art methods on the MVTec anomaly detection and localization datasets.      
### 38.Virtual H&amp;E Histology by Fiber-Based Picosecond Two-Photon Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2008.05319.pdf)
>  Two-Photon Microscopy (TPM) can provide three-dimensional morphological and functional contrast in vivo. Through proper staining, TPM can be utilized to create virtual, H&amp;E equivalent images and thus can improve throughput in histology-based applications. We previously reported on a new light source for TPM that employs a compact and robust fiber-amplified, directly modulated laser. This laser is pulse-to-pulse wavelength switchable between 1064 nm, 1122 nm, and 1186 nm with an adjustable pulse duration from 50ps to 5ns and arbitrary repetition rates up to 1MHz at kW-peak powers. Despite the longer pulse duration, it can achieve similar average signal levels compared to fs-setups by lowering the repetition rate to achieve similar cw and peak power levels. The longer pulses lead to a larger number of photons per pulse, which yields single shot fluorescence lifetime measurements (FLIM) by applying a fast 4 GSamples/s digitizer. In the previous setup, the wavelengths were limited to 1064 nm and longer. Here, we use four wave mixing in a non-linear photonic crystal fiber to expand the wavelength range down to 940 nm. This wavelength is highly suitable for imaging green fluorescent proteins in neurosciences and stains such as acridine orange (AO), eosin yellow (EY) and sulforhodamine 101 (SR101) used for histology applications. In a more compact setup, we also show virtual H&amp;E histological imaging using a direct 1030 nm fiber MOPA.      
### 39.Guided Collaborative Training for Pixel-wise Semi-Supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.05258.pdf)
>  We investigate the generalization of semi-supervised learning (SSL) to diverse pixel-wise tasks. Although SSL methods have achieved impressive results in image classification, the performances of applying them to pixel-wise tasks are unsatisfactory due to their need for dense outputs. In addition, existing pixel-wise SSL approaches are only suitable for certain tasks as they usually require to use task-specific properties. In this paper, we present a new SSL framework, named Guided Collaborative Training (GCT), for pixel-wise tasks, with two main technical contributions. First, GCT addresses the issues caused by the dense outputs through a novel flaw detector. Second, the modules in GCT learn from unlabeled data collaboratively through two newly proposed constraints that are independent of task-specific properties. As a result, GCT can be applied to a wide range of pixel-wise tasks without structural adaptation. Our extensive experiments on four challenging vision tasks, including semantic segmentation, real image denoising, portrait image matting, and night image enhancement, show that GCT outperforms state-of-the-art SSL methods by a large margin. Our code available at: <a class="link-external link-https" href="https://github.com/ZHKKKe/PixelSSL" rel="external noopener nofollow">this https URL</a>.      
### 40.Learning to Detect Anomalous Wireless Links in IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05232.pdf)
>  After decades of research, Internet of Things (IoT) is finally permeating real-life and helps improve the efficiency of infrastructures and processes as well as our health. As massive number of IoT devices are deployed, they naturally incurs great operational costs to ensure intended operations. To effectively handle such intended operations in massive IoT networks, automatic detection of malfunctioning, namely anomaly detection, becomes a critical but challenging task. In this paper, motivated by a real-world experimental IoT deployment, we introduce four types of wireless network anomalies that are identified at the link layer. We study the performance of threshold- and machine learning (ML)-based classifiers to automatically detect these anomalies. We examine the relative performance of three supervised and three unsupervised ML techniques on both non-encoded and encoded (autoencoder) feature representations. Our results demonstrate that; i) automatically generated features using autoencoders significantly outperform the non-encoded representations and can improve F1 score up to 500% and ii) among the best performing models based on F1 score, supervised ML models outperform the unsupervised counterpart models with about 18% on average for anomaly types SuddenD and SuddenR, and this trend also applies to SlowD and InstaD anomalies, albeit with a tiny margin.      
### 41.Bone Segmentation in Contrast Enhanced Whole-Body Computed Tomograph  [ :arrow_down: ](https://arxiv.org/pdf/2008.05223.pdf)
>  Segmentation of bone regions allows for enhanced diagnostics, disease characterisation and treatment monitoring in CT imaging. In contrast enhanced whole-body scans accurate automatic segmentation is particularly difficult as low dose whole body protocols reduce image quality and make contrast enhanced regions more difficult to separate when relying on differences in pixel intensities. This paper outlines a U-net architecture with novel preprocessing techniques, based on the windowing of training data and the modification of sigmoid activation threshold selection to successfully segment bone-bone marrow regions from low dose contrast enhanced whole-body CT scans. The proposed method achieved mean Dice coefficients of 0.979, 0.965, and 0.934 on two internal datasets and one external test dataset respectively. We have demonstrated that appropriate preprocessing is important for differentiating between bone and contrast dye, and that excellent results can be achieved with limited data.      
### 42.Pixel-level Corrosion Detection on Metal Constructions by Fusion of Deep Learning Semantic and Contour Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2008.05204.pdf)
>  Corrosion detection on metal constructions is a major challenge in civil engineering for quick, safe and effective inspection. Existing image analysis approaches tend to place bounding boxes around the defected region which is not adequate both for structural analysis and pre-fabrication, an innovative construction concept which reduces maintenance cost, time and improves safety. In this paper, we apply three semantic segmentation-oriented deep learning models (FCN, U-Net and Mask R-CNN) for corrosion detection, which perform better in terms of accuracy and time and require a smaller number of annotated samples compared to other deep models, e.g. CNN. However, the final images derived are still not sufficiently accurate for structural analysis and pre-fabrication. Thus, we adopt a novel data projection scheme that fuses the results of color segmentation, yielding accurate but over-segmented contours of a region, with a processed area of the deep masks, resulting in high-confidence corroded pixels.      
### 43.Dynamically Constrained Motion Planning Networks for Non-Holonomic Robots  [ :arrow_down: ](https://arxiv.org/pdf/2008.05112.pdf)
>  Reliable real-time planning for robots is essential in today's rapidly expanding automated ecosystem. In such environments, traditional methods that plan by relaxing constraints become unreliable or slow-down for kinematically constrained robots. This paper describes the algorithm Dynamic Motion Planning Networks (Dynamic MPNet), an extension to Motion Planning Networks, for non-holonomic robots that address the challenge of real-time motion planning using a neural planning approach. We propose modifications to the training and planning networks that make it possible for real-time planning while improving the data efficiency of training and trained models' generalizability. We evaluate our model in simulation for planning tasks for a non-holonomic robot. We also demonstrate experimental results for an indoor navigation task using a Dubins car.      
### 44.Effects of Voice-Based Synthetic Assistant on Performance of Emergency Care Provider in Training  [ :arrow_down: ](https://arxiv.org/pdf/2008.05064.pdf)
>  As part of a perennial project, our team is actively engaged in developing new synthetic assistant (SA) technologies to assist in training combat medics and medical first responders. It is critical that medical first responders are well trained to deal with emergencies more effectively. This would require real-time monitoring and feedback for each trainee. Therefore, we introduced a voice-based SA to augment the training process of medical first responders and enhance their performance in the field. The potential benefits of SAs include a reduction in training costs and enhanced monitoring mechanisms. Despite the increased usage of voice-based personal assistants (PAs) in day-to-day life, the associated effects are commonly neglected for a study of human factors. Therefore, this paper focuses on performance analysis of the developed voice-based SA in emergency care provider training for a selected emergency treatment scenario. The research discussed in this paper follows design science in developing proposed technology; at length, we discussed architecture and development and presented working results of voice-based SA. The empirical testing was conducted on two groups as user studies using statistical analysis tools, one trained with conventional methods and the other with the help of SA. The statistical results demonstrated the amplification in training efficacy and performance of medical responders powered by SA. Furthermore, the paper also discusses the accuracy and time of task execution (t) and concludes with the guidelines for resolving the identified problems.      
### 45.Online Graph Completion: Multivariate Signal Recovery in Computer Vision  [ :arrow_down: ](https://arxiv.org/pdf/2008.05060.pdf)
>  The adoption of "human-in-the-loop" paradigms in computer vision and machine learning is leading to various applications where the actual data acquisition (e.g., human supervision) and the underlying inference algorithms are closely interwined. While classical work in active learning provides effective solutions when the learning module involves classification and regression tasks, many practical issues such as partially observed measurements, financial constraints and even additional distributional or structural aspects of the data typically fall outside the scope of this treatment. For instance, with sequential acquisition of partial measurements of data that manifest as a matrix (or tensor), novel strategies for completion (or collaborative filtering) of the remaining entries have only been studied recently. Motivated by vision problems where we seek to annotate a large dataset of images via a crowdsourced platform or alternatively, complement results from a state-of-the-art object detector using human feedback, we study the "completion" problem defined on graphs, where requests for additional measurements must be made sequentially. We design the optimization model in the Fourier domain of the graph describing how ideas based on adaptive submodularity provide algorithms that work well in practice. On a large set of images collected from Imgur, we see promising results on images that are otherwise difficult to categorize. We also show applications to an experimental design problem in neuroimaging.      
### 46.Methods to Quantify Dislocation Behavior with Dark-field X-ray Microscopy Timescans of Single-Crystal Aluminum  [ :arrow_down: ](https://arxiv.org/pdf/2008.04972.pdf)
>  Crystal defects play a large role in how materials respond to their surroundings, yet there are many uncertainties in how extended defects form, move, and interact deep beneath a material's surface. A newly developed imaging diagnostic, dark-field X-ray microscopy (DFXM) can now visualize the behavior of line defects, known as dislocations, in materials under varying conditions. DFXM images visualize dislocations by imaging the very subtle long-range distortions in the material's crystal lattice, which produce a characteristic adjoined pair of bright and dark regions. Full analysis of how these dislocations evolve can be used to refine material models, however, it requires quantitative characterization of the statistics of their shape, position and motion. In this paper, we present a semi-automated approach to effectively isolate, track, and quantify the behavior of dislocations as composite objects. This analysis drives the statistical characterization of the defects, to include dislocation velocity and orientation in the crystal, for example, and is demonstrated on DFXM images measuring the evolution of defects at 98$\%$ of the melting temperature for single-crystal aluminum, collected at the European Synchrotron Radiation Facility.      
### 47.Little Motion, Big Results: Using Motion Magnification to Reveal Subtle Tremors in Infants  [ :arrow_down: ](https://arxiv.org/pdf/2008.04946.pdf)
>  Detecting tremors is challenging for both humans and machines. Infants exposed to opioids during pregnancy often show signs and symptoms of withdrawal after birth, which are easy to miss with the human eye. The constellation of clinical features, termed as Neonatal Abstinence Syndrome (NAS), include tremors, seizures, irritability, etc. The current standard of care uses Finnegan Neonatal Abstinence Syndrome Scoring System (FNASS), based on subjective evaluations. Monitoring with FNASS requires highly skilled nursing staff, making continuous monitoring difficult. In this paper we propose an automated tremor detection system using amplified motion signals. We demonstrate its applicability on bedside video of infant exhibiting signs of NAS. Further, we test different modes of deep convolutional network based motion magnification, and identify that dynamic mode works best in the clinical setting, being invariant to common orientational changes. We propose a strategy for discharge and follow up for NAS patients, using motion magnification to supplement the existing protocols. Overall our study suggests methods for bridging the gap in current practices, training and resource utilization.      
### 48.Content-based Music Similarity with Triplet Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.04938.pdf)
>  We explore the feasibility of using triplet neural networks to embed songs based on content-based music similarity. Our network is trained using triplets of songs such that two songs by the same artist are embedded closer to one another than to a third song by a different artist. We compare two models that are trained using different ways of picking this third song: at random vs. based on shared genre labels. Our experiments are conducted using songs from the Free Music Archive and use standard audio features. The initial results show that shallow Siamese networks can be used to embed music for a simple artist retrieval task.      
### 49.Towards Software-Defined Data Protection: GDPR Compliance at the Storage Layer is Within Reach  [ :arrow_down: ](https://arxiv.org/pdf/2008.04936.pdf)
>  Enforcing data protection and privacy rules within large data processing applications is becoming increasingly important, especially in the light of GDPR and similar regulatory frameworks. Most modern data processing happens on top of a distributed storage layer, and securing this layer against accidental or malicious misuse is crucial to ensuring global privacy guarantees. However, the performance overhead and the additional complexity for this is often assumed to be significant -- in this work we describe a path forward that tackles both challenges. We propose "Software-Defined Data Protection" (SDP), an adoption of the "Software-Defined Storage" approach to non-performance aspects: a trusted controller translates company and application-specific policies to a set of rules deployed on the storage nodes. These, in turn, apply the rules at line-rate but do not take any decisions on their own. Such an approach decouples often changing policies from request-level enforcement and allows storage nodes to implement the latter more efficiently. <br>Even though in-storage processing brings challenges, mainly because it can jeopardize line-rate processing, we argue that today's Smart Storage solutions can already implement the required functionality, thanks to the separation of concerns introduced by SDP. We highlight the challenges that remain, especially that of trusting the storage nodes. These need to be tackled before we can reach widespread adoption in cloud environments.      

# ArXiv eess --Fri, 14 Aug 2020
### 1.Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks in Highly Accelerated MRI  [ :arrow_down: ](https://arxiv.org/pdf/2008.06029.pdf)
>  Purpose: To develop an improved self-supervised learning strategy that efficiently uses the acquired data for training a physics-guided reconstruction network without a database of fully-sampled data. <br>Methods: Currently self-supervised learning for physics-guided reconstruction networks splits acquired undersampled data into two disjoint sets, where one is used for data consistency (DC) in the unrolled network and the other to define the training loss. The proposed multi-mask self-supervised learning via data undersampling (SSDU) splits acquired measurements into multiple pairs of disjoint sets for each training sample, while using one of these sets for DC units and the other for defining loss, thereby more efficiently using the undersampled data. Multi-mask SSDU is applied on fully-sampled 3D knee and prospectively undersampled 3D brain MRI datasets, which are retrospectively subsampled to acceleration rate (R)=8, and compared to CG-SENSE and single-mask SSDU DL-MRI, as well as supervised DL-MRI when fully-sampled data is available. <br>Results: Results on knee MRI show that the proposed multi-mask SSDU outperforms SSDU and performs closely with supervised DL-MRI, while significantly outperforming CG-SENSE. A clinical reader study further ranks the multi-mask SSDU higher than supervised DL-MRI in terms of SNR and aliasing artifacts. Results on brain MRI show that multi-mask SSDU achieves better reconstruction quality compared to SSDU and CG-SENSE. Reader study demonstrates that multi-mask SSDU at R=8 significantly improves reconstruction compared to single-mask SSDU at R=8, as well as CG-SENSE at R=2. <br>Conclusion: The proposed multi-mask SSDU approach enables improved training of physics-guided neural networks without fully-sampled data, by enabling efficient use of the undersampled data with multiple masks.      
### 2.Textual Echo Cancellation  [ :arrow_down: ](https://arxiv.org/pdf/2008.06006.pdf)
>  In this paper, we propose Textual Echo Cancellation (TEC) - a framework for cancelling the text-to-speech (TTS) playback echo from overlapped speech recordings. Such a system can largely improve speech recognition performance and user experience for intelligent devices such as smart speakers, as the user can talk to the device while the device is still playing the TTS signal responding to the previous query. We implement this system by using a novel sequence-to-sequence model with multi-source attention that takes both the microphone mixture signal and the source text of the TTS playback as inputs, and predicts the enhanced audio. Experiments show that the textual information of the TTS playback is critical to the enhancement performance. Besides, the text sequence is much smaller in size compared with the raw acoustic signal of the TTS playback, and can be immediately transmitted to the device and the ASR server even before the playback is synthesized. Therefore, our proposed approach effectively reduces Internet communication and latency compared with alternative approaches such as acoustic echo cancellation (AEC).      
### 3.Meta Learning MPC using Finite-Dimensional Gaussian Process Approximations  [ :arrow_down: ](https://arxiv.org/pdf/2008.05984.pdf)
>  Data availability has dramatically increased in recent years, driving model-based control methods to exploit learning techniques for improving the system description, and thus control performance. Two key factors that hinder the practical applicability of learning methods in control are their high computational complexity and limited generalization capabilities to unseen conditions. Meta-learning is a powerful tool that enables efficient learning across a finite set of related tasks, easing adaptation to new unseen tasks. This paper makes use of a meta-learning approach for adaptive model predictive control, by learning a system model that leverages data from previous related tasks, while enabling fast fine-tuning to the current task during closed-loop operation. The dynamics is modeled via Gaussian process regression and, building on the Karhunen-Lo{Ã¨}ve expansion, can be approximately reformulated as a finite linear combination of kernel eigenfunctions. Using data collected over a set of tasks, the eigenfunction hyperparameters are optimized in a meta-training phase by maximizing a variational bound for the log-marginal likelihood. During meta-testing, the eigenfunctions are fixed, so that only the linear parameters are adapted to the new unseen task in an online adaptive fashion via Bayesian linear regression, providing a simple and efficient inference scheme. Simulation results are provided for autonomous racing with miniature race cars adapting to unseen road conditions.      
### 4.Cross attentive pooling for speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.05983.pdf)
>  The goal of this paper is text-independent speaker verification where utterances come from 'in the wild' videos and may contain irrelevant signal. While speaker verification is naturally a pair-wise problem, existing methods to produce the speaker embeddings are instance-wise. In this paper, we propose Cross Attentive Pooling (CAP) that utilizes the context information across the reference-query pair to generate utterance-level embeddings that contain the most discriminative information for the pair-wise matching problem. Experiments are performed on the VoxCeleb dataset in which our method outperforms comparable pooling strategies.      
### 5.Deep Learning to Quantify Pulmonary Edema in Chest Radiographs  [ :arrow_down: ](https://arxiv.org/pdf/2008.05975.pdf)
>  Background: Clinical management decisions for acutely decompensated CHF patients are often based on grades of pulmonary edema severity, rather than its mere absence or presence. The grading of pulmonary edema on chest radiographs is based on well-known radiologic findings. <br>Purpose: We develop a clinical machine learning task to grade pulmonary edema severity and release both the underlying data and code to serve as a benchmark for future algorithmic developments in machine vision. <br>Materials and Methods: We collected 369,071 chest radiographs and their associated radiology reports from 64,581 patients from the MIMIC-CXR chest radiograph dataset. We extracted pulmonary edema severity labels from the associated radiology reports as 4 ordinal levels: no edema (0), vascular congestion (1), interstitial edema (2), and alveolar edema (3). We developed machine learning models using two standard approaches: 1) a semi-supervised model using a variational autoencoder and 2) a pre-trained supervised learning model using a dense neural network. <br>Results: We measured the area under the receiver operating characteristic curve (AUROC) from the semi-supervised model and the pre-trained model. AUROC for differentiating alveolar edema from no edema was 0.99 and 0.87 (semi-supervised and pre-trained models). Performance of the algorithm was inversely related to the difficulty in categorizing milder states of pulmonary edema: 2 vs 0 (0.88, 0.81), 1 vs 0 (0.79, 0.66), 3 vs 1 (0.93, 0.82), 2 vs 1 (0.69, 0.73), 3 vs 2 (0.88, 0.63). <br>Conclusion: Accurate grading of pulmonary edema on chest radiographs is a clinically important task. Application of state-of-the-art machine learning techniques can produce a novel quantitative imaging biomarker from one of the oldest and most widely available imaging modalities.      
### 6.Multi-Agent Double Deep Q-Learning for Beamforming in mmWave MIMO Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05943.pdf)
>  Beamforming is one of the key techniques in millimeter wave (mmWave) multi-input multi-output (MIMO) communications. Designing appropriate beamforming not only improves the quality and strength of the received signal, but also can help reduce the interference, consequently enhancing the data rate. In this paper, we propose a distributed multi-agent double deep Q-learning algorithm for beamforming in mmWave MIMO networks, where multiple base stations (BSs) can automatically and dynamically adjust their beams to serve multiple highly-mobile user equipments (UEs). In the analysis, largest received power association criterion is considered for UEs, and a realistic channel model is taken into account. Simulation results demonstrate that the proposed learning-based algorithm can achieve comparable performance with respect to exhaustive search while operating at much lower complexity.      
### 7.NOMA for Multiple Access Channel in Indoor Visible Light Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.05935.pdf)
>  In this letter, we consider a scenario of indoor visible light communications (VLC) where multiple transmitters (Txs) are communicating to a single receiver and each Tx uses a single light emitting diode (LED). For the considered multiple access channel scenario, we propose a generalized scheme based on non-orthogonal multiple access (NOMA) that can be applied for any number of Txs and any desired spectral efficiency for each of the Txs. We evaluate the performance of the proposed scheme using successive interference cancellation (SIC) based decoding, joint maximum likelihood (JML) decoding, and a combination of SIC and JML decoding. The numerical results indicate superior performance of the proposed NOMA-VLC scheme as compared to the state-of-the-art orthogonal multiple access schemes for VLC.      
### 8.Automatic Quality Assessment for Audio-Visual Verification Systems. The LOVe submission to NIST SRE Challenge 2019  [ :arrow_down: ](https://arxiv.org/pdf/2008.05889.pdf)
>  Fusion of scores is a cornerstone of multimodal biometric systems composed of independent unimodal parts. In this work, we focus on quality-dependent fusion for speaker-face verification. To this end, we propose a universal model which can be trained for automatic quality assessment of both face and speaker modalities. This model estimates the quality of representations produced by unimodal systems which are then used to enhance the score-level fusion of speaker and face verification modules. We demonstrate the improvements brought by this quality-dependent fusion on the recent NIST SRE19 Audio-Visual Challenge dataset.      
### 9.Evaluation of RF Wireless Power Transfer for Low-Power Aircraft Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2008.05869.pdf)
>  Low-power sensors can be integrated into an aircraft for numerous use cases. Conventionally, these sensors are powered via cables, which introduces various disadvantages to the overall efficiency of the aircraft. Alternatively, batteries may be used. However, this implies the necessity of additional maintenance for battery replacement. Another option to remove power cables is to use Radio Frequency (RF) Wireless Power Transfer (WPT) systems. Although general RF WPT technology has been studied in the literature, its feasibility for aviation use cases is not fully investigated. In this paper, we study the feasibility of RF WPT to wirelessly power low-power in-cabin sensors. In a cabin mock-up we show that RF WPT techonology is capable of almost fully covering an area of 20 seats and quantitatively assess this using Received Signal Strength Indicators (up to $28$ mW) and packet interval rate (up to $5.5$ Hz). Furthermore, we perform multi-tone sinusoidal wave experiments for power transmission scheme in a lab environment and thereby present potential ways to improve receiver sensitivity and consequently increase the WPT coverage in the cabin without changing the average transmission power. The overall results show that certain low-power cabin use cases can be supported by already existing commercial RF WPT systems.      
### 10.Neural collaborative filtering for unsupervised mitral valve segmentation in echocardiography  [ :arrow_down: ](https://arxiv.org/pdf/2008.05867.pdf)
>  The segmentation of the mitral valve annulus and leaflets specifies a crucial first step to establish a machine learning pipeline that can support physicians in performing multiple tasks, e.g.\ diagnosis of mitral valve diseases, surgical planning, and intraoperative procedures. Current methods for mitral valve segmentation on 2D echocardiography videos require extensive interaction with annotators and perform poorly on low-quality and noisy videos. We propose an automated and unsupervised method for the mitral valve segmentation based on a low dimensional embedding of the echocardiography videos using neural network collaborative filtering. The method is evaluated in a collection of echocardiography videos of patients with a variety of mitral valve diseases, and additionally on an independent test cohort. It outperforms state-of-the-art \emph{unsupervised} and \emph{supervised} methods on low-quality videos or in the case of sparse annotation.      
### 11.Massively Parallel Amplitude-Only Fourier Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.05853.pdf)
>  Machine-intelligence has become a driving factor in modern society. However, its demand outpaces the underlying electronic technology due to limitations given by fundamental physics such as capacitive charging of wires, but also by system architecture of storing and handling data, both driving recent trends towards processor heterogeneity. Here we introduce a novel amplitude-only Fourier-optical processor paradigm capable of processing large-scale ~(1,000 x 1,000) matrices in a single time-step and 100 microsecond-short latency. Conceptually, the information-flow direction is orthogonal to the two-dimensional programmable-network, which leverages 10^6-parallel channels of display technology, and enables a prototype demonstration performing convolutions as pixel-wise multiplications in the Fourier domain reaching peta operations per second throughputs. The required real-to-Fourier domain transformations are performed passively by optical lenses at zero-static power. We exemplary realize a convolutional neural network (CNN) performing classification tasks on 2-Megapixel large matrices at 10 kHz rates, which latency-outperforms current GPU and phase-based display technology by one and two orders of magnitude, respectively. Training this optical convolutional layer on image classification tasks and utilizing it in a hybrid optical-electronic CNN, shows classification accuracy of 98% (MNIST) and 54% (CIFAR-10). Interestingly, the amplitude-only CNN is inherently robust against coherence noise in contrast to phase-based paradigms and features an over 2 orders of magnitude lower delay than liquid crystal-based systems. Beyond contributing to novel accelerator technology, scientifically this amplitude-only massively-parallel optical compute-paradigm can be far-reaching as it de-validates the assumption that phase-information outweighs amplitude in optical processors for machine-intelligence.      
### 12.Interpretable Partial Discharge Detection with Temporal Convolution and Pulse Activation Maps: An application to Power Lines  [ :arrow_down: ](https://arxiv.org/pdf/2008.05838.pdf)
>  Partial discharge (PD) is a common indication of insulation damages in power systems and cables. These damages can eventually result in costly repairs and substantial power outages. PD detection traditionally relies on hand-crafted features and domain expertise to identify very specific pulses in the electrical current, and the performance declines in the presence of noise or of superposed pulses. In this paper, we propose a novel end-to-end framework based on convolutional neural networks. The framework has two contributions. First, it does not require any feature extraction and enables robust PD detection. Second, we devise the pulse activation map. It provides interpretability of the results for the domain experts with the identification of the pulses that led to the detection of the PDs. The performance is evaluated on a public dataset for the detection of damaged power lines. An ablation study demonstrates the benefits of each part of the proposed framework.      
### 13.Multi-Modality Pathology Segmentation Framework: Application to Cardiac Magnetic Resonance Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.05780.pdf)
>  Multi-sequence of cardiac magnetic resonance (CMR) images can provide complementary information for myocardial pathology (scar and edema). However, it is still challenging to fuse these underlying information for pathology segmentation effectively. This work presents an automatic cascade pathology segmentation framework based on multi-modality CMR images. It mainly consists of two neural networks: an anatomical structure segmentation network (ASSN) and a pathological region segmentation network (PRSN). Specifically, the ASSN aims to segment the anatomical structure where the pathology may exist, and it can provide a spatial prior for the pathological region segmentation. In addition, we integrate a denoising auto-encoder (DAE) into the ASSN to generate segmentation results with plausible shapes. The PRSN is designed to segment pathological region based on the result of ASSN, in which a fusion block based on channel attention is proposed to better aggregate multi-modality information from multi-modality CMR images. Experiments from the MyoPS2020 challenge dataset show that our framework can achieve promising performance for myocardial scar and edema segmentation.      
### 14.Continuous Speech Separation with Conformer  [ :arrow_down: ](https://arxiv.org/pdf/2008.05773.pdf)
>  Continuous speech separation plays a vital role in complicated speech related tasks such as conversation transcription. The separation model extracts a single speaker signal from a mixed speech. In this paper, we use transformer and conformer in lieu of recurrent neural networks in the separation system, as we believe capturing global information with the self-attention based method is crucial for the speech separation. Evaluating on the LibriCSS dataset, the conformer separation model achieves state of the art results, with a relative 23.5% word error rate (WER) reduction from bi-directional LSTM (BLSTM) in the utterance-wise evaluation and a 15.4% WER reduction in the continuous evaluation.      
### 15.Revisiting Temporal Modeling for Video Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2008.05765.pdf)
>  Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has drawn much attention in both the research and industrial communities. Although many deep learning-based VSR methods have been proposed, it is hard to directly compare these methods since the different loss functions and training datasets have a significant impact on the super-resolution results. In this work, we carefully study and compare three temporal modeling methods (2D CNN with early fusion, 3D CNN with slow fusion and Recurrent Neural Network) for video super-resolution. We also propose a novel Recurrent Residual Network (RRN) for efficient video super-resolution, where residual learning is utilized to stabilize the training of RNN and meanwhile to boost the super-resolution performance. Extensive experiments show that the proposed RRN is highly computational efficiency and produces temporal consistent VSR results with finer details than other temporal modeling methods. Besides, the proposed method achieves state-of-the-art results on several widely used benchmarks.      
### 16.Chance-Constrained Model Predictive Control A reformulated approach suitable for sewer networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05757.pdf)
>  In this work, a revised formulation of Chance-Constrained (CC) Model Predictive Control (MPC) is presented. The focus of this work is on the mathematical formulation of the revised CC-MPC, and the reason behind the need for its revision. The revised formulation is given in the context of sewer systems, and their weir overflow structures. A linear sewer model of the Astlingen Benchmark sewer model is utilized to illustrate the application of the formulation, both mathematically and performance-wise through simulations. Based on the simulations, a comparison of performance is done between the revised CC-MPC and a comparable deterministic MPC, with a focus on overflow avoidance, computation time, and operational behavior. The simulations show similar performance for overflow avoidance for both types of MPC, while the computation time increases slightly for the CC-MPC, together with operational behaviors getting limited      
### 17.AdaIN-Switchable CycleGAN for Efficient Unsupervised Low-Dose CT Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2008.05753.pdf)
>  Recently, deep learning approaches have been extensively studied for low-dose CT denoising thanks to its superior performance despite the fast computational time. In particular, cycleGAN has been demonstrated as a powerful unsupervised learning scheme to improve the low-dose CT image quality without requiring matched high-dose reference data. Unfortunately, one of the main limitations of the cycleGAN approach is that it requires two deep neural network generators at the training phase, although only one of them is used at the inference phase. The secondary auxiliary generator is needed to enforce the cycle-consistency, but the additional memory requirement and increases of the learnable parameters are the main huddles for cycleGAN training. To address this issue, here we propose a novel cycleGAN architecture using a single switchable generator. In particular, a single generator is implemented using adaptive instance normalization (AdaIN) layers so that the baseline generator converting a low-dose CT image to a routine-dose CT image can be switched to a generator converting high-dose to low-dose by simply changing the AdaIN code. Thanks to the shared baseline network, the additional memory requirement and weight increases are minimized, and the training can be done more stably even with small training data. Experimental results show that the proposed method outperforms the previous cycleGAN approaches while using only about half the parameters.      
### 18.Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.05750.pdf)
>  Transformer has achieved competitive performance against state-of-the-art end-to-end models in automatic speech recognition (ASR), and requires significantly less training time than RNN-based models. The original Transformer, with encoder-decoder architecture, is only suitable for offline ASR. It relies on an attention mechanism to learn alignments, and encodes input audio bidirectionally. The high computation cost of Transformer decoding also limits its use in production streaming systems. To make Transformer suitable for streaming ASR, we explore Transducer framework as a streamable way to learn alignments. For audio encoding, we apply unidirectional Transformer with interleaved convolution layers. The interleaved convolution layers are used for modeling future context which is important to performance. To reduce computation cost, we gradually downsample acoustic input, also with the interleaved convolution layers. Moreover, we limit the length of history context in self-attention to maintain constant computation cost for each decoding step. We show that this architecture, named Conv-Transformer Transducer, achieves competitive performance on LibriSpeech dataset (3.6\% WER on test-clean) without external language models. The performance is comparable to previously published streamable Transformer Transducer and strong hybrid streaming ASR systems, and is achieved with smaller look-ahead window (140~ms), fewer parameters and lower frame rate.      
### 19.Dynamic Active Average Consensus and its Application in Containment Control  [ :arrow_down: ](https://arxiv.org/pdf/2008.05722.pdf)
>  This paper proposes a continuous-time dynamic active weighted average consensus algorithm in which the agents can alternate between active and passive modes depending on their ability to access to their reference input. The objective is to enable all the agents, both active and passive, to track the weighted average of the reference inputs of the active agents. The algorithm is modeled as a switched linear system whose convergence properties are carefully studied considering the agents' piece-wise constant access to the reference signals and possible piece-wise constant weights of the agents. We also study the discrete-time implementation of this algorithm. Next, we show how a containment control problem, in which a group of followers should track the convex hull of a set of observed leaders, can be cast as an active average consensus problem, and solved efficiently by our proposed dynamic active average consensus algorithm. Numerical examples demonstrate our results.      
### 20.A Fault-Tolerant Integrated Vehicle Stability Control Using Adaptive Control Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2008.05697.pdf)
>  The focus of this paper is an integrated, fault-tolerant vehicle supervisory control algorithm for the overall stability of ground vehicles. Vehicle control systems contain many sensors and actuators that can communicate with each other over communication networks. The proposed supervisory control scheme is composed of a high-level controller that creates a virtual control input vector and a low-level control allocator that distributes the virtual control effort among redundant actuators. Virtual control input incorporates the required traction force, yaw, pitch, and roll moment corrections, and the lateral force correction to ensure stability while following a maneuvering reference initiated by the driver. Based on the virtual control input vector, the allocation module determines front steering angle correction, rear steering angle, traction forces at each tire, and active suspension forces. The proposed control framework distinguishes itself from earlier results in the literature by its ability to adapt to failures and uncertainties by updating its parameters online, without the need for fault identification. The control structure is validated in the simulation environment using a fourteen degree of freedom nonlinear vehicle model. Our results demonstrate that the proposed approach ensures that the vehicle follows references created by the driver despite the loss of actuator effectiveness up to 30% higher longitudinal maneuver velocity and approximately 35% lower roll and pitch angles during steering with representative driving scenarios.      
### 21.Evolutionary Algorithm Enhanced Neural Architecture Search for Text-Independent Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.05695.pdf)
>  State-of-the-art speaker verification models are based on deep learning techniques, which heavily depend on the handdesigned neural architectures from experts or engineers. We borrow the idea of neural architecture search(NAS) for the textindependent speaker verification task. As NAS can learn deep network structures automatically, we introduce the NAS conception into the well-known x-vector network. Furthermore, this paper proposes an evolutionary algorithm enhanced neural architecture search method called Auto-Vector to automatically discover promising networks for the speaker verification task. The experimental results demonstrate our NAS-based model outperforms state-of-the-art speaker verification models.      
### 22.Large-scale Transfer Learning for Low-resource Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2008.05671.pdf)
>  End-to-end Spoken Language Understanding (SLU) models are made increasingly large and complex to achieve the state-ofthe-art accuracy. However, the increased complexity of a model can also introduce high risk of over-fitting, which is a major challenge in SLU tasks due to the limitation of available data. In this paper, we propose an attention-based SLU model together with three encoder enhancement strategies to overcome data sparsity challenge. The first strategy focuses on the transferlearning approach to improve feature extraction capability of the encoder. It is implemented by pre-training the encoder component with a quantity of Automatic Speech Recognition annotated data relying on the standard Transformer architecture and then fine-tuning the SLU model with a small amount of target labelled data. The second strategy adopts multitask learning strategy, the SLU model integrates the speech recognition model by sharing the same underlying encoder, such that improving robustness and generalization ability. The third strategy, learning from Component Fusion (CF) idea, involves a Bidirectional Encoder Representation from Transformer (BERT) model and aims to boost the capability of the decoder with an auxiliary network. It hence reduces the risk of over-fitting and augments the ability of the underlying encoder, indirectly. Experiments on the FluentAI dataset show that cross-language transfer learning and multi-task strategies have been improved by up to 4:52% and 3:89% respectively, compared to the baseline.      
### 23.Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit  [ :arrow_down: ](https://arxiv.org/pdf/2008.05656.pdf)
>  Recent neural speech synthesis systems have gradually focused on the control of prosody to improve the quality of synthesized speech, but they rarely consider the variability of prosody and the correlation between prosody and semantics together. In this paper, a prosody learning mechanism is proposed to model the prosody of speech based on TTS system, where the prosody information of speech is extracted from the melspectrum by a prosody learner and combined with the phoneme sequence to reconstruct the mel-spectrum. Meanwhile, the sematic features of text from the pre-trained language model is introduced to improve the prosody prediction results. In addition, a novel self-attention structure, named as local attention, is proposed to lift this restriction of input text length, where the relative position information of the sequence is modeled by the relative position matrices so that the position encodings is no longer needed. Experiments on English and Mandarin show that speech with more satisfactory prosody has obtained in our model. Especially in Mandarin synthesis, our proposed model outperforms baseline model with a MOS gap of 0.08, and the overall naturalness of the synthesized speech has been significantly improved.      
### 24.MLNET: An Adaptive Multiple Receptive-field Attention Neural Network for Voice Activity Detection  [ :arrow_down: ](https://arxiv.org/pdf/2008.05650.pdf)
>  Voice activity detection (VAD) makes a distinction between speech and non-speech and its performance is of crucial importance for speech based services. Recently, deep neural network (DNN)-based VADs have achieved better performance than conventional signal processing methods. The existed DNNbased models always handcrafted a fixed window to make use of the contextual speech information to improve the performance of VAD. However, the fixed window of contextual speech information can't handle various unpredicatable noise environments and highlight the critical speech information to VAD task. In order to solve this problem, this paper proposed an adaptive multiple receptive-field attention neural network, called MLNET, to finish VAD task. The MLNET leveraged multi-branches to extract multiple contextual speech information and investigated an effective attention block to weight the most crucial parts of the context for final classification. Experiments in real-world scenarios demonstrated that the proposed MLNET-based model outperformed other baselines.      
### 25.Towards Modality Transferable Visual Information Representation with Optimal Model Compression  [ :arrow_down: ](https://arxiv.org/pdf/2008.05642.pdf)
>  Compactly representing the visual signals is of fundamental importance in various image/video-centered applications. Although numerous approaches were developed for improving the image and video coding performance by removing the redundancies within visual signals, much less work has been dedicated to the transformation of the visual signals to another well-established modality for better representation capability. In this paper, we propose a new scheme for visual signal representation that leverages the philosophy of transferable modality. In particular, the deep learning model, which characterizes and absorbs the statistics of the input scene with online training, could be efficiently represented in the sense of rate-utility optimization to serve as the enhancement layer in the bitstream. As such, the overall performance can be further guaranteed by optimizing the new modality incorporated. The proposed framework is implemented on the state-of-the-art video coding standard (i.e., versatile video coding), and significantly better representation capability has been observed based on extensive evaluations.      
### 26.Impact of Disturbances on Mixed Traffic Control with Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2008.05583.pdf)
>  This paper investigates the impact of disturbances on controlling an autonomous vehicle to smooth mixed traffic flow in a ring road setup. By exploiting the ring structure of this system, it is shown that velocity perturbations impacting any vehicle on the ring enter an uncontrollable and marginally stable mode defined by the sum of relative vehicle spacings. These disturbances are then integrated up by the system and cannot be unwound via controlling the autonomous vehicle. In particular, if the velocity disturbances are zero-mean Gaussians, then the traffic flow on the ring will undergo a random walk with the variance growing indefinitely and independently of the control policy applied. In contrast, the impact of acceleration disturbances is benign as these disturbances do no enter the uncontrollable mode, meaning that they can be easily regulated using the autonomous vehicle. Our results support and complement the existing theoretic analysis and field experiments.      
### 27.Online Automatic Speech Recognition with Listen, Attend and Spell Model  [ :arrow_down: ](https://arxiv.org/pdf/2008.05514.pdf)
>  The Listen, Attend and Spell (LAS) model and other attention-based automatic speech recognition (ASR) models have known limitations when operated in a fully online mode. In this paper, we analyze the online operation of LAS models to demonstrate that these limitations stem from the handling of silence regions and the reliability of online attention mechanism at the edge of input buffers. We propose a novel and simple technique that can achieve fully online recognition while meeting accuracy and latency targets. For the Mandarin dictation task, our proposed approach can achieve a character error rate in online operation that is within 4% relative to an offline LAS model. The proposed online LAS model operates at 12% lower latency relative to a conventional neural network hidden Markov model hybrid of comparable accuracy. We have validated the proposed method through a production scale deployment, which, to the best of our knowledge, is the first such deployment of a fully online LAS model.      
### 28.SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition with Distractors  [ :arrow_down: ](https://arxiv.org/pdf/2008.05955.pdf)
>  We present a new, publicly-available image dataset generated by the NVIDIA Deep Learning Data Synthesizer intended for use in object detection, pose estimation, and tracking applications. This dataset contains 144k stereo image pairs that synthetically combine 18 camera viewpoints of three photorealistic virtual environments with up to 10 objects (chosen randomly from the 21 object models of the YCB dataset [1]) and flying distractors. Object and camera pose, scene lighting, and quantity of objects and distractors were randomized. Each provided view includes RGB, depth, segmentation, and surface normal images, all pixel level. We describe our approach for domain randomization and provide insight into the decisions that produced the dataset.      
### 29.Learning Stability Certificates from Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.05952.pdf)
>  Many existing tools in nonlinear control theory for establishing stability or safety of a dynamical system can be distilled to the construction of a certificate function that guarantees a desired property. However, algorithms for synthesizing certificate functions typically require a closed-form analytical expression of the underlying dynamics, which rules out their use on many modern robotic platforms. To circumvent this issue, we develop algorithms for learning certificate functions only from trajectory data. We establish bounds on the generalization error - the probability that a certificate will not certify a new, unseen trajectory - when learning from trajectories, and we convert such generalization error bounds into global stability guarantees. We demonstrate empirically that certificates for complex dynamics can be efficiently learned, and that the learned certificates can be used for downstream tasks such as adaptive control.      
### 30.Secure Transmission in MIMO-NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05923.pdf)
>  This letter focuses on the physical layer security over two-user multiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA) networks. A linear precoding technique is designed to ensure the confidentiality of the message of each user from its counterpart. This technique first splits the base station power between the two users and, based on that, decomposes the secure MIMO-NOMA channel into two MIMO wiretap channels, and designs the transmit covariance matrix for each channel separately. The proposed method substantially enlarges the secrecy rate compared to existing linear precoding methods and strikes a balance between performance and computation cost. Simulation results verify the effectiveness of the proposed method.      
### 31.So You Need Datasets for Your COVID-19 Detection Research Using Machine Learning?  [ :arrow_down: ](https://arxiv.org/pdf/2008.05906.pdf)
>  Millions of people are infected by the coronavirus disease 2019 (COVID19) around the world. Machine Learning (ML) techniques are being used for COVID19 detection research from the beginning of the epidemic. This article represents the detailed information on frequently used datasets in COVID19 detection using Machine Learning (ML). We investigated 96 papers on COVID19 detection between January 2020 and June 2020. We extracted the information about used datasets from the articles and represented them here simultaneously. This investigation will help future researchers to find the COVID19 datasets without difficulty.      
### 32.LGNN: a Context-aware Line Segment Detector  [ :arrow_down: ](https://arxiv.org/pdf/2008.05892.pdf)
>  We present a novel real-time line segment detection scheme called Line Graph Neural Network (LGNN). Existing approaches require a computationally expensive verification or postprocessing step. Our LGNN employs a deep convolutional neural network (DCNN) for proposing line segment directly, with a graph neural network (GNN) module for reasoning their connectivities. Specifically, LGNN exploits a new quadruplet representation for each line segment where the GNN module takes the predicted candidates as vertexes and constructs a sparse graph to enforce structural context. Compared with the state-of-the-art, LGNN achieves near real-time performance without compromising accuracy. LGNN further enables time-sensitive 3D applications. When a 3D point cloud is accessible, we present a multi-modal line segment classification technique for extracting a 3D wireframe of the environment robustly and efficiently.      
### 33.Balancing Taxi Distribution in City-Scale Dynamic Ridesharing Service: A Hybrid Solution Based on Demand Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.05890.pdf)
>  In this paper, we study the challenging problem of how to balance taxi distribution across a city in a dynamic ridesharing service. First, we introduce the architecture of the dynamic ridesharing system and formally define the performance metrics indicating the efficiency of the system. Then, we propose a hybrid solution involving a series of algorithms: the Correlated Pooling collects correlated rider requests, the Adjacency Ride-Matching based on Demand Learning assigns taxis to riders and balances taxi distribution locally, the Greedy Idle Movement aims to direct taxis without a current assignment to the areas with riders in need of service. In the experiment, we apply city-scale data sets from the city of Chicago and complete a case study analyzing the threshold of correlated rider requests. We also compare our hybrid solution with multiple other methods. The results of our experiment show that our hybrid solution improves customer serving rate without increasing the number of taxis in operation, allows both drivers to earn more and riders to save more per trip, and all with a minimum increase in calling and extra trip time.      
### 34.A comprehensive dynamic growth and development model of Hermetia illucens larvae  [ :arrow_down: ](https://arxiv.org/pdf/2008.05888.pdf)
>  Larvae of Hermetia illucens, also commonly known as black soldier fly (BSF) have gained significant importance in the feed industry, primarily used as feed for aquaculture and other livestock farming. Mathematical model such as Von Bertalanffy growth model and dynamic energy budget models are available for modelling the growth of various organisms but have their demerits for their application to the growth and development of BSF. Also, such dynamic models were not yet applied to the growth of the BSF larvae despite models proven to be useful for automation of industrial production process (e.g. feeding, heating/cooling, ventilation, harvesting, etc.). This work primarily focuses on developing a model based on the principles of the afore mentioned models from literature that can provide accurate mathematical description of the dry mass changes throughout the life cycle and the transition of development phases of the larvae. To further improve the accuracy of these models, various factors affecting the growth and development such as temperature, feed quality, feeding rate, moisture content in feed, and airflow rate are developed and integrated into the dynamic growth model. An extensive set of data were aggregated from various literature and used for the model development, parameter estimation and validation. Models describing the environmental factors were individually validated based on the data sets collected. In addition, the dynamic growth model was also validated for dry mass evolution and development stage transition of larvae reared on different substrate feeding rates. The developed models with the estimated parameters performed well highlighting its application in decision-support systems and automation for large scale production.      
### 35.MIMO-Aided Nonlinear Hybrid Transceiver Design for Multiuser mmWave Systems Relying on Tomlinson-Harashima Precoding  [ :arrow_down: ](https://arxiv.org/pdf/2008.05860.pdf)
>  Hybrid analog-digital (A/D) transceivers designed for millimeter wave (mmWave) systems have received substantial research attention, as a benefit of their lower cost and modest energy consumption compared to their fully-digital counterparts. We further improve their performance by conceiving a Tomlinson-Harashima precoding (THP) based nonlinear joint design for the downlink of multiuser multiple-input multiple-output (MIMO) mmWave systems. Our optimization criterion is that of minimizing the mean square error (MSE) of the system under channel uncertainties subject both to realistic transmit power constraint and to the unit modulus constraint imposed on the elements of the analog beamforming (BF) matrices governing the BF operation in the radio frequency domain. We transform this optimization problem into a more tractable form and develop an efficient block coordinate descent (BCD) based algorithm for solving it. Then, a novel two-timescale nonlinear joint hybrid transceiver design algorithm is developed, which can be viewed as an extension of the BCD-based joint design algorithm for reducing both the channel state information (CSI) signalling overhead and the effects of outdated CSI. Moreover, we determine the near-optimal cancellation order for the THP structure based on the lower bound of the MSE. The proposed algorithms can be guaranteed to converge to a Karush-Kuhn-Tucker (KKT) solution of the original problem. The simulation results demonstrate that our proposed nonlinear joint hybrid transceiver design algorithms significantly outperform the existing linear hybrid transceiver algorithms and approach the performance of the fully-digital transceiver, despite its lower cost and power dissipation.      
### 36.Localizing the Common Action Among a Few Videos  [ :arrow_down: ](https://arxiv.org/pdf/2008.05826.pdf)
>  This paper strives to localize the temporal extent of an action in a long untrimmed video. Where existing work leverages many examples with their start, their ending, and/or the class of the action during training time, we propose few-shot common action localization. The start and end of an action in a long untrimmed video is determined based on just a hand-full of trimmed video examples containing the same action, without knowing their common class label. To address this task, we introduce a new 3D convolutional network architecture able to align representations from the support videos with the relevant query video segments. The network contains: (\textit{i}) a mutual enhancement module to simultaneously complement the representation of the few trimmed support videos and the untrimmed query video; (\textit{ii}) a progressive alignment module that iteratively fuses the support videos into the query branch; and (\textit{iii}) a pairwise matching module to weigh the importance of different support videos. Evaluation of few-shot common action localization in untrimmed videos containing a single or multiple action instances demonstrates the effectiveness and general applicability of our proposal.      
### 37.Enhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2008.05809.pdf)
>  The increased adoption of digital assistants makes text-to-speech (TTS) synthesis systems an indispensable feature of modern mobile devices. It is hence desirable to build a system capable of generating highly intelligible speech in the presence of noise. Past studies have investigated style conversion in TTS synthesis, yet degraded synthesized quality often leads to worse intelligibility. To overcome such limitations, we proposed a novel transfer learning approach using Tacotron and WaveRNN based TTS synthesis. The proposed speech system exploits two modification strategies: (a) Lombard speaking style data and (b) Spectral Shaping and Dynamic Range Compression (SSDRC) which has been shown to provide high intelligibility gains by redistributing the signal energy on the time-frequency domain. We refer to this extension as Lombard-SSDRC TTS system. Intelligibility enhancement as quantified by the Intelligibility in Bits (SIIB-Gauss) measure shows that the proposed Lombard-SSDRC TTS system shows significant relative improvement between 110% and 130% in speech-shaped noise (SSN), and 47% to 140% in competing-speaker noise (CSN) against the state-of-the-art TTS approach. Additional subjective evaluation shows that Lombard-SSDRC TTS successfully increases the speech intelligibility with relative improvement of 455% for SSN and 104% for CSN in median keyword correction rate compared to the baseline TTS method.      
### 38.CycleMorph: Cycle Consistent Unsupervised Deformable Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2008.05772.pdf)
>  Image registration is a fundamental task in medical image analysis. Recently, deep learning based image registration methods have been extensively investigated due to their excellent performance despite the ultra-fast computational time. However, the existing deep learning methods still have limitation in the preservation of original topology during the deformation with registration vector fields. To address this issues, here we present a cycle-consistent deformable image registration. The cycle consistency enhances image registration performance by providing an implicit regularization to preserve topology during the deformation. The proposed method is so flexible that can be applied for both 2D and 3D registration problems for various applications, and can be easily extended to multi-scale implementation to deal with the memory issues in large volume registration. Experimental results on various datasets from medical and non-medical applications demonstrate that the proposed method provides effective and accurate registration on diverse image pairs within a few seconds. Qualitative and quantitative evaluations on deformation fields also verify the effectiveness of the cycle consistency of the proposed method.      
### 39.Powers of layers for image-to-image translation  [ :arrow_down: ](https://arxiv.org/pdf/2008.05763.pdf)
>  We propose a simple architecture to address unpaired image-to-image translation tasks: style or class transfer, denoising, deblurring, deblocking, etc. We start from an image autoencoder architecture with fixed weights. For each task we learn a residual block operating in the latent space, which is iteratively called until the target domain is reached. A specific training schedule is required to alleviate the exponentiation effect of the iterations. At test time, it offers several advantages: the number of weight parameters is limited and the compositional design allows one to modulate the strength of the transformation with the number of iterations. This is useful, for instance, when the type or amount of noise to suppress is not known in advance. Experimentally, we provide proofs of concepts showing the interest of our method for many transformations. The performance of our model is comparable or better than CycleGAN with significantly fewer parameters.      
### 40.Conservative Stochastic Optimization with Expectation Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2008.05758.pdf)
>  This paper considers stochastic convex optimization problems where the objective and constraint functions involve expectations with respect to the data indices or environmental variables, in addition to deterministic convex constraints on the domain of the variables. Although the setting is generic and arises in different machine learning applications, online and efficient approaches for solving such problems have not been widely studied. Since the underlying data distribution is unknown a priori, a closed-form solution is generally not available, and classical deterministic optimization paradigms are not applicable. State-of-the-art approaches, such as those using the saddle point framework, can ensure that the optimality gap as well as the constraint violation decay as $Ã\left(T^{-\frac{1}{2}}\right)$ where $T$ is the number of stochastic gradients. The domain constraints are assumed simple and handled via projection at every iteration. In this work, we propose a novel conservative stochastic optimization algorithm (CSOA) that achieves zero constraint violation and $Ã\left(T^{-\frac{1}{2}}\right)$ optimality gap. <br>Further, the projection operation (for scenarios when calculating projection is expensive) in the proposed algorithm can be avoided by considering the conditional gradient or Frank-Wolfe (FW) variant of the algorithm. The state-of-the-art stochastic FW variants achieve an optimality gap of $Ã\left(T^{-\frac{1}{3}}\right)$ after $T$ iterations, though these algorithms have not been applied to problems with functional expectation constraints. In this work, we propose the FW-CSOA algorithm that is not only projection-free but also achieves zero constraint violation with $Ã\left(T^{-\frac{1}{4}}\right)$ decay of the optimality gap. The efficacy of the proposed algorithms is tested on two relevant problems: fair classification and structured matrix completion.      
### 41.A Vision-Based Control Method for Autonomous Landing of Vertical Flight Aircraft On a Moving Platform Without Using GPS  [ :arrow_down: ](https://arxiv.org/pdf/2008.05699.pdf)
>  The paper discusses a novel vision-based estimation and control approach to enable fully autonomous tracking and landing of vertical take-off and landing (VTOL) capable unmanned aerial vehicles (UAVs) on moving platforms without relying on a GPS signal. A unique feature of the present method is that it accomplishes this task without tracking the landing pad itself; however, by utilizing a standardized visual cue installed normal to the landing pad and parallel to the pilot's/vehicle's line of sight. A computer vision system using a single monocular camera is developed to detect the visual cue and then accurately estimate the heading of the UAV and its relative distances in all three directions to the landing pad. Through comparison with a Vicon-based motion capture system, the capability of the present vision system to measure distances in real-time within an accuracy of less than a centimeter and heading within a degree with the right visual cue, is demonstrated. A gain-scheduled proportional integral derivative (PID) control system is integrated with the vision system and then implemented on a quad-rotor-UAV dynamic model in a realistic simulation program called Gazebo. Extensive simulations are conducted to demonstrate the ability of the controller to achieve robust tracking and landing on platforms moving in arbitrary trajectories. Repeated flight tests, using both stationary and moving platforms are successfully conducted with less than 5 centimeters of landing error.      
### 42.A few brief notes on the equivalence of two expressions for statistical significance in point source detections  [ :arrow_down: ](https://arxiv.org/pdf/2008.05574.pdf)
>  The problem of point source detection in Poisson-limited count maps has been addressed by two recent papers [M. Lampton, ApJ 436, 784 (1994); D. E. Alexandreas, et al., Nucl. Instr. Meth. Phys. Res. A 328, 570 (1993)]. Both papers consider the problem of determining whether there are significantly more counts in a source region than would be expected given the number of counts observed in a background region. The arguments in the two papers are quite different (one takes a Bayesian point of view and the other does not), and the suggested formulas for computing p-values appear to be different as well. It is shown here that the expressions provided by the authors of these two articles are in fact equivalent.      
### 43.Self-Path: Self-supervision for Classification of Pathology Images with Limited Annotations  [ :arrow_down: ](https://arxiv.org/pdf/2008.05571.pdf)
>  While high-resolution pathology images lend themselves well to `data hungry' deep learning algorithms, obtaining exhaustive annotations on these images is a major challenge. In this paper, we propose a self-supervised CNN approach to leverage unlabeled data for learning generalizable and domain invariant representations in pathology images. The proposed approach, which we term as Self-Path, is a multi-task learning approach where the main task is tissue classification and pretext tasks are a variety of self-supervised tasks with labels inherent to the input data. We introduce novel domain specific self-supervision tasks that leverage contextual, multi-resolution and semantic features in pathology images for semi-supervised learning and domain adaptation. We investigate the effectiveness of Self-Path on 3 different pathology datasets. Our results show that Self-Path with the domain-specific pretext tasks achieves state-of-the-art performance for semi-supervised learning when small amounts of labeled data are available. Further, we show that Self-Path improves domain adaptation for classification of histology image patches when there is no labeled data available for the target domain. This approach can potentially be employed for other applications in computational pathology, where annotation budget is often limited or large amount of unlabeled image data is available.      
### 44.An Efficient Confidence Measure-Based Evaluation Metric for Breast Cancer Screening Using Bayesian Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.05566.pdf)
>  Screening mammograms is the gold standard for detecting breast cancer early. While a good amount of work has been performed on mammography image classification, especially with deep neural networks, there has not been much exploration into the confidence or uncertainty measurement of the classification. In this paper, we propose a confidence measure-based evaluation metric for breast cancer screening. We propose a modular network architecture, where a traditional neural network is used as a feature extractor with transfer learning, followed by a simple Bayesian neural network. Utilizing a two-stage approach helps reducing the computational complexity, making the proposed framework attractive for wider deployment. We show that by providing the medical practitioners with a tool to tune two hyperparameters of the Bayesian neural network, namely, fraction of sampled number of networks and minimum probability, the framework can be adapted as needed by the domain expert. Finally, we argue that instead of just a single number such as accuracy, a tuple (accuracy, coverage, sampled number of networks, and minimum probability) can be utilized as an evaluation metric of our framework. We provide experimental results on the CBIS-DDSM dataset, where we show the trends in accuracy-coverage tradeoff while tuning the two hyperparameters. We also show that our confidence tuning results in increased accuracy with a reduced set of images with high confidence when compared to the baseline transfer learning. To make the proposed framework readily deployable, we provide (anonymized) source code with reproducible results at <a class="link-external link-https" href="https://git.io/JvRqE" rel="external noopener nofollow">this https URL</a>.      
### 45.Model-Based Offline Planning  [ :arrow_down: ](https://arxiv.org/pdf/2008.05556.pdf)
>  Offline learning is a key part of making reinforcement learning (RL) useable in real systems. Offline RL looks at scenarios where there is data from a system's operation, but no direct access to the system when learning a policy. Recent work on training RL policies from offline data has shown results both with model-free policies learned directly from the data, or with planning on top of learnt models of the data. Model-free policies tend to be more performant, but are more opaque, harder to command externally, and less easy to integrate into larger systems. We propose an offline learner that generates a model that can be used to control the system directly through planning. This allows us to have easily controllable policies directly from data, without ever interacting with the system. We show the performance of our algorithm, Model-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and demonstrate its ability leverage planning to respect environmental constraints. We are able to find near-optimal polices for certain simulated systems from as little as 50 seconds of real-time system interaction, and create zero-shot goal-conditioned policies on a series of environments.      

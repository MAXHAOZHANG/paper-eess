# ArXiv eess --Fri, 7 Aug 2020
### 1.On Passivity, Feedback Passivity, And Feedback Passivity Over Erasure Network: A Piecewise Affine Approximation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.02748.pdf)
>  In this paper, we deal with the problem of passivity and feedback passification of smooth discrete-time nonlinear systems by considering their piecewise affine approximations. Sufficient conditions are derived for passivity and feedback passivity. These results are then extended to systems that operate over Gilbert-Elliott type communication channels. As a special case, results for feedback passivity of piecewise affine systems over a lossy channel are also derived.      
### 2.A Sensitivity Analysis Approach for Evaluating a Radar Simulation for Virtual Testing of Autonomous Driving Functions  [ :arrow_down: ](https://arxiv.org/pdf/2008.02725.pdf)
>  Simulation-based testing is a promising approach to significantly reduce the validation effort of automated driving functions. Realistic models of environment perception sensors such as camera, radar and lidar play a key role in this testing strategy. A generally accepted method to validate these sensor models does not yet exist. Particularly radar has traditionally been one of the most difficult sensors to model. Although promising as an alternative to real test drives, virtual tests are time-consuming due to the fact that they simulate the entire radar system in detail, using computation-intensive simulation techniques to approximate the propagation of electromagnetic waves. In this paper, we introduce a sensitivity analysis approach for developing and evaluating a radar simulation, with the objective to identify the parameters with the greatest impact regarding the system under test. A modular radar system simulation is presented and parameterized to conduct a sensitivity analysis in order to evaluate a spatial clustering algorithm as the system under test, while comparing the output from the radar model to real driving measurements to ensure a realistic model behavior. The presented approach is evaluated and it is demonstrated that with this approach results from different situations can be traced back to the contribution of the individual sub-modules of the radar simulation.      
### 3.Adaptive Coordination Offsets for Signalized Arterial Intersections using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.02691.pdf)
>  One of the most critical components of an urban transportation system is the coordination of intersections in arterial networks. With the advent of data-driven approaches for traffic control systems, deep reinforcement learning (RL) has gained significant traction in traffic control research. Proposed deep RL solutions to traffic control are designed to directly modify either phase order or timings; such approaches can lead to unfair situations -- bypassing low volume links for several cycles -- in the name of optimizing traffic flow. To address the issues and feasibility of the present approach, we propose a deep RL framework that dynamically adjusts the offsets based on traffic states and preserves the planned phase timings and order derived from model-based methods. This framework allows us to improve arterial coordination while preserving the notion of fairness for competing streams of traffic in an intersection. Using a validated and calibrated traffic model, we trained the policy of a deep RL agent that aims to reduce travel delays in the network. We evaluated the resulting policy by comparing its performance against the phase offsets obtained by a state-of-the-practice baseline, SYNCHRO. The resulting policy dynamically readjusts phase offsets in response to changes in traffic demand. Simulation results show that the proposed deep RL agent outperformed SYNCHRO on average, effectively reducing delay time by 13.21% in the AM Scenario, 2.42% in the noon scenario, and 6.2% in the PM scenario. Finally, we also show the robustness of our agent to extreme traffic conditions, such as demand surges and localized traffic incidents.      
### 4.Aalto's End-to-End DNN systems for the INTERSPEECH 2020 Computational Paralinguistics Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2008.02689.pdf)
>  End-to-end neural network models (E2E) have shown significant performance benefits on different INTERSPEECH ComParE tasks. Prior work has applied either a single instance of an E2E model for a task or the same E2E architecture for different tasks. However, applying a single model is unstable or using the same architecture under-utilizes task-specific information. On ComParE 2020 tasks, we investigate applying an ensemble of E2E models for robust performance and developing task-specific modifications for each task. ComParE 2020 introduces three sub-challenges: the breathing sub-challenge to predict the output of a respiratory belt worn by a patient while speaking, the elderly sub-challenge to estimate the elderly speaker's arousal and valence levels and the mask sub-challenge to classify if the speaker is wearing a mask or not. On each of these tasks, an ensemble outperforms the single E2E model. On the breathing sub-challenge, we study the impact of multi-loss strategies on task performance. On the elderly sub-challenge, predicting the valence and arousal levels prompts us to investigate multi-task training and implement data sampling strategies to handle class imbalance. On the mask sub-challenge, using an E2E system without feature engineering is competitive to feature-engineered baselines and provides substantial gains when combined with feature-engineered baselines.      
### 5.Attentive Fusion Enhanced Audio-Visual Encoding for Transformer Based Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.02686.pdf)
>  Audio-visual information fusion enables a performance improvement in speech recognition performed in complex acoustic scenarios, e.g., noisy environments. It is required to explore an effective audio-visual fusion strategy for audiovisual alignment and modality reliability. Different from the previous end-to-end approaches where the audio-visual fusion is performed after encoding each modality, in this paper we propose to integrate an attentive fusion block into the encoding process. It is shown that the proposed audio-visual fusion method in the encoder module can enrich audio-visual representations, as the relevance between the two modalities is leveraged. In line with the transformer-based architecture, we implement the embedded fusion block using a multi-head attention based audiovisual fusion with one-way or two-way interactions. The proposed method can sufficiently combine the two streams and weaken the over-reliance on the audio modality. Experiments on the LRS3-TED dataset demonstrate that the proposed method can increase the recognition rate by 0.55%, 4.51% and 4.61% on average under the clean, seen and unseen noise conditions, respectively, compared to the state-of-the-art approach.      
### 6.FISTA-Net: Learning A Fast Iterative Shrinkage Thresholding Network for Inverse Problems in Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.02683.pdf)
>  In this paper, we propose a model-based deep learning network, named FISTA-Net, by combining the interpretability and generality merits of model-based Fast Iterative Shrinkage/Thresholding Algorithm (FISTA) and strong regularization and tunning-free merits of data-driven neural network. The architecture of FISTA-Net consists of multiple gradient descent, proximal mapping, and two-step update blocks in cascade, which is designed by casting the FISTA into a deep network. A key part of FISTA-Net is to develop a proximal operator network for nonlinear thresholding that can be effectively learned through end-to-end training. All parameters of FISTA-Net including gradient step size, thresholding value and two-step update weight are tunning-free and learned from training data rather than being hand-crafted. We further impose positive and monotonous constraints on the model-based parameters to ensure they converge properly. We demonstrate, through visual results and numerical metrics, that the learned FISTA can optimize different parameters for different imaging tasks, i.e. Electromagnetic Tomography (EMT) and X-ray Computational Tomography (X-ray CT). For both EMT and sparse-view CT, superior results are achieved over state-of-the-art model-based and deep learning methods.      
### 7.Learning Power Control from a Fixed Batch of Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.02669.pdf)
>  We address how to exploit power control data, gathered from a monitored environment, for performing power control in an unexplored environment. We adopt offline deep reinforcement learning, whereby the agent learns the policy to produce the transmission powers solely by using the data. Experiments demonstrate that despite discrepancies between the monitored and unexplored environments, the agent successfully learns the power control very quickly, even if the objective functions in the monitored and unexplored environments are dissimilar. About one third of the collected data is sufficient to be of high-quality and the rest can be from any sub-optimal algorithm.      
### 8.Improving on-device speaker verification using federated learning with privacy  [ :arrow_down: ](https://arxiv.org/pdf/2008.02651.pdf)
>  Information on speaker characteristics can be useful as side information in improving speaker recognition accuracy. However, such information is often private. This paper investigates how privacy-preserving learning can improve a speaker verification system, by enabling the use of privacy-sensitive speaker data to train an auxiliary classification model that predicts vocal characteristics of speakers. In particular, this paper explores the utility achieved by approaches which combine different federated learning and differential privacy mechanisms. These approaches make it possible to train a central model while protecting user privacy, with users' data remaining on their devices. Furthermore, they make learning on a large population of speakers possible, ensuring good coverage of speaker characteristics when training a model. The auxiliary model described here uses features extracted from phrases which trigger a speaker verification system. From these features, the model predicts speaker characteristic labels considered useful as side information. The knowledge of the auxiliary model is distilled into a speaker verification system using multi-task learning, with the side information labels predicted by this auxiliary model being the additional task. This approach results in a 6% relative improvement in equal error rate over a baseline system.      
### 9.Theory Manual for the Tuned Mass Damper Module in FAST v8  [ :arrow_down: ](https://arxiv.org/pdf/2008.02650.pdf)
>  This manual describes the theory underlying new functionality in FAST 8 that simulates the addition of tuned mass dampers in the nacelle for structural control.      
### 10.Deep-Learning Based Adaptive Ultrasound Imaging from Sub-Nyquist Channel Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.02628.pdf)
>  Traditional beamforming of medical ultrasound images requires sampling rates significantly higher than the actual Nyquist rate of the received signals. This results in large amounts of data to store and process, translating to big, expensive and power-hungry devices. In light of the capabilities demonstrated by deep learning methods over the past years across a wide range of tasks, including medical imaging, it is natural to consider their ability to recover high-quality ultrasound images from sub-sampled data. Here, we propose an approach for reconstruction from temporally and spatially sub-sampled data. We begin by considering sub-Nyquist sampled channel data, time aligned in the frequency domain and transformed back to the time domain with no additional recovery steps. This results in low resolution and corruption due to loss of frequencies and aliasing. The data is further sampled spatially to emulate acquisition from a sparse array. It is then given as input to an encoder-decoder convolutional neural network which is trained separately for each rate reduction, with targets generated from minimum-variance (MV) beamforming of the fully-sampled data. Our approach yields high-quality B-mode images, with higher resolution than previously proposed reconstruction approaches (NESTA) from compressed data as well as delay-and-sum beamforming (DAS) of the fully-sampled data. In terms of contrast, it is comparable to MV beamforming of the fully-sampled data. Moreover, prediction times are 10 times faster than NESTA's, thus enabling better, faster and more efficient imaging than is mostly used in clinical practice today.      
### 11.A Low-Cost Algorithm for Adaptive Sampling and Censoring in Diffusion Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.02624.pdf)
>  Distributed signal processing has attracted widespread attention in the scientific community due to its several advantages over centralized approaches. Recently, graph signal processing has risen to prominence, and adaptive distributed solutions have also been proposed in the area. Both in the classical framework and in graph signal processing, sampling and censoring techniques have been topics of intense research, since the cost associated with measuring and/or transmitting data throughout the entire network may be prohibitive in certain applications. In this paper, we propose a low-cost adaptive mechanism for sampling and censoring over diffusion networks that uses information from more nodes when the error in the network is high and from less nodes otherwise. It presents fast convergence during transient and a significant reduction in computational cost and energy consumption in steady state. As a censoring technique, we show that it is able to noticeably outperform other solutions. We also present a theoretical analysis to give insights about its operation, and to help the choice of suitable values for its parameters.      
### 12.Deep Learning Based Defect Detection for Solder Joints on Industrial X-Ray Circuit Board Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.02604.pdf)
>  Quality control is of vital importance during electronics production. As the methods of producing electronic circuits improve, there is an increasing chance of solder defects during assembling the printed circuit board (PCB). Many technologies have been incorporated for inspecting failed soldering, such as X-ray imaging, optical imaging, and thermal imaging. With some advanced algorithms, the new technologies are expected to control the production quality based on the digital images. However, current algorithms sometimes are not accurate enough to meet the quality control. Specialists are needed to do a follow-up checking. For automated X-ray inspection, joint of interest on the X-ray image is located by region of interest (ROI) and inspected by some algorithms. Some incorrect ROIs deteriorate the inspection algorithm. The high dimension of X-ray images and the varying sizes of image dimensions also challenge the inspection algorithms. On the other hand, recent advances on deep learning shed light on image-based tasks and are competitive to human levels. In this paper, deep learning is incorporated in X-ray imaging based quality control during PCB quality inspection. Two artificial intelligence (AI) based models are proposed and compared for joint defect detection. The noised ROI problem and the varying sizes of imaging dimension problem are addressed. The efficacy of the proposed methods are verified through experimenting on a real-world 3D X-ray dataset. By incorporating the proposed methods, specialist inspection workload is largely saved.      
### 13.Data balancing for boosting performance of low-frequency classes in Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2008.02603.pdf)
>  Despite the fact that data imbalance is becoming more and more common in real-world Spoken Language Understanding (SLU) applications, it has not been studied extensively in the literature. To the best of our knowledge, this paper presents the first systematic study on handling data imbalance for SLU. In particular, we discuss the application of existing data balancing techniques for SLU and propose a multi-task SLU model for intent classification and slot filling. Aiming to avoid over-fitting, in our model methods for data balancing are leveraged indirectly via an auxiliary task which makes use of a class-balanced batch generator and (possibly) synthetic data. Our results on a real-world dataset indicate that i) our proposed model can boost performance on low frequency intents significantly while avoiding a potential performance decrease on the head intents, ii) synthetic data are beneficial for bootstrapping new intents when realistic data are not available, but iii) once a certain amount of realistic data becomes available, using synthetic data in the auxiliary task only yields better performance than adding them to the primary task training data, and iv) in a joint training scenario, balancing the intent distribution individually improves not only intent classification but also slot filling performance.      
### 14.Optical Flow and Mode Selection for Learning-based Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2008.02580.pdf)
>  This paper introduces a new method for inter-frame coding based on two complementary autoencoders: MOFNet and CodecNet. MOFNet aims at computing and conveying the Optical Flow and a pixel-wise coding Mode selection. The optical flow is used to perform a prediction of the frame to code. The coding mode selection enables competition between direct copy of the prediction or transmission through CodecNet. The proposed coding scheme is assessed under the Challenge on Learned Image Compression 2020 (CLIC20) P-frame coding conditions, where it is shown to perform on par with the state-of-the-art video codec ITU/MPEG HEVC. Moreover, the possibility of copying the prediction enables to learn the optical flow in an end-to-end fashion i.e. without relying on pre-training and/or a dedicated loss term.      
### 15.An Intelligent Non-Invasive Real Time Human Activity Recognition System for Next-Generation Healthcare  [ :arrow_down: ](https://arxiv.org/pdf/2008.02567.pdf)
>  Human motion detection is getting considerable attention in the field of Artificial Intelligence (AI) driven healthcare systems. Human motion can be used to provide remote healthcare solutions for vulnerable people by identifying particular movements such as falls, gait and breathing disorders. This can allow people to live more independent lifestyles and still have the safety of being monitored if more direct care is needed. At present wearable devices can provide real time monitoring by deploying equipment on a person's body. However, putting devices on a person's body all the time make it uncomfortable and the elderly tends to forget it to wear as well in addition to the insecurity of being tracked all the time. This paper demonstrates how human motions can be detected in quasi-real-time scenario using a non-invasive method. Patterns in the wireless signals presents particular human body motions as each movement induces a unique change in the wireless medium. These changes can be used to identify particular body motions. This work produces a dataset that contains patterns of radio wave signals obtained using software defined radios (SDRs) to establish if a subject is standing up or sitting down as a test case. The dataset was used to create a machine learning model, which was used in a developed application to provide a quasi-real-time classification of standing or sitting state. The machine learning model was able to achieve 96.70 % accuracy using the Random Forest algorithm using 10 fold cross validation. A benchmark dataset of wearable devices was compared to the proposed dataset and results showed the proposed dataset to have similar accuracy of nearly 90 %. The machine learning models developed in this paper are tested for two activities but the developed system is designed and applicable for detecting and differentiating x number of activities.      
### 16.Spectral-change enhancement with prior SNR for the hearing impaired  [ :arrow_down: ](https://arxiv.org/pdf/2008.02519.pdf)
>  A previous signal processing algorithm that aimed to enhance spectral changes (SCE) over time showed benefit for hearing-impaired (HI) listeners to recognize speech in background noise. In this work, the previous SCE was manipulated to perform on target-dominant segments, rather than treating all frames equally. Instantaneous signal-to-noise ratios (SNRs) were calculated to determine whether the segments should be processed. Initially, the ideal SNR calculated by the knowledge of premixed signals was introduced to the previous SCE algorithm (SCE-iSNR). Speech intelligibility (SI) and clarity preference were measured for 12 HI listeners in steady speech-spectrum noise (SSN) and six-talk speech (STS) maskers, respectively. The results showed the SCE-iSNR algorithm improved SI significantly for both maskers at high signal-to-masker ratios (SMRs) and for STS masker at low SMRs, while processing effect on speech quality was small. Secondly, the estimated SNR obtained from real mixtures was used, resulting in another SCE-eSNR. SI and subjective rating on naturalness and speech quality were tested for 7 HI subjects. The SCE-eSNR algorithm showed improved SI for SSN masker at high SMRs and for STS masker at low SMRs, as well as better naturalness and speech quality for STS masker. The limitations of applying the algorithms are discussed.      
### 17.FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire  [ :arrow_down: ](https://arxiv.org/pdf/2008.02516.pdf)
>  Lipreading is an impressive technique and there has been a definite improvement of accuracy in recent years. However, existing methods for lipreading mainly build on autoregressive (AR) model, which generate target tokens one by one and suffer from high inference latency. To breakthrough this constraint, we propose FastLR, a non-autoregressive (NAR) lipreading model which generates all target tokens simultaneously. NAR lipreading is a challenging task that has many difficulties: 1) the discrepancy of sequence lengths between source and target makes it difficult to estimate the length of the output sequence; 2) the conditionally independent behavior of NAR generation lacks the correlation across time which leads to a poor approximation of target distribution; 3) the feature representation ability of encoder can be weak due to lack of effective alignment mechanism; and 4) the removal of AR language model exacerbates the inherent ambiguity problem of lipreading. Thus, in this paper, we introduce three methods to reduce the gap between FastLR and AR model: 1) to address challenges 1 and 2, we leverage integrate-and-fire (I\&amp;F) module to model the correspondence between source video frames and output text sequence. 2) To tackle challenge 3, we add an auxiliary connectionist temporal classification (CTC) decoder to the top of the encoder and optimize it with extra CTC loss. We also add an auxiliary autoregressive decoder to help the feature extraction of encoder. 3) To overcome challenge 4, we propose a novel Noisy Parallel Decoding (NPD) for I\&amp;F and bring Byte-Pair Encoding (BPE) into lipreading. Our experiments exhibit that FastLR achieves the speedup up to 10.97$\times$ comparing with state-of-the-art lipreading model with slight WER absolute increase of 1.5\% and 5.5\% on GRID and LRS2 lipreading datasets respectively, which demonstrates the effectiveness of our proposed method.      
### 18.Subjective Quality Study and Database of Compressed Point Clouds with 6DoF Head-mounted Display  [ :arrow_down: ](https://arxiv.org/pdf/2008.02501.pdf)
>  In this paper, we focus on subjective and objective Point Cloud Quality Assessment (PCQA) in an immersive environment and study the effect of geometry and texture attributes in compression distortion. Using a Head-Mounted Display (HMD) with six degrees of freedom, we establish a subjective PCQA database, named SIAT Point Cloud Quality Database (SIAT-PCQD). Our database consists of 303 valid distorted point clouds compressed by the MPEG point cloud encoder with the combination of 20 sequences and 17 pairs of geometry and texture quantization parameters. The impacts of contents and geometry and texture attributes are further discussed in this paper. Then, we evaluate our subjective database with current objective PCQA methods and propose an objective weighted projection-based method to improve the consistency between observers' awareness and the importance of projected views. Our subjective database and findings can be used in perception-based point cloud processing, transmission, and coding, especially for Virtual Reality applications. The subjective dataset and quality scores will be available on the public repository.      
### 19.HooliGAN: Robust, High Quality Neural Vocoding  [ :arrow_down: ](https://arxiv.org/pdf/2008.02493.pdf)
>  Recent developments in generative models have shown that deep learning combined with traditional digital signal processing (DSP) techniques could successfully generate convincing violin samples [1], that source-excitation combined with WaveNet yields high-quality vocoders [2, 3] and that generative adversarial network (GAN) training can improve naturalness [4, 5]. By combining the ideas in these models we introduce HooliGAN, a robust vocoder that has state of the art results, finetunes very well to smaller datasets (&lt;30 minutes of speechdata) and generates audio at 2.2MHz on GPU and 35kHz on CPU. We also show a simple modification to Tacotron-basedmodels that allows seamless integration with HooliGAN. Results from our listening tests show the proposed model's ability to consistently output high-quality audio with a variety of datasets, big and small. We provide samples at the following demo page: <a class="link-external link-https" href="https://resemble-ai.github.io/hooligan_demo/" rel="external noopener nofollow">this https URL</a>      
### 20.PPSpeech: Phrase based Parallel End-to-End TTS System  [ :arrow_down: ](https://arxiv.org/pdf/2008.02490.pdf)
>  Current end-to-end autoregressive TTS systems (e.g. Tacotron 2) have outperformed traditional parallel approaches on the quality of synthesized speech. However, they introduce new problems at the same time. Due to the autoregressive nature, the time cost of inference has to be proportional to the length of text, which pose a great challenge for online serving. On the other hand, the style of synthetic speech becomes unstable and may change obviously among sentences. In this paper, we propose a Phrase based Parallel End-to-End TTS System (PPSpeech) to address these issues. PPSpeech uses autoregression approach within a phrase and executes parallel strategies for different phrases. By this method, we can achieve both high quality and high efficiency. In addition, we propose acoustic embedding and text context embedding as the conditions of encoder to keep successive and prevent from abrupt style or timbre change. Experiments show that, the synthesis speed of PPSpeech is much faster than sentence level autoregressive Tacotron 2 when a sentence has more than 5 phrases. The speed advantage increases with the growth of sentence length. Subjective experiments show that the proposed system with acoustic embedding and context embedding as conditions can make the style transition across sentences gradient and natural, defeating Global Style Token (GST) obviously in MOS.      
### 21.Shouted Speech Compensation for Speaker Verification Robust to Vocal Effort Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2008.02487.pdf)
>  The performance of speaker verification systems degrades when vocal effort conditions between enrollment and test (e.g., shouted vs. normal speech) are different. This is a potential situation in non-cooperative speaker verification tasks. In this paper, we present a study on different methods for linear compensation of embeddings making use of Gaussian mixture models to cluster shouted and normal speech domains. These compensation techniques are borrowed from the area of robustness for automatic speech recognition and, in this work, we apply them to compensate the mismatch between shouted and normal conditions in speaker verification. Before compensation, shouted condition is automatically detected by means of logistic regression. The process is computationally light and it is performed in the back-end of an x-vector system. Experimental results show that applying the proposed approach in the presence of vocal effort mismatch yields up to 13.8% equal error rate relative improvement with respect to a system that applies neither shouted speech detection nor compensation.      
### 22.3D Spectrum Mapping Based on ROI-Driven UAV Deployment  [ :arrow_down: ](https://arxiv.org/pdf/2008.02486.pdf)
>  Given the explosive growth of Internet of Things (IoT) devices ranging from the two-dimensional (2D) ground to the three-dimensional (3D) space, it is a necessity to establish a 3D spectrum map to comprehensively present and effectively manage the 3D spatial spectrum resources in smart city infrastructures. By leveraging the popularity and location flexibility of the unmanned aerial vehicles (UAVs), we are able to execute spatial sampling with these emerging flying spectrum-monitoring devices (SMDs) at will. In this paper, we first present a brief survey to show the state-of-the-art studies on spectrum mapping. Then, we introduce the 3D spectrum mapping model. Next, we propose a 3D spectrum mapping framework which is composed of pre-sampling, spectrum situation estimation, UAV deployment and spectrum recovery. Therein we develop a Region of Interest (ROI)-driven UAV deployment scheme, which selects new sampling points of the highest estimated interest and the lowest energy cost iteratively. Meanwhile, we slice the entire 3D spectrum map into a series of "images" and "repair" those unsampled locations. Furthermore, we provide an exemplary case study on the 3D spectrum mapping, where, for example, an important event is being held and the entire spectrum situation needs to be monitored in real time to deal with malicious interference sources. Lastly, the challenges and open issues are discussed.      
### 23.Machine Learning Based Framework for Estimation of Data Center Power Using Acoustic Side Channel  [ :arrow_down: ](https://arxiv.org/pdf/2008.02481.pdf)
>  Data centers are high power consumers and the energy consumption of data centers keeps on rising in spite of all the efforts for increasing the energy efficiency. The need for energy-awareness in data centers makes the use of power modeling and estimation to be still a big challenge due to huge amount of uncertainty in this area. In this paper, a machine learning based method is proposed to approximately estimate the amount of power consumption by using acoustic side channel caused by fan in the fan-based cooling system in the server room. For doing so, frequency components of the acoustic signal, recorded by a microphone in the server room, is extracted, pre-processed, and fed to a Multi-Layer Neural-Network as an estimator. The proposed method performed well to estimate the power consumption, having more than 85 percent accuracy.      
### 24.Mixing-Specific Data Augmentation Techniques for Improved Blind Violin/Piano Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2008.02480.pdf)
>  Blind music source separation has been a popular and active subject of research in both the music information retrieval and signal processing communities. To counter the lack of available multi-track data for supervised model training, a data augmentation method that creates artificial mixtures by combining tracks from different songs has been shown useful in recent works. Following this light, we examine further in this paper extended data augmentation methods that consider more sophisticated mixing settings employed in the modern music production routine, the relationship between the tracks to be combined, and factors of silence. As a case study, we consider the separation of violin and piano tracks in a violin piano ensemble, evaluating the performance in terms of common metrics, namely SDR, SIR, and SAR. In addition to examining the effectiveness of these new data augmentation methods, we also study the influence of the amount of training data. Our evaluation shows that the proposed mixing-specific data augmentation methods can help improve the performance of a deep learning-based model for source separation, especially in the case of small training data.      
### 25.Quantification of Transducer Misalignment in Ultrasound Tongue Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.02470.pdf)
>  In speech production research, different imaging modalities have been employed to obtain accurate information about the movement and shaping of the vocal tract. Ultrasound is an affordable and non-invasive imaging modality with relatively high temporal and spatial resolution to study the dynamic behavior of tongue during speech production. However, a long-standing problem for ultrasound tongue imaging is the transducer misalignment during longer data recording sessions. In this paper, we propose a simple, yet effective, misalignment quantification approach. The analysis employs MSE distance and two similarity measurement metrics to identify the relative displacement between the chin and the transducer. We visualize these measures as a function of the timestamp of the utterances. Extensive experiments are conducted on a Hungarian and Scottish English child dataset. The results suggest that large values of Mean Square Error (MSE) and small values of Structural Similarity Index (SSIM) and Complex Wavelet SSIM indicate corruptions or issues during the data recordings, which can either be caused by transducer misalignment or lack of gel.      
### 26.MetaRadar: Indoor Localization by Reconfigurable Metamaterials  [ :arrow_down: ](https://arxiv.org/pdf/2008.02459.pdf)
>  Indoor localization has drawn much attention owing to its potential for supporting location based services. Among various indoor localization techniques, the received signal strength (RSS) based technique is widely researched. However, in conventional RSS based systems where the radio environment is unconfigurable, adjacent locations may have similar RSS values, which limits the localization precision. In this paper, we present MetaRadar, which explores reconfigurable radio reflection with a surface/plane made of metamaterial units for multi-user localization. By changing the reflectivity of metamaterial, MetaRadar modifies the radio channels at different locations, and improves localization accuracy by making RSS values at adjacent locations have significant differences. However, in MetaRadar, it is challenging to build radio maps for all the radio environments generated by metamaterial units and select suitable maps from all the possible maps to realize a high accuracy localization. To tackle this challenge, we propose a compressive construction technique which can predict all the possible radio maps, and propose a configuration optimization algorithm to select favorable metamaterial reflectivities and the corresponding radio maps. The experimental results show a significant improvement from a decimeter-level localization error in the traditional RSS-based systems to a centimeter-level one in MetaRadar.      
### 27.Simultaneous measurement of time-invariant linear and nonlinear, and random and extra responses using frequency domain variant of velvet noise  [ :arrow_down: ](https://arxiv.org/pdf/2008.02439.pdf)
>  We introduce a new acoustic measurement method that can measure the linear time-invariant response, the nonlinear time-invariant response, and random and time-varying responses simultaneously. The method uses a set of orthogonal sequences made from a set of unit FVNs (Frequency domain variant of Velvet Noise), a new member of the TSP (Time Stretched Pulse). FVN has a unique feature that other TSP members do not. It is a high degree of design freedom that makes the proposed method possible without introducing extra equipment. We introduce two useful cases using two and four orthogonal sequences and illustrates their use using simulations and acoustic measurement examples. We developed an interactive and realtime acoustic analysis tool based on the proposed method. We made it available in an open-source repository. The proposed response analysis method is general and applies to other fields, such as auditory-feedback research and assessment of sound recording and coding.      
### 28.Accuracy and Resiliency of Analog Compute-in-Memory Inference Engines  [ :arrow_down: ](https://arxiv.org/pdf/2008.02400.pdf)
>  Recently, analog compute-in-memory (CIM) architectures based on emerging analog non-volatile memory (NVM) technologies have been explored for deep neural networks (DNN) to improve energy efficiency. Such architectures, however, leverage charge conservation, an operation with infinite resolution, and thus are susceptible to errors. The computations in DNN realized by analog NVM thus have high uncertainty due to the device stochasticity. Several reports have demonstrated the use of analog NVM for CIM in a limited scale. It is unclear whether the uncertainties in computations will prohibit large-scale DNNs. To explore this critical issue of scalability, this paper first presents a simulation framework to evaluate the feasibility of large-scale DNNs based on CIM architecture and analog NVM. Simulation results show that DNNs trained for high-precision digital computing engines are not resilient against the uncertainty of the analog NVM devices. To avoid such catastrophic failures, this paper introduces the analog floating-point representation for the DNN, and the Hessian-Aware Stochastic Gradient Descent (HA-SGD) training algorithm to enhance the inference accuracy of trained DNNs. As a result of such enhancements, DNNs such as Wide ResNets for the CIFAR-100 image recognition problem are demonstrated to have significant performance improvements in accuracy without adding cost to the inference hardware.      
### 29.OverNet: Lightweight Multi-Scale Super-Resolution with Overscaling Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.02382.pdf)
>  Super-resolution (SR) has achieved great success due to the development of deep convolutional neural networks (CNNs). However, as the depth and width of the networks increase, CNN-based SR methods have been faced with the challenge of computational complexity in practice. Moreover, most of them train a dedicated model for each target resolution, losing generality and increasing memory requirements. To address these limitations we introduce OverNet, a deep but lightweight convolutional network to solve SISR at arbitrary scale factors with a single model. We make the following contributions: first, we introduce a lightweight recursive feature extractor that enforces efficient reuse of information through a novel recursive structure of skip and dense connections. Second, to maximize the performance of the feature extractor we propose a reconstruction module that generates accurate high-resolution images from overscaled feature maps and can be independently used to improve existing architectures. Third, we introduce a multi-scale loss function to achieve generalization across scales. Through extensive experiments, we demonstrate that our network outperforms previous state-of-the-art results in standard benchmarks while using fewer parameters than previous approaches.      
### 30.Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.02371.pdf)
>  This paper presents an adversarial learning method for recognition-synthesis based non-parallel voice conversion. A recognizer is used to transform acoustic features into linguistic representations while a synthesizer recovers output features from the recognizer outputs together with the speaker identity. By separating the speaker characteristics from the linguistic representations, voice conversion can be achieved by replacing the speaker identity with the target one. In our proposed method, a speaker adversarial loss is adopted in order to obtain speaker-independent linguistic representations using the recognizer. Furthermore, discriminators are introduced and a generative adversarial network (GAN) loss is used to prevent the predicted features from being over-smoothed. For training model parameters, a strategy of pre-training on a multi-speaker dataset and then fine-tuning on the source-target speaker pair is designed. Our method achieved higher similarity than the baseline model that obtained the best performance in Voice Conversion Challenge 2018.      
### 31.Physics Regulated Neural Network for High Impedance Faults Detection  [ :arrow_down: ](https://arxiv.org/pdf/2008.02364.pdf)
>  High impedance faults (HIFs) in distribution grids may cause wildfires and threaten human lives. Still, more than 10\% HIFs fail to be detected by conventional protection relays. Existing methods require sufficient labeled datasets and heavily rely on measurements of relays at substations. Considering the insufficiency of labeled events, we construct a physics regulated convolutional auto-encoder (PRCAE) to detect HIFs without labeled HIFs for training. Our PRCAE introduces a physical regularization, derived from the elliptical trajectory of voltages-current characteristics, to distinguish HIFs from other abnormal events even in highly noisy situations. Also, we formulate a system-wide detection framework of combining multiple nodes' local detection results and a $\mu$PMU placement algorithm for the partially observed system. The proposed approaches are validated in the IEEE 34-node test feeder simulated through PSCAD/EMTDC. Our PRCAE shows superior detection performance than existing works in various scenarios, and is robust to different observability, noise, and low sampling rates.      
### 32.Exploiting Temporal Attention Features for Effective Denoising in Videos  [ :arrow_down: ](https://arxiv.org/pdf/2008.02344.pdf)
>  Video denoising has significant applications in diverse domains of computer vision, such as video-based object localization, text detection, and several others. An image denoising approach applied to video denoising results in flickering due to ignoring the temporal aspects of video frames. The proposed method makes use of the temporal as well as the spatial characteristics of video frames to form a two-stage denoising pipeline. Each stage uses a channel-wise attention mechanism to forward the encoder signal to the decoder side. The Attention Block used here is based on soft attention to rank the filters for effective learning. A key advantage of our approach is that it does not require prior information related to the amount of noise present in the video. Hence, it is quite suitable for application in real-life scenarios. We train the model on a large set of noisy videos along with their ground-truth. Experimental analysis shows that our approach performs denoising effectively and also surpasses existing methods in terms of efficiency and PSNR/SSIM metrics. In addition to this, we construct a new dataset for training video denoising models and also share the trained model online for further comparative studies.      
### 33.Global Voxel Transformer Networks for Augmented Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2008.02340.pdf)
>  Advances in deep learning have led to remarkable success in augmented microscopy, enabling us to obtain high-quality microscope images without using expensive microscopy hardware and sample preparation techniques. However, current deep learning models for augmented microscopy are mostly U-Net based neural networks, thus sharing certain drawbacks that limit the performance. In this work, we introduce global voxel transformer networks (GVTNets), an advanced deep learning tool for augmented microscopy that overcomes intrinsic limitations of the current U-Net based models and achieves improved performance. GVTNets are built on global voxel transformer operators (GVTOs), which are able to aggregate global information, as opposed to local operators like convolutions. We apply the proposed methods on existing datasets for three different augmented microscopy tasks under various settings. The performance is significantly and consistently better than previous U-Net based approaches.      
### 34.Optimal Data Detection and Signal Estimation in Systems with Input Noise  [ :arrow_down: ](https://arxiv.org/pdf/2008.02337.pdf)
>  Practical systems often suffer from hardware impairments that already appear during signal generation. Despite the limiting effect of such input-noise impairments on signal processing systems, they are routinely ignored in the literature. In this paper, we propose an algorithm for data detection and signal estimation, referred to as Approximate Message Passing with Input noise (AMPI), which takes into account input-noise impairments. To demonstrate the efficacy of AMPI, we investigate two applications: Data detection in large multiple-input multiple output (MIMO) wireless systems and sparse signal recovery in compressive sensing. For both applications, we provide precise conditions in the large-system limit for which AMPI achieves optimal performance. We furthermore use simulations to demonstrate that AMPI achieves near-optimal performance at low complexity in realistic, finite-dimensional systems.      
### 35.Fast Position-Aided MIMO Beam Training via Noisy Tensor Completion  [ :arrow_down: ](https://arxiv.org/pdf/2008.02333.pdf)
>  In this paper, a data-driven position-aided approach is proposed to reduce the training overhead in MIMO systems, by leveraging side information and on-the-field measurements. A data tensor is constructed by collecting beam-training measurements on a subset of positions and beams, and a hybrid noisy tensor completion (HNTC) algorithm is proposed to predict the received power across the coverage area, which exploits both the spatial smoothness and the low-rank property of MIMO channels. A recommendation algorithm based on the completed tensor, beam subset selection (BSS), is proposed to achieve fast and accurate beam-training. Besides, a grouping-based BSS algorithm is proposed to combat the detrimental effect of noisy positional information. Numerical results evaluated with the Quadriga channel simulator at 60 GHz millimeter-wave channels show that the proposed BSS recommendation algorithm in combination with HNTC achieve accurate received power predictions, enabling beam-alignment with small overhead: given power measurements on 40% of possible discretized positions, HNTC-based BSS attains a probability of correct alignment of 91%, with only 2% of trained beams, as opposed to a state-of-the-art position-aided beam-alignment scheme which achieves 54% correct alignment in the same configuration. Finally, an online HNTC method via warm-start is proposed, that alleviates the computational complexity by 50%, with no degradation in prediction accuracy.      
### 36.Predicting Crack Growth and Fatigue Life with Surrogate Models  [ :arrow_down: ](https://arxiv.org/pdf/2008.02324.pdf)
>  Fatigue-induced damage is still one of the most uncertain failures in structural systems. Prognostic health monitoring together with surrogate models can help to predict the fatigue life of a structure. This paper demonstrates how to combine data from previously observed crack evolutions with data from the currently observed structure in order to predict crack growth and the total fatigue life. We show the application of one physics-based model, which is based on Paris' law, and four mathematical surrogate models: recurrent neural networks, Gaussian process regression, k-nearest neighbors, and support vector regression. For a coupon test, we predict the time to failure and the crack growth with confidence intervals. Moreover, we compare the performance of all proposed models by the mean absolute error, coefficient of determination, mean of log-likelihood, and their confidence intervals. The results show that the best mathematical surrogate models are Gaussian process regression and recurrent neural networks. Furthermore, this paper shows that the mathematical surrogate models tend to have conservative confidence intervals, whereas the physics-based model exhibits overly optimistic (too small) confidence intervals.      
### 37.Hybrid Transformer/CTC Networks for Hardware Efficient Voice Triggering  [ :arrow_down: ](https://arxiv.org/pdf/2008.02323.pdf)
>  We consider the design of two-pass voice trigger detection systems. We focus on the networks in the second pass that are used to re-score candidate segments obtained from the first-pass. Our baseline is an acoustic model(AM), with BiLSTM layers, trained by minimizing the CTC loss. We replace the BiLSTM layers with self-attention layers. Results on internal evaluation sets show that self-attention networks yield better accuracy while requiring fewer parameters. We add an auto-regressive decoder network on top of the self-attention layers and jointly minimize the CTC loss on the encoder and the cross-entropy loss on the decoder. This design yields further improvements over the baseline. We retrain all the models above in a multi-task learning(MTL) setting, where one branch of a shared network is trained as an AM, while the second branch classifies the whole sequence to be true-trigger or not. Results demonstrate that networks with self-attention layers yield $\sim$60% relative reduction in false reject rates for a given false-alarm rate, while requiring 10% fewer parameters. When trained in the MTL setup, self-attention networks yield further accuracy improvements. On-device measurements show that we observe 70% relative reduction in inference time. Additionally, the proposed network architectures are $\sim$5X faster to train.      
### 38.Machine learning for faster and smarter fluorescence lifetime imaging microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2008.02320.pdf)
>  Fluorescence lifetime imaging microscopy (FLIM) is a powerful technique in biomedical research that uses the fluorophore decay rate to provide additional contrast in fluorescence microscopy. However, at present, the calculation, analysis, and interpretation of FLIM is a complex, slow, and computationally expensive process. Machine learning (ML) techniques are well suited to extract and interpret measurements from multi-dimensional FLIM data sets with substantial improvement in speed over conventional methods. In this topical review, we first discuss the basics of FILM and ML. Second, we provide a summary of lifetime extraction strategies using ML and its applications in classifying and segmenting FILM images with higher accuracy compared to conventional methods. Finally, we discuss two potential directions to improve FLIM with ML with proof of concept demonstrations.      
### 39.Huffman-Coded Sphere Shaping for Extended-Reach Single-Span Links  [ :arrow_down: ](https://arxiv.org/pdf/2008.02313.pdf)
>  Huffman-coded sphere shaping (HCSS) is an algorithm for finite-length probabilistic constellation shaping, which provides nearly optimal energy efficiency at low implementation complexity. In this paper, we experimentally study the nonlinear performance of HCSS employing dual-polarization 64-ary quadrature amplitude modulation (DP-64QAM) in an extended reach single-span link comprising 200 km of standard single mode fiber (SSMF). We investigate the effects of shaping sequence length, dimensionality of symbol mapping, and shaping rate. We determine that the naïve approach of Maxwell-Boltzmann distribution matching - which is optimal in the additive white Gaussian noise channel - provides a maximum achievable information rate gain of 0.18 bits/4D-symbol in the infinite length regime. Conversely, HCSS can achieve a gain of 0.37 bits/4Dsymbol using amplitude sequence lengths of 32, which may be implemented without multiplications, using integer comparison and addition operations only. Coded system performance, with a net data rate of approximately 425 Gb/s for both shaped and uniform inputs, is also analyzed.      
### 40.A Novel Spatial-Spectral Framework for the Classification of Hyperspectral Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2008.02797.pdf)
>  Hyper-spectral satellite imagery is now widely being used for accurate disaster prediction and terrain feature classification. However, in such classification tasks, most of the present approaches use only the spectral information contained in the images. Therefore, in this paper, we present a novel framework that takes into account both the spectral and spatial information contained in the data for land cover classification. For this purpose, we use the Gaussian Maximum Likelihood (GML) and Convolutional Neural Network methods for the pixel-wise spectral classification and then, using segmentation maps generated by the Watershed algorithm, we incorporate the spatial contextual information into our model with a modified majority vote technique. The experimental analyses on two benchmark datasets demonstrate that our proposed methodology performs better than the earlier approaches by achieving an accuracy of 99.52% and 98.31% on the Pavia University and the Indian Pines datasets respectively. Additionally, our GML based approach, a non-deep learning algorithm, shows comparable performance to the state-of-the-art deep learning techniques, which indicates the importance of the proposed approach for performing a computationally efficient classification of hyper-spectral imagery.      
### 41.Few-Shot Drum Transcription in Polyphonic Music  [ :arrow_down: ](https://arxiv.org/pdf/2008.02791.pdf)
>  Data-driven approaches to automatic drum transcription (ADT) are often limited to a predefined, small vocabulary of percussion instrument classes. Such models cannot recognize out-of-vocabulary classes nor are they able to adapt to finer-grained vocabularies. In this work, we address open vocabulary ADT by introducing few-shot learning to the task. We train a Prototypical Network on a synthetic dataset and evaluate the model on multiple real-world ADT datasets with polyphonic accompaniment. We show that, given just a handful of selected examples at inference time, we can match and in some cases outperform a state-of-the-art supervised ADT approach under a fixed vocabulary setting. At the same time, we show that our model can successfully generalize to finer-grained or extended vocabularies unseen during training, a scenario where supervised approaches cannot operate at all. We provide a detailed analysis of our experimental results, including a breakdown of performance by sound class and by polyphony.      
### 42.Efficient Non-Line-of-Sight Imaging from Transient Sinograms  [ :arrow_down: ](https://arxiv.org/pdf/2008.02787.pdf)
>  Non-line-of-sight (NLOS) imaging techniques use light that diffusely reflects off of visible surfaces (e.g., walls) to see around corners. One approach involves using pulsed lasers and ultrafast sensors to measure the travel time of multiply scattered light. Unlike existing NLOS techniques that generally require densely raster scanning points across the entirety of a relay wall, we explore a more efficient form of NLOS scanning that reduces both acquisition times and computational requirements. We propose a circular and confocal non-line-of-sight (C2NLOS) scan that involves illuminating and imaging a common point, and scanning this point in a circular path along a wall. We observe that (1) these C2NLOS measurements consist of a superposition of sinusoids, which we refer to as a transient sinogram, (2) there exists computationally efficient reconstruction procedures that transform these sinusoidal measurements into 3D positions of hidden scatterers or NLOS images of hidden objects, and (3) despite operating on an order of magnitude fewer measurements than previous approaches, these C2NLOS scans provide sufficient information about the hidden scene to solve these different NLOS imaging tasks. We show results from both simulated and real C2NLOS scans.      
### 43.Forecasting Photovoltaic Power Production using a Deep Learning Sequence to Sequence Model with Attention  [ :arrow_down: ](https://arxiv.org/pdf/2008.02775.pdf)
>  Rising penetration levels of (residential) photovoltaic (PV) power as distributed energy resource pose a number of challenges to the electricity infrastructure. High quality, general tools to provide accurate forecasts of power production are urgently needed. In this article, we propose a supervised deep learning model for end-to-end forecasting of PV power production. The proposed model is based on two seminal concepts that led to significant performance improvements of deep learning approaches in other sequence-related fields, but not yet in the area of time series prediction: the sequence to sequence architecture and attention mechanism as a context generator. The proposed model leverages numerical weather predictions and high-resolution historical measurements to forecast a binned probability distribution over the prognostic time intervals, rather than the expected values of the prognostic variable. This design offers significant performance improvements compared to common baseline approaches, such as fully connected neural networks and one-block long short-term memory architectures. Using normalized root mean square error based forecast skill score as a performance indicator, the proposed approach is compared to other models. The results show that the new design performs at or above the current state of the art of PV power forecasting.      
### 44.Exact, Parallelizable Dynamic Time Warping Alignment with Linear Memory  [ :arrow_down: ](https://arxiv.org/pdf/2008.02734.pdf)
>  Audio alignment is a fundamental preprocessing step in many MIR pipelines. For two audio clips with M and N frames, respectively, the most popular approach, dynamic time warping (DTW), has O(MN) requirements in both memory and computation, which is prohibitive for frame-level alignments at reasonable rates. To address this, a variety of memory efficient algorithms exist to approximate the optimal alignment under the DTW cost. To our knowledge, however, no exact algorithms exist that are guaranteed to break the quadratic memory barrier. In this work, we present a divide and conquer algorithm that computes the exact globally optimal DTW alignment using O(M+N) memory. Its runtime is still O(MN), trading off memory for a 2x increase in computation. However, the algorithm can be parallelized up to a factor of min(M, N) with the same memory constraints, so it can still run more efficiently than the textbook version with an adequate GPU. We use our algorithm to compute exact alignments on a collection of orchestral music, which we use as ground truth to benchmark the alignment accuracy of several popular approximate alignment schemes at scales that were not previously possible.      
### 45.Pairwise Relation Learning for Semi-supervised Gland Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2008.02699.pdf)
>  Accurate and automated gland segmentation on histology tissue images is an essential but challenging task in the computer-aided diagnosis of adenocarcinoma. Despite their prevalence, deep learning models always require a myriad number of densely annotated training images, which are difficult to obtain due to extensive labor and associated expert costs related to histology image annotations. In this paper, we propose the pairwise relation-based semi-supervised (PRS^2) model for gland segmentation on histology images. This model consists of a segmentation network (S-Net) and a pairwise relation network (PR-Net). The S-Net is trained on labeled data for segmentation, and PR-Net is trained on both labeled and unlabeled data in an unsupervised way to enhance its image representation ability via exploiting the semantic consistency between each pair of images in the feature space. Since both networks share their encoders, the image representation ability learned by PR-Net can be transferred to S-Net to improve its segmentation performance. We also design the object-level Dice loss to address the issues caused by touching glands and combine it with other two loss functions for S-Net. We evaluated our model against five recent methods on the GlaS dataset and three recent methods on the CRAG dataset. Our results not only demonstrate the effectiveness of the proposed PR-Net and object-level Dice loss, but also indicate that our PRS^2 model achieves the state-of-the-art gland segmentation performance on both benchmarks.      
### 46.MED-TEX: Transferring and Explaining Knowledge with Less Data from Pretrained Medical Imaging Models  [ :arrow_down: ](https://arxiv.org/pdf/2008.02593.pdf)
>  Deep neural network based image classification methods usually require a large amount of training data and lack interpretability, which are critical in the medical imaging domain. In this paper, we develop a novel knowledge distillation and model interpretation framework for medical image classification that jointly solves the above two issues. Specifically, to address the data-hungry issue, we propose to learn a small student model with less data by distilling knowledge only from a cumbersome pretrained teacher model. To interpret the teacher model as well as assisting the learning of the student, an explainer module is introduced to highlight the regions of an input medical image that are important for the predictions of the teacher model. Furthermore, the joint framework is trained by a principled way derived from the information-theoretic perspective. Our framework performance is demonstrated by the comprehensive experiments on the knowledge distillation and model interpretation tasks compared to state-of-the-art methods on a fundus disease dataset.      
### 47.The Canonical Controller for Distributed Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.02588.pdf)
>  This paper generalises results of Willems-Trentelman, and van der Schaft, on achievable behaviours, to the case of linear distributed systems defined by partial differential or difference equations. It shows that the `minimal' controller which achieves a particular subsystem is the canonical controller of van der Schaft, thereby answering the `open problem' of \cite{sc} in the setting of infinite dimensional and $n-D$ systems. This result is used to describe the collection of all linear subsystems of the electro-magnetic field, containing the vacuum solutions, that can be achieved by suitable choices of electric charge and current density.      
### 48.Reconfigurable Intelligent Surfaces with Reflection Pattern Modulation: Beamforming Design and Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2008.02555.pdf)
>  Recent considerations for reconfigurable intelligent surfaces (RISs) assume that RISs can convey information by reflection without the need of transmit radio frequency chains, which, however, is a challenging task. In this paper, we propose an RIS-enhanced multiple-input single-output system with reflection pattern modulation, where the RIS can configure its reflection state for boosting the received signal power via passive beamforming and simultaneously conveying its own information via reflection. We formulate an optimization problem to maximize the average received signal power by jointly optimizing the active beamforming at the access point (AP) and passive beamforming at the RIS for the case where the RIS's state information is statistically known by the AP, and propose a high-quality suboptimal solution based on the alternating optimization technique. We analyze the asymptotic outage probability of the proposed scheme under Rayleigh fading channels, for which a closed-form expression is derived. The achievable rate of the proposed scheme is also investigated for the case where the transmitted symbol is drawn from a finite constellation. Simulation results validate the effectiveness of the proposed scheme and reveal the effect of various system parameters on the achievable rate performance. It is shown that the proposed scheme outperforms the conventional RIS-assisted system without information transfer in terms of achievable rate performance.      
### 49.Zero-Shot Multi-View Indoor Localization via Graph Location Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.02492.pdf)
>  Indoor localization is a fundamental problem in location-based applications. Current approaches to this problem typically rely on Radio Frequency technology, which requires not only supporting infrastructures but human efforts to measure and calibrate the signal. Moreover, data collection for all locations is indispensable in existing methods, which in turn hinders their large-scale deployment. In this paper, we propose a novel neural network based architecture Graph Location Networks (GLN) to perform infrastructure-free, multi-view image based indoor localization. GLN makes location predictions based on robust location representations extracted from images through message-passing networks. Furthermore, we introduce a novel zero-shot indoor localization setting and tackle it by extending the proposed GLN to a dedicated zero-shot version, which exploits a novel mechanism Map2Vec to train location-aware embeddings and make predictions on novel unseen locations. Our extensive experiments show that the proposed approach outperforms state-of-the-art methods in the standard setting, and achieves promising accuracy even in the zero-shot setting where data for half of the locations are not available. The source code and datasets are publicly available at <a class="link-external link-https" href="https://github.com/coldmanck/zero-shot-indoor-localization-release" rel="external noopener nofollow">this https URL</a>.      
### 50.GL-GAN: Adaptive Global and Local Bilevel Optimization model of Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2008.02436.pdf)
>  Although Generative Adversarial Networks have shown remarkable performance in image generation, there are some challenges in image realism and convergence speed. The results of some models display the imbalances of quality within a generated image, in which some defective parts appear compared with other regions. Different from general single global optimization methods, we introduce an adaptive global and local bilevel optimization model(GL-GAN). The model achieves the generation of high-resolution images in a complementary and promoting way, where global optimization is to optimize the whole images and local is only to optimize the low-quality areas. With a simple network structure, GL-GAN is allowed to effectively avoid the nature of imbalance by local bilevel optimization, which is accomplished by first locating low-quality areas and then optimizing them. Moreover, by using feature map cues from discriminator output, we propose the adaptive local and global optimization method(Ada-OP) for specific implementation and find that it boosts the convergence speed. Compared with the current GAN methods, our model has shown impressive performance on CelebA, CelebA-HQ and LSUN datasets.      
### 51.Dynamic and Versatile Humanoid Walking via Embedding 3D Actuated SLIP Model with Hybrid LIP Based Stepping  [ :arrow_down: ](https://arxiv.org/pdf/2008.02435.pdf)
>  In this paper, we propose an efficient approach to generate dynamic and versatile humanoid walking with non-constant center of mass (COM) height. We exploit the benefits of using reduced order models (ROMs) and stepping control to generate dynamic and versatile walking motion. Specifically, we apply the stepping controller based on the Hybrid Linear Inverted Pendulum Model (H-LIP) to perturb a periodic walking motion of a 3D actuated Spring Loaded Inverted Pendulum (3D-aSLIP), which yields versatile walking behaviors of the 3D-aSLIP, including various 3D periodic walking, fixed location tracking, and global trajectory tracking. The 3D-aSLIP walking is then embedded on the fully-actuated humanoid via the task space control on the COM dynamics and ground reaction forces. The proposed approach is realized on the robot model of Atlas in simulation, wherein versatile dynamic motions are generated.      
### 52.Sequential Motion Planning for Bipedal Somersault via Flywheel SLIP and Momentum Transmission with Task Space Control  [ :arrow_down: ](https://arxiv.org/pdf/2008.02432.pdf)
>  In this paper, we present a sequential motion planning and control method for generating somersaults on bipedal robots. The somersault (backflip or frontflip) is considered as a coupling between an axile hopping motion and a rotational motion about the center of mass of the robot; these are encoded by a hopping Spring-loaded Inverted Pendulum (SLIP) model and the rotation of a Flywheel, respectively. We thus present the Flywheel SLIP model for generating the desired motion on the ground phase. In the flight phase, we present a momentum transmission method to adjust the orientation of the lower body based on the conservation of the centroidal momentum. The generated motion plans are realized on the full-dimensional robot via momentum-included task space control. Finally, the proposed method is implemented on a modified version of the bipedal robot Cassie in simulation wherein multiple somersault motions are generated.      
### 53.DANA: Dimension-Adaptive Neural Architecture for Multivariate Sensor Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.02397.pdf)
>  Current deep neural architectures for processing sensor data are mainly designed for data coming from a fixed set of sensors, with a fixed sampling rate. Changing the dimensions of the input data causes considerable accuracy loss, unnecessary computations, or application failures. To address this problem, we introduce a {\em dimension-adaptive pooling}~(DAP) layer that makes deep architectures robust to temporal changes in sampling rate and in sensor availability. DAP operates on convolutional filter maps of variable dimensions and produces an input of fixed dimensions suitable for feedforward and recurrent layers. Building on this architectural improvement, we propose a {\em dimension-adaptive training}~(DAT) procedure to generalize over the entire space of feasible data dimensions at the inference time. DAT comprises the random selection of dimensions during the forward passes and optimization with accumulated gradients of several backward passes. We then combine DAP and DAT to transform existing non-adaptive deep architectures into a {\em Dimension-Adaptive Neural Architecture}~(DANA) without altering other architectural aspects. Our solution does not need up-sampling or imputation, thus reduces unnecessary computations at inference time. Experimental results on public datasets show that DANA prevents losses in classification accuracy of the state-of-the-art deep architectures, under dynamic sensor availability and varying sampling rates.      
### 54.Optimal Control of Connected and Automated Vehicles at Multiple Adjacent Intersections  [ :arrow_down: ](https://arxiv.org/pdf/2008.02379.pdf)
>  In this paper, we establish a decentralized optimal control framework for connected and automated vehicles (CAVs) crossing multiple adjacent, multi-lane intersections to minimize energy consumption and improve traffic throughput. Our framework consists of two layers of planning. In the upper-level planning, each CAV computes its optimal arrival time at each intersection recursively along with the optimal lane to improve the traffic throughput. In the low-level planning, we formulate an energy-optimal control problem with interior-point constraints, the solution of which yields the optimal control input (acceleration/deceleration) of each CAV to cross the intersections at the time specified by the upper-level planning. Moreover, we extend the results of the proposed bi-level framework to include a bounded steady-state error in tracking the optimal position of the CAVs. Finally, we demonstrate the effectiveness of the proposed framework through simulation and comparison with traditional signalized intersections.      
### 55.Single-Pixel Fluorescent Diffraction Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2008.02376.pdf)
>  Optical diffraction tomography is an indispensable tool for studying objects in three-dimensions due to its ability to accurately reconstruct scattering objects. Until now this technique has been limited to coherent light because spatial phase information is required to solve the inverse scattering problem. We introduce a method that extends optical diffraction tomography to imaging spatially incoherent contrast mechanisms such as fluorescent emission. Our strategy mimics the coherent scattering process with two spatially coherent illumination beams. The interferometric illumination pattern encodes spatial phase in temporal variations of the fluorescent emission, thereby allowing incoherent fluorescent emission to mimic the behavior of coherent illumination. The temporal variations permit recovery of the propagation phase, and thus the spatial distribution of incoherent fluorescent emission can be recovered with an inverse scattering model.      
### 56.Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2008.02312.pdf)
>  To have a better understanding and usage of Convolution Neural Networks (CNNs), the visualization and interpretation of CNNs has attracted increasing attention in recent years. In particular, several Class Activation Mapping (CAM) methods have been proposed to discover the connection between CNN's decision and image regions. In spite of the reasonable visualization, lack of clear and sufficient theoretical support is the main limitation of these methods. In this paper, we introduce two axioms -- Conservation and Sensitivity -- to the visualization paradigm of the CAM methods. Meanwhile, a dedicated Axiom-based Grad-CAM (XGrad-CAM) is proposed to satisfy these axioms as much as possible. Experiments demonstrate that XGrad-CAM is an enhanced version of Grad-CAM in terms of conservation and sensitivity. It is able to achieve better visualization performance than Grad-CAM, while also be class-discriminative and easy-to-implement compared with Grad-CAM++ and Ablation-CAM. The code is available at <a class="link-external link-https" href="https://github.com/Fu0511/XGrad-CAM" rel="external noopener nofollow">this https URL</a>.      
### 57.Generalization of Spoofing Countermeasures: a Case Study with ASVspoof 2015 and BTAS 2016 Corpora  [ :arrow_down: ](https://arxiv.org/pdf/1901.08025.pdf)
>  Voice-based biometric systems are highly prone to spoofing attacks. Recently, various countermeasures have been developed for detecting different kinds of attacks such as replay, speech synthesis (SS) and voice conversion (VC). Most of the existing studies are conducted with a specific training set defined by the evaluation protocol. However, for realistic scenarios, selecting appropriate training data is an open challenge for the system administrator. Motivated by this practical concern, this work investigates the generalization capability of spoofing countermeasures in restricted training conditions where speech from a broad attack types are left out in the training database. We demonstrate that different spoofing types have considerably different generalization capabilities. For this study, we analyze the performance using two kinds of features, mel-frequency cepstral coefficients (MFCCs) which are considered as baseline and recently proposed constant Q cepstral coefficients (CQCCs). The experiments are conducted with standard Gaussian mixture model - maximum likelihood (GMM-ML) classifier on two recently released spoofing corpora: ASVspoof 2015 and BTAS 2016 that includes cross-corpora performance analysis. Feature-level analysis suggests that static and dynamic coefficients of spectral features, both are important for detecting spoofing attacks in the real-life condition.      

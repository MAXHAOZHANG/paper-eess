# ArXiv eess --Tue, 11 Aug 2020
### 1.Two-Stage Clustering of Household Electricity Load Shapes based on Temporal Pattern &amp; Peak Demand  [ :arrow_down: ](https://arxiv.org/pdf/2008.04293.pdf)
>  Analyzing smart meter data to understand energy consumption patterns helps utilities and energy providers perform customized demand response operations. Existing energy consumption segmentation techniques use assumptions that could result in reduced quality of clusters in representing their members. We address this limitation by introducing a two-stage clustering method that more accurately captures load shape temporal patterns and peak demands. In the first stage, load shapes are clustered by allowing a large number of clusters to accurately capture variations in energy use patterns and cluster centroids are extracted by accounting for shape misalignments. In the second stage, clusters of similar centroid and power magnitude range are merged by using Dynamic Time Warping. We used three datasets consisting of ~250 households (~15000 profiles) to demonstrate the performance improvement, compared to baseline methods, and discuss the impact on energy management.      
### 2.Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training  [ :arrow_down: ](https://arxiv.org/pdf/2008.04265.pdf)
>  Data efficient voice cloning aims at synthesizing target speaker's voice with only a few enrollment samples at hand. To this end, speaker adaptation and speaker encoding are two typical methods based on base model trained from multiple speakers. The former uses a small set of target speaker data to transfer the multi-speaker model to target speaker's voice through direct model update, while in the latter, only a few seconds of target speaker's audio directly goes through an extra speaker encoding model along with the multi-speaker model to synthesize target speaker's voice without model update. Nevertheless, the two methods need clean target speaker data. However, the samples provided by user may inevitably contain acoustic noise in real applications. It's still challenging to generating target voice with noisy data. In this paper, we study the data efficient voice cloning problem from noisy samples under the sequence-to-sequence based TTS paradigm. Specifically, we introduce domain adversarial training (DAT) to speaker adaptation and speaker encoding, which aims to disentangle noise from speech-noise mixture. Experiments show that for both speaker adaptation and encoding, the proposed approaches can consistently synthesize clean speech from noisy speaker samples, apparently outperforming the method adopting state-of-the-art speech enhancement module.      
### 3.Progress on a perimeter surveillance problem  [ :arrow_down: ](https://arxiv.org/pdf/2008.04262.pdf)
>  We consider a perimeter surveillance problem introduced by Kingston, Beard, and Holt in 2008 and studied by Davis, Humphrey, and Kingston in 2019. In this problem, $n$ drones surveil a finite interval, moving at uniform speed and exchanging information only when they meet another drone. Kingston, Beard, and Holt described a particular online algorithm for coordinating their behavior and asked for an upper bound on how long it can take before the drones are fully synchronized. They divided the algorithm's behavior into two phases, and presented upper bounds on the length of each phase based on conjectured worst-case configurations. Davis, Humphrey, and Kingston presented counterexamples to the conjecture for phase 1. <br>We present sharp upper and lower bounds on phase 2 which show that in this case the conjectured worst case is correct. We also present new lower bounds on phase 1 and the total time to synchronization, and report partial progress towards bounding phase 2.      
### 4.A Perceptually-Motivated Approach for Low-Complexity, Real-Time Enhancement of Fullband Speech  [ :arrow_down: ](https://arxiv.org/pdf/2008.04259.pdf)
>  Over the past few years, speech enhancement methods based on deep learning have greatly surpassed traditional methods based on spectral subtraction and spectral estimation. Many of these new techniques operate directly in the the short-time Fourier transform (STFT) domain, resulting in a high computational complexity. In this work, we propose PercepNet, an efficient approach that relies on human perception of speech by focusing on the spectral envelope and on the periodicity of the speech. We demonstrate high-quality, real-time enhancement of fullband (48 kHz) speech with less than 5% of a CPU core.      
### 5.Robust and Scalable Techniques for TWR and TDoA based localization using Ultra Wide Band Radios  [ :arrow_down: ](https://arxiv.org/pdf/2008.04248.pdf)
>  Current trends in autonomous vehicles and their applications indicates an increasing need in positioning at low battery and compute cost. Lidars provide accurate localization at the cost of high compute and power consumption which could be detrimental for drones. Modern requirements for autonomous drones such as No-Permit-No-Takeoff (NPNT) and applications restricting drones to a corridor require the infrastructure to constantly determine the location of the drone. Ultra Wide Band Radios (UWB) fulfill such requirements and offer high precision localization and fast position update rates at a fraction of the cost and battery consumption as compared to lidars and also have greater network availability than GPS in a dense forested campus or an indoor setting. We present in this paper a novel protocol and technique to localize a drone for such applications using a Time Difference of Arrival (TDoA) approach. This further increases the position update rates without sacrificing on accuracy and compare it to traditional methods      
### 6.TinySpeech: Attention Condensers for Deep Speech Recognition Neural Networks on Edge Devices  [ :arrow_down: ](https://arxiv.org/pdf/2008.04245.pdf)
>  Advances in deep learning have led to state-of-the-art performance across a multitude of speech recognition tasks. Nevertheless, the widespread deployment of deep neural networks for on-device speech recognition remains a challenge, particularly in edge scenarios where the memory and computing resources are highly constrained (e.g., low-power embedded devices) or where the memory and computing budget dedicated to speech recognition is low (e.g., mobile devices performing numerous tasks besides speech recognition). In this study, we introduce the concept of attention condensers for building low-footprint, highly-efficient deep neural networks for on-device speech recognition on the edge. More specifically, an attention condenser is a self-attention mechanism that learns and produces a condensed embedding characterizing joint local and cross-channel activation relationships, and performs adaptive activation recalibration accordingly for selective concentration. To illustrate its efficacy, we introduce TinySpeech, low-precision deep neural networks comprising largely of attention condensers tailored for on-device speech recognition using a machine-driven design exploration strategy. Experimental results on the Google Speech Commands benchmark dataset for limited-vocabulary speech recognition showed that TinySpeech networks achieved significantly lower architectural complexity (as much as $207\times$ fewer parameters) and lower computational complexity (as much as $21\times$ fewer multiply-add operations) when compared to previous deep neural networks in research literature. These results not only demonstrate the efficacy of attention condensers for building highly efficient deep neural networks for on-device speech recognition, but also illuminate its potential for accelerating deep learning on the edge and empowering a wide range of TinyML applications.      
### 7.Viral Aerosol Concentration Characterization and Detection in Bounded Environments  [ :arrow_down: ](https://arxiv.org/pdf/2008.04218.pdf)
>  Viral spread has been intermittently threatening human life over time. Characterizing the viral concentration and modelling the viral transmission are, therefore, considered major milestones for enhancing viral detection capabilities. This paper addresses the problem of viral aerosol detection based on the exhaled breath in a bounded environment, e.g., a bounded room. The paper models the exhaled breath as a cloud which is emitted through the room continuously, and analyzes the temporal-spatial virus concentration by accounting for partial absorption and reflection at each side of the room. The paper first derives a closed form expression of the temporal-spatial virus concentration. It then considers the deployment of a receiver composed of an air sampler and a bio-sensor to detect the viral existence of a specific virus. We, therefore, assess the detection capabilities of the proposed system via evaluating the viral miss-detection probability as a function of the sampling volume and the detection time-instance at the receiver side. Our numerical simulations verify the validity of the analytical results, and illustrate the ability of the proposed system to detect viruses in indoor environments. The results further characterize the impacts of several system parameters on the miss-detection probability.      
### 8.Learning Invariant Feature Representation to Improve Generalization across Chest X-ray Datasets  [ :arrow_down: ](https://arxiv.org/pdf/2008.04152.pdf)
>  Chest radiography is the most common medical image examination for screening and diagnosis in hospitals. Automatic interpretation of chest X-rays at the level of an entry-level radiologist can greatly benefit work prioritization and assist in analyzing a larger population. Subsequently, several datasets and deep learning-based solutions have been proposed to identify diseases based on chest X-ray images. However, these methods are shown to be vulnerable to shift in the source of data: a deep learning model performing well when tested on the same dataset as training data, starts to perform poorly when it is tested on a dataset from a different source. In this work, we address this challenge of generalization to a new source by forcing the network to learn a source-invariant representation. By employing an adversarial training strategy, we show that a network can be forced to learn a source-invariant representation. Through pneumonia-classification experiments on multi-source chest X-ray datasets, we show that this algorithm helps in improving classification accuracy on a new source of X-ray dataset.      
### 9.Deep-learning-based precoding in multiuser MIMO downlink channels with limited feedback  [ :arrow_down: ](https://arxiv.org/pdf/2008.04147.pdf)
>  We propose a deep-learning-based channel quantization, feedback, and precoding method for downlink multiuser multiple-input multiple-output systems. In the proposed system, the traditional codebook-based channel quantization process for limited feedback is handled by a receiver deep neural network (DNN) for each user. The precoder selection process is handled by a transmitter DNN for the base station. At each receiver DNN, a binarization layer is adopted to emulate the channel quantization process and enable end-to-end learning. However, during training, receiver DNNs with the binarization layer can be trapped at a poor local minimum because of inaccurate gradients caused by the binarization layer. To address this, we consider a method of knowledge distillation, in which the existing DNNs are jointly trained with an additional auxiliary transmitter DNN. By using the auxiliary DNN as a teacher network, the receiver DNNs can additionally exploit lossless gradients, which is useful in avoiding a poor local minimum. Moreover, through joint training, the existing DNNs can be generalized including the quantization loss from binarization. All DNNs at the associated users and transmitter are trained offline in an end-to-end manner, with the aid of the auxiliary transmitter DNN. The purpose of the end-to-end learning is to determine the precoding matrices that maximize the downlink sum rate. Our DNN-based precoding scheme can achieve a significantly higher downlink rate compared to traditional linear precoding with codebook-based limited feedback, for the same number of feedback bits, particularly when the number of receive antennas is greater than one.      
### 10.Learning Bloch Simulations for MR Fingerprinting by Invertible Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.04139.pdf)
>  Magnetic resonance fingerprinting (MRF) enables fast and multiparametric MR imaging. Despite fast acquisition, the state-of-the-art reconstruction of MRF based on dictionary matching is slow and lacks scalability. To overcome these limitations, neural network (NN) approaches estimating MR parameters from fingerprints have been proposed recently. Here, we revisit NN-based MRF reconstruction to jointly learn the forward process from MR parameters to fingerprints and the backward process from fingerprints to MR parameters by leveraging invertible neural networks (INNs). As a proof-of-concept, we perform various experiments showing the benefit of learning the forward process, i.e., the Bloch simulations, for improved MR parameter estimation. The benefit especially accentuates when MR parameter estimation is difficult due to MR physical restrictions. Therefore, INNs might be a feasible alternative to the current solely backward-based NNs for MRF reconstruction.      
### 11.Approximate Optimal Control for Safety-Critical Systems with Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2008.04122.pdf)
>  Control Barrier Functions (CBFs) have become a popular tool for enforcing set invariance in safety-critical control systems. While guaranteeing safety, most CBF approaches are myopic in the sense that they solve an optimization problem at each time step rather than over a long time horizon. This approach may allow a system to get too close to the unsafe set where the optimization problem can become infeasible. Some of these issues can be mitigated by introducing relaxation variables into the optimization problem; however, this compromises convergence to the desired equilibrium point. To address these challenges, we develop an approximate optimal approach to the safety-critical control problem in which the cost of violating safety constraints is directly embedded within the value function. We show that our method is capable of guaranteeing both safety and convergence to a desired equilibrium. Finally, we compare the performance of our method with that of the traditional quadratic programming approach through numerical examples.      
### 12.Phonological Features for 0-shot Multilingual Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.04107.pdf)
>  Code-switching---the intra-utterance use of multiple languages---is prevalent across the world. Within text-to-speech (TTS), multilingual models have been found to enable code-switching. By modifying the linguistic input to sequence-to-sequence TTS, we show that code-switching is possible for languages unseen during training, even within monolingual models. We use a small set of phonological features derived from the International Phonetic Alphabet (IPA), such as vowel height and frontness, consonant place and manner. This allows the model topology to stay unchanged for different languages, and enables new, previously unseen feature combinations to be interpreted by the model. We show that this allows us to generate intelligible, code-switched speech in a new language at test time, including the approximation of sounds never seen in training.      
### 13.Optimal multi-rate rigid body attitude estimation based on Lagrange-d'Alembert principle  [ :arrow_down: ](https://arxiv.org/pdf/2008.04104.pdf)
>  The rigid body attitude estimation problem under multi-rate measurements is treated using the discrete-time Lagrange-d'Alembert principle. Angular velocity measurements are assumed to be sampled at a higher rate compared to the direction vector measurements for attitude. The attitude determination problem from two or more vector measurements in the body-fixed frame is formulated as Wahba's problem. At instants when direction vector measurements are absent, a discrete-time model for attitude kinematics is used to propagate past measurements. A discrete-time Lagrangian is constructed as the difference between a kinetic energy-like term that is quadratic in the angular velocity estimation error and an artificial potential energy-like term obtained from Wahba's cost function. An additional dissipation term is introduced and the discrete-time Lagrange-d'Alembert principle is applied to the Lagrangian with this dissipation to obtain an optimal filtering scheme. A discrete-time Lyapunov analysis is carried out by constructing an appropriate discrete-time Lyapunov function. The analysis shows that the filtering scheme is exponentially stable in the absence of measurement noise and the domain of convergence is almost global. For a realistic evaluation of the scheme, numerical experiments are conducted with inputs corrupted by bounded measurement noise. These numerical simulations exhibit convergence of the estimated states to a bounded neighborhood of the actual states.      
### 14.mpNet: variable depth unfolded neural network for massive MIMO channel estimation  [ :arrow_down: ](https://arxiv.org/pdf/2008.04088.pdf)
>  Massive MIMO communication systems have a huge potential both in terms of data rate and energy efficiency, although channel estimation becomes challenging for a large number of antennas. Using a physical model allows to ease the problem by injecting a priori information based on the physics of propagation. However, such a model rests on simplifying assumptions and requires to know precisely the configuration of the system, which is unrealistic in practice. In this paper we present mpNet, an unfolded neural network specifically designed for massive MIMO channel estimation. It is trained online in an unsupervised way. Moreover, mpNet is computationally efficient and automatically adapts its depth to the SNR. The method we propose adds flexibility to physical channel models by allowing a base station to automatically correct its channel estimation algorithm based on incoming data, without the need for a separate offline training phase. It is applied to realistic millimeter wave channels and shows great performance, achieving a channel estimation error almost as low as one would get with a perfectly calibrated system. It also allows incident detection and automatic correction, making the base station resilient and able to automatically adapt to changes in its environment.      
### 15.Memcapacitors and Meminductors are Overunity Systems!  [ :arrow_down: ](https://arxiv.org/pdf/2008.04086.pdf)
>  It is rigorously proved that ideal memcapacitors and meminductors are not passive or lossless devices, nor are they satisfying the weaker notion of cyclo-passivity, which arises when dropping the requirement of non-negativity of the storage function. Equivalently, this implies that there exist excitation profiles that allow to extract more energy from the device than it is supplied with; so that their energy conversion efficiency exceeds 100%. This means that ideal memcapacitors and meminductors constitute so-called overunity systems. An illustrative mechanical analogue is provided that explicitly confirms this property. Hence, the question arises if ideal memcapacitors and meminductors will just remain some mathematical toys or artefacts.      
### 16.Safe and efficient collision avoidance control for autonomous vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2008.04080.pdf)
>  We study a novel principle for safe and efficient collision avoidance that adopts a mathematically elegant and general framework making as much as possible abstraction of the controlled vehicle's dynamics and of its environment. Vehicle dynamics is characterized by pre-computed functions for accelerating and braking to a given speed. Environment is modeled by a function of time giving the free distance ahead of the controlled vehicle under the assumption that the obstacles are either fixed or are moving in the same direction. The main result is a control policy enforcing the vehicle's speed so as to avoid collision and efficiently use the free distance ahead, provided some initial safety condition holds. The studied principle is applied to the design of two discrete controllers, one synchronous and another asynchronous. We show that both controllers are safe by construction. Furthermore, we show that their efficiency strictly increases for decreasing granularity of discretization. We present implementations of the two controllers, their experimental evaluation in the Carla autonomous driving simulator and investigate various performance issues.      
### 17.Subword Regularization: An Analysis of Scalability and Generalization for End-to-End Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.04034.pdf)
>  Subwords are the most widely used output units in end-to-end speech recognition. They combine the best of two worlds by modeling the majority of frequent words directly and at the same time allow open vocabulary speech recognition by backing off to shorter units or characters to construct words unseen during training. However, mapping text to subwords is ambiguous and often multiple segmentation variants are possible. Yet, many systems are trained using only the most likely segmentation. Recent research suggests that sampling subword segmentations during training acts as a regularizer for neural machine translation and speech recognition models, leading to performance improvements. In this work, we conduct a principled investigation on the regularizing effect of the subword segmentation sampling method for a streaming end-to-end speech recognition task. In particular, we evaluate the subword regularization contribution depending on the size of the training dataset. Our results suggest that subword regularization provides a consistent improvement of (2-8%) relative word-error-rate reduction, even in a large-scale setting with datasets up to a size of 20k hours. Further, we analyze the effect of subword regularization on recognition of unseen words and its implications on beam diversity.      
### 18.From private to public governance: The case for reconfiguring energy systems as a commons  [ :arrow_down: ](https://arxiv.org/pdf/2008.04028.pdf)
>  The discussions around the unsustainability of the dominant socio-economic structures have yet to produce solutions to address the escalating problems we face as a species. Such discussions, this paper argues, are hindered by the limited scope of the proposed solutions within a business-as-usual context as well as by the underlying technological rationale upon which these solutions are developed. In this paper, we conceptualize a radical sustainable alternative to the energy conundrum based on an emerging mode of production and a commons-based political economy. We propose a commons-oriented Energy Internet as a potential system for energy production and consumption, which may be better suited to tackle the current issues society faces. We conclude by referring to some of the challenges that the implementation of such a proposal would entail.      
### 19.An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI  [ :arrow_down: ](https://arxiv.org/pdf/2008.04024.pdf)
>  Computer-aided early diagnosis of Alzheimer's disease (AD) and its prodromal form mild cognitive impairment (MCI) based on structure Magnetic Resonance Imaging (sMRI) has provided a cost-effective and objective way for early prevention and treatment of disease progression, leading to improved patient care. In this work, we have proposed a novel computer-aided approach for early diagnosis of AD by introducing an explainable 3D Residual Attention Deep Neural Network (3D ResAttNet) for end-to-end learning from sMRI scans. Different from the existing approaches, the novelty of our approach is three-fold: 1) A Residual Self-Attention Deep Neural Network has been proposed to capture local, global and spatial information of MR images to improve diagnostic performance; 2) An explainable method using Gradient-based Localization Class Activation mapping (Grad-CAM) has been introduced to improve the explainable of the proposed method; 3) This work has provided a full end-to-end learning solution for automated disease diagnosis. Our proposed 3D ResAttNet method has been evaluated on a large cohort of subjects from real dataset for two changeling classification tasks (i.e. Alzheimer's disease (AD) vs. Normal cohort (NC) and progressive MCI (pMCI) vs. stable MCI (sMCI)). The experimental results show that the proposed approach outperforms the state-of-the-art models with significant performance improvement. The accuracy for AD vs. NC and sMCI vs. pMCI task are 97.1% and 84.1% respectively. The explainable mechanism in our approach regions is able to identify and highlight the contribution of the important brain parts (hippocampus, lateral ventricle and most parts of the cortex) for transparent decisions.      
### 20.Deterministic error bounds for kernel-based learning techniques under bounded noise  [ :arrow_down: ](https://arxiv.org/pdf/2008.04005.pdf)
>  We consider the problem of reconstructing a function from a finite set of noise-corrupted samples. Two kernel algorithms are analyzed, namely kernel ridge regression and $\varepsilon$-support vector regression. By assuming the ground-truth function belongs to the reproducing kernel Hilbert space of the chosen kernel, and the measurement noise affecting the dataset is bounded, we adopt an approximation theory viewpoint to establish \textit{deterministic} error bounds for the two models. Finally, we discuss their connection with Gaussian processes and two numerical examples are provided. In establishing our inequalities, we hope to help bring the fields of non-parametric kernel learning and robust control closer to each other.      
### 21.VAW-GAN for Singing Voice Conversion with Non-parallel Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.03992.pdf)
>  Singing voice conversion aims to convert singer's voice from source to target without changing singing content. Parallel training data is typically required for the training of singing voice conversion system, that is however not practical in real-life applications. Recent encoder-decoder structures, such as variational autoencoding Wasserstein generative adversarial network (VAW-GAN), provide an effective way to learn a mapping through non-parallel training data. In this paper, we propose a singing voice conversion framework that is based on VAW-GAN. We train an encoder to disentangle singer identity and singing prosody (F0 contour) from phonetic content. By conditioning on singer identity and F0, the decoder generates output spectral features with unseen target singer identity, and improves the F0 rendering. Experimental results show that the proposed framework achieves better performance than the baseline frameworks.      
### 22.Cooperative Communications for Internet of Everything in B5G/6G Hybrid and Ubiquitous Networks: Foundation and Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2008.03990.pdf)
>  Cooperative Communications (CC) has been one of most critical communication technologies which plays a founding role on Internet of Everything in B5G/6G networks. As 5G communications standard is gradually established recently, core communications technologies with CC are further studied to significantly improve communication quality and develop new communications scenarios for B5G/6G ubiquitous networks. Considering that CC has been regarded as foundation theory which widely exists in future multiple B5G/6G hybrid scenarios, such as, Cognitive Internet of Things (CIOT) networks, UAVs communications, air-space-ground of integrated networks, underwater acoustic communication and so on, besides it is closely combined with other key technologies, for examples, Massive MIMO, NOMA, Full-duplex transmission, Polar code and so on. Hence, in this paper we review foundation of CC for Internet of Everything in B5G/6G multiple heterogeneous CC networks, and compare fundamental CC algorithms to reveal key of performance improvement. Furthermore we propose that collective communications ideology is theory of foundation to realize communications for arbitrary two points as source/destination devices, sensors, relays, IOT nodes and so on in future.      
### 23.A model-guided deep network for limited-angle computed tomography  [ :arrow_down: ](https://arxiv.org/pdf/2008.03988.pdf)
>  In this paper, we first propose a variational model for the limited-angle computed tomography (CT) image reconstruction and then convert the model into an end-to-end deep network.We use the penalty method to solve the model and divide it into three iterative subproblems, where the first subproblem completes the sinograms by utilizing the prior information of sinograms in the frequency domain and the second refines the CT images by using the prior information of CT images in the spatial domain, and the last merges the outputs of the first two subproblems. In each iteration, we use the convolutional neural networks (CNNs) to approxiamte the solutions of the first two subproblems and, thus, obtain an end-to-end deep network for the limited-angle CT image reconstruction. Our network tackles both the sinograms and the CT images, and can simultaneously suppress the artifacts caused by the incomplete data and recover fine structural information in the CT images. Experimental results show that our method outperforms the existing algorithms for the limited-angle CT image reconstruction.      
### 24.Deep Learning from Dual-Energy Information for Whole-Heart Segmentation in Dual-Energy and Single-Energy Non-Contrast-Enhanced Cardiac CT  [ :arrow_down: ](https://arxiv.org/pdf/2008.03985.pdf)
>  Deep learning-based whole-heart segmentation in coronary CT angiography (CCTA) allows the extraction of quantitative imaging measures for cardiovascular risk prediction. Automatic extraction of these measures in patients undergoing only non-contrast-enhanced CT (NCCT) scanning would be valuable. In this work, we leverage information provided by a dual-layer detector CT scanner to obtain a reference standard in virtual non-contrast (VNC) CT images mimicking NCCT images, and train a 3D convolutional neural network (CNN) for the segmentation of VNC as well as NCCT images. Contrast-enhanced acquisitions on a dual-layer detector CT scanner were reconstructed into a CCTA and a perfectly aligned VNC image. In each CCTA image, manual reference segmentations of the left ventricular (LV) myocardium, LV cavity, right ventricle, left atrium, right atrium, ascending aorta, and pulmonary artery trunk were obtained and propagated to the corresponding VNC image. These VNC images and reference segmentations were used to train 3D CNNs for automatic segmentation in either VNC images or NCCT images. Automatic segmentations in VNC images showed good agreement with reference segmentations, with an average Dice similarity coefficient of 0.897 \pm 0.034 and an average symmetric surface distance of 1.42 \pm 0.45 mm. Volume differences [95% confidence interval] between automatic NCCT and reference CCTA segmentations were -19 [-67; 30] mL for LV myocardium, -25 [-78; 29] mL for LV cavity, -29 [-73; 14] mL for right ventricle, -20 [-62; 21] mL for left atrium, and -19 [-73; 34] mL for right atrium, respectively. In 214 (74%) NCCT images from an independent multi-vendor multi-center set, two observers agreed that the automatic segmentation was mostly accurate or better. This method might enable quantification of additional cardiac measures from NCCT images for improved cardiovascular risk prediction.      
### 25.Deep Self-Supervised Hierarchical Clustering for Speaker Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2008.03960.pdf)
>  The state-of-the-art speaker diarization systems use agglomerative hierarchical clustering (AHC) which performs the clustering of previously learned neural embeddings. While the clustering approach attempts to identify speaker clusters, the AHC algorithm does not involve any further learning. In this paper, we propose a novel algorithm for hierarchical clustering which combines the speaker clustering along with a representation learning framework. The proposed approach is based on principles of self-supervised learning where the self-supervision is derived from the clustering algorithm. The representation learning network is trained with a regularized triplet loss using the clustering solution at the current step while the clustering algorithm uses the deep embeddings from the representation learning step. By combining the self-supervision based representation learning along with the clustering algorithm, we show that the proposed algorithm improves significantly 29% relative improvement) over the AHC algorithm with cosine similarity for a speaker diarization task on CALLHOME dataset. In addition, the proposed approach also improves over the state-of-the-art system with PLDA affinity matrix with 10% relative improvement in DER.      
### 26.improving partition-block-based acoustic echo canceler in under-modeling scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2008.03944.pdf)
>  Recently, a partitioned-block-based frequency-domain Kalman filter (PFKF) has been proposed for acoustic echo cancellation. Compared with the normal frequency-domain Kalman filter, the PFKF utilizes the partitioned-block structure, resulting in both fast convergence and low time-latency. We present an analysis of the steady-state behavior of the PFKF and found that it suffers from a biased steady-state solution when the filter is of deficient length. Accordingly, we propose an effective modification that has the benefit of the guaranteed optimal steady-state behavior. Simulations are conducted to validate the improved performance of the proposed method.      
### 27.Joint Bandwidth Allocation and Path Selection in WANs with Path Cardinality Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2008.03942.pdf)
>  In this paper, we study a joint bandwidth allocation and path selection problem via solving a multi-objective minimization problem under the path cardinality constraints, namely MOPC. Our problem formulation captures various types of objectives including the proportional fairness, the total completion time, as well as the worst-case link utilization ratio. Such an optimization problem is very challenging since it is highly non-convex. Almost all existing works deal with such a problem using relaxation techniques to transform it to be a convex optimization problem. However, we provide a novel solution framework based on the classic alternating direction method of multipliers (ADMM) approach for solving this problem. Our proposed algorithm is simple and easy to be implemented. Each step of our algorithm consists of either finding the maximal root of a single-cubic equation which is guaranteed to have at least one positive solution or solving a one-dimensional convex subproblem in a fixed interval. Under some mild assumptions, we prove that any limiting point of the generated sequence under our proposed algorithm is a stationary point. Extensive numerical simulations are performed to demonstrate the advantages of our algorithm compared with various baselines.      
### 28.Leverage Point Identification Method for LAV-Based State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03941.pdf)
>  The state estimation problem can be solved through different methods. In terms of robustness, an effective approach is represented by the Least Absolute Value (LAV) estimator, though vulnerable to leverage points. Based on a previously proposed theorem, in this paper we enunciate, and rigorously demonstrate, a new lemma that proves the identifiability of leverage points in LAV-based state estimation. On the basis of these theoretical foundations, we propose an algorithm for leverage point identification whose performance is validated by means of extensive numerical simulations and compared against more traditional approaches, like Projection Statistics (PS). The obtained results confirm that the proposed method outperforms PS and represents a significant enhancement for LAV-based state estimators as it correctly identifies all the leverage points, independently of the accuracy or the presence of measurement gross errors. A dedicated application example with respect to power system state estimation is finally included and discussed.      
### 29.The Trajectory PHD Filter for Jump Markov System Models and Its Gaussian Mixture Implementation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03914.pdf)
>  The trajectory probability hypothesis density filter (TPHD) is capable of producing trajectory estimates in first principle without adding labels or tags. In this paper, we propose a new TPHD filter referred as MM-TPHD for jump Markov system (JMS) model that the highly dynamic targets movement switches between multiple models in multi-trajectory tracking. Firstly, we extend the concept of JMS to the multi-trajectory scenario of maneuvering target and derive the TPHD recursion for the proposed JMS model. Then, we develop the linear Gaussian Mixture (LGM) implementation of MM-TPHD recursion and also consider the L-scan computationally efficient implementations. Finally, simulation results in maneuvering multi-trajectory tracking demonstrate the performance of the proposed algorithm.      
### 30.Audio-visual Speaker Recognition with a Cross-modal Discriminative Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.03894.pdf)
>  Audio-visual speaker recognition is one of the tasks in the recent 2019 NIST speaker recognition evaluation (SRE). Studies in neuroscience and computer science all point to the fact that vision and auditory neural signals interact in the cognitive process. This motivated us to study a cross-modal network, namely voice-face discriminative network (VFNet) that establishes the general relation between human voice and face. Experiments show that VFNet provides additional speaker discriminative information. With VFNet, we achieve 16.54% equal error rate relative reduction over the score level fusion audio-visual baseline on evaluation set of 2019 NIST SRE.      
### 31.Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2008.03889.pdf)
>  Currently, most image quality assessment (IQA) models are supervised by the MAE or MSE loss with empirically slow convergence. It is well-known that normalization can facilitate fast convergence. Therefore, we explore normalization in the design of loss functions for IQA. Specifically, we first normalize the predicted quality scores and the corresponding subjective quality scores. Then, the loss is defined based on the norm of the differences between these normalized values. The resulting "Norm-in-Norm'' loss encourages the IQA model to make linear predictions with respect to subjective quality scores. After training, the least squares regression is applied to determine the linear mapping from the predicted quality to the subjective quality. It is shown that the new loss is closely connected with two common IQA performance criteria (PLCC and RMSE). Through theoretical analysis, it is proved that the embedded normalization makes the gradients of the loss function more stable and more predictable, which is conducive to the faster convergence of the IQA model. Furthermore, to experimentally verify the effectiveness of the proposed loss, it is applied to solve a challenging problem: quality assessment of in-the-wild images. Experiments on two relevant datasets (KonIQ-10k and CLIVE) show that, compared to MAE or MSE loss, the new loss enables the IQA model to converge about 10 times faster and the final model achieves better performance. The proposed model also achieves state-of-the-art prediction performance on this challenging problem. For reproducible scientific research, our code is publicly available at <a class="link-external link-https" href="https://github.com/lidq92/LinearityIQA" rel="external noopener nofollow">this https URL</a>.      
### 32.Mass-Matrix Differential-Algebraic Equation Formulation for Transient Stability Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03883.pdf)
>  This letter proposes a mass-matrix differential-algebraic equation (DAE) formulation for transient stability simulation. This formulation has two prominent advantages: compatible with a multitude of implicit DAE solvers and can be conveniently implemented based on the traditional formulation, for example, by separating the parameters in denominators into the diagonals of the mass matrix. It also allows reducing the dynamics using null time constants. Benchmark studies are presented on the time and accuracy of 17 implicit solvers for the proposed formulation using the Kundur's two-area system and a 2,000 bus system.      
### 33.Adaptive support driven Bayesian reweighted algorithm for sparse signal recovery  [ :arrow_down: ](https://arxiv.org/pdf/2008.03877.pdf)
>  Sparse learning has been widely studied to capture critical information from enormous data sources in the filed of system identification. Often, it is essential to understand internal working mechanisms of unknown systems (e.g. biological networks) in addition to input-output relationships. For this purpose, various feature selection techniques have been developed. For example, sparse Bayesian learning (SBL) was proposed to learn major features from a dictionary of basis functions, which makes identified models interpretable. Reweighted L1-regularization algorithms are often applied in SBL to solve optimization problems. However, they are expensive in both computation and memory aspects, thus not suitable for large-scale problems. This paper proposes an adaptive support driven Bayesian reweighted (ASDBR) algorithm for sparse signal recovery. A restart strategy based on shrinkage-thresholding is developed to conduct adaptive support estimate, which can effectively reduce computation burden and memory demands. Moreover, ASDBR accurately extracts major features and excludes redundant information from large datasets. Numerical experiments demonstrate the proposed algorithm outperforms state-of-the-art methods.      
### 34.Ordering for Communication-Efficient Quickest Change Detection in a Decomposable Graphical Model  [ :arrow_down: ](https://arxiv.org/pdf/2008.03871.pdf)
>  A quickest change detection problem is considered in a sensor network with observations whose statistical dependency structure across the sensors before and after the change is described by a decomposable graphical model (DGM). Distributed computation methods for this problem are proposed that are capable of producing the optimum centralized test statistic. The DGM leads to the proper way to collect nodes into local groups equivalent to cliques in the graph, such that a clique statistic which summarizes all the clique sensor data can be computed within each clique. The clique statistics are transmitted to a decision maker to produce the optimum centralized test statistic. In order to further improve communication efficiency, an ordered transmission approach is proposed where transmissions of the clique statistics to the fusion center are ordered and then adaptively halted when sufficient information is accumulated. This procedure is always guaranteed to provide the optimal change detection performance, despite not transmitting all the statistics from all the cliques. A lower bound on the average number of transmissions saved by ordered transmissions is provided and for the case where the change seldom occurs the lower bound approaches approximately half the number of cliques provided a well behaved distance measure between the distributions of the sensor observations before and after the change is sufficiently large. We also extend the approach to the case when the graph structure is different under each hypothesis. Numerical results show significant savings using the ordered transmission approach and validate the theoretical findings.      
### 35.SpeedySpeech: Efficient Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.03802.pdf)
>  While recent neural sequence-to-sequence models have greatly improved the quality of speech synthesis, there has not been a system capable of fast training, fast inference and high-quality audio synthesis at the same time. We propose a student-teacher network capable of high-quality faster-than-real-time spectrogram synthesis, with low requirements on computational resources and fast training time. We show that self-attention layers are not necessary for generation of high quality audio. We utilize simple convolutional blocks with residual connections in both student and teacher networks and use only a single attention layer in the teacher model. Coupled with a MelGAN vocoder, our model's voice quality was rated significantly higher than Tacotron 2. Our model can be efficiently trained on a single GPU and can run in real time even on a CPU. We provide both our source code and audio samples in our GitHub repository.      
### 36.Accurate Detection of Wake Word Start and End Using a CNN  [ :arrow_down: ](https://arxiv.org/pdf/2008.03790.pdf)
>  Small footprint embedded devices require keyword spotters (KWS) with small model size and detection latency for enabling voice assistants. Such a keyword is often referred to as \textit{wake word} as it is used to wake up voice assistant enabled devices. Together with wake word detection, accurate estimation of wake word endpoints (start and end) is an important task of KWS. In this paper, we propose two new methods for detecting the endpoints of wake words in neural KWS that use single-stage word-level neural networks. Our results show that the new techniques give superior accuracy for detecting wake words' endpoints of up to 50 msec standard error versus human annotations, on par with the conventional Acoustic Model plus HMM forced alignment. To our knowledge, this is the first study of wake word endpoints detection methods for single-stage neural KWS.      
### 37.Scalable Distributed Non-Convex ADMM-based Active Distribution System Service Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2008.03778.pdf)
>  Distributed restoration can harness distributed energy resources (DER) to enhance the resilience of active distribution networks. However, the large number of decision variables, especially the binary decision variables of reconfiguration, bring challenges on developing effective distributed distribution service restoration (DDSR) strategies. This paper proposes a scalable distributed optimization method based on the alternating direction method of multipliers (ADMM) for non-convex mixed-integer optimization problems and applies to develop the DDSR framework. The non-convex ADMM method consists of relax-drive-polish phases, 1) relaxing binary variables and applying the convex ADMM as a warm start; 2) driving the solutions toward Boolean values through a proximal operator; 3) fixing the obtained binary variables to polish continuous variables for a high-quality solution. Then, an autonomous clustering strategy together with consensus ADMM is developed to realize the distributed cluster-based framework of restoration. The nonconvex ADMM-based DDSR can determine DER scheduling and switch status for reconfiguration and load pickup in a distributed manner, energizing the out-of-service area from local faults or total blackouts in large-scale distribution networks. The effectiveness and scalability of the proposed DDSR framework are demonstrated through testing on the IEEE 123-node and IEEE 8500-node test feeders.      
### 38.Multiple Intelligent Reflecting Surfaces Assisted Secrue Transmissions in MISO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.03767.pdf)
>  Due to the broadcast nature of wireless communications, physical layer security has always been a fundamental but challenging concern. Fortunately, the recent advance of Intelligent Reflecting Surface (IRS) introduces another dimension for secure wireless communications by reconfiguring the transmission environments. In this paper, we devise secure transmission environments for multi-user MISO systems by collaboratively leveraging multiple IRSs. Specifically, achievable secrecy rate represents the amount of information per unit time that can be securely sent through a communication link, which is an important criterion for measuring secure communication. To guarantee the worst-case achievable secrecy rate among multiple legitimate users, we formulate a max-min problem and adopt an alternative optimization method to decouple multiple variables. Based on semidefinite relaxation and successive convex approximation, each sub-problem can be further converted into convex problem and easily solved. Extensive experimental results demonstrate that the proposed scheme can adapt to complex scenario for multiple users and achieve the significant gain in terms of achievable secrecy rate. To show the gap between the proposed problem and the traditional sum-rate problem, we also evaluate the performance sum-rate problem and make the comparison. The results show that performance of max-min problem converges to the performance of sum-rate problem in terms of the sum of secrecy rate with the increase of elements on IRSs.      
### 39.DFT-spread-OFDM Based Chirp Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2008.03766.pdf)
>  In this study, we propose a low-complexity transceiver for chirp-based communications by exploiting discrete Fourier transform-spread orthogonal frequency division multiplexing (DFT-s-OFDM). We show that a well-designed frequency-domain spectral shaping (FDSS) function for DFT-s-OFDM can convert its single-carrier nature to a linear combination of chirp signals circularly translated in the time domain. By utilizing Bessel functions and Fresnel integrals for FDSS coefficients, we synthesize modulated sinusoidal and linear chirps. We show that the chirp signals with low ripples in the frequency domain result in a lower bit-error ratio (BER) due to the less noise enhancement during the single-tap frequency-domain equalization (FDE). Numerical results indicate that the signal-to-noise ratio (SNR) degradation can be as high as 4 dB for sinusoidal chirps while it is approximately 0.5 dB for linear chirps as compared to DFT-s-OFDM without FDSS. The proposed scheme offers a way to efficiently generate chirp signals that can be used in Internet-of-Things (IoT) or radar applications with existing DFT-s-OFDM transceivers.      
### 40.Low-Light Maritime Image Enhancement with Regularized Illumination Optimization and Deep Noise Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2008.03765.pdf)
>  Maritime images captured under low-light imaging condition easily suffer from low visibility and unexpected noise, leading to negative effects on maritime traffic supervision and management. To promote imaging performance, it is necessary to restore the important visual information from degraded low-light images. In this paper, we propose to enhance the low-light images through regularized illumination optimization and deep noise suppression. In particular, a hybrid regularized variational model, which combines L0-norm gradient sparsity prior with structure-aware regularization, is presented to refine the coarse illumination map originally estimated using Max-RGB. The adaptive gamma correction method is then introduced to adjust the refined illumination map. Based on the assumption of Retinex theory, a guided filter-based detail boosting method is introduced to optimize the reflection map. The adjusted illumination and optimized reflection maps are finally combined to generate the enhanced maritime images. To suppress the effect of unwanted noise on imaging performance, a deep learning-based blind denoising framework is further introduced to promote the visual quality of enhanced image. In particular, this framework is composed of two sub-networks, i.e., E-Net and D-Net adopted for noise level estimation and non-blind noise reduction, respectively. The main benefit of our image enhancement method is that it takes full advantage of the regularized illumination optimization and deep blind denoising. Comprehensive experiments have been conducted on both synthetic and realistic maritime images to compare our proposed method with several state-of-the-art imaging methods. Experimental results have illustrated its superior performance in terms of both quantitative and qualitative evaluations.      
### 41.A methodology for the measurement of track geometry based on computer vision and inertial sensors  [ :arrow_down: ](https://arxiv.org/pdf/2008.03763.pdf)
>  This document describes the theory used for the calculation of track geometric irregularities on a Track Geometry Measuring System (TGMS) to be installed in railway vehicles. The TGMS includes a computer for data acquisition and process, a set of sensors including an inertial measuring unit (IMU, 3D gyroscope and 3D accelerometer), two video cameras and an encoder. The main features of the proposed system are: 1. It is capable to measure track alignment, vertical profile, cross-level, gauge, twist and rail-head profile using non-contact technology. 2. It can be installed in line railway vehicles. It is compact and low cost. Provided that the equipment sees the rail heads when the vehicle is moving, it can be installed in any body of the vehicle: at the wheelsets level, above primary suspension (bogie frame) or above the secondary suspension (car body).      
### 42.Linear and Deep Neural Network-based Receivers for Massive MIMO Systems with One-Bit ADCs  [ :arrow_down: ](https://arxiv.org/pdf/2008.03757.pdf)
>  The use of one-bit analog-to-digital converters (ADCs) is a practical solution for reducing cost and power consumption in massive Multiple-Input-Multiple-Output (MIMO) systems. However, the distortion caused by one-bit ADCs makes the data detection task much more challenging. In this paper, we propose a two-stage detection method for massive MIMO systems with one-bit ADCs. In the first stage, we propose several linear receivers based on the Bussgang decomposition, that show significant performance gain over existing linear receivers. Next, we reformulate the maximum-likelihood (ML) detection problem to address its non-robustness. Based on the reformulated ML detection problem, we propose a model-driven deep neural network-based (DNN-based) receiver, whose performance is comparable with an existing support vector machine-based receiver, albeit with a much lower computational complexity. A nearest-neighbor search method is then proposed for the second stage to refine the first stage solution. Unlike existing search methods that typically perform the search over a large candidate set, the proposed search method generates a limited number of most likely candidates and thus limits the search complexity. Numerical results confirm the low complexity, efficiency, and robustness of the proposed two-stage detection method.      
### 43.Cosine-Distance Virtual Adversarial Training for Semi-Supervised Speaker-Discriminative Acoustic Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2008.03756.pdf)
>  In this paper, we propose a semi-supervised learning (SSL) technique for training deep neural networks (DNNs) to generate speaker-discriminative acoustic embeddings (speaker embeddings). Obtaining large amounts of speaker recognition train-ing data can be difficult for desired target domains, especially under privacy constraints. The proposed technique reduces requirements for labelled data by leveraging unlabelled data. The technique is a variant of virtual adversarial training (VAT) [1] in the form of a loss that is defined as the robustness of the speaker embedding against input perturbations, as measured by the cosine-distance. Thus, we term the technique cosine-distance virtual adversarial training (CD-VAT). In comparison to many existing SSL techniques, the unlabelled data does not have to come from the same set of classes (here speakers) as the labelled data. The effectiveness of CD-VAT is shown on the 2750+ hour VoxCeleb data set, where on a speaker verification task it achieves a reduction in equal error rate (EER) of 11.1% relative to a purely supervised baseline. This is 32.5% of the improvement that would be achieved from supervised training if the speaker labels for the unlabelled data were available.      
### 44.Switching Loss for Generalized Nucleus Detection in Histopathology  [ :arrow_down: ](https://arxiv.org/pdf/2008.03750.pdf)
>  The accuracy of deep learning methods for two foundational tasks in medical image analysis -- detection and segmentation -- can suffer from class imbalance. We propose a `switching loss' function that adaptively shifts the emphasis between foreground and background classes. While the existing loss functions to address this problem were motivated by the classification task, the switching loss is based on Dice loss, which is better suited for segmentation and detection. Furthermore, to get the most out the training samples, we adapt the loss with each mini-batch, unlike previous proposals that adapt once for the entire training set. A nucleus detector trained using the proposed loss function on a source dataset outperformed those trained using cross-entropy, Dice, or focal losses. Remarkably, without retraining on target datasets, our pre-trained nucleus detector also outperformed existing nucleus detectors that were trained on at least some of the images from the target datasets. To establish a broad utility of the proposed loss, we also confirmed that it led to more accurate ventricle segmentation in MRI as compared to the other loss functions. Our GPU-enabled pre-trained nucleus detection software is also ready to process whole slide images right out-of-the-box and is usably fast.      
### 45.Underdetermined Blind Identification for $k$-Sparse Component Analysis using RANSAC-based Orthogonal Subspace Search  [ :arrow_down: ](https://arxiv.org/pdf/2008.03739.pdf)
>  Sparse component analysis is very popular in solving underdetermined blind source separation (UBSS) problem. Here, we propose a new underdetermined blind identification (UBI) approach for estimation of the mixing matrix in UBSS. Previous approaches either rely on single dominant component or consider $k \leq m-1$ active sources at each time instant, where $m$ is the number of mixtures, but impose constraint on the level of noise replacing inactive sources. Here, we propose an effective, computationally less complex, and more robust to noise UBI approach to tackle such restrictions when $k = m-1$ based on a two-step scenario: (1) estimating the orthogonal complement subspaces of the overall space and (2) identifying the mixing vectors. For this purpose, an integrated algorithm is presented to solve both steps based on Gram-Schmidt process and random sample consensus method. Experimental results using simulated data show more effectiveness of the proposed method compared with the existing algorithms.      
### 46.Disentangled Multidimensional Metric Learning for Music Similarity  [ :arrow_down: ](https://arxiv.org/pdf/2008.03720.pdf)
>  Music similarity search is useful for a variety of creative tasks such as replacing one music recording with another recording with a similar "feel", a common task in video editing. For this task, it is typically necessary to define a similarity metric to compare one recording to another. Music similarity, however, is hard to define and depends on multiple simultaneous notions of similarity (i.e. genre, mood, instrument, tempo). While prior work ignore this issue, we embrace this idea and introduce the concept of multidimensional similarity and unify both global and specialized similarity metrics into a single, semantically disentangled multidimensional similarity metric. To do so, we adapt a variant of deep metric learning called conditional similarity networks to the audio domain and extend it using track-based information to control the specificity of our model. We evaluate our method and show that our single, multidimensional model outperforms both specialized similarity spaces and alternative baselines. We also run a user-study and show that our approach is favored by human annotators as well.      
### 47.A Modular Approach for Synchronized Wireless Multimodal Multisensor Data Acquisition in Highly Dynamic Social Settings  [ :arrow_down: ](https://arxiv.org/pdf/2008.03715.pdf)
>  Existing data acquisition literature for human behavior research provides wired solutions, mainly for controlled laboratory setups. In uncontrolled free-standing conversation settings, where participants are free to walk around, these solutions are unsuitable. While wireless solutions are employed in the broadcasting industry, they can be prohibitively expensive. In this work, we propose a modular and cost-effective wireless approach for synchronized multisensor data acquisition of social human behavior. Our core idea involves a cost-accuracy trade-off by using Network Time Protocol (NTP) as a source reference for all sensors. While commonly used as a reference in ubiquitous computing, NTP is widely considered to be insufficiently accurate as a reference for video applications, where Precision Time Protocol (PTP) or Global Positioning System (GPS) based references are preferred. We argue and show, however, that the latency introduced by using NTP as a source reference is adequate for human behavior research, and the subsequent cost and modularity benefits are a desirable trade-off for applications in this domain. We also describe one instantiation of the approach deployed in a real-world experiment to demonstrate the practicality of our setup in-the-wild.      
### 48.Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2008.03710.pdf)
>  While deep learning has made impressive progress in speech synthesis and voice conversion, the assessment of the synthesized speech is still carried out by human participants. Several recent papers have proposed deep-learning-based assessment models and shown the potential to automate the speech quality assessment. To improve the previously proposed assessment model, MOSNet, we propose three models using cluster-based modeling methods: using a global quality token (GQT) layer, using an Encoding Layer, and using both of them. We perform experiments using the evaluation results of the Voice Conversion Challenge 2018 to predict the mean opinion score of synthesized speech and similarity score between synthesized speech and reference speech. The results show that the GQT layer helps to predict human assessment better by automatically learning the useful quality tokens for the task and that the Encoding Layer helps to utilize frame-level scores more precisely.      
### 49.LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.03687.pdf)
>  Speech synthesis (text to speech, TTS) and recognition (automatic speech recognition, ASR) are important speech tasks, and require a large amount of text and speech pairs for model training. However, there are more than 6,000 languages in the world and most languages are lack of speech training data, which poses significant challenges when building TTS and ASR systems for extremely low-resource languages. In this paper, we develop LRSpeech, a TTS and ASR system under the extremely low-resource setting, which can support rare languages with low data cost. LRSpeech consists of three key techniques: 1) pre-training on rich-resource languages and fine-tuning on low-resource languages; 2) dual transformation between TTS and ASR to iteratively boost the accuracy of each other; 3) knowledge distillation to customize the TTS model on a high-quality target-speaker voice and improve the ASR model on multiple voices. We conduct experiments on an experimental language (English) and a truly low-resource language (Lithuanian) to verify the effectiveness of LRSpeech. Experimental results show that LRSpeech 1) achieves high quality for TTS in terms of both intelligibility (more than 98% intelligibility rate) and naturalness (above 3.5 mean opinion score (MOS)) of the synthesized speech, which satisfy the requirements for industrial deployment, 2) achieves promising recognition accuracy for ASR, and 3) last but not least, uses extremely low-resource training data. We also conduct comprehensive analyses on LRSpeech with different amounts of data resources, and provide valuable insights and guidances for industrial deployment. We are currently deploying LRSpeech into a commercialized cloud speech service to support TTS on more rare languages.      
### 50.An Overview of Voice Conversion and its Challenges: From Statistical Modeling to Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03648.pdf)
>  Speaker identity is one of the important characteristics of human speech. In voice conversion, we change the speaker identity from one to another, while keeping the linguistic content unchanged. Voice conversion involves multiple speech processing techniques, such as speech analysis, spectral conversion, prosody conversion, speaker characterization, and vocoding. With the recent advances in theory and practice, we are now able to produce human-like voice quality with high speaker similarity. In this paper, we provide a comprehensive overview of the state-of-the-art of voice conversion techniques and their performance evaluation methods from the statistical approaches to deep learning, and discuss their promise and limitations. We will also report the recent Voice Conversion Challenges (VCC), the performance of the current state of technology, and provide a summary of the available resources for voice conversion research.      
### 51.Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images  [ :arrow_down: ](https://arxiv.org/pdf/2008.03632.pdf)
>  Anomaly detection in retinal image refers to the identification of abnormality caused by various retinal diseases/lesions, by only leveraging normal images in training phase. Normal images from healthy subjects often have regular structures (e.g., the structured blood vessels in the fundus image, or structured anatomy in optical coherence tomography image). On the contrary, the diseases and lesions often destroy these structures. Motivated by this, we propose to leverage the relation between the image texture and structure to design a deep neural network for anomaly detection. Specifically, we first extract the structure of the retinal images, then we combine both the structure features and the last layer features extracted from original health image to reconstruct the original input healthy image. The image feature provides the texture information and guarantees the uniqueness of the image recovered from the structure. In the end, we further utilize the reconstructed image to extract the structure and measure the difference between structure extracted from original and the reconstructed image. On the one hand, minimizing the reconstruction difference behaves like a regularizer to guarantee that the image is corrected reconstructed. On the other hand, such structure difference can also be used as a metric for normality measurement. The whole network is termed as P-Net because it has a ``P'' shape. Extensive experiments on RESC dataset and iSee dataset validate the effectiveness of our approach for anomaly detection in retinal images. Further, our method also generalizes well to novel class discovery in retinal images and anomaly detection in real-world images.      
### 52.One for Many: Transfer Learning for Building HVAC Control  [ :arrow_down: ](https://arxiv.org/pdf/2008.03625.pdf)
>  The design of building heating, ventilation, and air conditioning (HVAC) system is critically important, as it accounts for around half of building energy consumption and directly affects occupant comfort, productivity, and health. Traditional HVAC control methods are typically based on creating explicit physical models for building thermal dynamics, which often require significant effort to develop and are difficult to achieve sufficient accuracy and efficiency for runtime building control and scalability for field implementations. Recently, deep reinforcement learning (DRL) has emerged as a promising data-driven method that provides good control performance without analyzing physical models at runtime. However, a major challenge to DRL (and many other data-driven learning methods) is the long training time it takes to reach the desired performance. In this work, we present a novel transfer learning based approach to overcome this challenge. Our approach can effectively transfer a DRL-based HVAC controller trained for the source building to a controller for the target building with minimal effort and improved performance, by decomposing the design of neural network controller into a transferable front-end network that captures building-agnostic behavior and a back-end network that can be efficiently trained for each specific building. We conducted experiments on a variety of transfer scenarios between buildings with different sizes, numbers of thermal zones, materials and layouts, air conditioner types, and ambient weather conditions. The experimental results demonstrated the effectiveness of our approach in significantly reducing the training time, energy cost, and temperature violations.      
### 53.Speaker discrimination in humans and machines: Effects of speaking style variability  [ :arrow_down: ](https://arxiv.org/pdf/2008.03617.pdf)
>  Does speaking style variation affect humans' ability to distinguish individuals from their voices? How do humans compare with automatic systems designed to discriminate between voices? In this paper, we attempt to answer these questions by comparing human and machine speaker discrimination performance for read speech versus casual conversations. Thirty listeners were asked to perform a same versus different speaker task. Their performance was compared to a state-of-the-art x-vector/PLDA-based automatic speaker verification system. Results showed that both humans and machines performed better with style-matched stimuli, and human performance was better when listeners were native speakers of American English. Native listeners performed better than machines in the style-matched conditions (EERs of 6.96% versus 14.35% for read speech, and 15.12% versus 19.87%, for conversations), but for style-mismatched conditions, there was no significant difference between native listeners and machines. In all conditions, fusing human responses with machine results showed improvements compared to each alone, suggesting that humans and machines have different approaches to speaker discrimination tasks. Differences in the approaches were further confirmed by examining results for individual speakers which showed that the perception of distinct and confused speakers differed between human listeners and machines.      
### 54.Variable frame rate-based data augmentation to handle speaking-style variability for automatic speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.03616.pdf)
>  The effects of speaking-style variability on automatic speaker verification were investigated using the UCLA Speaker Variability database which comprises multiple speaking styles per speaker. An x-vector/PLDA (probabilistic linear discriminant analysis) system was trained with the SRE and Switchboard databases with standard augmentation techniques and evaluated with utterances from the UCLA database. The equal error rate (EER) was low when enrollment and test utterances were of the same style (e.g., 0.98% and 0.57% for read and conversational speech, respectively), but it increased substantially when styles were mismatched between enrollment and test utterances. For instance, when enrolled with conversation utterances, the EER increased to 3.03%, 2.96% and 22.12% when tested on read, narrative, and pet-directed speech, respectively. To reduce the effect of style mismatch, we propose an entropy-based variable frame rate technique to artificially generate style-normalized representations for PLDA adaptation. The proposed system significantly improved performance. In the aforementioned conditions, the EERs improved to 2.69% (conversation -- read), 2.27% (conversation -- narrative), and 18.75% (pet-directed -- read). Overall, the proposed technique performed comparably to multi-style PLDA adaptation without the need for training data in different speaking styles per speaker.      
### 55.Exploring the Use of an Unsupervised Autoregressive Model as a Shared Encoder for Text-Dependent Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.03615.pdf)
>  In this paper, we propose a novel way of addressing text-dependent automatic speaker verification (TD-ASV) by using a shared-encoder with task-specific decoders. An autoregressive predictive coding (APC) encoder is pre-trained in an unsupervised manner using both out-of-domain (LibriSpeech, VoxCeleb) and in-domain (DeepMine) unlabeled datasets to learn generic, high-level feature representation that encapsulates speaker and phonetic content. Two task-specific decoders were trained using labeled datasets to classify speakers (SID) and phrases (PID). Speaker embeddings extracted from the SID decoder were scored using a PLDA. SID and PID systems were fused at the score level. There is a 51.9% relative improvement in minDCF for our system compared to the fully supervised x-vector baseline on the cross-lingual DeepMine dataset. However, the i-vector/HMM method outperformed the proposed APC encoder-decoder system. A fusion of the x-vector/PLDA baseline and the SID/PLDA scores prior to PID fusion further improved performance by 15% indicating complementarity of the proposed approach to the x-vector system. We show that the proposed approach can leverage from large, unlabeled, data-rich domains, and learn speech patterns independent of downstream tasks. Such a system can provide competitive performance in domain-mismatched scenarios where test data is from data-scarce domains.      
### 56.Block Deep Neural Network-Based Signal Detector for Generalized Spatial Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03612.pdf)
>  Generalized Spatial Modulation (GSM) is being considered for high capacity and energy-efficient networks of the future. However, signal detection due to inter channel interference among the active antennas is a challenge in GSM systems and is the focus of this paper. Specifically, we explore the feasibility of using deep neural networks (DNN) for signal detection in GSM. In particular, we propose a block DNN (B-DNN) based architecture, where the active antennas and their transmitted constellation symbols are detected by smaller sub-DNNs. After $N$-ordinary DNN detection, the Euclidean distance-based soft constellation algorithm is implemented. The proposed B-DNN detector achieves a BER performance that is superior to traditional block zero-forcing (B-ZF) and block minimum mean-squared error (B-MMSE) detection schemes and similar to that of classical maximum likelihood (ML) detector. Further, the proposed method requires less computation time and is more accurate than alternative conventional numerical methods.      
### 57.Speech Driven Talking Face Generation from a Single Image and an Emotion Condition  [ :arrow_down: ](https://arxiv.org/pdf/2008.03592.pdf)
>  Visual emotion expression plays an important role in audiovisual speech communication. In this work, we propose a novel approach to rendering visual emotion expression in speech-driven talking face generation. Specifically, we design an end-to-end talking face generation system that takes a speech utterance, a single face image, and a categorical emotion label as input to render a talking face video in sync with the speech and expressing the condition emotion. Objective evaluation on image quality, audiovisual synchronization, and visual emotion expression shows that the proposed system outperforms a state-of-the-art baseline system. Subjective evaluation of visual emotion expression and video realness also demonstrates the superiority of the proposed system. Furthermore, we conduct a pilot study on human emotion recognition of generated videos with mismatched emotions between the audio and visual modalities, and results show that humans reply on the visual modality more significantly than the audio modality on this task.      
### 58.Extrapolating false alarm rates in automatic speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2008.03590.pdf)
>  Automatic speaker verification (ASV) vendors and corpus providers would both benefit from tools to reliably extrapolate performance metrics for large speaker populations without collecting new speakers. We address false alarm rate extrapolation under a worst-case model whereby an adversary identifies the closest impostor for a given target speaker from a large population. Our models are generative and allow sampling new speakers. The models are formulated in the ASV detection score space to facilitate analysis of arbitrary ASV systems.      
### 59.Maneuvering and robustness issues in undirected displacement-consensus-based formation control  [ :arrow_down: ](https://arxiv.org/pdf/2008.03544.pdf)
>  In this paper, we first propose a novel maneuvering technique compatible with displacement-consensus-based formation controllers. We show that the formation can be translated with an arbitrary velocity by modifying the weights in the consensus Laplacian matrix. In fact, we demonstrate that the displacement-consensus-based formation control is a particular case of our more general method. We then uncover robustness issues with undesired steady-state motions and resultant distorted shapes in undirected displacement-consensus-based formation control. In particular, these issues are triggered when neighboring agents mismeasure their relative positions, e.g., their onboard sensors are misaligned and have different scale factors. We will show that if all the sensing is close to perfect but different among the agents, then the stability of the system is compromised. Explicit expressions for the eventual non-desired velocity and shape's distortion are given as functions of the scale factors and misalignments for formations based on tree graphs.      
### 60.NPU Speaker Verification System for INTERSPEECH 2020 Far-Field Speaker Verification Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2008.03521.pdf)
>  This paper describes the NPU system submitted to Interspeech 2020 Far-Field Speaker Verification Challenge (FFSVC). We particularly focus on far-field text-dependent SV from single (task1) and multiple microphone arrays (task3). The major challenges in such scenarios are short utterance and cross-channel and distance mismatch for enrollment and test. With the belief that better speaker embedding can alleviate the effects from short utterance, we introduce a new speaker embedding architecture - ResNet-BAM, which integrates a bottleneck attention module with ResNet as a simple and efficient way to further improve the representation power of ResNet. This contribution brings up to 1% EER reduction. We further address the mismatch problem in three directions. First, domain adversarial training, which aims to learn domain-invariant features, can yield to 0.8% EER reduction. Second, front-end signal processing, including WPE and beamforming, has no obvious contribution, but together with data selection and domain adversarial training, can further contribute to 0.5% EER reduction. Finally, data augmentation, which works with a specifically-designed data selection strategy, can lead to 2% EER reduction. Together with the above contributions, in the middle challenge results, our single submission system (without multi-system fusion) achieves the first and second place on task 1 and task 3, respectively.      
### 61.Context Dependent RNNLM for Automatic Transcription of Conversations  [ :arrow_down: ](https://arxiv.org/pdf/2008.03517.pdf)
>  Conversational speech, while being unstructured at an utterance level, typically has a macro topic which provides larger context spanning multiple utterances. The current language models in speech recognition systems using recurrent neural networks (RNNLM) rely mainly on the local context and exclude the larger context. In order to model the long term dependencies of words across multiple sentences, we propose a novel architecture where the words from prior utterances are converted to an embedding. The relevance of these embeddings for the prediction of next word in the current sentence is found using a gating network. The relevance weighted context embedding vector is combined in the language model to improve the next word prediction, and the entire model including the context embedding and the relevance weighting layers is jointly learned for a conversational language modeling task. Experiments are performed on two conversational datasets - AMI corpus and the Switchboard corpus. In these tasks, we illustrate that the proposed approach yields significant improvements in language model perplexity over the RNNLM baseline. In addition, the use of proposed conversational LM for ASR rescoring results in absolute WER reduction of $1.2$\% on Switchboard dataset and $1.0$\% on AMI dataset over the RNNLM based ASR baseline.      
### 62.D-MEC: Discontinuous Mobile Edge Computing  [ :arrow_down: ](https://arxiv.org/pdf/2008.03508.pdf)
>  We propose a novel strategy for energy-efficient dynamic computation offloading, in the context of edge-computing-aided 5G (and beyond) networks. The goal is to minimize the energy consumption of the overall system, comprising users and network elements, under constraints on the end-to-end service delay and the packet error rate performance over the wireless interface. To reduce the energy consumption, we exploit low-power sleep operation modes for the users, the access point and the edge server, shifting the edge computing paradigm from an always on to an always available architecture, capable of guaranteeing an on-demand target service quality with the minimum energy consumption. To this aim, we propose Discontinuous Mobile Edge Computing (D-MEC): an online algorithm that dynamically and optimally orchestrates the sleep mode operations and the duty cycles of the network's elements. In such a dynamic framework, end-to-end delay constraints translate into constraints on overall queueing delays, including both the communication and the computation phases of the offloading service. D-MEC hinges on stochastic Lyapunov optimization, does not require any prior knowledge on the statistics of the offloading traffic or the radio channels, and satisfies the long-term performance constraints imposed by users. Several numerical results illustrate the advantages of the proposed method.      
### 63.JukeBox: A Multilingual Singer Recognition Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2008.03507.pdf)
>  A text-independent speaker recognition system relies on successfully encoding speech factors such as vocal pitch, intensity, and timbre to achieve good performance. A majority of such systems are trained and evaluated using spoken voice or everyday conversational voice data. Spoken voice, however, exhibits a limited range of possible speaker dynamics, thus constraining the utility of the derived speaker recognition models. Singing voice, on the other hand, covers a broader range of vocal and ambient factors and can, therefore, be used to evaluate the robustness of a speaker recognition system. However, a majority of existing speaker recognition datasets only focus on the spoken voice. In comparison, there is a significant shortage of labeled singing voice data suitable for speaker recognition research. To address this issue, we assemble \textit{JukeBox} - a speaker recognition dataset with multilingual singing voice audio annotated with singer identity, gender, and language labels. We use the current state-of-the-art methods to demonstrate the difficulty of performing speaker recognition on singing voice using models trained on spoken voice alone. We also evaluate the effect of gender and language on speaker recognition performance, both in spoken and singing voice data. The complete \textit{JukeBox} dataset can be accessed at <a class="link-external link-http" href="http://iprobe.cse.msu.edu/datasets/jukebox.html" rel="external noopener nofollow">this http URL</a>.      
### 64.Bidirectional Mapping Generative Adversarial Networks for Brain MR to PET Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.03483.pdf)
>  Fusing multi-modality medical images, such as MR and PET, can provide various anatomical or functional information about human body. But PET data is always unavailable due to different reasons such as cost, radiation, or other limitations. In this paper, we propose a 3D end-to-end synthesis network, called Bidirectional Mapping Generative Adversarial Networks (BMGAN), where image contexts and latent vector are effectively used and jointly optimized for brain MR-to-PET synthesis. Concretely, a bidirectional mapping mechanism is designed to embed the semantic information of PET images into the high dimensional latent space. And the 3D DenseU-Net generator architecture and the extensive objective functions are further utilized to improve the visual quality of synthetic results. The most appealing part is that the proposed method can synthesize the perceptually realistic PET images while preserving the diverse brain structures of different subjects. Experimental results demonstrate that the performance of the proposed method outperforms other competitive cross-modality synthesis methods in terms of quantitative measures, qualitative displays, and classification evaluation.      
### 65.Representation Learning via Cauchy Convolutional Sparse Coding  [ :arrow_down: ](https://arxiv.org/pdf/2008.03473.pdf)
>  In representation learning, Convolutional Sparse Coding (CSC) enables unsupervised learning of features by jointly optimising both an \(\ell_2\)-norm fidelity term and a sparsity enforcing penalty. This work investigates using a regularisation term derived from an assumed Cauchy prior for the coefficients of the feature maps of a CSC generative model. The sparsity penalty term resulting from this prior is solved via its proximal operator, which is then applied iteratively, element-wise, on the coefficients of the feature maps to optimise the CSC cost function. The performance of the proposed Iterative Cauchy Thresholding (ICT) algorithm in reconstructing natural images is compared against the common choice of \(\ell_1\)-norm optimised via soft and hard thresholding. ICT outperforms IHT and IST in most of these reconstruction experiments across various datasets, with an average PSNR of up to 11.30 and 7.04 above ISTA and IHT respectively.      
### 66.Complex Grey Matter Structure Segmentation in Brains via Deep Learning: Example of the Claustrum  [ :arrow_down: ](https://arxiv.org/pdf/2008.03465.pdf)
>  Segmentationand parcellation of the brain has been widely performed on brain MRI using atlas-based methods. However, segmentation of the claustrum, a thin and sheet-like structure between insular cortex and putamen has not been amenable to automatized segmentation, thus limiting its investigation in larger imaging cohorts. Recently, deep-learning based approaches have been introduced for automated segmentation of brain structures, yielding great potential to overcome preexisting limitations. In the following, we present a multi-view deep-learning based approach to segment the claustrum in T1-weighted MRI scans. We trained and evaluated the proposed method on 181 manual bilateral claustrum annotations by an expert neuroradiologist serving as reference standard. Cross-validation experiments yielded median volumetric similarity, robust Hausdor? distance and Dice score of 93.3%, 1.41mm and 71.8% respectively which represents equal or superior segmentation performance compared to human intra-rater reliability. Leave-one-scanner-out evaluation showed good transfer-ability of the algorithm to images from unseen scanners, however at slightly inferior performance. Furthermore, we found that AI-based claustrum segmentation benefits from multi-view information and requires sample sizes of around 75 MRI scans in the training set. In conclusion, the developed algorithm has large potential in independent study cohorts and to facilitate MRI-based research of the human claustrum through automated segmentation. The software and models of our method are made publicly available.      
### 67.Audio Spoofing Verification using Deep Convolutional Neural Networks by Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03464.pdf)
>  Automatic Speaker Verification systems are gaining popularity these days; spoofing attacks are of prime concern as they make these systems vulnerable. Some spoofing attacks like Replay attacks are easier to implement but are very hard to detect thus creating the need for suitable countermeasures. In this paper, we propose a speech classifier based on deep-convolutional neural network to detect spoofing attacks. Our proposed methodology uses acoustic time-frequency representation of power spectral densities on Mel frequency scale (Mel-spectrogram), via deep residual learning (an adaptation of ResNet-34 architecture). Using a single model system, we have achieved an equal error rate (EER) of 0.9056% on the development and 5.32% on the evaluation dataset of logical access scenario and an equal error rate (EER) of 5.87% on the development and 5.74% on the evaluation dataset of physical access scenario of ASVspoof 2019.      
### 68.Dimensionality Reduction via Diffusion Map Improved with Supervised Linear Projection  [ :arrow_down: ](https://arxiv.org/pdf/2008.03440.pdf)
>  When performing classification tasks, raw high dimensional features often contain redundant information, and lead to increased computational complexity and overfitting. In this paper, we assume the data samples lie on a single underlying smooth manifold, and define intra-class and inter-class similarities using pairwise local kernel distances. We aim to find a linear projection to maximize the intra-class similarities and minimize the inter-class similarities simultaneously, so that the projected low dimensional data has optimized pairwise distances based on the label information, which is more suitable for a Diffusion Map to do further dimensionality reduction. Numerical experiments on several benchmark datasets show that our proposed approaches are able to extract low dimensional discriminate features that could help us achieve higher classification accuracy.      
### 69.Auto-weighting for Breast Cancer Classification in Multimodal Ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2008.03435.pdf)
>  Breast cancer is the most common invasive cancer in women. Besides the primary B-mode ultrasound screening, sonographers have explored the inclusion of Doppler, strain and shear-wave elasticity imaging to advance the diagnosis. However, recognizing useful patterns in all types of images and weighing up the significance of each modality can elude less-experienced clinicians. In this paper, we explore, for the first time, an automatic way to combine the four types of ultrasonography to discriminate between benign and malignant breast nodules. A novel multimodal network is proposed, along with promising learnability and simplicity to improve classification accuracy. The key is using a weight-sharing strategy to encourage interactions between modalities and adopting an additional cross-modalities objective to integrate global information. In contrast to hardcoding the weights of each modality in the model, we embed it in a Reinforcement Learning framework to learn this weighting in an end-to-end manner. Thus the model is trained to seek the optimal multimodal combination without handcrafted heuristics. The proposed framework is evaluated on a dataset contains 1616 set of multimodal images. Results showed that the model scored a high classification accuracy of 95.4%, which indicates the efficiency of the proposed method.      
### 70.Recent Advances and New Guidelines on Hyperspectral and Multispectral Image Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2008.03426.pdf)
>  Hyperspectral image (HSI) with high spectral resolution often suffers from low spatial resolution owing to the limitations of imaging sensors. Image fusion is an effective and economical way to enhance the spatial resolution of HSI, which combines HSI with higher spatial resolution multispectral image (MSI) of the same scenario. In the past years, many HSI and MSI fusion algorithms are introduced to obtain high-resolution HSI. However, it lacks a full-scale review for the newly proposed HSI and MSI fusion approaches. To tackle this problem,this work gives a comprehensive review and new guidelines for HSI-MSI fusion. According to the characteristics of HSI-MSI fusion methods, they are categorized as four categories, including pan-sharpening based approaches, matrix factorization based approaches, tensor representation based approaches, and deep convolution neural network based approaches. We make a detailed introduction, discussions, and comparison for the fusion methods in each category. Additionally, the existing challenges and possible future directions for the HSI-MSI fusion are presented.      
### 71.Deep F-measure Maximization for End-to-End Speech Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2008.03425.pdf)
>  Spoken language understanding (SLU) datasets, like many other machine learning datasets, usually suffer from the label imbalance problem. Label imbalance usually causes the learned model to replicate similar biases at the output which raises the issue of unfairness to the minority classes in the dataset. In this work, we approach the fairness problem by maximizing the F-measure instead of accuracy in neural network model training. We propose a differentiable approximation to the F-measure and train the network with this objective using standard backpropagation. We perform experiments on two standard fairness datasets, Adult, and Communities and Crime, and also on speech-to-intent detection on the ATIS dataset and speech-to-image concept classification on the Speech-COCO dataset. In all four of these tasks, F-measure maximization results in improved micro-F1 scores, with absolute improvements of up to 8% absolute, as compared to models trained with the cross-entropy loss function. In the two multi-class SLU tasks, the proposed approach significantly improves class coverage, i.e., the number of classes with positive recall.      
### 72.Application of the Non-Hermitian Singular Spectrum Analysis to the exponential retrieval problem  [ :arrow_down: ](https://arxiv.org/pdf/2008.03413.pdf)
>  We present a new approach to solve the exponential retrieval problem. We derive a stable technique, based on the singular value decomposition (SVD) of lag-covariance and crosscovariance matrices consisting of covariance coefficients computed for index translated copies of an initial time series. For these matrices a generalized eigenvalue problem is solved. The initial signal is mapped into the basis of the generalized eigenvectors and phase portraits are consequently analyzed. Pattern recognition techniques could be applied to distinguish phase portraits related to the exponentials and noise. Each frequency is evaluated by unwrapping phases of the corresponding portrait, detecting potential wrapping events and estimation of the phase slope. Efficiency of the proposed and existing methods is compared on the set of examples, including the white Gaussian and auto-regressive model noise.      
### 73.Using PSPNet and UNet to analyze the internal parameter relationship and visualization of the convolutional neural network  [ :arrow_down: ](https://arxiv.org/pdf/2008.03411.pdf)
>  Convolutional neural network(CNN) has achieved great success in many fields, but due to the huge number of parameters, it is very difficult to study. Then, can we start from the parameters themselves to explore the relationship between the internal parameters of CNN? This paper proposes to use the convolution layer parameters substitution with the same convolution kernel setting to explore the relationship between the internal parameters of CNN and proposes to use the CNN visualization method to check the relationship. Using the visualization method, the forward propagation process of CNN is visualized. It is an intuitive representation of how CNN learns. According to the experiments, this paper believes that 1. Residual layer parameters of ResNet are correlated, and some layers can be substituted for each other; 2. Image segmentation is a process of first learning image texture features and then locating and segmentation.      
### 74.OCMR (v1.0)--Open-Access Dataset for Multi-Coil k-Space Data for Cardiovascular Magnetic Resonance Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2008.03410.pdf)
>  Cardiovascular MRI (CMR) is a non-invasive imaging modality that provides excellent soft-tissue contrast without the use of ionizing radiation. Physiological motions and limited speed of MRI data acquisition necessitate development of accelerated methods, which typically rely on undersampling. Recovering diagnostic quality CMR images from highly undersampled data has been an active area of research. Recently, several data acquisition and processing methods have been proposed to accelerate CMR. The availability of data to objectively evaluate and compare different reconstruction methods could expedite innovation and promote clinical translation of these methods. In this work, we introduce an open-access dataset, called OCMR, that provides multi-coil k-space data from 53 fully sampled and 212 prospectively undersampled cardiac cine series.      
### 75.Stacked 1D convolutional networks for end-to-end small footprint voice trigger detection  [ :arrow_down: ](https://arxiv.org/pdf/2008.03405.pdf)
>  We propose a stacked 1D convolutional neural network (S1DCNN) for end-to-end small footprint voice trigger detection in a streaming scenario. Voice trigger detection is an important speech application, with which users can activate their devices by simply saying a keyword or phrase. Due to privacy and latency reasons, a voice trigger detection system should run on an always-on processor on device. Therefore, having small memory and compute cost is crucial for a voice trigger detection system. Recently, singular value decomposition filters (SVDFs) has been used for end-to-end voice trigger detection. The SVDFs approximate a fully-connected layer with a low rank approximation, which reduces the number of model parameters. In this work, we propose S1DCNN as an alternative approach for end-to-end small-footprint voice trigger detection. An S1DCNN layer consists of a 1D convolution layer followed by a depth-wise 1D convolution layer. We show that the SVDF can be expressed as a special case of the S1DCNN layer. Experimental results show that the S1DCNN achieve 19.0% relative false reject ratio (FRR) reduction with a similar model size and a similar time delay compared to the SVDF. By using longer time delays, the S1DCNN further improve the FRR up to 12.2% relative.      
### 76.Word Error Rate Estimation Without ASR Output: e-WER2  [ :arrow_down: ](https://arxiv.org/pdf/2008.03403.pdf)
>  Measuring the performance of automatic speech recognition (ASR) systems requires manually transcribed data in order to compute the word error rate (WER), which is often time-consuming and expensive. In this paper, we continue our effort in estimating WER using acoustic, lexical and phonotactic features. Our novel approach to estimate the WER uses a multistream end-to-end architecture. We report results for systems using internal speech decoder features (glass-box), systems without speech decoder features (black-box), and for systems without having access to the ASR system (no-box). The no-box system learns joint acoustic-lexical representation from phoneme recognition results along with MFCC acoustic features to estimate WER. Considering WER per sentence, our no-box system achieves 0.56 Pearson correlation with the reference evaluation and 0.24 root mean square error (RMSE) across 1,400 sentences. The estimated overall WER by e-WER2 is 30.9% for a three hours test set, while the WER computed using the reference transcriptions was 28.5%.      
### 77.Controllable Neural Prosody Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2008.03388.pdf)
>  Speech synthesis has recently seen significant improvements in fidelity, driven by the advent of neural vocoders and neural prosody generators. However, these systems lack intuitive user controls over prosody, making them unable to rectify prosody errors (e.g., misplaced emphases and contextually inappropriate emotions) or generate prosodies with diverse speaker excitement levels and emotions. We address these limitations with a user-controllable, context-aware neural prosody generator. Given a real or synthesized speech recording, our model allows a user to input prosody constraints for certain time frames and generates the remaining time frames from input text and contextual prosody. We also propose a pitch-shifting neural vocoder to modify input speech to match the synthesized prosody. Through objective and subjective evaluations we show that we can successfully incorporate user control into our prosody generation model without sacrificing the overall naturalness of the synthesized speech.      
### 78.Comparative Evaluation Of Three Methods Of Automatic Segmentation Of Brain Structures Using 426 Cases  [ :arrow_down: ](https://arxiv.org/pdf/2008.03387.pdf)
>  Segmentation of brain structures in a large dataset of magnetic resonance images (MRI) necessitates automatic segmentation instead of manual tracing. Automatic segmentation methods provide a much-needed alternative to manual segmentation which is both labor intensive and time-consuming. Among brain structures, the hippocampus presents a challenging segmentation task due to its irregular shape, small size, and unclear edges. In this work, we use T1-weighted MRI of 426 subjects to validate the approach and compare three automatic segmentation methods: FreeSurfer, LocalInfo, and ABSS. Four evaluation measures are used to assess agreement between automatic and manual segmentation of the hippocampus. ABSS outperformed the others based on the Dice coefficient, precision, Hausdorff distance, ASSD, RMS, similarity, sensitivity, and volume agreement. Moreover, comparison of the segmentation results, acquired using 1.5T and 3T MRI systems, showed that ABSS is more sensitive than the others to the field inhomogeneity of 3T MRI.      
### 79.Classifying sleep-wake stages through recurrent neural networks using pulse oximetry signals  [ :arrow_down: ](https://arxiv.org/pdf/2008.03382.pdf)
>  The regulation of the autonomic nervous system changes with the sleep stages causing variations in the physiological variables. We exploit these changes with the aim of classifying the sleep stages in awake or asleep using pulse oximeter signals. We applied a recurrent neural network to heart rate and peripheral oxygen saturation signals to classify the sleep stage every 30 seconds. The network architecture consists of two stacked layers of bidirectional gated recurrent units (GRUs) and a softmax layer to classify the output. In this paper, we used 5000 patients from the Sleep Heart Health Study dataset. 2500 patients were used to train the network, and two subsets of 1250 were used to validate and test the trained models. In the test stage, the best result obtained was 90.13% accuracy, 94.13% sensitivity, 80.26% specificity, 92.05% precision, and 84.68% negative predictive value. Further, the Cohen's Kappa coefficient was 0.74 and the average absolute error percentage to the actual sleep time was 8.9%. The performance of the proposed network is comparable with the state-of-the-art algorithms when they use much more informative signals (except those with EEG).      
### 80.Rounded Hartley Transform: A Quasi-involution  [ :arrow_down: ](https://arxiv.org/pdf/2008.03379.pdf)
>  A new multiplication-free transform derived from DHT is introduced: the RHT. Investigations on the properties of the RHT led us to the concept of weak-inversion. Using new constructs, we show that RHT is not involutional like the DHT, but exhibits quasi-involutional property, a new definition derived from the periodicity of matrices. Thus instead of using the actual inverse transform, the RHT is viewed as an involutional transform, allowing the use of direct (multiplication-free) to evaluate the inverse. A fast algorithm to compute RHT is presented. This algorithm show embedded properties. We also extended RHT to the two-dimensional case. This permitted us to perform a preliminary analysis on the effects of RHT on images. Despite of some SNR loss, RHT can be very interesting for applications involving image monitoring associated to decision making, such as military applications or medical imaging.      
### 81.Classification of Huntington Disease using Acoustic and Lexical Features  [ :arrow_down: ](https://arxiv.org/pdf/2008.03367.pdf)
>  Speech is a critical biomarker for Huntington Disease (HD), with changes in speech increasing in severity as the disease progresses. Speech analyses are currently conducted using either transcriptions created manually by trained professionals or using global rating scales. Manual transcription is both expensive and time-consuming and global rating scales may lack sufficient sensitivity and fidelity. Ultimately, what is needed is an unobtrusive measure that can cheaply and continuously track disease progression. We present first steps towards the development of such a system, demonstrating the ability to automatically differentiate between healthy controls and individuals with HD using speech cues. The results provide evidence that objective analyses can be used to support clinical diagnoses, moving towards the tracking of symptomatology outside of laboratory and clinical environments.      
### 82.A New Approach to Accent Recognition and Conversion for Mandarin Chinese  [ :arrow_down: ](https://arxiv.org/pdf/2008.03359.pdf)
>  Two new approaches to accent classification and conversion are presented and explored, respectively. The first topic is Chinese accent classification/recognition. The second topic is the use of encoder-decoder models for end-to-end Chinese accent conversion, where the classifier in the first topic is used for the training of the accent converter encoder-decoder model. Experiments using different features and model are performed for accent recognition. These features include MFCCs and spectrograms. The classifier models were TDNN and 1D-CNN. On the MAGICDATA dataset with 5 classes of accents, the TDNN classifier trained on MFCC features achieved a test accuracy of 54% and a test F1 score of 0.54 while the 1D-CNN classifier trained on spectrograms achieve a test accuracy of 62% and a test F1 score of 0.62. A prototype of an end-to-end accent converter model is also presented. The converter model comprises of an encoder and a decoder. The encoder model converts an accented input into an accent-neutral form. The decoder model converts an accent-neutral form to an accented form with the specified accent assigned by the input accent label. The converter prototype preserves the tone and foregoes the details in the output audio. An encoder-decoder structure demonstrates the potential of being an effective accent converter. A proposal for future improvements is also presented to address the issue of lost details in the decoder output.      
### 83.X-Ray bone abnormalities detection using MURA dataset  [ :arrow_down: ](https://arxiv.org/pdf/2008.03356.pdf)
>  We introduce the deep network trained on the MURA dataset from the Stanford University released in 2017. Our system is able to detect bone abnormalities on the radiographs and visualise such zones. We found that our solution has the accuracy comparable to the best results that have been achieved by other development teams that used MURA dataset, in particular the overall Kappa score that was achieved by our team is about 0.942 on the wrist, 0.862 on the hand and o.735 on the shoulder (compared to the best available results to this moment on the official web-site 0.931, 0.851 and 0.729 accordingly). However, despite the good results there are a lot of directions for the future enhancement of the proposed technology. We see a big potential in the further development computer aided systems (CAD) for the radiographs as the one that will help practical specialists diagnose bone fractures as well as bone oncology cases faster and with the higher accuracy.      
### 84.Reliable Liver Fibrosis Assessment from Ultrasound using Global Hetero-Image Fusion and View-Specific Parameterization  [ :arrow_down: ](https://arxiv.org/pdf/2008.03352.pdf)
>  Ultrasound (US) is a critical modality for diagnosing liver fibrosis. Unfortunately, assessment is very subjective, motivating automated approaches. We introduce a principled deep convolutional neural network (CNN) workflow that incorporates several innovations. First, to avoid overfitting on non-relevant image features, we force the network to focus on a clinical region of interest (ROI), encompassing the liver parenchyma and upper border. Second, we introduce global heteroimage fusion (GHIF), which allows the CNN to fuse features from any arbitrary number of images in a study, increasing its versatility and flexibility. Finally, we use 'style'-based view-specific parameterization (VSP) to tailor the CNN processing for different viewpoints of the liver, while keeping the majority of parameters the same across views. Experiments on a dataset of 610 patient studies (6979 images) demonstrate that our pipeline can contribute roughly 7% and 22% improvements in partial area under the curve and recall at 90% precision, respectively, over conventional classifiers, validating our approach to this crucial problem.      
### 85.A Joint Framework for Audio Tagging and Weakly Supervised Acoustic Event Detection Using DenseNet with Global Average Pooling  [ :arrow_down: ](https://arxiv.org/pdf/2008.03350.pdf)
>  This paper proposes a network architecture mainly designed for audio tagging, which can also be used for weakly supervised acoustic event detection (AED). The proposed network consists of a modified DenseNet as the feature extractor, and a global average pooling (GAP) layer to predict frame-level labels at inference time. This architecture is inspired by the work proposed by Zhou et al., a well-known framework using GAP to localize visual objects given image-level labels. While most of the previous works on weakly supervised AED used recurrent layers with attention-based mechanism to localize acoustic events, the proposed network directly localizes events using the feature map extracted by DenseNet without any recurrent layers. In the audio tagging task of DCASE 2017, our method significantly outperforms the state-of-the-art method in F1 score by 5.3% on the dev set, and 6.0% on the eval set in terms of absolute values. For weakly supervised AED task in DCASE 2018, our model outperforms the state-of-the-art method in event-based F1 by 8.1% on the dev set, and 0.5% on the eval set in terms of absolute values, by using data augmentation and tri-training to leverage unlabeled data.      
### 86.Linear Parameter-Varying Subspace Identification: A Unified Framework  [ :arrow_down: ](https://arxiv.org/pdf/2008.03347.pdf)
>  In this paper, we establish a unified framework for subspace identification (SID) of linear parameter-varying (LPV) systems to estimate LPV state-space (SS) models in innovation form. This framework enables us to derive novel LPV SID schemes that are extensions of existing linear time-invariant (LTI) methods. More specifically, we derive the open-loop, closed-loop, and predictor-based data-equations, an input-output surrogate form of the SS representation, by systematically establishing an LPV subspace identification theory. We show the additional challenges of the LPV setting compared to the LTI case. Based on the data-equations, several methods are proposed to estimate LPV-SS models based on a maximum-likelihood or a realization based argument. Furthermore, the established theoretical framework for the LPV subspace identification problem allows us to lower the number of to-be-estimated parameters and to overcome dimensionality problems of the involved matrices, leading to a decrease in the computational complexity of LPV SIDs in general. To the authors' knowledge, this paper is the first in-depth examination of the LPV subspace identification problem. The effectiveness of the proposed subspace identification methods are demonstrated and compared with existing methods in a Monte Carlo study of identifying a benchmark MIMO LPV system.      
### 87.Generative Adversarial Network for Radar Signal Generation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03346.pdf)
>  A major obstacle in radar based methods for concealed object detection on humans and seamless integration into security and access control system is the difficulty in collecting high quality radar signal data. Generative adversarial networks (GAN) have shown promise in data generation application in the fields of image and audio processing. As such, this paper proposes the design of a GAN for application in radar signal generation. Data collected using the Finite-Difference Time-Domain (FDTD) method on three concealed object classes (no object, large object, and small object) were used as training data to train a GAN to generate radar signal samples for each class. The proposed GAN generated radar signal data which was indistinguishable from the training data by qualitative human observers.      
### 88.Deep Learning Based Dereverberation of Temporal Envelopesfor Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2008.03339.pdf)
>  Automatic speech recognition in reverberant conditions is a challenging task as the long-term envelopes of the reverberant speech are temporally smeared. In this paper, we propose a neural model for enhancement of sub-band temporal envelopes for dereverberation of speech. The temporal envelopes are derived using the autoregressive modeling framework of frequency domain linear prediction (FDLP). The neural enhancement model proposed in this paper performs an envelop gain based enhancement of temporal envelopes and it consists of a series of convolutional and recurrent neural network layers. The enhanced sub-band envelopes are used to generate features for automatic speech recognition (ASR). The ASR experiments are performed on the REVERB challenge dataset as well as the CHiME-3 dataset. In these experiments, the proposed neural enhancement approach provides significant improvements over a baseline ASR system with beamformed audio (average relative improvements of 21% on the development set and about 11% on the evaluation set in word error rates for REVERB challenge dataset).      
### 89.Evaluating Load Models and Their Impacts on Power Transfer Limits  [ :arrow_down: ](https://arxiv.org/pdf/2008.03336.pdf)
>  Power transfer limits or transfer capability (TC) directly relate to the system operation and control as well as electricity markets. As a consequence, their assessment has to comply with static constraints, such as line thermal limits, and dynamic constraints, such as transient stability limits, voltage stability limits and small-signal stability limits. Since the load dynamics have substantial impacts on power system transient stability, load models are one critical factor that affects the power transfer limits. Currently, multiple load models have been proposed and adopted in the industry and academia, including the ZIP model, ZIP plus induction motor composite model (ZIP + IM) and WECC composite load model (WECC CLM). Each of them has its unique advantages, but their impacts on the power transfer limits are not yet adequately addressed. One existing challenge is fitting the high-order nonlinear models such as WECC CLM. In this study, we innovatively adopt double deep Q-learning Network (DDQN) agent as a general load modeling tool in the dynamic assessment procedure and fit the same transient field measurements into different load models. A comprehensive evaluation is then conducted to quantify the load models' impacts on the power transfer limits. The simulation environment is the IEEE-39 bus system constructed in Transient Security Assessment Tool (TSAT).      
### 90.Self-Supervised Learning of Audio-Visual Objects from Video  [ :arrow_down: ](https://arxiv.org/pdf/2008.04237.pdf)
>  Our objective is to transform a video into a set of discrete audio-visual objects using self-supervised learning. To this end, we introduce a model that uses attention to localize and group sound sources, and optical flow to aggregate information over time. We demonstrate the effectiveness of the audio-visual object embeddings that our model learns by using them for four downstream speech-oriented tasks: (a) multi-speaker sound source separation, (b) localizing and tracking speakers, (c) correcting misaligned audio-visual data, and (d) active speaker detection. Using our representation, these tasks can be solved entirely by training on unlabeled video, without the aid of object detectors. We also demonstrate the generality of our method by applying it to non-human speakers, including cartoons and puppets.Our model significantly outperforms other self-supervised approaches, and obtains performance competitive with methods that use supervised face detection.      
### 91.An improved convergence analysis for decentralized online stochastic non-convex optimization  [ :arrow_down: ](https://arxiv.org/pdf/2008.04195.pdf)
>  In this paper, we study decentralized online stochastic non-convex optimization over a network of nodes. Integrating a technique called gradient tracking in decentralized stochastic gradient descent (DSGD), we show that the resulting algorithm, GT-DSGD, exhibits several important characteristics towards minimizing a sum of smooth non-convex functions. The main results of this paper can be divided into two categories: <br>(1) For general smooth non-convex functions, we establish a non-asymptotic characterization of GT-DSGD and derive the conditions under which it achieves network-independent performance and matches centralized minibatch SGD. In comparison, the existing results suggest that the performance of GT-DSGD is always network-dependent and is therefore strictly worse than that of centralized minibatch SGD. <br>(2) When the global function additionally satisfies the Polyak-Lojasiewics condition, we derive the exponential stability range for GT-DSGD under a constant step-size up to a steady-state error. Under stochastic approximation step-sizes, we establish, for the first time, the optimal global sublinear convergence rate on almost every sample path, in addition to the convergence rate in mean. Since strongly convex functions are a special case of this class of problems, our results are not only immediately applicable but also improve the currently known best convergence rates and their dependence on problem parameters.      
### 92.Deep Q-Network Based Multi-agent Reinforcement Learning with Binary Action Agents  [ :arrow_down: ](https://arxiv.org/pdf/2008.04109.pdf)
>  Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement learning (RL) use various schemes where in the agents have to learn and communicate. The learning is however specific to each agent and communication may be satisfactorily designed for the agents. As more complex Deep QNetworks come to the fore, the overall complexity of the multi-agent system increases leading to issues like difficulty in training, need for higher resources and more training time, difficulty in fine-tuning, etc. To address these issues we propose a simple but efficient DQN based MAS for RL which uses shared state and rewards, but agent-specific actions, for updation of the experience replay pool of the DQNs, where each agent is a DQN. The benefits of the approach are overall simplicity, faster convergence and better performance as compared to conventional DQN based approaches. It should be noted that the method can be extended to any DQN. As such we use simple DQN and DDQN (Double Q-learning) respectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment) , LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized environment). The proposed approach outperforms the baseline on these tasks by decent margins respectively.      
### 93.Cloud Fog Architectures in 6G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.04004.pdf)
>  Prior to the advent of the cloud, storage and processing services were accommodated by specialized hardware, however, this approach introduced a number of challenges in terms of scalability, energy efficiency, and cost. Then came the concept of cloud computing, where to some extent, the issue of massive storage and computation was dealt with by centralized data centers that are accessed via the core network. The cloud has remained with us thus far, however, this has introduced further challenges among which, latency and energy efficiency are of the pinnacle. With the increase in embedded devices intelligence came the concept of the Fog. The availability of massive numbers of storage and computational devices at the edge of the network, where some are owned and deployed by the end-users themselves but most by service operators. This means that cloud services are pushed further out from the core towards the edge of the network, hence reduced latency is achieved. Fog nodes are massively distributed in the network, some benefit from wired connections, and others are connected via wireless links. The question of where to allocate services remains an important task and requires extensive attention. This chapter introduces and evaluates cloud fog architectures in 6G networks paying special attention to latency, energy efficiency, scalability, and the trade-offs between distributed and centralized processing resources.      
### 94.Deep Learning for Joint Channel Estimation and Signal Detection in OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.03977.pdf)
>  In this paper, we propose a novel deep learning based approach for joint channel estimation and signal detection in orthogonal frequency division multiplexing (OFDM) systems by exploring the time and frequency correlation of wireless fading channels. Specifically, a Channel Estimation Network (CENet) is designed to replace the conventional interpolation procedure in pilot-aided estimation scheme. Then, based on the outcome of the CENet, a Channel Conditioned Recovery Network (CCRNet) is designed to recover the transmit signal. Experimental results demonstrate that CENet and CCRNet achieve superior performance compared with conventional estimation and detection methods. In addition, both networks are shown to be robust to the variation of parameter chances, which makes them appealing for practical implementation.      
### 95.DQI: A Guide to Benchmark Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2008.03964.pdf)
>  A `state of the art' model A surpasses humans in a benchmark B, but fails on similar benchmarks C, D, and E. What does B have that the other benchmarks do not? Recent research provides the answer: spurious bias. However, developing A to solve benchmarks B through E does not guarantee that it will solve future benchmarks. To progress towards a model that `truly learns' an underlying task, we need to quantify the differences between successive benchmarks, as opposed to existing binary and black-box approaches. We propose a novel approach to solve this underexplored task of quantifying benchmark quality by debuting a data quality metric: DQI.      
### 96.Knowledge Distillation and Data Selection for Semi-Supervised Learning in CTC Acoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2008.03923.pdf)
>  Semi-supervised learning (SSL) is an active area of research which aims to utilize unlabelled data in order to improve the accuracy of speech recognition systems. The current study proposes a methodology for integration of two key ideas: 1) SSL using connectionist temporal classification (CTC) objective and teacher-student based learning 2) Designing effective data-selection mechanisms for leveraging unlabelled data to boost performance of student models. Our aim is to establish the importance of good criteria in selecting samples from a large pool of unlabelled data based on attributes like confidence measure, speaker and content variability. The question we try to answer is: Is it possible to design a data selection mechanism which reduces dependence on a large set of randomly selected unlabelled samples without compromising on Word Error Rate (WER)? We perform empirical investigations of different data selection methods to answer this question and quantify the effect of different sampling strategies. On a semi-supervised ASR setting with 40000 hours of carefully selected unlabelled data, our CTC-SSL approach gives 17% relative WER improvement over a baseline CTC system trained with labelled data. It also achieves on-par performance with CTC-SSL system trained on order of magnitude larger unlabeled data based on random sampling.      
### 97.Online Optimization of Switched LTI Systems Using Continuous-Time and Hybrid Accelerated Gradient Flows  [ :arrow_down: ](https://arxiv.org/pdf/2008.03903.pdf)
>  This paper studies the design of feedback controllers that steer the output of a switched linear time-invariant system to the solution of a possibly time-varying optimization problem. The design of the feedback controllers is based on an online gradient descent method, and an online hybrid controller that can be seen as a regularized Nesterov's accelerated gradient method. Both of the proposed approaches accommodate output measurements of the plant, and are implemented in closed-loop with the switched dynamical system. By design, the controllers continuously steer the system output to an optimal trajectory implicitly defined by the time-varying optimization problem without requiring knowledge of exogenous inputs and disturbances. For cost functions that are smooth and satisfy the Polyak-Lojasiewicz inequality, we demonstrate that the online gradient descent controller ensures uniform global exponential stability when the time-scales of the plant and the controller are sufficiently separated and the switching signal of the plant is slow on the average. Under a strong convexity assumption, we also show that the online hybrid Nesterov's method guarantees tracking of optimal trajectories, and outperforms online controllers based on gradient descent. Interestingly, the proposed hybrid accelerated controller resolves the potential lack of robustness suffered by standard continuous-time accelerated gradient methods when coupled with a dynamical system. When the function is not strongly convex, we establish global practical asymptotic stability results for the accelerated method, and we unveil the existence of a trade-off between acceleration and exact convergence in online optimization problems with controllers using dynamic momentum. Our theoretical results are illustrated via different numerical examples.      
### 98.IF-Net: An Illumination-invariant Feature Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.03897.pdf)
>  Feature descriptor matching is a critical step is many computer vision applications such as image stitching, image retrieval and visual localization. However, it is often affected by many practical factors which will degrade its performance. Among these factors, illumination variations are the most influential one, and especially no previous descriptor learning works focus on dealing with this problem. In this paper, we propose IF-Net, aimed to generate a robust and generic descriptor under crucial illumination changes conditions. We find out not only the kind of training data important but also the order it is presented. To this end, we investigate several dataset scheduling methods and propose a separation training scheme to improve the matching accuracy. Further, we propose a ROI loss and hard-positive mining strategy along with the training scheme, which can strengthen the ability of generated descriptor dealing with large illumination change conditions. We evaluate our approach on public patch matching benchmark and achieve the best results compared with several state-of-the-arts methods. To show the practicality, we further evaluate IF-Net on the task of visual localization under large illumination changes scenes, and achieves the best localization accuracy.      
### 99.Polarization-independent reconfigurable frequency selective rasorber/absorber with low insertion loss  [ :arrow_down: ](https://arxiv.org/pdf/2008.03882.pdf)
>  A polarization-independent reconfigurable frequency selective rasorber (FSR)/absorber with low insertion loss based on diodes is proposed in this paper. The presented structure consists of a lossy layer based on square loops and a bandpass frequency-selective surface. These two layers are separated by an air layer. Each layer has an embedded bias network that provides the bias voltage to the diodes through metallic via. This configuration can avoid undesirable effects associated with the additional biasing wire. When the diodes are in off-state, the structure is in FSR mode and exhibits a transmission window at 4.28GHz with only 0.69dB insertion loss (IL) within the absorption bands. While diodes are in on-state and the structure switches to absorber mode, it achieves perfect absorption with absorptivity of over 90% ranging from 2.8 to 5.2 GHz. An equivalent circuit model (ECM) is developed to analyse the physical mechanism of the structure. A prototype of the proposed architecture is fabricated and measured, where reasonable agreements between simulations and measurements are observed, verifying the effectiveness of this design.      
### 100.Nighttime Dehazing with a Synthetic Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2008.03864.pdf)
>  Increasing the visibility of nighttime hazy images is challenging because of uneven illumination from active artificial light sources and haze absorbing/scattering. The absence of large-scale benchmark datasets hampers progress in this area. To address this issue, we propose a novel synthetic method called 3R to simulate nighttime hazy images from daytime clear images, which first reconstructs the scene geometry, then simulates the light rays and object reflectance, and finally renders the haze effects. Based on it, we generate realistic nighttime hazy images by sampling real-world light colors from a prior empirical distribution. Experiments on the synthetic benchmark show that the degrading factors jointly reduce the image quality. To address this issue, we propose an optimal-scale maximum reflectance prior to disentangle the color correction from haze removal and address them sequentially. Besides, we also devise a simple but effective learning-based baseline which has an encoder-decoder structure based on the MobileNet-v2 backbone. Experiment results demonstrate their superiority over state-of-the-art methods in terms of both image quality and runtime. Both the dataset and source code will be available at \url{<a class="link-external link-https" href="https://github.com/chaimi2013/3R" rel="external noopener nofollow">this https URL</a>}.      
### 101.Dual In-painting Model for Unsupervised Gaze Correction and Animation in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2008.03834.pdf)
>  In this paper we address the problem of unsupervised gaze correction in the wild, presenting a solution that works without the need for precise annotations of the gaze angle and the head pose. We have created a new dataset called CelebAGaze, which consists of two domains X, Y, where the eyes are either staring at the camera or somewhere else. Our method consists of three novel modules: the Gaze Correction module (GCM), the Gaze Animation module (GAM), and the Pretrained Autoencoder module (PAM). Specifically, GCM and GAM separately train a dual in-painting network using data from the domain $X$ for gaze correction and data from the domain $Y$ for gaze animation. Additionally, a Synthesis-As-Training method is proposed when training GAM to encourage the features encoded from the eye region to be correlated with the angle information, resulting in a gaze animation which can be achieved by interpolation in the latent space. To further preserve the identity information~(e.g., eye shape, iris color), we propose the PAM with an Autoencoder, which is based on Self-Supervised mirror learning where the bottleneck features are angle-invariant and which works as an extra input to the dual in-painting models. Extensive experiments validate the effectiveness of the proposed method for gaze correction and gaze animation in the wild and demonstrate the superiority of our approach in producing more compelling results than state-of-the-art baselines. Our code, the pretrained models and the supplementary material are available at: <a class="link-external link-https" href="https://github.com/zhangqianhui/GazeAnimation" rel="external noopener nofollow">this https URL</a>.      
### 102.Distilling the Knowledge of BERT for Sequence-to-Sequence ASR  [ :arrow_down: ](https://arxiv.org/pdf/2008.03822.pdf)
>  Attention-based sequence-to-sequence (seq2seq) models have achieved promising results in automatic speech recognition (ASR). However, as these models decode in a left-to-right way, they do not have access to context on the right. We leverage both left and right context by applying BERT as an external language model to seq2seq ASR through knowledge distillation. In our proposed method, BERT generates soft labels to guide the training of seq2seq ASR. Furthermore, we leverage context beyond the current utterance as input to BERT. Experimental evaluations show that our method significantly improves the ASR performance from the seq2seq baseline on the Corpus of Spontaneous Japanese (CSJ). Knowledge distillation from BERT outperforms that from a transformer LM that only looks at left context. We also show the effectiveness of leveraging context beyond the current utterance. Our method outperforms other LM application approaches such as n-best rescoring and shallow fusion, while it does not require extra inference cost.      
### 103.Can I lift it? Humanoid robot reasoning about the feasibility of lifting a heavy box with unknown physical properties  [ :arrow_down: ](https://arxiv.org/pdf/2008.03801.pdf)
>  A robot cannot lift up an object if it is not feasible to do so. However, in most research on robot lifting, "feasibility" is usually presumed to exist a priori. This paper proposes a three-step method for a humanoid robot to reason about the feasibility of lifting a heavy box with physical properties that are unknown to the robot. Since feasibility of lifting is directly related to the physical properties of the box, we first discretize a range for the unknown values of parameters describing these properties and tabulate all valid optimal quasi-static lifting trajectories generated by simulations over all combinations of indices. Second, a physical-interaction-based algorithm is introduced to identify the robust gripping position and physical parameters corresponding to the box. During this process, the stability and safety of the robot are ensured. On the basis of the above two steps, a third step of mapping operation is carried out to best match the estimated parameters to the indices in the table. The matched indices are then queried to determine whether a valid trajectory exists. If so, the lifting motion is feasible; otherwise, the robot decides that the task is beyond its capability. Our method efficiently evaluates the feasibility of a lifting task through simple interactions between the robot and the box, while simultaneously obtaining the desired safe and stable trajectory. We successfully demonstrated the proposed method using a NAO humanoid robot.      
### 104.Metric Learning vs Classification for Disentangled Music Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03729.pdf)
>  Deep representation learning offers a powerful paradigm for mapping input data onto an organized embedding space and is useful for many music information retrieval tasks. Two central methods for representation learning include deep metric learning and classification, both having the same goal of learning a representation that can generalize well across tasks. Along with generalization, the emerging concept of disentangled representations is also of great interest, where multiple semantic concepts (e.g., genre, mood, instrumentation) are learned jointly but remain separable in the learned representation space. In this paper we present a single representation learning framework that elucidates the relationship between metric learning, classification, and disentanglement in a holistic manner. For this, we (1) outline past work on the relationship between metric learning and classification, (2) extend this relationship to multi-label data by exploring three different learning approaches and their disentangled versions, and (3) evaluate all models on four tasks (training time, similarity retrieval, auto-tagging, and triplet prediction). We find that classification-based models are generally advantageous for training time, similarity retrieval, and auto-tagging, while deep metric learning exhibits better performance for triplet-prediction. Finally, we show that our proposed approach yields state-of-the-art results for music auto-tagging.      
### 105.Block Shuffle: A Method for High-resolution Fast Style Transfer with Limited Memory  [ :arrow_down: ](https://arxiv.org/pdf/2008.03706.pdf)
>  Fast Style Transfer is a series of Neural Style Transfer algorithms that use feed-forward neural networks to render input images. Because of the high dimension of the output layer, these networks require much memory for computation. Therefore, for high-resolution images, most mobile devices and personal computers cannot stylize them, which greatly limits the application scenarios of Fast Style Transfer. At present, the two existing solutions are purchasing more memory and using the feathering-based method, but the former requires additional cost, and the latter has poor image quality. To solve this problem, we propose a novel image synthesis method named \emph{block shuffle}, which converts a single task with high memory consumption to multiple subtasks with low memory consumption. This method can act as a plug-in for Fast Style Transfer without any modification to the network architecture. We use the most popular Fast Style Transfer repository on GitHub as the baseline. Experiments show that the quality of high-resolution images generated by our method is better than that of the feathering-based method. Although our method is an order of magnitude slower than the baseline, it can stylize high-resolution images with limited memory, which is impossible with the baseline. The code and models will be made available on \url{<a class="link-external link-https" href="https://github.com/czczup/block-shuffle" rel="external noopener nofollow">this https URL</a>}.      
### 106.Variable Stiffness Control with Strict Frequency Domain Constraints for Physical Human-Robot Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2008.03663.pdf)
>  Variable impedance control is advantageous for physical human-robot interaction to improve safety, adaptability and many other aspects. This paper presents a gain-scheduled variable stiffness control approach under strict frequency-domain constraints. Firstly, to reduce conservativeness, we characterize and constrain the impedance rendering, actuator saturation, disturbance/noise rejection and passivity requirements into their specific frequency bands. This relaxation makes sense because of the restricted frequency properties of the interactive robots. Secondly, a gain-scheduled method is taken to regulate the controller gains with respect to the desired stiffness. Thirdly, the scheduling function is parameterized via a nonsmooth optimization method. Finally, the proposed approach is validated by simulations, experiments and comparisons with a gain-fixed passivity-based PID method.      
### 107.Forget About the LiDAR: Self-Supervised Depth Estimators with MED Probability Volumes  [ :arrow_down: ](https://arxiv.org/pdf/2008.03633.pdf)
>  Self-supervised depth estimators have recently shown results comparable to the supervised methods on the challenging single image depth estimation (SIDE) task, by exploiting the geometrical relations between target and reference views in the training data. However, previous methods usually learn forward or backward image synthesis, but not depth estimation, as they cannot effectively neglect occlusions between the target and the reference images. Previous works rely on rigid photometric assumptions or the SIDE network to infer depth and occlusions, resulting in limited performance. On the other hand, we propose a method to "Forget About the LiDAR" (FAL), for the training of depth estimators, with Mirrored Exponential Disparity (MED) probability volumes, from which we obtain geometrically inspired occlusion maps with our novel Mirrored Occlusion Module (MOM). Our MOM does not impose a burden on our FAL-net. Contrary to the previous methods that learn SIDE from stereo pairs by regressing disparity in the linear space, our FAL-net regresses disparity by binning it into the exponential space, which allows for better detection of distant and nearby objects. We define a two-step training strategy for our FAL-net: It is first trained for view synthesis and then fine-tuned for depth estimation with our MOM. Our FAL-net is remarkably light-weight and outperforms the previous state-of-the-art methods with 8x fewer parameters and 3x faster inference speeds on the challenging KITTI dataset. We present extensive experimental results on the KITTI, CityScapes, and Make3D datasets to verify our method's effectiveness. To the authors' best knowledge, the presented method performs the best among all the previous self-supervised methods until now.      
### 108.Spatial Sharing of GPU for Autotuning DNN models  [ :arrow_down: ](https://arxiv.org/pdf/2008.03602.pdf)
>  GPUs are used for training, inference, and tuning the machine learning models. However, Deep Neural Network (DNN) vary widely in their ability to exploit the full power of high-performance GPUs. Spatial sharing of GPU enables multiplexing several DNNs on the GPU and can improve GPU utilization, thus improving throughput and lowering latency. DNN models given just the right amount of GPU resources can still provide low inference latency, just as much as dedicating all of the GPU for their inference task. An approach to improve DNN inference is tuning of the DNN model. Autotuning frameworks find the optimal low-level implementation for a certain target device based on the trained machine learning model, thus reducing the DNN's inference latency and increasing inference throughput. We observe an interdependency between the tuned model and its inference latency. A DNN model tuned with specific GPU resources provides the best inference latency when inferred with close to the same amount of GPU resources. While a model tuned with the maximum amount of the GPU's resources has poorer inference latency once the GPU resources are limited for inference. On the other hand, a model tuned with an appropriate amount of GPU resources still achieves good inference latency across a wide range of GPU resource availability. We explore the causes that impact the tuning of a model at different amounts of GPU resources. We present many techniques to maximize resource utilization and improve tuning performance. We enable controlled spatial sharing of GPU to multiplex several tuning applications on the GPU. We scale the tuning server instances and shard the tuning model across multiple client instances for concurrent tuning of different operators of a model, achieving better GPU multiplexing. With our improvements, we decrease DNN autotuning time by up to 75 percent and increase throughput by a factor of 5.      
### 109.A Unified Framework for Shot Type Classification Based on Subject Centric Lens  [ :arrow_down: ](https://arxiv.org/pdf/2008.03548.pdf)
>  Shots are key narrative elements of various videos, e.g. movies, TV series, and user-generated videos that are thriving over the Internet. The types of shots greatly influence how the underlying ideas, emotions, and messages are expressed. The technique to analyze shot types is important to the understanding of videos, which has seen increasing demand in real-world applications in this era. Classifying shot type is challenging due to the additional information required beyond the video content, such as the spatial composition of a frame and camera movement. To address these issues, we propose a learning framework Subject Guidance Network (SGNet) for shot type recognition. SGNet separates the subject and background of a shot into two streams, serving as separate guidance maps for scale and movement type classification respectively. To facilitate shot type analysis and model evaluations, we build a large-scale dataset MovieShots, which contains 46K shots from 7K movie trailers with annotations of their scale and movement types. Experiments show that our framework is able to recognize these two attributes of shot accurately, outperforming all the previous methods.      
### 110.Online Multi-modal Person Search in Videos  [ :arrow_down: ](https://arxiv.org/pdf/2008.03546.pdf)
>  The task of searching certain people in videos has seen increasing potential in real-world applications, such as video organization and editing. Most existing approaches are devised to work in an offline manner, where identities can only be inferred after an entire video is examined. This working manner precludes such methods from being applied to online services or those applications that require real-time responses. In this paper, we propose an online person search framework, which can recognize people in a video on the fly. This framework maintains a multimodal memory bank at its heart as the basis for person recognition, and updates it dynamically with a policy obtained by reinforcement learning. Our experiments on a large movie dataset show that the proposed method is effective, not only achieving remarkable improvements over online schemes but also outperforming offline methods.      
### 111.Multimodal Image-to-Image Translation via Mutual Information Estimation and Maximization  [ :arrow_down: ](https://arxiv.org/pdf/2008.03529.pdf)
>  In this paper, we present a novel framework that can achieve multimodal image-to-image translation by simply encouraging the statistical dependence between the latent code and the output image in conditional generative adversarial networks. In addition, by incorporating a U-net generator into our framework, our method only needs to train a one-sided translation model from the source image domain to the target image domain for both supervised and unsupervised multimodal image-to-image translation. Furthermore, our method also achieves disentanglement between the source domain content and the target domain style for free. We conduct experiments under supervised and unsupervised settings on various benchmark image-to-image translation datasets compared with the state-of-the-art methods, showing the effectiveness and simplicity of our method to achieve multimodal and high-quality results.      
### 112.A Novel Method for Obtaining Diffuse Field Measurements for Microphone Calibration  [ :arrow_down: ](https://arxiv.org/pdf/2008.03513.pdf)
>  We propose a straightforward and cost-effective method to perform diffuse soundfield measurements for calibrating the magnitude response of a microphone array. Typically, such calibration is performed in a diffuse soundfield created in reverberation chambers, an expensive and time-consuming process. A method is proposed for obtaining diffuse field measurements in untreated environments. First, a closed-form expression for the spatial correlation of a wideband signal in a diffuse field is derived. Next, we describe a practical procedure for obtaining the diffuse field response of a microphone array in the presence of a non-diffuse soundfield by the introduction of random perturbations in the microphone location. Experimental spatial correlation data obtained is compared with the theoretical model, confirming that it is possible to obtain diffuse field measurements in untreated environments with relatively few loudspeakers. A 30 second test signal played from 4-8 loudspeakers is shown to be sufficient in obtaining a diffuse field measurement using the proposed method. An Eigenmike is then successfully calibrated at two different geographical locations.      
### 113.Optimizing Co-flows Scheduling and Routing in Data Centre Networks for Big Data Applications  [ :arrow_down: ](https://arxiv.org/pdf/2008.03497.pdf)
>  This paper optimizes the scheduling and routing of the co-flows of MapReduce shuffling phase in state-of-the-art and proposed Passive Optical Networking (PON)-based Data Centre Network (DCN) architectures. A time-slotted Mixed Integer Linear Programming (MILP) model is developed and used for the optimization with the objective of minimizing either the total energy consumption or the completion time. The DCN architectures include four state-of-the-art electronic switching architectures which are spine-leaf, Fat-tree, BCube, and DCell data centres. The proposed PON-based DCN architectures include two designs that utilize ports in Optical Line Terminal (OLT) line cards for inter and possibly intra data centre networking in addition to passive interconnects for the intra data centre networking between different PON groups (i.e. racks) within a PON cell (i.e. number of PON groups connected to a single OLT port). The first design is a switch-centric design that uses two Arrayed Waveguide Grating Routers (AWGRs) and the second is a server-centric design. The study also considers different traffic patterns defined according to the distribution of map and reduce tasks in the servers and data skewness.      
### 114.Visual Pattern Recognition with on On-chip Learning: towards a Fully Neuromorphic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.03470.pdf)
>  We present a spiking neural network (SNN) for visual pattern recognition with on-chip learning on neuromorphichardware. We show how this network can learn simple visual patterns composed of horizontal and vertical bars sensed by a Dynamic Vision Sensor, using a local spike-based plasticity rule. During recognition, the network classifies the pattern's identity while at the same time estimating its location and scale. We build on previous work that used learning with neuromorphic hardware in the loop and demonstrate that the proposed network can properly operate with on-chip learning, demonstrating a complete neuromorphic pattern learning and recognition setup. Our results show that the network is robust against noise on the input (no accuracy drop when adding 130% noise) and against up to 20% noise in the neuron parameters.      
### 115.$k$-means on a log-Cholesky Manifold, with Unsupervised Classification of Radar Products  [ :arrow_down: ](https://arxiv.org/pdf/2008.03454.pdf)
>  We state theoretical properties for $k$-means clustering of Symmetric Positive Definite (SPD) matrices, in a non-Euclidean space, that provides a natural and favourable representation of these data. We then provide a novel application for this method, to time-series clustering of pixels in a sequence of Synthetic Aperture Radar images, via their finite-lag autocovariance matrices.      
### 116.Partitioning signal classes using transport transforms for data analysis and machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.03452.pdf)
>  A relatively new set of transport-based transforms (CDT, R-CDT, LOT) have shown their strength and great potential in various image and data processing tasks such as parametric signal estimation, classification, cancer detection among many others. It is hence worthwhile to elucidate some of the mathematical properties that explain the successes of these transforms when they are used as tools in data analysis, signal processing or data classification. In particular, we give conditions under which classes of signals that are created by algebraic generative models are transformed into convex sets by the transport transforms. Such convexification of the classes simplify the classification and other data analysis and processing problems when viewed in the transform domain. More specifically, we study the extent and limitation of the convexification ability of these transforms under an algebraic generative modeling framework. We hope that this paper will serve as an introduction to these transforms and will encourage mathematicians and other researchers to further explore the theoretical underpinnings and algorithmic tools that will help understand the successes of these transforms and lay the groundwork for further successful applications.      
### 117.Symbolic Music Playing Techniques Generation as a Tagging Problem  [ :arrow_down: ](https://arxiv.org/pdf/2008.03436.pdf)
>  Music generation has always been a hot topic. When discussing symbolic music, melody or harmonies are usually seen as the only generating targets. But in fact, playing techniques are also quite an important part of the music. In this paper, we discuss the playing techniques generation problem by seeing it as a tagging problem. We propose a model that can use both the current data and external knowledge. Experiments were carried out by applying the proposed model in Chinese bamboo flute music, and results show that our method can make generated music more lively.      
### 118.Using UNet and PSPNet to explore the reusability principle of CNN parameters  [ :arrow_down: ](https://arxiv.org/pdf/2008.03414.pdf)
>  How to reduce the requirement on training dataset size is a hot topic in deep learning community. One straightforward way is to reuse some pre-trained parameters. Some previous work like Deep transfer learning reuse the model parameters trained for the first task as the starting point for the second task, and semi-supervised learning is trained upon a combination of labeled and unlabeled data. However, the fundamental reason of the success of these methods is unclear. In this paper, the reusability of parameters in each layer of a deep convolutional neural network is experimentally quantified by using a network to do segmentation and auto-encoder task. This paper proves that network parameters can be reused for two reasons: first, the network features are general; Second, there is little difference between the pre-trained parameters and the ideal network parameters. Through the use of parameter replacement and comparison, we demonstrate that reusability is different in BN(Batch Normalization)[7] layer and Convolution layer and some observations: (1)Running mean and running variance plays an important role than Weight and Bias in BN layer.(2)The weight and bias can be reused in BN layers.( 3) The network is very sensitive to the weight of convolutional layer.(4) The bias in Convolution layers are not sensitive, and it can be reused directly.      
### 119.Learning to Detect Bipolar Disorder and Borderline Personality Disorder with Language and Speech in Non-Clinical Interviews  [ :arrow_down: ](https://arxiv.org/pdf/2008.03408.pdf)
>  Bipolar disorder (BD) and borderline personality disorder (BPD) are both chronic psychiatric disorders. However, their overlapping symptoms and common comorbidity make it challenging for the clinicians to distinguish the two conditions on the basis of a clinical interview. In this work, we first present a new multi-modal dataset containing interviews involving individuals with BD or BPD being interviewed about a non-clinical topic . We investigate the automatic detection of the two conditions, and demonstrate a good linear classifier that can be learnt using a down-selected set of features from the different aspects of the interviews and a novel approach of summarising these features. Finally, we find that different sets of features characterise BD and BPD, thus providing insights into the difference between the automatic screening of the two conditions.      
### 120.Distributed optimization for nonrigid nano-tomography  [ :arrow_down: ](https://arxiv.org/pdf/2008.03375.pdf)
>  Resolution level and reconstruction quality in nano-computed tomography (nano-CT) are in part limited by the stability of microscopes, because the magnitude of mechanical vibrations during scanning becomes comparable to the imaging resolution, and the ability of the samples to resist beam damage during data acquisition. In such cases, there is no incentive in recovering the sample state at different time steps like in time-resolved reconstruction methods, but instead the goal is to retrieve a single reconstruction at the highest possible spatial resolution and without any imaging artifacts. Here we propose a joint solver for imaging samples at the nanoscale with projection alignment, unwarping and regularization. Projection data consistency is regulated by dense optical flow estimated by Farneback's algorithm, leading to sharp sample reconstructions with less artifacts. Synthetic data tests show robustness of the method to Poisson and low-frequency background noise. Applicability of the method is demonstrated on two large-scale nano-imaging experimental data sets.      

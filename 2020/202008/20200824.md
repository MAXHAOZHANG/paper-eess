# ArXiv eess --Mon, 24 Aug 2020
### 1.An Overview of Deep-Learning-Based Audio-Visual Speech Enhancement and Separation  [ :arrow_down: ](https://arxiv.org/pdf/2008.09586.pdf)
>  Speech enhancement and speech separation are two related tasks, whose purpose is to extract either one or more target speech signals, respectively, from a mixture of sounds generated by several sources. Traditionally, these tasks have been tackled using signal processing and machine learning techniques applied to the available acoustic signals. More recently, visual information from the target speakers, such as lip movements and facial expressions, has been introduced to speech enhancement and speech separation systems, because the visual aspect of speech is essentially unaffected by the acoustic environment. In order to efficiently fuse acoustic and visual information, researchers have exploited the flexibility of data-driven approaches, specifically deep learning, achieving state-of-the-art performance. The ceaseless proposal of a large number of techniques to extract features and fuse multimodal information has highlighted the need for an overview that comprehensively describes and discusses audio-visual speech enhancement and separation based on deep learning. In this paper, we provide a systematic survey of this research topic, focusing on the main elements that characterise the systems in the literature: visual features; acoustic features; deep learning methods; fusion techniques; training targets and objective functions. We also survey commonly employed audio-visual speech datasets, given their central role in the development of data-driven approaches, and evaluation methods, because they are generally used to compare different systems and determine their performance. In addition, we review deep-learning-based methods for speech reconstruction from silent videos and audio-visual sound source separation for non-speech signals, since these methods can be more or less directly applied to audio-visual speech enhancement and separation.      
### 2.A persistent homology-based topological loss function for multi-class CNN segmentation of cardiac MRI  [ :arrow_down: ](https://arxiv.org/pdf/2008.09585.pdf)
>  With respect to spatial overlap, CNN-based segmentation of short axis cardiovascular magnetic resonance (CMR) images has achieved a level of performance consistent with inter observer variation. However, conventional training procedures frequently depend on pixel-wise loss functions, limiting optimisation with respect to extended or global features. As a result, inferred segmentations can lack spatial coherence, including spurious connected components or holes. Such results are implausible, violating the anticipated topology of image segments, which is frequently known a priori. Addressing this challenge, published work has employed persistent homology, constructing topological loss functions for the evaluation of image segments against an explicit prior. Building a richer description of segmentation topology by considering all possible labels and label pairs, we extend these losses to the task of multi-class segmentation. These topological priors allow us to resolve all topological errors in a subset of 150 examples from the ACDC short axis CMR training data set, without sacrificing overlap performance.      
### 3.An Unsupervised Approach to Ultrasound Elastography with End-to-end Strain Regularisation  [ :arrow_down: ](https://arxiv.org/pdf/2008.09572.pdf)
>  Quasi-static ultrasound elastography (USE) is an imaging modality that consists of determining a measure of deformation (i.e.strain) of soft tissue in response to an applied mechanical force. The strain is generally determined by estimating the displacement between successive ultrasound frames acquired before and after applying manual compression. The computational efficiency and accuracy of the displacement prediction, also known as time-delay estimation, are key challenges for real-time USE applications. In this paper, we present a novel deep-learning method for efficient time-delay estimation between ultrasound radio-frequency (RF) data. The proposed method consists of a convolutional neural network (CNN) that predicts a displacement field between a pair of pre- and post-compression ultrasound RF frames. The network is trained in an unsupervised way, by optimizing a similarity metric be-tween the reference and compressed image. We also introduce a new regularization term that preserves displacement continuity by directly optimizing the strain smoothness. We validated the performance of our method by using both ultrasound simulation and in vivo data on healthy volunteers. We also compared the performance of our method with a state-of-the-art method called OVERWIND [17]. Average contrast-to-noise ratio (CNR) and signal-to-noise ratio (SNR) of our method in 30 simulation and 3 in vivo image pairs are 7.70 and 6.95, 7 and 0.31, respectively. Our results suggest that our approach can effectively predict accurate strain images. The unsupervised aspect of our approach represents a great potential for the use of deep learning application for the analysis of clinical ultrasound data.      
### 4.Achieving Disaster-Resilient Distribution Systems via Emergency Response Resources: A Practical Approach  [ :arrow_down: ](https://arxiv.org/pdf/2008.09539.pdf)
>  This paper presents a practical approach to utilizing emergency response resources (ERRs) and post-disaster available distributed energy resources (PDA-DERs) to improve the resilience of power distribution systems against natural disasters. The proposed approach consists of two sequential steps: first, the minimum amount of ERRs is determined in a pre-disaster planning model; second, a post-disaster restoration model is proposed to co-optimize the dispatch of pre-planned ERRs and PDA-DERs to minimize the impact of disasters on customers, i.e., unserved energy for the entire restoration window. Compared with existing restoration strategies using ERRs, the proposed approach is more tractable since 1) in the pre-disaster stage, the needed EERs are determined based on the prediction of energy shortage and disaster-induced damages using machine learning-based algorithms (i.e., cost-sensitive-RFQRF for prediction of outage customers, random forest for prediction of outage duration, and CART for prediction of disaster-induced damages); 2) in the post-disaster stage, the super-node approximation (SNA) and the convex hull relaxation (CHR) of distribution networks are introduced to achieve the best trade-off between computational burden and accuracy. Tests of the proposed approach on IEEE test feeders demonstrated that a combination of SNA and CHR remarkably reduces the solution time of the post-disaster restoration model.      
### 5.Optimum Multi-Antenna Ambient Backscatter Receiver for General Binary-Modulated Signal  [ :arrow_down: ](https://arxiv.org/pdf/2008.09523.pdf)
>  Ambient backscatter communication (AmBC) is becoming increasingly popular for enabling green communication amidst the continual development of the Internet-of-things paradigm. Efforts have been put into backscatter signal detection as the detection performance is limited by the low signal-to-interference-plus-noise ratio (SINR) of the signal at the receiver. The low SINR can be improved by adopting a multi-antenna receiver. In this paper, the optimum multi-antenna receiver that does not impose any constraints on the types of binary modulation performed by the backscatter device and the waveform used by the ambient source system is studied. The proposed receiver owns a simple structure formed by two beamformers. Bit error rate (BER) performances of the optimum receiver are derived under constant-amplitude ambient signal and Gaussian-distributed ambient signal. Moreover, to facilitate the implementation of the optimum receiver, a simplified receiver is proposed and practical approximations to required beamformers are provided. The derived optimum receiver avoids the complex direct path interference cancellation and coherent reception, but exploits the fact that backscatter signal changes the composite channel impinging at the receiver and the directivity of receiver antenna array. Comparative simulation results show that the performance of the optimum receiver achieves the same performance as the coherent receiver even though it realizes non-coherent reception. The studied receivers provide high flexibility for implementing simple and low-cost receivers in different AmBC systems.      
### 6.TRICE: An Efficient Channel Estimation Framework for RIS-Aided MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2008.09499.pdf)
>  Reconfigurable intelligent surfaces (RISs) have been proposed recently as an enabling technology for tuning the wireless propagation channel between transceivers. To realize RISs advantages, however, accurate channel state information is required. In this paper, we consider a single-user RIS-aided system model and propose a two-stage high-resolution channel parameter estimation framework termed TRICE that exploits the low-rank nature of millimeter-wave MIMO channels. In both stages, we formulate the channel parameter estimation problem as a 2D direction-of-arrival estimation problem, for which several solution methods exist in the literature. Based on this formulation, we resort to a 2D DFT beamspace ESPRIT method to estimate the angular parameters of the involved communication channels. Our numerical results show that the proposed TRICE framework has a lower training overhead, as compared to benchmark methods, which makes it appealing in practical applications.      
### 7.Dynamic Channel Emulation in a Cost-Effective MPAC Setup for mmWave Devices Over-The-Air Testing with Dominant Cluster Concept  [ :arrow_down: ](https://arxiv.org/pdf/2008.09487.pdf)
>  Millimeter-Wave (mmWave) has been considered as the key enabler for the fifth generation (5G) communications. The link budget and spectral efficiency of mmWave communications can be further enhanced by adopting the massive multiple-input-multiple-output (MIMO) exploiting beamforming. Nevertheless, it is essential to design and test mmWave 5G devices under various realistic scenarios, since the uncontrollable radio propagation channels pose intrinsic limitations on system performance. This requires emulating the realistic dynamic mmWave channels in a reproducible manner in laboratories, hence the goal of this paper. In this contribution, the beamforming effect is firstly investigated, showing that the non-dominant clusters existing in the mmWave channels are insignificant with beamforming operations applied in mmWave 5G devices. Thus, an over-the-air (OTA) emulation strategy for dynamic mmWave channels is then proposed based on a dominant-cluster concept using a sectored multiprobe anechoic chamber (SMPAC) setup. The key design parameters including the probe number and the angular spacing of probes are investigated through comprehensive simulations. A cost-effective switch circuit is also designed for this purpose and validated in the simulation. Furthermore, a dynamic mmWave channel measured in an indoor scenario at 28-30 GHz is presented, where the proposed emulation strategy is also validated by reproducing the measured reality.      
### 8.Laughter Synthesis: Combining Seq2seq modeling with Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2008.09483.pdf)
>  Despite the growing interest for expressive speech synthesis, synthesis of nonverbal expressions is an under-explored area. In this paper we propose an audio laughter synthesis system based on a sequence-to-sequence TTS synthesis system. We leverage transfer learning by training a deep learning model to learn to generate both speech and laughs from annotations. We evaluate our model with a listening test, comparing its performance to an HMM-based laughter synthesis one and assess that it reaches higher perceived naturalness. Our solution is a first step towards a TTS system that would be able to synthesize speech with a control on amusement level with laughter integration.      
### 9.Coherent Multi-antenna Receiver for BPSK-modulated Ambient Backscatter Tags  [ :arrow_down: ](https://arxiv.org/pdf/2008.09462.pdf)
>  Ambient Backscatter Communication (AmBC) is an emerging communication technology that can enable green Internet-of-Things deployments. The widespread acceptance of this paradigm is limited by low Signal-to-Interference-Plus-Noise Ratio (SINR) of the signal impinging on the receiver antenna due to the strong direct path interference and unknown ambient signal. The adverse impact of these two factors can be mitigated by using non-coherent multi-antenna receivers, which is known to require higher SINR to reach Bit-Error-Rate (BER) performance of coherent receivers. However, in literature, coherent receivers for AmBC systems are little-studied because of unknown ambient signal, unknown location of AmBC tags, and varying channel conditions. In this paper, a coherent multi-antenna receiver, which does not require a prior information of the ambient signal, for decoding Binary-Phase-shift-Keying (BPSK) modulated signal is presented. The performance of the proposed receiver is compared with the ideal coherent receiver that has a perfect phase information, and also with the performance of non-coherent receiver, which assumes distributions for ambient signal and phase offset caused by excess length of the backscatter path. Comparative simulation results show the designed receiver can achieve the same BER-performance of the ideal coherent receiver with 1-dB more SINR, which corresponds to 5-dB or more gain with respect to non-coherent reception of On-Off-Keying modulated signals. Variation of the detection performance with the tag location shows that the coverage area is in the close vicinity of the transmitter and a larger region around the receiver, which is consistent with the theoretical results.      
### 10.Low-Complexity Detection of Small Frequency Changes by the Generalized LMPU Test  [ :arrow_down: ](https://arxiv.org/pdf/2008.09458.pdf)
>  In this paper, we consider the detection of a small change in the frequency of sinusoidal signals, which arises in various signal processing applications. The generalized likelihood ratio test (GLRT) for this problem uses the maximum likelihood (ML) estimator of the frequency, and therefore suffers from high computational complexity. In addition, the GLRT is not necessarily optimal and its performance may degrade for non-asymptotic scenarios that are characterized by close hypotheses and small sample sizes. In this paper we propose a new detection method, named the generalized locally most powerful unbiased (GLMPU) test, which is a general method for local detection in the presence of nuisance parameters. A closed-form expression of the GLMPU test is developed for the detection of frequency deviation in the case where the complex amplitudes of the measured signals are unknown. Numerical simulations show improved performance over the GLRT in terms of probability of detection performance and computational complexity.      
### 11.ADIC: Anomaly Detection Integrated Circuit in 65nm CMOS utilizing Approximate Computing  [ :arrow_down: ](https://arxiv.org/pdf/2008.09442.pdf)
>  In this paper, we present a low-power anomaly detection integrated circuit (ADIC) based on a one-class classifier (OCC) neural network. The ADIC achieves low-power operation through a combination of (a) careful choice of algorithm for online learning and (b) approximate computing techniques to lower average energy. In particular, online pseudoinverse update method (OPIUM) is used to train a randomized neural network for quick and resource efficient learning. An additional 42% energy saving can be achieved when a lighter version of OPIUM method is used for training with the same number of data samples lead to no significant compromise on the quality of inference. Instead of a single classifier with large number of neurons, an ensemble of K base learner approach is chosen to reduce learning memory by a factor of K. This also enables approximate computing by dynamically varying the neural network size based on anomaly detection. Fabricated in 65nm CMOS, the ADIC has K = 7 Base Learners (BL) with 32 neurons in each BL and dissipates 11.87pJ/OP and 3.35pJ/OP during learning and inference respectively at Vdd = 0.75V when all 7 BLs are enabled. Further, evaluated on the NASA bearing dataset, approximately 80% of the chip can be shut down for 99% of the lifetime leading to an energy efficiency of 0.48pJ/OP, an 18.5 times reduction over full-precision computing running at Vdd = 1.2V throughout the lifetime.      
### 12.Deep Learning for Wireless Coded Caching with Unknown and Time-Variant Content Popularity  [ :arrow_down: ](https://arxiv.org/pdf/2008.09422.pdf)
>  Coded caching is effective in leveraging the accumulated storage size in wireless networks by distributing different coded segments of each file in multiple cache nodes. This paper aims to find a wireless coded caching policy to minimize the total discounted network cost, which involves both transmission delay and cache replacement cost, using tools from deep learning. The problem is known to be challenging due to the unknown, time-variant content popularity as well as the continuous, high-dimensional action space. We first propose a clustering based long short-term memory (C-LTSM) approach to predict the number of content requests using historical request information. This approach exploits the correlation of the historical request information between different files through clustering. Based on the predicted results, we then propose a supervised deep deterministic policy gradient (SDDPG) approach. This approach, on one hand, can learn the caching policy in continuous action space by using the actor-critic architecture. On the other hand, it accelerates the learning process by pre-training the actor network based on the solution of an approximate problem that minimizes the per-slot cost. Real-world trace-based numerical results show that the proposed prediction and caching policy using deep learning outperform the considered existing methods.      
### 13.Deep Learning Methods for Lung Cancer Segmentation in Whole-slide Histopathology Images -- the ACDC@LungHP Challenge 2019  [ :arrow_down: ](https://arxiv.org/pdf/2008.09352.pdf)
>  Accurate segmentation of lung cancer in pathology slides is a critical step in improving patient care. We proposed the ACDC@LungHP (Automatic Cancer Detection and Classification in Whole-slide Lung Histopathology) challenge for evaluating different computer-aided diagnosis (CADs) methods on the automatic diagnosis of lung cancer. The ACDC@LungHP 2019 focused on segmentation (pixel-wise detection) of cancer tissue in whole slide imaging (WSI), using an annotated dataset of 150 training images and 50 test images from 200 patients. This paper reviews this challenge and summarizes the top 10 submitted methods for lung cancer segmentation. All methods were evaluated using the false positive rate, false negative rate, and DICE coefficient (DC). The DC ranged from 0.7354$\pm$0.1149 to 0.8372$\pm$0.0858. The DC of the best method was close to the inter-observer agreement (0.8398$\pm$0.0890). All methods were based on deep learning and categorized into two groups: multi-model method and single model method. In general, multi-model methods were significantly better ($\textit{p}$&lt;$0.01$) than single model methods, with mean DC of 0.7966 and 0.7544, respectively. Deep learning based methods could potentially help pathologists find suspicious regions for further analysis of lung cancer in WSI.      
### 14.DTDN: Dual-task De-raining Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.09326.pdf)
>  Removing rain streaks from rainy images is necessary for many tasks in computer vision, such as object detection and recognition. It needs to address two mutually exclusive objectives: removing rain streaks and reserving realistic details. Balancing them is critical for de-raining methods. We propose an end-to-end network, called dual-task de-raining network (DTDN), consisting of two sub-networks: generative adversarial network (GAN) and convolutional neural network (CNN), to remove rain streaks via coordinating the two mutually exclusive objectives self-adaptively. DTDN-GAN is mainly used to remove structural rain streaks, and DTDN-CNN is designed to recover details in original images. We also design a training algorithm to train these two sub-networks of DTDN alternatively, which share same weights but use different training sets. We further enrich two existing datasets to approximate the distribution of real rain streaks. Experimental results show that our method outperforms several recent state-of-the-art methods, based on both benchmark testing datasets and real rainy images.      
### 15.FairFly: A Fair Motion Planner for Fleets of Autonomous UAVs in Urban Airspace  [ :arrow_down: ](https://arxiv.org/pdf/2008.09297.pdf)
>  We present a solution to the problem of fairly planning a fleet of Unmanned Aerial Vehicles (UAVs) that have different missions and operators, such that no one operator unfairly gets to finish its missions early at the expense of others - unless this was explicitly negotiated. When hundreds of UAVs share an urban airspace, the relevant authorities should allocate corridors to them such that they complete their missions, but no one vehicle is accidentally given an exceptionally fast path at the expense of another, which is thus forced to wait and waste energy. Our solution, FairFly, addresses the fair planning question for general autonomous systems, including UAV fleets, subject to complex missions typical of urban applications. FairFly formalizes each mission in temporal logic. An offline search finds the fairest paths that satisfy the missions and can be flown by the UAVs, leading to lighter online control load. It allows explicit negotiation between UAVs to enable imbalanced path durations if desired. We present three fairness notions, including one that reduces energy consumption. We validate our results in simulation, and demonstrate a lighter computational load and less UAV energy consumption as a result of flying fair trajectories.      
### 16.CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile Application  [ :arrow_down: ](https://arxiv.org/pdf/2008.09264.pdf)
>  In this paper, we present a deep learning-based speech signal-processing mobile application, CITISEN, which can perform three functions: speech enhancement (SE), acoustic scene conversion (ASC), and model adaptation (MA). For SE, CITISEN can effectively reduce noise components from speech signals and accordingly enhance their clarity and intelligibility. For ASC, CITISEN can convert the current background sound to a different background sound. Finally, for MA, CITISEN can effectively adapt an SE model, with a few audio files, when it encounters unknown speakers or noise types; the adapted SE model is used to enhance the upcoming noisy utterances. Experimental results confirmed the effectiveness of CITISEN in performing these three functions via objective evaluation and subjective listening tests. The promising results reveal that the developed CITISEN mobile application can potentially be used as a front-end processor for various speech-related services such as voice communication, assistive hearing devices, and virtual reality headsets.      
### 17.On the Optimal 3D Placement of a UAV Base Station for Maximal Coverage of UAV Users  [ :arrow_down: ](https://arxiv.org/pdf/2008.09262.pdf)
>  Unmanned aerial vehicles (UAVs) can be users that support new applications, or be communication access points that serve terrestrial and/or aerial users. In this paper, we focus on the connectivity problem of aerial users when they are exclusively served by aerial base stations (BS), i.e., UAVBSs. Specifically, the 3D placement problem of a directional antenna equipped UAV-BS, aiming to maximize the number of covered aerial users under a spectrum sharing policy with terrestrial networks, is investigated. Given a known spectrum sharing policy between the aerial and terrestrial networks, we propose a 3D placement algorithm that achieves optimality. Simulation results show the performance of our approach, in terms of number of covered aerial users, for different configurations and parameters, such as the spectrum sharing policy, antenna beamwidth, transmit power, and aerial users density. These results represent novel guidelines for exclusive aerial networks deployment and applications, distinctively for orthogonal and non-orthogonal spectrum sharing policies with terrestrial networks.      
### 18.Suboptimal Nonlinear Model Predictive Control Strategies for Tracking Near Rectilinear Halo Orbits  [ :arrow_down: ](https://arxiv.org/pdf/2008.09240.pdf)
>  Near Rectilinear Halo Orbits (NRHOs), a subclass of halo orbits around the L1 and L2 Lagrange points, are promising candidates for future lunar gateways in cis-lunar space and as staging orbits for lunar missions. Closed-loop control is beneficial to compensate orbital perturbations and potential instabilities while maintaining spacecraft on NRHOs and performing relative motion maneuvers. This paper investigates the use of nonlinear model predictive control (NMPC) coupled with low-thrust actuators for station-keeping on NRHOs. It is demonstrated through numerical simulations that NMPC is able to stabilize a spacecraft to a reference orbit and handle control constraints. Further, it is shown that the computational burden of NMPC can be managed using specialized optimization routines and suboptimal approaches without jeopardizing closed-loop performance.      
### 19.AWNet: Attentive Wavelet Network for Image ISP  [ :arrow_down: ](https://arxiv.org/pdf/2008.09228.pdf)
>  As the revolutionary improvement being made on the performance of smartphones over the last decade, mobile photography becomes one of the most common practices among the majority of smartphone users. However, due to the limited size of camera sensors on phone, the photographed image is still visually distinct to the one taken by the digital single-lens reflex (DSLR) camera. To narrow this performance gap, one is to redesign the camera image signal processor (ISP) to improve the image quality. Owing to the rapid rise of deep learning, recent works resort to the deep convolutional neural network (CNN) to develop a sophisticated data-driven ISP that directly maps the phone-captured image to the DSLR-captured one. In this paper, we introduce a novel network that utilizes the attention mechanism and wavelet transform, dubbed AWNet, to tackle this learnable image ISP problem. By adding the wavelet transform, our proposed method enables us to restore favorable image details from RAW information and achieve a larger receptive field while remaining high efficiency in terms of computational cost. The global context block is adopted in our method to learn the non-local color mapping for the generation of appealing RGB images. More importantly, this block alleviates the influence of image misalignment occurred on the provided dataset. Experimental results indicate the advances of our design in both qualitative and quantitative measurements.      
### 20.Simultaneous input &amp; state estimation, singular filtering and stability  [ :arrow_down: ](https://arxiv.org/pdf/2008.09217.pdf)
>  Input estimation is a signal processing technique associated with deconvolution of measured signals after filtering through a known dynamic system. Kitanidis and others extended this to the simultaneous estimation of the input signal and the state of the intervening system. This is normally posed as a special least-squares estimation problem with unbiasedness. The approach has application in signal analysis and in control. Despite the connection to optimal estimation, the standard algorithms are not necessarily stable, leading to a number of recent papers which present sufficient conditions for stability. In this paper we complete these stability results in two ways in the time-invariant case: for the square case, where the number of measurements equals the number of unknown inputs, we establish exactly the location of the algorithm poles; for the non-square case, we show that the best sufficient conditions are also necessary. We then draw on our previous results interpreting these algorithms, when stable, as singular Kalman filters to advocate a direct, guaranteed stable implementation via Kalman filtering. This has the advantage of clarity and flexibility in addition to stability. En route, we decipher the existing algorithms in terms of system inversion and successive singular filtering. The stability results are extended to the time-varying case directly to recover the earlier sufficient conditions for stability via the Riccati difference equation.      
### 21.Adaptive multi-channel event segmentation and feature extraction for monitoring health outcomes  [ :arrow_down: ](https://arxiv.org/pdf/2008.09215.pdf)
>  $\textbf{Objective}$: To develop a multi-channel device event segmentation and feature extraction algorithm that is robust to changes in data distribution. $\textbf{Methods}$: We introduce an adaptive transfer learning algorithm to classify and segment events from non-stationary multi-channel temporal data. Using a multivariate hidden Markov model (HMM) and Fisher's linear discriminant analysis (FLDA) the algorithm adaptively adjusts to shifts in distribution over time. The proposed algorithm is unsupervised and learns to label events without requiring $\textit{a priori}$ information about true event states. The procedure is illustrated on experimental data collected from a cohort in a human viral challenge (HVC) study, where certain subjects have disrupted wake and sleep patterns after exposure to a H1N1 influenza pathogen. $\textbf{Results}$: Simulations establish that the proposed adaptive algorithm significantly outperforms other event classification methods. When applied to early time points in the HVC data the algorithm extracts sleep/wake features that are predictive of both infection and infection onset time. $\textbf{Conclusion}$: The proposed transfer learning event segmentation method is robust to temporal shifts in data distribution and can be used to produce highly discriminative event-labeled features for health monitoring. $\textbf{Significance}$: Our integrated multisensor signal processing and transfer learning method is applicable to many ambulatory monitoring applications.      
### 22.Fifteen Years of Progress at Zero Velocity: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2008.09208.pdf)
>  Fifteen years have passed since the publication of Foxlin's seminal paper "Pedestrian tracking with shoe-mounted inertial sensors". In addition to popularizing the zero-velocity update, Foxlin also hinted that the optimal parameter tuning of the zero-velocity detector is dependent on, for example, the user's gait speed. As demonstrated by the recent influx of related studies, the question of how to properly design a robust zero-velocity detector is still an open research question. In this review, we first recount the history of foot-mounted inertial navigation and characterize the main sources of error, thereby motivating the need for a robust solution. Following this, we systematically analyze current approaches to robust zero-velocity detection, while categorizing public code and data. The article concludes with a discussion on commercialization along with guidance for future research.      
### 23.Dyadic Speech-based Affect Recognition using DAMI-P2C Parent-child Multimodal Interaction Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2008.09207.pdf)
>  Automatic speech-based affect recognition of individuals in dyadic conversation is a challenging task, in part because of its heavy reliance on manual pre-processing. Traditional approaches frequently require hand-crafted speech features and segmentation of speaker turns. In this work, we design end-to-end deep learning methods to recognize each person's affective expression in an audio stream with two speakers, automatically discovering features and time regions relevant to the target speaker's affect. We integrate a local attention mechanism into the end-to-end architecture and compare the performance of three attention implementations -- one mean pooling and two weighted pooling methods. Our results show that the proposed weighted-pooling attention solutions are able to learn to focus on the regions containing target speaker's affective information and successfully extract the individual's valence and arousal intensity. Here we introduce and use a "dyadic affect in multimodal interaction - parent to child" (DAMI-P2C) dataset collected in a study of 34 families, where a parent and a child (3-7 years old) engage in reading storybooks together. In contrast to existing public datasets for affect recognition, each instance for both speakers in the DAMI-P2C dataset is annotated for the perceived affect by three labelers. To encourage more research on the challenging task of multi-speaker affect sensing, we make the annotated DAMI-P2C dataset publicly available, including acoustic features of the dyads' raw audios, affect annotations, and a diverse set of developmental, social, and demographic profiles of each dyad.      
### 24.Training of mixed-signal optical convolutional neural network with reduced quantization level  [ :arrow_down: ](https://arxiv.org/pdf/2008.09206.pdf)
>  Mixed-signal artificial neural networks (ANNs) that employ analog matrix-multiplication accelerators can achieve higher speed and improved power efficiency. Though analog computing is known to be susceptible to noise and device imperfections, various analog computing paradigms have been considered as promising solutions to address the growing computing demand in machine learning applications, thanks to the robustness of ANNs. This robustness has been explored in low-precision, fixed-point ANN models, which have proven successful on compressing ANN model size on digital computers. However, these promising results and network training algorithms cannot be easily migrated to analog accelerators. The reason is that digital computers typically carry intermediate results with higher bit width, though the inputs and weights of each ANN layers are of low bit width; while the analog intermediate results have low precision, analogous to digital signals with a reduced quantization level. Here we report a training method for mixed-signal ANN with two types of errors in its analog signals, random noise, and deterministic errors (distortions). The results showed that mixed-signal ANNs trained with our proposed method can achieve an equivalent classification accuracy with noise level up to 50% of the ideal quantization step size. We have demonstrated this training method on a mixed-signal optical convolutional neural network based on diffractive optics.      
### 25.Fluorescence fluctuations-based super-resolution microscopy techniques: an experimental comparative study  [ :arrow_down: ](https://arxiv.org/pdf/2008.09195.pdf)
>  Fluorescence fluctuations-based super-resolution microscopy (FF-SRM) is an emerging field promising low-cost and live-cell compatible imaging beyond the resolution of conventional optical microscopy. A comprehensive overview on how the nature of fluctuations, label density, out-of-focus light, sub-cellular dynamics, and the sample itself influence the reconstruction in FF-SRM is crucial to design appropriate biological experiments. We have experimentally compared several of the recently developed FF-SRM techniques (namely ESI, bSOFI, SRRF, SACD, MUSICAL and HAWK) on widefield fluorescence image sequences of a diverse set of samples (namely liposomes, tissues, fixed and living cells), and on three-dimensional simulated data where the ground truth is available. The simulated microscopy data showed that the different techniques have different requirements for signal fluctuation to achieve their optimal performance. While different levels of signal fluctuations had little effect on the SRRF, ESI and SACD images, image reconstructions from both bSOFI and MUSICAL displayed a substantial improvement in their noise rejection, z-sectioning, and overall super-resolution capabilities.      
### 26.Conditional Entropy Coding for Efficient Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2008.09180.pdf)
>  We propose a very simple and efficient video compression framework that only focuses on modeling the conditional entropy between frames. Unlike prior learning-based approaches, we reduce complexity by not performing any form of explicit transformations between frames and assume each frame is encoded with an independent state-of-the-art deep image compressor. We first show that a simple architecture modeling the entropy between the image latent codes is as competitive as other neural video compression works and video codecs while being much faster and easier to implement. We then propose a novel internal learning extension on top of this architecture that brings an additional 10% bitrate savings without trading off decoding speed. Importantly, we show that our approach outperforms H.265 and other deep learning baselines in MS-SSIM on higher bitrate UVG video, and against all video codecs on lower framerates, while being thousands of times faster in decoding than deep models utilizing an autoregressive entropy model.      
### 27.Blind Mask to Improve Intelligibility of Non-Stationary Noisy Speech  [ :arrow_down: ](https://arxiv.org/pdf/2008.09175.pdf)
>  This letter proposes a novel blind acoustic mask (BAM) designed to adaptively detect noise components and preserve target speech segments in time-domain. A robust standard deviation estimator is applied to the non-stationary noisy speech to identify noise masking elements. The main contribution of the proposed solution is the use of this noise statistics to derive an adaptive information to define and select samples with lower noise proportion. Thus, preserving speech intelligibility. Additionally, no information of the target speech and noise signals statistics is previously required to this non-ideal mask. The BAM and three competitive methods, Ideal Binary Mask (IBM), Target Binary Mask (TBM), and Non-stationary Noise Estimation for Speech Enhancement (NNESE), are evaluated considering speech signals corrupted by three non-stationary acoustic noises and six values of signal-to-noise ratio (SNR). Results demonstrate that the BAM technique achieves intelligibility gains comparable to ideal masks while maintaining good speech quality.      
### 28.Defending Against Adversarial Attacks in Transmission- and Distribution-level PMU Data  [ :arrow_down: ](https://arxiv.org/pdf/2008.09153.pdf)
>  Phasor measurement units (PMUs) provide high-fidelity data that improve situation awareness of electric power grid operations. PMU datastreams inform wide-area state estimation, monitor area control error, and facilitate event detection in real time. As PMU data become more available and increasingly reliable, these devices are found in new roles within control systems, such as remedial action schemes and early warning detection systems. As with other cyber physical systems, maintaining data integrity and security pose a significant challenge for power system operators. In this paper, we present a comprehensive analysis of multiple machine learning techniques to detect malicious data injection within PMU data streams. The two datasets used in this study come from two PMU networks: an inter-university, research-grade distribution network spanning three institutions in the U.S. Pacific Northwest, and a utility transmission network from the Bonneville Power Administration. We implement the detection algorithms with TensorFlow, an open-source software library for machine learning, and the results demonstrate potential for distributing the training workload and achieving higher performance, while maintaining effectiveness in the detection of spoofed data.      
### 29.Robust and Efficient Swarm Communication Topologies for Hostile Environments  [ :arrow_down: ](https://arxiv.org/pdf/2008.09575.pdf)
>  Swarm Intelligence-based optimization techniques combine systematic exploration of the search space with information available from neighbors and rely strongly on communication among agents. These algorithms are typically employed to solve problems where the function landscape is not adequately known and there are multiple local optima that could result in premature convergence for other algorithms. Applications of such algorithms can be found in communication systems involving design of networks for efficient information dissemination to a target group, targeted drug-delivery where drug molecules search for the affected site before diffusing, and high-value target localization with a network of drones. In several of such applications, the agents face a hostile environment that can result in loss of agents during the search. Such a loss changes the communication topology of the agents and hence the information available to agents, ultimately influencing the performance of the algorithm. In this paper, we present a study of the impact of loss of agents on the performance of such algorithms as a function of the initial network configuration. We use particle swarm optimization to optimize an objective function with multiple sub-optimal regions in a hostile environment and study its performance for a range of network topologies with loss of agents. The results reveal interesting trade-offs between efficiency, robustness, and performance for different topologies that are subsequently leveraged to discover general properties of networks that maximize performance. Moreover, networks with small-world properties are seen to maximize performance under hostile conditions.      
### 30.Change Point Detection in Time Series Data using Autoencoders with a Time-Invariant Representation  [ :arrow_down: ](https://arxiv.org/pdf/2008.09524.pdf)
>  Change point detection (CPD) aims to locate abrupt property changes in time series data. Recent CPD methods demonstrated the potential of using deep learning techniques, but often lack the ability to identify more subtle changes in the autocorrelation statistics of the signal and suffer from a high false alarm rate. To address these issues, we employ an autoencoder-based methodology with a novel loss function, through which the used autoencoders learn a partially time-invariant representation that is tailored for CPD. The result is a flexible method that allows the user to indicate whether change points should be sought in the time domain, frequency domain or both. Detectable change points include abrupt changes in the slope, mean, variance, autocorrelation function and frequency spectrum. We demonstrate that our proposed method is consistently highly competitive or superior to baseline methods on diverse simulated and real-life benchmark data sets. Finally, we mitigate the issue of false detection alarms through the use of a postprocessing procedure that combines a matched filter and a newly proposed change point score. We show that this combination drastically improves the performance of our method as well as all baseline methods.      
### 31.Graph learning under spectral sparsity constraints  [ :arrow_down: ](https://arxiv.org/pdf/2008.09522.pdf)
>  Graph inference plays an essential role in machine learning, pattern recognition, and classification. Signal processing based approaches in literature generally assume some variational property of the observed data on the graph. We make a case for inferring graphs on which the observed data has high variation. We propose a signal processing based inference model that allows for wideband frequency variation in the data and propose an algorithm for graph inference. The proposed inference algorithm consists of two steps: 1) learning orthogonal eigenvectors of a graph from the data; 2) recovering the adjacency matrix of the graph topology from the given graph eigenvectors. The first step is solved by an iterative algorithm with a closed-form solution. In the second step, the adjacency matrix is inferred from the eigenvectors by solving a convex optimization problem. Numerical results on synthetic data show the proposed inference algorithm can effectively capture the meaningful graph topology from observed data under the wideband assumption.      
### 32.The Coverage Overlapping Problem of Serving Arbitrary Crowds in 3D Drone Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2008.09519.pdf)
>  Providing coverage for flash crowds is an important application for drone base stations (DBSs). However, any arbitrary crowd is likely to be distributed at a high density. Under the condition for each DBS to serve the same number of ground users, multiple DBSs may be placed at the same horizontal location but different altitudes and will cause severe co-channel interference, to which we refer as the coverage overlapping problem. To solve this problem, we then proposed the data-driven 3D placement (DDP) and the enhanced DDP (eDDP) algorithms. The proposed DDP and eDDP can effectively find the appropriate number, altitude, location, and coverage of DBSs in the serving area in polynomial time to maximize the system sum rate and guarantee the minimum data rate requirement of the user equipment. The simulation results show that, compared with the balanced k-means approach, the proposed eDDP can increase the system sum rate by 200% and reduce the computation time by 50%. In particular, eDDP can effectively reduce the occurrence of the coverage overlapping problem and then outperform DDP by about 100% in terms of system sum rate.      
### 33.RespVAD: Voice Activity Detection via Video-Extracted Respiration Patterns  [ :arrow_down: ](https://arxiv.org/pdf/2008.09466.pdf)
>  Voice Activity Detection (VAD) refers to the task of identification of regions of human speech in digital signals such as audio and video. While VAD is a necessary first step in many speech processing systems, it poses challenges when there are high levels of ambient noise during the audio recording. To improve the performance of VAD in such conditions, several methods utilizing the visual information extracted from the region surrounding the mouth/lip region of the speakers' video recording have been proposed. Even though these provide advantages over audio-only methods, they depend on faithful extraction of lip/mouth regions. Motivated by these, a new paradigm for VAD based on the fact that respiration forms the primary source of energy for speech production is proposed. Specifically, an audio-independent VAD technique using the respiration pattern extracted from the speakers' video is developed. The Respiration Pattern is first extracted from the video focusing on the abdominal-thoracic region of a speaker using an optical flow based method. Subsequently, voice activity is detected from the respiration pattern signal using neural sequence-to-sequence prediction models. The efficacy of the proposed method is demonstrated through experiments on a challenging dataset recorded in real acoustic environments and compared with four previous methods based on audio and visual cues.      
### 34.Method to Classify Skin Lesions using Dermoscopic images  [ :arrow_down: ](https://arxiv.org/pdf/2008.09418.pdf)
>  Skin cancer is the most common cancer in the existing world constituting one-third of the cancer cases. Benign skin cancers are not fatal, can be cured with proper medication. But it is not the same as the malignant skin cancers. In the case of malignant melanoma, in its peak stage, the maximum life expectancy is less than or equal to 5 years. But, it can be cured if detected in early stages. Though there are numerous clinical procedures, the accuracy of diagnosis falls between 49% to 81% and is time-consuming. So, dermoscopy has been brought into the picture. It helped in increasing the accuracy of diagnosis but could not demolish the error-prone behaviour. A quick and less error-prone solution is needed to diagnose this majorly growing skin cancer. This project deals with the usage of deep learning in skin lesion classification. In this project, an automated model for skin lesion classification using dermoscopic images has been developed with CNN(Convolution Neural Networks) as a training model. Convolution neural networks are known for capturing features of an image. So, they are preferred in analyzing medical images to find the characteristics that drive the model towards success. Techniques like data augmentation for tackling class imbalance, segmentation for focusing on the region of interest and 10-fold cross-validation to make the model robust have been brought into the picture. This project also includes usage of certain preprocessing techniques like brightening the images using piece-wise linear transformation function, grayscale conversion of the image, resize the image. This project throws a set of valuable insights on how the accuracy of the model hikes with the bringing of new input strategies, preprocessing techniques. The best accuracy this model could achieve is 0.886      
### 35.Automatic sleep stage classification with deep residual networks in a mixed-cohort setting  [ :arrow_down: ](https://arxiv.org/pdf/2008.09416.pdf)
>  Study Objectives: Sleep stage scoring is performed manually by sleep experts and is prone to subjective interpretation of scoring rules with low intra- and interscorer reliability. Many automatic systems rely on few small-scale databases for developing models, and generalizability to new datasets is thus unknown. We investigated a novel deep neural network to assess the generalizability of several large-scale cohorts. <br>Methods: A deep neural network model was developed using 15684 polysomnography studies from five different cohorts. We applied four different scenarios: 1) impact of varying time-scales in the model; 2) performance of a single cohort on other cohorts of smaller, greater or equal size relative to the performance of other cohorts on a single cohort; 3) varying the fraction of mixed-cohort training data compared to using single-origin data; and 4) comparing models trained on combinations of data from 2, 3, and 4 cohorts. <br>Results: Overall classification accuracy improved with increasing fractions of training data (0.25$\%$: 0.782 $\pm$ 0.097, 95$\%$ CI [0.777-0.787]; 100$\%$: 0.869 $\pm$ 0.064, 95$\%$ CI [0.864-0.872]), and with increasing number of data sources (2: 0.788 $\pm$ 0.102, 95$\%$ CI [0.787-0.790]; 3: 0.808 $\pm$ 0.092, 95$\%$ CI [0.807-0.810]; 4: 0.821 $\pm$ 0.085, 95$\%$ CI [0.819-0.823]). Different cohorts show varying levels of generalization to other cohorts. <br>Conclusions: Automatic sleep stage scoring systems based on deep learning algorithms should consider as much data as possible from as many sources available to ensure proper generalization. Public datasets for benchmarking should be made available for future research.      
### 36.Robust Secure UAV Communications with the Aid of Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2008.09404.pdf)
>  This paper investigates a novel unmanned aerial vehicles (UAVs) secure communication system with the assistance of reconfigurable intelligent surfaces (RISs), where an UAV and a ground user communicate with each other, while an eavesdropper tends to wiretap their information. Due to the limited capacity of UAVs, a RIS is applied to further improve the quality of the secure communications. The time division multiple access (TDMA) protocol is applied for the communications between the UAV and the ground user, namely, the downlink (DL) and the uplink (UL) communications. In particular, the channel state information (CSI) of the eavesdropping channels is assumed to be imperfect. We aim to maximize the average worst-case secrecy rate by the robust joint design of the UAV's trajectory, RIS's passive beamforming, and transmit power of the legitimate transmitters. It is challenging to solve the Joint UL/DL optimization problem due to its non-convexity. To this end, we develop an efficient algorithm based on the alternating optimization (AO) technique. Specifically, the formulated problem is divided into three sub-problems, and the successive convex approximation (SCA), S-Procedure, and semidefinite relaxation (SDR) are applied to tackle these non-convex sub-problems. Numerical results demonstrate that the proposed algorithm can considerably improve the average secrecy rate compared with the benchmark algorithms, and also confirm the robustness of the proposed algorithm.      
### 37.CDE-GAN: Cooperative Dual Evolution Based Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2008.09388.pdf)
>  Generative adversarial networks (GANs) have been a popular deep generative model for real-word applications. Despite many recent efforts on GANs have been contributed, however, mode collapse and instability of GANs are still open problems caused by their adversarial optimization difficulties. In this paper, motivated by the cooperative co-evolutionary algorithm, we propose a Cooperative Dual Evolution based Generative Adversarial Network (CDE-GAN) to circumvent these drawbacks. In essence, CDE-GAN incorporates dual evolution with respect to generator(s) and discriminators into a unified evolutionary adversarial framework, thus it exploits the complementary properties and injects dual mutation diversity into training to steadily diversify the estimated density in capturing multi-modes, and to improve generative performance. Specifically, CDE-GAN decomposes the complex adversarial optimization problem into two subproblems (generation and discrimination), and each subproblem is solved with a separated subpopulation (E-Generators and EDiscriminators), evolved by an individual evolutionary algorithm. Additionally, to keep the balance between E-Generators and EDiscriminators, we proposed a Soft Mechanism to cooperate them to conduct effective adversarial training. Extensive experiments on one synthetic dataset and three real-world benchmark image datasets, demonstrate that the proposed CDE-GAN achieves the competitive and superior performance in generating good quality and diverse samples over baselines. The code and more generated results are available at our project homepage <a class="link-external link-https" href="https://shiming-chen.github.io/CDE-GAN-website/CDE-GAN.html" rel="external noopener nofollow">this https URL</a>.      
### 38.Learning Camera-Aware Noise Models  [ :arrow_down: ](https://arxiv.org/pdf/2008.09370.pdf)
>  Modeling imaging sensor noise is a fundamental problem for image processing and computer vision applications. While most previous works adopt statistical noise models, real-world noise is far more complicated and beyond what these models can describe. To tackle this issue, we propose a data-driven approach, where a generative noise model is learned from real-world noise. The proposed noise model is camera-aware, that is, different noise characteristics of different camera sensors can be learned simultaneously, and a single learned noise model can generate different noise for different camera sensors. Experimental results show that our method quantitatively and qualitatively outperforms existing statistical noise models and learning-based methods.      
### 39.Radar Imaging Based on IEEE 802.11ad Waveform  [ :arrow_down: ](https://arxiv.org/pdf/2008.09311.pdf)
>  The extension to millimeter-wave (mmWave) spectrum of communication frequency band makes it easy to implement a joint radar and communication system using single hardware. In this paper, we propose radar imaging based on the IEEE 802.11ad waveform for a vehicular setting. The necessary parameters to be estimated for inverse synthetic aperture radar (ISAR) imaging are sampled version of round-trip delay, Doppler shift, and vehicular velocity. The delay is estimated using the correlation property of Golay complementary sequences embedded on the IEEE 802.11ad preamble. The Doppler shift is first obtained from least square estimation using radar return signals and refined by correcting the phase uncertainty of Doppler shift by phase rotation. The vehicular velocity is determined from the estimated Doppler shifts and an equation of motion. Finally, an ISAR image is formed with the acquired parameters. Simulation results show that it is possible to obtain recognizable ISAR image from a point scatterer model of a realistic vehicular setting.      
### 40.Location Information Aided Multiple Intelligent Reflecting Surface Systems  [ :arrow_down: ](https://arxiv.org/pdf/2008.09248.pdf)
>  This paper proposes a novel location information aided multiple intelligent reflecting surface (IRS) systems. Assuming imperfect user location information, the effective angles from the IRS to the users are estimated, which is then used to design the transmit beam and IRS beam. Furthermore, closed-form expressions for the achievable rate are derived. The analytical findings indicate that the achievable rate can be improved by increasing the number of base station (BS) antennas or reflecting elements. Specifically, a power gain of order $N M^2$ is achieved, where $N$ is the antenna number and $M$ is the number of reflecting elements. Moreover, with a large number of reflecting elements, the individual signal to interference plus noise ratio (SINR) is proportional to $M$, while becomes proportional to $M^2$ as non-line-of-sight (NLOS) paths vanish. Also, it has been shown that high location uncertainty would significantly degrade the achievable rate. Besides, IRSs should be deployed at distinct directions (relative to the BS) and be far away from each other to reduce the interference from multiple IRSs. Finally, an optimal power allocation scheme has been proposed to improve the system performance.      
### 41.Robust Mean Estimation in High Dimensions via $\ell_0$ Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2008.09239.pdf)
>  We study the robust mean estimation problem in high dimensions, where $\alpha &lt;0.5$ fraction of the data points can be arbitrarily corrupted. Motivated by compressive sensing, we formulate the robust mean estimation problem as the minimization of the $\ell_0$-`norm' of the outlier indicator vector, under second moment constraints on the inlier data points. We prove that the global minimum of this objective is order optimal for the robust mean estimation problem, and we propose a general framework for minimizing the objective. We further leverage the $\ell_1$ and $\ell_p$ $(0&lt;p&lt;1)$, minimization techniques in compressive sensing to provide computationally tractable solutions to the $\ell_0$ minimization problem. Both synthetic and real data experiments demonstrate that the proposed algorithms significantly outperform state-of-the-art robust mean estimation methods.      
### 42.The Canonical Interval Forest (CIF) Classifier for Time Series Classification  [ :arrow_down: ](https://arxiv.org/pdf/2008.09172.pdf)
>  Time series classification (TSC) is home to a number of algorithm groups that utilise different kinds of discriminatory patterns. One of these groups describes classifiers that predict using phase dependant intervals. The time series forest (TSF) classifier is one of the most well known interval methods, and has demonstrated strong performance as well as relative speed in training and predictions. However, recent advances in other approaches have left TSF behind. TSF originally summarises intervals using three simple summary statistics. The `catch22' feature set of 22 time series features was recently proposed to aid time series analysis through a concise set of diverse and informative descriptive characteristics. We propose combining TSF and catch22 to form a new classifier, the Canonical Interval Forest (CIF). We outline additional enhancements to the training procedure, and extend the classifier to include multivariate classification capabilities. We demonstrate a large and significant improvement in accuracy over both TSF and catch22, and show it to be on par with top performers from other algorithmic classes. By upgrading the interval-based component from TSF to CIF, we also demonstrate a significant improvement in the hierarchical vote collective of transformation-based ensembles (HIVE-COTE) that combines different time series representations. HIVE-COTE using CIF is significantly more accurate on the UCR archive than any other classifier we are aware of and represents a new state of the art for TSC.      
### 43.Cooperative Multi-Point Vehicular Positioning Using Millimeter-Wave Surface Reflection (Extended version)  [ :arrow_down: ](https://arxiv.org/pdf/2008.08906.pdf)
>  Multi-point vehicular positioning is one essential operation for autonomous vehicles. However, the state-of-the-art positioning technologies, relying on reflected signals from a target (i.e., RADAR and LIDAR), cannot work without line-of-sight. Besides, it takes significant time for environment scanning and object recognition with potential detection inaccuracy, especially in complex urban situations. Some recent fatal accidents involving autonomous vehicles further expose such limitations. In this paper, we aim at overcoming these limitations by proposing a novel relative positioning approach, called Cooperative Multi-point Positioning (COMPOP). The COMPOP establishes cooperation between a target vehicle (TV) and a sensing vehicle (SV) if a LoS path exists, where a TV explicitly lets an SV to know the TV's existence by transmitting positioning waveforms. This cooperation makes it possible to remove the time-consuming scanning and target recognizing processes, facilitating real-time positioning. One prerequisite for the cooperation is a clock synchronization between a pair of TV and SV. To this end, we use a phase-differential-of-arrival based approach to remove the TV-SV clock difference from the received signal. With clock difference correction, the TV's position can be obtained via peak detection over a 3D power spectrum constructed by a Fourier transform (FT) based algorithm. The COMPOP also incorporates nearby vehicles, without knowing their locations, into the above cooperation for the case without a LoS path. The effectiveness of the COMPOP is verified by several simulations concerning practical channel parameters.      

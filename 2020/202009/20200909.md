# ArXiv eess --Wed, 9 Sep 2020
### 1.Edge Selection in Bilinear Dynamical Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03884.pdf)
>  In large-scale networks, agents (e.g., sensors and actuators) and links (e.g., couplings and communication links) can fail or be (cyber-)attacked. In this paper, we focus on continuous-time bilinear networks, where additive disturbances model attack/uncertainty on agents/states (a.k.a. node disturbances) and multiplicative disturbances model attack/uncertainty on couplings between agents/states (a.k.a. link disturbances). We then investigate a network robustness notion in terms of the underlying digraph of the network, and structure of exogenous uncertainties/attacks. Specifically, we define the robustness measure using the H2-norm of the network and calculate it in terms of the reachability Gramian of the bilinear system. The main result shows that under certain conditions, the measure is supermodular over the set of all possible attacked links. The supermodular property facilitates the efficient solution finding of the optimization problem. We conclude the paper with a few examples illustrating how different structures can make the system more or less vulnerable to malicious attacks on links and present our concluding remarks.      
### 2.Convolution Neural Networks for diagnosing colon and lung cancer histopathological images  [ :arrow_down: ](https://arxiv.org/pdf/2009.03878.pdf)
>  Lung and Colon cancer are one of the leading causes of mortality and morbidity in adults. Histopathological diagnosis is one of the key components to discern cancer type. The aim of the present research is to propose a computer aided diagnosis system for diagnosing squamous cell carcinomas and adenocarcinomas of lung as well as adenocarcinomas of colon using convolutional neural networks by evaluating the digital pathology images for these cancers. Hereby, rendering artificial intelligence as useful technology in the near future. A total of 2500 digital images were acquired from LC25000 dataset containing 5000 images for each class. A shallow neural network architecture was used classify the histopathological slides into squamous cell carcinomas, adenocarcinomas and benign for the lung. Similar model was used to classify adenocarcinomas and benign for colon. The diagnostic accuracy of more than 97% and 96% was recorded for lung and colon respectively.      
### 3.High-Bandwidth Spatial Equalization for mmWave Massive MU-MIMO with Processing-In-Memory  [ :arrow_down: ](https://arxiv.org/pdf/2009.03874.pdf)
>  All-digital basestation (BS) architectures enable superior spectral efficiency compared to hybrid solutions in massive multi-user MIMO systems. However, supporting large bandwidths with all-digital architectures at mmWave frequencies is challenging as traditional baseband processing would result in excessively high power consumption and large silicon area. The recently-proposed concept of finite-alphabet equalization is able to address both of these issues by using equalization matrices that contain low-resolution entries to lower the power and complexity of high-throughput matrix-vector products in hardware. In this paper, we explore two different finite-alphabet equalization hardware implementations that tightly integrate the memory and processing elements: (i) a parallel array of multiply-accumulate (MAC) units and (ii) a bit-serial processing-in-memory (PIM) architecture. Our all-digital VLSI implementation results in 28nm CMOS show that the bit-serial PIM architecture reduces the area and power consumption up to a factor of 2x and 3x, respectively, when compared to a parallel MAC array that operates at the same throughput.      
### 4.$\mathcal{RL}_1$-$\mathcal{GP}$: Safe Simultaneous Learning and Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.03864.pdf)
>  We present $\mathcal{RL}_1$-$\mathcal{GP}$, a control framework that enables safe simultaneous learning and control for systems subject to uncertainties. The two main constituents are Riemannian energy $\mathcal{L}_1$ ($\mathcal{RL}_1$) control and Bayesian learning in the form of Gaussian process (GP) regression. The $\mathcal{RL}_1$ controller ensures that control objectives are met while providing safety certificates. Furthermore, $\mathcal{RL}_1$-$\mathcal{GP}$ incorporates any available data into a GP model of uncertainties, which improves performance and enables the motion planner to achieve optimality safely. This way, the safe operation of the system is always guaranteed, even during the learning transients. We provide a few illustrative examples for the safe learning and control of planar quadrotor systems in a variety of environments.      
### 5.Maximizing Privacy in MIMO Cyber-Physical Systems Using the Chapman-Robbins Bound  [ :arrow_down: ](https://arxiv.org/pdf/2009.03850.pdf)
>  Privacy breaches of cyber-physical systems could expose vulnerabilities to an adversary. Here, privacy leaks of step inputs to linear-time-invariant systems are mitigated through additive Gaussian noise. Fundamental lower bounds on the privacy are derived, which are based on the variance of any estimator that seeks to recreate the input. Fully private inputs are investigated and related to transmission zeros. Thereafter, a method to increase the privacy of optimal step inputs is presented and a privacy-utility trade-off bound is derived. Finally, these results are verified on data from the KTH Live-In Lab Testbed, showing good correspondence with theoretical results.      
### 6.ECG Beats Fast Classification Base on Sparse Dictionaries  [ :arrow_down: ](https://arxiv.org/pdf/2009.03792.pdf)
>  Feature extraction plays an important role in Electrocardiogram (ECG) Beats classification system. Compared to other popular methods, VQ method performs well in feature extraction from ECG with advantages of dimensionality reduction. In VQ method, a set of dictionaries corresponding to segments of ECG beats is trained, and VQ codes are used to represent each heartbeat. However, in practice, VQ codes optimized by k-means or k-means++ exist large quantization errors, which results in VQ codes for two heartbeats of the same type being very different. So the essential differences between different types of heartbeats cannot be representative well. On the other hand, VQ uses too much data during codebook construction, which limits the speed of dictionary learning. In this paper, we propose a new method to improve the speed and accuracy of VQ method. To reduce the computation of codebook construction, a set of sparse dictionaries corresponding to wave segments of ECG beats is constructed. After initialized, sparse dictionaries are updated efficiently by Feature-sign and Lagrange dual algorithm. Based on those dictionaries, a set of codes can be computed to represent original ECG beats.Experimental results show that features extracted from ECG by our method are more efficient and separable. The accuracy of our method is higher than other methods with less time consumption of feature extraction      
### 7.Payoff distribution in robust coalitional games on time-varying networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03783.pdf)
>  In this paper, we consider a sequence of transferable utility (TU) coalitional games where the coalitional values are unknown but vary within certain bounds. As a solution to the resulting family of games, we propose the notion of "robust CORE". Our main contribution is to design two distributed algorithms, namely, distributed payoff allocation and distributed bargaining, that converge to a consensual payoff distribution in the robust CORE. We adopt an operator-theoretic perspective to show convergence of both algorithms executed on time-varying communication networks. An energy storage optimization application motivates our framework for "robust coalitional games".      
### 8.Federated Classification using Parsimonious Functions in Reproducing Kernel Hilbert Spaces  [ :arrow_down: ](https://arxiv.org/pdf/2009.03768.pdf)
>  Federated learning forms a global model using data collected from a federation agent. This type of learning has two main challenges: the agents generally don't collect data over the same distribution, and the agents have limited capabilities of storing and transmitting data. Therefore, it is impractical for each agent to send the entire data over the network. Instead, each agent must form a local model and decide what information is fundamental to the learning problem, which will be sent to a central unit. The central unit can then form the global model using only the information received from the agents. We propose a method that tackles these challenges. First each agent forms a local model using a low complexity reproducing kernel Hilbert space representation. From the model the agents identify the fundamental samples which are sent to the central unit. The fundamental samples are obtained by solving the dual problem. The central unit then forms the global model. We show that the solution of the federated learner converges to that of the centralized learner asymptotically as the sample size increases. The performance of the proposed algorithm is evaluated using experiments with both simulated data and real data sets from an activity recognition task, for which the data is collected from a wearable device. The experimentation results show that the accuracy of our method converges to that of a centralized learner with increasing sample size.      
### 9.Safe-by-Design Control for Euler-Lagrange Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.03767.pdf)
>  Safety-critical control is characterized as ensuring constraint satisfaction for a given dynamical system. Control barrier functions are valuable for satisfying system constraints and allow for modular control design for general nonlinear systems. However a main drawback to existing techniques is the proper construction of these barrier functions to satisfy system and input constraints, and addressing multiple state constraints simultaneously. In this paper, we propose a methodology to construct multiple, non-conflicting control barrier functions for Euler-Lagrange systems subject to input constraints, while concurrently taking into account robustness margins and sampling-time effects. The proposed approach consists of an algorithm for barrier function construction and two control laws (one continuous and one sampled-data) to enforce safety (i.e satisfy position and velocity constraints). The proposed method is validated in simulation on a 2-DOF planar manipulator.      
### 10.Prediction-Coherent LSTM-based Recurrent Neural Network for Safer Glucose Predictions in Diabetic People  [ :arrow_down: ](https://arxiv.org/pdf/2009.03722.pdf)
>  In the context of time-series forecasting, we propose a LSTM-based recurrent neural network architecture and loss function that enhance the stability of the predictions. In particular, the loss function penalizes the model, not only on the prediction error (mean-squared error), but also on the predicted variation error. <br>We apply this idea to the prediction of future glucose values in diabetes, which is a delicate task as unstable predictions can leave the patient in doubt and make him/her take the wrong action, threatening his/her life. The study is conducted on type 1 and type 2 diabetic people, with a focus on predictions made 30-minutes ahead of time. <br>First, we confirm the superiority, in the context of glucose prediction, of the LSTM model by comparing it to other state-of-the-art models (Extreme Learning Machine, Gaussian Process regressor, Support Vector Regressor). <br>Then, we show the importance of making stable predictions by smoothing the predictions made by the models, resulting in an overall improvement of the clinical acceptability of the models at the cost in a slight loss in prediction accuracy. <br>Finally, we show that the proposed approach, outperforms all baseline results. More precisely, it trades a loss of 4.3\% in the prediction accuracy for an improvement of the clinical acceptability of 27.1\%. When compared to the moving average post-processing method, we show that the trade-off is more efficient with our approach.      
### 11.Deep Cyclic Generative Adversarial Residual Convolutional Networks for Real Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2009.03693.pdf)
>  Recent deep learning based single image super-resolution (SISR) methods mostly train their models in a clean data domain where the low-resolution (LR) and the high-resolution (HR) images come from noise-free settings (same domain) due to the bicubic down-sampling assumption. However, such degradation process is not available in real-world settings. We consider a deep cyclic network structure to maintain the domain consistency between the LR and HR data distributions, which is inspired by the recent success of CycleGAN in the image-to-image translation applications. We propose the Super-Resolution Residual Cyclic Generative Adversarial Network (SRResCycGAN) by training with a generative adversarial network (GAN) framework for the LR to HR domain translation in an end-to-end manner. We demonstrate our proposed approach in the quantitative and qualitative experiments that generalize well to the real image super-resolution and it is easy to deploy for the mobile/embedded devices. In addition, our SR results on the AIM 2020 Real Image SR Challenge datasets demonstrate that the proposed SR approach achieves comparable results as the other state-of-art methods.      
### 12.Toward the pre-cocktail party problem with TasTas$+$  [ :arrow_down: ](https://arxiv.org/pdf/2009.03692.pdf)
>  Deep neural network with dual-path bi-directional long short-term memory (BiLSTM) block has been proved to be very effective in sequence modeling, especially in speech separation, e.g. DPRNN-TasNet \cite{luo2019dual}, TasTas \cite{shi2020speech}. In this paper, we propose two improvements of TasTas \cite{shi2020speech} for end-to-end approach to monaural speech separation in pre-cocktail party problems, which consists of 1) generate new training data through the original training batch in real time, and 2) train each module in TasTas separately. The new approach is called TasTas$+$, which takes the mixed utterance of five speakers and map it to five separated utterances, where each utterance contains only one speaker's voice. For the objective, we train the network by directly optimizing the utterance level scale-invariant signal-to-distortion ratio (SI-SDR) in a permutation invariant training (PIT) style. Our experiments on the public WSJ0-5mix data corpus results in 11.14dB SDR improvement, which shows our proposed networks can lead to performance improvement on the speaker separation task. We have open-sourced our re-implementation of the DPRNN-TasNet in <a class="link-external link-https" href="https://github.com/ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" rel="external noopener nofollow">this https URL</a>, and our TasTas$+$ is realized based on this implementation of DPRNN-TasNet, it is believed that the results in this paper can be reproduced with ease.      
### 13.Synthetic multi-focus optical-resolution photoacoustic microscope for large volumetric imaging  [ :arrow_down: ](https://arxiv.org/pdf/2009.03689.pdf)
>  Photoacoustic microscopy is becoming an important tool for the biomedical research. It has been widely used in biological researches, such as structural imaging of vasculature, brain structural and functional imaging, and tumor detection. The conventional optical-resolution photoacoustic microscopy (OR- PAM) employs focused gaussian beam to achieve high lateral resolution by a microscope objective with high numerical apertures. Since the focused gaussian beam only has narrow depth range in focus, little detail in depth direction can be revealed. Here, we developed a synthetic multi-focus optical-resolution photoacoustic microscope using multi-scale weighted gradient-based fusion. Based on the saliency of the image structure, a gradient-based multi-focus image fusion method is used, and a multi-scale method is used to determine the gradient weights. We pay special attention to a dual-scale scheme, which effectively solves the fusion problem caused by anisotropic blur and registration error. First, the structure-based large-scale focus measurement method is used to reduce the effect of anisotropic blur and registration error on the detection of the focus area, and then the gradient weights near the edge wave are used by applying the small-scale focus measure. Simulation was performed to test the performance of our method, different focused images were used to verify the feasibility of the method. Performance of our method was analyzed by calculating Entropy, Mean Square Error (MSE) and Edge strength. The result of simulation shown that this method can extend the depth of field of PAM two times without the sacrifice of lateral resolution. And the in vivo imaging of the zebra fish further demonstrates the feasibility of our method.      
### 14.AutoKWS: Keyword Spotting with Differentiable Architecture Search  [ :arrow_down: ](https://arxiv.org/pdf/2009.03658.pdf)
>  Smart audio devices are gated by an always-on lightweight keyword spotting program to reduce power consumption. It is however challenging to design models that have both high accuracy and low latency for accurate and fast responsiveness. Many efforts have been made to develop end-to-end neural networks, in which depthwise separable convolutions, temporal convolutions, and LSTMs are adopted as building units. Nonetheless, these networks designed with human expertise may not achieve an optimal trade-off in an expansive search space. In this paper, we propose to leverage recent advances in differentiable neural architecture search to discover more efficient networks. Our found model attains 97.2% top-1 accuracy on Google Speech Command Dataset v1.      
### 15.Unsupervised Change Detection in Satellite Images with Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2009.03630.pdf)
>  Detecting changed regions in paired satellite images plays a key role in many remote sensing applications. The evolution of recent techniques could provide satellite images with very high spatial resolution (VHR) and made it challenging to apply image coregistration whose accuracy is the basis of many change detection methods.Due to the advantage in deep feature representation, deep learning is introduced to detect changes on unregistered images. However, the absence of ground truth makes the performance of deep learning models in unsupervised task hard to be evaluated or be <a class="link-external link-http" href="http://guaranteed.To" rel="external noopener nofollow">this http URL</a> alleviate the effect of unregistered pairs and make better use of deep learning structures, we propose a novel change detection procedure based on a special neural network architecture---Generative Adversarial Network (GAN).GAN features generating realistic images rather than giving hypervectors that contain visual features, so it is easy to evaluate the GAN model by judging the generated images. In this paper, we show that GAN model can be trained upon a pair of images through utilizing the proposed expanding strategy to create a training set and optimising designed objective functions. The optimised GAN model would produce many coregistered images where changes can be easily spotted and then the change map can be presented through a comparison strategy using these generated images explicitly.Compared to other deep learning-based methods, our method is less sensitive to the problem of unregistered images and makes most of the deep learning structure.Experimental results on synthetic images and real data with many different scenes could demonstrate the effectiveness of the proposed approach.      
### 16.Joint deconvolution and blind source separation on the sphere with an application to radio-astronomy  [ :arrow_down: ](https://arxiv.org/pdf/2009.03606.pdf)
>  Blind source separation is one of the major analysis tool to extract relevant information from multichannel data. While being central, joint deconvolution and blind source separation (DBSS) methods are scarce. To that purpose, a DBSS algorithm coined SDecGMCA is proposed. It is designed to process data sampled on the sphere, allowing large-field data analysis in radio-astronomy.      
### 17.Are wave union methods still suitable for 20 nm FPGA-based high-resolution (&lt; 2 ps) time-to-digital converters?  [ :arrow_down: ](https://arxiv.org/pdf/2009.03591.pdf)
>  This paper presents several new structures to pursue high-resolution (&lt; 2 ps) time-to-digital converters (TDCs) in Xilinx 20 nm UltraScale field-programmable gate arrays (FPGAs). The proposed TDCs combined the advantages of 1) our newly proposed sub-tapped delay line (sub-TDL) architecture effective in removing bubbles and zero-bins and 2) the wave union (WU) A method to improve the resolution and reduce the impact introduced from ultrawide bins. We also compared the proposed WU/sub-TDL TDC with the TDC combining the dual sampling (DS) structure and the sub-TDL technique. Moreover, we introduced a binning method to improve the linearity and derived a formula of the total measurement uncertainty for a single-stage TDL-TDC to obtain its root-mean-square (RMS) resolution. Results conclude that the proposed designs are cost-effective in logic resources and have the potential for multiple-channel implementations. Different from the conclusions from a previous study, we found that the wave union is still influential in UltraScale devices when combining with our sub-TDL structure. We also compared with other published TDCs to demonstrate where the proposed TDCs stand.      
### 18.On Spectral Properties of Signed Laplacians with Connections to Eventual Positivity  [ :arrow_down: ](https://arxiv.org/pdf/2009.03581.pdf)
>  Signed graphs have appeared in a broad variety of applications, ranging from social networks to biological networks, from distributed control and computation to power systems. In this paper, we investigate spectral properties of signed Laplacians for undirected signed graphs. We find conditions on the negative weights under which a signed Laplacian is positive semidefinite via the Kron reduction and multiport network theory. For signed Laplacians that are indefinite, we characterize their inertias with the same framework. Furthermore, we build connections between signed Laplacians, generalized M-matrices, and eventually exponentially positive matrices.      
### 19.Securing Mobile Multiuser Transmissions with UAVs in the Presence of Multiple Eavesdroppers  [ :arrow_down: ](https://arxiv.org/pdf/2009.03557.pdf)
>  This paper discusses the problem of securing the transmissions of multiple ground users against eavesdropping attacks. We propose and optimize the deployment of a single unmanned aerial vehicle (UAV), which serves as an aerial relay between the user cluster and the base station. The focus is on maximizing the secrecy energy efficiency by jointly optimizing the uplink transmission powers of the ground users and the position of the UAV. The joint optimization problem is nonconvex; therefore we split it into two subproblems and solve them using an iterative algorithm.      
### 20.Predictions of Subjective Ratings and Spoofing Assessments of Voice Conversion Challenge 2020 Submissions  [ :arrow_down: ](https://arxiv.org/pdf/2009.03554.pdf)
>  The Voice Conversion Challenge 2020 is the third edition under its flagship that promotes intra-lingual semiparallel and cross-lingual voice conversion (VC). While the primary evaluation of the challenge submissions was done through crowd-sourced listening tests, we also performed an objective assessment of the submitted systems. The aim of the objective assessment is to provide complementary performance analysis that may be more beneficial than the time-consuming listening tests. In this study, we examined five types of objective assessments using automatic speaker verification (ASV), neural speaker embeddings, spoofing countermeasures, predicted mean opinion scores (MOS), and automatic speech recognition (ASR). Each of these objective measures assesses the VC output along different aspects. We observed that the correlations of these objective assessments with the subjective results were high for ASV, neural speaker embedding, and ASR, which makes them more influential for predicting subjective test results. In addition, we performed spoofing assessments on the submitted systems and identified some of the VC methods showing a potentially high security risk.      
### 21.An IMM-based Decentralized Cooperative Localization with LoS and NLoS UWB Inter-agent Ranging  [ :arrow_down: ](https://arxiv.org/pdf/2009.03538.pdf)
>  This paper studies the global localization of a group of communicating mobile agents via an ultra-wideband (UWB) inter-agent ranging aided dead-reckoning system. We propose a loosely coupled cooperative localization algorithm that acts as an augmentation atop the local dead-reckoning system of each mobile agent. This augmentation becomes active only when an agent wants to process a relative measurement it has taken. The main contribution of this paper is to address the challenges in the proper processing of the UWB range measurements in the framework of the proposed cooperative localization. Even though UWB offers a decimeter level accuracy in line-of-sight (LoS) ranging, its accuracy degrades significantly in non-line-of-sight (NLoS) due to the significant unknown positive bias in the measurements. Thus, the measurement models for the UWB LoS and NLoS ranging conditions are different, and proper processing of NLoS measurements requires a bias compensation measure. On the other hand, in practice, the measurement modal discriminators determine the type of UWB range measurements with only some level of certainty. To take into account the probabilistic nature of the NLoS identifiers, our proposed cooperative localization employs an interacting multiple model (IMM) estimator. The effectiveness of our proposed method is demonstrated via an experiment for a group of pedestrians who use UWB relative range measurements among themselves to improve their geolocation using a shoe-mounted INS system.      
### 22.Communications and Networking Standards for UASs: The 3GPP Perspective and Research Drivers  [ :arrow_down: ](https://arxiv.org/pdf/2009.03533.pdf)
>  The unmanned aircraft system (UAS) is becoming increasingly popular for a myriad of applications, including commercial, public safety, and mission critical. A UAS consists of an unmanned aerial vehicle (UAV) and the UAV controller which use radios to communicate. While the controller is traditionally a human operator who is maintaining line of sight with the UAV it controls, the trend is moving towards long-range control and autonomous operation. To enable this, reliable and omnipresent wireless connectivity is indispensable as it is the only way to control or take control of the UAV flight. This paper surveys the ongoing 3GPP standardization activities for enabling networked UAVs. In particular, we discuss the requirements, envisaged architecture and services to be offered to UAVs and to remote controllers, which will communicate with one another and the UAS Traffic Management (UTM) through cellular networks. Global research and major R\&amp;D platforms are presented as those will drive future standards.      
### 23.Energy-Efficient NOMA Multicasting System for 5G Cellular V2X Communications with Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2009.03507.pdf)
>  Vehicle-to-everything (V2X) is a modern vehicular technology that improves conventional vehicle systems in traffic and communications. V2X communications demand energyefficient and high-reliability networking because of massive vehicular connections and high mobility wireless channels. Nonorthogonal multiple access (NOMA) is a promising solution for 5G V2X services that intend to guarantee high reliability, quality-of-service (QoS) provisioning, and massive connectivity requirements. In V2X, it is vital to inspect imperfect CSI because the high mobility of vehicles leads to more channel estimation uncertainties. Unlike existing literatures, we propose energy-efficient roadside units (RSUs) assisted NOMA multicasting system for 5G cellular V2X communications, and investigate the energy-efficient power allocation problem. The proposed system multicast the information through low complexity optimal power allocation algorithms used under channel outage probability constraint of vehicles with imperfect CSI, QoS constraints of vehicles, and transmit power limits constraint of RSUs. The formulated problem with the channel outage probability constraint is a nonconvex probabilistic optimization problem. This problem is solved efficiently by converting the probabilistic problem through relaxation into a non-probabilistic problem.      
### 24.On The Synergy Between Nonconvex Extensions of The Tensor Nuclear Norm for Tensor Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2009.03503.pdf)
>  Low-rank tensor recovery has attracted much attention among various tensor recovery approaches. A tensor rank has several definitions, unlike the matrix rank--e.g. the CP rank and the Tucker rank. Many low-rank tensor recovery methods are focused on the Tucker rank. Since the Tucker rank is nonconvex and discontinuous, many relaxations of the Tucker rank have been proposed, e.g., the tensor nuclear norm, weighted tensor nuclear norm, and weighted tensor Schatten-$p$ norm. In particular, the weighted tensor Schatten-p norm has two parameters, the weight and $p$, and the tensor nuclear norm and weighted tensor nuclear norm are special cases of these parameters. However, there has been no detailed discussion of whether the effects of the weighting and $p$ are synergistic. In this paper, we propose a novel low-rank tensor completion model using the weighted tensor Schatten-$p$ norm to reveal the relationships between the weight and $p$. To clarify whether complex methods such as the weighted tensor Schatten-$p$ norm are necessary, we compare them with a simple method using rank-constrained minimization. It was found that the simple methods did not outperform the complex methods unless the rank of the original tensor could be accurately known. If we can obtain the ideal weight, $p = 1$ is sufficient, although it is necessary to set $p&lt;1$ when using the weights obtained from observations. These results are consistent with existing reports.      
### 25.Waypoint Following Dynamics of a Quaternion Error Feedback Attitude Control System  [ :arrow_down: ](https://arxiv.org/pdf/2009.03459.pdf)
>  Closed-loop attitude steering can be used to implement a non-standard attitude maneuver by using a conventional attitude control system to track a non-standard attitude profile. The idea has been employed to perform zero-propellant maneuvers on the International Space Station and minimum time maneuvers on NASA's TRACE space telescope. A challenge for operational implementation of the idea is the finite capacity of a space vehicle's command storage buffer. One approach to mitigate the problem is to downsample-and-hold the attitude commands as a set of waypoints for the attitude control system to follow. In this paper, we explore the waypoint following dynamics of a quaternion error feedback control law for downsample-and-hold. It is shown that downsample-and-hold induces a ripple between downsamples that causes the satellite angular rate to significantly overshoot the desired limit. Analysis in the $z$-domain is carried out in order to understand the phenomenon. An interpolating Chebyshev-type filter is proposed that allows attitude commands to be encoded in terms of a set of filter coefficients. Using the interpolating filter, commands can be issued at the ACS rate but with significantly reduced memory requirements. The attitude control system of NASA's Lunar Reconnaissance Orbiter is used as an example to illustrate the behavior of a practical attitude control system.      
### 26.Machine learning-based method for linearization and error compensation of an absolute rotary encoder  [ :arrow_down: ](https://arxiv.org/pdf/2009.03442.pdf)
>  The main objective of this work is to develop a miniaturized, high accuracy, single-turn absolute, rotary encoder called ASTRAS360. Its measurement principle is based on capturing an image that uniquely identifies the rotation angle. To evaluate this angle, the image first has to be classified into its sector based on its color, and only then can the angle be regressed. In-spired by machine learning, we built a calibration setup, able to generate labeled training data automatically. We used these training data to test, characterize, and compare several machine learning algorithms for the classification and the regression. In an additional experiment, we also characterized the tolerance of our rotary encoder to eccentric mounting. Our findings demonstrate that various algorithms can perform these tasks with high accuracy and reliability; furthermore, providing extra-inputs (e.g. rotation direction) allows the machine learning algorithms to compensate for the mechanical imperfections of the rotary encoder.      
### 27.A Distributed Power Control Algorithm for Energy Efficiency Maximization in Wireless Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03433.pdf)
>  In this paper, we propose a distributed power control algorithm for addressing the global energy efficiency (GEE) maximization problem subject to satisfying a minimum target SINR for all user equipments (UEs) in wireless cellular networks. We state the problem as a multi-objective optimization problem which targets minimizing total power consumption and maximizing total throughput, simultaneously, while a minimum target SINR is guaranteed for all UEs. We propose an iterative scheme executed in the UEs to control their transmit power using individual channel state information (CSI) such that the GEE is maximized in a distributed manner. We prove the convergence of the proposed iterative algorithm to its corresponding unique fixed point also shown by our numerical results. Additionally, simulation results demonstrate that our proposed scheme outperforms other algorithms in the literature and performs like the centralized algorithm executed in the base station and maximizes the GEE using the global CSI.      
### 28.Deep Local and Global Spatiotemporal Feature Aggregation for Blind Video Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2009.03411.pdf)
>  In recent years, deep learning has achieved promising success for multimedia quality assessment, especially for image quality assessment (IQA). However, since there exist more complex temporal characteristics in videos, very little work has been done on video quality assessment (VQA) by exploiting powerful deep convolutional neural networks (DCNNs). In this paper, we propose an efficient VQA method named Deep SpatioTemporal video Quality assessor (DeepSTQ) to predict the perceptual quality of various distorted videos in a no-reference manner. In the proposed DeepSTQ, we first extract local and global spatiotemporal features by pre-trained deep learning models without fine-tuning or training from scratch. The composited features consider distorted video frames as well as frame difference maps from both global and local views. Then, the feature aggregation is conducted by the regression model to predict the perceptual video quality. Finally, experimental results demonstrate that our proposed DeepSTQ outperforms state-of-the-art quality assessment algorithms.      
### 29.Evaluation of gps/glonass patch versus rf gps (L1) patch antenna performance parameter  [ :arrow_down: ](https://arxiv.org/pdf/2009.03381.pdf)
>  In any wireless communication network and system an antenna is an important element along the propagation path of an electrical signals. Antenna module is a vital component of automated driving systems, it should function as needed in dGPS, HD map correction services, and radio and navigation systems. The main scope of this engineering research work involves the evaluation and determining the performance parameter and characteristic of the GPS/GLONASS patch vs RF GPS L1(1.57542 GHz) patch antenna characteristic. FEKO simulation studies are carried out to extensively compare, make an assessment and evaluate the characteristic and performance parameter, such as the average/passive gain of the proposed antenna in the presence of background noise. Prior to the start of the FEKO simulation studies, a physical mechanical dimension measurements via a Digital instrumentation were conducted for the following: Radiating Element Size: The actual length (L), and width (W), Substrate Material Size: The substrate length (Lsub), width (Wsub), and height (h). The proposed antenna model for GPS only patch antenna operating at 1.57542 GHz and the dual band patch antenna resonating at 1.5925 GHz are developed. To be specific, this work presents the design, modeling, determining passive gain of the RF GPS L1 patch vs. dual band patch antenna with intended targeted applications within the automotive system and space. Simulation are undertaken to generate the RF GPS L1 patch and dual band patch antenna structure respectively for the sole purpose of evaluating the performance of the proposed dual band antenna. Simulation are performed rather than mathematical modelling. The emphasis of this paper is how to obtain the equivalent amount of total passive gain in a GPS vs. that of dual band antenna.      
### 30.Chance-Constrained Optimal Distribution Network Partitioning to Enhance Grid Resilience  [ :arrow_down: ](https://arxiv.org/pdf/2009.03380.pdf)
>  This paper formulates a chance-constrained optimal distribution network partitioning (ODNP) problem addressing uncertainties in load and renewable energy generation; and presents a solution methodology using sample average approximation (SAA). The objective is to identify potential sub-networks in the existing distribution grid; that are likely to survive as self-adequate islands if supply from the main grid is lost. {This constitutes a planning problem.} Practical constraints like ensuring network radiality and availability of grid-forming generators are considered. Quality of the obtained solution is evaluated by comparison with: a) an upper bound on the probability that the identified islands are supply-deficient, and b) a lower bound on the optimal value of the true problem. Performance of the ODNP formulation is illustrated on a modified IEEE 37-bus feeder. It is shown that the network flexibility is well utilized; the partitioning changes with risk budget; and that the SAA method is able to yield good quality solutions with modest computation cost.      
### 31.Auction Based Approach For Resource Allocation In D2D Communication  [ :arrow_down: ](https://arxiv.org/pdf/2009.03377.pdf)
>  Device to device communication has prevailed as an issue for small cell networks. Here we have implemented a new scheme that allows us to improve spectral capabilities of mobiles communicating with each other (peer to peer network) for downlink cellular network. Previously the spectral capabilities were handled by Reverse Iterative combinatorial auction mechanism, where the cellular uses used to bid for d2d links. We have made a comparison between Reverse Iterative combinatorial Auction (R-ICA) and New Auction method on the basis of plots on sum rate over SINR and number of d2d users.      
### 32.Adversarial attacks on deep learning models for fatty liver disease classification by modification of ultrasound image reconstruction method  [ :arrow_down: ](https://arxiv.org/pdf/2009.03364.pdf)
>  Convolutional neural networks (CNNs) have achieved remarkable success in medical image analysis tasks. In ultrasound (US) imaging, CNNs have been applied to object classification, image reconstruction and tissue characterization. However, CNNs can be vulnerable to adversarial attacks, even small perturbations applied to input data may significantly affect model performance and result in wrong output. In this work, we devise a novel adversarial attack, specific to ultrasound (US) imaging. US images are reconstructed based on radio-frequency signals. Since the appearance of US images depends on the applied image reconstruction method, we explore the possibility of fooling deep learning model by perturbing US B-mode image reconstruction method. We apply zeroth order optimization to find small perturbations of image reconstruction parameters, related to attenuation compensation and amplitude compression, which can result in wrong output. We illustrate our approach using a deep learning model developed for fatty liver disease diagnosis, where the proposed adversarial attack achieved success rate of 48%.      
### 33.Going deeper with brain morphometry using neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03303.pdf)
>  Brain morphometry from magnetic resonance imaging (MRI) is a consolidated biomarker for many neurodegenerative diseases. Recent advances in this domain indicate that deep convolutional neural networks can infer morphometric measurements within a few seconds. Nevertheless, the accuracy of the devised model for insightful bio-markers (mean curvature and thickness) remains unsatisfactory. In this paper, we propose a more accurate and efficient neural network model for brain morphometry named HerstonNet. More specifically, we develop a 3D ResNet-based neural network to learn rich features directly from MRI, design a multi-scale regression scheme by predicting morphometric measures at feature maps of different resolutions, and leverage a robust optimization method to avoid poor quality minima and reduce the prediction variance. As a result, HerstonNet improves the existing approach by 24.30% in terms of intraclass correlation coefficient (agreement measure) to FreeSurfer silver-standards while maintaining a competitive run-time.      
### 34.Dynamic Max-Consensus and Size Estimation of Anonymous Multi-Agent Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03858.pdf)
>  In this paper we propose a novel consensus protocol for discrete-time multi-agent systems (MAS), which solves the dynamic consensus problem on the max value, i.e., the dynamic max-consensus problem. In the dynamic max-consensus problem to each agent is fed a an exogenous reference signal, the objective of each agent is to estimate the instantaneous and time-varying value of the maximum among the signals fed to the network, by exploiting only local and anonymous interactions among the agents. The absolute and relative tracking error of the proposed distributed control protocol is theoretically characterized and is shown to be bounded and by tuning its parameters it is possible to trade-off convergence time for steady-state error. The dynamic Max-consensus algorithm is then applied to solve the distributed size estimation problem in a dynamic setting where the size of the network is time-varying during the execution of the estimation algorithm. Numerical simulations are provided to corroborate the theoretical analysis.      
### 35.Understanding Compositional Structures in Art Historical Images using Pose and Gaze Priors  [ :arrow_down: ](https://arxiv.org/pdf/2009.03807.pdf)
>  Image compositions as a tool for analysis of artworks is of extreme significance for art historians. These compositions are useful in analyzing the interactions in an image to study artists and their artworks. Max Imdahl in his work called Ikonik, along with other prominent art historians of the 20th century, underlined the aesthetic and semantic importance of the structural composition of an image. Understanding underlying compositional structures within images is challenging and a time consuming task. Generating these structures automatically using computer vision techniques (1) can help art historians towards their sophisticated analysis by saving lot of time; providing an overview and access to huge image repositories and (2) also provide an important step towards an understanding of man made imagery by machines. In this work, we attempt to automate this process using the existing state of the art machine learning techniques, without involving any form of training. Our approach, inspired by Max Imdahl's pioneering work, focuses on two central themes of image composition: (a) detection of action regions and action lines of the artwork; and (b) pose-based segmentation of foreground and background. Currently, our approach works for artworks comprising of protagonists (persons) in an image. In order to validate our approach qualitatively and quantitatively, we conduct a user study involving experts and non-experts. The outcome of the study highly correlates with our approach and also demonstrates its domain-agnostic capability. We have open-sourced the code at <a class="link-external link-https" href="https://github.com/image-compostion-canvas-group/image-compostion-canvas" rel="external noopener nofollow">this https URL</a>.      
### 36.On the assessment of an optimized method to determine the number of turns and the air gap length in ferrite-core low-frequency-current biased inductors  [ :arrow_down: ](https://arxiv.org/pdf/2009.03750.pdf)
>  This paper presents a first assessment of a design method aiming at the minimization of the number of turns $N$ and the air gap length $g$ in ferrite-core based low-frequency-current biased AC filter inductors. Several design cases are carried on a specific model of Power Module (PM) core, made of distinct ferrite materials and having different kinds of air gap arrangements The correspondingly obtained design results are firstly compared with the classic approach by linearization of the magnetic curve to calculate $N$ and the use of a fringing factor to determine $g$. Next, a refined design approach of specifying the inductance roll-off at the peak current and its potential limitations are discussed with respect to our design method. Finally, the behaviour of inductors operated beyond their design specifications is analyzed.      
### 37.Fast and Reliable WiFi Fingerprint Collection for Indoor Localization  [ :arrow_down: ](https://arxiv.org/pdf/2009.03743.pdf)
>  Fingerprinting is a popular indoor localization technique since it can utilize existing infrastructures (e.g., access points). However, its site survey process is a labor-intensive and time-consuming task, which limits the application of such systems in practice. In this paper, motivated by the availability of advanced sensing capabilities in smartphones, we propose a fast and reliable fingerprint collection method to reduce the time and labor required for site survey. The proposed method uses a landmark graph-based method to automatically associate the collected fingerprints, which does not require active user participation. We will show that besides fast fingerprint data collection, the proposed method results in accurate location estimate compared to the state-of-the-art methods. Experimental results show that the proposed method is an order of magnitude faster than the manual fingerprint collection method, and using the radio map generated by our method achieves a much better accuracy compared to the existing methods.      
### 38.On the Battery Consumption of Mobile Browsers  [ :arrow_down: ](https://arxiv.org/pdf/2009.03740.pdf)
>  Mobile web browsing has recently surpassed desktop browsing both in term of popularity and traffic. Following its desktop counterpart, the mobile browsers ecosystem has been growing from few browsers (Chrome, Firefox, and Safari) to a plethora of browsers, each with unique characteristics (battery friendly, privacy preserving, lightweight, etc.). In this paper, we introduce a browser benchmarking pipeline for Android browsers encompassing automation, in-depth experimentation, and result analysis. We tested 15 Android browsers, using Cappuccino a novel testing suite we built for third party Android applications. We perform a battery-centric analysis of such browsers and show that: 1) popular browsers tend also to consume the most, 2) adblocking produces significant battery savings (between 20 and 40% depending on the browser), and 3) dark mode offers an extra 10% battery savings on AMOLED screens. We exploit this observation to build AttentionDim, a screen dimming mechanism driven by browser events. Via integration with the Brave browser and 10 volunteers, we show potential battery savings up to 30%, on both devices with AMOLED and LCD screens.      
### 39.Modeling and Analysis of Dynamic Charging for EVs: A Stochastic Geometry Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.03726.pdf)
>  With the increasing demand for greener and more energy efficient transportation solutions, electric vehicles (EVs) have emerged to be the future of transportation across the globe. However, currently, one of the biggest bottlenecks of EVs is the battery. Small batteries limit the EVs driving range, while big batteries are expensive and not environmentally friendly. One potential solution to this challenge is the deployment of charging roads, i.e., dynamic wireless charging systems installed under the roads that enable EVs to be charged while driving. In this paper, we use tools from stochastic geometry to establish a framework that enables evaluating the performance of charging roads deployment in metropolitan cities. We first present the course of actions that a driver should take when driving from a random source to a random destination in order to maximize dynamic charging during the trip. Next, we analyze the distribution of the distance to the nearest charging road. This distribution is vital for studying multiple performance metrics such as the trip efficiency, which we define as the fraction of the total trip spent on charging roads. Next, we derive the probability that a given trip passes through at least one charging road. The derived probability distributions can be used to assist urban planners and policy makers in designing the deployment plans of dynamic wireless charging systems. In addition, they can also be used by drivers and automobile manufacturers in choosing the best driving routes given the road conditions and level of energy of EV battery.      
### 40.Multi-Agent Collaboration for Building Construction  [ :arrow_down: ](https://arxiv.org/pdf/2009.03584.pdf)
>  This paper details the algorithms involved and task planner for vehicle collaboration in building a structure. This is the problem defined in challenge 2 of Mohammed Bin Zayed International Robotic Challenge 2020 (MBZIRC). The work addresses various aspects of the challenge for Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicle (UGV). The challenge involves repeated pick and place operations using UAVs and UGV to build two structures of different shape and sizes. The algorithms are implemented using the Robot Operating System (ROS) framework and visualised in Gazebo. The whole developed architecture could readily be implemented in suitable hardware.      
### 41.NC-MOPSO: A network centrality guided multi-objective particle swarm optimization for transport optimization on networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.03575.pdf)
>  Transport processes are universal in real-world complex networks, such as communication and transportation networks. As the increase of the traffic in these complex networks, problems like traffic congestion and transport delay are becoming more and more serious, which call for a systematic optimization of these networks. In this paper, we formulate a multi-objective optimization problem (MOP) to deal with the enhancement of network capacity and efficiency simultaneously, by appropriately adjusting the weights of edges in networks. To solve this problem, we provide a multi-objective evolutionary algorithm (MOEA) based on particle swarm optimization (PSO) with crowding distance, namely network centrality guided multi-objective PSO (NC-MOPSO). Specifically, in the framework of PSO, we propose a hybrid population initialization mechanism and a local search strategy by employing the network centrality theory to enhance the quality of initial solutions and strengthen the exploration of the search space, respectively. Simulation experiments performed on network models and real networks show that our algorithm has better performance than three state-of-the-art alternatives on several most-used metrics.      
### 42.Joint Beam Training and Positioning For Intelligent Reflecting Surfaces Assisted Millimeter Wave Communications  [ :arrow_down: ](https://arxiv.org/pdf/2009.03536.pdf)
>  Intelligent reflecting surface (IRS) offers a cost effective solution to link blockage problem in mmWave communications, and the prerequisite of which is the accurate estimation of (1) the optimal beams for base station/access point (BS/AP) and mobile terminal (MT), (2) the optimal reflection patterns for IRSs, and (3) link blockage. In this paper, we carry out beam training design for IRSs assisted mmWave communications to estimate the aforementioned parameters. To acquire the optimal beams and reflection patterns, we firstly perform random beamforming and maximum likelihood estimation to estimate angle of arrival (AoA) and angle of departure (AoD) of the line of sight (LoS) path between BS/AP (or IRSs) and MT. Then, with the estimate of AoAs and AoDs, we propose an iterative positioning algorithm that achieves centimeter-level positioning accuracy. The obtained location information is not only a fringe benefit but also enables us to cross verify and enhance the estimation of AoA and AoD, and facilitates the prediction of blockage indicator. Numerical results show the superiority of our proposed beam training scheme and verify the performance gain brought by location information.      
### 43.An optimal mode selection algorithm for scalable video coding  [ :arrow_down: ](https://arxiv.org/pdf/2009.03523.pdf)
>  Scalable video coding (SVC) is extended from its predecessor advanced video coding (AVC) because of its flexible transmission to all type of gadgets. However, SVC is more flexible and scalable than AVC, but it is more complex in determining the computations than AVC. The traditional full search method in the standard H.264 SVC consumes more encoding time for computation. This complexity in computation need to be reduced and many fast mode decision (FMD) algorithms were developed, but many fail to balance in all the three measures such as peak signal to noise ratio (PSNR), encoding time and bit rate. In this paper, the proposed optimal mode selection algorithm based on the orientation of pixels achieves better time saving, good PSNR and coding efficiency. The proposed algorithm is compared with the standard H.264 JSVM reference software and found to be 57.44% time saving, 0.43 dB increments in PSNR and 0.23% compression in bit rate.      
### 44.SGX-MR: Regulating Dataflows for Protecting Access Patterns of Data-Intensive SGX Applications  [ :arrow_down: ](https://arxiv.org/pdf/2009.03518.pdf)
>  Intel SGX has been a popular trusted execution environment (TEE) for protecting the integrity and confidentiality of applications running on untrusted platforms such as cloud. However, the access patterns of SGX-based programs can still be observed by adversaries, which may leak important information for successful attacks. Researchers have been experimenting with Oblivious RAM (ORAM) to address the privacy of access patterns. ORAM is a powerful low-level primitive that provides application-agnostic protection for any I/O operations, however, at a high cost. We find that some application-specific access patterns, such as sequential block I/O, do not provide additional information to adversaries. Others, such as sorting, can be replaced with specific oblivious algorithms that are more efficient than ORAM. The challenge is that developers may need to look into all the details of application-specific access patterns to design suitable solutions, which is time-consuming and error-prone. In this paper, we present the lightweight SGX based MapReduce (SGX-MR) approach that regulates the dataflow of data-intensive SGX applications for easier application-level access-pattern analysis and protection. It uses the MapReduce framework to cover a large class of data-intensive applications, and the entire framework can be implemented with a small memory footprint. With this framework, we have examined the stages of data processing, identified the access patterns that need protection, and designed corresponding efficient protection methods. Our experiments show that SGX-MR based applications are much more efficient than ORAM-based implementations.      
### 45.A Residual Solver and Its Unfolding Neural Network for Total Variation Regularized Models  [ :arrow_down: ](https://arxiv.org/pdf/2009.03477.pdf)
>  This paper proposes to solve the Total Variation regularized models by finding the residual between the input and the unknown optimal solution. After analyzing a previous method, we developed a new iterative algorithm, named as Residual Solver, which implicitly solves the model in gradient domain. We theoretically prove the uniqueness of the gradient field in our algorithm. We further numerically confirm that the residual solver can reach the same global optimal solutions as the classical method on 500 natural images. Moreover, we unfold our iterative algorithm into a convolution neural network (named as Residual Solver Network). This network is unsupervised and can be considered as an "enhanced version" of our iterative algorithm. Finally, both the proposed algorithm and neural network are successfully applied on several problems to demonstrate their effectiveness and efficiency, including image smoothing, denoising, and biomedical image reconstruction. The proposed network is general and can be applied to solve other total variation regularized models.      
### 46.Attack-resilient observer pruning for path-tracking control of Wheeled Mobile Robot  [ :arrow_down: ](https://arxiv.org/pdf/2009.03414.pdf)
>  Path-tracking control of wheeled mobile robot (WMR) has gained a lot of research attention, primarily because of its wide applicability -- for example intelligent wheelchairs, exploration-assistant remote WMR. Recent increase in remote and autonomous operations\requirements for WMR has led to more and more use of IoT devices within the control loop. Consequently, providing interfaces for malicious interactions through false data injection attacks (FDIA). Moreover, optimization-based FDIAs have been shown to cause catastrophic consequences in feedback control systems while by-passing any residual-based monitoring system. Since these attacks target system measurement process, this paper focuses on the problem of improving the resiliency of dynamical observers against FDIA. Specifically, we propose an attack-resilient pruning algorithm which attempts to exclude compromised channels from being processed by the observer. The proposed pruning algorithm improves attack-localization precision to $100\%$ with high probability, which correspondingly improves the resiliency of the underlying UKF to FDIA. The improvements due to the developed resilient pruning-based observer is validated through a numerical simulation of a two-layer path-tracking control platform of differential-driven wheeled mobile robot (DDWMR) under FDIA.      
### 47.Deep Learning and Reinforcement Learning for Autonomous Unmanned Aerial Systems: Roadmap for Theory to Deployment  [ :arrow_down: ](https://arxiv.org/pdf/2009.03349.pdf)
>  Unmanned Aerial Systems (UAS) are being increasingly deployed for commercial, civilian, and military applications. The current UAS state-of-the-art still depends on a remote human controller with robust wireless links to perform several of these applications. The lack of autonomy restricts the domains of application and tasks for which a UAS can be deployed. Enabling autonomy and intelligence to the UAS will help overcome this hurdle and expand its use improving safety and efficiency. The exponential increase in computing resources and the availability of large amount of data in this digital era has led to the resurgence of machine learning from its last winter. Therefore, in this chapter, we discuss how some of the advances in machine learning, specifically deep learning and reinforcement learning can be leveraged to develop next-generation autonomous UAS. We first begin motivating this chapter by discussing the application, challenges, and opportunities of the current UAS in the introductory section. We then provide an overview of some of the key deep learning and reinforcement learning techniques discussed throughout this chapter. A key area of focus that will be essential to enable autonomy to UAS is computer vision. Accordingly, we discuss how deep learning approaches have been used to accomplish some of the basic tasks that contribute to providing UAS autonomy. Then we discuss how reinforcement learning is explored for using this information to provide autonomous control and navigation for UAS. Next, we provide the reader with directions to choose appropriate simulation suites and hardware platforms that will help to rapidly prototype novel machine learning based solutions for UAS. We additionally discuss the open problems and challenges pertaining to each aspect of developing autonomous UAS solutions to shine light on potential research areas.      

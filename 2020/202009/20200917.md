# ArXiv eess --Thu, 17 Sep 2020
### 1.Multiport Rapid Charging Power Converter  [ :arrow_down: ](https://arxiv.org/pdf/2009.07825.pdf)
>  Rapid charger is getting more and more important as the electric vehicle (EV) getting popular. The rapid charging technique plays an important part in the electric vehicle development. Multiport converter is used in the rapid charging technique to reduce the required current and also provides some other advantages. In this paper, the literature review form multiport converter to the rapid charger of electric vehicle is introduced. Some topologies of multiport converter are discussed in the literature review. Triple active bridge topology (TAB) is selected as it is useful and commonly used. The feasibility of using Sinusoidal Pulse Width Modulation (SPWM) to control the converter is also discussed in the simulation part. A simple hardware design and experiment is included at the end.      
### 2.Ultra Buck DC/DC Converter for Electric Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2009.07822.pdf)
>  A critical challenge in power conversion in electric vehicles is the efficient use of DC-DC buck converters that need to provide 12-V supply for load systems from 400/800-V batteries. This paper presents a literature review on the development of DC-DC buck converters. Moreover, one novel four-phase interleaved step-down topology is selected for simulation and hardware experiments. Based on the four-phase interleaved structure, an extended-phase topology is proposed, which has a higher voltage conversion ratio. Control techniques are also applied to it. Theoretical analyses and simulation results are provided to verify the improved converter. A 400V-to-12V and 150W output power hardware prototype is implemented to verify its performance      
### 3.Trajectory planning with a dynamic obstacle clustering strategy using Mixed-Integer Linear Programming  [ :arrow_down: ](https://arxiv.org/pdf/2009.07818.pdf)
>  In this paper we propose a technique that assigns obstacles to clusters used for collision avoidance via Mixed-Integer Programming. This strategy enables a reduction in the number of binary variables used for collision avoidance, thus entailing a decrease in computational cost, which has been a hindrance to the application of Model Predictive Control approaches with Mixed-Integer Programming formulations in real-time. Moreover, the assignment of obstacles to clusters and the sizes of the clusters are decided within the same optimization problem that performs the trajectory planning, thus yielding optimal cluster choices. Simulation results are presented to illustrate an application of the proposal.      
### 4.Probabilistic Value-Deviation-Bounded Source-Dependent Bit-Level Channel Adaptation for Approximate Communication  [ :arrow_down: ](https://arxiv.org/pdf/2009.07811.pdf)
>  Computing systems that can tolerate effects of errors in their communicated data values can trade this tolerance for improved resource efficiency. Many important applications of computing, such as embedded sensor systems, can tolerate errors that are bounded in their distribution of deviation from correctness (distortion). We present a channel adaptation technique which modulates properties of I/O channels typical in embedded sensor systems, to provide a tradeoff between I/O power dissipation and distortion of communicated data. We provide an efficient-to-compute formulation for the distribution of integer distortion accounting for the distribution of transmitted values. Using this formulation we implement our value-deviation-bounded (VDB) channel adaptation. We experimentally quantify the achieved reduction in power dissipation on a hardware prototype integrated with the required programmable channel modulation circuitry. We augment these experimental measurements with an analysis of the distributions of distortions. We show that our probabilistic VDB channel adaptation can provide up to a 2$\times$ reduction in I/O power dissipation. When synthesized for a miniature low-power FPGA intended for use in sensor interfaces, a register transfer level implementation of the channel adaptation control logic requires only 106 flip-flops and 224 4-input LUTs for implementing per-bit channel adaptation on serialized streams of 8-bit sensor data.      
### 5.Deep-Learning Based Blind Recognition of Channel Code Parameters over Candidate Sets under AWGN and Multi-Path Fading Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2009.07774.pdf)
>  We consider the problem of recovering channel code parameters over a candidate set by merely analyzing the received encoded signals. We propose a deep learning-based solution that I) is capable of identifying the channel code parameters for any coding scheme (such as LDPC, Convolutional, Turbo, and Polar codes), II) is robust against channel impairments like multi-path fading, III) does not require any previous knowledge or estimation of channel state or signal-to-noise ratio (SNR), and IV) outperforms related works in terms of probability of detecting the correct code parameters.      
### 6.Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2009.07683.pdf)
>  This work has been accepted by IEEE TGRS for publication. The majority of optical observations acquired via spaceborne earth imagery are affected by clouds. While there is numerous prior work on reconstructing cloud-covered information, previous studies are oftentimes confined to narrowly-defined regions of interest, raising the question of whether an approach can generalize to a diverse set of observations acquired at variable cloud coverage or in different regions and seasons. We target the challenge of generalization by curating a large novel data set for training new cloud removal approaches and evaluate on two recently proposed performance metrics of image quality and diversity. Our data set is the first publically available to contain a global sample of co-registered radar and optical observations, cloudy as well as cloud-free. Based on the observation that cloud coverage varies widely between clear skies and absolute coverage, we propose a novel model that can deal with either extremes and evaluate its performance on our proposed data set. Finally, we demonstrate the superiority of training models on real over synthetic data, underlining the need for a carefully curated data set of real observations. To facilitate future research, our data set is made available online      
### 7.Contrastive Cross-site Learning with Redesigned Net for COVID-19 CT Classification  [ :arrow_down: ](https://arxiv.org/pdf/2009.07652.pdf)
>  The pandemic of coronavirus disease 2019 (COVID-19) has lead to a global public health crisis spreading hundreds of countries. With the continuous growth of new infections, developing automated tools for COVID-19 identification with CT image is highly desired to assist the clinical diagnosis and reduce the tedious workload of image interpretation. To enlarge the datasets for developing machine learning methods, it is essentially helpful to aggregate the cases from different medical systems for learning robust and generalizable models. This paper proposes a novel joint learning framework to perform accurate COVID-19 identification by effectively learning with heterogeneous datasets with distribution discrepancy. We build a powerful backbone by redesigning the recently proposed COVID-Net in aspects of network architecture and learning strategy to improve the prediction accuracy and learning efficiency. On top of our improved backbone, we further explicitly tackle the cross-site domain shift by conducting separate feature normalization in latent space. Moreover, we propose to use a contrastive training objective to enhance the domain invariance of semantic embeddings for boosting the classification performance on each dataset. We develop and evaluate our method with two public large-scale COVID-19 diagnosis datasets made up of CT images. Extensive experiments show that our approach consistently improves the performances on both datasets, outperforming the original COVID-Net trained on each dataset by 12.16% and 14.23% in AUC respectively, also exceeding existing state-of-the-art multi-site learning methods.      
### 8.Distributed formation maneuver control by manipulating the complex Laplacian  [ :arrow_down: ](https://arxiv.org/pdf/2009.07625.pdf)
>  This paper proposes a novel maneuvering technique for the complex-Laplacian-based formation control. We show how to modify the original weights that build the Laplacian such that a designed steady-state motion of the desired shape emerges from the local interactions among the agents. These collective motions can be exploited to solve problems such as the shaped consensus (the rendezvous with a particular shape), the enclosing of a target, or translations with controlled speed and heading to assist mobile robots in area coverage, escorting, and traveling missions, respectively. The designed steady-state collective motions correspond to rotations around the centroid, translations, and scalings of a reference shape. The proposed modification of the weights relocates one of the Laplacian's zero eigenvalues while preserving its associated eigenvector that constructs the desired shape. For example, such relocation on the imaginary or real axis induces rotational and scaling motions, respectively. We will show how to satisfy a sufficient condition to guarantee the global convergence to the desired shape and motions. Finally, we provide simulations and comparisons with other maneuvering techniques.      
### 9.Deep Learning in Photoacoustic Tomography: Current approaches and future directions  [ :arrow_down: ](https://arxiv.org/pdf/2009.07608.pdf)
>  Biomedical photoacoustic tomography, which can provide high resolution 3D soft tissue images based on the optical absorption, has advanced to the stage at which translation from the laboratory to clinical settings is becoming possible. The need for rapid image formation and the practical restrictions on data acquisition that arise from the constraints of a clinical workflow are presenting new image reconstruction challenges. There are many classical approaches to image reconstruction, but ameliorating the effects of incomplete or imperfect data through the incorporation of accurate priors is challenging and leads to slow algorithms. Recently, the application of Deep Learning, or deep neural networks, to this problem has received a great deal of attention. This paper reviews the literature on learned image reconstruction, summarising the current trends, and explains how these new approaches fit within, and to some extent have arisen from, a framework that encompasses classical reconstruction methods. In particular, it shows how these new techniques can be understood from a Bayesian perspective, providing useful insights. The paper also provides a concise tutorial demonstration of three prototypical approaches to learned image reconstruction. The code and data sets for these demonstrations are available to researchers. It is anticipated that it is in in vivo applications - where data may be sparse, fast imaging critical and priors difficult to construct by hand - that Deep Learning will have the most impact. With this in mind, the paper concludes with some indications of possible future research directions.      
### 10.6G Vision: An Ultra-Flexible Radio Access Technology Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2009.07597.pdf)
>  Radio access technologies (RATs) are the primary enablers of mobile communications systems. The upcoming sixth generation (6G) communications systems are expected to support an unprecedented variety of applications, pervading through every aspect of human life. It is clearly not possible, without realizing a plethora of flexible options pertaining to the RATs themselves. At that point, this work presents an overview of the potential 6G RATs from the flexibility perspective, categorizes them, and provides a general framework to incorporate them in the future networks. Furthermore, the role of artificial intelligence and integrated sensing and communications as enablers of the said framework is also discussed.      
### 11.Video Compression with CNN-based Post Processing  [ :arrow_down: ](https://arxiv.org/pdf/2009.07583.pdf)
>  In recent years, video compression techniques have been significantly challenged by the rapidly increased demands associated with high quality and immersive video content. Among various compression tools, post-processing can be applied on reconstructed video content to mitigate visible compression artefacts and to enhance overall perceptual quality. Inspired by advances in deep learning, we propose a new CNN-based post-processing approach, which has been integrated with two state-of-the-art coding standards, VVC and AV1. The results show consistent coding gains on all tested sequences at various spatial resolutions, with average bit rate savings of 4.0% and 5.8% against original VVC and AV1 respectively (based on the assessment of PSNR). This network has also been trained with perceptually inspired loss functions, which have further improved reconstruction quality based on perceptual quality assessment (VMAF), with average coding gains of 13.9% over VVC and 10.5% against AV1.      
### 12.Exploiting Linear Substructure In LRKFs (Extended)  [ :arrow_down: ](https://arxiv.org/pdf/2009.07571.pdf)
>  We exploit knowledge of linear substructure in the linear-regression Kalman filters (LRKFs) to simplify the problem of moment matching. The theoretical results yield quantifiable and significant computational speedups at no cost of estimation accuracy, assuming partially linear estimation models. The results apply to any symmetrical LRKF, and reductions in computational complexity are stated as a function of the cubature rule, the number of linear and nonlinear states in the estimation model respectively. The implications for the filtering problem are illustrated by numerical examples.      
### 13.U-Net with Graph Based Smoothing Regularizer for Small Vessel Segmentation on Fundus Image  [ :arrow_down: ](https://arxiv.org/pdf/2009.07567.pdf)
>  The detection of retinal blood vessels, especially the changes of small vessel condition is the most important indicator to identify the vascular network of the human body. Existing techniques focused mainly on shape of the large vessels, which is not appropriate for the disconnected small and isolated vessels. Paying attention to the low contrast small blood vessel in fundus region, first time we proposed to combine graph based smoothing regularizer with the loss function in the U-net framework. The proposed regularizer treated the image as two graphs by calculating the graph laplacians on vessel regions and the background regions on the image. The potential of the proposed graph based smoothing regularizer in reconstructing small vessel is compared over the classical U-net with or without regularizer. Numerical and visual results shows that our developed regularizer proved its effectiveness in segmenting the small vessels and reconnecting the fragmented retinal blood vessels.      
### 14.Brain tumour segmentation using cascaded 3D densely-connected U-net  [ :arrow_down: ](https://arxiv.org/pdf/2009.07563.pdf)
>  Accurate brain tumour segmentation is a crucial step towards improving disease diagnosis and proper treatment planning. In this paper, we propose a deep-learning based method to segment a brain tumour into its subregions: whole tumour, tumour core and enhancing tumour. The proposed architecture is a 3D convolutional neural network based on a variant of the U-Net architecture of Ronneberger et al. [17] with three main modifications: (i) a heavy encoder, light decoder structure using residual blocks (ii) employment of dense blocks instead of skip connections, and (iii) utilization of self-ensembling in the decoder part of the network. The network was trained and tested using two different approaches: a multitask framework to segment all tumour subregions at the same time and a three-stage cascaded framework to segment one sub-region at a time. An ensemble of the results from both frameworks was also computed. To address the class imbalance issue, appropriate patch extraction was employed in a pre-processing step. The connected component analysis was utilized in the post-processing step to reduce false positive predictions. Experimental results on the BraTS20 validation dataset demonstrates that the proposed model achieved average Dice Scores of 0.90, 0.82, and 0.78 for whole tumour, tumour core and enhancing tumour respectively.      
### 15.RCNN for Region of Interest Detection in Whole Slide Images  [ :arrow_down: ](https://arxiv.org/pdf/2009.07532.pdf)
>  Digital pathology has attracted significant attention in recent years. Analysis of Whole Slide Images (WSIs) is challenging because they are very large, i.e., of Giga-pixel resolution. Identifying Regions of Interest (ROIs) is the first step for pathologists to analyse further the regions of diagnostic interest for cancer detection and other anomalies. In this paper, we investigate the use of RCNN, which is a deep machine learning technique, for detecting such ROIs only using a small number of labelled WSIs for training. For experimentation, we used real WSIs from a public hospital pathology service in Western Australia. We used 60 WSIs for training the RCNN model and another 12 WSIs for testing. The model was further tested on a new set of unseen WSIs. The results show that RCNN can be effectively used for ROI detection from WSIs.      
### 16.Joint Waveform and Beamforming Optimization for MIMO Wireless Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2009.07500.pdf)
>  In this paper, we study a multi-sine multiple-input multiple-output (MIMO) wireless power transfer (WPT) system with the objective to increase the output DC power. We jointly optimize the multi-sine waveform and beamforming accounting for the rectenna nonlinearity, and consider two combining schemes for the rectennas at the receiver, namely DC and RF combinings. For DC combining, the waveform and transmit beamforming are optimized, as a function of the channel state information (CSI). For RF combining, the optimal transmit and receive beamformings are provided in closed form and the waveform is optimized. We also consider a practical RF combining circuit using phase shifter and RF power combiner and optimize the waveform, transmit beamforming, and analog receive beamforming adaptive to the CSI. Two types of performance evaluations, based on the nonlinear rectenna model and accurate and realistic circuit simulations, are provided. The evaluations demonstrate that the joint waveform and beamforming design can increase the output DC power by leveraging the beamforming gain, the frequency diversity gain, and the rectenna nonlinearity. It also shows that the joint waveform and beamforming design provides a higher output DC power than the beamforming-only design with a relative gain of 180% in a two-transmit antenna sixteen-sinewave two-receive antenna setup.      
### 17.Quasi-distributed fiber sensing via perfect periodic Legendre codes  [ :arrow_down: ](https://arxiv.org/pdf/2009.07496.pdf)
>  Long-range Rayleigh-based Distributed Acoustic Sensing (DAS) systems are often limited in their sensitivity and bandwidth. The former limitation is a result of the low backscattered power and poor \textit{dynamic-strain to optical-phase} transduction efficiency. The latter constraint results from the trade-off between range and scan-rate which limits the sampling interval to the longest delay in the sensing fiber. Quasi-DAS (Q-DAS) can yield enhanced sensitivity but may still suffer from low backscattered power and low scan-rate for long-haul, many-sensor, systems. In this work we study the use of Perfect Periodic Correlation codes for interrogating a long-haul Q-DAS system. It is shown that judicious choice of the code parameters allows order of magnitude increase in detection bandwidths and in the power reflected from each sensor.      
### 18.Location-aware Predictive Beamforming for UAV Communications: A Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.07478.pdf)
>  Unmanned aerial vehicle (UAV)-assisted communication becomes a promising technique to realize the beyond fifth generation (5G) wireless networks, due to the high mobility and maneuverability of UAVs which can adapt to heterogeneous requirements of different applications. However, the movement of UAVs impose challenge for accurate beam alignment between the UAV and the ground user equipment (UE). In this letter, we propose a deep learning-based location-aware predictive beamforming scheme to track the beam for UAV communications in a dynamic scenario. Specifically, a long short-term memory (LSTM)-based recurrent neural network (LRNet) is designed for UAV location prediction. Based on the predicted location, a predicted angle between the UAV and the UE can be determined for effective and fast beam alignment in the next time slot, which enables reliable communications between the UAV and the UE. Simulation results demonstrate that the proposed scheme can achieve a satisfactory UAV-to-UE communication rate, which is close to the upper bound of communication rate obtained by the perfect genie-aided alignment scheme.      
### 19.Deep Sinogram Completion with Image Prior for Metal Artifact Reduction in CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2009.07469.pdf)
>  Computed tomography (CT) has been widely used for medical diagnosis, assessment, and therapy planning and guidance. In reality, CT images may be affected adversely in the presence of metallic objects, which could lead to severe metal artifacts and influence clinical diagnosis or dose calculation in radiation therapy. In this paper, we propose a generalizable framework for metal artifact reduction (MAR) by simultaneously leveraging the advantages of image domain and sinogram domain-based MAR techniques. We formulate our framework as a sinogram completion problem and train a neural network (SinoNet) to restore the metal-affected projections. To improve the continuity of the completed projections at the boundary of metal trace and thus alleviate new artifacts in the reconstructed CT images, we train another neural network (PriorNet) to generate a good prior image to guide sinogram learning, and further design a novel residual sinogram learning strategy to effectively utilize the prior image information for better sinogram completion. The two networks are jointly trained in an end-to-end fashion with a differentiable forward projection (FP) operation so that the prior image generation and deep sinogram completion procedures can benefit from each other. Finally, the artifact-reduced CT images are reconstructed using the filtered backward projection (FBP) from the completed sinogram. Extensive experiments on simulated and real artifacts data demonstrate that our method produces superior artifact-reduced results while preserving the anatomical structures and outperforms other MAR methods.      
### 20.Adversarial Attacks on Co-Occurrence Features for GAN Detection  [ :arrow_down: ](https://arxiv.org/pdf/2009.07456.pdf)
>  Improvements in Generative Adversarial Networks (GANs) have greatly reduced the difficulty of producing new, photo-realistic images with unique semantic meaning. With this rise in ability to generate fake images comes demand to detect them. While numerous methods have been developed for this task, the majority of them remain vulnerable to adversarial attacks. In this paper, develop two novel adversarial attacks on co-occurrence based GAN detectors. These are the first attacks to be presented against such a detector. We show that our method can reduce accuracy from over 98% to less than 4%, with no knowledge of the deep learning model or weights. Furthermore, accuracy can be reduced to 0% with full knowledge of the deep learning model details.      
### 21.Surgical Video Motion Magnification with Suppression of Instrument Artefacts  [ :arrow_down: ](https://arxiv.org/pdf/2009.07432.pdf)
>  Video motion magnification could directly highlight subsurface blood vessels in endoscopic video in order to prevent inadvertent damage and bleeding. Applying motion filters to the full surgical image is however sensitive to residual motion from the surgical instruments and can impede practical application due to aberration motion artefacts. By storing the temporal filter response from local spatial frequency information for a single cardiovascular cycle prior to tool introduction to the scene, a filter can be used to determine if motion magnification should be active for a spatial region of the surgical image. In this paper, we propose a strategy to reduce aberration due to non-physiological motion for surgical video motion magnification. We present promising results on endoscopic transnasal transsphenoidal pituitary surgery with a quantitative comparison to recent methods using Structural Similarity (SSIM), as well as qualitative analysis by comparing spatio-temporal cross sections of the videos and individual frames.      
### 22.Functional sets with typed symbols: Framework and mixed Polynotopes for hybrid nonlinear reachability and filtering  [ :arrow_down: ](https://arxiv.org/pdf/2009.07387.pdf)
>  Verification and synthesis of Cyber-Physical Systems (CPS) are challenging and still raise numerous issues so far. In this paper, an original framework with mixed sets defined as function images of symbol type domains is first proposed. Syntax and semantics are explicitly distinguished. Then, both continuous (interval) and discrete (signed, boolean) symbol types are used to model dependencies through linear and polynomial functions, so leading to mixed zonotopic and polynotopic sets. Polynotopes extend sparse polynomial zonotopes with typed symbols. Polynotopes can both propagate a mixed encoding of intervals and describe the behavior of logic gates. A functional completeness result is given, as well as an inclusion method for elementary nonlinear and switching functions. A Polynotopic Kalman Filter (PKF) is then proposed as a hybrid nonlinear extension of Zonotopic Kalman Filters (ZKF). Bridges with a stochastic uncertainty paradigm are outlined. Finally, several discrete, continuous and hybrid numerical examples including comparisons illustrate the effectiveness of the theoretical results.      
### 23.Q-space quantitative diffusion MRI measures using a stretched-exponential representation  [ :arrow_down: ](https://arxiv.org/pdf/2009.07376.pdf)
>  Diffusion magnetic resonance imaging (dMRI) is a relatively modern technique used to study tissue microstructure in a non-invasive way. Non-Gaussian diffusion representation is related to the restricted diffusion and can provide information about the underlying tissue properties. In this paper, we analytically derive $n$-th order statistics of the signal considering a stretched-exponential representation of the diffusion. Then, we retrieve the Q-space quantitative measures such as the Return-To-the-Origin Probability (RTOP), Q-space mean square displacement (QMSD), Q-space mean fourth-order displacement (QMFD). The stretched-exponential representation enables the handling of the diffusion contributions from a higher $b$-value regime under a non-Gaussian assumption, which can be useful in diagnosing or prognosis of neurodegenerative diseases in the early stages. Numerical implementation of the method is freely available at <a class="link-external link-https" href="https://github.com/TPieciak/Stretched" rel="external noopener nofollow">this https URL</a>.      
### 24.Random-Sampling Monte-Carlo Tree Search Methods for Cost Approximation in Long-Horizon Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.07354.pdf)
>  In this paper, we develop Monte-Carlo based heuristic approaches to approximate the objective function in long horizon optimal control problems. In these approaches, to approximate the expectation operator in the objective function, we evolve the system state over multiple trajectories into the future while sampling the noise disturbances at each time-step, and find the average (or weighted average) of the costs along all the trajectories. We call these methods random sampling - multipath hypothesis propagation or RS-MHP. These methods (or variants) exist in the literature; however, the literature lacks results on how well these approximation strategies converge. This paper fills this knowledge gap to a certain extent. We derive convergence results for the cost approximation error from the RS-MHP methods and discuss their convergence (in probability) as the sample size increases. We consider two case studies to demonstrate the effectiveness of our methods - a) linear quadratic control problem; b) UAV path optimization problem.      
### 25.Analog vs. Digital Spatial Transforms: A Throughput, Power, and Area Comparison  [ :arrow_down: ](https://arxiv.org/pdf/2009.07332.pdf)
>  Spatial linear transforms that process multiple parallel analog signals to simplify downstream signal processing find widespread use in multi-antenna communication systems, machine learning inference, data compression, audio and ultrasound applications, among many others. In the past, a wide range of mixed-signal as well as digital spatial transform circuits have been proposed---it is, however, a longstanding question whether analog or digital transforms are superior in terms of throughput, power, and area. In this paper, we focus on Hadamard transforms and perform a systematic comparison of state-of-the-art analog and digital circuits implementing spatial transforms in the same 65\,nm CMOS technology. We analyze the trade-offs between throughput, power, and area, and we identify regimes in which mixed-signal or digital Hadamard transforms are preferable. Our comparison reveals that (i) there is no clear winner and (ii) analog-to-digital conversion is often dominating area and energy efficiency---and not the spatial transform.      
### 26.Bearing-Only Navigation with Field of View Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2009.07308.pdf)
>  This paper addresses the problem of navigation using only relative direction measurements (i.e., relative distances are unknown) under field of view constraints. We present a novel navigation vector field for the bearing-based visual homing problem with respect to static visual landmarks in 2-D and 3-D environments. Our method employs two control fields that are tangent and normal to ellipsoids having landmarks as their foci. The tangent field steers the robot to a set of points where the average of observed bearings is parallel to the average of the desired bearings, and the normal field uses the angle between a pair of bearings as a proxy to adjust the robot's distance from landmarks and to satisfy the field of view constraints. Both fields are blended together to construct an almost globally stable control law. Our method is easy to implement, as it requires only comparisons between average bearings, and between angles of pairs of vectors. We provide simulations that demonstrate the performance of our approach for a double integrator system and unicycles.      
### 27.Characterizing Attitudinal Network Graphs through Frustration Cloud  [ :arrow_down: ](https://arxiv.org/pdf/2009.07776.pdf)
>  Attitudinal Network Graphs (ANG) are network graphs where edges capture an expressed opinion: two vertices connected by an edge can be agreeable (positive) or antagonistic (negative). Measure of consensus in attitudinal graph reflects how easy or difficult consensus can be reached that is acceptable by everyone. Frustration index is one such measure as it determines the distance of a network from a state of total structural balance. In this paper, we propose to measure the consensus in the graph by expanding the notion of frustration index to a frustration cloud, a collection of nearest balanced states for a given network. The frustration cloud resolves the consensus problem with minimal sentiment disruption, taking all possible consensus views over the entire network into consideration. A frustration cloud based approach removes the brittleness of traditional network graph analysis, as it allows one to examine the consensus on entire graph. A spanning-tree-based balancing algorithm captures the variations of balanced states and global consensus of the network, and enables us to measure vertex influence on consensus and strength of its expressed attitudes. The proposed algorithm provides a parsimonious account of the differences between strong and weak statuses and influences of a vertex in a large network, as demonstrated on sample attitudinal network graphs constructed from social and survey data. We show that the proposed method accurately models the alliance network, provides discriminant features for community discovery, successfully predicts administrator election outcome consistent with real election outcomes, and provides deeper analytic insights into ANG outcome analysis by pinpointing influential vertices and anomalous decisions.      
### 28.Exploring Bayesian Surprise to Prevent Overfitting and to Predict Model Performance in Non-Intrusive Load Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2009.07756.pdf)
>  Non-Intrusive Load Monitoring (NILM) is a field of research focused on segregating constituent electrical loads in a system based only on their aggregated signal. Significant computational resources and research time are spent training models, often using as much data as possible, perhaps driven by the preconception that more data equates to more accurate models and better performing algorithms. When has enough prior training been done? When has a NILM algorithm encountered new, unseen data? This work applies the notion of Bayesian surprise to answer these questions which are important for both supervised and unsupervised algorithms. We quantify the degree of surprise between the predictive distribution (termed postdictive surprise), as well as the transitional probabilities (termed transitional surprise), before and after a window of observations. We compare the performance of several benchmark NILM algorithms supported by NILMTK, in order to establish a useful threshold on the two combined measures of surprise. We validate the use of transitional surprise by exploring the performance of a popular Hidden Markov Model as a function of surprise threshold. Finally, we explore the use of a surprise threshold as a regularization technique to avoid overfitting in cross-dataset performance. Although the generality of the specific surprise threshold discussed herein may be suspect without further testing, this work provides clear evidence that a point of diminishing returns of model performance with respect to dataset size exists. This has implications for future model development, dataset acquisition, as well as aiding in model flexibility during deployment.      
### 29.Hardware-Assisted Detection of Firmware Attacks in Inverter-Based Cyberphysical Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2009.07691.pdf)
>  The electric grid modernization effort relies on the extensive deployment of microgrid (MG) systems. MGs integrate renewable resources and energy storage systems, allowing to generate economic and zero-carbon footprint electricity, deliver sustainable energy to communities using local energy resources, and enhance grid resilience. MGs as cyberphysical systems include interconnected devices that measure, control, and actuate energy resources and loads. For optimal operation, cyberphysical MGs regulate the onsite energy generation through support functions enabled by smart inverters. Smart inverters, being consumer electronic firmware-based devices, are susceptible to increasing security threats. If inverters are maliciously controlled, they can significantly disrupt MG operation and electricity delivery as well as impact the grid stability. In this paper, we demonstrate the impact of denial-of-service (DoS) as well as controller and setpoint modification attacks on a simulated MG system. Furthermore, we employ custom-built hardware performance counters (HPCs) as design-for-security (DfS) primitives to detect malicious firmware modifications on MG inverters. The proposed HPCs measure periodically the order of various instruction types within the MG inverter's firmware code. Our experiments illustrate that the firmware modifications are successfully identified by our custom-built HPCs utilizing various machine learning-based classifiers.      
### 30.Verifying Stochastic Hybrid Systems with Temporal Logic Specifications via Model Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2009.07649.pdf)
>  We present a scalable methodology to verify stochastic hybrid systems. Using the Mori-Zwanzig reduction method, we construct a finite state Markov chain reduction of a given stochastic hybrid system and prove that this reduced Markov chain is approximately equivalent to the original system in a distributional sense. Approximate equivalence of the stochastic hybrid system and its Markov chain reduction means that analyzing the Markov chain with respect to a suitably strengthened property, allows us to conclude whether the original stochastic hybrid system meets its temporal logic specifications. We present the first statistical model checking algorithms to verify stochastic hybrid systems against correctness properties, expressed in the linear inequality linear temporal logic (iLTL) or the metric interval temporal logic (MITL).      
### 31.The FaceChannel: A Fast &amp; Furious Deep Neural Network for Facial Expression Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2009.07635.pdf)
>  Current state-of-the-art models for automatic Facial Expression Recognition (FER) are based on very deep neural networks that are effective but rather expensive to train. Given the dynamic conditions of FER, this characteristic hinders such models of been used as a general affect recognition. In this paper, we address this problem by formalizing the FaceChannel, a light-weight neural network that has much fewer parameters than common deep neural networks. We introduce an inhibitory layer that helps to shape the learning of facial features in the last layer of the network and thus improving performance while reducing the number of trainable parameters. To evaluate our model, we perform a series of experiments on different benchmark datasets and demonstrate how the FaceChannel achieves a comparable, if not better, performance to the current state-of-the-art in FER. Our experiments include cross-dataset analysis, to estimate how our model behaves on different affective recognition conditions. We conclude our paper with an analysis of how FaceChannel learns and adapt the learned facial features towards the different datasets.      
### 32.Multi-Stage CNN Architecture for Face Mask Detection  [ :arrow_down: ](https://arxiv.org/pdf/2009.07627.pdf)
>  The end of 2019 witnessed the outbreak of Coronavirus Disease 2019 (COVID-19), which has continued to be the cause of plight for millions of lives and businesses even in 2020. As the world recovers from the pandemic and plans to return to a state of normalcy, there is a wave of anxiety among all individuals, especially those who intend to resume in-person activity. Studies have proved that wearing a face mask significantly reduces the risk of viral transmission as well as provides a sense of protection. However, it is not feasible to manually track the implementation of this policy. Technology holds the key here. We introduce a Deep Learning based system that can detect instances where face masks are not used properly. Our system consists of a dual-stage Convolutional Neural Network (CNN) architecture capable of detecting masked and unmasked faces and can be integrated with pre-installed CCTV cameras. This will help track safety violations, promote the use of face masks, and ensure a safe working environment.      
### 33.Similarity-based data mining for online domain adaptation of a sonar ATR system  [ :arrow_down: ](https://arxiv.org/pdf/2009.07560.pdf)
>  Due to the expensive nature of field data gathering, the lack of training data often limits the performance of Automatic Target Recognition (ATR) systems. This problem is often addressed with domain adaptation techniques, however the currently existing methods fail to satisfy the constraints of resource and time-limited underwater systems. We propose to address this issue via an online fine-tuning of the ATR algorithm using a novel data-selection method. Our proposed data-mining approach relies on visual similarity and outperforms the traditionally employed hard-mining methods. We present a comparative performance analysis in a wide range of simulated environments and highlight the benefits of using our method for the rapid adaptation to previously unseen environments.      
### 34.PCA Reduced Gaussian Mixture Models with Applications in Superresolution  [ :arrow_down: ](https://arxiv.org/pdf/2009.07520.pdf)
>  Despite the rapid development of computational hardware, the treatment of large and high dimensional data sets is still a challenging problem. This paper provides a twofold contribution to the topic. First, we propose a Gaussian Mixture Model in conjunction with a reduction of the dimensionality of the data in each component of the model by principal component analysis, called PCA-GMM. To learn the (low dimensional) parameters of the mixture model we propose an EM algorithm whose M-step requires the solution of constrained optimization problems. Fortunately, these constrained problems do not depend on the usually large number of samples and can be solved efficiently by an (inertial) proximal alternating linearized minimization algorithm. Second, we apply our PCA-GMM for the superresolution of 2D and 3D material images based on the approach of Sandeep and Jacob. Numerical results confirm the moderate influence of the dimensionality reduction on the overall superresolution result.      
### 35.MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.07517.pdf)
>  Reasoning about human motion is a core component of modern human-robot interactive systems. In particular, one of the main uses of behavior prediction in autonomous systems is to inform ego-robot motion planning and control. However, a majority of planning and control algorithms reason about system dynamics rather than the predicted agent tracklets that are commonly output by trajectory forecasting methods, which can hinder their integration. Towards this end, we propose Mixtures of Affine Time-varying Systems (MATS) as an output representation for trajectory forecasting that is more amenable to downstream planning and control use. Our approach leverages successful ideas from probabilistic trajectory forecasting works to learn dynamical system representations that are well-studied in the planning and control literature. We integrate our predictions with a proposed multimodal planning methodology and demonstrate significant computational efficiency improvements on a large-scale autonomous driving dataset.      
### 36.A Unified Approach to Synchronization Problems over Subgroups of the Orthogonal Group  [ :arrow_down: ](https://arxiv.org/pdf/2009.07514.pdf)
>  Given a group $\mathcal{G}$, the problem of synchronization over the group $\mathcal{G}$ is a constrained estimation problem where a collection of group elements $G^*_1, \dots, G^*_n \in \mathcal{G}$ are estimated based on noisy observations of pairwise ratios $G^*_i {G^*_j}^{-1}$ for an incomplete set of index pairs $(i,j)$. This problem has gained much attention recently and finds lots of applications due to its appearance in a wide range of scientific and engineering areas. In this paper, we consider the class of synchronization problems over a closed subgroup of the orthogonal group, which covers many instances of group synchronization problems that arise in practice. Our contributions are threefold. First, we propose a unified approach to solve this class of group synchronization problems, which consists of a suitable initialization and an iterative refinement procedure via the generalized power method. Second, we derive a master theorem on the performance guarantee of the proposed approach. Under certain conditions on the subgroup, the measurement model, the noise model and the initialization, the estimation error of the iterates of our approach decreases geometrically. As our third contribution, we study concrete examples of the subgroup (including the orthogonal group, the special orthogonal group, the permutation group and the cyclic group), the measurement model, the noise model and the initialization. The validity of the related conditions in the master theorem are proved for these specific examples. Numerical experiments are also presented. Experiment results show that our approach outperforms existing approaches in terms of computational speed, scalability and estimation error.      
### 37.A priori guarantees of finite-time convergence for Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.07509.pdf)
>  In this paper, we perform Lyapunov based analysis of the loss function to derive an a priori upper bound on the settling time of deep neural networks. While previous studies have attempted to understand deep learning using control theory framework, there is limited work on a priori finite time convergence analysis. Drawing from the advances in analysis of finite-time control of non-linear systems, we provide a priori guarantees of finite-time convergence in a deterministic control theoretic setting. We formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. An analytical formula for finite-time upper bound on settling time is computed a priori under the assumptions of boundedness of input. Finally, we prove the robustness and sensitivity of the loss function against input perturbations.      
### 38.Deep Residual Learning-Assisted Channel Estimation in Ambient Backscatter Communications  [ :arrow_down: ](https://arxiv.org/pdf/2009.07468.pdf)
>  Channel estimation is a challenging problem for realizing efficient ambient backscatter communication (AmBC) systems. In this letter, channel estimation in AmBC is modeled as a denoising problem and a convolutional neural network-based deep residual learning denoiser (CRLD) is developed to directly recover the channel coefficients from the received noisy pilot signals. To simultaneously exploit the spatial and temporal features of the pilot signals, a novel three-dimension (3D) denoising block is specifically designed to facilitate denoising in CRLD. In addition, we provide theoretical analysis to characterize the properties of the proposed CRLD. Simulation results demonstrate that the performance of the proposed method approaches the performance of the optimal minimum mean square error (MMSE) estimator with perfect statistical channel correlation matrix.      
### 39.Cell A* for Navigation of Unmanned Aerial Vehicles in Partially-known Environments  [ :arrow_down: ](https://arxiv.org/pdf/2009.07404.pdf)
>  Proper path planning is the first step of robust and efficient autonomous navigation for mobile robots. Meanwhile, it is still challenging for robots to work in a complex environment without complete prior information. This paper presents an extension to the A* search algorithm and its variants to make the path planning stable with less computational burden while handling long-distance tasks. The implemented algorithm is capable of online searching for a collision-free and smooth path when heading to the defined goal position. This paper deploys the algorithm on the autonomous drone platform and implements it on a remote control car for algorithm efficiency validation.      
### 40.Sensitivity-based Data Augmentation for Learning an Approximate Model Predictive Controller  [ :arrow_down: ](https://arxiv.org/pdf/2009.07398.pdf)
>  Recently, there has been a surge of interest in approximating the model predictive control (MPC) law using expert supervised learning techniques, such as deep neural networks (DNN). Approximating the MPC control policy requires labeled training data sets, which is typically obtained by sampling the state-space and evaluating the control law by solving the numerical optimization problem offline for each sample. The accuracy of the MPC policy approximation is dependent on the availability of large training data set sampled across the entire state space. Although the resulting approximate MPC law can be cheaply evaluated online, generating large training samples to learn the MPC control law can be time consuming and prohibitively expensive. This paper aims to address this issue, and proposes the use of NLP sensitivities in order to cheaply generate additional training samples in the neighborhood of the existing samples.      
### 41.Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S. Supreme Court Oral Arguments  [ :arrow_down: ](https://arxiv.org/pdf/2009.07391.pdf)
>  This study presents a corpus of turn changes between speakers in U.S. Supreme Court oral arguments. Each turn change is labeled on a spectrum of "cooperative" to "competitive" by a human annotator with legal experience in the United States. We analyze the relationship between speech features, the nature of exchanges, and the gender and legal role of the speakers. Finally, we demonstrate that the models can be used to predict the label of an exchange with moderate success. The automatic classification of the nature of exchanges indicates that future studies of turn-taking in oral arguments can rely on larger, unlabeled corpora.      
### 42.Policies for elementary link generation in quantum networks  [ :arrow_down: ](https://arxiv.org/pdf/2007.03193.pdf)
>  Protocols in a quantum network involve multiple parties performing actions on their quantum systems in a carefully orchestrated manner over time in order to accomplish a given task. This sequence of actions over time is often referred to as a strategy, or policy. In this work, we consider policy optimization in a quantum network. Specifically, as a first step towards developing full-fledged quantum network protocols, we consider policies for generating elementary links in a quantum network. We start by casting elementary link generation as a quantum partially observable Markov decision process, as defined in [Phys. Rev. A 90, 032311 (2014)]. Then, we analyze in detail the commonly used memory cutoff policy. Under this policy, once a link is established it is kept in quantum memory for some amount $t^{\star}$ of time, called the cutoff, before it is discarded and link generation is reattempted. For this policy, we determine the average quantum state of the elementary link as a function of time for an arbitrary number of nodes in the link, as well as the average fidelity of the link as a function of time for any noise model for the quantum memories. We then show how optimal policies can be obtained in the finite-horizon setting using dynamic programming.      

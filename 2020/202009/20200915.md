# ArXiv eess --Tue, 15 Sep 2020
### 1.Passive communication with ambient noise  [ :arrow_down: ](https://arxiv.org/pdf/2009.06618.pdf)
>  Motivated by applications to wireless communications, this paper addresses the propagation of waves transmitted by ambient noise sources and interacting with metamaterials. We discuss a generalized Helmholtz-Kirchhoff identity that is valid in dispersive media and we characterize the statistical properties of the empirical cross spectral density of the wave field. We can then introduce and analyze an original communication scheme between two passive arrays that uses only ambient noise illumination. The passive transmitter array does not transmit anything but it is a tunable metamaterial surface that can modulate its scattering properties and encode a message in the modulation. The passive receiver array can then decode the message from the wave field, provided its geometry is appropriately chosen.      
### 2.An Energy-efficient Wireless Neural Recording System with Compressed Sensing and Encryption  [ :arrow_down: ](https://arxiv.org/pdf/2009.06532.pdf)
>  This paper presents a wireless neural recording system featuring energy-efficient data compression and encryption. An ultra-high efficiency is achieved by leveraging compressed sensing (CS) for simultaneous data compression and encryption. CS enables sub-Nyquist sampling of neural signals by taking advantage of its intrinsic sparsity. It simultaneously encrypts the data with the sampling matrix being the cryptographic key. To share the key over an insecure wireless channel, we implement an elliptic-curve cryptography (ECC) based key exchanging protocol. The CS operation is executed in a custom-designed IC fabricated in 180nm CMOS technology. Mixed-signal circuits are designed to optimize the power efficiency of the matrix-vector multiplication (MVM) of the CS operation. The ECC algorithm is implemented in a low-power Cortex-M0 microcontroller (MCU). To be protected from timing and power analysis attacks, the implementation avoids possible data-dependent branches and also employs a randomized ECC initialization. At a compression ratio of 8x, the average correlated coefficient between the reconstructed signals and the uncompressed signals is 0.973, while the ciphertext-only attacks (CoA) achieve no better than 0.054 over 200,000 attacks. The prototype achieves a 35x power saving compared with conventional implementation in low-power MCUs. This work demonstrates a promising solution for future chronic neural recording systems with requirements in high energy efficiency and security.      
### 3.Principle Component Analysis for Classification of the Quality of Aromatic Rice  [ :arrow_down: ](https://arxiv.org/pdf/2009.06496.pdf)
>  This research introduces an instrument for performing quality control on aromatic rice by utilizing feature extraction of Principle Component Analysis (PCA) method. Our proposed system (DNose v0.2) uses the principle of electronic nose or enose. Enose is a detector instrument that work based on classification of the smell, like function of human nose. It has to be trained first for recognizing the smell before work in classification process. The aim of this research is to build an enose system for quality control instrument, especially on aromatic rice. The advantage of this system is easy to operate and not damaging the object of research. In this experiment, ATMega 328 and 6 gas sensors are involved in the electronic module and PCA method is used for classification process.      
### 4.Label-Free Segmentation of COVID-19 Lesions in Lung CT  [ :arrow_down: ](https://arxiv.org/pdf/2009.06456.pdf)
>  Scarcity of annotated images hampers the building of automated solution for reliable COVID-19 diagnosis and evaluation from CT. To alleviate the burden of data annotation, we herein present a label-free approach for segmenting COVID-19 lesions in CT via pixel-level anomaly modeling that mines out the relevant knowledge from normal CT lung scans. Our modeling is inspired by the observation that the parts of tracheae and vessels, which lay in the high-intensity range where lesions belong to, exhibit strong patterns. To facilitate the learning of such patterns at a pixel level, we synthesize `lesions' using a set of surprisingly simple operations and insert the synthesized `lesions' into normal CT lung scans to form training pairs, from which we learn a normalcy-converting network (NormNet) that turns an 'abnormal' image back to normal. Our experiments on three different datasets validate the effectiveness of NormNet, which conspicuously outperforms a variety of unsupervised anomaly detection (UAD) methods.      
### 5.Automatic Trajectory Synthesis for Real-Time Temporal Logic  [ :arrow_down: ](https://arxiv.org/pdf/2009.06436.pdf)
>  Many safety-critical systems must achieve high-level task specifications with guaranteed safety and correctness. Much recent progress towards this goal has been made through controller synthesis from temporal logic specifications. Existing approaches, however, have been limited to relatively short and simple specifications. Furthermore, existing methods either consider some prior discretization of the state-space, deal only with a convex fragment of temporal logic, or are not provably complete. We propose a scalable, provably complete algorithm that synthesizes continuous trajectories to satisfy non-convex \gls*{rtl} specifications. We separate discrete task planning and continuous motion planning on-the-fly and harness highly efficient boolean satisfiability (SAT) and \gls*{lp} solvers to find dynamically feasible trajectories that satisfy non-convex \gls*{rtl} specifications for high dimensional systems. The proposed design algorithms are proven sound and complete, and simulation results demonstrate our approach's scalability.      
### 6.Comprehensive Comparison of Deep Learning Models for Lung and COVID-19 Lesion Segmentation in CT scans  [ :arrow_down: ](https://arxiv.org/pdf/2009.06412.pdf)
>  Recently there has been an explosion in the use of Deep Learning (DL) methods for medical image segmentation. However the field's reliability is hindered by the lack of a common base of reference for accuracy/performance evaluation and the fact that previous research uses different datasets for evaluation. In this paper, an extensive comparison of DL models for lung and COVID-19 lesion segmentation in Computerized Tomography (CT) scans is presented, which can also be used as a benchmark for testing medical image segmentation models. Four DL architectures (Unet, Linknet, FPN, PSPNet) are combined with 25 randomly initialized and pretrained encoders (variations of VGG, DenseNet, ResNet, ResNext, DPN, MobileNet, Xception, Inception-v4, EfficientNet), to construct 200 tested models. Three experimental setups are conducted for lung segmentation, lesion segmentation and lesion segmentation using the original lung masks. A public COVID-19 dataset with 100 CT scan images (80 for train, 20 for validation) is used for training/validation and a different public dataset consisting of 829 images from 9 CT scan volumes for testing. Multiple findings are provided including the best architecture-encoder models for each experiment as well as mean Dice results for each experiment, architecture and encoder independently. Finally, the upper bounds improvements when using lung masks as a preprocessing step or when using pretrained models are quantified. The source code and 600 pretrained models for the three experiments are provided, suitable for fine-tuning in experimental setups without GPU capabilities.      
### 7.Frequency Estimation of Multi-Sinusoidal Signals in Finite-Time  [ :arrow_down: ](https://arxiv.org/pdf/2009.06400.pdf)
>  This paper considers the problem of frequency estimation for a multi-sinusoidal signal consisting of n sinuses in finite-time. The parameterization approach based on applying delay operators to a measurable signal is used. The result is the nth order linear regression model with n parameters, which depends on the signals frequencies. We propose to use Dynamic Regressor Extension and Mixing method to replace nth order regression model with n first-order regression models. Then the standard gradient descent method is used to estimate separately for each the regression model parameter. On the next step using algebraic equations finite-time frequency estimate is found. The described method does not require measuring or calculating derivatives of the input signal, and uses only the signal measurement. The efficiency of the proposed approach is demonstrated through the set of numerical simulations.      
### 8.Optimal Resource Allocation for Delay Minimization in NOMA-MEC Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.06397.pdf)
>  Multi-access edge computing (MEC) can enhance the computing capability of mobile devices, while non-orthogonal multiple access (NOMA) can provide high data rates. Combining these two strategies can effectively benefit the network with spectrum and energy efficiency. In this paper, we investigate the task delay minimization in multi-user NOMA-MEC networks, where multiple users can offload their tasks simultaneously through the same frequency band. We adopt the partial offloading policy, in which each user can partition its computation task into offloading and locally computing parts. We aim to minimize the task delay among users by optimizing their tasks partition ratios and offloading transmit power. The delay minimization problem is first formulated, and it is shown that it is a nonconvex one. By carefully investigating its structure, we transform the original problem into an equivalent quasi-convex. In this way, a bisection search iterative algorithm is proposed in order to achieve the minimum task delay. To reduce the complexity of the proposed algorithm and evaluate its optimality, we further derive closed-form expressions for the optimal task partition ratio and offloading power for the case of two-user NOMA-MEC networks. Simulations demonstrate the convergence and optimality of the proposed algorithm and the effectiveness of the closed-form analysis.      
### 9.Comparison of Deep Learning and Traditional Machine Learning Techniques for Classification of Pap Smear Images  [ :arrow_down: ](https://arxiv.org/pdf/2009.06366.pdf)
>  A comprehensive study on machine and deep learning techniques for classification of normal and abnormal cervical cells by using pap smear images from Herlev dataset results are presented. This dataset includes 917 images and 7 different classes. All techniques used in this study are modeled by using Google Colab platform with scikit-learn and Keras library inside TensorFlow. In the first study, traditional machine learning methods such as logistic regression, k-Nearest Neighbors (kNN), Support Vector Machine (SVM), Decision Tree, Random Forest and eXtreme Gradient Boosting (XGBoost) are used and compared with each other to find binary classification as normal and abnormal cervical cells. Better results are observed by XGBoost and kNN classifiers among the others with an accuracy of 85%. In the second study, a deep learning model based on Convolutional Neural Network(CNN) is used for the same dataset. Accordingly, accuracies of 99% and 93% are obtained for the training and the test dataset, respectively. In this model, it takes 50 epochs to have these accuracies within 20 minutes of computational time.      
### 10.Automatic elimination of the pectoral muscle in mammograms based on anatomical features  [ :arrow_down: ](https://arxiv.org/pdf/2009.06357.pdf)
>  Digital mammogram inspection is the most popular technique for early detection of abnormalities in human breast tissue. When mammograms are analyzed through a computational method, the presence of the pectoral muscle might affect the results of breast lesions detection. This problem is particularly evident in the mediolateral oblique view (MLO), where pectoral muscle occupies a large part of the mammography. Therefore, identifying and eliminating the pectoral muscle are essential steps for improving the automatic discrimination of breast tissue. In this paper, we propose an approach based on anatomical features to tackle this problem. Our method consists of two steps: (1) a process to remove the noisy elements such as labels, markers, scratches and wedges, and (2) application of an intensity transformation based on the Beta distribution. The novel methodology is tested with 322 digital mammograms from the Mammographic Image Analysis Society (mini-MIAS) database and with a set of 84 mammograms for which the area normalized error was previously calculated. The results show a very good performance of the method.      
### 11.Empirical Evaluation of a 28~GHz Antenna Array on a 5G Mobile Phone Using a Body Phantom  [ :arrow_down: ](https://arxiv.org/pdf/2009.06318.pdf)
>  Implementation of an antenna array on a 5G mobile phone chassis is crucial in ensuring the radio link quality especially at millimeter-waves. However, we generally lack the ability to design antennas under practical operational conditions involving body effects of a mobile user in a repeatable manner. We developed numerical and physical phantoms of a human body for evaluation of mobile handset antennas at 28 GHz. While the numerical phantom retains a realistic and accurate body shape, our physical phantom has much simpler hexagonal cross-section to represent a body. Gains of the phased antenna array configuration on a mobile phone chassis, called co-located array is numerically and experimentally evaluated. The array is formed by placing two sets of 4-element dual-polarized patch antenna arrays, called two modules, at two locations of a mobile phone chassis. Modules are intended to collect the maximum amount of energy to the single transceiver chain. Spherical coverage of the realized gain by the array shows that the experimental statistics of the realized gains across entire solid angles agree with numerical simulations. We thereby demonstrate that our antenna evaluation method reproduces the reality and our phantom serves repeatable tests of antenna array prototypes at 28 GHz.      
### 12.Feedback Prediction for Proactive HARQ in the Context of Industrial Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2009.06301.pdf)
>  In this work, we investigate proactive Hybrid Automatic Repeat reQuest (HARQ) using link-level simulations for multiple packet sizes, modulation orders, BLock Error Rate (BLER) targets and two delay budgets of 1 ms and 2 ms, in the context of Industrial Internet of Things (IIOT) applications. In particular, we propose an enhanced proactive HARQ protocol using a feedback prediction mechanism. We show that the enhanced protocol achieves a significant gain over the classical proactive HARQ in terms of energy efficiency for almost all evaluated BLER targets at least for sufficiently large feedback delays. Furthermore, we demonstrate that the proposed protocol clearly outperforms the classical proactive HARQ in all scenarios when taking a processing delay reduction due to the less complex prediction approach into account, achieving an energy efficiency gain in the range of 11% up to 15% for very stringent latency budgets of 1 ms at $10^{-2}$ BLER and from 4% up to 7.5% for less stringent latency budgets of 2 ms at $10^{-3}$ BLER. Furthermore, we show that power-constrained proactive HARQ with prediction even outperforms unconstrained reactive HARQ for sufficiently large feedback delays.      
### 13.Neurodynamic TDOA Localization with NLOS Mitigation via Maximum Correntropy Criterion  [ :arrow_down: ](https://arxiv.org/pdf/2009.06281.pdf)
>  The commonly applied approaches for localization in the Internet of Things context using time-of-arrival (TOA) or time-difference-of-arrival (TDOA) measurements usually suffer significant performance degradation due to the presence of non-line-of-sight (NLOS) propagation. Unlike the majority of existing efforts made under the framework of convex relaxation, in this paper we devise a computationally simpler neurodynamic optimization method for robust TDOA-based localization with the use of the maximum correntropy criterion. To be specific, the outlier-insensitive correntropy-induced loss function is utilized as the measure for the fitting error after TDOA-to-TOA model transformation, whereupon we design a hardware implementable recurrent neural network to solve the derived nonlinear and nonconvex constrained optimization problem, based on the redefined augmented Lagrangian and projection theorem. The local stability of equilibrium for the established dynamical system is examined, and numerically realizing the presented projection-type neural network leads to merely quadratic complexity in the number of sensors. Simulation investigations show that our TDOA-based localization solution outperforms several state-of-the-art schemes in terms of localization accuracy, especially when the NLOS paths and errors tend to exhibit sparsity and severeness, respectively.      
### 14.Correction to:"Position estimation from direction or range measurements"  [ :arrow_down: ](https://arxiv.org/pdf/2009.06278.pdf)
>  This technical communiqué aims at correcting an erroneous statement (Lemma 2.4) in an earlier paper by the same authors concerning a sufficient condition of uniform observability for a Linear Time-Varying (LTV) system. In this earlier paper, the proofs of two other lemmas, about body-pose estimation from range measurements, relied on this erroneous statement. For the sake of conciseness, only a new proof of one of these lemmas is presented, the proof of the second lemma being a simpler version of it.      
### 15.Efficient multi-class fetal brain segmentation in high resolution MRI reconstructions with noisy labels  [ :arrow_down: ](https://arxiv.org/pdf/2009.06275.pdf)
>  Segmentation of the developing fetal brain is an important step in quantitative analyses. However, manual segmentation is a very time-consuming task which is prone to error and must be completed by highly specialized indi-viduals. Super-resolution reconstruction of fetal MRI has become standard for processing such data as it improves image quality and resolution. However, dif-ferent pipelines result in slightly different outputs, further complicating the gen-eralization of segmentation methods aiming to segment super-resolution data. Therefore, we propose using transfer learning with noisy multi-class labels to automatically segment high resolution fetal brain MRIs using a single set of seg-mentations created with one reconstruction method and tested for generalizability across other reconstruction methods. Our results show that the network can auto-matically segment fetal brain reconstructions into 7 different tissue types, regard-less of reconstruction method used. Transfer learning offers some advantages when compared to training without pre-initialized weights, but the network trained on clean labels had more accurate segmentations overall. No additional manual segmentations were required. Therefore, the proposed network has the potential to eliminate the need for manual segmentations needed in quantitative analyses of the fetal brain independent of reconstruction method used, offering an unbiased way to quantify normal and pathological neurodevelopment.      
### 16.Observer-Based Fault-Tolerant Spacecraft Attitude Tracking Using Sequential Lyapunov Analyses  [ :arrow_down: ](https://arxiv.org/pdf/2009.06241.pdf)
>  The spacecraft attitude tracking problem is addressed with actuator faults and uncertainties among inertias, external disturbances, and, in particular, state estimates. A continuous sliding mode attitude controller is designed using attitude and angular velocity estimates from an arbitrary stable stand-alone observer. Rigorous analysis shows that the controller ensures robust stability of the entire closed-loop system as long as the observer yields state estimates with uniformly ultimately bounded estimation errors. In addition, a sequential Lyapunov analysis is utilized to obtain a convergent sequence of analytical, successively tighter upper bounds on the steady-state tracking error. Therefore, our results can be used to predict steady-state performance bounds given selected gains or facilitate gain selection given steady-state performance bounds. Numerical examples demonstrate the utility of the proposed theory.      
### 17.Consensus of Multi-agent System via Constrained Invariant Set of a class of Unstable System  [ :arrow_down: ](https://arxiv.org/pdf/2009.06236.pdf)
>  This work shows an approach to achieve output consensus among heterogeneous agents in a multi-agent environment where each agent is subject to input constraints. The communication among agents is described by a time-varying directed/undirected graph. The approach is based on the well-known Internal Model Principle which uses an unstable reference system. One main contribution of this work is the characterization of the maximal constraint admissible invariant set (MCAI) for the combined agent-reference system. Typically, MCAI sets do not exist for unstable system. This work shows that for an important class of agent-reference system that is unstable, MCAI exists and can be computed. This MCAI set is used in a Reference Governor approach, combined with a projected consensus algorithm, to achieve output consensus of all agents while satisfying constraints of each. Examples are provided to illustrate the approach.      
### 18.Energy-Efficient Resource Allocation for NOMA enabled MEC Networks with Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2009.06234.pdf)
>  The combination of non-orthogonal multiple access (NOMA) and mobile edge computing (MEC) can significantly improve the spectrum efficiency beyond the fifth-generation network. In this paper, we mainly focus on energy-efficient resource allocation for a multi-user, multi-BS NOMA assisted MEC network with imperfect channel state information (CSI), in which each user can upload its tasks to multiple base stations (BSs) for remote executions. To minimize the energy consumption, we consider jointly optimizing the task assignment, power allocation and user association. As the main contribution, with imperfect CSI, the optimal closed-form expressions of task assignment and power allocation are analytically derived for the two-BS case. Specifically, the original formulated problem is nonconvex. We first transform the probabilistic problem into a non-probabilistic one. Subsequently, a bilevel programming method is proposed to derive the optimal solution. In addition, by incorporating the matching algorithm with the optimal task and power allocation, we propose a low complexity algorithm to efficiently optimize user association for the multi-user and multi-BS case. Simulations demonstrate that the proposed algorithm can yield much better performance than the conventional OMA scheme but also the identical results with lower complexity from the exhaustive search with the small number of BSs.      
### 19.Joint Optimization of Beamforming, Phase-Shifting and Power Allocation in a Multi-cluster IRS-NOMA Network  [ :arrow_down: ](https://arxiv.org/pdf/2009.06233.pdf)
>  The combination of non-orthogonal multiple access (NOMA) and intelligent reflecting surface (IRS) is an efficient solution to significantly enhance the energy efficiency of the wireless communication system. In this paper, we focus on a downlink multi-cluster NOMA network, where each cluster is supported by one IRS. We aim to minimize the transmit power by jointly optimizing the beamforming, the power allocation and the phase shift of each IRS. The formulated problem is non-convex and challenging to solve due to the coupled variables, i.e., the beamforming vector, the power allocation coefficient and the phase shift matrix. To address this non-convex problem, we propose an alternating optimization based algorithm. Specifically, we divide the primal problem into the two subproblems for beamforming optimization and phase shifting feasiblity, where the two subproblems are solved iteratively. Moreover, to guarantee the feasibility of the beamforming optimization problem, an iterative algorithm is proposed to search the feasible initial points. To reduce the complexity, we also propose a simplified algorithm based on partial exhaustive search for this system model. Simulation results demonstrate that the proposed alternating algorithm can yield a better performance gain than the partial exhaustive search algorithm, OMA-IRS, and NOMA with random IRS phase shift.      
### 20.Enhancing Ambient Backscatter Communication Utilizing Coherent and Non-Coherent Space-Time Codes  [ :arrow_down: ](https://arxiv.org/pdf/2009.06204.pdf)
>  Ambient backscatter communication (AmBC) leverages the existing ambient radio frequency (RF) environment to implement communication with battery-free devices. The key challenge in the development of AmBC is the very weak RF signals backscattered by the AmBC Tag. To overcome this challenge, we propose the use of space-time codes by incorporating multiple antennas at the Tag. Our approach considers both coherent and non-coherent space-time codes so that systems with and without Channel State Information can be considered. To allow the application of space-time codes, we propose an approximate linearized and normalized multiple-input multiple-output (MIMO) channel model for the AmBC system. Such MIMO channel model is shown to be accurate for a wide range of useful operating conditions. Two coherent detectors and a non-coherent detector are also provided based on the proposed channel. Simulation results show that enhanced bit error rate performance can be achieved, demonstrating the benefit of using multiple Tag or Reader antennas to leverage the diversity gain. The results are restricted to two antennas at the Tag, to maintain compact size by using polarization diversity and maintain a multiplexing gain of unity, but the results can easily be extended to more than two antennas.      
### 21.Cyber Attack and Machine Induced Fault Detection and Isolation Methodologies for Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.06196.pdf)
>  In this paper, the problem of simultaneous cyber attack and fault detection and isolation (CAFDI) in cyber-physical systems (CPS) is studied. The proposed solution methodology consists of two filters on the plant and the command and control (C\&amp;C) sides of the CPS and an unknown input observer (UIO) based detector on the plant side. Conditions under which the proposed methodology can detect deception attacks, such as covert attacks, zero dynamics attacks, and replay attacks are characterized. An advantage of the proposed methodology is that one does not require a fully secured communication link which implies that the communication link can be compromised by the adversary while it is used to transmit the C\&amp;C side observer estimates. Also, it is assumed that adversaries have access to parameters of the system, filters, and the UIO-based detector, however, they do not have access to all the communication link channels. Conditions under which, using the communication link cyber attacks, the adversary cannot eliminate the impact of actuator and sensor cyber attacks are investigated. To illustrate the capabilities and effectiveness of the proposed CAFDI methodologies, simulation case studies are provided and comparisons with detection methods that are available in the literature are included to demonstrate the advantages and benefits of our proposed solutions.      
### 22.Mitigation and Resiliency of Multi-Agent Systems Subject to Malicious Cyber Attacks on Communication Links  [ :arrow_down: ](https://arxiv.org/pdf/2009.06181.pdf)
>  This paper aims at investigating a novel type of cyber attack that is injected to multi-agent systems (MAS) having an underlying directed graph. The cyber attack, which is designated as the controllability attack, is injected by the malicious adversary into the communication links among the agents. The adversary, leveraging the compromised communication links disguises the cyber attack signals and attempts to take control over the entire network of MAS. The adversary aims at achieving this by directly attacking only a subset of the multi-agents. Conditions under which the malicious hacker has control over the entire MAS network are provided. Two notions of security controllability indices are proposed and developed. These notions are utilized as metrics to evaluate the controllability that each agent provides to the adversary for executing the malicious cyber attack. Furthermore, the possibility of introducing zero dynamics cyber attacks on the MAS through compromising the communication links is also investigated. Finally, an illustrative numerical example is provided to demonstrate the effectiveness of our proposed methods.      
### 23.Undetectable Cyber Attacks on Communication Links in Multi-Agent Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.06173.pdf)
>  The objective in this paper is to study and develop conditions for a network of multi-agent cyber-physical systems (MAS) where a malicious adversary can utilize vulnerabilities in order to ensure and maintain cyber attacks undetectable. We classify these cyber attacks as undetectable in the sense that their impact cannot be observed in the generated residuals. It is shown if an agent that is the root of a rooted spanning tree in the MAS graph is under a cyber attack, the attack is undetectable by the entire network. Next we investigate if a non-root agent is compromised, then under certain conditions cyber attacks can become detectable. Moreover, a novel cyber attack that is designated as quasi-covert cyber attack is introduced that can be used to eliminate detectable impacts of cyber attacks to the entire network and maintain these attacks as undetected. Finally, an event-triggered based detector is proposed that can be used to detect the quasi-covert cyber attacks. Numerical simulations are provided to illustrate the effectiveness and capabilities of our proposed methodologies.      
### 24.Distributed Peer-to-Peer Energy Trading for Residential Fuel Cell Combined Heat and Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2009.06159.pdf)
>  This paper studies the optimal energy management in a group of dwellings having micro fuel cell combined heat and power systems. To increase the self-sufficiency and resilience of such local community, a peer-to-peer energy trading system between dwellings is proposed in which output powers from fuel cells working under their rated powers can be sold to those already reach their rated outputs but still lack powers. The arising optimization problem from this optimal peer-to-peer energy trading system is non-convex due to the nonlinear dependence of power and heat efficiencies on fuel cell output power. Therefore, a linearization method is proposed to convexify the problem. Consequently, a distributed ADMM approach is introduced to solve the convexified optimization problem in parallel at each dwelling. A case study for a group of six dwellings based on realistic electric consumption data is then presented to demonstrate the proposed approach performance and positive impacts of the P2P energy trading system. More specifically, the proposed distributed ADMM approach is reasonably fast in convergence and is scalable well with system size. In addition, P2P electricity trading system helps operate fuel cells at a higher efficiency and increase the self-sufficiency of such dwellings.      
### 25.Super Resolution of Arterial Spin Labeling MR Imaging Using Unsupervised Multi-Scale Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2009.06129.pdf)
>  Arterial spin labeling (ASL) magnetic resonance imaging (MRI) is a powerful imaging technology that can measure cerebral blood flow (CBF) quantitatively. However, since only a small portion of blood is labeled compared to the whole tissue volume, conventional ASL suffers from low signal-to-noise ratio (SNR), poor spatial resolution, and long acquisition time. In this paper, we proposed a super-resolution method based on a multi-scale generative adversarial network (GAN) through unsupervised training. The network only needs the low-resolution (LR) ASL image itself for training and the T1-weighted image as the anatomical prior. No training pairs or pre-training are needed. A low-pass filter guided item was added as an additional loss to suppress the noise interference from the LR ASL image. After the network was trained, the super-resolution (SR) image was generated by supplying the upsampled LR ASL image and corresponding T1-weighted image to the generator of the last layer. Performance of the proposed method was evaluated by comparing the peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) using normal-resolution (NR) ASL image (5.5 min acquisition) and high-resolution (HR) ASL image (44 min acquisition) as the ground truth. Compared to the nearest, linear, and spline interpolation methods, the proposed method recovers more detailed structure information, reduces the image noise visually, and achieves the highest PSNR and SSIM when using HR ASL image as the ground-truth.      
### 26.Low Complexity Soft-Output Faster-than-Nyquist Detector Based on Semidefinite Relaxation  [ :arrow_down: ](https://arxiv.org/pdf/2009.06128.pdf)
>  Faster than Nyquist (FTN) signaling is an attractive transmission technique that is capable of improving the spectral efficiency with additional detection complexity at the receiver. Semidefinite relaxation (SDR) based FTN detectors are appealing as they provide good performance with linear decoding complexity. In this paper, we propose a soft-output semidefinite relaxation (soSDR) based FTN detector which has a similar polynomial complexity order when compared to its counterpart that only produces hard-output decisions. The main complexity reduction lies in re-using the candidate sequences generated in the Gaussian randomization (GR) step to produce reliable soft-output values, which approximate the calculation of the log-likelihood ratio (LLR) inputs for the channel decoder. The effectiveness of the proposed soSDR algorithm is evaluated using polar codes with successive cancellation decoding (SCD) through simulations, and its performance is compared against the state-of-the-art techniques from the literature. Simulation results show that the proposed soSDR algorithm provides reliable LLR values and strikes a good balance between detection complexity and bit error rate (BER) performance.      
### 27.Revisiting the nonlinear Gaussian noise model: The case of hybrid fiber spans  [ :arrow_down: ](https://arxiv.org/pdf/2009.06126.pdf)
>  We rederive from first principles and generalize the theoretical framework of the nonlinear Gaussian noise model to the case of coherent optical systems with multiple fiber types per span and ideal Nyquist spectra. We focus on the accurate numerical evaluation of the integral for the nonlinear noise variance for hybrid fiber spans. This task consists in addressing four computational aspects: (i) Adopting a novel transformation of variables (other than using hyperbolic coordinates) that changes the integrand to a more appropriate form for numerical quadrature; (ii) Evaluating analytically the integral at its lower limit, where the integrand presents a singularity; (iii) Dividing the interval of integration into subintervals of size pi and approximating the integral in each subinterval by using various algorithms; and (iv) Deriving an upper bound for the relative error when the interval of integration is truncated in order to accelerate computation. We apply the proposed model to coherent optical communications systems with hybrid fiber spans composed of quasi-singlemode fiber and single-mode fiber segments. The accuracy of the final analytical relationship for the nonlinear noise variance in long-haul coherent optical communications systems with hybrid fiber spans is checked using the split-step Fourier method and Monte Carlo simulation. It is shown to be adequate to within 0.1 dBQ for the determination of the optimal fiber segment lengths per span that maximize system performance.      
### 28.Phase-Only Beam Broadening of Contiguous Uniform Subarrayed Arrays Utilizing Three Metaheuristic Global Optimization Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2009.06123.pdf)
>  Radar beam broadening provides continuous coverage of a wider angular extent. While many methods have been published that address beam broadening of traditional (nonsubarrayed) arrays, there is a knowledge gap in the published literature with respect to efficient and effective beam broadening of contiguous uniform subarrayed arrays. This paper presents efficient and effective methods for beam broadening of contiguous uniform subarrayed arrays where elements of the array are grouped together to have the same element excitations. Particularly, this paper focuses on phase-only optimization to preserve maximum power output. The high dimensionality of the solution space of possible phase settings causes brute force techniques to be infeasible for exhaustively evaluating the entire space. This paper presents three metaheuristic global optimization techniques that efficiently and effectively search for optimal phase values in this large solution space that satisfy the desired broadened pattern. The techniques presented in this paper are simulated annealing, genetic algorithm with elitism, and particle swarm optimization. These techniques are evaluated on idealized 40x40 and 80x80 element rectangular arrays with 5x5 element subarrays. The results of this study show that as configured in this paper the simulated annealing and particle swarm techniques outshine the genetic algorithm technique for 40x40 and 80x80 rectangular arrays grouped into contiguous uniform 5x5 element subarrays.      
### 29.ICASSP 2021 Deep Noise Suppression Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2009.06122.pdf)
>  The Deep Noise Suppression (DNS) challenge is designed to foster innovation in the area of noise suppression to achieve superior perceptual speech quality. We recently organized a DNS challenge special session at INTERSPEECH 2020. We open sourced training and test datasets for researchers to train their noise suppression models. We also open sourced a subjective evaluation framework and used the tool to evaluate and pick the final winners. Many researchers from academia and industry made significant contributions to push the field forward. We also learned that as a research community, we still have a long way to go in achieving excellent speech quality in challenging noisy real-time conditions. In this challenge, we are expanding both our training and test datasets. There are two tracks with one focusing on real-time denoising and the other focusing on real-time personalized deep noise suppression. We also make a non-intrusive objective speech quality metric called DNSMOS available for participants to use during their development stages. The final evaluation will be based on subjective tests.      
### 30.Peak Estimation and Recovery with Occupation Measures  [ :arrow_down: ](https://arxiv.org/pdf/2009.06120.pdf)
>  Peak Estimation aims to find the maximum value of a state function achieved by a dynamical system. This problem is non-convex when considering standard Barrier and Density methods for invariant sets, and has been treated heuristically by using auxiliary functions. A convex formulation based on occupation measures is proposed in this paper to solve peak estimation. This method is dual to the auxiliary function approach. Our method will converge to the optimal solution and can recover trajectories even from approximate solutions. This framework is extended to safety analysis by maximizing the minimum of a set of costs along trajectories.      
### 31.Band-Passing Nonlinearity in Reset Elements  [ :arrow_down: ](https://arxiv.org/pdf/2009.06091.pdf)
>  This paper addresses nonlinearity in reset elements and their effects. Reset elements are known for having less phase lag compared to their linear counterparts; however, they are nonlinear elements and produce higher-order harmonics. This paper investigates the higher-order harmonics for reset elements with one resetting state and proposes an architecture and a method of design which allows for band-passing the nonlinearity and its effects, namely, higher-order harmonics and phase advantage. The nonlinearity of reset elements is not entirely useful for all frequencies, e.g., they are useful for reducing phase lag at cross-over frequency region; however, higher-order harmonics can compromise tracking and disturbance rejection performance at lower frequencies. Using proposed "phase shaping" method, one can selectively suppress nonlinearity of a single-state reset element in a desired range of frequencies and allow the nonlinearity to provide its phase benefit in a different desired range of frequencies. This can be especially useful for the reset elements in the framework of "Constant in gain, Lead in phase" (CgLp) filter, which is a newly introduced nonlinear filter, bound to circumvent the well-known linear control limitation -- the waterbed effect.      
### 32.An Overview of Microinverter Design Characteristics and MPPT Control  [ :arrow_down: ](https://arxiv.org/pdf/2009.06055.pdf)
>  Micro-inverter technologies are becoming increasingly popular as a choice of grid connection for small-scale photovoltaic systems. Efficiently harvesting the maximum energy from a photovoltaic system reduces the Levelized cost for solar energy, enhancing its role in combatting climate change. Various topologies are proposed through research and have been summarised in this paper. Furthermore, this paper investigates two popular Maximum Power Point Tracking (MPPT) methods through simulation using Matlab Simulink.      
### 33.Millimeter Wave Full-Duplex Radios: New Challenges and Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2009.06048.pdf)
>  Equipping millimeter wave (mmWave) systems with full-duplex capability would accelerate and transform next-generation wireless applications and forge a path for new ones. Full-duplex mmWave transceivers could capitalize on the already attractive features of mmWave communication by supplying spectral efficiency gains and latency improvements while also affording future networks with deployment solutions in the form of interference management and wireless backhaul. Foreseeable challenges and obstacles in making mmWave full-duplex a reality are presented in this article along with noteworthy unknowns warranting further investigation. With these novelties of mmWave full-duplex in mind, we lay out potential solutions---beyond active self-interference cancellation---that harness the spatial degrees of freedom bestowed by dense antenna arrays to enable simultaneous transmission and reception in-band.      
### 34.Set operations and order reductions for constrained zonotopes  [ :arrow_down: ](https://arxiv.org/pdf/2009.06039.pdf)
>  This paper presents methods for using zonotopes and constrained zonotopes to improve the practicality of a wide variety of set-based operations commonly used in control theory. The proposed methods extend the use of constrained zonotopes to represent sets resulting from operations including halfspace intersections, convex hulls, robust positively invariant sets, and Pontryagin differences. Order reduction techniques are also presented that provide lower-complexity inner-approximations of zonotopes and constrained zonotopes. Numerical examples are used to demonstrate the efficacy and computational advantages of using zonotope-based set representations for dynamic system analysis and control.      
### 35.Maximum correntropy criterion for robust TOA-based localization in NLOS environments  [ :arrow_down: ](https://arxiv.org/pdf/2009.06032.pdf)
>  We investigate the problem of non-line-of-sight (NLOS) mitigation for source localization using time-of-arrival (TOA) measurements. To achieve resistance against the bias-like NLOS errors in the TOA-based squared-range observations, we follow the maximum correntropy criterion to establish a novel robust loss function, of which the minimization is pursued. As the nonlinear and nonconvex optimization problem formulated is generally hard to solve, half-quadratic technique is applied to settle it in an alternating maximization (AM) manner. The implementation of our method requires nothing but merely the TOA-based range measurements and sensor positions as prior information, and the major computational challenge at each AM iteration by construction boils down to handling an easily solvable generalized trust region subproblem. Simulation and experimental results show the competence of the presented scheme in outperforming several state-of-the-art approaches in terms of positioning accuracy, especially in scenarios where the percentage of NLOS paths is not large enough.      
### 36.Rumor-robust Decentralized Gaussian Process Learning, Fusion, and Planning for Modeling Multiple Moving Targets  [ :arrow_down: ](https://arxiv.org/pdf/2009.06021.pdf)
>  This paper presents a decentralized Gaussian Process (GP) learning, fusion, and planning (RESIN) formalism for mobile sensor networks to actively learn target motion models. RESIN is characterized by both computational and communication efficiency, and the robustness to rumor propagation in sensor networks. By using the weighted exponential product rule and the Chernoff information, a rumor-robust decentralized GP fusion approach is developed to generate a globally consistent target trajectory prediction from local GP models. A decentralized information-driven path planning approach is then proposed for mobile sensors to generate informative sensing paths. A novel, constant-sized information sharing strategy is developed for path coordination between sensors, and an analytical objective function is derived that significantly reduces the computational complexity of the path planning. The effectiveness of RESIN is demonstrated in various numerical simulations.      
### 37.A Tutorial of Ultra-Reliable and Low-Latency Communications in 6G: Integrating Theoretical Knowledge into Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.06010.pdf)
>  As one of the key communication scenarios in the 5th and also the 6th generation (6G) cellular networks, ultra-reliable and low-latency communications (URLLC) will be central for the development of various emerging mission-critical applications. The state-of-the-art mobile communication systems do not fulfill the end-to-end delay and overall reliability requirements of URLLC. A holistic framework that takes into account latency, reliability, availability, scalability, and decision-making under uncertainty is lacking. Driven by recent breakthroughs in deep neural networks, deep learning algorithms have been considered as promising ways of developing enabling technologies for URLLC in future 6G networks. This tutorial illustrates how to integrate theoretical knowledge (models, analysis tools, and optimization frameworks) of wireless communications into different kinds of deep learning algorithms for URLLC. We first introduce the background of URLLC and review promising network architectures and deep learning frameworks in 6G. To better illustrate how to improve learning algorithms with theoretical knowledge, we revisit model-based analysis tools and cross-layer optimization frameworks for URLLC. Following that, we examine the potential of applying supervised/unsupervised deep learning and deep reinforcement learning in URLLC and summarize related open problems. Finally, we provide simulation and experimental results to validate the effectiveness of different learning algorithms and discuss future directions.      
### 38.Energy Efficient Power Allocation in Massive MIMO NOMA Systems Based on SIF Using Cell Division Technique  [ :arrow_down: ](https://arxiv.org/pdf/2009.05997.pdf)
>  In this paper, we investigate energy-efficient power allocation for the downlink of the massive multiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA) systems. In our proposed scheme, we divide a cell into two zones. The first area is for users whose distance from the base station (BS) is less than half of the radius of cell and the second area is for users whose distance from BS is more than half of the radius of cell. Based on distance of users from BS and the number of users in each area, we dedicate an amount of power for each user. We also use standard interference function (SIF) to propose a new iterative algorithm to solve the optimization problem and obtain the optimal power allocation scheme. Simulation results show that the proposed algorithm outperforms other algorithms from the energy efficiency (EE) point of view.      
### 39.Multimodal Medical Image registration using Discrete Wavelet Transform and Gaussian Pyramids  [ :arrow_down: ](https://arxiv.org/pdf/2009.05978.pdf)
>  In this research paper, authors propose multimodal brain image registration using discrete wavelet transform(DWT) followed by Gaussian pyramids. The reference and target images are decomposed into their LL, LH, HL and LL DWT coefficients and then are processed for image registration using Gaussian pyramids. The image registration is also done using Gaussian pyramids only and wavelets transforms only for comparison. The quality of registration is measured by comparing the maximum MI values used by the three methods and also by comparing their correlation coefficients. Our proposed technique proves to show better results when compared with the other two methods.      
### 40.Beamforming Optimization for MIMO Wireless Power Transfer with Nonlinear Energy Harvesting: RF Combining versus DC Combining  [ :arrow_down: ](https://arxiv.org/pdf/2009.05967.pdf)
>  In this paper, we study the multiple-input and multiple-output (MIMO) wireless power transfer (WPT) system so as to enhance the output DC power of the rectennas. To that end, we revisit the rectenna nonlinearity considering multiple receive antennas. Two combining schemes for multiple rectennas at the receiver, DC and RF combinings, are modeled and analyzed. For DC combining, we optimize the transmit beamforming, adaptive to the channel state information (CSI), so as to maximize the total output DC power. For RF combining, we compute a closed-form solution of the optimal transmit and receive beamforming. In addition, we propose a practical RF combining circuit using RF phase shifter and RF power combiner and also optimize the analog receive beamforming adaptive to CSI. We also analytically derive the scaling laws of the output DC power as a function of the number of transmit and receive antennas. Those scaling laws confirm the benefits of using multiple antennas at the transmitter or receiver. They also highlight that RF combining significantly outperforms DC combining since it leverages the rectenna nonlinearity more efficiently. Two types of performance evaluations, based on the nonlinear rectenna model and based on realistic and accurate rectenna circuit simulations, are provided. The evaluations demonstrate that the output DC power can be linearly increased by using multiple rectennas at the receiver and that the relative gain of RF combining versus DC combining in terms of the output DC power level is very significant, of the order of 240% in a one-transmit antenna ten-receive antenna setup.      
### 41.Inertia and feedback parameters adaptive control of virtual synchronous generator  [ :arrow_down: ](https://arxiv.org/pdf/2009.05916.pdf)
>  The virtual synchronous generator technology analogs the characteristics of the synchronous generator via the controller design. It improved the stability of the grid systems which include the new energy. At the same time, according to the adjustable characteristics of the virtual synchronous generator parameters, the parameter adaptive adjustment is used to improve the dynamic performance of the system. However, the traditional virtual synchronous generator adaptive control technology still has two drawbacks: on the one hand, the large-scale adjustment of the damping droop coefficient and the virtual moment of inertia requires the system having a high energy storage margin; On the other hand, there is a power overshoot phenomenon in the transient regulation process, which is disadvantageous to the power equipment. First, this paper provides a convenient adjustment method for improving the transient stability of the system, the system damping is adjusted by introducing the output speed feedback. Second, according to the transient power-angle characteristics of the system, a parameter adaptive control strategy is proposed, which shortens the transient adjustment time and ensures that the deviation of the system frequency in the transient adjustment process is within the allowable range, and improves the transient performance of the grid frequency adjustment, at the same time, the power overshoot is suppressed. Finally, the experimental results show that the proposed control strategy is superior to the existing adaptive control strategy.      
### 42.A Data-driven Hierarchical Control Structure for Systems with Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2009.05914.pdf)
>  The paper introduces a Data-driven Hierarchical Control (DHC) structure to improve performance of systems operating under the effect of system and/or environment uncertainty. The proposed hierarchical approach consists of two parts: 1) A data-driven model identification component to learn a linear approximation between reference signals given to an existing lower-level controller and uncertain time-varying plant outputs. 2) A higher-level controller component that utilizes the identified approximation and wraps around the existing controller for the system to handle modeling errors and environment uncertainties during system deployment. <br>We derive loose and tight bounds for the identified approximation's sensitivity to noisy data. Further, we show that adding the higher-level controller maintains the original system's stability. A benefit of the proposed approach is that it requires only a small amount of observations on states and inputs, and it thus works online; that feature makes our approach appealing to robotics applications where real-time operation is critical. The efficacy of the DHC structure is demonstrated in simulation and is validated experimentally using aerial robots with approximately-known mass and moment of inertia parameters and that operate under the influence of ground effect.      
### 43.Attention Cube Network for Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2009.05907.pdf)
>  Recently, deep convolutional neural network (CNN) have been widely used in image restoration and obtained great success. However, most of existing methods are limited to local receptive field and equal treatment of different types of information. Besides, existing methods always use a multi-supervised method to aggregate different feature maps, which can not effectively aggregate hierarchical feature information. To address these issues, we propose an attention cube network (A-CubeNet) for image restoration for more powerful feature expression and feature correlation learning. Specifically, we design a novel attention mechanism from three dimensions, namely spatial dimension, channel-wise dimension and hierarchical dimension. The adaptive spatial attention branch (ASAB) and the adaptive channel attention branch (ACAB) constitute the adaptive dual attention module (ADAM), which can capture the long-range spatial and channel-wise contextual information to expand the receptive field and distinguish different types of information for more effective feature representations. Furthermore, the adaptive hierarchical attention module (AHAM) can capture the long-range hierarchical contextual information to flexibly aggregate different feature maps by weights depending on the global context. The ADAM and AHAM cooperate to form an "attention in attention" structure, which means AHAM's inputs are enhanced by ASAB and ACAB. Experiments demonstrate the superiority of our method over state-of-the-art image restoration methods in both quantitative comparison and visual analysis.      
### 44.Identifying Grey-box Thermal Models with Bayesian Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.05889.pdf)
>  Smart thermostats are one of the most prevalent home automation products. They learn occupant preferences and schedules, and utilize an accurate thermal model to reduce the energy use of heating and cooling equipment while maintaining the temperature for maximum comfort. Despite the importance of having an accurate thermal model for the operation of smart thermostats, fast and reliable identification of this model is still an open problem. In this paper, we explore various techniques for establishing a suitable thermal model using time series data generated by smart thermostats. We show that Bayesian neural networks can be used to estimate parameters of a grey-box thermal model if sufficient training data is available, and this model outperforms several black-box models in terms of the temperature prediction accuracy. Leveraging real data from 8,884 homes equipped with smart thermostats, we discuss how the prior knowledge about the model parameters can be utilized to quickly build an accurate thermal model for another home with similar floor area and age in the same climate zone. Moreover, we investigate how to adapt the model originally built for the same home in another season using a small amount of data collected in this season. Our results confirm that maintaining only a small number of pre-trained thermal models will suffice to quickly build accurate thermal models for many other homes, and that 1~day smart thermostat data could significantly improve the accuracy of transferred models in another season.      
### 45.Distributed Kalman Estimation with Decoupled Local Filters  [ :arrow_down: ](https://arxiv.org/pdf/2009.05799.pdf)
>  We study a distributed Kalman filtering problem in which a number of nodes cooperate without central coordination to estimate a common state based on local measurements and data received from neighbors. This is typically done by running a local filter at each node using information obtained through some procedure for fusing data across the network. A common problem with existing methods is that the outcome of local filters at each time step depends on the data fused at the previous step. We propose an alternative approach to eliminate this error propagation. The proposed local filters are guaranteed to be stable under some mild conditions on certain global structural data, and their fusion yields the centralized Kalman estimate. The main feature of the new approach is that fusion errors introduced at a given time step do not carry over to subsequent steps. This offers advantages in many situations including when a global estimate in only needed at a rate slower than that of measurements or when there are network interruptions. If the global structural data can be fused correctly asymptotically, the stability of local filters is equivalent to that of the centralized Kalman filter. Otherwise, we provide conditions to guarantee stability and bound the resulting estimation error. Numerical experiments are given to show the advantage of our method over other existing alternatives.      
### 46.EdgeLoc: An Edge-IoT Framework for Robust Indoor Localization Using Capsule Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.05780.pdf)
>  With the unprecedented demand for location-based services in indoor scenarios, wireless indoor localization has become essential for mobile users. While GPS is not available at indoor spaces, WiFi RSS fingerprinting has become popular with its ubiquitous accessibility. However, it is challenging to achieve robust and efficient indoor localization with two major challenges. First, the localization accuracy can be degraded by the random signal fluctuations, which would influence conventional localization algorithms that simply learn handcrafted features from raw fingerprint data. Second, mobile users are sensitive to the localization delay, but conventional indoor localization algorithms are computation-intensive and time-consuming. In this paper, we propose EdgeLoc, an edge-IoT framework for efficient and robust indoor localization using capsule networks. We develop a deep learning model with the CapsNet to efficiently extract hierarchical information from WiFi fingerprint data, thereby significantly improving the localization accuracy. Moreover, we implement an edge-computing prototype system to achieve a nearly real-time localization process, by enabling mobile users with the deep-learning model that has been well-trained by the edge server. We conduct a real-world field experimental study with over 33,600 data points and an extensive synthetic experiment with the open dataset, and the experimental results validate the effectiveness of EdgeLoc. The best trade-off of the EdgeLoc system achieves 98.5% localization accuracy within an average positioning time of only 2.31 ms in the field experiment.      
### 47.Grid-Forming Converters control based on DC voltage feedback  [ :arrow_down: ](https://arxiv.org/pdf/2009.05759.pdf)
>  The renewable energy is connected to the power grid through power electronic converters, which are lack of make the inertia of synchronous generator/machine (SM) be lost. The increasing penetration of renewable energy in power system weakens the frequency and voltage stability. The Grid-Forming Converters (GFCs) simulate the function of synchronous motor through control method in order to improve the stability of power grid by providing inertia and stability regulation mechanism. This kind of converter control methods include virtual synchronous machine, schedulable virtual oscillator control and so on. These control method mainly use AC side state feedback and do not monitor the DC side state. This paper analyzes the control strategy of GFC considering power grid stability, including Frequency Droop Control, Virtual Synchronous Machine Control and dispatchable Virtual Oscillator Control. The DC side voltage collapse problem is found when a large load disturbance occurs. The control methods of GFC considering DC side voltage feedback are proposed, which can ensure the synchronization characteristics of grid connection and solve the problem of DC side voltage collapse. The proposed method is verified by IEEE-9 bus system, which shows the effectiveness of the proposed method.      
### 48.Decentralized Model-free Loss Minimization in Distribution Grids with the Use of Inverters  [ :arrow_down: ](https://arxiv.org/pdf/2009.05753.pdf)
>  Nowadays, distribution grids are undergoing massive penetration of renewable energy sources (RESs), especially rooftop photovoltaic solar panels (PVs) and small wind turbines (WTs), which lead to a greater ratio of fluctuating generation. As a result, the inherited problems of distribution grids, such as poor voltage profile and high power losses, become even worse due to bidirectional flows. To operate a grid in the optimal mode, we propose a communication- and model-free algorithm that exploits the inverters' capabilities to control the reactive power output. While inverters are already installed in the system for connecting PVs, the inclusion of our algorithm in the inverters' software allows minimizing active power losses in the grid. We provide a mathematical proof that the proposed algorithm has better performance than approaches from the previous works. Finally, we demonstrate the performance of the algorithm on a 141-bus radial system with the random placing of the generating units and provide the analysis of the gradual increase of distributed generation and its influence on the choice of the optimization algorithm.      
### 49.Segmentation of Lungs in Chest X-Ray Image Using Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.05752.pdf)
>  Chest X-ray (CXR) is a low-cost medical imaging technique. It is a common procedure for the identification of many respiratory diseases compared to MRI, CT, and PET scans. This paper presents the use of generative adversarial networks (GAN) to perform the task of lung segmentation on a given CXR. GANs are popular to generate realistic data by learning the mapping from one domain to another. In our work, the generator of the GAN is trained to generate a segmented mask of a given input CXR. The discriminator distinguishes between a ground truth and the generated mask, and updates the generator through the adversarial loss measure. The objective is to generate masks for the input CXR, which are as realistic as possible compared to the ground truth masks. The model is trained and evaluated using four different discriminators referred to as D1, D2, D3, and D4, respectively. Experimental results on three different CXR datasets reveal that the proposed model is able to achieve a dice-score of 0.9740, and IOU score of 0.943, which are better than other reported state-of-the art results.      
### 50.Corrective feedback, emphatic speech synthesis, visual-speech exaggeration, pronunciation learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.05748.pdf)
>  To provide more discriminative feedback for the second language (L2) learners to better identify their mispronunciation, we propose a method for exaggerated visual-speech feedback in computer-assisted pronunciation training (CAPT). The speech exaggeration is realized by an emphatic speech generation neural network based on Tacotron, while the visual exaggeration is accomplished by ADC Viseme Blending, namely increasing Amplitude of movement, extending the phone's Duration and enhancing the color Contrast. User studies show that exaggerated feedback outperforms non-exaggerated version on helping learners with pronunciation identification and pronunciation improvement.      
### 51.Preamble-Based Packet Detection in Wi-Fi: A Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.05740.pdf)
>  Wi-Fi systems based on the family of IEEE 802.11 standards that operate in unlicenced bands are the most popular wireless interfaces that use Listen Before Talk (LBT) methodology for channel access. Distinctive feature of majority of LBT-based systems is that the transmitters use preambles that precede the data to allow the receivers to acquire initial signal detection and synchronization. The first digital processing step at the receiver applied over the incoming discrete-time complex-baseband samples after analog-to-digital conversion is the packet detection step, i.e., the detection of the initial samples of each of the frames arriving within the incoming stream. Since the preambles usually contain repetitions of training symbols with good correlation properties, conventional digital receivers apply correlation-based methods for packet detection. Following the recent interest in data-based deep learning (DL) methods for physical layer signal processing, in this paper, we challenge the conventional methods with DL-based approach for Wi-Fi packet detection. Using one-dimensional Convolutional Neural Networks (1D-CNN), we present a detailed complexity vs performance analysis and comparison between conventional and DL-based Wi-Fi packet detection approaches.      
### 52.Probabilistic Voltage Sensitivity Analysis (PVSA) to Quantify Impact of High PV Penetration on Unbalanced Distribution System  [ :arrow_down: ](https://arxiv.org/pdf/2009.05734.pdf)
>  From an operational and planning perspective, it is important to quantify the impact of increasing penetration of photovoltaics on the distribution system. Most existing impact assessment studies are scenario-based where derived results are scenario specific and not generalizable. Moreover, stochasticity in the temporal behavior of spatially distributed PVs requires a large number of scenarios that increase with the size of the network and the level of penetration. Therefore, we propose a new computationally efficient analytical framework of voltage sensitivity analysis that allows for stochastic analysis of voltage change due to random changes in PV generation. We first derive an analytical approximation for voltage change at any node of the network due to change in power at other nodes in an unbalanced distribution network. The quality of this approximation is reinforced via bounds on the approximation error. Then, we derive the probability distribution of voltage change at a certain node due to random changes in power injections/consumptions at multiple locations of the network. The accuracy of the proposed PVSA is illustrated using a modified version of the IEEE 37 bus test system. The proposed PVSA can serve as a powerful tool for proactive monitoring/control and ease the computational burden associated with perturbation based cybersecurity mechanisms.      
### 53.Feedback Control Methods for a Single Machine Infinite Bus System  [ :arrow_down: ](https://arxiv.org/pdf/2009.05689.pdf)
>  In this manuscript, we present a high-fidelity physics-based truth model of a Single Machine Infinite Bus (SMIB) system. We also present reduced-order control-oriented nonlinear and linear models of a synchronous generator-turbine system connected to a power grid. The reduced-order control-oriented models are next used to design various control strategies such as: proportional-integral derivative (PID), linear-quadratic regulator (LQR), pole placement-based state feedback, observer-based output feedback, loop transfer recovery (LTR)-based linear-quadratic-Gaussian (LQG), and nonlinear feedback-linearizing control for the SMIB system. The controllers developed are then validated on the high-fidelity physics-based truth model of the SMIB system. Finally, a comparison is made of the performance of the controllers at different operating points of the SMIB system.      
### 54.Affine Transformation-Based Deep Frame Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2009.05666.pdf)
>  We propose a neural network model to estimate the current frame from two reference frames, using affine transformation and adaptive spatially-varying filters. The estimated affine transformation allows for using shorter filters compared to existing approaches for deep frame prediction. The predicted frame is used as a reference for coding the current frame. Since the proposed model is available at both encoder and decoder, there is no need to code or transmit motion information for the predicted frame. By making use of dilated convolutions and reduced filter length, our model is significantly smaller, yet more accurate, than any of the neural networks in prior works on this topic. Two versions of the proposed model - one for uni-directional, and one for bi-directional prediction - are trained using a combination of Discrete Cosine Transform (DCT)-based l1-loss with various transform sizes, multi-scale Mean Squared Error (MSE) loss, and an object context reconstruction loss. The trained models are integrated with the HEVC video coding pipeline. The experiments show that the proposed models achieve about 7.3%, 5.4%, and 4.2% bit savings for the luminance component on average in the Low delay P, Low delay, and Random access configurations, respectively.      
### 55.Reinforcement Learning for Optimal Frequency Control: A Lyapunov Approach  [ :arrow_down: ](https://arxiv.org/pdf/2009.05654.pdf)
>  The increase in penetration of inverter-based resources provide us with more flexibility in frequency regulation of power systems in addition to conventional linear droop controllers. Because of the fast power electronic interfaces, inverter-based resources can be used to realize complex control functions and potentially offer large gains in performance compared to linear controllers. Reinforcement learning has emerged as popular method to find these nonlinear controllers by parameterizing them as neural networks. <br>The key challenge with learning based approach is that stability constraints are difficult to enforce on the learned controllers. In addition, optimizing the controllers are nontrivial because of the time-coupled dynamics of power systems. In this paper, we propose to explicitly engineer the structure of neural network based controllers such that they guarantee system stability for all topologies and parameters. This is done by using a Lyapunov function to guide their structures. A recurrent neural network based reinforcement learning architecture is used to efficiently train the weights of controllers. The resulting controllers only use local information and outperform linear droop as well as strategies learned purely by using reinforcement learning.      
### 56.Efficient Folded Attention for 3D Medical Image Reconstruction and Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2009.05576.pdf)
>  Recently, 3D medical image reconstruction (MIR) and segmentation (MIS) based on deep neural networks have been developed with promising results, and attention mechanism has been further designed to capture global contextual information for performance enhancement. However, the large size of 3D volume images poses a great computational challenge to traditional attention methods. In this paper, we propose a folded attention (FA) approach to improve the computational efficiency of traditional attention methods on 3D medical images. The main idea is that we apply tensor folding and unfolding operations with four permutations to build four small sub-affinity matrices to approximate the original affinity matrix. Through four consecutive sub-attention modules of FA, each element in the feature tensor can aggregate spatial-channel information from all other elements. Compared to traditional attention methods, with moderate improvement of accuracy, FA can substantially reduce the computational complexity and GPU memory consumption. We demonstrate the superiority of our method on two challenging tasks for 3D MIR and MIS, which are quantitative susceptibility mapping and multiple sclerosis lesion segmentation.      
### 57.SNR-enhanced diffusion MRI with structure-preserving low-rank denoising in reproducing kernel Hilbert spaces  [ :arrow_down: ](https://arxiv.org/pdf/2009.06600.pdf)
>  Purpose: To introduce, develop, and evaluate a novel denoising technique for diffusion MRI that leverages non-linear redundancy in the data to boost the SNR while preserving signal information. Methods: We exploit non-linear redundancy of the dMRI data by means of Kernel Principal Component Analysis (KPCA), a non-linear generalization of PCAto reproducing kernel Hilbert spaces. By mapping the signal to a high-dimensional space, better redundancy is achieved despite nonlinearities in the data thereby enabling better denoising than linear PCA. We implement KPCA with a Gaussian kernel, with parameters automatically selected from knowledge of the noise statistics, and validate it on realistic Monte-Carlo simulations as well as with in-vivo human brain submillimeter resolution dMRI data. We demonstrate KPCA denoising using multi-coil dMRI data also. Results: SNR improvements up to 2.7 X were obtained in real in-vivo datasets denoised with KPCA, in comparison to SNR gains of up to 1.8 X when using state-of-the-art PCA denoising, e.g., Marchenko- Pastur PCA (MPPCA). Compared to gold-standard dataset references created from averaged data, we showed that lower normalized root mean squared error (NRMSE) was achieved with KPCA compared to MPPCA. Statistical analysis of residuals shows that only noise is removed. Improvements in the estimation of diffusion model parameters such as fractional anisotropy, mean diffusivity, and fiber orientation distribution functions (fODFs)were demonstrated. Conclusion:Non-linear redundancy of the dMRI signal can be exploited with KPCA, which allows superior noise reduction/ SNR improvements than state-of-the-art PCA methods, without loss of signal information.      
### 58.A Task Allocation Approach for Human-Robot Collaboration in Product Defects Inspection Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2009.06423.pdf)
>  The presence and coexistence of human operators and collaborative robots in shop-floor environments raises the need for assigning tasks to either operators or robots, or both. Depending on task characteristics, operator capabilities and the involved robot functionalities, it is of the utmost importance to design strategies allowing for the concurrent and/or sequential allocation of tasks related to object manipulation and assembly. In this paper, we extend the \textsc{FlexHRC} framework presented in \cite{darvish2018flexible} to allow a human operator to interact with multiple, heterogeneous robots at the same time in order to jointly carry out a given task. The extended \textsc{FlexHRC} framework leverages a concurrent and sequential task representation framework to allocate tasks to either operators or robots as part of a dynamic collaboration process. In particular, we focus on a use case related to the inspection of product defects, which involves a human operator, a dual-arm Baxter manipulator from Rethink Robotics and a Kuka youBot mobile manipulator.      
### 59.Federated Generalized Bayesian Learning via Distributed Stein Variational Gradient Descent  [ :arrow_down: ](https://arxiv.org/pdf/2009.06419.pdf)
>  This paper introduces Distributed Stein Variational Gradient Descent (DSVGD), a non-parametric generalized Bayesian inference framework for federated learning that enables a flexible trade-off between per-iteration communication load and performance. DSVGD maintains a number of non-random and interacting particles at a central server that represent the current iterate of the model global posterior. The particles are iteratively downloaded and updated by one of the agents by minimizing the local free energy with the end goal of minimizing the global free energy. By using a sufficiently large number of particles, DSVGD is shown to outperform benchmark frequentist and Bayesian federated learning strategies, also scheduling a single device per iteration, in terms of accuracy, number of communication rounds, and scalability with respect to the number of agents, while also providing well-calibrated, and hence trustworthy, predictions.      
### 60.Far-field intensity signature of sub-wavelength microscopic objects  [ :arrow_down: ](https://arxiv.org/pdf/2009.06324.pdf)
>  Information about microscopic objects with features smaller than the diffraction limit is almost entirely lost in a far-field diffraction image but could be partly recovered with data completition techniques. Any such approach critically depends on the level of noise. This new path to superresolution has been recently investigated with the use of compressed sensing and machine learning. We demonstrate a two-stage technique based on deconvolution and genetic optimization which enables the recovery of objects with features of 1/10 of the wavelength. We indicate that l1-norm based optimization in the Fourier domain unrelated to sparsity is more robust to noise than its l2-based counterpart. We also introduce an extremely fast general-purpose restricted domain calculation method for Fourier transform based iterative algorithms operating on sparse data.      
### 61.Multi-Agent Reinforcement Learning in Cournot Games  [ :arrow_down: ](https://arxiv.org/pdf/2009.06224.pdf)
>  In this work, we study the interaction of strategic agents in continuous action Cournot games with limited information feedback. Cournot game is the essential market model for many socio-economic systems where agents learn and compete without the full knowledge of the system or each other. We consider the dynamics of the policy gradient algorithm, which is a widely adopted continuous control reinforcement learning algorithm, in concave Cournot games. We prove the convergence of policy gradient dynamics to the Nash equilibrium when the price function is linear or the number of agents is two. This is the first result (to the best of our knowledge) on the convergence property of learning algorithms with continuous action spaces that do not fall in the no-regret class.      
### 62.VC-Net: Deep Volume-Composition Networks for Segmentation and Visualization of Highly Sparse and Noisy Image Data  [ :arrow_down: ](https://arxiv.org/pdf/2009.06184.pdf)
>  The motivation of our work is to present a new visualization-guided computing paradigm to combine direct 3D volume processing and volume rendered clues for effective 3D exploration such as extracting and visualizing microstructures in-vivo. However, it is still challenging to extract and visualize high fidelity 3D vessel structure due to its high sparseness, noisiness, and complex topology variations. In this paper, we present an end-to-end deep learning method, VC-Net, for robust extraction of 3D microvasculature through embedding the image composition, generated by maximum intensity projection (MIP), into 3D volume image learning to enhance the performance. The core novelty is to automatically leverage the volume visualization technique (MIP) to enhance the 3D data exploration at deep learning level. The MIP embedding features can enhance the local vessel signal and are adaptive to the geometric variability and scalability of vessels, which is crucial in microvascular tracking. A multi-stream convolutional neural network is proposed to learn the 3D volume and 2D MIP features respectively and then explore their inter-dependencies in a joint volume-composition embedding space by unprojecting the MIP features into 3D volume embedding space. The proposed framework can better capture small / micro vessels and improve vessel connectivity. To our knowledge, this is the first deep learning framework to construct a joint convolutional embedding space, where the computed vessel probabilities from volume rendering based 2D projection and 3D volume can be explored and integrated synergistically. Experimental results are compared with the traditional 3D vessel segmentation methods and the deep learning state-of-the-art on public and real patient (micro-)cerebrovascular image datasets. Our method demonstrates the potential in a powerful MR arteriogram and venogram diagnosis of vascular diseases.      
### 63.Thing-to-Thing Optical Wireless Power Transfer Based on Metal Halide Perovskite Transceivers  [ :arrow_down: ](https://arxiv.org/pdf/2009.06163.pdf)
>  This paper proposes a novel conceptual system of optical wireless power transfer between objects, whether stationary or in-motion. Different from the currently existing optical wireless power transfer systems, where the optical transmitter and receiver are two distinct devices, the proposed system in this paper employs a single device - an optical transceiver, which is capable of working as both light absorption and emission. This optical transceiver is fabricated from a metal halide perovskite which yields superior features such as low costs, capability of flexibly attached on curved surfaces, thin and light weight. Therefore, the whole system size and cost can be significantly reduced, while perovskite transceivers can be made adaptive to any surface. This will contribute to realize a thing-to-thing optical wireless power transfer system, in which surfaces of objects/things are covered (fully or partially) by perovskite transceivers, enabling them to wirelessly charge or discharge from the others.      
### 64.Energy-Efficient Trajectory Design for UAV-Enabled Communication Under Malicious Jamming  [ :arrow_down: ](https://arxiv.org/pdf/2009.06161.pdf)
>  In this letter, we investigate a UAV-enabled communication system, where a UAV is deployed to communicate with the ground node (GN) in the presence of multiple jammers. We aim to maximize the energy efficiency (EE) of the UAV by optimizing its trajectory, subject to the UAV's mobility constraints. However, the formulated problem is difficult to solve due to the non-convex and fractional form of the objective function. Thus, we propose an iterative algorithm based on successive convex approximation (SCA) technique and Dinkelbach's algorithm to solve it. Numerical results show that the proposed algorithm can strike a better balance between the throughput and energy consumption by the optimized trajectory and thus improve the EE significantly as compared to the benchmark algorithms.      
### 65.Accelerating COVID-19 Differential Diagnosis with Explainable Ultrasound Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2009.06116.pdf)
>  Controlling the COVID-19 pandemic largely hinges upon the existence of fast, safe, and highly-available diagnostic tools. Ultrasound, in contrast to CT or X-Ray, has many practical advantages and can serve as a globally-applicable first-line examination technique. We provide the largest publicly available lung ultrasound (US) dataset for COVID-19 consisting of 106 videos from three classes (COVID-19, bacterial pneumonia, and healthy controls); curated and approved by medical experts. On this dataset, we perform an in-depth study of the value of deep learning methods for differential diagnosis of COVID-19. We propose a frame-based convolutional neural network that correctly classifies COVID-19 US videos with a sensitivity of 0.98+-0.04 and a specificity of 0.91+-08 (frame-based sensitivity 0.93+-0.05, specificity 0.87+-0.07). We further employ class activation maps for the spatio-temporal localization of pulmonary biomarkers, which we subsequently validate for human-in-the-loop scenarios in a blindfolded study with medical experts. Aiming for scalability and robustness, we perform ablation studies comparing mobile-friendly, frame- and video-based architectures and show reliability of the best model by aleatoric and epistemic uncertainty estimates. We hope to pave the road for a community effort toward an accessible, efficient and interpretable screening method and we have started to work on a clinical validation of the proposed method. Data and code are publicly available.      
### 66.Recent Advances in Wearable Sensors with Application in Rehabilitation Motion Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2009.06062.pdf)
>  The increase in world elderly population has significantly underlined the need for continuous health care measurement, specifically in rehabilitation monitoring. The new technologies has enabled people to have in home healthcare services, meanwhile, motion analysis methods are widely used for human activity monitoring as a remote healthcare service. Wearable sensors have indicated promising results both in convenience and technical performance. These sensors are extensively used in human motion analysis and advancement of wireless communications has intensively contributed to this field. Exploiting wireless technology and wearable sensors contributes to more effective help in emergency cases and has significantly decreased the hospitalization time. This paper reviews the most recent advances in wearable sensors used in motion analysis, specifically in the field of rehabilitation. Firstly, common wearable sensor technologies are introduced and then wearable sensors deploying Carbon Nano Tubes (CNT) are specifically reviewed. The next section is dedicated to sensor fusion in which possibility and performance of integration of new technologies are reviewed. This technique has been widely exploited to bring forth certainty in clinical results. Lastly, the challenges and future possibilities for advancement in motion analysis sensors is discussed.      
### 67.Multi-Objective Optimization for Sustainable Closed-Loop Supply Chain Network Under Demand Uncertainty: A Genetic Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2009.06047.pdf)
>  Supply chain management has been concentrated on productive ways to manage flows through a sophisticated vendor, manufacturer, and consumer networks for decades. Recently, energy and material rates have been greatly consumed to improve the sector, making sustainable development the core problem for advanced and developing countries. A new approach of supply chain management is proposed to maintain the economy along with the environment issue for the design of supply chain as well as the highest reliability in the planning horizon to fulfill customers demand as much as possible. This paper aims to optimize a new sustainable closed-loop supply chain network to maintain the financial along with the environmental factor to minimize the negative effect on the environment and maximize the average total number of products dispatched to customers to enhance reliability. The situation has been considered under demand uncertainty with warehouse reliability. This approach has been suggested the multi-objective mathematical model minimizing the total costs and total CO2 emissions and maximize the reliability in handling for establishing the closed-loop supply chain. Two optimization methods are used namely Multi-Objective Genetic Algorithm Optimization Method and Weighted Sum Method. Two results have shown the optimality of this approach. This paper also showed the optimal point using Pareto front for clear identification of optima. The results are approved to verify the efficiency of the model and the methods to maintain the financial, environmental, and reliability issues.      
### 68.Clinically Translatable Direct Patlak Reconstruction from Dynamic PET with Motion Correction Using Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2009.05901.pdf)
>  Patlak model is widely used in 18F-FDG dynamic positron emission tomography (PET) imaging, where the estimated parametric images reveal important biochemical and physiology information. Because of better noise modeling and more information extracted from raw sinogram, direct Patlak reconstruction gains its popularity over the indirect approach which utilizes reconstructed dynamic PET images alone. As the prerequisite of direct Patlak methods, raw data from dynamic PET are rarely stored in clinics and difficult to obtain. In addition, the direct reconstruction is time-consuming due to the bottleneck of multiple-frame reconstruction. All of these impede the clinical adoption of direct Patlak <a class="link-external link-http" href="http://reconstruction.In" rel="external noopener nofollow">this http URL</a> this work, we proposed a data-driven framework which maps the dynamic PET images to the high-quality motion-corrected direct Patlak images through a convolutional neural network. For the patient motion during the long period of dynamic PET scan, we combined the correction with the backward/forward projection in direct reconstruction to better fit the statistical model. Results based on fifteen clinical 18F-FDG dynamic brain PET datasets demonstrates the superiority of the proposed framework over Gaussian, nonlocal mean and BM4D denoising, regarding the image bias and contrast-to-noise ratio.      
### 69.An approach to human iris recognition using quantitative analysis of image features and machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2009.05880.pdf)
>  The Iris pattern is a unique biological feature for each individual, making it a valuable and powerful tool for human identification. In this paper, an efficient framework for iris recognition is proposed in four steps. (1) Iris segmentation (using a relative total variation combined with Coarse Iris Localization), (2) feature extraction (using Shape&amp;density, FFT, GLCM, GLDM, and Wavelet), (3) feature reduction (employing Kernel-PCA) and (4) classification (applying multi-layer neural network) to classify 2000 iris images of CASIA-Iris-Interval dataset obtained from 200 volunteers. The results confirm that the proposed scheme can provide a reliable prediction with an accuracy of up to 99.64%.      
### 70.A multirate variational approach to simulation and optimal control for flexible spacecraft  [ :arrow_down: ](https://arxiv.org/pdf/2009.05873.pdf)
>  We propose an optimal control method for simultaneous slewing and vibration control of flexible spacecraft. Considering dynamics on different time scales, the optimal control problem is discretized on micro and macro time grids using a multirate variational approach. The description of the system and the necessary optimality conditions are derived through the discrete Lagrange-d'Alembert principle. The discrete problem retains the conservation properties of the continuous model and achieves high fidelity simulation at a reduced computational cost. Simulation results for a single-axis rotational maneuver demonstrate vibration suppression and achieve the same accuracy as the single rate method at reduced computational cost.      
### 71.Guided Policy Search Based Control of a High Dimensional Advanced Manufacturing Process  [ :arrow_down: ](https://arxiv.org/pdf/2009.05838.pdf)
>  In this paper we apply guided policy search (GPS) based reinforcement learning framework for a high dimensional optimal control problem arising in an additive manufacturing process. The problem comprises of controlling the process parameters so that layer-wise deposition of material leads to desired geometric characteristics of the resulting part surface while minimizing the material deposited. A realistic simulation model of the deposition process along with carefully selected set of guiding distributions generated based on iterative Linear Quadratic Regulator is used to train a neural network policy using GPS. A closed loop control based on the trained policy and in-situ measurement of the deposition profile is tested experimentally, and shows promising performance.      
### 72.A general framework for decentralized optimization with first-order methods  [ :arrow_down: ](https://arxiv.org/pdf/2009.05837.pdf)
>  Decentralized optimization to minimize a finite sum of functions over a network of nodes has been a significant focus within control and signal processing research due to its natural relevance to optimal control and signal estimation problems. More recently, the emergence of sophisticated computing and large-scale data science needs have led to a resurgence of activity in this area. In this article, we discuss decentralized first-order gradient methods, which have found tremendous success in control, signal processing, and machine learning problems, where such methods, due to their simplicity, serve as the first method of choice for many complex inference and training tasks. In particular, we provide a general framework of decentralized first-order methods that is applicable to undirected and directed communication networks alike, and show that much of the existing work on optimization and consensus can be related explicitly to this framework. We further extend the discussion to decentralized stochastic first-order methods that rely on stochastic gradients at each node and describe how local variance reduction schemes, previously shown to have promise in the centralized settings, are able to improve the performance of decentralized methods when combined with what is known as gradient tracking. We motivate and demonstrate the effectiveness of the corresponding methods in the context of machine learning and signal processing problems that arise in decentralized environments.      
### 73.SeaShark: Towards a Modular Multi-Purpose Man-Portable AUV  [ :arrow_down: ](https://arxiv.org/pdf/2009.05762.pdf)
>  In this work, we present the SeaShark AUV: a modular, easily configurable, one-man portable micro-AUV. The SeaShark AUV is conceived as modular parts that fit around a central main tube, which holds battery and other vital parts. The head unit comprises easy exhangeable, stackable, and 360 degree rotatable payload sections to quickly obtain a suitable configuration for many objectives. We employ navigation no better than dead reckoning or relative navigation with respect to some well-known structure, and thus aim at underwater activities that do not require highly accurate geo-referenced data-points. Operating the SeaShark AUV requires only the vehicle itself and a tablet for mission planning and post-mission review. We have built several complete SeaShark systems and have begun exploring the many possibilities and use-cases in both research and commercial use. Here we present a comprehensive overview and introduction to our AUV and operation principles, and further show data examples for experimental operations for shore-to-sea bio-habitat mapping and in-harbor wall and pier inspection      
### 74.Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2009.05702.pdf)
>  This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The sampling-based model predictive control relies on mode insertion gradient optimization for this risk measure as well as Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot's desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.      
### 75.QRnet: optimal regulator design with LQR-augmented neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2009.05686.pdf)
>  In this paper we propose a new computational method for designing optimal regulators for high-dimensional nonlinear systems. The proposed approach leverages physics-informed machine learning to solve high-dimensional Hamilton-Jacobi-Bellman equations arising in optimal feedback control. Concretely, we augment linear quadratic regulators with neural networks to handle nonlinearities. We train the augmented models on data generated without discretizing the state space, enabling application to high-dimensional problems. We use the proposed method to design a candidate optimal regulator for an unstable Burgers' equation, and through this example, demonstrate improved robustness and accuracy compared to existing neural network formulations.      
### 76.HSolo: Homography from a single affine aware correspondence  [ :arrow_down: ](https://arxiv.org/pdf/2009.05004.pdf)
>  The performance of existing robust homography estimation algorithms is highly dependent on the inlier rate of feature point correspondences. In this paper, we present a novel procedure for homography estimation that is particularly well suited for inlier-poor domains. By utilizing the scale and rotation byproducts created by affine aware feature detectors such as SIFT and SURF, we obtain an initial homography estimate from a single correspondence pair. This estimate allows us to filter the correspondences to an inlier-rich subset for use with a robust estimator. Especially at low inlier rates, our novel algorithm provides dramatic performance improvements.      
### 77.Persuasion-based Robust Sensor Design Against Attackers with Unknown Control Objectives  [ :arrow_down: ](https://arxiv.org/pdf/1901.10618.pdf)
>  In this paper, we introduce a robust sensor design framework to provide "persuasion-based" defense in stochastic control systems against an unknown type attacker with a control objective exclusive to its type. For effective control, such an attacker's actions depend on its belief on the underlying state of the system. We design a robust "linear-plus-noise" signaling strategy to encode sensor outputs in order to shape the attacker's belief in a strategic way and correspondingly to persuade the attacker to take actions that lead to minimum damage with respect to the system's objective. The specific model we adopt is a Gauss-Markov process driven by a controller with a (partially) "unknown" malicious/benign control objective. We seek to defend against the worst possible distribution over control objectives in a robust way under the solution concept of Stackelberg equilibrium, where the sensor is the leader. We show that a necessary and sufficient condition on the covariance matrix of the posterior belief is a certain linear matrix inequality and we provide a closed-form solution for the associated signaling strategy. This enables us to formulate an equivalent tractable problem, indeed a semi-definite program, to compute the robust sensor design strategies "globally" even though the original optimization problem is non-convex and highly nonlinear. We also extend this result to scenarios where the sensor makes noisy or partial measurements. Finally, we analyze the ensuing performance numerically for various scenarios.      

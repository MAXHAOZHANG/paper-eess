# ArXiv eess --Tue, 3 Nov 2020
### 1.Focus on the present: a regularization method for the ASR source-target attention layer  [ :arrow_down: ](https://arxiv.org/pdf/2011.01210.pdf)
>  This paper introduces a novel method to diagnose the source-target attention in state-of-the-art end-to-end speech recognition models with joint connectionist temporal classification (CTC) and attention training. Our method is based on the fact that both, CTC and source-target attention, are acting on the same encoder representations. To understand the functionality of the attention, CTC is applied to compute the token posteriors given the attention outputs. We found that the source-target attention heads are able to predict several tokens ahead of the current one. Inspired by the observation, a new regularization method is proposed which leverages CTC to make source-target attention more focused on the frames corresponding to the output token being predicted by the decoder. Experiments reveal stable improvements up to 7\% and 13\% relatively with the proposed regularization on TED-LIUM 2 and LibriSpeech.      
### 2.A Deep Learning Study on Osteosarcoma Detection from Histological Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.01177.pdf)
>  In the U.S, 5-10\% of new pediatric cases of cancer are primary bone tumors. The most common type of primary malignant bone tumor is osteosarcoma. The intention of the present work is to improve the detection and diagnosis of osteosarcoma using computer-aided detection (CAD) and diagnosis (CADx). Such tools as convolutional neural networks (CNNs) can significantly decrease the surgeon's workload and make a better prognosis of patient conditions. CNNs need to be trained on a large amount of data in order to achieve a more trustworthy performance. In this study, transfer learning techniques, pre-trained CNNs, are adapted to a public dataset on osteosarcoma histological images to detect necrotic images from non-necrotic and healthy tissues. First, the dataset was preprocessed, and different classifications are applied. Then, Transfer learning models including VGG19 and Inception V3 are used and trained on Whole Slide Images (WSI) with no patches, to improve the accuracy of the outputs. Finally, the models are applied to different classification problems, including binary and multi-class classifiers. Experimental results show that the accuracy of the VGG19 has the highest, 96\%, performance amongst all binary classes and multiclass classification. Our fine-tuned model demonstrates state-of-the-art performance on detecting malignancy of Osteosarcoma based on histologic images.      
### 3.CAMP: a Two-Stage Approach to Modelling Prosody in Context  [ :arrow_down: ](https://arxiv.org/pdf/2011.01175.pdf)
>  Prosody is an integral part of communication, but remains an open problem in state-of-the-art speech synthesis. <br>There are two major issues faced when modelling prosody: (1) prosody varies at a slower rate compared with other content in the acoustic signal (e.g. segmental information and background noise); (2) determining appropriate prosody without sufficient context is an ill-posed problem. In this paper, we propose solutions to both these issues. <br>To mitigate the challenge of modelling a slow-varying signal, we learn to disentangle prosodic information using a word level representation. To alleviate the ill-posed nature of prosody modelling, we use syntactic and semantic information derived from text to learn a context-dependent prior over our prosodic space. Our Context-Aware Model of Prosody (CAMP) outperforms the state-of-the-art technique, closing the gap with natural speech by 26%. We also find that replacing attention with a jointly-trained duration model improves prosody significantly.      
### 4.Perceptually Guided End-to-End Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2011.01174.pdf)
>  Several fast text-to-speech (TTS) models have been proposed for real-time processing, but there is room for improvement in speech quality. Meanwhile, there is a mismatch between the loss function for training and the mean opinion score (MOS) for evaluation, which may limit the speech quality of TTS models. In this work, we propose a method that can improve the speech quality of a fast TTS model while maintaining the inference speed. To do so, we train a TTS model using a perceptual loss based on the predicted MOS. Under the supervision of a MOS prediction model, a TTS model can learn to increase the perceptual quality of speech directly. In experiments, we train FastSpeech on our internal Korean dataset using the MOS prediction model pre-trained on the Voice Conversion Challenge 2018 evaluation results. The MOS test results show that our proposed approach outperforms FastSpeech in speech quality.      
### 5.Exploiting Multiple Intelligent Reflecting Surfaces in Multi-Cell Uplink MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2011.01141.pdf)
>  Applications of intelligent reflecting surfaces (IRSs) in wireless networks have attracted significant attention recently. Most of the relevant literature is focused on the single cell setting where a single IRS is deployed, while static and perfect channel state information (CSI) is assumed. In this work, we develop a novel methodology for multi-IRS-assisted multi-cell networks in the uplink. We formulate the sum-rate maximization problem aiming to jointly optimize the IRS reflect beamformers, base station (BS) combiners, and user equipment (UE) transmit powers. In this optimization, we consider the scenario in which (i) channels are dynamic and (ii) only partial CSI is available at each BS; specifically, scalar effective channels of local UEs and some of the interfering UEs. In casting this as a sequential decision making problem, we propose a multi-agent deep reinforcement learning algorithm to solve it, where each BS acts as an independent agent in charge of tuning the local UEs transmit powers, the local IRS reflect beamformer, and its combiners. We introduce an efficient message passing scheme that requires limited information exchange among the neighboring BSs to cope with the non-stationarity caused by the coupling of actions taken by multiple BSs. Our numerical simulations show that our method obtains substantial improvement in average data rate compared to several baseline approaches, e.g., fixed UEs transmit power and maximum ratio combining.      
### 6.Frequency-based Automated Modulation Classification in the Presence of Adversaries  [ :arrow_down: ](https://arxiv.org/pdf/2011.01132.pdf)
>  Automatic modulation classification (AMC) aims to improve the efficiency of crowded radio spectrums by automatically predicting the modulation constellation of wireless RF signals. Recent work has demonstrated the ability of deep learning to achieve robust AMC performance using raw in-phase and quadrature (IQ) time samples. Yet, deep learning models are highly susceptible to adversarial interference, which cause intelligent prediction models to misclassify received samples with high confidence. Furthermore, adversarial interference is often transferable, allowing an adversary to attack multiple deep learning models with a single perturbation crafted for a particular classification network. In this work, we present a novel receiver architecture consisting of deep learning models capable of withstanding transferable adversarial interference. Specifically, we show that adversarial attacks crafted to fool models trained on time-domain features are not easily transferable to models trained using frequency-domain features. In this capacity, we demonstrate classification performance improvements greater than 30% on recurrent neural networks (RNNs) and greater than 50% on convolutional neural networks (CNNs). We further demonstrate our frequency feature-based classification models to achieve accuracies greater than 99% in the absence of attacks.      
### 7.Speaker anonymisation using the McAdams coefficient  [ :arrow_down: ](https://arxiv.org/pdf/2011.01130.pdf)
>  Anonymisation has the goal of manipulating speech signals in order to degrade the reliability of automatic approaches to speaker recognition, while preserving other aspects of speech, such as those relating to intelligibility and naturalness. This paper reports an approach to anonymisation that, unlike other current approaches, requires no training data, is based upon well-known signal processing techniques and is both efficient and effective. The proposed solution uses the McAdams coefficient to transform the spectral envelope of speech signals. Results derived using common VoicePrivacy 2020 databases and protocols show that random, optimised transformations can outperform competing solutions in terms of anonymisation while causing only modest, additional degradations to intelligibility, even in the case of a semi-informed privacy adversary.      
### 8.Reinforcement Learning of Structured Control for Linear Systems with Unknown State Matrix  [ :arrow_down: ](https://arxiv.org/pdf/2011.01128.pdf)
>  This paper delves into designing stabilizing feedback control gains for continuous linear systems with unknown state matrix, in which the control is subject to a general structural constraint. We bring forth the ideas from reinforcement learning (RL) in conjunction with sufficient stability and performance guarantees in order to design these structured gains using the trajectory measurements of states and controls. We first formulate a model-based framework using dynamic programming (DP) to embed the structural constraint to the Linear Quadratic Regulator (LQR) gain computation in the continuous-time setting. Subsequently, we transform this LQR formulation into a policy iteration RL algorithm that can alleviate the requirement of known state matrix in conjunction with maintaining the feedback gain structure. Theoretical guarantees are provided for stability and convergence of the structured RL (SRL) algorithm. The introduced RL framework is general and can be applied to any control structure. A special control structure enabled by this RL framework is distributed learning control which is necessary for many large-scale cyber-physical systems. As such, we validate our theoretical results with numerical simulations on a multi-agent networked linear time-invariant (LTI) dynamic system.      
### 9.U-Net and its variants for medical image segmentation: theory and applications  [ :arrow_down: ](https://arxiv.org/pdf/2011.01118.pdf)
>  U-net is an image segmentation technique developed primarily for medical image analysis that can precisely segment images using a scarce amount of training data. These traits provide U-net with a very high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in all major image modalities from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. As the potential of U-net is still increasing, in this review we look at the various developments that have been made in the U-net architecture and provide observations on recent trends. We examine the various innovations that have been made in deep learning and discuss how these tools facilitate U-net. Furthermore, we look at image modalities and application areas where U-net has been applied.      
### 10.End-to-end anti-spoofing with RawNet2  [ :arrow_down: ](https://arxiv.org/pdf/2011.01108.pdf)
>  Spoofing countermeasures aim to protect automatic speaker verification systems from attempts to manipulate their reliability with the use of spoofed speech signals. While results from the most recent ASVspoof 2019 evaluation show great potential to detect most forms of attack, some continue to evade detection. This paper reports the first application of RawNet2 to anti-spoofing. RawNet2 ingests raw audio and has potential to learn cues that are not detectable using more traditional countermeasure solutions. We describe modifications made to the original RawNet2 architecture so that it can be applied to anti-spoofing. For A17 attacks, our RawNet2 systems results are the second-best reported, while the fusion of RawNet2 and baseline countermeasures gives the second-best results reported for the full ASVspoof 2019 logical access condition. Our results are reproducible with open source software.      
### 11.Predicting the future state of disturbed LTI systems: A solution based on high-order observers  [ :arrow_down: ](https://arxiv.org/pdf/2011.01093.pdf)
>  Predicting the state of a system in a relatively near future time instant is often needed for control purposes. However, when the system is affected by external disturbances, its future state is dependent on the forthcoming disturbance; which is, in most of the cases, unknown and impossible to measure. In this scenario, making predictions of the future system-state is not straightforward and, indeed, there are scarce contributions provided to this issue. This paper treats the following problem: given a LTI system affected by continuously differentiable unknown disturbances, how its future state can be predicted in a sufficiently small time-horizon by high-order observers. Observer design methodologies in order to reduce the prediction errors are given. Comparisons with other solutions are also established.      
### 12.Application of Kalker Theory of Rolling Contact for Dynamic Simulation of Mobile Robots  [ :arrow_down: ](https://arxiv.org/pdf/2011.01066.pdf)
>  This paper presents a derivation of a dynamic simulation of a steerable-wheel mobile robot with wheel slip. The robot is controlled using pure pursuit algorithm. Kalker simplified and linear theory of rolling contact are utilized to describe friction-creepage relationship between the robot wheel and the ground. Two simulations were created based on the two friction models. Simulation results of the two models are presented and compared.      
### 13.Top 10 BraTS 2020 challenge solution: Brain tumor segmentation with self-ensembled, deeply-supervised 3D-Unet like neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.01045.pdf)
>  Brain tumor segmentation is a critical task for patient's disease management. To this end, we trained multiple U-net like neural networks, mainly with deep supervision and stochastic weight averaging, on the Multimodal Brain Tumor Segmentation Challenge (BraTS) 2020 training dataset, in a cross-validated fashion. Final brain tumor segmentations were produced by first averaging independently two sets of models, and then custom merging the labelmaps to account for individual performance of each set. Our performance on the online validation dataset with test time augmentation were as follows: Dice of 0.81, 0.91 and 0.85; Hausdorff (95%) of 20.6, 4,3, 5.7 mm for the enhancing tumor, whole tumor and tumor core, respectively. Similarly, our ensemble achieved a Dice of 0.79, 0.89 and 0.84, as well as Hausdorff (95%) of 20.4, 6.7 and 19.5mm on the final test dataset. More complicated training schemes and neural network architectures were investigated, without significant performance gain, at the cost of greatly increased training time. While relatively straightforward, our approach yielded good and balanced performance for each tumor subregions. Our solution is open sourced at <a class="link-external link-https" href="https://github.com/lescientifik/xxxxx" rel="external noopener nofollow">this https URL</a>.      
### 14.Transfer Function Analysis and Implementation of Active Disturbance Rejection Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.01044.pdf)
>  To support the adoption of active disturbance rejection control (ADRC) in industrial practice, this article aims at improving both understanding and implementation of ADRC using traditional means, in particular via transfer functions and a frequency-domain view. Firstly, to enable an immediate comparability with existing classical control solutions, a realizable transfer function implementation of continous-time linear ADRC is introduced. Secondly, a frequency-domain analysis of ADRC components, performance, parameter sensitivity, and tuning method is performed. Finally, an exact implementation of discrete-time ADRC using transfer functions is introduced for the first time, with special emphasis on practical aspects such as computational efficiency, low parameter footprint, and windup protection.      
### 15.Decentralized Algorithms for Consensus-Based Power Packet Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2011.01031.pdf)
>  Power packets are proposed as a transmission unit that can deliver power and information simultaneously. They are transferred using the store-and-forward method of power routers. A system that achieves power supply/demand in this manner is called a power packet network (PPN). A PPN is expected to enhance structural robustness and operational reliability in an energy storage system (ESS) with recent diverse distributed sources. However, this technology is still in its early stage, and faces numerous challenges, such as high cost of implementation and complicated energy management. In this paper, we propose a novel power control based on decentralized algorithms for a PPN. Specifically, the power supply is triggered and managed by communications between power routers. We also discuss the mechanism of the decentralized algorithm for the operation of power packets and reveal the feasibility of the given control method and application by forming biased power flows on the consensus-based distribution.      
### 16.ASIST: Annotation-free synthetic instance segmentation and tracking for microscope video analysis  [ :arrow_down: ](https://arxiv.org/pdf/2011.01009.pdf)
>  Instance object segmentation and tracking provide comprehensive quantification of objects across microscope videos. The recent single-stage pixel-embedding based deep learning approach has shown its superior performance compared with "segment-then-associate" two-stage solutions. However, one major limitation of applying a supervised pixel-embedding based method to microscope videos is the resource-intensive manual labeling, which involves tracing hundreds of overlapped objects with their temporal associations across video frames. Inspired by the recent generative adversarial network (GAN) based annotation-free image segmentation, we propose a novel annotation-free synthetic instance segmentation and tracking (ASIST) algorithm for analyzing microscope videos of sub-cellular microvilli. The contributions of this paper are three-fold: (1) proposing a new annotation-free video analysis paradigm is proposed. (2) aggregating the embedding based instance segmentation and tracking with annotation-free synthetic learning as a holistic framework; and (3) to the best of our knowledge, this is first study to investigate microvilli instance segmentation and tracking using embedding based deep learning. From the experimental results, the proposed annotation-free method achieved superior performance compared with supervised learning.      
### 17.Distributed speech separation in spatially unconstrained microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2011.00982.pdf)
>  Speech separation with several speakers is a challenging task because of the non-stationarity of the speech and the strong signal similarity between interferent sources. Current state-of-the-art solutions can separate well the different sources using sophisticated deep neural networks which are very tedious to train. When several microphones are available, spatial information can be exploited to design much simpler algorithms to discriminate speakers. We propose a distributed algorithm that can process spatial information in a spatially unconstrained microphone array. The algorithm relies on a convolutional recurrent neural network that can exploit the signal diversity from the distributed nodes. In a typical case of a meeting room, this algorithm can capture an estimate of each source in a first step and propagate it over the microphone array in order to increase the separation performance in a second step. We show that this approach performs even better when the number of sources and nodes increases. We also study the influence of a mismatch in the number of sources between the training and testing conditions.      
### 18.Deep Learning in Computer-Aided Diagnosis and Treatment of Tumors: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2011.00940.pdf)
>  Computer-Aided Diagnosis and Treatment of Tumors is a hot topic of deep learning in recent years, which constitutes a series of medical tasks, such as detection of tumor markers, the outline of tumor leisures, subtypes and stages of tumors, prediction of therapeutic effect, and drug development. Meanwhile, there are some deep learning models with precise positioning and excellent performance produced in mainstream task scenarios. Thus follow to introduce deep learning methods from task-orient, mainly focus on the improvements for medical tasks. Then to summarize the recent progress in four stages of tumor diagnosis and treatment, which named In-Vitro Diagnosis (IVD), Imaging Diagnosis (ID), Pathological Diagnosis (PD), and Treatment Planning (TP). According to the specific data types and medical tasks of each stage, we present the applications of deep learning in the Computer-Aided Diagnosis and Treatment of Tumors and analyzing the excellent works therein. This survey concludes by discussing research issues and suggesting challenges for future improvement.      
### 19.FeatherTTS: Robust and Efficient attention based Neural TTS  [ :arrow_down: ](https://arxiv.org/pdf/2011.00935.pdf)
>  Attention based neural TTS is elegant speech synthesis pipeline and has shown a powerful ability to generate natural speech. However, it is still not robust enough to meet the stability requirements for industrial products. Besides, it suffers from slow inference speed owning to the autoregressive generation process. In this work, we propose FeatherTTS, a robust and efficient attention-based neural TTS system. Firstly, we propose a novel Gaussian attention which utilizes interpretability of Gaussian attention and the strict monotonic property in TTS. By this method, we replace the commonly used stop token prediction architecture with attentive stop prediction. Secondly, we apply block sparsity on the autoregressive decoder to speed up speech synthesis. The experimental results show that our proposed FeatherTTS not only nearly eliminates the problem of word skipping, repeating in particularly hard texts and keep the naturalness of generated speech, but also speeds up acoustic feature generation by 3.5 times over Tacotron. Overall, the proposed FeatherTTS can be $35$x faster than real-time on a single CPU.      
### 20.Maximum Likelihood Estimation in Data-Driven Modeling and Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.00925.pdf)
>  Recently, various algorithms for data-driven simulation and control have been proposed based on the Willems' fundamental lemma. However, when collected data are noisy, these methods lead to ill-conditioned data-driven model structures. In this work, we present a maximum likelihood framework to obtain an optimal data-driven model, the signal matrix model, in the presence of output noise. A data compression scheme is also proposed to enable more efficient use of large datasets. Two approaches in system identification and receding horizon control are developed based on the derived optimal estimator. The first one identifies a finite impulse response model in combination with the kernel-based method. This approach improves the least-squares-based estimator with less restrictive assumptions. The second one applies the signal matrix model as the predictor in predictive control. The control performance is shown to be better than existing data-driven predictive control algorithms, especially under high noise levels. Both approaches demonstrate that the derived estimator provides a promising framework to apply data-driven algorithms to noisy data.      
### 21.Channel Estimation in Reconfigurable Intelligent Surface Assisted mmWave MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.00900.pdf)
>  Reconfigurable intelligent surfaces (RISs) can be used to establish a communication link when there is no or weak line-of-sight (LoS) path between a base station (BS) and user equipment (UE) in millimeter-wave MIMO systems. RIS comprises of many passive phase shifters, which can be controlled from the BS to focus a signal to a desired location and modify the propagation environment. Due to the passive-only elements, pilots cannot be decoded at the RIS. Thus channel estimation in RIS-assisted MIMO communication systems is challenging. Although the LoS channel between the BS and RIS can be obtained from the knowledge of their locations, the RIS-UE channel needs to be estimated. Estimating the RIS-UE channel at the BS amounts to localizing the UE. In this paper, we present a pilot-based uplink channel estimation technique to estimate the LoS channel between the RIS and UE at the BS. To do so, we assume an angular channel model. Central to the proposed algorithm is a new technique in which we observe the channel through multiple soundings with different phase shifts at the RIS. These multiple measurements allow us to resolve the underlying ambiguity in resolving the complex path gain and the angle of arrival at the RIS and to estimate the RIS-UE channel. Simulation results indicate that the performance of the proposed method is comparable to that of an oracle estimator, which assumes a partial channel state information with perfect knowledge of the locations of the BS, UE, and RIS.      
### 22.Mobile Human Ad Hoc Networks: A Communication Engineering Viewpoint on Interhuman Airborne Pathogen Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2011.00884.pdf)
>  Pathogens such as viruses and bacteria play a vital role in human life, since they cause infectious diseases which can lead to epidemics. Recent coronavirus disease 2019 epidemic has shown that taking effective prevention measures such as wearing masks are important to reduce the human deaths and side effects of the epidemic. It is therefore requisite to accurately model the spread of infectious diseases whose one of the most crucial routes of transmission is airborne transmission. The transmission models in the literature are proposed independently from each other, at different scales and by the researchers from various disciplines. Thus, there is a need to merge all these research attempts. To this end, we propose a communication engineering approach that melts different disciplines such as epidemiology, biology, medicine, and fluid dynamics in the same pot to model airborne pathogen transmission among humans. In this approach, we introduce the concept of mobile human ad hoc networks (MoHANETs). This concept exploits the similarity of airborne transmission-driven human groups with mobile ad hoc networks and uses molecular communication as the enabling paradigm. The aim of this article is to present a unified framework using communication engineering, and to highlight future research directions for modeling the spread of infectious diseases among humans through airborne pathogen transmission. In this article, we first review the airborne pathogen transmission mechanisms. Then, the MoHANET is given with a layered structure. In these layers, the infectious human emitting pathogen-laden droplets through air and the exposed human to these droplets are considered as the transmitter and receiver, respectively. Moreover, the experimental methods for the proposed approach are reviewed and discussed.      
### 23.Output Series-Parallel Connection of Passivity-Based Controlled DC-DC Converters: Theoretical Generalization of Stability  [ :arrow_down: ](https://arxiv.org/pdf/2011.00861.pdf)
>  The series-paralleling technique of dc-dc converters is utilized in various domains of electrical engineering for improved power conversion. Previous studies have proposed and classified the control schemes for the series-paralleled converters. However, they have several restrictions and a lack of diversity. The purpose of this paper is to propose passivity-based control (PBC) for the diverse series-parallel connection of dc-dc converters. First, PBC for the dc-dc converters is generally explained. Then, it is theoretically shown that the output series-paralleled converters regulated by PBC are asymptotically stable. The series-paralleled converters are numerically simulated to confirm asymptotic stability. In the simulation, PBC maintained the stability of the series-paralleled converters with diverse circuit topologies, parameters, and steady-states, due to its robust feature. The result of this paper will contribute to allowing various dc-dc converters to have a wide variety of output connections.      
### 24.nnU-Net for Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2011.00848.pdf)
>  We apply nnU-Net to the segmentation task of the BraTS 2020 challenge. The unmodified nnU-Net baseline configuration already achieves a respectable result. By incorporating BraTS-specific modifications regarding postprocessing, region-based training, a more aggressive data augmentation as well as several minor modifications to the nnUNet pipeline we are able to improve its segmentation performance substantially. We furthermore re-implement the BraTS ranking scheme to determine which of our nnU-Net variants best fits the requirements imposed by it. Our final ensemble took the first place in the BraTS 2020 competition with Dice scores of 88.95, 85.06 and 82.03 and HD95 values of 8.498,17.337 and 17.805 for whole tumor, tumor core and enhancing tumor, respectively.      
### 25.Estimating State of Charge for xEV batteries using 1D Convolutional Neural Networks and Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.00841.pdf)
>  A state of charge estimator is an essential component of battery management systems used in Electric Vehicles. In the recent years deep learning algorithms have fared well as accurate and reliable state of charge estimators, owing to their high accuracy of estimation under noisy conditions and the relative ease with which they can process large amount of data. However, deep learning algorithms are extremely task specific and need to be retrained when the battery data distribution changes. This paper proposes a novel state of charge estimation algorithm consisting of one dimensional convolutional neural networks and also introduces a transfer learning framework for improving generalization across different battery data distributions. The proposed method fares well in terms of estimation accuracy, learning speed and generalization capability.      
### 26.Millimeter-Wave Antenna Array Diagnosis with Partial Channel State Information  [ :arrow_down: ](https://arxiv.org/pdf/2011.00828.pdf)
>  Large antenna arrays enable directional precoding for Millimeter-Wave (mmWave) systems and provide sufficient link budget to combat the high path-loss at these frequencies. Due to atmospheric conditions and hardware malfunction, outdoor mmWave antenna arrays are prone to blockages or complete failures. This results in a modified array geometry, distorted far-field radiation pattern, and system performance degradation. Recent remote array diagnostic techniques have emerged as an effective way to detect defective antenna elements in an array with few diagnostic measurements. These techniques, however, require full and perfect channel state information (CSI), which can be challenging to acquire in the presence of antenna faults. This paper proposes a new remote array diagnosis technique that relaxes the need for full CSI and only requires knowledge of the incident angle-of-arrivals, i.e. partial channel knowledge. Numerical results demonstrate the effectiveness of the proposed technique and show that fault detection can be obtained with comparable number of diagnostic measurements required by diagnostic techniques based on full channel knowledge. In presence of channel estimation errors, the proposed technique is shown to out-perform recently proposed array diagnostic techniques.      
### 27.Near-on-Demand Mobility. The Benefits of User Flexibility for Ride-Pooling Services  [ :arrow_down: ](https://arxiv.org/pdf/2011.00823.pdf)
>  Mobility-On-Demand (MoD) services have been transforming the urban mobility ecosystem. However, they raise a lot of concerns for their impact on congestion, Vehicle Miles Travelled (VMT), and competition with transit. There are also questions about their long-term survival because of inherent inefficiencies in their operations. Considering the popularity of the MoD services, increasing ride-pooling is an important means to address these concerns. Shareability depends not only on riders attitudes and preferences but also on operating models deployed by providers. The paper introduces an advance requests operating model for ride pooling where users may request rides at least H minutes in advance of their desired departure times. A platform with efficient algorithms for request matching, vehicle routing, rebalancing, and flexible user preferences is developed. A large-scale transportation network company dataset is used to evaluate the performance of the advance requests system relative to current practices. The impacts of various design aspects of the system (advance requests horizon, vehicle capacity) on its performance are investigated. The sensitivity of the results to user preferences in terms of the level of service (time to be served and excess trip time), willingness to share and place requests in advance, and traffic conditions are explored. The results suggest that significant benefits in terms of sustainability, level of service, and fleet utilization can be realized when advance requests are along with an increased willingness to share. Furthermore, even near-on-demand (relative short advance planning horizons) operations can offer many benefits for all stakeholders involved (passengers, operators, and cities).      
### 28.Incorporating Gas Pipeline Leakage Failure Modes in Risk Evaluation of Electricity-Gas Integrated Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.00776.pdf)
>  In the existing literatures for the risk evaluation of electricity-gas integrated energy system (EGIES), the impacts of gas leakage in pipelines are ignored. This paper presents a method to incorporate the failure modes of gas pipeline leakage in EGIES risk evaluation. A Markov state transition model of gas pipeline with multi-state and multi-mode transition process, and a bi-level Monte Carlo sampling method for this model are developed. A stochastic topology change based network model of EGIES considering the pipeline leakage failure modes is presented. The risk indices for EGIES based on the load shedding, including those specifically for gas leakage risks, are also proposed. An EGIES with a modified RBTS and a 7-node gas system was used to demonstrate an application of the proposed method and models. The results indicate that pipeline leakage failures have significant impacts on the risk of EGIES. Ignoring pipeline leakage failures in the risk evaluation of EGIES will result in an overly underestimation of system risk and most likely a misleading conclusion in system planning.      
### 29.Intelligent Omni-Surface: Ubiquitous Wireless Transmission by Reflective-Transmissive Metasurface  [ :arrow_down: ](https://arxiv.org/pdf/2011.00765.pdf)
>  Intelligent reflecting surface (IRS), which is capable to adjust propagation conditions by controlling phase shifts of the reflected waves that impinge on the surface, has been widely analyzed for enhancing the performance of wireless systems. However, the reflective properties of widely studied IRSs restrict the service coverage to only one side of the surface. In this paper, to extend the wireless coverage of communication systems, we introduce the concept of intelligent omni-surface (IOS)-assisted communication. More precisely, IOS is an important instance of reconfigurable intelligent surface (RIS) that is capable to provide service coverage to the mobile users (MUs) in a reflective and a transmissive manner. We consider a downlink IOS-assisted communication system, where a multi-antenna small base station (SBS) and an IOS perform beamforming jointly, to improve the received power of multiple MUs on both sides of the IOS, through different reflective/transmissive channels. To maximize the sum-rate, we formulate a joint IOS phase shift design and SBS beamforming optimization problem, and propose an iterative algorithm to solve the resulting non-convex program efficiently. Both theoretical analysis and simulation results show that an IOS significantly extends the service coverage of the SBS when compared to an IRS.      
### 30.Clinical Evaluation of Real-Time Optical-Tracking Navigation and Live Time-Intensity Curves to Provide Feedback During Blinded 4D Contrast-Enhanced Ultrasound Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2011.00744.pdf)
>  Current commercial matrix transducers for 3D DCE-US do not display side-by-side B-mode and contrast-mode images when capturing volumetric data, thus leaving the operator with no position feedback during lengthy acquisitions. The purpose of this study was to investigate the use of transducer tracking to provide positioning feedback and to re-align images to improve quantification. An interventional tracking system was developed in house using an infrared camera and a 3D-printed tracking target attached to a X6-1 matrix transducer. The system displays a virtual probe on a separate screen and allows to capture a reference position to provide operator feedback when no B-mode image is available. To test this set-up, five experienced operators were asked to locate an image landmark within a volunteer liver in B-mode images using the X6-1 connected to an EPIQ7 system. Operators were then asked to maintain the transducer position for 4 minutes under three feedback methods: i) B-mode, ii) display of real-time virtual transducer, iii) blind. The magnitude of displacement over the cine was computed as an estimate of the imaging position error. We also investigated whether transducer coordinates can be used to re-align images due to motion and improve contrast ultrasound perfusion repeatability. A total of 8 patient data were obtained under an IRB for this. Results suggest that tracking can assist operators maintain a steady position during a lengthy acquisition. With blinded acquisition, an average displacement of 4.58 mm (S.D. 2.65 mm) was noted. In contrast, the average displacement for tracking-feedback was comparable to B-mode at 3.48 mm (S.D. 0.8 mm). We also observed that perfusion parameters had better repeatability after re-alignment.      
### 31.A $0.11-0.38$ pJ/cycle Differential Ring Oscillator in $65$ nm CMOS for Robust Neurocomputing  [ :arrow_down: ](https://arxiv.org/pdf/2011.00743.pdf)
>  This paper presents a low-area and low-power consumption CMOS differential current controlled oscillator (CCO) for neuromorphic applications. The oscillation frequency is improved over the conventional one by reducing the number of MOS transistors thus lowering the load capacitor in each stage. The analysis shows that for the same power consumption, the oscillation frequency can be increased about $11\%$ compared with the conventional one without degrading the phase noise. Alternatively, the power consumption can be reduced $15\%$ at the same frequency. The prototype structures are fabricated in a standard $65$ nm CMOS technology and measurements demonstrate that the proposed CCO operates from $0.7-1.2$ V supply with maximum frequencies of $80$ MHz and energy/cycle ranging from $0.11-0.38$ pJ over the tuning range. Further, system level simulations show that the nonlinearity in current-frequency conversion by the CCO does not affect its use as a neuron in a Deep Neural Network if accounted for during training.      
### 32.Power Allocation for Fingerprint-Based PHY-Layer Authentication with mmWave UAV Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00742.pdf)
>  Physical layer security (PLS) techniques can help to protect wireless networks from eavesdropper attacks. In this paper, we consider the authentication technique that uses fingerprint embedding to defend 5G cellular networks with unmanned aerial vehicle (UAV) systems from eavesdroppers and intruders. Since the millimeter wave (mmWave) cellular networks use narrow and directional beams, PLS can take further advantage of the 3D spatial dimension for improving the authentication of UAV users. Considering a multi-user mmWave cellular network, we propose a power allocation technique that jointly takes into account splitting of the transmit power between the precoder and the authentication tag, which manages both the secrecy as well as the achievable rate. Our results show that we can obtain optimal achievable rate with expected secrecy.      
### 33.Distributed Precoding Using Local CSIT for MU-MIMO Heterogeneous Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00727.pdf)
>  Cell densification is a key driver to increase area spectral efficiencies in multi-antenna cellular systems. As increasing the densities of base stations (BSs) and users that share the same spectrum, however, both inter-user-interference (IUI) and inter-cell interference (ICI) problems give rise to a significant loss in spectral efficiencies in such systems. To resolve this problem under the constraint of local channel state information per BS, in this paper, we present a novel noncooperative multi-user multiple-input multiple-output (MIMO) precoding technique, called signal-to-interference-pulse-leakage-pulse-noise-ratio (SILNR) maximization precoding. The key innovation of our distributed precoding method is to maximize the product of SILNRs of users per cell using local channel state information at the transmitter (CSIT). We show that our precoding technique only using local CSIT can asymptotically achieve the multi-cell cooperative bound attained by cooperative precoding using global CSIT in some cases. We also present a precoding algorithm that is robust to CSIT errors in multi-cell scenarios. By multi-cell system-level simulations, we demonstrate that our distributed precoding technique outperforms all existing noncooperative precoding methods considerably and can also achieve the multi-cell bound very tightly even with not-so-many antennas at BSs.      
### 34.Robust Raw Waveform Speech Recognition Using Relevance Weighted Representations  [ :arrow_down: ](https://arxiv.org/pdf/2011.00721.pdf)
>  Speech recognition in noisy and channel distorted scenarios is often challenging as the current acoustic modeling schemes are not adaptive to the changes in the signal distribution in the presence of noise. In this work, we develop a novel acoustic modeling framework for noise robust speech recognition based on relevance weighting mechanism. The relevance weighting is achieved using a sub-network approach that performs feature selection. A relevance sub-network is applied on the output of first layer of a convolutional network model operating on raw speech signals while a second relevance sub-network is applied on the second convolutional layer output. The relevance weights for the first layer correspond to an acoustic filterbank selection while the relevance weights in the second layer perform modulation filter selection. The model is trained for a speech recognition task on noisy and reverberant speech. The speech recognition experiments on multiple datasets (Aurora-4, CHiME-3, VOiCES) reveal that the incorporation of relevance weighting in the neural network architecture improves the speech recognition word error rates significantly (average relative improvements of 10% over the baseline systems)      
### 35.Multistep Frequency Response Optimized Integrators and Their Application to Accelerating a Power System Transient Simulation Scheme  [ :arrow_down: ](https://arxiv.org/pdf/2011.00711.pdf)
>  This paper proposes several explicit and implicit multistep frequency response optimized integrators considering first or second order derivative. A prediction-based method aiming at accelerating a novel power system transient simulation scheme without impacting its accuracy is further put forward utilizing the proposed numerical integrators and some others available in the literature. Case studies verify the effectiveness of the proposed prediction method. Although they are utilized to accelerate the simulation scheme in this paper, the proposed numerical integrators are in fact general-purpose and can be applied to other areas.      
### 36.Transformer-based Arabic Dialect Identification  [ :arrow_down: ](https://arxiv.org/pdf/2011.00699.pdf)
>  This paper presents a dialect identification (DID) system based on the transformer neural network architecture. The conventional convolutional neural network (CNN)-based systems use the shorter receptive fields. We believe that long range information is equally important for language and DID, and self-attention mechanism in transformer captures the long range dependencies. In addition, to reduce the computational complexity, self-attention with downsampling is used to process the acoustic features. This process extracts sparse, yet informative features. Our experimental results show that transformer outperforms CNN-based networks on the Arabic dialect identification (ADI) dataset. We also report that the score-level fusion of CNN and transformer-based systems obtains an overall accuracy of 86.29% on the ADI17 database.      
### 37.Extracting resilience metrics from distribution utility data using outage and restore process statistics  [ :arrow_down: ](https://arxiv.org/pdf/2011.00693.pdf)
>  Resilience curves track the accumulation and restoration of outages during an event on an electric distribution grid. We show that a resilience curve generated from utility data can always be decomposed into an outage process and a restore process and that these processes generally overlap in time. We use many events in real utility data to characterize the statistics of these processes, and derive formulas based on these statistics for resilience metrics such as restore duration, customer hours not served, and outage and restore rates. Estimating the variability of restore duration allows us to predict a maximum restore duration with 95% confidence.      
### 38.Data-Driven Assisted Chance-Constrained Energy and Reserve Scheduling with Wind Curtailment  [ :arrow_down: ](https://arxiv.org/pdf/2011.00689.pdf)
>  Chance-constrained optimization (CCO) has been widely used for uncertainty management in power system operation. With the prevalence of wind energy, it becomes possible to consider the wind curtailment as a dispatch variable in CCO. However, the wind curtailment will cause impulse for the uncertainty distribution, yielding challenges for the chance constraints modeling. To deal with that, a data-driven framework is developed. By modeling the wind curtailment as a cap enforced on the wind power output, the proposed framework constructs a Gaussian process (GP) surrogate to describe the relationship between wind curtailment and the chance constraints. This allows us to reformulate the CCO with wind curtailment as a mixed-integer second-order cone programming (MI-SOCP) problem. An error correction strategy is developed by solving a convex linear programming (LP) to improve the modeling accuracy. Case studies performed on the PJM 5-bus and IEEE 118-bus systems demonstrate that the proposed method is capable of accurately accounting the influence of wind curtailment dispatch in CCO.      
### 39.A Wearable CMOS Biosensor with 3 Designs of Energy-Resolution Scalable Time-Based Resistance to Digital Converter  [ :arrow_down: ](https://arxiv.org/pdf/2011.00649.pdf)
>  This paper presents the design and analysis of a wearable CMOS biosensor with three different designs of energy-resolution scalable time-based resistance to digital converters (RDC), targeted towards either minimizing the energy/conversion step or maximizing bit-resolution. The implemented RDCs consist of a 3-stage differential ring oscillator which is current starved with the resistive sensor, a differential to single ended amplifier, an off-chip counter and serial interface. The first design RDC included the basic structure of time-based RDC and targeted low energy/conversion step. The second design RDC aimed to improve the rms jitter/phase noise of the oscillator with help of speed-up latches, to achieve higher bit-resolution as compared to the first design RDC. The third design RDC reduced the power consumption by scaling the technology with the improved phase-noise design, achieving 1-bit better resolution as that of the second design RDC. Using a time-based implementation, the RDCs exhibit energy-resolution scalablity, and consume 861nW with 18-bit resolution in design 1 in TSMC 0.35um technology. Design 2 and 3 consume 19.1uW with 20-bit resolution using TSMC 0.35um, and 17.6uW with 20-bit resolutions using TSMC 0.18um, respectively (both with 10ms read-time, repeated every second). With 30ms read-time, design 3 achieves 21-bit resolution, which is the highest resolution reported for a time-based ADC. The 0.35um time-based RDC is the lowest-power time-based ADC reported, while the 0.18um time-based RDC with speed-up latch offers the highest resolution. The active chip-area for all 3-designs are less than 1.1 mm^2.      
### 40.3D Near-Field Millimeter-Wave Synthetic Aperture Radar Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2011.00636.pdf)
>  In this paper, we present 3D high resolution radar imaging process at millimeter-Wave (mmWave) frequencies by creating the effect of a large aperture synthetically. We use a low cost fully integrated Frequency Modulated Continuous Wave (FMCW) radar operating at $\rm 79\;GHz$ and then perform Synthetic Aperture Radar (SAR) imaging in the near-filed zone. At the end, we conduct a real experiment and present the reconstructed image.      
### 41.Synthesis of Discounted-Reward Optimal Policies for Markov Decision Processes Under Linear Temporal Logic Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2011.00632.pdf)
>  We present a method to find an optimal policy with respect to a reward function for a discounted Markov Decision Process under general linear temporal logic (LTL) specifications. Previous work has either focused on maximizing a cumulative reward objective under finite-duration tasks, specified by syntactically co-safe LTL, or maximizing an average reward for persistent (e.g., surveillance) tasks. This paper extends and generalizes these results by introducing a pair of occupancy measures to express the LTL satisfaction objective and the expected discounted reward objective, respectively. These occupancy measures are then connected to a single policy via a novel reduction resulting in a mixed integer linear program whose solution provides an optimal policy. Our formulation can also be extended to include additional constraints with respect to secondary reward functions. We illustrate the effectiveness of our approach in the context of robotic motion planning for complex missions under uncertainty and performance objectives.      
### 42.Bifurcated Autoencoder for Segmentation of COVID-19 Infected Regions in CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.00631.pdf)
>  The new coronavirus infection has shocked the world since early 2020 with its aggressive outbreak. Rapid detection of the disease saves lives, and relying on medical imaging (Computed Tomography and X-ray) to detect infected lungs has shown to be effective. Deep learning and convolutional neural networks have been used for image analysis in this context. However, accurate identification of infected regions has proven challenging for two main reasons. Firstly, the characteristics of infected areas differ in different images. Secondly, insufficient training data makes it challenging to train various machine learning algorithms, including deep-learning models. This paper proposes an approach to segment lung regions infected by COVID-19 to help cardiologists diagnose the disease more accurately, faster, and more manageable. We propose a bifurcated 2-D model for two types of segmentation. This model uses a shared encoder and a bifurcated connection to two separate decoders. One decoder is for segmentation of the healthy region of the lungs, while the other is for the segmentation of the infected regions. Experiments on publically available images show that the bifurcated structure segments infected regions of the lungs better than state of the art.      
### 43.Brain Tumor Classification Using Medial Residual Encoder Layers  [ :arrow_down: ](https://arxiv.org/pdf/2011.00628.pdf)
>  According to the World Health Organization, cancer is the second leading cause of death worldwide, responsible for over 9.5 million deaths in 2018 alone. Brain tumors count for one out of every four cancer deaths. Accurate and timely diagnosis of brain tumors will lead to more effective treatments. To date, several image classification approaches have been proposed to aid diagnosis and treatment. We propose an encoder layer that uses post-max-pooling features for residual learning. Our approach shows promising results by improving the tumor classification accuracy in MR images using a limited medical image dataset. Experimental evaluations of this model on a dataset consisting of 3064 MR images show 95-98% accuracy, which is better than previous studies on this database.      
### 44.Triage of Potential COVID-19 Patients from Chest X-ray Images using Hierarchical Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00618.pdf)
>  The current COVID-19 pandemic has motivated the researchers to use artificial intelligence techniques for potential alternatives to reverse transcription polymerase chain reaction (RT-PCR) due to the limited scale of testing. The chest X-ray (CXR) is one of the alternatives to achieve fast diagnosis but the unavailability of large scale annotated data makes the clinical implementation of machine learning-based COVID detection methods difficult. Another important issue is the usage of ImageNet pre-trained networks which does not guarantee to extract reliable feature representations. In this paper, we propose the use of hierarchical convolutional network (HCN) architecture to naturally augment the data along with diversified features. The HCN uses the first convolution layer from COVIDNet followed by the convolutional layers from well known pre-trained networks to extract the features. The use of the convolution layer from COVIDNet ensures the extraction of representations relevant to the CXR modality. We also propose the use of ECOC for encoding multiclass problems to binary classification for improving the recognition performance. Experimental results show that HCN architecture is capable of achieving better results in comparison to the existing studies. The proposed method can accurately triage potential COVID-19 patients through CXR images for sharing the testing load and increasing the testing capacity.      
### 45.Approximate Solutions to a Class of Reachability Games  [ :arrow_down: ](https://arxiv.org/pdf/2011.00601.pdf)
>  In this paper, we present a method for finding approximate Nash equilibria in a broad class of reachability games. These games are often used to formulate both collision avoidance and goal satisfaction. Our method is computationally efficient, running in real-time for scenarios involving multiple players and more than ten state dimensions. The proposed approach forms a family of increasingly exact approximations to the original game. Our results characterize the quality of these approximations and show operation in a receding horizon, minimally-invasive control context. Additionally, as a special case, our method reduces to local optimization in the single-player (optimal control) setting, for which a wide variety of efficient algorithms exist.      
### 46.A Flow-Efficient and Legal-by-Construction Real-Time Traffic Signal Control Platform  [ :arrow_down: ](https://arxiv.org/pdf/2011.00560.pdf)
>  Inefficiencies in traffic flow through an intersection lead to stopping vehicles, unnecessary congestion, and increased accident risk. In this paper, we propose a traffic signal controller platform demonstrating the ability to increase traffic flow for arbitrary intersection topologies. This model uses Model Predictive Control on a Mixed Logical Dynamical system to control the state of independently controlled traffic signals in a single intersection, removing constraints forcing the selection of signals from a set of phases. Further, we use constraints to impose a guarantee on the output of the system to be in the set of permissible actions under constraints including precise yellow timing, minimum inter-lane green transition timing, and selection of signal states with non-conflicting dependencies. We evaluate our model on a simulated 4-way intersection and an intersection in Denmark with true traffic data and a currently implemented timing schedule as a baseline. Our model shows at least 22\% reduction in time loss compared to baseline light schedules, and timing shows that this system can feasibly run online predictions at a frequency faster than 2s/prediction optimizing over a prediction horizon of 25s.      
### 47.Learning Euler's Elastica Model for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2011.00526.pdf)
>  Image segmentation is a fundamental topic in image processing and has been studied for many decades. Deep learning-based supervised segmentation models have achieved state-of-the-art performance but most of them are limited by using pixel-wise loss functions for training without geometrical constraints. Inspired by Euler's Elastica model and recent active contour models introduced into the field of deep learning, we propose a novel active contour with elastica (ACE) loss function incorporating Elastica (curvature and length) and region information as geometrically-natural constraints for the image segmentation tasks. We introduce the mean curvature i.e. the average of all principal curvatures, as a more effective image prior to representing curvature in our ACE loss function. Furthermore, based on the definition of the mean curvature, we propose a fast solution to approximate the ACE loss in three-dimensional (3D) by using Laplace operators for 3D image segmentation. We evaluate our ACE loss function on four 2D and 3D natural and biomedical image datasets. Our results show that the proposed loss function outperforms other mainstream loss functions on different segmentation networks. Our source code is available at <a class="link-external link-https" href="https://github.com/HiLab-git/ACELoss" rel="external noopener nofollow">this https URL</a>.      
### 48.Joint Tracking of Multiple Beams in Beamspace MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.00506.pdf)
>  In millimeter-wave (mmWave) systems, beamforming is needed to overcome harsh channel environments. As a promising beamforming solution, lens antenna array (LAA) implementation can provide a cost-effective solution without notable performance degradation compared to its counterpart. However, an appropriate beam selection is a challenge since it requires efficient channel estimation via an extensive beam training process for perfect beam alignment. In this paper, we propose a high mobility beam and channel tracking algorithm based on the unscented Kalman filter (UKF) to address this challenge, where the channel changes can be monitored over a certain time. The proposed algorithm tracks the channel changes after establishing a connection with an appropriate beam. The algorithm is first introduced in a multi-user beamspace multiple-input multiple-output (MIMO) system with LAA where a single beam is tracked at the user side at downlink transmission. Then, it is employed for multi-beam joint-tracking at the base station side in the uplink transmission. The analysis indicates that under different channel variation conditions, the proposed algorithm outmatches the popular extended Kalman filter (EKF) in both single-beam and multi-beam tracking systems. While it is common to individually track the beams in a multi-beam system scenario, the proposed joint tracking approach can provide around 62% performance enhancement compared to individual beam tracking using the conventional EKF method.      
### 49.Focusing Phenomena in Linear Discrete Inverse Problems in Acoustics  [ :arrow_down: ](https://arxiv.org/pdf/2011.00502.pdf)
>  The focusing operation inherent to the linear discrete inverse problem is formalised. The development is given in the context of sound-field reproduction where the source strengths are the inverse solution needed to recreate a prescribed pressure field at discrete locations. The behaviour of the system is fundamentally tied to the amount of acoustic crosstalk at each control point as a result of the focusing operation inherent to the pseudoinverse. The maximisation of the crosstalk at just one point leads to linear dependence in the system. On the other hand, its minimisation leads to the ideal focusing state wherein the sources can selectively focus at each point, while a null is created at all other points. Two theoretical case studies are presented that demonstrate ideal and super ideal focusing, wherein the latter the condition number is unitary. First, the application of binaural audio reproduction using an array of loudspeakers is examined and several cases of ideal focusing are presented. In the process, the Optimal Source Distribution is re-derived and shown to be a case of super ideal focusing. Secondly, the application of recreating multiple sound zones is examined using a uniform linear array. The conditions are derived to achieve ideal focusing at control points positioned arbitrarily in the far-field. In all cases, the ability to maintain ideal focusing as a function of frequency requires proportional changes in the loudspeaker or control geometry.      
### 50.A novel receiver design for energy packet-based dispatching  [ :arrow_down: ](https://arxiv.org/pdf/2011.00497.pdf)
>  A steadily growing share of renewable energies with uctuating and decentralized generation as well as rising peak loads require novel solutions to ensure the reliability of electricity supply. More speci cally, grid stability is endangered by equally relevant line constraints and battery capacity limits. In this light, energy packet-based dispatching with power signal dual modulation has recently been introduced as an innovative solution. However, this approach assumes a central synchronicity provision unit for energy packet dispatching. In order to overcome this assumption, the present paper's main contribution is a design of an energy packet receiver which recovers the required synchronicity information directly from the received signal itself. Key implementation aspects are discussed in detail. By means of a DC grid example, simulation results show the performance and applicability of the proposed novel receiver for packet-based energy dispatching.      
### 51.Storage placement policy for minimizing frequency deviation: A combinatorial optimization approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.00492.pdf)
>  As the share of renewable sources is increasing the need for multiple storage units appropriately sized and located is essential to achieve better inertial response. This work focuses on the question of "how to distribute constant number of storage units in the gird under transient events such that the inertial response of the maximum frequency deviation is minimized?". To answer this question, we provide a comprehensive modeling framework for energy storage units placement and size for frequency stability under spatial effects. The distributed storage units are modeled as grid supporting inverters and the total storage capacity in the grid is bounded based on the allowed steady-state frequency deviation after disturbances. The problem of finding the optimal distributions can be considered as combinatorial problem which consists of high dimensional solutions. In this light, we develop two numeric approaches based on Brute-force search and adaptation of the Cross-entropy method for finding the best distribution and examined it on a case study of the future Israeli grid. The results on the case study provide a new insight---the storage units should be placed around the area of the disturbances, including in sites with high inertia in accordance to the network topology.      
### 52.Dynamic radiomics: a new methodology to extract quantitative time-related features from tomographic images  [ :arrow_down: ](https://arxiv.org/pdf/2011.00454.pdf)
>  The feature extraction methods of radiomics are mainly based on static tomographic images at a certain moment, while the occurrence and development of disease is a dynamic process that cannot be fully reflected by only static characteristics. This study proposes a new dynamic radiomics feature extraction workflow that uses time-dependent tomographic images of the same patient, focuses on the changes in image features over time, and then quantifies them as new dynamic features for diagnostic or prognostic evaluation. We first define the mathematical paradigm of dynamic radiomics and introduce three specific methods that can describe the transformation process of features over time. Three different clinical problems are used to validate the performance of the proposed dynamic feature with conventional 2D and 3D static features.      
### 53.A Unified Framework for Joint Energy and AoI Optimization via Deep Reinforcement Learning for NOMA MEC-based Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00436.pdf)
>  In this paper, we design a novel scheduling and resource allocation algorithm for a smart mobile edge computing (MEC) assisted radio access network. Different from previous energy efficiency (EE) based or the average age of information (AAoI)-based network designs, we propose a unified metric for simultaneously optimizing ESE and AAoI of the network. To further improve the system capacity, non-orthogonal multiple access (NOMA) is proposed as a candidate for multiple access schemes for future cellular networks. Our main aim is to maximize the long-term objective function under AoI, NOMA, and resource capacity constraints using stochastic optimization. To overcome the complexities and unknown dynamics of the network parameters (e.g., wireless channel and interference), we apply the concept of reinforcement learning and implement a deep Q-network (DQN). Simulation results illustrate the effectiveness of the proposed framework and analyze different parameters impact on network performance. Based on the results, our proposed reward function converges fast with negligible loss value. Also, they illustrate our work outperforms the existing state of the art baselines up to 64% in the objective function and 51% in AAoI, which are stated as examples.      
### 54.Two-layer clustering-based sparsifying transform learning for low-dose CT reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2011.00428.pdf)
>  Achieving high-quality reconstructions from low-dose computed tomography (LDCT) measurements is of much importance in clinical settings. Model-based image reconstruction methods have been proven to be effective in removing artifacts in LDCT. In this work, we propose an approach to learn a rich two-layer clustering-based sparsifying transform model (MCST2), where image patches and their subsequent feature maps (filter residuals) are clustered into groups with different learned sparsifying filters per group. We investigate a penalized weighted least squares (PWLS) approach for LDCT reconstruction incorporating learned MCST2 priors. Experimental results show the superior performance of the proposed PWLS-MCST2 approach compared to other related recent schemes.      
### 55.Segmentation of Infrared Breast Images Using MultiResUnet Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.00376.pdf)
>  Breast cancer is the second leading cause of death for women in the U.S. Early detection of breast cancer is key to higher survival rates of breast cancer patients. We are investigating infrared (IR) thermography as a noninvasive adjunct to mammography for breast cancer screening. IR imaging is radiation-free, pain-free, and non-contact. Automatic segmentation of the breast area from the acquired full-size breast IR images will help limit the area for tumor search, as well as reduce the time and effort costs of manual segmentation. Autoencoder-like convolutional and deconvolutional neural networks (C-DCNN) had been applied to automatically segment the breast area in IR images in previous studies. In this study, we applied a state-of-the-art deep-learning segmentation model, MultiResUnet, which consists of an encoder part to capture features and a decoder part for precise localization. It was used to segment the breast area by using a set of breast IR images, collected in our pilot study by imaging breast cancer patients and normal volunteers with a thermal infrared camera (N2 Imager). The database we used has 450 images, acquired from 14 patients and 16 volunteers. We used a thresholding method to remove interference in the raw images and remapped them from the original 16-bit to 8-bit, and then cropped and segmented the 8-bit images manually. Experiments using leave-one-out cross-validation (LOOCV) and comparison with the ground-truth images by using Tanimoto similarity show that the average accuracy of MultiResUnet is 91.47%, which is about 2% higher than that of the autoencoder. MultiResUnet offers a better approach to segment breast IR images than our previous model.      
### 56.Deep learning in the ultrasound evaluation of neonatal respiratory status  [ :arrow_down: ](https://arxiv.org/pdf/2011.00337.pdf)
>  Lung ultrasound imaging is reaching growing interest from the scientific community. On one side, thanks to its harmlessness and high descriptive power, this kind of diagnostic imaging has been largely adopted in sensitive applications, like the diagnosis and follow-up of preterm newborns in neonatal intensive care units. On the other side, state-of-the-art image analysis and pattern recognition approaches have recently proven their ability to fully exploit the rich information contained in these data, making them attractive for the research community. In this work, we present a thorough analysis of recent deep learning networks and training strategies carried out on a vast and challenging multicenter dataset comprising 87 patients with different diseases and gestational ages. These approaches are employed to assess the lung respiratory status from ultrasound images and are evaluated against a reference marker. The conducted analysis sheds some light on this problem by showing the critical points that can mislead the training procedure and proposes some adaptations to the specific data and task. The achieved results sensibly outperform those obtained by a previous work, which is based on textural features, and narrow the gap with the visual score predicted by the human experts.      
### 57.AGAIN-VC: A One-shot Voice Conversion using Activation Guidance and Adaptive Instance Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2011.00316.pdf)
>  Recently, voice conversion (VC) has been widely studied. Many VC systems use disentangle-based learning techniques to separate the speaker and the linguistic content information from a speech signal. Subsequently, they convert the voice by changing the speaker information to that of the target speaker. To prevent the speaker information from leaking into the content embeddings, previous works either reduce the dimension or quantize the content embedding as a strong information bottleneck. These mechanisms somehow hurt the synthesis quality. In this work, we propose AGAIN-VC, an innovative VC system using Activation Guidance and Adaptive Instance Normalization. AGAIN-VC is an auto-encoder-based model, comprising of a single encoder and a decoder. With a proper activation as an information bottleneck on content embeddings, the trade-off between the synthesis quality and the speaker similarity of the converted speech is improved drastically. This one-shot VC system obtains the best performance regardless of the subjective or objective evaluations.      
### 58.In-The-Wild Interference Characterization and Modelling for Electro-Quasistatic-HBC with Miniaturized Wearables  [ :arrow_down: ](https://arxiv.org/pdf/2011.00300.pdf)
>  The emergence of Human Body Communication (HBC) as an alternative to wireless body area networks (WBAN) has led to the development of small sized, energy efficient and more secure wearable and implantable devices forming a network in and around the body. Previous studies claim that though HBC is comparatively more secure than WBAN, nevertheless, the electromagnetic (EM) radiative nature of HBC in &gt;10MHz region makes the information susceptible to eavesdropping. Furthermore, interferences may be picked up by the body due to the human body antenna effect in the 40-400MHz range. Alternatively, electro-quasistatic (EQS) mode of HBC forms an attractive way for covert data transmission in the sub 10MHz region by allowing the signal to be contained within the body. However, there is a gap in the knowledge about the mechanism and sources of interference in this region (crucial in allowing for proper choice of data transmission band). In this paper, the interference coupling modality in the EQS region is explained along with its possible sources. Interferences seen by the wearable in the actual scenario is a non-trivial problem and a suitable measurement EQS HBC setup is designed to recreate it by employing a wearable sized measurement setup having a small ground plane. For the first time, a human biophysical interference pickup model is proposed and interference measurement results using a wearable device are presented up to 250kHz in different environmental settings.      
### 59.Infectious Disease Transmission via Aerosol Propagation from a Molecular Communication Perspective: Shannon Meets Coronavirus  [ :arrow_down: ](https://arxiv.org/pdf/2011.00290.pdf)
>  Molecular communication is not just able to mimic biological and chemical communication mechanisms, but also provides a theoretical framework regarding viral infection processes. In this tutorial, aerosol and droplet transmission is modeled as a multiuser scenario with mobile nodes, related to broadcasting and relaying. In contrast to data communication systems, in the application of pathogen-laden aerosol transmission, mutual information between nodes should be minimized. Towards this goal, several countermeasures are reasoned. The findings are supported by experimental results and by an advanced particle simulation tool. This work is inspired by the recent outbreak of the coronavirus (COVID-19) pandemic, but also applicable to other air-borne infectious diseases like influenza.      
### 60.Defect Detection by MIMO Wireless Sensing based on Weighted Low-Rank plus Sparse Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2011.00278.pdf)
>  We address the detection of material defects, which are inside a layered material structure by multiple input multiple output (MIMO) wireless sensing from compressive measurements. However, due to reflections from the surface of the layered material structure the defect detection is challenging. To cope with this challenge, advanced signal processing methods are required. By utilizing a low-rank nature of the reflections of the layered material structure and sparse nature of the defects, we propose a method based on rank minimization and sparse recovery. To obtain a higher accuracy in the recovery of low-rank and sparse components, we propose a non-convex approach based on the iteratively reweighted nuclear norm and iteratively reweighted $\ell_1-$norm algorithm. Our numerical results show that the proposed method is able to demix and recover the signalling responses of the defects and layered structure successfully from substantially reduced number of observations. Further, the proposed approach outperforms the state-of-the-art clutter reduction approaches.      
### 61.A Privacy-Preserving Content-Based Image Retrieval Scheme Allowing Mixed Use Of Encrypted And Plain Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.00270.pdf)
>  In this paper, we propose a novel content based-image retrieval scheme allowing the mixed use of encrypted and plain images for the first time. In the proposed scheme, images are encrypted by a block-scrambling method developed for encryption-then-compression (EtC) systems. The encrypted images, referred to as EtC images, can be compressed with JPEG, as well as for plain images. Image descriptors used for the proposed retrieval is designed to avoid the effect of image encryption. As a result, the use of EtC images and the descriptors allows us to carry out retrieval of both encrypted images and plain ones. In an experiment, the proposed scheme is demonstrated to have the same performance as conventional retrieval methods with plain images, even under the mixed use of plain images and EtC ones.      
### 62.Encoding Clinical Priori in 3D Convolutional Neural Networks for Prostate Cancer Detection in bpMRI  [ :arrow_down: ](https://arxiv.org/pdf/2011.00263.pdf)
>  We hypothesize that anatomical priors can be viable mediums to infuse domain-specific clinical knowledge into state-of-the-art convolutional neural networks (CNN) based on the U-Net architecture. We introduce a probabilistic population prior which captures the spatial prevalence and zonal distinction of clinically significant prostate cancer (csPCa), in order to improve its computer-aided detection (CAD) in bi-parametric MR imaging (bpMRI). To evaluate performance, we train 3D adaptations of the U-Net, U-SEResNet, UNet++ and Attention U-Net using 800 institutional training-validation scans, paired with radiologically-estimated annotations and our computed prior. For 200 independent testing bpMRI scans with histologically-confirmed delineations of csPCa, our proposed method of encoding clinical priori demonstrates a strong ability to improve patient-based diagnosis (upto 8.70% increase in AUROC) and lesion-level detection (average increase of 1.08 pAUC between 0.1-1.0 false positive per patient) across all four architectures.      
### 63.Wireless Power Transfer with Distributed Antennas: System Design, Prototype, and Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2011.00252.pdf)
>  In this paper, we design and experiment a far-field wireless power transfer (WPT) architecture based on distributed antennas, so-called WPT DAS, that dynamically selects transmit antenna and frequency to increase the output dc power. Uniquely, spatial and frequency diversities are jointly exploited in the proposed WPT DAS with low complexity, low cost, and flexible deployment to combat the wireless fading channel. A numerical experiment is designed to show the benefits using antenna and frequency selections in spatially and frequency selective fading channels for single-user and multi-user cases. Accordingly, the proposed WPT DAS for single-user and two-user cases is prototyped. At the transmitter, we adopt antenna selection to exploit spatial diversity and adopt frequency selection to exploit frequency diversity. A low-complexity over-the-air limited feedback using an IEEE 802.15.4 RF interface is designed for antenna and frequency selections and reporting from the receiver to the transmitter. The proposed WPT DAS prototype is demonstrated in a real indoor environment. The measurements show that WPT DAS can boost the output dc power by up to 30 dB in single-user case and boost the sum of output dc power by up to 21.8 dB in two-user case and broaden the service coverage area in a low cost, low complexity, and flexible manner.      
### 64.Non-Orthogonal Multiple Access (NOMA) with Multiple Intelligent Reflecting Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2011.00211.pdf)
>  In this paper, non-orthogonal multiple access (NOMA) networks assisted by multiple intelligent reflecting surfaces (IRSs) with discrete phase shifts are investigated, in which each user device (UD) is served by an IRS to improve the quality of the received signal. Two scenarios are considered based on whether there is a direct link or not between the base station (BS) and each UD, and the outage performance is analyzed for each of them. Specifically, the outage probability is approximated in the high signal-to-noise ratio (SNR) regime, and the diversity order is obtained. Orthogonal multiple access (OMA) can be regarded as a special case of NOMA, and the outage performance of the multi-IRS assisted OMA system is also characterized. It is demonstrated that NOMA outperforms OMA in multi-IRS assisted networks. Furthermore, it is shown that the use of discrete phase shifts does not degrade the diversity order. More importantly, simulation results further reveal that a 3-bit resolution for discrete phase shifts is sufficient to achieve near-optimal outage performance.      
### 65.Convolutional Neural Networks Based System for Urban Sound Tagging with Spatiotemporal Context  [ :arrow_down: ](https://arxiv.org/pdf/2011.00175.pdf)
>  Noise pollution has a significant impact on the quality of life of citizens and urban development, and its prevention and control has been widely valued. In order to better protect the environment, the analysis and monitoring technology of urban noise pollution needs to be further optimized. Urban Sound Tagging (UST) can help to map the distribution of noise pollution and therefore attracts more attentions. The goal of UST is to tag a recording, which is collected by the sensors from urban environment, and returns whether noise pollution is audible or not. In previous works, only sound signal is provided and used. However, the spatiotemporal context can offer more information. In this paper, we proposed convolutional neural networks (CNNs) based system for UST with spatiotemporal context. In our system, multiple features and spatiotemporal context are combined, and fed into a residual CNN to predict whether noise of pollution is present in a 10-second recording. To eliminate the imbalance problem of the dataset, a data augmentation method is applied during the training. Finally, a fusion strategy is adopted to further improve the performance of UST. We evaluated the proposed system on the DCASE2020 task5 dataset. The experimental results show that the proposed system significantly outperform the baseline system on the evaluation metrics.      
### 66.Dense Pixel-wise Micro-motion Estimation of Object Surface by using Low Dimensional Embedding of Laser Speckle Pattern  [ :arrow_down: ](https://arxiv.org/pdf/2011.00174.pdf)
>  This paper proposes a method of estimating micro-motion of an object at each pixel that is too small to detect under a common setup of camera and illumination. The method introduces an active-lighting approach to make the motion visually detectable. The approach is based on speckle pattern, which is produced by the mutual interference of laser light on object's surface and continuously changes its appearance according to the out-of-plane motion of the surface. In addition, speckle pattern becomes uncorrelated with large motion. To compensate such micro- and large motion, the method estimates the motion parameters up to scale at each pixel by nonlinear embedding of the speckle pattern into low-dimensional space. The out-of-plane motion is calculated by making the motion parameters spatially consistent across the image. In the experiments, the proposed method is compared with other measuring devices to prove the effectiveness of the method.      
### 67.From data to reduced-order models via moment matching  [ :arrow_down: ](https://arxiv.org/pdf/2011.00150.pdf)
>  A new method for data-driven interpolatory model reduction is presented in this paper. Using the so-called data informativity perspective, we define a framework that enables the computation of moments at given (possibly complex) interpolation points based on time-domain input-output data only, without explicitly identifying the high-order system. Instead, by characterizing the set of all systems explaining the data, necessary and sufficient conditions are provided under which all systems in this set share the same moment at a given interpolation point. Moreover, these conditions allow for explicitly computing these moments. Reduced-order models are then derived by employing a variation of the classical rational interpolation method. The condition to enforce moment matching model reduction with prescribed poles is also discussed as a means to obtain stable reduced-order models. An example of an electrical circuit illustrates this framework.      
### 68.EDCNN: Edge enhancement-based Densely Connected Network with Compound Loss for Low-Dose CT Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2011.00139.pdf)
>  In the past few decades, to reduce the risk of X-ray in computed tomography (CT), low-dose CT image denoising has attracted extensive attention from researchers, which has become an important research issue in the field of medical images. In recent years, with the rapid development of deep learning technology, many algorithms have emerged to apply convolutional neural networks to this task, achieving promising results. However, there are still some problems such as low denoising efficiency, over-smoothed result, etc. In this paper, we propose the Edge enhancement based Densely connected Convolutional Neural Network (EDCNN). In our network, we design an edge enhancement module using the proposed novel trainable Sobel convolution. Based on this module, we construct a model with dense connections to fuse the extracted edge information and realize end-to-end image denoising. Besides, when training the model, we introduce a compound loss that combines MSE loss and multi-scales perceptual loss to solve the over-smoothed problem and attain a marked improvement in image quality after denoising. Compared with the existing low-dose CT image denoising algorithms, our proposed model has a better performance in preserving details and suppressing noise.      
### 69.Multi-stage transfer learning for lung segmentation using portable X-ray devices for patients with COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2011.00133.pdf)
>  In 2020, the SARS-CoV-2 virus causes a global pandemic of the new human coronavirus disease COVID-19. This pathogen primarily infects the respiratory system of the afflicted, usually resulting in pneumonia and in a severe case of acute respiratory distress syndrome. These disease developments result in the formation of different pathological structures in the lungs, similar to those observed in other viral pneumonias that can be detected by the use of chest X-rays. For this reason, the detection and analysis of the pulmonary regions, the main focus of affection of COVID-19, becomes a crucial part of both clinical and automatic diagnosis processes. Due to the overload of the health services, portable X-ray devices are widely used, representing an alternative to fixed devices to reduce the risk of cross-contamination. However, these devices entail different complications as the image quality that, together with the subjectivity of the clinician, make the diagnostic process more difficult. In this work, we developed a novel fully automatic methodology specially designed for the identification of these lung regions in X-ray images of low quality as those from portable devices. To do so, we took advantage of a large dataset from magnetic resonance imaging of a similar pathology and performed two stages of transfer learning to obtain a robust methodology with a low number of images from portable X-ray devices. This way, our methodology obtained a satisfactory accuracy of $0.9761 \pm 0.0100$ for patients with COVID-19, $0.9801 \pm 0.0104$ for normal patients and $0.9769 \pm 0.0111$ for patients with pulmonary diseases with similar characteristics as COVID-19 (such as pneumonia) but not genuine COVID-19.      
### 70.Understanding The Role of Magnetic and Magneto-Quasistatic Fields in Human Body Communication  [ :arrow_down: ](https://arxiv.org/pdf/2011.00125.pdf)
>  With the advent of wearable technologies, Human Body Communication (HBC) has emerged as a physically secure and power-efficient alternative to the otherwise ubiquitous Wireless Body Area Network (WBAN). Whereas the most investigated nodes of HBC have been Electric and Electro-quasistatic (EQS) Capacitive and Galvanic, recently Magnetic HBC (M-HBC) has been proposed as a viable alternative. Previous works have investigated M-HBC through an application point of view, without developing a fundamental working principle for the same. In this paper, for the first time, a ground up analysis has been performed to study the possible effects and contributions of the human body channel in M-HBC over a broad frequency range (1kHz to 10 GHz), by detailed electromagnetic simulations and supporting experiments. The results show that while M-HBC can be successfully operated as a body area network, the human body itself plays a minimal or negligible role in it's functionality. For frequencies less than about 30 MHz, in the domain of operation of Magneto-quasistatic (MQS) HBC, the human body is transparent to the quasistatic magnetic field. Conversely for higher frequencies, the conductive nature of human tissues end up attenuating Magnetic HBC fields due to Eddy currents induced in body tissues, eliminating the possibility of the body to support efficient waveguide modes. With this better understanding at hand, different modes of operations of MQS HBC have been outlined for both high impedance capacitive and 50 Ohm termination cases, and their performances have been compared with EQS HBC for similar sized devices, over varying distance between TX and RX. The resulting report presents the first fundamental understanding towards M-HBC operation and its contrast with EQS HBC, aiding HBC device designers to make educated design decisions, depending on mode of applications.      
### 71.An Uncertainty Estimation Framework for Risk Assessment in Deep Learning-based Atrial Fibrillation Classification  [ :arrow_down: ](https://arxiv.org/pdf/2011.00121.pdf)
>  Atrial Fibrillation (AF) is among one of the most common types of heart arrhythmia afflicting more than 3 million people in the U.S. alone. AF is estimated to be the cause of death of 1 in 4 individuals. Recent advancements in Artificial Intelligence (AI) algorithms have led to the capability of reliably detecting AF from ECG signals. While these algorithms can accurately detect AF with high precision, the discrete and deterministic classifications mean that these networks are likely to erroneously classify the given ECG signal. This paper proposes a variational autoencoder classifier network that provides an uncertainty estimation of the network's output in addition to reliable classification accuracy. This framework can increase physicians' trust in using AI-based AF detection algorithms by providing them with a confidence score which reflects how uncertain the algorithm is about a case and recommending them to put more attention to the cases with a lower confidence score. The uncertainty is estimated by conducting multiple passes of the input through the network to build a distribution; the mean of the standard deviations is reported as the network's uncertainty. Our proposed network obtains 97.64% accuracy in addition to reporting the uncertainty      
### 72.Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous Vehicles and Multi-Agent RL  [ :arrow_down: ](https://arxiv.org/pdf/2011.00120.pdf)
>  We study the ability of autonomous vehicles to improve the throughput of a bottleneck using a fully decentralized control scheme in a mixed autonomy setting. We consider the problem of improving the throughput of a scaled model of the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four lanes reduce to two and then reduce to one. Although there is extensive work examining variants of bottleneck control in a centralized setting, there is less study of the challenging multi-agent setting where the large number of interacting AVs leads to significant optimization difficulties for reinforcement learning methods. We apply multi-agent reinforcement algorithms to this problem and demonstrate that significant improvements in bottleneck throughput, from 20\% at a 5\% penetration rate to 33\% at a 40\% penetration rate, can be achieved. We compare our results to a hand-designed feedback controller and demonstrate that our results sharply outperform the feedback controller despite extensive tuning. Additionally, we demonstrate that the RL-based controllers adopt a robust strategy that works across penetration rates whereas the feedback controllers degrade immediately upon penetration rate variation. We investigate the feasibility of both action and observation decentralization and demonstrate that effective strategies are possible using purely local sensing. Finally, we open-source our code at <a class="link-external link-https" href="https://github.com/eugenevinitsky/decentralized_bottlenecks" rel="external noopener nofollow">this https URL</a>.      
### 73.Versatile Configuration and Control Framework for Real Time Data Acquisition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.00112.pdf)
>  Modern physics experiments often utilize FPGA-based systems for real-time data acquisition. Integrated analog electronics demand for complex calibration routines. Furthermore, versatile configuration and control of the whole system is a key requirement. Beside low-level register interface to the FPGA, also access to I$^2$C and SPI buses is often needed to configure the complete system. Calibration through an FPGA is inflexible and yields a complex hardware implementation. On the contrary, calibration through a remote system is possible but considerably slower due to repetitive network accesses. By using SoC-FPGA solutions with a microprocessor, more sophisticated configuration and calibration solutions, as well as standard remote access protocols, can be efficiently integrated in software. <br>Based on Xilinx Zynq US+ SoC-FPGAs, we implemented a versatile control framework. This software framework offers a convenient access to the hardware and a flexible abstraction via remote-procedure calls (RPCs). Based on the open source RPC library gRPC, functionality with low-latent control flow, complex algorithms, data conversions and processing, as well as configuration via external buses can be provided to a client via Ethernet. Furthermore, client interfaces for various programming languages can be generated automatically which eases collaboration among different working groups and integration into existing software. This contribution presents the framework as well as benchmarks regarding latency and data throughput.      
### 74.Generator Controller Tuning Considering Stochastic Load Variation Using Analysis of Variance and Response Surface Method  [ :arrow_down: ](https://arxiv.org/pdf/2011.00098.pdf)
>  This article proposes a method for generator controller tuning in a power system affected by stochastic loads. The method uses the Analysis of Variance to detect the controllers with significant effect over the quality of the system response. Such quality is measured with an objective function defined as a weighted average of the Integral Absolute Error of each controller. The significant variables are then varied over a specified region in order to characterize the objective function through a regression model, which is then optimized. The method was applied to the system IEEE14 and the results were compared with benchmark parameters, showing better performance.      
### 75.Directional ASR: A New Paradigm for E2E Multi-Speaker Speech Recognition with Source Localization  [ :arrow_down: ](https://arxiv.org/pdf/2011.00091.pdf)
>  This paper proposes a new paradigm for handling far-field multi-speaker data in an end-to-end neural network manner, called directional automatic speech recognition (D-ASR), which explicitly models source speaker locations. In D-ASR, the azimuth angle of the sources with respect to the microphone array is defined as a latent variable. This angle controls the quality of separation, which in turn determines the ASR performance. All three functionalities of D-ASR: localization, separation, and recognition are connected as a single differentiable neural network and trained solely based on ASR error minimization objectives. The advantages of D-ASR over existing methods are threefold: (1) it provides explicit speaker locations, (2) it improves the explainability factor, and (3) it achieves better ASR performance as the process is more streamlined. In addition, D-ASR does not require explicit direction of arrival (DOA) supervision like existing data-driven localization models, which makes it more appropriate for realistic data. For the case of two source mixtures, D-ASR achieves an average DOA prediction error of less than three degrees. It also outperforms a strong far-field multi-speaker end-to-end system in both separation quality and ASR performance.      
### 76.C-Net: A Reliable Convolutional Neural Network for Biomedical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2011.00081.pdf)
>  Cancers are the leading cause of death in many developed countries. Early diagnosis plays a crucial role in having proper treatment for this debilitating disease. The automated classification of the type of cancer is a challenging task since pathologists must examine a huge number of histopathological images to detect infinitesimal abnormalities. In this study, we propose a novel convolutional neural network (CNN) architecture composed of a Concatenation of multiple Networks, called C-Net, to classify biomedical images. In contrast to conventional deep learning models in biomedical image classification, which utilize transfer learning to solve the problem, no prior knowledge is employed. The model incorporates multiple CNNs including Outer, Middle, and Inner. The first two parts of the architecture contain six networks that serve as feature extractors to feed into the Inner network to classify the images in terms of malignancy and benignancy. The C-Net is applied for histopathological image classification on two public datasets, including BreakHis and Osteosarcoma. To evaluate the performance, the model is tested using several evaluation metrics for its reliability. The C-Net model outperforms all other models on the individual metrics for both datasets and achieves zero misclassification.      
### 77.Adversarial Robust Training in MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2011.00070.pdf)
>  Deep Learning has shown potential in accelerating Magnetic Resonance Image acquisition and reconstruction. Nevertheless, there is a dearth of tailored methods to guarantee that the reconstruction of small features is achieved with high fidelity. In this work, we employ adversarial attacks to generate small synthetic perturbations that when added to the input MRI, they are not reconstructed by a trained DL reconstruction network. Then, we use robust training to increase the network's sensitivity to small features and encourage their reconstruction. Next, we investigate the generalization of said approach to real world features. For this, a musculoskeletal radiologist annotated a set of cartilage and meniscal lesions from the knee Fast-MRI dataset, and a classification network was devised to assess the features reconstruction. Experimental results show that by introducing robust training to a reconstruction network, the rate (4.8\%) of false negative features in image reconstruction can be reduced. The results are encouraging and highlight the necessity for attention on this problem by the image reconstruction community, as a milestone for the introduction of DL reconstruction in clinical practice. To support further research, we make our annotation publicly available at <a class="link-external link-https" href="https://github.com/fcaliva/fastMRI_BB_abnormalities_annotation" rel="external noopener nofollow">this https URL</a>.      
### 78.A Curated Dataset of Urban Scenes for Audio-Visual Scene Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2011.00030.pdf)
>  This paper introduces a curated dataset of urban scenes for audio-visual scene analysis which consists of carefully selected and recorded material. The data was recorded in multiple European cities, using the same equipment, in multiple locations for each scene, and is openly available. We also present a case study for audio-visual scene recognition and show that joint modeling of audio and visual modalities brings significant performance gain compared to state of the art uni-modal systems. Our approach obtained an 84.4% accuracy compared to 76.8% for the audio-only and 70.0% for the video-only equivalent systems.      
### 79.Data-Driven Adaptive Task Allocation for Heterogeneous Multi-Robot Teams Using Robust Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2011.01164.pdf)
>  Multi-robot task allocation is a ubiquitous problem in robotics due to its applicability in a variety of scenarios. Adaptive task-allocation algorithms account for unknown disturbances and unpredicted phenomena in the environment where robots are deployed to execute tasks. However, this adaptivity typically comes at the cost of requiring precise knowledge of robot models in order to evaluate the allocation effectiveness and to adjust the task assignment online. As such, environmental disturbances can significantly degrade the accuracy of the models which in turn negatively affects the quality of the task allocation. In this paper, we leverage Gaussian processes, differential inclusions, and robust control barrier functions to learn environmental disturbances in order to guarantee robust task execution. We show the implementation and the effectiveness of the proposed framework on a real multi-robot system.      
### 80.Optimize what matters: Training DNN-HMM Keyword Spotting Model Using End Metric  [ :arrow_down: ](https://arxiv.org/pdf/2011.01151.pdf)
>  Deep Neural Network--Hidden Markov Model (DNN-HMM) based methods have been successfully used for many always-on keyword spotting algorithms that detect a wake word to trigger a device. The DNN predicts the state probabilities of a given speech frame, while HMM decoder combines the DNN predictions of multiple speech frames to compute the keyword detection score. The DNN, in prior methods, is trained independent of the HMM parameters to minimize the cross-entropy loss between the predicted and the ground-truth state probabilities. The mis-match between the DNN training loss (cross-entropy) and the end metric (detection score) is the main source of sub-optimal performance for the keyword spotting task. We address this loss-metric mismatch with a novel end-to-end training strategy that learns the DNN parameters by optimizing for the detection score. To this end, we make the HMM decoder (dynamic programming) differentiable and back-propagate through it to maximize the score for the keyword and minimize the scores for non-keyword speech segments. Our method does not require any change in the model architecture or the inference framework; therefore, there is no overhead in run-time memory or compute requirements. Moreover, we show significant reduction in false rejection rate (FRR) at the same false trigger experience (&gt; 70% over independent DNN training).      
### 81.SIMDive: Approximate SIMD Soft Multiplier-Divider for FPGAs with Tunable Accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2011.01148.pdf)
>  The ever-increasing quest for data-level parallelism and variable precision in ubiquitous multimedia and Deep Neural Network (DNN) applications has motivated the use of Single Instruction, Multiple Data (SIMD) architectures. To alleviate energy as their main resource constraint, approximate computing has re-emerged,albeit mainly specialized for their Application-Specific Integrated Circuit (ASIC) implementations. This paper, presents for the first time, an SIMD architecture based on novel multiplier and divider with tunable accuracy, targeted for Field-Programmable Gate Arrays (FPGAs). The proposed hybrid architecture implements Mitchell's algorithms and supports precision variability from 8 to 32 bits. Experimental results obtained from Vivado, multimedia and DNN applications indicate superiority of proposed architecture (both SISD and SIMD) over accurate and state-of-the-art approximate counterparts. In particular, the proposed SISD divider outperforms the accurate Intellectual Property (IP) divider provided by Xilinx with 4x higher speed and 4.6x less energy and tolerating only &lt; 0.8% error. Moreover, the proposed SIMD multiplier-divider supersede accurate SIMD multiplier by achieving up to 26%, 45%, 36%, and 56% improvement in area, throughput, power, and energy, respectively.      
### 82.Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds  [ :arrow_down: ](https://arxiv.org/pdf/2011.01143.pdf)
>  Recent progress in deep learning has enabled many advances in sound separation and visual scene understanding. However, extracting sound sources which are apparent in natural videos remains an open problem. In this work, we present AudioScope, a novel audio-visual sound separation framework that can be trained without supervision to isolate on-screen sound sources from real in-the-wild videos. Prior audio-visual separation work assumed artificial limitations on the domain of sound classes (e.g., to speech or music), constrained the number of sources, and required strong sound separation or visual segmentation labels. AudioScope overcomes these limitations, operating on an open domain of sounds, with variable numbers of sources, and without labels or prior visual segmentation. The training procedure for AudioScope uses mixture invariant training (MixIT) to separate synthetic mixtures of mixtures (MoMs) into individual sources, where noisy labels for mixtures are provided by an unsupervised audio-visual coincidence model. Using the noisy labels, along with attention between video and audio features, AudioScope learns to identify audio-visual similarity and to suppress off-screen sounds. We demonstrate the effectiveness of our approach using a dataset of video clips extracted from open-domain YFCC100m video data. This dataset contains a wide diversity of sound classes recorded in unconstrained conditions, making the application of previous methods unsuitable. For evaluation and semi-supervised experiments, we collected human labels for presence of on-screen and off-screen sounds on a small subset of clips.      
### 83.Scheduling Real-time Deep Learning Services as Imprecise Computations  [ :arrow_down: ](https://arxiv.org/pdf/2011.01112.pdf)
>  The paper presents an efficient real-time scheduling algorithm for intelligent real-time edge services, defined as those that perform machine intelligence tasks, such as voice recognition, LIDAR processing, or machine vision, on behalf of local embedded devices that are themselves unable to support extensive computations. The work contributes to a recent direction in real-time computing that develops scheduling algorithms for machine intelligence tasks with anytime prediction. We show that deep neural network workflows can be cast as imprecise computations, each with a mandatory part and (several) optional parts whose execution utility depends on input data. The goal of the real-time scheduler is to maximize the average accuracy of deep neural network outputs while meeting task deadlines, thanks to opportunistic shedding of the least necessary optional parts. The work is motivated by the proliferation of increasingly ubiquitous but resource-constrained embedded devices (for applications ranging from autonomous cars to the Internet of Things) and the desire to develop services that endow them with intelligence. Experiments on recent GPU hardware and a state of the art deep neural network for machine vision illustrate that our scheme can increase the overall accuracy by 10%-20% while incurring (nearly) no deadline misses.      
### 84.Image Inpainting with Learnable Feature Imputation  [ :arrow_down: ](https://arxiv.org/pdf/2011.01077.pdf)
>  A regular convolution layer applying a filter in the same way over known and unknown areas causes visual artifacts in the inpainted image. Several studies address this issue with feature re-normalization on the output of the convolution. However, these models use a significant amount of learnable parameters for feature re-normalization, or assume a binary representation of the certainty of an output. We propose (layer-wise) feature imputation of the missing input values to a convolution. In contrast to learned feature re-normalization, our method is efficient and introduces a minimal number of parameters. Furthermore, we propose a revised gradient penalty for image inpainting, and a novel GAN architecture trained exclusively on adversarial loss. Our quantitative evaluation on the FDF dataset reflects that our revised gradient penalty and alternative convolution improves generated image quality significantly. We present comparisons on CelebA-HQ and Places2 to current state-of-the-art to validate our model.      
### 85.RRScell method for automated learning immune cell phenotypes with immunofluorescence cancer tissue  [ :arrow_down: ](https://arxiv.org/pdf/2011.01002.pdf)
>  Multiplexed immunofluorescence tissue imaging enables precise spatial assessment of protein expression in medical resection specimens. However, tissue sections are stained with a mixture of antibodies, DNA and RNA markers, the detection of weak or broken edges due to fluorescent membrane staining artifacts between touching or overlapping cells is a long term studied problem, and is an active research topic in biomedical image analysis. Sometimes detecting these kinds of edges which are even lacking discrimination or judgment by human visual intelligence. We have built a GPU client-server and have developed a hybrid system combining the stochastic random-reaction-seed (RRS) method and deep neural learning U-net to identify cell-membrane accurately and automatically. Furthermore, we have designed a high performance machine-learning AI-pipeline in quantifying spatial distribution of cell phenotypes from tissue images with various complexities, and extract single-cell or even subcellular resolution profiling-map of protein and RNA expression over a million cells tissue section.      
### 86.Multiuser MIMO with Large Intelligent Surfaces: Communication Model and Transmit Design  [ :arrow_down: ](https://arxiv.org/pdf/2011.00922.pdf)
>  This paper proposes a communication model for multiuser multiple-input multiple-output (MIMO) systems based on large intelligent surfaces (LIS), where the LIS is modeled as a collection of tightly packed antenna elements. The LIS system is first represented in a circuital way, obtaining expressions for the radiated and received powers, as well as for the coupling between the distinct elements. Then, this circuital model is used to characterize the channel in a line-of-sight propagation scenario, rendering the basis for the analysis and design of MIMO systems. Due to the particular properties of LIS, the model accounts for superdirectivity and mutual coupling effects along with near field propagation, necessary in those situations where the array dimension becomes very large. Finally, with the proposed model, the matched filter transmitter and the weighted minimum mean square error precoding are derived under both realistic constraints: limited radiated power and maximum ohmic losses.      
### 87.AnyMOD.jl: A Julia package for creating energy system models  [ :arrow_down: ](https://arxiv.org/pdf/2011.00895.pdf)
>  AnyMOD.jl is a Julia framework for creating large-scale energy system models with multiple periods of capacity expansion. It applies a novel graph-based approach that was developed to address the challenges in modeling high levels of intermittent generation and sectoral integration. Created models are formulated as linear optimization problems using JuMP.jl as a backend. To enable modelers to work more efficiently, the framework provides additional features that help to visualize results, streamline the read-in of input data, and rescale optimization problems to increase solver performance.      
### 88.A Formally Verified Highly Resilient Safety Concept with Degraded Modes for Automated Driving  [ :arrow_down: ](https://arxiv.org/pdf/2011.00892.pdf)
>  Modern Automated Driving Systems (ADS) rely on fragmented safety measures to handle faults and make driving decisions. To eradicate lethal road accidents, safety engineering has to expand beyond contemporary automotive design practices and patterns. We present a holistic safety concept unifying advanced safety measures for handling multiple-point faults and fault-free hazardous situations associated with system performance limitations. Noteworthy, we illustrate how our safety mechanism mitigates triple-point faults, which are often beyond the focus of the safety community. Furthermore, on top of handling faults in the ADS, our design can effectively react to its own faults. To reduce specification errors, we developed an executable model of the safety concept in the formal specification language mCRL2. The behavior of the model is governed by a four-mode degradation policy controlling distributed processors, redundant communication networks, and virtual machines. To keep the vehicle as safe as possible our degradation policy can reduce driving comfort or ADS availability using additional low-cost driving channels. We formalized five safety requirements in the modal mu-calculus and proved them against our mCRL2 model, which is intractable to accomplish exhaustively using traditional road tests or simulation techniques. In conclusion, our formally proven safety concept defines a holistic design pattern for ADS minimizing road fatalities.      
### 89.Shack-Hartmann sensor as an imaging system with a phase diversity  [ :arrow_down: ](https://arxiv.org/pdf/2011.00891.pdf)
>  Conventional methods of wavefront reconstruction from the raw data of the Shack-Hartmann sensor use the focal spot shifts and discard the high-frequency information about the wavefront. Phase-retrieval-based methods treat the Hartmann pattern as the diffraction image and use the Rayleigh-Sommerfeld propagation to estimate the wavefront with greater accuracy and resolution. In this Letter, we propose a novel approach to the phase-retrieval-based reconstruction by considering the Hartmann pattern as a point-spread function of a general imaging system with an introduced phase diversity of a special type. This model allows one not only to use any phase retrieval algorithm to reconstruct the wavefront but also to analyse the limitations of the phase-retrieval-based methods. We demonstrate the validity of this approach both on the simulated and experimental data.      
### 90.Predicting Brain Degeneration with a Multimodal Siamese Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.00840.pdf)
>  To study neurodegenerative diseases, longitudinal studies are carried on volunteer patients. During a time span of several months to several years, they go through regular medical visits to acquire data from different modalities, such as biological samples, cognitive tests, structural and functional imaging. These variables are heterogeneous but they all depend on the patient's health condition, meaning that there are possibly unknown relationships between all modalities. Some information may be specific to some modalities, others may be complementary, and others may be redundant. Some data may also be missing. In this work we present a neural network architecture for multimodal learning, able to use imaging and clinical data from two time points to predict the evolution of a neurodegenerative disease, and robust to missing values. Our multimodal network achieves 92.5\% accuracy and an AUC score of 0.978 over a test set of 57 subjects. We also show the superiority of the multimodal architecture, for up to 37.5\% of missing values in test set subjects' clinical measurements, compared to a model using only the clinical modality.      
### 91.Ant Colony Inspired Machine Learning Algorithm for Identifying and Emulating Virtual Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2011.00836.pdf)
>  The scale of systems employed in industrial environments demands a large number of sensors to facilitate meticulous monitoring and functioning. These requirements could potentially lead to inefficient system designs. The data coming from various sensors are often correlated due to the underlying relations in the system parameters that the sensors monitor. In theory, it should be possible to emulate the output of certain sensors based on other sensors. Tapping into such possibilities holds tremendous advantages in terms of reducing system design complexity. In order to identify the subset of sensors whose readings can be emulated, the sensors must be grouped into clusters. Complex systems generally have a large quantity of sensors that collect and store data over prolonged periods of time. This leads to the accumulation of massive amounts of data. In this paper we propose an end-to-end algorithmic solution, to realise virtual sensors in such systems. This algorithm splits the dataset into blocks and clusters each of them individually. It then fuses these clustering solutions to obtain a global solution using an Ant Colony inspired technique, FAC2T. Having grouped the sensors into clusters, we select representative sensors from each cluster. These sensors are retained in the system while the other sensors readings are emulated by applying supervised learning algorithms.      
### 92.Data-free Knowledge Distillation for Segmentation using Data-Enriching GAN  [ :arrow_down: ](https://arxiv.org/pdf/2011.00809.pdf)
>  Distilling knowledge from huge pre-trained networks to improve the performance of tiny networks has favored deep learning models to be used in many real-time and mobile applications. Several approaches that demonstrate success in this field have made use of the true training dataset to extract relevant knowledge. In absence of the True dataset, however, extracting knowledge from deep networks is still a challenge. Recent works on data-free knowledge distillation demonstrate such techniques on classification tasks. To this end, we explore the task of data-free knowledge distillation for segmentation tasks. First, we identify several challenges specific to segmentation. We make use of the DeGAN training framework to propose a novel loss function for enforcing diversity in a setting where a few classes are underrepresented. Further, we explore a new training framework for performing knowledge distillation in a data-free setting. We get an improvement of 6.93% in Mean IoU over previous approaches.      
### 93.What's All the FUSS About Free Universal Sound Separation Data?  [ :arrow_down: ](https://arxiv.org/pdf/2011.00803.pdf)
>  We introduce the Free Universal Sound Separation (FUSS) dataset, a new corpus for experiments in separating mixtures of an unknown number of sounds from an open domain of sound types. The dataset consists of 23 hours of single-source audio data drawn from 357 classes, which are used to create mixtures of one to four sources. To simulate reverberation, an acoustic room simulator is used to generate impulse responses of box shaped rooms with frequency-dependent reflective walls. Additional open-source data augmentation tools are also provided to produce new mixtures with different combinations of sources and room simulations. Finally, we introduce an open-source baseline separation model, based on an improved time-domain convolutional network (TDCN++), that can separate a variable number of sources in a mixture. This model achieves 9.8 dB of scale-invariant signal-to-noise ratio improvement (SI-SNRi) on mixtures with two to four sources, while reconstructing single-source inputs with 35.5 dB absolute SI-SNR. We hope this dataset will lower the barrier to new research and allow for fast iteration and application of novel techniques from other machine learning domains to the sound separation challenge.      
### 94.Sound Event Detection and Separation: a Benchmark on Desed Synthetic Soundscapes  [ :arrow_down: ](https://arxiv.org/pdf/2011.00801.pdf)
>  We propose a benchmark of state-of-the-art sound event detection systems (SED). We designed synthetic evaluation sets to focus on specific sound event detection challenges. We analyze the performance of the submissions to DCASE 2021 task 4 depending on time related modifications (time position of an event and length of clips) and we study the impact of non-target sound events and reverberation. We show that the localization in time of sound events is still a problem for SED systems. We also show that reverberation and non-target sound events are severely degrading the performance of the SED systems. In the latter case, sound separation seems like a promising solution.      
### 95.On Control of Epidemics with Application to COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2011.00790.pdf)
>  At the time of writing, the ongoing COVID-19 pandemic, caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), had already resulted in more than thirty-two million cases infected and more than one million deaths worldwide. <br>Given the fact that the pandemic is still threatening health and safety, it is in the urgency to understand the COVID-19 contagion process and know how it might be controlled. With this motivation in mind, in this paper, we consider a version of a stochastic discrete-time Susceptible-Infected-Recovered-Death~(SIRD)-based epidemiological model with two uncertainties: The uncertain rate of infected cases which are undetected or asymptomatic, and the uncertain effectiveness rate of control. Our aim is to study the effect of an epidemic control policy on the uncertain model in a control-theoretic framework. We begin by providing the closed-form solutions of states in the modified SIRD-based model such as infected cases, susceptible cases, recovered cases, and deceased cases. Then, the corresponding expected states and the technical lower and upper bounds for those states are provided as well. Subsequently, we consider two epidemic control problems to be addressed: One is almost sure epidemic control problem and the other average epidemic control problem. Having defined the two problems, our main results are a set of sufficient conditions on a class of linear control policy which assures that the epidemic is "well-controlled"; i.e., both of the infected cases and deceased cases are upper bounded uniformly and the number of infected cases converges to zero asymptotically. Our numerical studies, using the historical COVID-19 contagion data in the United States, suggest that our appealingly simple model and control framework can provide a reasonable epidemic control performance compared to the ongoing pandemic situation.      
### 96.CVC: Contrastive Learning for Non-parallel Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2011.00782.pdf)
>  Cycle consistent generative adversarial network (CycleGAN) and variational autoencoder (VAE) based models have gained popularity in non-parallel voice conversion recently. However, they usually suffer from difficulty in model training and unsatisfactory results. In this paper, we propose CVC, a contrastive learning-based adversarial model for voice conversion. Compared to previous methods, CVC only requires one-way GAN training when it comes to non-parallel one-to-one voice conversion, while improving speech quality and reducing training time. CVC further demonstrates performance improvements in many-to-one voice conversion, enabling the conversion from unseen speakers.      
### 97.Using a Bi-directional LSTM Model with Attention Mechanism trained on MIDI Data for Generating Unique Music  [ :arrow_down: ](https://arxiv.org/pdf/2011.00773.pdf)
>  Generating music is an interesting and challenging problem in the field of machine learning. Mimicking human creativity has been popular in recent years, especially in the field of computer vision and image processing. With the advent of GANs, it is possible to generate new similar images, based on trained data. But this cannot be done for music similarly, as music has an extra temporal dimension. So it is necessary to understand how music is represented in digital form. When building models that perform this generative task, the learning and generation part is done in some high-level representation such as MIDI (Musical Instrument Digital Interface) or scores. This paper proposes a bi-directional LSTM (Long short-term memory) model with attention mechanism capable of generating similar type of music based on MIDI data. The music generated by the model follows the theme/style of the music the model is trained on. Also, due to the nature of MIDI, the tempo, instrument, and other parameters can be defined, and changed, post generation.      
### 98.Multitask Learning and Joint Optimization for Transformer-RNN-Transducer Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2011.00771.pdf)
>  Recently, several types of end-to-end speech recognition methods named transformer-transducer were introduced. According to those kinds of methods, transcription networks are generally modeled by transformer-based neural networks, while prediction networks could be modeled by either transformers or recurrent neural networks (RNN). This paper explores multitask learning, joint optimization, and joint decoding methods for transformer-RNN-transducer systems. Our proposed methods have the main advantage in that the model can maintain information on the large text corpus. We prove their effectiveness by performing experiments utilizing the well-known ESPNET toolkit for the widely used Librispeech datasets. We also show that the proposed methods can reduce word error rate (WER) by 16.6 % and 13.3 % for test-clean and test-other datasets, respectively, without changing the overall model structure nor exploiting an external LM.      
### 99.Data-Driven Approximation of the Perron-Frobenius Operator Using the Wasserstein Metric  [ :arrow_down: ](https://arxiv.org/pdf/2011.00759.pdf)
>  This manuscript introduces a regression-type formulation for approximating the Perron-Frobenius Operator by relying on distributional snapshots of data. These snapshots may represent densities of particles. The Wasserstein metric is leveraged to define a suitable functional optimization in the space of distributions. The formulation allows seeking suitable dynamics so as to interpolate the distributional flow in function space. A first-order necessary condition for optimality is derived and utilized to construct a gradient flow approximating algorithm. The framework is exemplied with numerical simulations.      
### 100.BayesBeat: A Bayesian Deep Learning Approach for Atrial Fibrillation Detection from Noisy Photoplethysmography Data  [ :arrow_down: ](https://arxiv.org/pdf/2011.00753.pdf)
>  The increasing popularity of smartwatches as affordable and longitudinal monitoring devices enables us to capture photoplethysmography (PPG) sensor data for detecting Atrial Fibrillation (AF) in real-time. A significant challenge in AF detection from PPG signals comes from the inherent noise in the smartwatch PPG signals. In this paper, we propose a novel deep learning based approach, BayesBeat that leverages the power of Bayesian deep learning to accurately infer AF risks from noisy PPG signals, and at the same time provide the uncertainty estimate of the prediction. Bayesbeat is efficient, robust, flexible, and highly scalable which makes it particularly suitable for deployment in commercially available wearable devices. Extensive experiments on a recently published large dataset reveal that our proposed method BayesBeat substantially outperforms the existing state-of-the-art methods.      
### 101.An interactive sequential-decision benchmark from geosteering  [ :arrow_down: ](https://arxiv.org/pdf/2011.00733.pdf)
>  Geosteering workflows are increasingly based on the quantification of subsurface uncertainties during real-time operations. As a consequence operational decision making is becoming both better informed and more complex. This paper presents an experimental web-based decision support system, which can be used to both aid expert decisions under uncertainty or further develop decision optimization algorithms in controlled environment. A user of the system (either human or AI) controls the decisions to steer the well or stop drilling. Whenever a user drills ahead, the system produces simulated measurements along the selected well trajectory which are used to update the uncertainty represented by model realizations using the ensemble Kalman filter. To enable informed decisions the system is equipped with functionality to evaluate the value of the selected trajectory under uncertainty with respect to the objectives of the current experiment. <br>To illustrate the utility of the system as a benchmark, we present the initial experiment, in which we compare the decision skills of geoscientists with those of a recently published automatic decision support algorithm. The experiment and the survey after it showed that most participants were able to use the interface and complete the three test rounds. At the same time, the automated algorithm outperformed 28 out of 29 qualified human participants. <br>Such an experiment is not sufficient to draw conclusions about practical geosteering, but is nevertheless useful for geoscience. First, this communication-by-doing made 76% of respondents more curious about and/or confident in the presented technologies. Second, the system can be further used as a benchmark for sequential decisions under uncertainty. This can accelerate development of algorithms and improve the training for decision making.      
### 102.Fundamental Limits of Obfuscation for Linear Gaussian Dynamical Systems: An Information-Theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.00718.pdf)
>  In this paper, we study the fundamental limits of obfuscation in terms of privacy-distortion tradeoffs for linear Gaussian dynamical systems via an information-theoretic approach. Particularly, we obtain analytical formulas that capture the fundamental privacy-distortion tradeoffs when privacy masks are to be added to the outputs of the dynamical systems, while indicating explicitly how to design the privacy masks in an optimal way: The privacy masks should be colored Gaussian with power spectra shaped specifically based upon the system and noise properties.      
### 103.Learning generic feature representation with synthetic data for weakly-supervised sound event detection by inter-frame distance loss  [ :arrow_down: ](https://arxiv.org/pdf/2011.00695.pdf)
>  Due to the limitation of strong-labeled sound event detection data set, using synthetic data to improve the sound event detection system performance has been a new research focus. In this paper, we try to exploit the usage of synthetic data to improve the feature representation. Based on metric learning, we proposed inter-frame distance loss function for domain adaptation, and prove the effectiveness of it on sound event detection. We also applied multi-task learning with synthetic data. We find the the best performance can be achieved when the two methods being used together. The experiment on DCASE 2018 task 4 test set and DCASE 2019 task 4 synthetic set both show competitive results.      
### 104.Multi-Modal Active Learning for Automatic Liver Fibrosis Diagnosis based on Ultrasound Shear Wave Elastography  [ :arrow_down: ](https://arxiv.org/pdf/2011.00694.pdf)
>  With the development of radiomics, noninvasive diagnosis like ultrasound (US) imaging plays a very important role in automatic liver fibrosis diagnosis (ALFD). Due to the noisy data, expensive annotations of US images, the application of Artificial Intelligence (AI) assisting approaches encounters a bottleneck. Besides, the use of mono-modal US data limits the further improve of the classification results. In this work, we innovatively propose a multi-modal fusion network with active learning (MMFN-AL) for ALFD to exploit the information of multiple modalities, eliminate the noisy data and reduce the annotation cost. Four image modalities including US and three types of shear wave elastography (SWEs) are exploited. A new dataset containing these modalities from 214 candidates is well-collected and pre-processed, with the labels obtained from the liver biopsy results. Experimental results show that our proposed method outperforms the state-of-the-art performance using less than 30% data, and by using only around 80% data, the proposed fusion network achieves high AUC 89.27% and accuracy 70.59%.      
### 105.Stability and Transparency in Series Elastic Actuation: A Two-Port Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2011.00664.pdf)
>  Series Elastic Actuation (SEA) is a widely-used approach for interaction control, as it enables high fidelity and robust force control, improving the safety of physical human-robot interaction (pHRI). In the design of pHRI systems, safety is an imperative design criterion that limits interaction performance, since there exists a fundamental trade-off between the stability robustness and rendering performance. The safety of interaction necessitates coupled stability to ensure the closed-loop stability of a pHRI system when coupled to a wide range of unknown operators and environments. The frequency-domain passivity framework provides powerful analysis tools to study the coupled stability of linear time-invariant systems. In the literature, coupled stability of one-port models of SEA has been studied for various controllers while rendering certain basic environments, and the necessary and sufficient conditions for such passive terminations have been derived. In this study, we extend the one-port passivity analyzes provided in the literature and provide the necessary and sufficient condition for two-port passivity of SEA under velocity-sourced impedance control. Based on the newly established conditions, we derive non-conservative passivity bounds for a virtual coupler. We also prove the need for a physical damping term in parallel to the series elastic element to ensure two-port passivity, even when a virtual coupler is present. Finally, we validate our theoretical results through numerical simulations and by reproducing one-port passivity results as special cases of our results that correspond to appropriate one-port terminations.      
### 106.Efficient Solutions for the Multidimensional Sparse Turnpike Problem  [ :arrow_down: ](https://arxiv.org/pdf/2011.00619.pdf)
>  The turnpike problem of recovering a set of points in $\mathbb{R}^D$ from the set of their pairwise differences is a classic inverse problem in combinatorics. This problem or variants arise in a number of applications, prominently including bioinformatics and imaging, where it is intimately related to the phase retrieval problem of recovering a signal from magnitude-only measurements of its Fourier transform. We propose the Multidimensional Intersection Sparse Phase Retrieval (MISTR) algorithm for solving the turnpike problem in dimension $D \geq 2$. By taking advantage of the structure of multiple dimensions, we are able to achieve the same accuracy as the best one-dimensional algorithms in less time. We prove theoretically that MISTR correctly recovers most signals distributed as a Gaussian point process as long as sparsity is at most $O\left(N^{D(1/2 - \delta)}\right)$. Detailed and reproducible numerical experiments demonstrate the effectiveness of our algorithm, showing that in practice MISTR enjoys $O\left(k^2\log{k}\right)$ average-case time complexity, nearly linear in the size of the input. This represents a substantial improvement over existing one-dimensional algorithms.      
### 107.Incremental Model Building Homotopy Approach for Solving Exact AC-Constrained Optimal Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2011.00587.pdf)
>  Alternating-Current Optimal Power Flow (AC-OPF) is framed as a NP-hard non-convex optimization problem that solves for the most economical dispatch of grid generation given the AC-network and device constraints. Although there are no standard methodologies for obtaining the global optimum for the problem, there is considerable interest from planning and operational engineers in finding a local optimum. Nonetheless, solving for the local optima of a large AC-OPF problem is challenging and time-intensive, as none of the leading non-linear optimization toolboxes can provide any timely guarantees of convergence. To provide robust local convergence for large complex systems, we introduce a homotopy-based approach that solves a sequence of primal-dual interior point problems. We utilize the physics of the grid to develop the proposed homotopy method and demonstrate the efficacy of this approach on U.S. Eastern Interconnection sized test networks.      
### 108.Autonomous Extraction of Gleason Patterns for Grading Prostate Cancer using Multi-Gigapixel Whole Slide Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.00527.pdf)
>  Prostate cancer (PCa) is the second deadliest form of cancer in males. The severity of PCa can be clinically graded through the Gleason scores obtained by examining the structural representation of Gleason cellular patterns. This paper presents an asymmetric encoder-decoder model that integrates a novel hierarchical decomposition block to exploit the feature representations pooled across various scales and then fuses them together to generate the Gleason cellular patterns using the whole slide images. Furthermore, the proposed network is penalized through a novel three-tiered hybrid loss function which ensures that the proposed model accurately recognizes the cluttered regions of the cancerous tissues despite having similar contextual and textural characteristics. We have rigorously tested the proposed network on 10,516 whole slide scans (containing around 71.7M patches), where the proposed model achieved 3.59\% improvement over state-of-the-art scene parsing, encoder-decoder, and fully convolutional networks in terms of intersection-over-union.      
### 109.Optimal minimal-contact customer routing through grocery stores  [ :arrow_down: ](https://arxiv.org/pdf/2011.00472.pdf)
>  Grocery shopping has remained an essential activity even during the peak of the COVID-19 pandemic. In this context, we present an optimization framework for identifying routes through a grocery store that eliminate or minimize contacts between customers at grocery stock points while also minimizing the time spent within the store. We develop a discrete-event simulation of the customer arrival process, and simulate the arrival of customers with varying shopping list sizes and movement patterns. We then present two optimization formulations for generating optimal shopping routes on a real-time basis for each customer arriving to the store given the route information of other customers already present in the store. The first formulation eliminates contacts between customers whereas the second minimizes contacts between customers. Both formulations are mixed-integer problems based on extensions to the Miller-Tucker-Zemlin formulation of the traveling salesman problem. We also explore an alternate scenario for the deployment of these formulations wherein the customers and the store can plan visits ahead of time. This framework can be applied to more general contexts wherein minimizing contacts between randomly arriving agents needing to visit a subset of nodes in a connected network is required.      
### 110.Impact of Low-Resolution ADC on DOA Estimation Performance for Massive MIMO Receive Array  [ :arrow_down: ](https://arxiv.org/pdf/2011.00451.pdf)
>  In this paper, we present a new scenario of direction of arrival (DOA) estimation using massive multiple-input multiple-output (MIMO) receive array with low-resolution analog-to-digital convertors (ADCs), which can strike a good balance between performance and circuit cost. Based on the linear additive quantization noise model (AQNM), the conventional Root-MUSIC methods are modified to be suitable for such as scenario. Also, the Cramer-Rao lower bound (CRLB) is derived to evaluate the performance loss due to the low-resolution quantization. The simulation results show that the modified Root-MUSIC methods can achieve the corresponding CRLB, and the CRLB performance loss is less than 0.5dB in the low SNR region even when the 2-bit ADCs are adopted. This means that 2-bit is sufficient for DOA measurement in the low SNR region if the 0.5dB performance loss is acceptable for practical applications.      
### 111.Impacts of Game-Theoretic Activation on Epidemic Spread over Dynamical Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00445.pdf)
>  We investigate the evolution of epidemics over dynamical networks when nodes choose to interact with others in a selfish and decentralized manner. Specifically, we analyze the susceptible-asymptomatic-infected-recovered (SAIR) epidemic in the framework of activity-driven networks with heterogeneous node degrees and time-varying activation rates, and derive both individual and degree-based mean-field approximations of the exact state evolution. We then present a game-theoretic model where nodes choose their activation probabilities in a strategic manner using current state information as feedback, and characterize the quantal response equilibrium (QRE) of the proposed setting. We then consider the activity-driven susceptible-infected-susceptible (SIS) epidemic model, characterize equilibrium activation probabilities and analyze epidemic evolution in closed-loop. Our numerical results provide compelling insights into epidemic evolution under game-theoretic activation. Specifically, for the SAIR epidemic, we show that under suitable conditions, the epidemic can persist, as any decrease in infected proportion is counteracted by an increase in activity rates by the nodes. For the SIS epidemic, we show that in regimes where there is an endemic state, the infected proportion could be significantly smaller under game-theoretic activation if the loss upon infection is sufficiently high.      
### 112.Collision Avoidance in Tightly-Constrained Environments without Coordination: a Hierarchical Control Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.00413.pdf)
>  We present a hierarchical control approach for maneuvering an autonomous vehicle (AV) in a tightly-constrained environment where other moving AVs and/or human driven vehicles are present. A two-level hierarchy is proposed: a high-level data-driven strategy predictor and a lower-level model-based feedback controller. The strategy predictor maps a high-dimensional environment encoding into a set of high-level strategies. Our approach uses data collected on an offline simulator to train a neural network model as the strategy predictor. Depending on the online selected strategy, a set of time-varying hyperplanes in the AV's motion space is generated and included in the lower level control. The latter is a Strategy-Guided Optimization-Based Collision Avoidance (SG-OBCA) algorithm where the strategy-dependent hyperplane constraints are used to drive a model-based receding horizon controller towards a predicted feasible area. The strategy also informs switching from the SG-OBCA control policy to a safety or emergency control policy. We demonstrate the effectiveness of the proposed data-driven hierarchical control framework in simulations and experiments on a 1/10 scale autonomous car platform where the strategy-guided approach outperforms a model predictive control baseline in both cases.      
### 113.CityPM: Predictive Monitoring with Logic-Calibrated Uncertainty for Smart Cities  [ :arrow_down: ](https://arxiv.org/pdf/2011.00384.pdf)
>  We present CityPM, a novel predictive monitoring system for smart cities, that continuously generates sequential predictions of future city states using Bayesian deep learning and monitors if the generated predictions satisfy city safety and performance requirements. We formally define a flowpipe signal to characterize prediction outputs of Bayesian deep learning models, and develop a new logic, named {Signal Temporal Logic with Uncertainty} (STL-U), for reasoning about the correctness of flowpipe signals. CityPM can monitor city requirements specified in STL-U such as "with 90% confidence level, the predicated air quality index in the next 10 hours should always be below 100". We also develop novel STL-U logic-based criteria to measure uncertainty for Bayesian deep learning. CityPM uses these logic-calibrated uncertainty measurements to select and tune the uncertainty estimation schema in deep learning models. We evaluate CityPM on three large-scale smart city case studies, including two real-world city datasets and one simulated city experiment. The results show that CityPM significantly improves the simulated city's safety and performance, and the use of STL-U logic-based criteria leads to improved uncertainty calibration in various Bayesian deep learning models.      
### 114.Uplink Transmission Design for Crowded Correlated Cell-Free Massive MIMO-OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.00203.pdf)
>  In cell-free massive multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) systems, user equipments (UEs) are served by many distributed access points (APs), where channels are correlated due to finite angle-delay spread in realistic outdoor wireless propagation environments. Meanwhile, the number of UEs is growing rapidly for future fully networked society. In this paper, we focus on the uplink transmission design in crowded correlated cell-free massive MIMO-OFDM systems with limited number of orthogonal pilots. For the pilot transmission phase, we identify active UEs based on non-orthogonal pilot phase shift hopping patterns and non-orthogonal adjustable phase shift pilots (APSP). We derive a closed-form expression of mean square error of channel estimation (MSE-CE) and obtain an optimal condition for minimizing MSE-CE. According to this condition, the APSP set allocation scheme is proposed. Furthermore, for the data transmission, the max-min power control algorithm is devised to maximize the minimum spectral efficiency (SE) lower bound among active UEs. Simulation results indicate significant performance gains in terms of MSE-CE for the proposed APSP set allocation scheme. The proposed power control scheme can further improve the minimum SE among active UEs. Hence, they are crucial for crowded correlated cell-free massive MIMO-OFDM systems.      
### 115.The xx205 System for the VoxCeleb Speaker Recognition Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2011.00200.pdf)
>  This report describes the systems submitted to the first and second tracks of the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020, which ranked second in both tracks. Three key points of the system pipeline are explored: (1) investigating multiple CNN architectures including ResNet, Res2Net and dual path network (DPN) to extract the x-vectors, (2) using a composite angular margin softmax loss to train the speaker models, and (3) applying score normalization and system fusion to boost the performance. Measured on the VoxSRC-20 Eval set, the best submitted systems achieve an EER of $3.808\%$ and a MinDCF of $0.1958$ in the close-condition track 1, and an EER of $3.798\%$ and a MinDCF of $0.1942$ in the open-condition track 2, respectively.      
### 116.A Novel Semi-Supervised Data-Driven Method for Chiller Fault Diagnosis with Unlabeled Data  [ :arrow_down: ](https://arxiv.org/pdf/2011.00187.pdf)
>  In practical chiller systems, applying efficient fault diagnosis techniques can significantly reduce energy consumption and improve energy efficiency of buildings. The success of the existing methods for fault diagnosis of chillers relies on the condition that sufficient labeled data are available for training. However, label acquisition is laborious and costly in practice. Usually, the number of labeled data is limited and most data available are unlabeled. The existing methods cannot exploit the information contained in unlabeled data, which significantly limits the improvement of fault diagnosis performance in chiller systems. To make effective use of unlabeled data to further improve fault diagnosis performance and reduce the dependency on labeled data, we proposed a novel semi-supervised data-driven fault diagnosis method for chiller systems based on the semi-generative adversarial network, which incorporates both unlabeled and labeled data into learning process. The semi-generative adversarial network can learn the information of data distribution from unlabeled data and this information can help to significantly improve the diagnostic performance. Experimental results demonstrate the effectiveness of the proposed method. Under the scenario that there are only 80 labeled samples and 16000 unlabeled samples, the proposed method can improve the diagnostic accuracy to 84%, while the supervised baseline methods only reach the accuracy of 65% at most. Besides, the minimal required number of labeled samples can be reduced by about 60% with the proposed method when there are enough unlabeled samples.      
### 117.EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2011.00101.pdf)
>  Research and development of electroencephalogram (EEG) based brain-computer interfaces (BCIs) have advanced rapidly, partly due to the wide adoption of sophisticated machine learning approaches for decoding the EEG signals. However, recent studies have shown that machine learning algorithms are vulnerable to adversarial attacks, e.g., the attacker can add tiny adversarial perturbations to a test sample to fool the model, or poison the training data to insert a secret backdoor. Previous research has shown that adversarial attacks are also possible for EEG-based BCIs. However, only adversarial perturbations have been considered, and the approaches are theoretically sound but very difficult to implement in practice. This article proposes to use narrow period pulse for poisoning attack of EEG-based BCIs, which is more feasible in practice and has never been considered before. One can create dangerous backdoors in the machine learning model by injecting poisoning samples into the training set. Test samples with the backdoor key will then be classified into the target class specified by the attacker. What most distinguishes our approach from previous ones is that the backdoor key does not need to be synchronized with the EEG trials, making it very easy to implement. The effectiveness and robustness of the backdoor attack approach is demonstrated, highlighting a critical security concern for EEG-based BCIs.      
### 118.(Un)Masked COVID-19 Trends from Social Media  [ :arrow_down: ](https://arxiv.org/pdf/2011.00052.pdf)
>  COVID-19 has affected the entire world. One useful protection method for people against COVID-19 is to wear masks in public areas. Across the globe, many public service providers have mandated correctly wearing masks to use their services. This paper proposes two new datasets VAriety MAsks - Classification VAMA-C) and VAriety MAsks - Segmentation (VAMA-S), for mask detection and mask fit analysis tasks, respectively. We propose a framework for classifying masked and unmasked faces and a segmentation based model to calculate the mask-fit score. Both the models trained in this study achieved an accuracy of 98%. Using the two trained deep learning models, 2.04 million social media images for six major US cities were analyzed. By comparing the regulations, an increase in masks worn in images as the COVID-19 cases rose in these cities was observed, particularly when their respective states imposed strict regulations. Furthermore, mask compliance in the Black Lives Matter protest was analyzed, eliciting that 40% of the people in group photos wore masks, and 45% of them wore the masks with a fit score of greater than 80%.      
### 119.Resource-Efficient Quantum Computing by Breaking Abstractions  [ :arrow_down: ](https://arxiv.org/pdf/2011.00028.pdf)
>  Building a quantum computer that surpasses the computational power of its classical counterpart is a great engineering challenge. Quantum software optimizations can provide an accelerated pathway to the first generation of quantum computing applications that might save years of engineering effort. Current quantum software stacks follow a layered approach similar to the stack of classical computers, which was designed to manage the complexity. In this review, we point out that greater efficiency of quantum computing systems can be achieved by breaking the abstractions between these layers. We review several works along this line, including two hardware-aware compilation optimizations that break the quantum Instruction Set Architecture (ISA) abstraction and two error-correction/information-processing schemes that break the qubit abstraction. Last, we discuss several possible future directions.      
### 120.Molecular Communications in Viral Infections Research: Modelling, Experimental Data and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2011.00002.pdf)
>  Hundreds of millions of people worldwide are affected by viral infections each year, and yet, several of them neither have vaccines nor effective treatment during and post-infection. This challenge has been highlighted by the COVID-19 pandemic, showing how viruses can quickly spread and how they can impact society as a whole. Novel techniques that bring in different disciplines must emerge to provide forward-looking strategies to combat viral infections, as well as possible future pandemics. In the past decade, an interdisciplinary area involving bioengineering, nanotechnology and information and communication technology (ICT) has been developing, known as Molecular Communications. This new emerging area uses elements of classical communication systems and maps it to molecular signalling and communication found inside and outside the body, where the aim is to develop new tools that can serve future medicine. In this paper, we provide an extensive and detailed discussion on how Molecular Communications can be integrated into the research on viral infectious diseases modelling, and how possible treatment and vaccines can be developed considering molecules as information carriers. We provide a literature review on the existing models of Molecular Communications for viral infection (in-body and out-body), a deep analysis on their effects on the host and subsequent communication process for other systems within the body (e.g., immune response), sources of experimental data on known viral infections and how it can be used by the Molecular Communications community, as well as open issues and future directions. Since the development of therapeutics/vaccines needs an interdisciplinary approach centred around ICT, we are confident that Molecular Communications can play a central role here by providing a detail characterisation and manipulation of the propagation of molecules in different media.      
### 121.Policy Iterations for Reinforcement Learning Problems in Continuous Time and Space -- Fundamental Theory and Methods  [ :arrow_down: ](https://arxiv.org/pdf/1705.03520.pdf)
>  Policy iteration (PI) is a recursive process of policy evaluation and improvement for solving an optimal decision-making/control problem, or in other words, a reinforcement learning (RL) problem. PI has also served as the fundamental for developing RL methods. In this paper, we propose two PI methods, called differential PI (DPI) and integral PI (IPI), and their variants, for a general RL framework in continuous time and space (CTS), where the environment is modeled by a system of ordinary differential equations (ODEs). The proposed methods inherit the current ideas of PI in classical RL and optimal control and theoretically support the existing RL algorithms in CTS: TD-learning and value-gradient-based (VGB) greedy policy update. We also provide case studies including 1) discounted RL and 2) optimal control tasks. Fundamental mathematical properties -- admissibility, uniqueness of the solution to the Bellman equation (BE), monotone improvement, convergence, and optimality of the solution to the Hamilton-Jacobi-Bellman equation (HJBE) -- are all investigated in-depth and improved from the existing theory, along with the general and case studies. Finally, the proposed ones are simulated with an inverted-pendulum model and their model-based and partially model-free implementations to support the theory and further investigate them beyond.      

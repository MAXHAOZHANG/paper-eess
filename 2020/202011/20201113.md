# ArXiv eess --Fri, 13 Nov 2020
### 1.Evaluating the Intelligibility Benefits of Neural Speech Enrichment for Listeners with Normal Hearing and Hearing Impairment using the Greek Harvard Corpus  [ :arrow_down: ](https://arxiv.org/pdf/2011.06548.pdf)
>  In this work we evaluate a neural based speech intelligibility booster based on spectral shaping and dynamic range compression (SSDRC), referred to as WaveNet-based SSDRC (wSSDRC), using a recently designed Greek Harvard-style corpus. The corpus has been developed according to the format of the Harvard/IEEE sentences and offers the opportunity to apply neural speech enhancement models and examine their performance gain for Greek listeners. wSSDRC has been successfully tested for English material and speakers in the past. In this paper we revisit wSSDRC to perform a full scale evaluation of the model with Greek listeners under the condition of equal energy before and after modification. Both normal hearing (NH) and hearing impaired (HI) listeners evaluated the model under speech shaped noise (SSN) at listener-specific SNRs matching their Speech Reception Threshold (SRT) - a point at which 50 % of unmodified speech is intelligible. The analysis statistics show that the wSSDRC model has produced a median intelligibility boost of 39% for NH and 38% for HI, relative to the plain unprocessed speech.      
### 2.Accelerated calibrationless parallel transmit mapping using joint transmit and receive low-rank tensor completion  [ :arrow_down: ](https://arxiv.org/pdf/2011.06471.pdf)
>  Purpose: To evaluate an algorithm for calibrationless parallel imaging to reconstruct undersampled parallel transmit field maps for the body and brain. <br>Methods: Using synthetic data, body, and brain measurements of relative transmit maps, three different approaches to a joint transmit-receive low-rank tensor completion algorithm are evaluated. These methods included: (i) virtual coils using the product of receive and transmit sensitivities, (ii) joint-receiver coils that enforces a low rank structure across receive coils of all transmit modes, and (iii) transmit low rank (TxLR) that uses a low rank structure for both receive and transmit modes simultaneously. The performance of each are investigated for different noise levels and different acceleration rates on an 8-channel parallel transmit 7T system. <br>Results: The virtual coils method broke down with increasing noise levels or acceleration rates greater than two producing RMS error greater than 0.1. The joint receiver coils method worked well up to acceleration factors of four, beyond which the RMS error exceeded 0.1. While TxLR enabled an eight-fold acceleration with most RMS errors remaining below 0.1. <br>Conclusion: This work demonstrates that under-sampling factors of up to eight-fold are feasible for transmit array mapping and can be reconstructed using calibrationless parallel imaging methods.      
### 3.Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2011.06465.pdf)
>  Prosody modeling is an essential component in modern text-to-speech (TTS) frameworks. By explicitly providing prosody features to the TTS model, the style of synthesized utterances can thus be controlled. However, predicting natural and reasonable prosody at inference time is challenging. In this work, we analyzed the behavior of non-autoregressive TTS models under different prosody-modeling settings and proposed a hierarchical architecture, in which the prediction of phoneme-level prosody features are conditioned on the word-level prosody features. The proposed method outperforms other competitors in terms of audio quality and prosody naturalness in our objective and subjective evaluation.      
### 4.Secure Identification for Gaussian Channels and Identification for Multi-Antenna Gaussian Channels  [ :arrow_down: ](https://arxiv.org/pdf/2011.06443.pdf)
>  New applications in modern communications are demanding robust and ultra-reliable low latency information exchange such as machine-to-machine and human-to-machine communications. For many of these applications, the identification approach of Ahlswede and Dueck is much more efficient than the classical message transmission scheme proposed by Shannon. Previous studies concentrate mainly on identification over discrete channels. For discrete channels, it was proved that identification is robust under channels uncertainty. Furthermore, optimal identification schemes that are secure and robust against jamming attacks have been considered. However, no results for continuous channels have yet been established. That is why we focus on the continuous case: the Gaussian channel for its known practical relevance. We deal with secure identification over Gaussian channels. Provable secure communication is of a high interest for future communication systems. A key technique for implementing secure communication is the physical layer security based on information theoretic security. We model this with the wiretap channel. In particular, we provide a suitable coding scheme for the Gaussian wiretap channel (GWC) and determine the corresponding secure identification capacity. We also consider Multiple-Input Multiple-Output (MIMO) Gaussian channels and provide an efficient signal-processing scheme. This scheme allows a separation of signal-processing and Gaussian coding.      
### 5.First steps toward a simple but efficient model-free control synthesis for variable-speed wind turbines  [ :arrow_down: ](https://arxiv.org/pdf/2011.06415.pdf)
>  Although variable-speed three-blade wind turbines are nowadays quite popular, their control remains a challenging task. We propose a new easily implementable model-free control approach with the corresponding intelligent controllers. Several convincing computer simulations, including some fault accommodations, shows that model-free controllers are more efficient and robust than classic proportional-integral controllers.      
### 6.Curved Holographic Optical Elements from a Geometric View Point  [ :arrow_down: ](https://arxiv.org/pdf/2011.06414.pdf)
>  We present a geometric framework to model the optical effects of deformations of planar holographic optical elements (HOE) into curved surfaces, such as sphere segments. In particular, we consider deformations which do not preserve the Gaussian curvature.      
### 7.End-to-end optimized image compression for machines, a study  [ :arrow_down: ](https://arxiv.org/pdf/2011.06409.pdf)
>  An increasing share of image and video content is analyzed by machines rather than viewed by humans, and therefore it becomes relevant to optimize codecs for such applications where the analysis is performed remotely. Unfortunately, conventional coding tools are challenging to specialize for machine tasks as they were originally designed for human perception. However, neural network based codecs can be jointly trained end-to-end with any convolutional neural network (CNN)-based task model. In this paper, we propose to study an end-to-end framework enabling efficient image compression for remote machine task analysis, using a chain composed of a compression module and a task algorithm that can be optimized end-to-end. We show that it is possible to significantly improve the task accuracy when fine-tuning jointly the codec and the task networks, especially at low bit-rates. Depending on training or deployment constraints, selective fine-tuning can be applied only on the encoder, decoder or task network and still achieve rate-accuracy improvements over an off-the-shelf codec and task network. Our results also demonstrate the flexibility of end-to-end pipelines for practical applications.      
### 8.Deep machine learning-assisted multiphoton microscopy to reduce light exposure and expedite imaging  [ :arrow_down: ](https://arxiv.org/pdf/2011.06408.pdf)
>  Two-photon excitation fluorescence (2PEF) allows imaging of tissue up to about one millimeter in thickness. Typically, reducing fluorescence excitation exposure reduces the quality of the image. However, using deep learning super resolution techniques, these low-resolution images can be converted to high-resolution images. This work explores improving human tissue imaging by applying deep learning to maximize image quality while reducing fluorescence excitation exposure. We analyze two methods: a method based on U-Net, and a patch-based regression method. Both methods are evaluated on a skin dataset and an eye dataset. The eye dataset includes 1200 paired high power and low power images of retinal organoids. The skin dataset contains multiple frames of each sample of human skin. High-resolution images were formed by averaging 70 frames for each sample and low-resolution images were formed by averaging the first 7 and 15 frames for each sample. The skin dataset includes 550 images for each of the resolution levels. We track two measures of performance for the two methods: mean squared error (MSE) and structural similarity index measure (SSIM). For the eye dataset, the patches method achieves an average MSE of 27,611 compared to 146,855 for the U-Net method, and an average SSIM of 0.636 compared to 0.607 for the U-Net method. For the skin dataset, the patches method achieves an average MSE of 3.768 compared to 4.032 for the U-Net method, and an average SSIM of 0.824 compared to 0.783 for the U-Net method. Despite better performance on image quality, the patches method is worse than the U-Net method when comparing the speed of prediction, taking 303 seconds to predict one image compared to less than one second for the U-Net method.      
### 9.Sensor Placement for Contamination Detection in Water Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.06406.pdf)
>  Sensor placement for contaminant detection in water distribution systems (WDS) has become a topic of great interest aiming to secure a population's water supply. Several approaches can be found in the literature with differences ranging from the objective selected to optimize to the methods implemented to solve the optimization problem. In this work we aim to give an overview of the current work in sensor placement with focus on contaminant detection for WDS. We present some of the objectives for which the sensor placement problem is defined along with common optimization algorithms and Toolkits available to help with algorithm testing and comparison.      
### 10.Extended Dynamics Observer for Linear Systems with Disturbance  [ :arrow_down: ](https://arxiv.org/pdf/2011.06383.pdf)
>  This is the last part of four series papers, aiming at stabilization for signal-input-signaloutput (SISO) linear finite-dimensional systems corrupted by general input disturbances. A new observer, referred to as Extended Dynamics Observer (EDO), is proposed to estimate both the state and disturbance simultaneously. The working mechanism of EDO consists of two parts: The disturbance with known dynamics is canceled completely by its dynamics and the disturbance with unknown dynamics is absorbed by high-gain. It is found that the high-gain is always working as long as the control plant with unknown input disturbance is observable which is the only assumption for the observer design. When the disturbance dynamics are completely unknown except some boundedness, the EDO is reduced to an extension of the well-known extended state observer or high-gain observer. The main advantage of the developed method is that the prior information about both the control plant and the disturbance can be utilized as much as possible. The more the prior information we have, the better performance the observer would be. An EDO based stabilizing output feedback is also developed in the spirit of estimation/cancellation strategy. The stability of the resulting closed-loop system is established and some of the theoretical results are validated by numerical simulations.      
### 11.Low PAPR waveform design for OFDM SYSTEM based on Convolutional Auto-Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2011.06349.pdf)
>  This paper introduces the architecture of a convolutional autoencoder (CAE) for the task of peak-to-average power ratio (PAPR) reduction and waveform design, for orthogonal frequency division multiplexing (OFDM) systems. The proposed architecture integrates a PAPR reduction block and a non-linear high power amplifier (HPA) model. We apply gradual loss learning for multi-objective optimization. We analyze the models performance by examining the bit error rate (BER), the PAPR and the spectral response, and comparing them with common PAPR reduction algorithms.      
### 12.Hardware Complexity Aware Design Strategy for a Fused Logarithmic and Anti-Logarithmic Converter  [ :arrow_down: ](https://arxiv.org/pdf/2011.06341.pdf)
>  The logarithmic and anti-logarithmic converters are realized with the piecewise linear approximation method, which is implemented by the shift-and-add architecture. This brief utilizes the similarities of Log and Antilog functions so that the adder tree block and multiplexer block can be shared by the Log and Antilog converters. As a result, the Antilog function can be implemented by the Log converter at the cost of additional 14% area and 6% latency. It implies the shift-and-add architecture can approximate multiple similar nonlinear functions with a slightly hardware cost. In addition, this brief proposes a set of formulas to predict the area and latency of shift-and-add architecture with different quantized coefficients that can facilitate the finding of a trade-off point in the Latency-Area-Precision space.      
### 13.The CUHK-TUDELFT System for The SLT 2021 Children Speech Recognition Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2011.06239.pdf)
>  This technical report describes our submission to the 2021 SLT Children Speech Recognition Challenge (CSRC) Track 1. Our approach combines the use of a joint CTC-attention end-to-end (E2E) speech recognition framework, transfer learning, data augmentation and development of various language models. Procedures of data pre-processing, the background and the course of system development are described. The analysis of the experiment results, as well as the comparison between the E2E and DNN-HMM hybrid system are discussed in detail. Our system achieved a character error rate (CER) of 20.1% in our designated test set, and 23.6% in the official evaluation set, which is placed at 10-th overall.      
### 14.Decomposing Normal and Abnormal Features of Medical Images for Content-based Image Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2011.06224.pdf)
>  Medical images can be decomposed into normal and abnormal features, which is considered as the compositionality. Based on this idea, we propose an encoder-decoder network to decompose a medical image into two discrete latent codes: a normal anatomy code and an abnormal anatomy code. Using these latent codes, we demonstrate a similarity retrieval by focusing on either normal or abnormal features of medical images.      
### 15.Recursive Regret Matching: A General Method for Solving Time-invariant Nonlinear Zero-sum Differential Games  [ :arrow_down: ](https://arxiv.org/pdf/2011.06209.pdf)
>  In this paper, a new method is proposed to compute the rolling Nash equilibrium of the time-invariant nonlinear two-person zero-sum differential games. The idea is to discretize the time to transform a differential game into a sequential game with several steps, and by introducing state-value function, transform the sequential game into a recursion consisting of several normal-form games, finally, each normal-form game is solved with action abstraction and regret matching. To improve the real-time property of the proposed method, the state-value function can be kept in memory. This method can deal with the situations that the saddle point exists or does not exist, and the analysises of the existence of the saddle point can be avoided. If the saddle point does not exist, the mixed optimal control pair can be obtained. At the end of this paper, some examples are taken to illustrate the validity of the proposed method.      
### 16.Atrial Fibrillation Detection and ECG Classification based on CNN-BiLSTM  [ :arrow_down: ](https://arxiv.org/pdf/2011.06187.pdf)
>  It is challenging to visually detect heart disease from the electrocardiographic (ECG) signals. Implementing an automated ECG signal detection system can help diagnosis arrhythmia in order to improve the accuracy of diagnosis. In this paper, we proposed, implemented, and compared an automated system using two different frameworks of the combination of convolutional neural network (CNN) and long-short term memory (LSTM) for classifying normal sinus signals, atrial fibrillation, and other noisy signals. The dataset we used is from the MIT-BIT Arrhythmia Physionet. Our approach demonstrated that the cascade of two deep learning network has higher performance than the concatenation of them, achieving a weighted f1 score of 0.82. The experimental results have successfully validated that the cascade of CNN and LSTM can achieve satisfactory performance on discriminating ECG signals.      
### 17.Dynamic Power Balancing Algorithm for Single-Phase Energy Storage Systems in LV Distribution Network with Unbalanced PV Systems Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2011.06181.pdf)
>  Unbalanced power, due to high penetration of single-phase PV rooftops into a four-wire multi-grounded LV distribution system, can result in significant rise in the neutral current and neutral voltage. This preprint proposes a distributed clustering algorithm for dynamic power balancing, using single-phase battery storage systems distributed in the LV distribution system, in order to reduce the neutral current and neutral voltage rise. The distributed clustering algorithm aggregates households connected to the same phase into clusters. Within each cluster, another distributed clustering algorithm is applied to calculate the total grid power exchanged but the corresponding phase. Then, the dynamic power balancing control is applied to balance the powers at the bus, based on battery storage systems' charge/discharge constraints, power minimization and willingness of the households to participate in the power balancing control.      
### 18.Distributed Adaptive and Resilient Control of Multi-Robot Systems with Limited Field of View Interactions using Q-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.06179.pdf)
>  In this paper, we consider the problem of dynamically tuning gains for multi-robot systems (MRS) under potential based control design framework where the MRS team coordinates to maintain a connected topology while equipped with limited field of view sensors. Applying the potential-based control framework and assuming robot interaction is encoded by a triangular geometry, we derive a distributed control law in order to achieve the topology control objective. A typical shortcoming of potential-based control in distributed networks is that the overall system behavior is highly sensitive to gain-tuning. To overcome this limitation, we propose a distributed and adaptive gain controller that preserves a designed pairwise interaction strength, independent of the network size. Over that, we implement a control scheme that enables the MRS to be resilient against exogenous attacks on on-board sensors or actuator of the robots in MRS. In this regard, we model additive sensor and actuator faults which are induced externally to render the MRS unstable. However, applying $H_{\infty}$ control protocols by employing a static output-feedback design technique guarantees bounded $L_2$ gains of the error induced by the sensor and actuator fault signals. Finally, we apply policy iteration based Q-Learning to solve for adaptive gains for the discrete-time MRS. Simulation results are provided to support the theoretical findings.      
### 19.A Two-Stage Radar Sensing Approach based on MIMO-OFDM Technology  [ :arrow_down: ](https://arxiv.org/pdf/2011.06161.pdf)
>  Recently, integrating the communication and sensing functions into a common network has attracted a great amount of attention. This paper considers the advanced signal processing techniques for enabling the radar to sense the environment via the communication signals. Since the technologies of orthogonal frequency division multiplexing (OFDM) and multiple-input multiple-output (MIMO) are widely used in the legacy cellular systems, this paper proposes a two-stage signal processing approach for radar sensing in an MIMO-OFDM system, where the scattered channels caused by various targets are estimated in the first stage, and the location information of the targets is then extracted from their scattered channels in the second stage. Specifically, based on the observations that radar sensing is similar to multi-path communication in the sense that different targets scatter the signal sent by the radar transmitter to the radar receiver with various delay, and that the number of scatters is limited, we show that the OFDM-based channel training approach together with the compressed sensing technique can be utilized to estimate the scattered channels efficiently in Stage I. Moreover, to tackle the challenge arising from range resolution for sensing the location of closely spaced targets, we show that the MIMO radar technique can be leveraged in Stage II such that the radar has sufficient spatial samples to even detect the targets in close proximity based on their scattered channels. Last, numerical examples are provided to show the effectiveness of our proposed sensing approach which merely relies on the existing MIMO-OFDM communication techniques.      
### 20.Limited-view Photoacoustic Imaging Reconstruction With Dual Domain Inputs Under Mutual Information Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2011.06147.pdf)
>  Based on photoacoustic effect, photoacoustic tomography is developing very fast in recent years, and becoming an important imaging tool for both preclinical and clinical studies. With enough ultrasound transducers placed around the biological tissue, PAT can provide both deep penetration and high image contrast by hybrid usage of light and sound. However, considering space and measurement environmental limitations, transducers are always placed in a limited-angle way, which means that the other side without transducer coverage suffers severe information loss. With conventional image reconstruction algorithms, the limited-view tissue induces artifacts and information loss, which may cause doctors misdiagnosis or missed diagnosis. In order to solve limited-view PA imaging reconstruction problem, we propose to use both time domain and frequency domain reconstruction algorithms to get delay-and-sum (DAS) image inputs and k-space image inputs. These dual domain images share nearly same texture information but different artifact information, which can teach network how to distinguish these two kinds of information at input level. In this paper, we propose Dual Domain Unet (DuDoUnet) with specially designed Information Sharing Block (ISB), which can further share two domains' information and distinguish artifacts. Besides, we use mutual information (MI) with an auxiliary network, whose inputs and outputs are both ground truth, to compensate prior knowledge of limited-view PA inputs. The proposed method is verified with a public clinical database, and shows superior results with SSIM = 93.5622% and PSNR = 20.8859.      
### 21.CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2011.06129.pdf)
>  The use of smartphones to take photographs of chest x-rays represents an appealing solution for scaled deployment of deep learning models for chest x-ray interpretation. However, the performance of chest x-ray algorithms on photos of chest x-rays has not been thoroughly investigated. In this study, we measured the diagnostic performance for 8 different chest x-ray models when applied to photos of chest x-rays. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to smartphone photos of x-rays in the CheXphoto dataset without further tuning. We found that several models had a drop in performance when applied to photos of chest x-rays, but even with this drop, some models still performed comparably to radiologists. Further investigation could be directed towards understanding how different model training procedures may affect model generalization to photos of chest x-rays.      
### 22.Efficient Knowledge Distillation for RNN-Transducer Models  [ :arrow_down: ](https://arxiv.org/pdf/2011.06110.pdf)
>  Knowledge Distillation is an effective method of transferring knowledge from a large model to a smaller model. Distillation can be viewed as a type of model compression, and has played an important role for on-device ASR applications. In this paper, we develop a distillation method for RNN-Transducer (RNN-T) models, a popular end-to-end neural network architecture for streaming speech recognition. Our proposed distillation loss is simple and efficient, and uses only the "y" and "blank" posterior probabilities from the RNN-T output probability lattice. We study the effectiveness of the proposed approach in improving the accuracy of sparse RNN-T models obtained by gradually pruning a larger uncompressed model, which also serves as the teacher during distillation. With distillation of 60% and 90% sparse multi-domain RNN-T models, we obtain WER reductions of 4.3% and 12.1% respectively, on a noisy FarField eval set. We also present results of experiments on LibriSpeech, where the introduction of the distillation loss yields a 4.8% relative WER reduction on the test-other dataset for a small Conformer model.      
### 23.A WLAV-based Robust Hybrid State Estimation using Circuit-theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.06021.pdf)
>  For reliable and secure power grid operation, AC state-estimation (ACSE) must provide certain guarantees of convergence while being resilient against bad-data. This paper develops a circuit-theoretic weighted least absolute value (WLAV) based hybrid ACSE that satisfies these needs to overcome some of the limitations of existing ACSE methods. Hybrid refers to the inclusion of RTU and PMU measurement data, and the use of the LAV objective function enables automatic rejection of bad data while providing clear identification of suspicious measurements from the sparse residual vector. Taking advantage of linear construction of the measurement models in circuit-theoretic approach, the proposed hybrid SE is formulated as a LP problem with guaranteed convergence. To address efficiency, we further develop problem-specific heuristics for fast convergence. To validate the efficacy of the proposed approach, we run ACSE on large cases and compare the results against WLS-based algorithms. We further demonstrate the advantages of our solution methodology over standard commercial LP solvers through comparison of runtime and convergence performance.      
### 24.Noncoherent Multiuser Chirp Spread Spectrum: Performance with Doppler and Asynchronism  [ :arrow_down: ](https://arxiv.org/pdf/2011.06575.pdf)
>  In this paper, we investigate multi user chirp spread spectrum with noncoherent detection as a continuation of our work on coherent detection in [1]. We derive the analytical bit error ratio (BER) expression for binary chirp spread spectrum (BCSS) in the presence of multiple access interference (MAI) caused by correlation with other user signals because of either asynchronism or Doppler shifts, or both, and validate with simulations. To achieve this we analyze the signal cross correlations, and compare traditional linear chirps with our recently-proposed nonlinear chirps introduced in [1] and with other nonlinear chirps from the literature. In doing so we illustrate the superior performance of our new nonlinear chirp designs in these practical conditions, for the noncoherent counterpart of [1].      
### 25.Stress Testing Method for Scenario Based Testing of Automated Driving Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.06553.pdf)
>  Classical approaches and procedures for testing of automated vehicles of SAE levels 1 and 2 were based on defined scenarios with specific maneuvers, depending on the function under test. For automated driving systems (ADS) of SAE level 3+, the scenario space is infinite and calling for virtual testing and verification. However, even in simulation, the generation of safety-relevant scenarios for ADS is expensive and time-consuming. This leads to a demand for stochastic and realistic traffic simulation. Therefore, microscopic traffic flow simulation models (TFSM) are becoming a crucial part of scenario-based testing of ADS. In this paper, a co-simulation between the multi-body simulation software IPG CarMaker and the microscopic traffic flow simulation software (TFSS) PTV Vissim is used. Although the TFSS could provide realistic and stochastic behavior of the traffic participants, safety-critical scenarios (SCS) occur rarely. In order to avoid this, a novel Stress Testing Method (STM) is introduced. With this method, traffic participants are manipulated via external driver DLL interface from PTV Vissim in the vicinity of the vehicle under test in order to provoke defined critical maneuvers derived from statistical accident data on highways in Austria. These external driver models imitate human driving errors, resulting in an increase of safety-critical scenarios. As a result, the presented STM method contributes to an increase of safety-relevant scenarios for verification, testing and assessment of ADS.      
### 26.Shared Prior Learning of Energy-Based Models for Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2011.06539.pdf)
>  We propose a novel learning-based framework for image reconstruction particularly designed for training without ground truth data, which has three major building blocks: energy-based learning, a patch-based Wasserstein loss functional, and shared prior learning. In energy-based learning, the parameters of an energy functional composed of a learned data fidelity term and a data-driven regularizer are computed in a mean-field optimal control problem. In the absence of ground truth data, we change the loss functional to a patch-based Wasserstein functional, in which local statistics of the output images are compared to uncorrupted reference patches. Finally, in shared prior learning, both aforementioned optimal control problems are optimized simultaneously with shared learned parameters of the regularizer to further enhance unsupervised image reconstruction. We derive several time discretization schemes of the gradient flow and verify their consistency in terms of Mosco convergence. In numerous numerical experiments, we demonstrate that the proposed method generates state-of-the-art results for various image reconstruction applications--even if no ground truth images are available for training.      
### 27.Image analysis for Alzheimer's disease prediction: Embracing pathological hallmarks for model architecture design  [ :arrow_down: ](https://arxiv.org/pdf/2011.06531.pdf)
>  Alzheimer's disease (AD) is associated with local (e.g. brain tissue atrophy) and global brain changes (loss of cerebral connectivity), which can be detected by high-resolution structural magnetic resonance imaging. Conventionally, these changes and their relation to AD are investigated independently. Here, we introduce a novel, highly-scalable approach that simultaneously captures $\textit{local}$ and $\textit{global}$ changes in the diseased brain. It is based on a neural network architecture that combines patch-based, high-resolution 3D-CNNs with global topological features, evaluating multi-scale brain tissue connectivity. Our local-global approach reached competitive results with an average precision score of $0.95\pm0.03$ for the classification of cognitively normal subjects and AD patients (prevalence $\approx 55\%$).      
### 28.IRS-Assisted Green Communication Systems: Provable Convergence and Robust Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2011.06484.pdf)
>  Intelligent reflecting surfaces (IRSs) are regarded as a key enabler of green wireless communication, due to their capability of customizing favorable wireless propagation environments. In this paper, we investigate resource allocation for IRS-assisted green multiuser multiple-input single-output (MISO) systems. To minimize the total transmit power, both the beamforming vectors at the access point (AP) and the phase shifts at multiple IRSs are jointly optimized, while taking into account the minimum required quality-of-service (QoS) of multiple users. First, two novel algorithms, namely a penalty-based alternating minimization (AltMin) algorithm and an inner approximation (IA) algorithm, are developed to tackle the non-convexity of the formulated optimization problem when perfect channel state information (CSI) is available. Unlike existing designs that cannot ensure convergence, the proposed penalty-based AltMin and IA algorithms are guaranteed to converge to a stationary point and a Karush-Kuhn-Tucker (KKT) solution of the design problem, respectively. Second, the impact of imperfect knowledge of the CSI of the channels between the AP and the users is investigated. To this end, a non-convex robust optimization problem is formulated and the penalty-based AltMin algorithm is extended to obtain a stationary solution. Simulation results reveal a key trade-off between the speed of convergence and the achievable total transmit power for the two proposed algorithms. In addition, we show that the proposed algorithms can significantly reduce the total transmit power at the AP compared to various baseline schemes and that the optimal numbers of transmit antennas and IRS reflecting elements, which minimize the total power consumption of the considered system, are finite.      
### 29.Realization of Stochastic Neural Networks and Its Potential Applications  [ :arrow_down: ](https://arxiv.org/pdf/2011.06427.pdf)
>  Successive Cancellation Decoders have come a long way since the implementation of traditional SC decoders, but there still is a potential for improvement. The main struggle over the years was to find an optimal algorithm to implement them. Most of the proposed algorithms are not practical enough to be implemented in real-life. In this research, we aim to introduce the Efficiency of stochastic neural networks as an SC decoder and Find the possible ways of improving its performance and practicality. In this paper, after a brief introduction to stochastic neurons and SNNs, we introduce methods to realize Stochastic NNs on both deterministic and stochastic platforms.      
### 30.Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker Adaptation and Pronunciation Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2011.06392.pdf)
>  Recent neural Text-to-Speech (TTS) models have been shown to perform very well when enough data is available. However, fine-tuning them towards a new speaker or a new language is not as straight-forward in a low-resource setup. In this paper, we show that by applying minor changes to a Tacotron model, one can transfer an existing TTS model for a new speaker with the same or a different language using only 20 minutes of data. For this purpose, we first introduce a baseline multi-lingual Tacotron with language-agnostic input, then show how transfer learning is done for different scenarios of speaker adaptation without exploiting any pre-trained speaker encoder or code-switching technique. We evaluate the transferred model in both subjective and objective ways.      
### 31.Automatic Neural Lyrics and Melody Composition  [ :arrow_down: ](https://arxiv.org/pdf/2011.06380.pdf)
>  In this paper, we propose a technique to address the most challenging aspect of algorithmic songwriting process, which enables the human community to discover original lyrics, and melodies suitable for the generated lyrics. The proposed songwriting system, Automatic Neural Lyrics and Melody Composition (AutoNLMC) is an attempt to make the whole process of songwriting automatic using artificial neural networks. Our lyric to vector (lyric2vec) model trained on a large set of lyric-melody pairs dataset parsed at syllable, word and sentence levels are large scale embedding models enable us to train data driven model such as recurrent neural networks for popular English songs. AutoNLMC is a encoder-decoder sequential recurrent neural network model consisting of a lyric generator, a lyric encoder and melody decoder trained end-to-end. AutoNLMC is designed to generate both lyrics and corresponding melody automatically for an amateur or a person without music knowledge. It can also take lyrics from professional lyric writer to generate matching melodies. The qualitative and quantitative evaluation measures revealed that the proposed method is indeed capable of generating original lyrics and corresponding melody for composing new songs.      
### 32.Cross Layer Optimization and Distributed Reinforcement Learning Approach for Tile-Based 360 Degree Wireless Video Streaming  [ :arrow_down: ](https://arxiv.org/pdf/2011.06356.pdf)
>  Wirelessly streaming high quality 360 degree videos is still a challenging problem. When there are many users watching different 360 degree videos and competing for the computing and communication resources, the streaming algorithm at hand should maximize the average quality of experience (QoE) while guaranteeing a minimum rate for each user. In this paper, we propose a \emph{cross layer} optimization approach that maximizes the available rate to each user and efficiently uses it to maximize users' QoE. Particularly, we consider a tile based 360 degree video streaming, and we optimize a QoE metric that balances the tradeoff between maximizing each user's QoE and ensuring fairness among users. We show that the problem can be decoupled into two interrelated subproblems: (i) a physical layer subproblem whose objective is to find the download rate for each user, and (ii) an application layer subproblem whose objective is to use that rate to find a quality decision per tile such that the user's QoE is maximized. We prove that the physical layer subproblem can be solved optimally with low complexity and an actor-critic deep reinforcement learning (DRL) is proposed to leverage the parallel training of multiple independent agents and solve the application layer subproblem. Extensive experiments reveal the robustness of our scheme and demonstrate its significant performance improvement compared to several baseline algorithms.      
### 33.UHD-DPDK Performance Analysis for Advanced Software Radio Communications  [ :arrow_down: ](https://arxiv.org/pdf/2011.06355.pdf)
>  Research conducted in LTE and 5G wireless communications systems uses common off-the-shelf hardware components and commercial software defined radio (SDR) hardware. One of the more popular SDR platforms is the Ettus USRP product line which uses the UHD driver and transport protocol framework. System performance can be increased using kernel bypass frameworks along with UHD. This paper investigates UHD with DPDK in an SDR environment using srslTE as the SDR application. We present measurement results using the iperf3 network performance application that show performance improvements when employing a kernel bypass framework to facilitate data transfer over the network interface between the SDR application and the radio hardware.      
### 34.Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting Bootstrap Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2011.06337.pdf)
>  Recently, deep learning approaches for MR motion artifact correction have been extensively studied. Although these approaches have shown high performance and reduced computational complexity compared to classical methods, most of them require supervised training using paired artifact-free and artifact-corrupted images, which may prohibit its use in many important clinical applications. For example, transient severe motion (TSM) due to acute transient dyspnea in Gd-EOB-DTPA-enhanced MR is difficult to control and model for paired data generation. To address this issue, here we propose a novel unsupervised deep learning scheme through outlier-rejecting bootstrap subsampling and aggregation. This is inspired by the observation that motions usually cause sparse k-space outliers in the phase encoding direction, so k-space subsampling along the phase encoding direction can remove some outliers and the aggregation step can further improve the results from the reconstruction network. Our method does not require any paired data because the training step only requires artifact-free images. Furthermore, to address the smoothing from potential bias to the artifact-free images, the network is trained in an unsupervised manner using optimal transport driven cycleGAN. We verify that our method can be applied for artifact correction from simulated motion as well as real motion from TSM successfully, outperforming existing state-of-the-art deep learning methods.      
### 35.Adaptive Force-based Control for Legged Robots  [ :arrow_down: ](https://arxiv.org/pdf/2011.06236.pdf)
>  In this paper, we present a novel methodology to introduce adaptive control for force-based control systems, with application to legged robots. In our approach, the reference model is based on the quadratic program force control. We evaluate our proposed control design on a high-fidelity physical simulation of LASER, a dynamic quadruped robot. Our proposed method guarantees input-to-state stability and is successfully validated for the problem of quadruped robots walking on rough terrain while carrying unknown and time-varying loads.      
### 36.Unsupervised Multimodal Image Registration with Adaptative Gradient Guidance  [ :arrow_down: ](https://arxiv.org/pdf/2011.06216.pdf)
>  Multimodal image registration (MIR) is a fundamental procedure in many image-guided therapies. Recently, unsupervised learning-based methods have demonstrated promising performance over accuracy and efficiency in deformable image registration. However, the estimated deformation fields of the existing methods fully rely on the to-be-registered image pair. It is difficult for the networks to be aware of the mismatched boundaries, resulting in unsatisfactory organ boundary alignment. In this paper, we propose a novel multimodal registration framework, which leverages the deformation fields estimated from both: (i) the original to-be-registered image pair, (ii) their corresponding gradient intensity maps, and adaptively fuses them with the proposed gated fusion module. With the help of auxiliary gradient-space guidance, the network can concentrate more on the spatial relationship of the organ boundary. Experimental results on two clinically acquired CT-MRI datasets demonstrate the effectiveness of our proposed approach.      
### 37.Privacy Preserving in Non-Intrusive Load Monitoring: A Differential Privacy Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2011.06205.pdf)
>  Smart meter devices enable a better understanding of the demand at the potential risk of private information leakage. One promising solution to mitigating such risk is to inject noises into the meter data to achieve a certain level of differential privacy. In this paper, we cast one-shot non-intrusive load monitoring (NILM) in the compressive sensing framework, and bridge the gap between theoretical accuracy of NILM inference and differential privacy's parameters. We then derive the valid theoretical bounds to offer insights on how the differential privacy parameters affect the NILM performance. Moreover, we generalize our conclusions by proposing the hierarchical framework to solve the multi-shot NILM problem. Numerical experiments verify our analytical results and offer better physical insights of differential privacy in various practical scenarios. This also demonstrates the significance of our work for the general privacy preserving mechanism design.      
### 38.Optimizing Large-Scale Fleet Management on a Road Network using Multi-Agent Deep Reinforcement Learning with Graph Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.06175.pdf)
>  Optimizing fleet management is an important issue in ride-hailing service in terms of customer's satisfaction and increased revenue for drivers. However finding an optimal strategy in a real environment that demand and supply are changing in real time, is a challenging problem. In this paper, we try to solve this problem by using multi-agent reinforcement learning. Instead of grid which was used in existing works, we use a graph to represent road network more realistically. We model the problem using Markov game and adopt stochastic policy update which can resolve the problem of greedy policy update in multi-agent scheme. We use modified DQN to fit our problem. To approximate Q values on the graph, we use two basic graph neural networks, GCN and GAT. We design a simulator using real taxi call data and evaluate the algorithms under various conditions. The result demonstrates effectiveness of the proposed stochastic policy update model with graph neural network.      
### 39.A Data-Driven Reinforcement Learning Solution Framework for Optimal and Adaptive Personalization of a Hip Exoskeleton  [ :arrow_down: ](https://arxiv.org/pdf/2011.06116.pdf)
>  Robotic exoskeletons are exciting technologies for augmenting human mobility. However, designing such a device for seamless integration with the human user and to assist human movement still is a major challenge. This paper aims at developing a novel data-driven solution framework based on reinforcement learning (RL), without first modeling the human-robot dynamics, to provide optimal and adaptive personalized torque assistance for reducing human efforts during walking. Our automatic personalization solution framework includes the assistive torque profile with two control timing parameters (peak and offset timings), the least square policy iteration (LSPI) for learning the parameter tuning policy, and a cost function based on transferred work ratio. The proposed controller was successfully validated on a healthy human subject to assist unilateral hip extension in walking. The results showed that the optimal and adaptive RL controller as a new approach was feasible for tuning assistive torque profile of the hip exoskeleton that coordinated with human actions and reduced activation level of hip extensor muscle in human.      
### 40.FS-HGR: Few-shot Learning for Hand Gesture Recognition via ElectroMyography  [ :arrow_down: ](https://arxiv.org/pdf/2011.06104.pdf)
>  This work is motivated by the recent advances in Deep Neural Networks (DNNs) and their widespread applications in human-machine interfaces. DNNs have been recently used for detecting the intended hand gesture through processing of surface electromyogram (sEMG) signals. The ultimate goal of these approaches is to realize high-performance controllers for prosthetic. However, although DNNs have shown superior accuracy than conventional methods when large amounts of data are available for training, their performance substantially decreases when data are limited. Collecting large datasets for training may be feasible in research laboratories, but it is not a practical approach for real-life applications. Therefore, there is an unmet need for the design of a modern gesture detection technique that relies on minimal training data while providing high accuracy. Here we propose an innovative and novel "Few-Shot Learning" framework based on the formulation of meta-learning, referred to as the FS-HGR, to address this need. Few-shot learning is a variant of domain adaptation with the goal of inferring the required output based on just one or a few training examples. More specifically, the proposed FS-HGR quickly generalizes after seeing very few examples from each class. The proposed approach led to 85.94% classification accuracy on new repetitions with few-shot observation (5-way 5-shot), 81.29% accuracy on new subjects with few-shot observation (5-way 5-shot), and 73.36% accuracy on new gestures with few-shot observation (5-way 5-shot).      
### 41.Global Position Control on Underactuated Bipedal Robots: Step-to-step Dynamics Approximation for Step Planning  [ :arrow_down: ](https://arxiv.org/pdf/2011.06050.pdf)
>  Global position control for underactuated bipedal walking is a challenging problem due to the lack of actuation on the feet of the robots. In this paper, we apply the Hybrid-Linear Inverted Pendulum (H-LIP) based stepping on 3D underactuated bipedal robots for global position control. The step-to-step (S2S) dynamics of the H-LIP walking approximates the actual S2S dynamics of the walking of the robot, where the step size is considered as the input. Thus the feedback controller based on the H-LIP approximately controls the robot to behave like the H-LIP, the differences between which stay in an error invariant set. Model Predictive Control (MPC) is applied to the H-LIP for global position control in 3D. The H-LIP stepping then generates desired step sizes for the robot to track. Moreover, turning behavior is integrated with the step planning. The proposed framework is verified on the 3D underactuated bipedal robot Cassie in simulation together with a proof-of-concept experiment.      
### 42.Robust multi-stage model-based design of optimal experiments for nonlinear estimation  [ :arrow_down: ](https://arxiv.org/pdf/2011.06042.pdf)
>  We study approaches to robust model-based design of experiments in the context of maximum-likelihood estimation. These approaches provide robustification of model-based methodologies for the design of optimal experiments by accounting for the effect of the parametric uncertainty. We study the problem of robust optimal design of experiments in the framework of nonlinear least-squares parameter estimation using linearized confidence regions. We investigate several well-known robustification frameworks in this respect and propose a novel methodology based on multi-stage robust optimization. The proposed methodology aims at problems, where the experiments are designed sequentially with a possibility of re-estimation in-between the experiments. The multi-stage formalism aids in identifying experiments that are better conducted in the early phase of experimentation, where parameter knowledge is poor. We demonstrate the findings and effectiveness of the proposed methodology using four case studies of varying complexity.      
### 43.FastPathology: An open-source platform for deep learning-based research and decision support in digital pathology  [ :arrow_down: ](https://arxiv.org/pdf/2011.06033.pdf)
>  Deep convolutional neural networks (CNNs) are the current state-of-the-art for digital analysis of histopathological images. The large size of whole-slide microscopy images (WSIs) requires advanced memory handling to read, display and process these images. There are several open-source platforms for working with WSIs, but few support deployment of CNN models. These applications use third-party solutions for inference, making them less user-friendly and unsuitable for high-performance image analysis. To make deployment of CNNs user-friendly and feasible on low-end machines, we have developed a new platform, FastPathology, using the FAST framework and C++. It minimizes memory usage for reading and processing WSIs, deployment of CNN models, and real-time interactive visualization of results. Runtime experiments were conducted on four different use cases, using different architectures, inference engines, hardware configurations and operating systems. Memory usage for reading, visualizing, zooming and panning a WSI were measured, using FastPathology and three existing platforms. FastPathology performed similarly in terms of memory to the other C++ based application, while using considerably less than the two Java-based platforms. The choice of neural network model, inference engine, hardware and processors influenced runtime considerably. Thus, FastPathology includes all steps needed for efficient visualization and processing of WSIs in a single application, including inference of CNNs with real-time display of the results. Source code, binary releases and test data can be found online on GitHub at <a class="link-external link-https" href="https://github.com/SINTEFMedtek/FAST-Pathology/" rel="external noopener nofollow">this https URL</a>.      
### 44.Physics-constrained Deep Learning of Multi-zone Building Thermal Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2011.05987.pdf)
>  We present a physics-constrained control-oriented deep learning method for modeling building thermal dynamics. The proposed method is based on the systematic encoding of physics-based prior knowledge into a structured recurrent neural architecture. Specifically, our method incorporates structural priors from traditional physics-based building modeling into the neural network thermal dynamics model structure. Further, we leverage penalty methods to provide inequality constraints, thereby bounding predictions within physically realistic and safe operating ranges. Observing that stable eigenvalues accurately characterize the dissipativeness of the system, we additionally use a constrained matrix parameterization based on the Perron-Frobenius theorem to bound the dominant eigenvalues of the building thermal model parameter matrices. We demonstrate the proposed data-driven modeling approach's effectiveness and physical interpretability on a dataset obtained from a real-world office building with 20 thermal zones. Using only 10 days' measurements for training, we demonstrate generalization over 20 consecutive days, significantly improving the accuracy compared to prior state-of-the-art results reported in the literature.      

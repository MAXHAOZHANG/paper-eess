# ArXiv eess --Wed, 25 Nov 2020
### 1.Optimal Two-way TOA Localization and Synchronization for Moving User Devices with Clock Drift  [ :arrow_down: ](https://arxiv.org/pdf/2011.12272.pdf)
>  In two-way time-of-arrival (TOA) systems, a user device (UD) obtains its position and timing information by round-trip communications to a number of anchor nodes (ANs) at known locations. Compared with the one-way TOA technique, the two-way TOA scheme is easy to implement and has better localization and synchronization accuracy. Existing two-way TOA localization and synchronization methods assume a stationary UD. This will cause uncompensated position and timing errors. In this article, we propose an optimal maximum likelihood (ML) based two-way TOA localization and synchronization method, namely TWLAS, which takes the UD motion into account to compensate the error caused by the UD movement. We analyze its estimation error and derive the Cramer-Rao lower bound (CRLB). We show that the conventional two-way TOA method is a special case of the TWLAS when the UD is stationary, and the TWLAS has better estimation accuracy than the conventional one-way TOA method. We also derive the estimation error in the case of deviated UD velocity information. Numerical result demonstrates that the estimation accuracy of the new TWLAS for a moving UD reaches CRLB, better than that of the conventional one-way TOA method, and the estimation error caused by the deviated UD velocity information is consistent with the theoretical analysis.      
### 2.Nonlinearity Compensation Based on Identified NARX Polynomials Models  [ :arrow_down: ](https://arxiv.org/pdf/2011.12246.pdf)
>  This paper deals with the compensation of nonlinearities in dynamical systems using nonlinear polynomial autoregressive models with exogenous inputs (NARX). The compensation approach is formulated for static and dynamical contexts, as well as its adaptation to hysteretic systems. In all of these scenarios, identified NARX models are used. The core idea is to rewrite the model as an algebraic polynomial whose roots are potential compensation inputs. A procedure is put forward to choose the most adequate root, in cases where more than one is possible. Both numerical and experimental results are presented to illustrate the method. In the experimental case the method is compared to other approaches. The results show that the proposed methodology can provide compensation input signals that practically linearize the studied systems using simple and representative models with no more than five terms.      
### 3.Discovering Hidden Physics Behind Transport Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2011.12222.pdf)
>  Transport processes are ubiquitous. They are, for example, at the heart of optical flow approaches; or of perfusion imaging, where blood transport is assessed, most commonly by injecting a tracer. An advection-diffusion equation is widely used to describe these transport phenomena. Our goal is estimating the underlying physics of advection-diffusion equations, expressed as velocity and diffusion tensor fields. We propose a learning framework (YETI) building on an auto-encoder structure between 2D and 3D image time-series, which incorporates the advection-diffusion model. To help with identifiability, we develop an advection-diffusion simulator which allows pre-training of our model by supervised learning using the velocity and diffusion tensor fields. Instead of directly learning these velocity and diffusion tensor fields, we introduce representations that assure incompressible flow and symmetric positive semi-definite diffusion fields and demonstrate the additional benefits of these representations on improving estimation accuracy. We further use transfer learning to apply YETI on a public brain magnetic resonance (MR) perfusion dataset of stroke patients and show its ability to successfully distinguish stroke lesions from normal brain regions via the estimated velocity and diffusion tensor fields.      
### 4.A light transformer for speech-to-intent applications  [ :arrow_down: ](https://arxiv.org/pdf/2011.12221.pdf)
>  Spoken language understanding (SLU) systems can make life more agreeable, safer (e.g. in a car) or can increase the independence of physically challenged users. However, due to the many sources of variation in speech, a well-trained system is hard to transfer to other conditions like a different language or to speech impaired users. A remedy is to design a user-taught SLU system that can learn fully from scratch from users' demonstrations, which in turn requires that the system's model quickly converges after only a few training samples. In this paper, we propose a light transformer structure by using a simplified relative position encoding with the goal to reduce the model size and improve efficiency. The light transformer works as an alternative speech encoder for an existing user-taught multitask SLU system. Experimental results on three datasets with challenging speech conditions prove our approach outperforms the existed system and other state-of-art models with half of the original model size and training time.      
### 5.A Joint Wireless-Optical Front-haul Solution for Multi-user Massive MIMO 5G RAN  [ :arrow_down: ](https://arxiv.org/pdf/2011.12214.pdf)
>  We demonstrate a high capacity IF-over-fiber mobile fronthaul solution for multi-user massive MIMO 5G RAN. Using this scheme, a record aggregated radio bandwidth of 25.6 GHz was transmitted on a single optical wavelength over 40 km without fiber chromatic dispersion compensation      
### 6.TFGAN: Time and Frequency Domain Based Generative Adversarial Network for High-fidelity Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2011.12206.pdf)
>  Recently, GAN based speech synthesis methods, such as MelGAN, have become very popular. Compared to conventional autoregressive based methods, parallel structures based generators make waveform generation process fast and stable. However, the quality of generated speech by autoregressive based neural vocoders, such as WaveRNN, is still higher than GAN. To address this issue, we propose a novel vocoder model: TFGAN, which is adversarially learned both in time and frequency domain. On one hand, we propose to discriminate ground-truth waveform from synthetic one in frequency domain for offering more consistency guarantees instead of only in time domain. On the other hand, in contrast to the conventionally frequency-domain STFT loss approach or feature map loss by discriminator to learn waveform, we propose a set of time-domain loss that encourage the generator to capture the waveform directly. TFGAN has nearly same synthesis speed as MelGAN, but the fidelity is significantly improved by our novel learning method. In our experiments, TFGAN shows the ability to achieve comparable mean opinion score (MOS) than autoregressive vocoder under speech synthesis context.      
### 7.A Sphere Decoding Algorithm for Multistep Sequential Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.12194.pdf)
>  This paper investigates the combination of two model predictive control concepts, sequential model predictive control and long-horizon model predictive control for power electronics. To achieve sequential model predictive control, the optimization problem is split into two subproblems: The first one summarizes all control goals which linearly depend on the system inputs. Sequential model predictive control generally requires to obtain more than one solution for the first subproblem. Due to the mixed-integer nature of finite control set model predictive control power electronics a special sphere decoder is therefore proposed within the paper. The second subproblem consists of all those control goals which depend nonlinearly on the system inputs and is solved by an exhaustive search. The effectiveness of the proposed method is validated via numerical simulations at different scenarios on a three-level neutral point clamped permanent magnet synchronous generator wind turbine system and compared to otherlong-horizon model predictive control methods      
### 8.A DC-Autotransformer based Multilevel Inverter for Automotive Applications  [ :arrow_down: ](https://arxiv.org/pdf/2011.12164.pdf)
>  This paper proposes a novel multilevel inverter for automotive applications. The topology consists of a modular DCDC converter and a tap selector, where the DC-DC converter provides several DC-output levels and the tap selector produces an AC signal by choosing different DC-output signals from the DC-DC converter. To produce the DC-levels, the DC-DC converter consists of a modular structure where the modules are connected in series. The novelty is that the modules are connected both, magnetically in the AC-domain and electrically in the DCdomain. Due to the usage of low power switches in the modules, the proposed structure provides high efficiency. Furthermore, the DC-DC converter is capable of self-balancing its modules and thus does not require large capacitors which yields a high power density. A prototype of the proposed converter is built and simulation, as well as experimental results, are used to verify the findings.      
### 9.Locate the Source of Resonance-Involved Forced Oscillation in Power Systems Based on Mode Shape Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2011.12147.pdf)
>  This paper proposed a new method to locate the source of forced oscillation that involves resonance with natural oscillation modes. The new method is based on comparing the oscillation mode shape of the forced oscillation with that of the natural oscillation that the forced oscillation resonating with. The location that has the largest angle difference between the forced oscillation mode and the natural oscillation mode usually indicates the location of the driving force in forced oscillations. Some examples in actual U.S. EI system verified this approach.      
### 10.Fetal ECG Extraction from Maternal ECG using attention-based Asymmetric CycleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2011.12138.pdf)
>  Non-invasive fetal electrocardiogram (FECG) is used to monitor the electrical pulse of the fetal heart. Decomposing the FECG signal from maternal ECG (MECG) is a challenging problem due to the low amplitude of FECG, the overlap of R waves, and the potential exposure to noise from different sources. Traditional decomposition techniques, such as adaptive filters, require tuning, alignment, or pre-configuration, such as modeling the noise or desired signal. In this paper, a modified Cycle Generative Adversarial Network (CycleGAN) is introduced to map signal domains efficiently. The high correlation between maternal and fetal ECG parts decreases the performance of convolution layers. Therefore, masking attention layer which is inspired by the latent vector is implemented to improve generators. Three available datasets from the Physionet, including A&amp;D FECG, NI-FECG and NI-FECG challenge, and one synthetic dataset using FECGSYN toolbox are used for evaluating the performance. The proposed method could map abdominal MECG to scalp FECG with an average 97.2% R-Square [CI 95%: 97.1, 97.2] and 7.8 +- 1.9 [CI 95% 6.13-9.47] Wavelet Energy based Diagnostic Distortion on A&amp;D FECG dataset. Moreover, it achieved 99.4% [CI 95%: 97.8, 99.6], 99.3% [CI 95%: 97.5, 99.5] and 97.2% [CI 95%:93.3%, 97.1%] F1-score for QRS detection in A&amp;D FECG, NI-FECG and NI-FECG challenge datasets, respectively. Finally, the generated synthetic dataset is used for investigating the effect of maternal and fetal heart rates on the proposed method. These results are comparable to the-state-of-the-art and has thus a potential of being a new algorithm for FECG extraction.      
### 11.Self-Supervised Transformers for Activity Classification using Ambient Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2011.12137.pdf)
>  Providing care for ageing populations is an onerous task, and as life expectancy estimates continue to rise, the number of people that require senior care is growing rapidly. This paper proposes a methodology based on Transformer Neural Networks to classify the activities of a resident within an ambient sensor based environment. We also propose a methodology to pre-train Transformers in a self-supervised manner, as a hybrid autoencoder-classifier model instead of using contrastive loss. The social impact of the research is considered with wider benefits of the approach and next steps for identifying transitions in human behaviour. In recent years there has been an increasing drive for integrating sensor based technologies within care facilities for data collection. This allows for employing machine learning for many aspects including activity recognition and anomaly detection. Due to the sensitivity of healthcare environments, some methods of data collection used in current research are considered to be intrusive within the senior care industry, including cameras for image based activity recognition, and wearables for activity tracking, but recent studies have shown that using these methods commonly result in poor data quality due to the lack of resident interest in participating in data gathering. This has led to a focus on ambient sensors, such as binary PIR motion, connected domestic appliances, and electricity and water metering. By having consistency in ambient data collection, the quality of data is considerably more reliable, presenting the opportunity to perform classification with enhanced accuracy. Therefore, in this research we looked to find an optimal way of using deep learning to classify human activity with ambient sensor data.      
### 12.Zero-Shot Audio Classification via Semantic Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2011.12133.pdf)
>  In this paper, we study zero-shot learning in audio classification via semantic embeddings extracted from textual labels and sentence descriptions of sound classes. Our goal is to obtain a classifier that is capable of recognizing audio instances of sound classes that have no available training samples, but only semantic side information. We employ a bilinear compatibility framework to learn an acoustic-semantic projection between intermediate-level representations of audio instances and sound classes, i.e., acoustic embeddings and semantic embeddings. We use VGGish to extract deep acoustic embeddings from audio clips, and pre-trained language models (Word2Vec, GloVe, BERT) to generate either label embeddings from textual labels or sentence embeddings from sentence descriptions of sound classes. Audio classification is performed by a linear compatibility function that measures how compatible an acoustic embedding and a semantic embedding are. We evaluate the proposed method on a small balanced dataset ESC-50 and a large-scale unbalanced audio subset of AudioSet. The experimental results show that classification performance is significantly improved by involving sound classes that are semantically close to the test classes in training. Meanwhile, we demonstrate that both label embeddings and sentence embeddings are useful for zero-shot learning. Classification performance is improved by concatenating label/sentence embeddings generated with different language models. With their hybrid concatenations, the results are improved further.      
### 13.A Reusable Framework Based on Reinforcement Learning to Design Antennas for Curved Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2011.12131.pdf)
>  The design and implementation of low-profile antennas has been analyzed in past decades from different perspectives while the purpose is to have a small size in the device, and an adequate electromagnetic behavior. This work pursues a methodology to identify small antennas and consequently presents some similarities. Meanwhile, curved surfaces are considered for a certain variety of antennas with reduced size. The so-called deep reinforcement learning technique is used as an assistance against morphological variations that are specifically taken into account in this work. The objective is to identify antennas that can be efficiently mounted on the surface of metal tubes such as those frequently present in public infrastructure (e.g. traffic lights and luminaries). The motivation is to reduce the visual impact and optimize the radiation pattern of the antenna. It is analyzed that if changes in variables such as the radius of curvature, or the electromagnetic properties of the materials appear, an automatic identification of the underlying characteristics of the problem (by means of machine learning techniques) can readjust the design efficiently. The results obtained in this work are analyzed based on variables that are typically used to characterize antennas, such as their impedance and radiation pattern.      
### 14.A Generalizable Model for Fault Detection in Offshore Wind Turbines Based on Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.12130.pdf)
>  This paper presents a new deep learning-based model for fault detection in offshore wind turbines. To design a generalizable model for fault detection, we use 5 sensors and a sliding window to exploit the inherent temporal information contained in the raw time-series data obtained from sensors. The proposed model uses the nonlinear relationships among multiple sensor variables and the temporal dependency of each sensor on others that considerably increases the performance of fault detection model. A 10-fold cross-validation is used to verify the generalization of the model and evaluate the classification metrics. To evaluate the performance of the model, simulated data from a benchmark floating offshore wind turbine (FOWT) with supervisory control and data acquisition (SCADA) are used. The results illustrate that the proposed model would accurately disclose and classify more than 99% of the faults. Moreover, it is generalizable and can be used to detect faults for different types of systems.      
### 15.Self-supervised transfer learning of physiological representations from free-living wearable data  [ :arrow_down: ](https://arxiv.org/pdf/2011.12121.pdf)
>  Wearable devices such as smartwatches are becoming increasingly popular tools for objectively monitoring physical activity in free-living conditions. To date, research has primarily focused on the purely supervised task of human activity recognition, demonstrating limited success in inferring high-level health outcomes from low-level signals. Here, we present a novel self-supervised representation learning method using activity and heart rate (HR) signals without semantic labels. With a deep neural network, we set HR responses as the supervisory signal for the activity data, leveraging their underlying physiological relationship. In addition, we propose a custom quantile loss function that accounts for the long-tailed HR distribution present in the general population. <br>We evaluate our model in the largest free-living combined-sensing dataset (comprising &gt;280k hours of wrist accelerometer &amp; wearable ECG data). Our contributions are two-fold: i) the pre-training task creates a model that can accurately forecast HR based only on cheap activity sensors, and ii) we leverage the information captured through this task by proposing a simple method to aggregate the learnt latent representations (embeddings) from the window-level to user-level. Notably, we show that the embeddings can generalize in various downstream tasks through transfer learning with linear classifiers, capturing physiologically meaningful, personalized information. For instance, they can be used to predict variables associated with individuals' health, fitness and demographic characteristics, outperforming unsupervised autoencoders and common bio-markers. Overall, we propose the first multimodal self-supervised method for behavioral and physiological data with implications for large-scale health and lifestyle monitoring.      
### 16.Towards Assistive Diagnoses in m-Health: A Gray-box Neural Model for Cerebral Autoregulation Index  [ :arrow_down: ](https://arxiv.org/pdf/2011.12115.pdf)
>  The cerebral autoregulation system (CAS), is a mechanism which aims to regulate pressure variations occurring in the cerebral circulatory system. At present, there only exist invasive methods and, in turn, they are not used to prevent cerebrovascular accidents. Nowadays, the emergent concept of m-Health allows to use mobile devices to assist the cerebral autoregulation index (ARI). For this, it is necessary to find novel models which allow to approximate the ARI by using the blood pressure value. This work proposes a gray-box neural model to find a relation between the arterial blood pressure (ABP) and the cerebral blood flow velocity (CBFV) in order to obtain the ARI. Preliminary results show good performance by using a phenomenological model in comparison to the Aaslid-Tiecks model.      
### 17.Rethinking solar photovoltaic parameter estimation: global optimality analysis and a simple efficient differential evolution method  [ :arrow_down: ](https://arxiv.org/pdf/2011.12114.pdf)
>  Accurate, fast, and reliable parameter estimation is crucial for modeling, control, and optimization of solar photovoltaic (PV) systems. In this paper, we focus on the two most widely used benchmark datasets and try to answer (i) whether the global minimum in terms of root mean square error (RMSE) has already been reached; and (ii) whether a significantly simpler metaheuristic, in contrast to currently sophisticated ones, is capable of identifying PV parameters with comparable performance, e.g., attaining the same RMSE. We address the former using an interval analysis based branch and bound algorithm and certify the global minimum rigorously for the single diode model (SDM) as well as locating a fairly tight upper bound for the double diode model (DDM) on both datasets. These obtained values will serve as useful references for metaheuristic methods, since none of them can guarantee or recognize the global minimum even if they have literally discovered it. However, this algorithm is excessively slow and unsuitable for time-sensitive applications (despite the great insights on RMSE that it yields). Regarding the second question, extensive examination and comparison reveal that, perhaps surprisingly, a classic and remarkably simple differential evolution (DE) algorithm can consistently achieve the certified global minimum for the SDM and obtain the best known result for the DDM on both datasets. Thanks to its extreme simplicity, the DE algorithm takes only a fraction of the running time required by other contemporary metaheuristics and is thus preferable in real-time scenarios. This unusual (and certainly notable) finding also indicates that the employment of increasingly complicated metaheuristics might possibly be somewhat overkill for regular PV parameter estimation. Finally, we discuss the implications of these results and suggest promising directions for future development.      
### 18.Automatic artifact removal of resting-state fMRI with Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.12113.pdf)
>  Functional Magnetic Resonance Imaging (fMRI) is a non-invasive technique for studying brain activity. During an fMRI session, the subject executes a set of tasks (task-related fMRI study) or no tasks (resting-state fMRI), and a sequence of 3-D brain images is obtained for further analysis. In the course of fMRI, some sources of activation are caused by noise and artifacts. The removal of these sources is essential before the analysis of the brain activations. Deep Neural Network (DNN) architectures can be used for denoising and artifact removal. The main advantage of DNN models is the automatic learning of abstract and meaningful features, given the raw data. This work presents advanced DNN architectures for noise and artifact classification, using both spatial and temporal information in resting-state fMRI sessions. The highest performance is achieved by a voting schema using information from all the domains, with an average accuracy of over 98% and a very good balance between the metrics of sensitivity and specificity (98.5% and 97.5% respectively).      
### 19.Wavelet-based clustering for time-series trend detection  [ :arrow_down: ](https://arxiv.org/pdf/2011.12111.pdf)
>  In this paper, we introduce a method performing clustering of time-series on the basis of their trend (increasing, stagnating/decreasing, and seasonal behavior). The clustering is performed using $k$-means method on a selection of coefficients obtained by discrete wavelet transform, reducing drastically the dimensionality. The method is applied on an use case for the clustering of a 864 daily sales revenue time-series for 61 retail shops. The results are presented for different mother wavelets. The importance of each wavelet coefficient and its level is discussed thanks to a principal component analysis along with a reconstruction of the signal from the selected wavelet coefficients.      
### 20.Reconfigurable Intelligent Surfaces in Challenging Environments  [ :arrow_down: ](https://arxiv.org/pdf/2011.12110.pdf)
>  Reconfigurable intelligent surfaces (RISs) have been introduced to improve the signal propagation characteristics by focusing the signal power in the preferred direction, thus making the communication environment 'smart'. The typical use cases and applications for the 'smart' environment include beyond 5G communication networks, smart cities, etc. The main advantage of employing RISs in such networks is a more efficient exploitation of spatial degrees of freedom. This advantage manifests in better interference mitigation as well as increased spectral and energy efficiency due to passive beam steering. Challenging environments (CEs) comprise a range of scenarios, which share the fact that it is extremely difficult to establish a communication link using conventional technology due to many impairments typically associated with the propagation medium and increased signal scattering. Although the challenges for the design of communication networks in such environments are known, there is no common enabler or solution for all these applications. Interestingly, the use of RISs in such scenarios can become such an enabler and a game changer technology. Surprisingly, the benefits of RIS for wireless networking in underwater and underground medium as well as in industrial and disaster environments have not been addressed yet. This paper aims at filling this gap by providing a motivation for the application of RISs in CEs. In addition, novel research challenges to be addressed in this context are discussed.      
### 21.Predicting of shear wave velocity using Artificial Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.12109.pdf)
>  Shear wave velocity is an important parameter for determining lithology, porosity and the dynamic properties in geo-mechanical studies. However, due to time and cost limitations, shear wave velocity is not available at all intervals and in all wells. In this paper, well logs with strong correlation to shear wave velocity were determined and used to predict the shear wave velocity for the Tano North Field. Four different methods were used to estimate the shear wave velocity under three different conditions. Then, based on obtained coefficient of determination and average absolute percent relative error between real and predicted values of shear wave velocity, the final results were compared. The results of this work demonstrated that the neural network based on multiple variables can estimate the shear wave velocity better than other methods used.      
### 22.EEG-GCNN: Augmenting Electroencephalogram-based Neurological Disease Diagnosis using a Domain-guided Graph Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.12107.pdf)
>  This paper presents a novel graph convolutional neural network (GCNN)-based approach for improving the diagnosis of neurological diseases using scalp-electroencephalograms (EEGs). Although EEG is one of the main tests used for neurological-disease diagnosis, the sensitivity of EEG-based expert visual diagnosis remains at $\sim$50\%. This indicates a clear need for advanced methodology to reduce the false negative rate in detecting abnormal scalp-EEGs. In that context, we focus on the problem of distinguishing the abnormal scalp EEGs of patients with neurological diseases, which were originally classified as 'normal' by experts, from the scalp EEGs of healthy individuals. The contributions of this paper are three-fold: 1) we present EEG-GCNN, a novel GCNN model for EEG data that captures both the spatial and functional connectivity between the scalp electrodes, 2) using EEG-GCNN, we perform the first large-scale evaluation of the aforementioned hypothesis, and 3) using two large scalp-EEG databases, we demonstrate that EEG-GCNN significantly outperforms the human baseline and classical machine learning (ML) baselines, with an AUC of 0.90.      
### 23.Towards SAR Tomographic Inversion via Sparse Bayesian Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.12069.pdf)
>  Existing SAR tomography (TomoSAR) algorithms are mostly based on an inversion of the SAR imaging model, which are often computationally expensive. Previous study showed perspective of using data-driven methods like KPCA to decompose the signal and reduce the computational complexity. This paper gives a preliminary demonstration of a new data-driven method based on sparse Bayesian learning. Experiments on simulated data show that the proposed method significantly outperforms KPCA methods in estimating the steering vectors of the scatterers. This gives a perspective of data-drive approach or combining it with model-driven approach for high precision tomographic inversion of large areas.      
### 24.How Far Are We from Robust Voice Conversion: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2011.12063.pdf)
>  Voice conversion technologies have been greatly improved in recent years with the help of deep learning, but their capabilities of producing natural sounding utterances in different conditions remain unclear. In this paper, we gave a thorough study of the robustness of known VC models. We also modified these models, such as the replacement of speaker embeddings, to further improve their performances. We found that the sampling rate and audio duration greatly influence voice conversion. All the VC models suffer from unseen data, but AdaIN-VC is relatively more robust. Also, the speaker embedding jointly trained is more suitable for voice conversion than those trained on speaker identification.      
### 25.Integration of variational autoencoder and spatial clustering for adaptive multi-channel neural speech separation  [ :arrow_down: ](https://arxiv.org/pdf/2011.11984.pdf)
>  In this paper, we propose a method combining variational autoencoder model of speech with a spatial clustering approach for multi-channel speech separation. The advantage of integrating spatial clustering with a spectral model was shown in several works. As the spectral model, previous works used either factorial generative models of the mixed speech or discriminative neural networks. In our work, we combine the strengths of both approaches, by building a factorial model based on a generative neural network, a variational autoencoder. By doing so, we can exploit the modeling power of neural networks, but at the same time, keep a structured model. Such a model can be advantageous when adapting to new noise conditions as only the noise part of the model needs to be modified. We show experimentally, that our model significantly outperforms previous factorial model based on Gaussian mixture model (DOLPHIN), performs comparably to integration of permutation invariant training with spatial clustering, and enables us to easily adapt to new noise conditions. The code for the method is available at <a class="link-external link-https" href="https://github.com/BUTSpeechFIT/vae_dolphin" rel="external noopener nofollow">this https URL</a>      
### 26.Provably robust blind source separation of linear-quadratic near-separable mixtures  [ :arrow_down: ](https://arxiv.org/pdf/2011.11966.pdf)
>  In this work, we consider the problem of blind source separation (BSS) by departing from the usual linear model and focusing on the linear-quadratic (LQ) model. We propose two provably robust and computationally tractable algorithms to tackle this problem under separability assumptions which require the sources to appear as samples in the data set. The first algorithm generalizes the successive nonnegative projection algorithm (SNPA), designed for linear BSS, and is referred to as SNPALQ. By explicitly modeling the product terms inherent to the LQ model along the iterations of the SNPA scheme, the nonlinear contributions of the mixing are mitigated, thus improving the separation quality. SNPALQ is shown to be able to recover the ground truth factors that generated the data, even in the presence of noise. The second algorithm is a brute-force (BF) algorithm, which is used as a post-processing step for SNPALQ. It enables to discard the spurious (mixed) samples extracted by SNPALQ, thus broadening its applicability. The BF is in turn shown to be robust to noise under easier-to-check and milder conditions than SNPALQ. We show that SNPALQ with and without the BF postprocessing is relevant in realistic numerical experiments.      
### 27.Good and Bad Boundaries in Ultrasound Compounding: Preserving Anatomic Boundaries While Suppressing Artifacts  [ :arrow_down: ](https://arxiv.org/pdf/2011.11962.pdf)
>  Ultrasound 3D compounding is important for volumetric reconstruction, but as of yet there is no consensus on best practices for compounding. Ultrasound images depend on probe direction and the path sound waves pass through, so when multiple intersecting B-scans of the same spot from different perspectives yield different pixel values, there is not a single, ideal representation for compounding (i.e. combining) the overlapping pixel values. Current popular methods inevitably suppress or altogether leave out bright or dark regions that are useful, and potentially introduce new artifacts. In this work, we establish a new algorithm to compound the overlapping pixels from different view points in ultrasound. We uniquely leverage Laplacian and Gaussian Pyramids to preserve the maximum boundary contrast without overemphasizing noise and speckle. We evaluate our algorithm by comparing ours with previous algorithms, and we show that our approach not only preserves both light and dark details, but also somewhat suppresses artifacts, rather than amplifying them.      
### 28.Weakly- and Semi-Supervised Probabilistic Segmentation and Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better AI Understanding of Tissue Beneath Needles  [ :arrow_down: ](https://arxiv.org/pdf/2011.11958.pdf)
>  Ultrasound image quality has been continually improving. However, when needles or other metallic objects are operating inside the tissue, the resulting reverberation artifacts can severely corrupt the surrounding image quality. Such effects are challenging for existing computer vision algorithms for medical image analysis. Needle reverberation artifacts can be hard to identify at times and affect various pixel values to different degrees. The boundaries of such artifacts are ambiguous, leading to disagreement among human experts labeling the artifacts. We purpose a weakly- and semi-supervised, probabilistic needle-and-needle-artifact segmentation algorithm to separate the desired tissue-based pixel values from the superimposed artifacts. Our method models the intensity decay of artifact intensities and is designed to minimize the human labeling error. We demonstrate the applicability of the approach, comparing it against other segmentation algorithms. Our method is capable of differentiating the reverberations from artifact-free patches between reverberations, as well as modeling the intensity fall-off in the artifacts. Our method matches state-of-the-art artifact segmentation performance, and sets a new standard in estimating the per-pixel contributions of artifact vs underlying anatomy, especially in the immediately adjacent regions between reverberation lines.      
### 29.Ultrasound Confidence Maps of Intensity and Structure Based on Directed Acyclic Graphs and Artifact Models  [ :arrow_down: ](https://arxiv.org/pdf/2011.11956.pdf)
>  Ultrasound imaging has been improving, but continues to suffer from inherent artifacts that are challenging to model, such as attenuation, shadowing, diffraction, speckle, etc. These artifacts can potentially confuse image analysis algorithms unless an attempt is made to assess the certainty of individual pixel values. Our novel confidence algorithms analyze pixel values using a directed acyclic graph based on acoustic physical properties of ultrasound imaging. We demonstrate unique capabilities of our approach and compare it against previous confidence-measurement algorithms for shadow-detection and image-compounding tasks.      
### 30.SimTreeLS: Simulating aerial and terrestrial laser scans of trees  [ :arrow_down: ](https://arxiv.org/pdf/2011.11954.pdf)
>  There are numerous emerging applications for digitizing trees using terrestrial and aerial laser scanning, particularly in the fields of agriculture and forestry. Interpretation of LiDAR point clouds is increasingly relying on data-driven methods (such as supervised machine learning) that rely on large quantities of hand-labelled data. As this data is potentially expensive to capture, and difficult to clearly visualise and label manually, a means of supplementing real LiDAR scans with simulated data is becoming a necessary step in realising the potential of these methods. We present an open source tool, SimTreeLS (Simulated Tree Laser Scans), for generating point clouds which simulate scanning with user-defined sensor, trajectory, tree shape and layout parameters. Upon simulation, material classification is kept in a pointwise fashion so leaf and woody matter are perfectly known, and unique identifiers separate individual trees, foregoing post-simulation labelling. This allows for an endless supply of procedurally generated data with similar characteristics to real LiDAR captures, which can then be used for development of data processing techniques or training of machine learning algorithms. To validate our method, we compare the characteristics of a simulated scan with a real scan using similar trees and the same sensor and trajectory parameters. Results suggest the simulated data is significantly more similar to real data than a sample-based control. We also demonstrate application of SimTreeLS on contexts beyond the real data available, simulating scans of new tree shapes, new trajectories and new layouts, with results presenting well. SimTreeLS is available as an open source resource built on publicly available libraries.      
### 31.Alleviating Class-wise Gradient Imbalance for Pulmonary Airway Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2011.11952.pdf)
>  Automated airway segmentation is a prerequisite for pre-operative diagnosis and intra-operative navigation for pulmonary intervention. Due to the small size and scattered spatial distribution of peripheral bronchi, this is hampered by severe class imbalance between foreground and background regions, which makes it challenging for CNN-based methods to parse distal small airways. In this paper, we demonstrate that this problem is arisen by gradient erosion and dilation of the neighborhood voxels. During back-propagation, if the ratio of the foreground gradient to background gradient is small while the class imbalance is local, the foreground gradients can be eroded by their neighborhoods. This process cumulatively increases the noise information included in the gradient flow from top layers to the bottom ones, limiting the learning of small structures in CNNs. To alleviate this problem, we use group supervision and the corresponding WingsNet to provide complementary gradient flows to enhance the training of shallow layers. To further address the intra-class imbalance between large and small airways, we design a General Union loss function which obviates the impact of airway size by distance-based weights and adaptively tunes the gradient ratio based on the learning process. Extensive experiments on public datasets demonstrate that the proposed method can predict the airway structures with higher accuracy and better morphological completeness.      
### 32.A Model-Free Loop-Shaping Method based on Iterative Learning Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.11923.pdf)
>  Many techniques have been developed for the loop-shaping method in control design. While most loop-shaping methods apply a model of the open-loop controlled plant, the resulting performance depends on the accuracy of the dynamical model. This paper aims to develop a model-free loop-shaping technique. The core idea is to convert the model matching problem to a trajectory tracking problem. To achieve the desired loop gain, we need to determine the control input such that the system output tracks the impulse response of the loop gain function. In this paper, a model-free iterative learning control (ILC) algorithm is applied to solve this tracking problem. Once the ILC converges, the feedback controller that meets the desired loop gain can then be constructed. This method does not require the model of the controlled plant; hence it provides better performance of loop-shaping control design. The proposed method is validated through numerical simulation on a third order plant.      
### 33.A Data-Fusion-Assisted Telemetry Layer for Autonomous Optical Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.11896.pdf)
>  For further improving the capacity and reliability of optical networks, a closed-loop autonomous architecture is preferred. Considering a large number of optical components in an optical network and many digital signal processing modules in each optical transceiver, massive real-time data can be collected. However, for a traditional monitoring structure, collecting, storing and processing a large size of data are challenging tasks. Moreover, strong correlations and similarities between data from different sources and regions are not properly considered, which may limit function extension and accuracy improvement. To address abovementioned issues, a data-fusion-assisted telemetry layer between the physical layer and control layer is proposed in this paper. The data fusion methodologies are elaborated on three different levels: Source Level, Space Level and Model Level. For each level, various data fusion algorithms are introduced and relevant works are reviewed. In addition, proof-of-concept use cases for each level are provided through simulations, where the benefits of the data-fusion-assisted telemetry layer are shown.      
### 34.Simulation-based Optimization of Toll Pricing in Large-Scale Urban Networks using the Network Fundamental Diagram: A Cross-Comparison of Methods  [ :arrow_down: ](https://arxiv.org/pdf/2011.11892.pdf)
>  Simulation-based optimization (SO or SBO) has become increasingly important to address challenging transportation network design problems. In this paper, we propose to solve two toll pricing problems with different levels of complexity using the concept of the macroscopic or network fundamental diagram (MFD or NFD), where a large-scale simulation-based dynamic traffic assignment model of Melbourne, Australia is used. Four computationally efficient SBO methods are applied and compared, including the proportional-integral (PI) controller, regressing kriging (RK), DIviding RECTangles (DIRECT), and simultaneous perturbation stochastic approximation (SPSA). The comparison reveals that these methods work equally well on the simple problem without exhibiting significant performance differences. But, for the complex problem, RK manifests itself to be the best-performing method thanks to its capability of filtering out the numerical noise arising from computer simulations (i.e. allowing for non-smoothness of the objective function). While the PI controller is a more competitive solution to the simple problem given its faster rate of convergence, the poor scalability of the method in the complex problem results in limited applicability. Two caveats, however, deserve emphasis: (i) the chosen critical network density of the NFD does not necessarily represent a robust network control or optimization threshold, as it might shift in the presence of toll pricing; and (ii) re-interpolation is required as part of RK in order to achieve global convergence.      
### 35.A fully distributed event-triggered communication strategy for second-order multi-agent systems consensus  [ :arrow_down: ](https://arxiv.org/pdf/2011.11882.pdf)
>  This paper investigates the communication strategy for second-order multi-agent systems with nonlinear dynamics. To save the scarce resources of communication channels, a novel event-triggered communication mechanism is designed without using continuous signals among the followers. To get rid of the centralized information depending on the spectrum of the Laplacian matrix, a consensus protocol with updated coupling gains and an event-triggered strategy of interagent communication with updated thresholds are presented. To minimize the impacts of noise, only relative positions among agents are employed in the protocol. With the proposed event-triggered mechanism and the control protocol, the leader-following consensus of MASs and no Zeno behavior included are mathematically proven. The results are verified through numerical examples.      
### 36.Effective Parallelism for Equation and Jacobian Evaluation in Power Flow Calculation  [ :arrow_down: ](https://arxiv.org/pdf/2011.11880.pdf)
>  This letter investigates parallelism approaches for equations and Jacobian evaluation in power flow calculations. Two levels of parallelism are proposed and analyzed: inter-model parallelism, which evaluates models in parallel, and intra-model parallelism, which evaluates calculations within each model in parallel. Parallelism techniques such as multi-threading and single instruction multiple data (SIMD) vectorization are discussed, implemented, and benchmarked as six calculation workflows. Case studies on the 70,000-bus synthetic grid show that equation evaluations can be accelerated by ten times, and the overall Newton power flow outperforms MATPOWER by 20%.      
### 37.Blind deblurring for microscopic pathology images using deep learning networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.11879.pdf)
>  Artificial Intelligence (AI)-powered pathology is a revolutionary step in the world of digital pathology and shows great promise to increase both diagnosis accuracy and efficiency. However, defocus and motion blur can obscure tissue or cell characteristics hence compromising AI algorithms'accuracy and robustness in analyzing the images. In this paper, we demonstrate a deep-learning-based approach that can alleviate the defocus and motion blur of a microscopic image and output a sharper and cleaner image with retrieved fine details without prior knowledge of the blur type, blur extent and pathological stain. In this approach, a deep learning classifier is first trained to identify the image blur type. Then, two encoder-decoder networks are trained and used alone or in combination to deblur the input image. It is an end-to-end approach and introduces no corrugated artifacts as traditional blind deconvolution methods do. We test our approach on different types of pathology specimens and demonstrate great performance on image blur correction and the subsequent improvement on the diagnosis outcome of AI algorithms.      
### 38.Intelligent Reflecting Surface Aided MISO Uplink Communication Network: Feasibility and Power Minimization for Perfect and Imperfect CSI  [ :arrow_down: ](https://arxiv.org/pdf/2011.11856.pdf)
>  In this paper, we consider the weighted sum-power minimization under quality-of-service (QoS) constraints in the multi-user multi-input-single-output (MISO) uplink wireless network assisted by intelligent reflecting surface (IRS). We perform a comprehensive investigation on various aspects of this problem. First, when users have sufficient transmit powers, we present a new sufficient condition guaranteeing arbitrary information rate constraints. This result strengthens the feasibility condition in existing literature. Then, we design novel penalty dual decomposition (PDD) based and nonlinear equality constrained alternative direction method of multipliers (neADMM) based solutions to tackle the IRS-dependent-QoS-constraints, which effectively solve the feasibility check and power minimization problems. Besides, we further extend our proposals to the cases where channel status information (CSI) is imperfect and develop an online stochastic algorithm that satisfy QoS constraints stochastically without requiring prior knowledge of CSI errors. Extensive numerical results are presented to verify the effectiveness of our proposed algorithms.      
### 39.A Data-Driven Automatic Tuning Method for MPC under Uncertainty using Constrained Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2011.11841.pdf)
>  The closed-loop performance of model predictive controllers (MPCs) is sensitive to the choice of prediction models, controller formulation, and tuning parameters. However, prediction models are typically optimized for prediction accuracy instead of performance, and MPC tuning is typically done manually to satisfy (probabilistic) constraints. In this work, we demonstrate a general approach for automating the tuning of MPC under uncertainty. In particular, we formulate the automated tuning problem as a constrained black-box optimization problem that can be tackled with derivative-free optimization. We rely on a constrained variant of Bayesian optimization (BO) to solve the MPC tuning problem that can directly handle noisy and expensive-to-evaluate functions. The benefits of the proposed automated tuning approach are demonstrated on a benchmark continuously stirred tank reactor example.      
### 40.Peer Offloading with Delayed Feedback in Fog Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.11835.pdf)
>  Comparing to cloud computing, fog computing performs computation and services at the edge of networks, thus relieving the computation burden of the data center and reducing the task latency of end devices. Computation latency is a crucial performance metric in fog computing, especially for real-time applications. In this paper, we study a peer computation offloading problem for a fog network with unknown dynamics. In this scenario, each fog node (FN) can offload their computation tasks to neighboring FNs in a time slot manner. The offloading latency, however, could not be fed back to the task dispatcher instantaneously due to the uncertainty of the processing time in peer FNs. Besides, peer competition occurs when different FNs offload tasks to one FN at the same time. To tackle the above difficulties, we model the computation offloading problem as a sequential FN selection problem with delayed information feedback. Using adversarial multi-arm bandit framework, we construct an online learning policy to deal with delayed information feedback. Different contention resolution approaches are considered to resolve peer competition. Performance analysis shows that the regret of the proposed algorithm, or the performance loss with suboptimal FN selections, achieves a sub-linear order, suggesting an optimal FN selection policy. In addition, we prove that the proposed strategy can result in a Nash equilibrium (NE) with all FNs playing the same policy. Simulation results validate the effectiveness of the proposed policy.      
### 41.Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech  [ :arrow_down: ](https://arxiv.org/pdf/2011.11818.pdf)
>  In recent years, Text-To-Speech (TTS) has been used as a data augmentation technique for speech recognition to help complement inadequacies in the training data. Correspondingly, we investigate the use of a multi-speaker TTS system to synthesize speech in support of speaker recognition. In this study we focus the analysis on tasks where a relatively small number of speakers is available for training. We observe on our datasets that TTS synthesized speech improves cross-domain speaker recognition performance and can be combined effectively with multi-style training. Additionally, we explore the effectiveness of different types of text transcripts used for TTS synthesis. Results suggest that matching the textual content of the target domain is a good practice, and if that is not feasible, a transcript with a sufficiently large vocabulary is recommended.      
### 42.Spectral Domain Spline Graph Filter Bank  [ :arrow_down: ](https://arxiv.org/pdf/2011.11781.pdf)
>  In this paper, we present a structure for two-channel spline graph filter bank with spectral sampling (SGFBSS) on arbitrary undirected graphs. Our proposed structure has many desirable properties; namely, perfect reconstruction, critical sampling in spectral domain, flexibility in choice of shape and cut-off frequency of the filters, and low complexity implementation of the synthesis section, thanks to our closed-form derivation of the synthesis filter and its sparse structure. These properties play a pivotal role in multi-scale transforms of graph signals. Additionally, this framework can use both normalized and non-normalized Laplacian of any undirected graph. We evaluate the performance of our proposed SGFBSS structure in nonlinear approximation and denoising applications through simulations. We also compare our method with the existing graph filter bank structures and show its superior performance.      
### 43.Automatic Recognition of the Supraspinatus Tendinopathy from Ultrasound Images using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.11777.pdf)
>  Tendon injuries like tendinopathies, full and partial thickness tears are prevalent, and the supraspinatus tendon (SST) is the most vulnerable ones in the rotator cuff. Early diagnosis of SST tendinopathies is of high importance and hard to achieve using ultrasound imaging. In this paper, an automatic tendinopathy recognition framework based on convolutional neural networks has been proposed to assist the diagnosis. This framework has two essential parts of tendon segmentation and classification. Tendon segmentation is done through a novel network, NASUNet, which follows an encoder-decoder architecture paradigm and utilizes a multi-scale Enlarging cell. Moreover, a general classification pipeline has been proposed for tendinopathy recognition, which supports different base models as the feature extractor engine. Two feature maps comprising positional information of the tendon region have been introduced as the network input to make the classification network spatial-aware. To evaluate the tendinopathy recognition system, a data set consisting of 100 SST ultrasound images have been acquired, in which tendinopathy cases are double-verified by magnetic resonance imaging. In both segmentation and classification tasks, lack of training data has been compensated by incorporating knowledge transferring, transfer learning, and data augmentation techniques. In cross-validation experiments, the proposed tendinopathy recognition model achieves 91% accuracy, 86.67% sensitivity, and 92.86% specificity, showing state-of-the-art performance against other models.      
### 44.Patch-based field-of-view matching in multi-modal images for electroporation-based ablations  [ :arrow_down: ](https://arxiv.org/pdf/2011.11759.pdf)
>  Various multi-modal imaging sensors are currently involved at different steps of an interventional therapeutic work-flow. Cone beam computed tomography (CBCT), computed tomography (CT) or Magnetic Resonance (MR) images thereby provides complementary functional and/or structural information of the targeted region and organs at risk. Merging this information relies on a correct spatial alignment of the observed anatomy between the acquired images. This can be achieved by the means of multi-modal deformable image registration (DIR), demonstrated to be capable of estimating dense and elastic deformations between images acquired by multiple imaging devices. However, due to the typically different field-of-view (FOV) sampled across the various imaging modalities, such algorithms may severely fail in finding a satisfactory solution. <br>In the current study we propose a new fast method to align the FOV in multi-modal 3D medical images. To this end, a patch-based approach is introduced and combined with a state-of-the-art multi-modal image similarity metric in order to cope with multi-modal medical images. The occurrence of estimated patch shifts is computed for each spatial direction and the shift value with maximum occurrence is selected and used to adjust the image field-of-view. <br>We show that a regional registration approach using voxel patches provides a good structural compromise between the voxel-wise and "global shifts" approaches. The method was thereby beneficial for CT to CBCT and MRI to CBCT registration tasks, especially when highly different image FOVs are involved. Besides, the benefit of the method for CT to CBCT and MRI to CBCT image registration is analyzed, including the impact of artifacts generated by percutaneous needle insertions. Additionally, the computational needs are demonstrated to be compatible with clinical constraints in the practical case of on-line procedures.      
### 45.Federated Semi-Supervised Learning for COVID Region Segmentation in Chest CT using Multi-National Data from China, Italy, Japan  [ :arrow_down: ](https://arxiv.org/pdf/2011.11750.pdf)
>  The recent outbreak of COVID-19 has led to urgent needs for reliable diagnosis and management of SARS-CoV-2 infection. As a complimentary tool, chest CT has been shown to be able to reveal visual patterns characteristic for COVID-19, which has definite value at several stages during the disease course. To facilitate CT analysis, recent efforts have focused on computer-aided characterization and diagnosis, which has shown promising results. However, domain shift of data across clinical data centers poses a serious challenge when deploying learning-based models. In this work, we attempt to find a solution for this challenge via federated and semi-supervised learning. A multi-national database consisting of 1704 scans from three countries is adopted to study the performance gap, when training a model with one dataset and applying it to another. Expert radiologists manually delineated 945 scans for COVID-19 findings. In handling the variability in both the data and annotations, a novel federated semi-supervised learning technique is proposed to fully utilize all available data (with or without annotations). Federated learning avoids the need for sensitive data-sharing, which makes it favorable for institutions and nations with strict regulatory policy on data privacy. Moreover, semi-supervision potentially reduces the annotation burden under a distributed setting. The proposed framework is shown to be effective compared to fully supervised scenarios with conventional data sharing instead of model weight sharing.      
### 46.Accurate and Rapid Diagnosis of COVID-19 Pneumonia with Batch Effect Removal of Chest CT-Scans and Interpretable Artificial Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2011.11736.pdf)
>  Since late 2019, COVID-19 has been spreading over the world and caused the death of many people. The high transmission rate of the virus demands the rapid identification of infected patients to reduce the spread of the disease. The current gold-standard test, Reverse-Transcription Polymerase Chain Reaction (RT-PCR), suffers from a high rate of false negatives. Diagnosis from CT-scan images as an alternative with higher accuracy and sensitivity has the challenge of distinguishing COVID-19 from other lung diseases which demand expert radiologists. In peak times, artificial intelligence (AI) based diagnostic systems can help radiologists to accelerate the process of diagnosis, increase the accuracy, and understand the severity of the disease. We designed an interpretable deep neural network to distinguish healthy people, patients with COVID-19, and patients with other lung diseases from chest CT-scan images. Our model also detects the infected areas of the lung and is able to calculate the percentage of the infected volume. We preprocessed the images to eliminate the batch effect related to CT-scan devices and medical centers and then adopted a weakly supervised method to train the model without having any label for infected parts and any tags for the slices of the CT-scan images that had signs of disease. We trained and evaluated the model on a large dataset of 3359 CT-scan images from 6 medical centers. The model reached a sensitivity of 97.75% and a specificity of 87% in separating healthy people from the diseased and a sensitivity of 98.15% and a specificity of 81.03% in distinguishing COVID-19 from other diseases. The model also reached similar metrics in 1435 samples from 6 unseen medical centers that prove its generalizability. The performance of the model on a large diverse dataset, its generalizability, and interpretability makes it suitable to be used as a diagnostic system.      
### 47.Detecting hidden signs of diabetes in external eye photographs  [ :arrow_down: ](https://arxiv.org/pdf/2011.11732.pdf)
>  Diabetes-related retinal conditions can be detected by examining the posterior of the eye. By contrast, examining the anterior of the eye can reveal conditions affecting the front of the eye, such as changes to the eyelids, cornea, or crystalline lens. In this work, we studied whether external photographs of the front of the eye can reveal insights into both diabetic retinal diseases and blood glucose control. We developed a deep learning system (DLS) using external eye photographs of 145,832 patients with diabetes from 301 diabetic retinopathy (DR) screening sites in one US state, and evaluated the DLS on three validation sets containing images from 198 sites in 18 other US states. In validation set A (n=27,415 patients, all undilated), the DLS detected poor blood glucose control (HbA1c &gt; 9%) with an area under receiver operating characteristic curve (AUC) of 70.2; moderate-or-worse DR with an AUC of 75.3; diabetic macular edema with an AUC of 78.0; and vision-threatening DR with an AUC of 79.4. For all 4 prediction tasks, the DLS's AUC was higher (p&lt;0.001) than using available self-reported baseline characteristics (age, sex, race/ethnicity, years with diabetes). In terms of positive predictive value, the predicted top 5% of patients had a 67% chance of having HbA1c &gt; 9%, and a 20% chance of having vision threatening diabetic retinopathy. The results generalized to dilated pupils (validation set B, 5,058 patients) and to a different screening service (validation set C, 10,402 patients). Our results indicate that external eye photographs contain information useful for healthcare providers managing patients with diabetes, and may help prioritize patients for in-person screening. Further work is needed to validate these findings on different devices and patient populations (those without diabetes) to evaluate its utility for remote diagnosis and management.      
### 48.RACH in Self-Powered NB-IoT Networks: Energy Availability and Performance Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2011.11723.pdf)
>  NarrowBand-Internet of Things (NB-IoT) is a new 3GPP radio access technology designed to provide better coverage for a massive number of low-throughput low-cost devices in delay-tolerant applications with low power consumption. To provide reliable connections with extended coverage, a repetition transmission scheme is introduced to NB-IoT during both Random Access CHannel (RACH) procedure and data transmission procedure. To avoid the difficulty in replacing the battery for IoT devices, the energy harvesting is considered as a promising solution to support energy sustainability in the NB-IoT network. In this work, we analyze RACH success probability in a self-powered NB-IoT network taking into account the repeated preamble transmissions and collisions, where each IoT device with data is active when its battery energy is sufficient to support the transmission. We model the temporal dynamics of the energy level as a birth-death process, derive the energy availability of each IoT device, and examine its dependence on the energy storage capacity and the repetition value. We show that in certain scenarios, the energy availability remains unchanged despite randomness in the energy harvesting. We also derive the exact expression for the RACH success probability of a {randomly chosen} IoT device under the derived energy availability, which is validated under different repetition values via simulations. We show that the repetition scheme can efficiently improve the RACH success probability in a light traffic scenario, but only slightly improves that performance with very inefficient channel resource utilization in a heavy traffic scenario.      
### 49.Explainable-by-design Semi-Supervised Representation Learning for COVID-19 Diagnosis from CT Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2011.11719.pdf)
>  Our motivating application is a real-world problem: COVID-19 classification from CT imaging, for which we present an explainable Deep Learning approach based on a semi-supervised classification pipeline that employs variational autoencoders to extract efficient feature embedding. We have optimized the architecture of two different networks for CT images: (i) a novel conditional variational autoencoder (CVAE) with a specific architecture that integrates the class labels inside the encoder layers and uses side information with shared attention layers for the encoder, which make the most of the contextual clues for representation learning, and (ii) a downstream convolutional neural network for supervised classification using the encoder structure of the CVAE. With the explainable classification results, the proposed diagnosis system is very effective for COVID-19 classification. Based on the promising results obtained qualitatively and quantitatively, we envisage a wide deployment of our developed technique in large-scale clinical studies.Code is available at <a class="link-external link-https" href="https://git.etrovub.be/AVSP/ct-based-covid-19-diagnostic-tool.git" rel="external noopener nofollow">this https URL</a>.      
### 50.Streaming Multi-speaker ASR with RNN-T  [ :arrow_down: ](https://arxiv.org/pdf/2011.11671.pdf)
>  Recent research shows end-to-end ASR systems can recognize overlapped speech from multiple speakers. However, all published works have assumed no latency constraints during inference, which does not hold for most voice assistant interactions. This work focuses on multi-speaker speech recognition based on a recurrent neural network transducer (RNN-T) that has been shown to provide high recognition accuracy at a low latency online recognition regime. We investigate two approaches to multi-speaker model training of the RNN-T: deterministic output-target assignment and permutation invariant training. We show that guiding separation with speaker order labels in the former case enhances the high-level speaker tracking capability of RNN-T. Apart from that, with multistyle training on single- and multi-speaker utterances, the resulting models gain robustness against ambiguous numbers of speakers during inference. Our best model achieves a WER of 10.2% on simulated 2-speaker LibriSpeech data, which is competitive with the previously reported state-of-the-art nonstreaming model (10.3%), while the proposed model could be directly applied for streaming applications.      
### 51.Safely Learning Dynamical Systems from Short Trajectories  [ :arrow_down: ](https://arxiv.org/pdf/2011.12257.pdf)
>  A fundamental challenge in learning to control an unknown dynamical system is to reduce model uncertainty by making measurements while maintaining safety. In this work, we formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize the next trajectory. In our framework, the state of the system is required to stay within a given safety region under the (possibly repeated) action of all dynamical systems that are consistent with the information gathered so far. For our first two results, we consider the setting of safely learning linear dynamics. We present a linear programming-based algorithm that either safely recovers the true dynamics from trajectories of length one, or certifies that safe learning is impossible. We also give an efficient semidefinite representation of the set of initial conditions whose resulting trajectories of length two are guaranteed to stay in the safety region. For our final result, we study the problem of safely learning a nonlinear dynamical system. We give a second-order cone programming based representation of the set of initial conditions that are guaranteed to remain in the safety region after one application of the system dynamics.      
### 52.Symmetry Reduction in Optimal Control of Multiagent Systems on Lie Groups  [ :arrow_down: ](https://arxiv.org/pdf/2011.12234.pdf)
>  We study the reduction of degrees of freedom for the equations that determine necessary optimality conditions for extrema in an optimal control problem for a multiagent system by exploiting the physical symmetries of agents, where the kinematics of each agent is given by a left-invariant control system. Reduced optimality conditions are obtained using techniques from variational calculus and Lagrangian mechanics. A Hamiltonian formalism is also studied, where the problem is explored through an application of Pontryagin's maximum principle for left-invariant systems, and the optimality conditions are obtained as integral curves of a reduced Hamiltonian vector field. We apply the results to an energy-minimum control problem for multiple unicycles.      
### 53.Linear Convergence of Distributed Mirror Descent with Integral Feedback for Strongly Convex Problems  [ :arrow_down: ](https://arxiv.org/pdf/2011.12233.pdf)
>  Distributed optimization often requires finding the minimum of a global objective function written as a sum of local functions. A group of agents work collectively to minimize the global function. We study a continuous-time decentralized mirror descent algorithm that uses purely local gradient information to converge to the global optimal solution. The algorithm enforces consensus among agents using the idea of integral feedback. Recently, Sun and Shahrampour (2020) studied the asymptotic convergence of this algorithm for when the global function is strongly convex but local functions are convex. Using control theory tools, in this work, we prove that the algorithm indeed achieves (local) exponential convergence. We also provide a numerical experiment on a real data-set as a validation of the convergence speed of our algorithm.      
### 54.Wide-angle Image Rectification: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2011.12108.pdf)
>  Wide field-of-view (FOV) cameras, which capture a larger scene area than narrow FOV cameras, are used in many applications including 3D reconstruction, autonomous driving, and video surveillance. However, wide-angle images contain distortions that violate the assumptions underlying pinhole camera models, resulting in object distortion, difficulties in estimating scene distance, area, and direction, and preventing the use of off-the-shelf deep models trained on undistorted images for downstream computer vision tasks. Image rectification, which aims to correct these distortions, can solve these problems. In this paper, we comprehensively survey progress in wide-angle image rectification from transformation models to rectification methods. Specifically, we first present a detailed description and discussion of the camera models used in different approaches. Then, we summarize several distortion models including radial distortion and projection distortion. Next, we review both traditional geometry-based image rectification methods and deep learning-based methods, where the former formulate distortion parameter estimation as an optimization problem and the latter treat it as a regression problem by leveraging the power of deep neural networks. We evaluate the performance of state-of-the-art methods on public datasets and show that although both kinds of methods can achieve good results, these methods only work well for specific camera models and distortion types. We also provide a strong baseline model and carry out an empirical study of different distortion models on synthetic datasets and real-world wide-angle images. Finally, we discuss several potential research directions that are expected to further advance this area in the future.      
### 55.Model Order Reduction for Gas and Energy Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.12099.pdf)
>  To counter the volatile nature of renewable energy sources, gas networks take a vital role. But, to ensure fulfillment of contracts under these new circumstances, a vast number of possible scenarios, incorporating uncertain supply and demand, has to be simulated ahead of time. This many-query task can be accelerated by model order reduction, yet, large-scale, nonlinear, parametric, hyperbolic partial differential (-algebraic) equation systems, modeling gas transport, are a challenging application for model reduction algorithms. <br>For this industrial application, we bring together the scientific computing topics of: mathematical modeling of gas transport networks, numerical simulation of hyperbolic partial differential equation, and model order reduction for nonlinear parametric systems. This research resulted in the "morgen" (Model Order Reduction for Gas and Energy Networks) software platform, which enables modular testing of various combinations of models, solvers, and model reduction methods. In this work we present the theoretical background on systemic modeling and structured, data-driven, system-theoretic model reduction for gas networks, as well as the implementation of "morgen" and associated numerical experiments testing model reduction adapted to gas network models.      
### 56.On stability of nonzero set-point for non linear impulsive control systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.12085.pdf)
>  The interest in non-linear impulsive systems (NIS) has been growing due to its impact in application problems such as disease treatments (diabetes, HIV, influenza, among many others), where the control action (drug administration) is given by short-duration pulses followed by time periods of null values. Within this framework the concept of equilibrium needs to be extended (redefined) to allows the system to keep orbiting (between two consecutive pulses) in some state space regions out of the origin, according to usual objectives of most real applications. Although such regions can be characterized by means of a discrete-time system obtained by sampling the NIS at the impulsive times, no agreements have reached about their asymptotic stability (AS). This paper studies the asymptotic stability of control equilibrium orbits for NSI, based on the underlying discrete time system, in order to establish the conditions under which the AS for the latter leads to the AS for the former. Furthermore, based on the latter AS characterization, an impulsive Model Predictive Control (i-MPC) that feasibly stabilizes the non-linear impulsive system is presented. Finally, the proposed stable MPC is applied to two control problems of interest: the intravenous bolus administration of Lithium and the administration of antiretrovirals for HIV treatments.      
### 57.Dendritic trafficking: synaptic scaling and structural plasticity  [ :arrow_down: ](https://arxiv.org/pdf/2011.12067.pdf)
>  Neuronal circuits internally regulate electrical signaling via a host of homeostatic mechanisms. Two prominent mechanisms, synaptic scaling and structural plasticity, are believed to maintain average activity within an operating range by modifying the strength and spatial extent of network connectivity using negative feedback. However, both mechanisms operate on relatively slow timescales and thus face fundamental limits due to delays. We show that these mechanisms fulfill complementary roles in maintaining stability in a large network. In particular, even relatively, slow growth dynamics improves performance significantly beyond synaptic scaling alone.      
### 58.Infrared small target detection based on isotropic constraint under complex background  [ :arrow_down: ](https://arxiv.org/pdf/2011.12059.pdf)
>  Infrared search and tracking (IRST) system has been widely concerned and applied in the area of national defence. Small target detection under complex background is a very challenging task in the development of system algorithm. Low signal-to-clutter ratio (SCR) of target and the interference caused by irregular background clutter make it difficult to get an accurate result. In this paper, small targets are considered to have two characteristics of high contrast and isotropy, and we propose a multilayer gray difference (MGD) method constrained by isotropy. Firstly, the suspected regions are obtained through MGD, and then the eigenvalues of the original image's Hessian matrix are calculated to obtain the isotropy parameter of each region. Finally, those regions do not meet the isotropic constraint condition are suppressed. Experiments show that the proposed method is effective and superior to several common methods in terms of signal-to-clutter ratio gain (SCRG) and receiver operating characteristic (ROC) curve.      
### 59.Multi-Decoder DPRNN: High Accuracy Source Counting and Separation  [ :arrow_down: ](https://arxiv.org/pdf/2011.12022.pdf)
>  ChampaignABSTRACTWe propose an end-to-end trainable approach to single-channel speech separation with unknown number of speakers.Our approach extends the MulCat source separation backbonewith additional output heads: a count-head to infer the num-ber of speakers, and decoder-heads for reconstructing theoriginal signals. Beyond the model, we also propose a metricon how to evaluate source separation with variable numberof speakers. Specifically, we cleared up the issue on how toevaluate the quality when the ground-truth hasmore or lessspeakersthan the ones predicted by the model. We evaluateour approach on the WSJ0-mix datasets, with mixtures upto five speakers. We demonstrate that our approach outper-forms state-of-the-art in counting the number of speakers andremains competitive in quality of reconstructed signals.      
### 60.A Novel Multimodal Music Genre Classifier using Hierarchical Attention and Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.11970.pdf)
>  Music genre classification is one of the trending topics in regards to the current Music Information Retrieval (MIR) Research. Since, the dependency of genre is not only limited to the audio profile, we also make use of textual content provided as lyrics of the corresponding song. We implemented a CNN based feature extractor for spectrograms in order to incorporate the acoustic features and a Hierarchical Attention Network based feature extractor for lyrics. We then go on to classify the music track based upon the resulting fused feature vector.      
### 61.Policy Optimization for Markovian Jump Linear Quadratic Control: Gradient-Based Methods and Global Convergence  [ :arrow_down: ](https://arxiv.org/pdf/2011.11852.pdf)
>  Recently, policy optimization for control purposes has received renewed attention due to the increasing interest in reinforcement learning. In this paper, we investigate the global convergence of gradient-based policy optimization methods for quadratic optimal control of discrete-time Markovian jump linear systems (MJLS). First, we study the optimization landscape of direct policy optimization for MJLS, with static state feedback controllers and quadratic performance costs. Despite the non-convexity of the resultant problem, we are still able to identify several useful properties such as coercivity, gradient dominance, and almost smoothness. Based on these properties, we show global convergence of three types of policy optimization methods: the gradient descent method; the Gauss-Newton method; and the natural policy gradient method. We prove that all three methods converge to the optimal state feedback controller for MJLS at a linear rate if initialized at a controller which is mean-square stabilizing. Some numerical examples are presented to support the theory. This work brings new insights for understanding the performance of policy gradient methods on the Markovian jump linear quadratic control problem.      
### 62.Health-Focused Optimal Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2011.11849.pdf)
>  In this paper, we propose a novel Health-Focused Optimal Power Flow (HF-OPF) to take into account the equipment health in operational and physical constraints. The health condition index is estimated based on the possible fault characteristics for generators and batteries. The paper addresses the need for understanding the relationship between health condition index and the operational constraints in OPF problems. Such a relationship is established through Finite Element Method (FEM)-based simulations. The simulations for generator and battery faults indicate the presence of an inflection point after which effect of fault becomes severe. A microgrid system is used to illustrate the performance of the proposed HF-OPF. The results show that health condition inflicts high cost of generation and can lead to infeasibility even with less critical faults.      
### 63.Stabilizing Queuing Networks with Model Data-Independent Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.11788.pdf)
>  This work studies the stability of multi-class queuing networks under a class of centralized or decentralized model data-independent (MDI) control policies, which only depend on traffic state observation and network topology. Control actions include routing, sequencing, and holding. By constructing piecewise-linear test functions, we derive an easy-to-use criterion to check the stability of a multi-class network under a given MDI control policy. For stabilizable multi-class networks, we show that a centralized, stabilizing MDI control policy exists. For stabilizable single-class networks, we further show that a decentralized, stabilizing MDI control policy exists. In addition, for both scenarios, we explicitly construct throughput-maximizing policies and present numerical examples to illustrate the results.      
### 64.A robust solution of a statistical inverse problem in multiscale computational mechanics using an artificial neural network  [ :arrow_down: ](https://arxiv.org/pdf/2011.11761.pdf)
>  This work addresses the inverse identification of apparent elastic properties of random heterogeneous materials using machine learning based on artificial neural networks. The proposed neural network-based identification method requires the construction of a database from which an artificial neural network can be trained to learn the nonlinear relationship between the hyperparameters of a prior stochastic model of the random compliance field and some relevant quantities of interest of an ad hoc multiscale computational model. An initial database made up with input and target data is first generated from the computational model, from which a processed database is deduced by conditioning the input data with respect to the target data using the nonparametric statistics. Two-and three-layer feedforward artificial neural networks are then trained from each of the initial and processed databases to construct an algebraic representation of the nonlinear mapping between the hyperparameters (network outputs) and the quantities of interest (network inputs). The performances of the trained artificial neural networks are analyzed in terms of mean squared error, linear regression fit and probability distribution between network outputs and targets for both databases. An ad hoc probabilistic model of the input random vector is finally proposed in order to take into account uncertainties on the network input and to perform a robustness analysis of the network output with respect to the input uncertainties level. The capability of the proposed neural network-based identification method to efficiently solve the underlying statistical inverse problem is illustrated through two numerical examples developed within the framework of 2D plane stress linear elasticity, namely a first validation example on synthetic data obtained through computational simulations and a second application example on real experimental data obtained through a physical experiment monitored by digital image correlation on a real heterogeneous biological material (beef cortical bone).      
### 65.Multi-regime analysis for computer vision-based traffic surveillance using a change-point detection algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2011.11758.pdf)
>  As a result of significant advances in deep learning, computer vision technology has been widely adopted in the field of traffic surveillance. Nonetheless, it is difficult to find a universal model that can measure traffic parameters irrespective of ambient conditions such as times of the day, weather, or shadows. These conditions vary recurrently, but the exact points of change are inconsistent and unpredictable. Thus, the application of a multi-regime method would be problematic, even when separate sets of model parameters are prepared in advance. In the present study we devised a robust approach that facilitates multi-regime analysis. This approach employs an online parametric algorithm to determine the change-points for ambient conditions. An autoencoder was used to reduce the dimensions of input images, and reduced feature vectors were used to implement the online change-point algorithm. Seven separate periods were tagged with typical times in a given day. Multi-regime analysis was then performed so that the traffic density could be separately measured for each period. To train and test models for vehicle counting, 1,100 video images were randomly chosen for each period and labeled with traffic counts. The measurement accuracy of multi-regime analysis was much higher than that of an integrated model trained on all data.      
### 66.Path Design and Resource Management for NOMA enhanced Indoor Intelligent Robots  [ :arrow_down: ](https://arxiv.org/pdf/2011.11745.pdf)
>  A communication enabled indoor intelligent robots (IRs) service framework is proposed, where non-orthogonal multiple access (NOMA) technique is adopted to enable highly reliable communications. In cooperation with the ultramodern indoor channel model recently proposed by the International Telecommunication Union (ITU), the Lego modeling method is proposed, which can deterministically describe the indoor layout and channel state in order to construct the radio map. The investigated radio map is invoked as a virtual environment to train the reinforcement learning agent, which can save training time and hardware costs. Build on the proposed communication model, motions of IRs who need to reach designated mission destinations and their corresponding down-link power allocation policy are jointly optimized to maximize the mission efficiency and communication reliability of IRs. In an effort to solve this optimization problem, a novel reinforcement learning approach named deep transfer deterministic policy gradient (DT-DPG) algorithm is proposed. Our simulation results demonstrate that 1) With the aid of NOMA techniques, the communication reliability of IRs is effectively improved; 2) The radio map is qualified to be a virtual training environment, and its statistical channel state information improves training efficiency by about 30%; 3) The proposed DT-DPG algorithm is superior to the conventional deep deterministic policy gradient (DDPG) algorithm in terms of optimization performance, training time, and anti-local optimum ability.      
### 67.Multi-task Language Modeling for Improving Speech Recognition of Rare Words  [ :arrow_down: ](https://arxiv.org/pdf/2011.11715.pdf)
>  End-to-end automatic speech recognition (ASR) systems are increasingly popular due to their relative architectural simplicity and competitive performance. However, even though the average accuracy of these systems may be high, the performance on rare content words often lags behind hybrid ASR systems. To address this problem, second-pass rescoring is often applied. In this paper, we propose a second-pass system with multi-task learning, utilizing semantic targets (such as intent and slot prediction) to improve speech recognition performance. We show that our rescoring model with trained with these additional tasks outperforms the baseline rescoring model, trained with only the language modeling task, by 1.4% on a general test and by 2.6% on a rare word test set in term of word-error-rate relative (WERR).      

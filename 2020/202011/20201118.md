# ArXiv eess --Wed, 18 Nov 2020
### 1.A Multi-Task Deep Learning Framework to Localize the Eloquent Cortex in Brain Tumor Patients Using Dynamic Functional Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2011.08813.pdf)
>  We present a novel deep learning framework that uses dynamic functional connectivity to simultaneously localize the language and motor areas of the eloquent cortex in brain tumor patients. Our method leverages convolutional layers to extract graph-based features from the dynamic connectivity matrices and a long-short term memory (LSTM) attention network to weight the relevant time points during classification. The final stage of our model employs multi-task learning to identify different eloquent subsystems. Our unique training strategy finds a shared representation between the cognitive networks of interest, which enables us to handle missing patient data. We evaluate our method on resting-state fMRI data from 56 brain tumor patients while using task fMRI activations as surrogate ground-truth labels for training and testing. Our model achieves higher localization accuracies than conventional deep learning approaches and can identify bilateral language areas even when trained on left-hemisphere lateralized cases. Hence, our method may ultimately be useful for preoperative mapping in tumor patients.      
### 2.Taming and Leveraging Interference in Mobile Radar Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.08803.pdf)
>  Mobile radar networks, such as autonomous driving systems, are subject to the severe challenge of mutual interference. Despite the inborn interference-proof capability in frequency modulation continuous waveform (FMCW) radar, interference management is necessary for dense radar networks. The approaches combatting the radar interference include the timing diversity of waveform parameters, data-driven detection interference, and signal processing based decoupling of interference. Moreover, the leverage of radar interference for inferring the information of interfere is studied. Simulations are carried out in the scenario of radar interferences in vehicular networks, which demonstrates the performance of the proposed algorithms.      
### 3.Imaging Using Millimeter Wave Communication Networks: A Bonus SAR  [ :arrow_down: ](https://arxiv.org/pdf/2011.08801.pdf)
>  In the next generations of cellular communication networks, higher density of base stations and higher frequency bands will be adopted. If being reflected by targets, the communication signal also brings information of the targets, in addition to the communication messages, to the receivers. In this paper, it is proposed to leverage the reflected communication signals to reconstruct an image of the environment. Due to the analogy to traditional synthetic aperture radar (SAR) and inverse SAR (ISAR), the principles of SAR and ISAR, namely the tomography via Fourier transformation, are adopted with necessary improvements. The algorithms are further refined to estimate the 3-dimensional silhouette of the environment. Numerical simulations are carried out to demonstrate the proposed algorithms.      
### 4.A Spiking Neural Network (SNN) for detecting High Frequency Oscillations (HFOs) in the intraoperative ECoG  [ :arrow_down: ](https://arxiv.org/pdf/2011.08783.pdf)
>  To achieve seizure freedom, epilepsy surgery requires the complete resection of the epileptogenic brain tissue. In intraoperative ECoG recordings, high frequency oscillations (HFOs) generated by epileptogenic tissue can be used to tailor the resection margin. However, automatic detection of HFOs in real-time remains an open challenge. Here we present a spiking neural network (SNN) for automatic HFO detection that is optimally suited for neuromorphic hardware implementation. We trained the SNN to detect HFO signals measured from intraoperative ECoG on-line, using an independently labeled dataset. We targeted the detection of HFOs in the fast ripple frequency range (250-500 Hz) and compared the network results with the labeled HFO data. We endowed the SNN with a novel artifact rejection mechanism to suppress sharp transients and demonstrate its effectiveness on the ECoG dataset. The HFO rates (median 6.6 HFO/min in pre-resection recordings) detected by this SNN are comparable to those published in the dataset (58 min, 16 recordings). The postsurgical seizure outcome was "predicted" with 100% accuracy for all 8 patients. These results provide a further step towards the construction of a real-time portable battery-operated HFO detection system that can be used during epilepsy surgery to guide the resection of the epileptogenic zone.      
### 5.Learning Sentinel-2 Spectral Dynamics for Long-Run Predictions Using Residual Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.08746.pdf)
>  Making the most of multispectral image time-series is a promis-ing but still relatively under-explored research direction be-cause of the complexity of jointly analyzing spatial, spectraland temporal information. Being able to capture temporaldynamics can drastically improve results on tasks such as un-mixing or classification, and allow to tackle filtering, denoisingor interpolation problems in an unified and principled process.Dealing with time-series dynamics classically requires theknowledge of a dynamical model and an observation model.The former may be incorrect or computationally hard to han-dle, thus motivating data-driven strategies aiming at learningdynamics directly from data. In this paper, we adapt neuralnetwork architectures to learn periodic dynamics of both sim-ulated and real multispectral time-series. We emphasize thenecessity of choosing the right state variable to capture peri-odic dynamics and show that our models can reproduce theaverage seasonal dynamics of vegetation using only one yearof training data.      
### 6.A Load Switching Group based Feeder-level Microgrid Energy Management Algorithm for Service Restoration in Power Distribution System  [ :arrow_down: ](https://arxiv.org/pdf/2011.08735.pdf)
>  This paper presents a load switching group based energy management system (LSG-EMS) for operating microgrids on a distribution feeder powered by one or multiple grid-forming distributed energy resources. Loads on a distribution feeder are divided into load switching groups that can be remotely switched on and off. The LSG-EMS algorithm, formulated as a mixed-integer linear programming (MILP) problem, has an objective function of maximizing the served loads while minimizing the total number of switching actions. A new set of topology constraints are developed for allowing multiple microgrids to be formed on the feeder and selecting the optimal supply path. Customer comfort is accounted for by maximizing the supply duration in the customer preferred service period and enforcing a minimum service duration. The proposed method is demonstrated on a modified IEEE 33-bus system using actual customer data. Simulation results show that the LSG-EMS successfully coordinates multiple grid-forming sources by selecting an optimal supply topology that maximizes the supply period of both the critical and noncritical loads while minimizing customer service interruptions in the service restoration process.      
### 7.Robust Stability of Suboptimal Moving Horizon Estimation using an Observer-Based Candidate Solution  [ :arrow_down: ](https://arxiv.org/pdf/2011.08723.pdf)
>  In this paper, we propose a suboptimal moving horizon estimator for nonlinear systems. For the stability analysis we transfer the "feasibility-implies-stability/robustness" paradigm from model predictive control to the context of moving horizon estimation in the following sense: Using a suitably defined, feasible candidate solution based on the trajectory of an auxiliary observer, robust stability of the proposed suboptimal estimator is inherited independently of the horizon length and even if no optimization is performed.      
### 8.FPAENet: Pneumonia Detection Network Based on Feature Pyramid Attention Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2011.08706.pdf)
>  Automatic pneumonia Detection based on deep learning has increasing clinical value. Although the existing Feature Pyramid Network (FPN) and its variants have already achieved some great successes, their detection accuracies for pneumonia lesions in medical images are still unsatisfactory. In this paper, we propose a pneumonia detection network based on feature pyramid attention enhancement, which integrates attended high-level semantic features with low-level information. We add another information extracting path equipped with feature enhancement modules, which are conducted with an attention mechanism. Experimental results show that our proposed method can achieve much better performances, as a higher value of 4.02% and 3.19%, than the baselines in detecting pneumonia lesions.      
### 9.Loss Comparison of Electric Vehicle Fuel Cell Integration Methods  [ :arrow_down: ](https://arxiv.org/pdf/2011.08688.pdf)
>  This study analyzes and compares the drivetrain losses of two methods of fuel cell integration in electric vehicle drivetrains. The first is a conventional (boosted) two-stage system while the second is a dual inverter based solution. Each source of drivetrain losses is described by mathematical equations and the impact of higher order harmonics are observed through circuit model simulation. The dual inverter system achieves an overall energy efficiency improvement of 5.27% and 10.13% for highway and urban driving compared to the conventional method. The use of lower voltage rated power modules and lower switching frequency in the dual inverter system has significantly reduced the switching losses and improved the driving efficiency.      
### 10.PhaseGAN: A deep-learning phase-retrieval approach for unpaired datasets  [ :arrow_down: ](https://arxiv.org/pdf/2011.08660.pdf)
>  Phase retrieval approaches based on DL provide a framework to obtain phase information from an intensity hologram or diffraction pattern in a robust manner and in real time. However, current DL architectures applied to the phase problem rely i) on paired datasets, i. e., they are only applicable when a satisfactory solution of the phase problem has been found, and ii) on the fact that most of them ignore the physics of the imaging process. Here, we present PhaseGAN, a new DL approach based on Generative Adversarial Networks, which allows the use of unpaired datasets and includes the physics of image formation. Performance of our approach is enhanced by including the image formation physics and provides phase reconstructions when conventional phase retrieval algorithms fail, such as ultra-fast experiments. Thus, PhaseGAN offers the opportunity to address the phase problem when no phase reconstructions are available, but good simulations of the object or data from other experiments are available, enabling us to obtain results not possible before.      
### 11.Lung Segmentation in Chest X-rays with Res-CR-Net  [ :arrow_down: ](https://arxiv.org/pdf/2011.08655.pdf)
>  Deep Neural Networks (DNN) are widely used to carry out segmentation tasks in biomedical images. Most DNNs developed for this purpose are based on some variation of the encoder-decoder U-Net architecture. Here we show that Res-CR-Net, a new type of fully convolutional neural network, which was originally developed for the semantic segmentation of microscopy images, and which does not adopt a U-Net architecture, is very effective at segmenting the lung fields in chest X-rays from either healthy patients or patients with a variety of lung pathologies.      
### 12.Space-time budget allocation policy design for viral marketing  [ :arrow_down: ](https://arxiv.org/pdf/2011.08639.pdf)
>  We address formally the problem of opinion dynamics when the agents of a social network (e.g., consumers) are not only influenced by their neighbors but also by an external influential entity referred to as a marketer. The influential entity tries to sway the overall opinion as close as possible to a desired opinion by using a specific influence budget. We assume that the exogenous influences of the entity happen during discrete-time advertising campaigns; consequently, the overall closed-loop opinion dynamics becomes a linear-impulsive (hybrid) one. The main technical issue addressed is finding how the marketer should allocate its budget over time (through marketing campaigns) and over space (among the agents) such that the agents' opinion be as close as possible to the desired opinion. Our main results show that the marketer has to prioritize certain agents over others based on their initial condition, their influence power in the social graph and the size of the cluster they belong to. The corresponding space-time allocation problem is formulated and solved for several special cases of practical interest. Valuable insights can be extracted from our analysis. For instance, for most cases, we prove that the marketer has an interest in investing most of its budget at the beginning of the process and that budget should be shared among agents according to the famous water-filling allocation rule. Numerical examples illustrate the analysis.      
### 13.A tunable mixed feedback oscillator  [ :arrow_down: ](https://arxiv.org/pdf/2011.08564.pdf)
>  The interplay of positive and negative feedback loops on different time scales appears to be a fundamental mechanisms for robust and tunable oscillations in both biological systems and electro-mechanical systems. We develop a detailed analysis of a basic three dimensional Lure model to show how controlled oscillations arise from the tuning of positive and negative feedback strengths. Our analysis is based on dominance theory and confirms, from a system-theoretic perspective, that the mixed feedback is a fundamental enabler of robust oscillations. Our results are not limited to three dimensional systems and extend to larger systems via passivity theory, and to uncertain systems via small gain arguments.      
### 14.Deep Learning Based HPV Status Prediction for Oropharyngeal Cancer Patients  [ :arrow_down: ](https://arxiv.org/pdf/2011.08555.pdf)
>  We investigated the ability of deep learning models for imaging based HPV status detection. To overcome the problem of small medical datasets we used a transfer learning approach. A 3D convolutional network pre-trained on sports video clips was fine tuned such that full 3D information in the CT images could be exploited. The video pre-trained model was able to differentiate HPV-positive from HPV-negative cases with an area under the receiver operating characteristic curve (AUC) of 0.81 for an external test set. In comparison to a 3D convolutional neural network (CNN) trained from scratch and a 2D architecture pre-trained on ImageNet the video pre-trained model performed best.      
### 15.Marketing resource allocation in duopolies over social networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.08553.pdf)
>  One of the key features of this paper is that the agents' opinion of a social network is assumed to be not only influenced by the other agents but also by two marketers in competition. One of our contributions is to propose a pragmatic game-theoretical formulation of the problem and to conduct the complete corresponding equilibrium analysis (existence, uniqueness, dynamic characterization, and determination). Our analysis provides practical insights to know how a marketer should exploit its knowledge about the social network to allocate its marketing or advertising budget among the agents (who are the consumers). By providing relevant definitions for the agent influence power (AIP) and the gain of targeting (GoT), the benefit of using a smart budget allocation policy instead of a uniform one is assessed and operating conditions under which it is potentially high are identified.      
### 16.Improving magnetic nanothermometry accuracy through mixing-frequency excitation  [ :arrow_down: ](https://arxiv.org/pdf/2011.08532.pdf)
>  In this study, we proposed a temperature model of magnetic nanoparticle relaxation and a phase measurement method under a mixing-frequency excitation field, which can improve the temperature accuracy of magnetic nanothermometry. According to the Debye-based magnetization model for magnetic nanoparticles, the phases at the mixing frequencies are used to solve the relaxation phase delay to the magnetic field with the higher frequency. The method could improve the signal-to-noise ratio of the magnetic response signal, and also weaken the phase shift of the detection coils caused by temperature changes. Experimental results show that the method can achieve static temperature measurement error less than 0.1K and dynamic temperature measurement error less than 0.2K.      
### 17.Decision and Feature Level Fusion of Deep Features Extracted from Public COVID-19 Data-sets  [ :arrow_down: ](https://arxiv.org/pdf/2011.08528.pdf)
>  The Coronavirus (COVID-19), which is an infectious pulmonary disorder, has affected millions of people and has been declared as a global pandemic by the WHO. Due to highly contagious nature of COVID-19 and its high possibility of causing severe conditions in the patients, the development of rapid and accurate diagnostic tools have gained importance. The real-time reverse transcription-polymerize chain reaction (RT-PCR) is used to detect the presence of Coronavirus RNA by using the mucus and saliva mixture samples. But, RT-PCR suffers from having low-sensitivity especially in the early stage. Therefore, the usage of chest radiography has been increasing in the early diagnosis of COVID-19 due to its fast imaging speed, significantly low cost and low dosage exposure of radiation. In our study, a computer-aided diagnosis system for X-ray images based on convolutional neural networks (CNNs), which can be used by radiologists as a supporting tool in COVID-19 detection, has been proposed. Deep feature sets extracted by using CNNs were concatenated for feature level fusion and fed to multiple classifiers in terms of decision level fusion idea with the aim of discriminating COVID-19, pneumonia and no-finding classes. In the decision level fusion idea, a majority voting scheme was applied to the resultant decisions of classifiers. The obtained accuracy values and confusion matrix based evaluation criteria were presented for three progressively created data-sets. The aspects of the proposed method that are superior to existing COVID-19 detection studies have been discussed and the fusion performance of proposed approach was validated visually by using Class Activation Mapping technique. The experimental results show that the proposed approach has attained high COVID-19 detection performance that was proven by its comparable accuracy and superior precision/recall values with the existing studies.      
### 18.Challenging an experimental nonlinear modal analysis method with a new strongly friction-damped structure  [ :arrow_down: ](https://arxiv.org/pdf/2011.08527.pdf)
>  In this work, we show that a recently proposed method for experimental nonlinear modal analysis based on the extended periodic motion concept is well suited to extract modal properties for strongly nonlinear systems (i.e. in the presence of large frequency shifts, high and nonlinear damping, changes of the mode shape, and higher harmonics). To this end, we design a new test rig that exhibits a large extent of friction-induced damping (modal damping ratio up to 15 %) and frequency shift by 36 %. The specimen, called RubBeR, is a cantilevered beam under the influence of dry friction, ranging from full stick to mainly sliding. With the specimen's design, the measurements are well repeatable for a system subjected to dry frictional force. Then, we apply the method to the specimen and show that single-point excitation is sufficient to track the modal properties even though the deflection shape changes with amplitude. Computed frequency responses using a single nonlinear-modal oscillator with the identified modal properties agree well with measured reference curves of different excitation levels, indicating the modal properties' significance and accuracy.      
### 19.Experimental assessment of polynomial nonlinear state-space and nonlinear-mode models for near-resonant vibrations  [ :arrow_down: ](https://arxiv.org/pdf/2011.08520.pdf)
>  In the present paper, two existing nonlinear system identification methodologies are used to identify data-driven models. The first methodology focuses on identifying the system using steady-state excitations. To accomplish this, a phase-locked loop controller is implemented to acquire periodic oscillations near resonance and construct a nonlinear-mode model. This model is based on amplitude-dependent modal properties, i.e. does not require nonlinear basis functions. The second methodology exploits uncontrolled experiments with broadband random inputs to build polynomial nonlinear state-space models using advanced system identification tools. The methods are applied to two experimental test rigs, a magnetic cantilever beam and a free-free beam with a lap joint. The respective models of both methods and both specimens are then challenged to predict dynamic, near-resonant behavior observed under different sine and sine-sweep excitations. The vibration prediction of the nonlinear-mode and state-space models clearly highlight the capabilities and limitations of the models. The nonlinear-mode model, by design, yields a perfect match at resonance peaks and high accuracy in close vicinity. However, it is limited to well-spaced modes and sinusoidal excitation. The state-space model covers a wider dynamic range, including transient excitations. However, the real-life nonlinearities considered in this study can only be approximated by polynomial basis functions. Consequently, the identified state-space models are found to be highly input-dependent, in particular for sinusoidal excitations where they are found to lead to a low predictive capability.      
### 20.A Phase Resonance Approach for Modal Testing of Structures with Nonlinear Dissipation  [ :arrow_down: ](https://arxiv.org/pdf/2011.08500.pdf)
>  The concept of nonlinear modes is useful for the dynamical characterization of nonlinear mechanical systems. While efficient and broadly applicable methods are now available for the computation of nonlinear modes, nonlinear modal testing is still in its infancy. The purpose of this work is to overcome its present limitation to conservative nonlinearities. Our approach relies on the recently extended periodic motion concept, according to which nonlinear modes of damped systems are defined as family of periodic motions induced by an appropriate artificial excitation that compensates the natural dissipation. The particularly simple experimental implementation with only a single-point, single-frequency, phase resonant forcing is analyzed in detail. The method permits the experimental extraction of natural frequencies, modal damping ratios and deflection shapes (including harmonics), for each mode of interest, as function of the vibration level. The accuracy, robustness and current limitations of the method are first demonstrated numerically. The method is then verified experimentally for a friction-damped system. Moreover, a self-contained measure for estimating the quality of the extracted modal properties is investigated. The primary advantages over alternative vibration testing methods are noise robustness, broad applicability and short measurement duration. The central limitation of the identified modal quantities is that they only characterize the system in the regime near isolated resonances.      
### 21.s-Transformer: Segment-Transformer for Robust Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2011.08480.pdf)
>  Neural end-to-end text-to-speech (TTS) , which adopts either a recurrent model, e.g. Tacotron, or an attention one, e.g. Transformer, to characterize a speech utterance, has achieved significant improvement of speech synthesis. However, it is still very challenging to deal with different sentence lengths, particularly, for long sentences where sequence model has limitation of the effective context length. We propose a novel segment-Transformer (s-Transformer), which models speech at segment level where recurrence is reused via cached memories for both the encoder and decoder. Long-range contexts can be captured by the extended memory, meanwhile, the encoder-decoder attention on segment which is much easier to handle. In addition, we employ a modified relative positional self attention to generalize sequence length beyond a period possibly unseen in the training data. By comparing the proposed s-Transformer with the standard Transformer, on short sentences, both achieve the same MOS scores of 4.29, which is very close to 4.32 by the recordings; similar scores of 4.22 vs 4.2 on long sentences, and significantly better for extra-long sentences with a gain of 0.2 in MOS. Since the cached memory is updated with time, the s-Transformer generates rather natural and coherent speech for a long period of time.      
### 22.Data-Driven Reachability Analysis Using Matrix Zonotopes  [ :arrow_down: ](https://arxiv.org/pdf/2011.08472.pdf)
>  In this paper, we propose a data-driven reachability analysis approach for an unknown control system. Reachability analysis is an essential tool for guaranteeing safety properties. However, most current reachability analysis heavily relies on the existence of a suitable system model, which is often not directly available in practice. We instead propose a reachability analysis approach based on noisy data. More specifically, we first provide an algorithm for over-approximating the reachable set of a linear time-invariant system using matrix zonotopes. Then we introduce an extension for nonlinear systems. We provide theoretical guarantees in both cases. Numerical examples show the potential and applicability of the introduced methods.      
### 23.Assessing Wireless Sensing Potential with Large Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2011.08465.pdf)
>  Sensing capability is one of the most highlighted new feature of future 6G wireless networks. This paper addresses the sensing potential of Large Intelligent Surfaces (LIS) in an exemplary Industry 4.0 scenario. Besides the attention received by LIS in terms of communication aspects, it can offer a high-resolution rendering of the propagation environment. This is because, in an indoor setting, it can be placed in proximity to the sensed phenomena, while the high resolution is offered by densely spaced tiny antennas deployed over a large area. By treating an LIS as a radio image of the environment relying on the received signal power, we develop techniques to sense the environment, by leveraging the tools of image processing and machine learning. Once a holographic image is obtained, a Denoising Autoencoder (DAE) network can be used for constructing a super-resolution image leading to sensing advantages not available in traditional sensing systems. Also, we derive a statistical test based on the Generalized Likelihood Ratio (GLRT) as a benchmark for the machine learning solution. We test these methods for a scenario where we need to detect whether an industrial robot deviates from a predefined route. The results show that the LIS-based sensing offers high precision and has a high application potential in indoor industrial environments.      
### 24.Implicit Filter-and-sum Network for Multi-channel Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2011.08401.pdf)
>  Various neural network architectures have been proposed in recent years for the task of multi-channel speech separation. Among them, the filter-and-sum network (FaSNet) performs end-to-end time-domain filter-and-sum beamforming and has shown effective in both ad-hoc and fixed microphone array geometries. In this paper, we investigate multiple ways to improve the performance of FaSNet. From the problem formulation perspective, we change the explicit time-domain filter-and-sum operation which involves all the microphones into an implicit filter-and-sum operation in the latent space of only the reference microphone. The filter-and-sum operation is applied on a context around the frame to be separated. This allows the problem formulation to better match the objective of end-to-end separation. From the feature extraction perspective, we modify the calculation of sample-level normalized cross correlation (NCC) features into feature-level NCC (fNCC) features. This makes the model better matches the implicit filter-and-sum formulation. Experiment results on both ad-hoc and fixed microphone array geometries show that the proposed modification to the FaSNet, which we refer to as iFaSNet, is able to significantly outperform the benchmark FaSNet across all conditions with an on par model complexity.      
### 25.Rethinking the Separation Layers in Speech Separation Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.08400.pdf)
>  Modules in all existing speech separation networks can be categorized into single-input-multi-output (SIMO) modules and single-input-single-output (SISO) modules. SIMO modules generate more outputs than input, and SISO modules keep the numbers of input and output the same. While the majority of separation models only contain SIMO architectures, it has also been shown that certain two-stage separation systems integrated with a post-enhancement SISO module can improve the separation quality. Why performance improvements can be achieved by incorporating the SISO modules? Are SIMO modules always necessary? In this paper, we empirically examine those questions by designing models with varying configurations in the SIMO and SISO modules. We show that comparing with the standard SIMO-only design, a mixed SIMO-SISO design with a same model size is able to improve the separation performance especially under low-overlap conditions. We further validate the necessity of SIMO modules and show that SISO-only models are still able to perform separation without sacrificing the performance. The observations allow us to rethink the model design paradigm and present different views on how the separation is performed.      
### 26.Ultra-Lightweight Speech Separation via Group Communication  [ :arrow_down: ](https://arxiv.org/pdf/2011.08397.pdf)
>  Model size and complexity remain the biggest challenges in the deployment of speech enhancement and separation systems on low-resource devices such as earphones and hearing aids. Although methods such as compression, distillation and quantization can be applied to large models, they often come with a cost on the model performance. In this paper, we provide a simple model design paradigm that explicitly designs ultra-lightweight models without sacrificing the performance. Motivated by the sub-band frequency-LSTM (F-LSTM) architectures, we introduce the group communication (GroupComm), where a feature vector is split into smaller groups and a small processing block is used to perform inter-group communication. Unlike standard F-LSTM models where the sub-band outputs are concatenated, an ultra-small module is applied on all the groups in parallel, which allows a significant decrease on the model size. Experiment results show that comparing with a strong baseline model which is already lightweight, GroupComm can achieve on par performance with 35.6 times fewer parameters and 2.3 times fewer operations.      
### 27.Joint Resource Optimization for IRS-Assisted mmWave MIMO under QoS Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2011.08395.pdf)
>  This letter focuses on the non-convex joint optimization with a dynamic resource of multi-user for an intelligent reflecting surface-enhanced mmWave system, where all users are concentrated on the unique cluster beam. Firstly, the objective function of the above non-linear problem is converted into a quadratic programming form under the quality of service constraints. Further, a multi-blocks alternating optimization framework with dynamic power allocation is proposed to obtain the maximum sum-rate, where the relaxed ADMM algorithm is adopted to tackle the optimal fulldigital precoder and the corresponding passive reflecting matrix is obtained by the gradient-projection. The numerical results verify that beam optimization should be emphasized in high SINR, but joint dynamic resource allocation can further improve system performance even if the hardware dimensions reaches the limit.      
### 28.Refining Automatic Speech Recognition System for older adults  [ :arrow_down: ](https://arxiv.org/pdf/2011.08346.pdf)
>  Building a high quality automatic speech recognition (ASR) system with limited training data has been a challenging task particularly for a narrow target population. Open-sourced ASR systems, trained on sufficient data from adults, are susceptible on seniors' speech due to acoustic mismatch between adults and seniors. With 12 hours of training data, we attempt to develop an ASR system for socially isolated seniors (80+ years old) with possible cognitive impairments. We experimentally identify that ASR for the adult population performs poorly on our target population and transfer learning (TL) can boost the system's performance. Standing on the fundamental idea of TL, tuning model parameters, we further improve the system by leveraging an attention mechanism to utilize the model's intermediate information. Our approach achieves 1.58% absolute improvements over the TL model.      
### 29.Real-Time Radio Technology and Modulation Classification via an LSTM Auto-Encoder  [ :arrow_down: ](https://arxiv.org/pdf/2011.08295.pdf)
>  Identification of the type of communication technology and/or modulation scheme based on detected radio signal are challenging problems encountered in a variety of applications including spectrum allocation and radio interference mitigation. They are rendered difficult due to a growing number of emitter types and varied effects of real-world channels upon the radio signal. Existing spectrum monitoring techniques are capable of acquiring massive amounts of radio and real-time spectrum data using compact sensors deployed in a variety of settings. However, state-of-the-art methods that use such data to classify emitter types and detect communication schemes struggle to achieve required levels of accuracy at a computational efficiency that would allow their implementation on low-cost computational platforms. In this paper, we present a learning framework based on an LSTM denoising auto-encoder designed to automatically extract stable and robust features from noisy radio signals, and infer modulation or technology type using the learned features. The algorithm utilizes a compact neural network architecture readily implemented on a low-cost computational platform while exceeding state-of-the-art accuracy. Results on realistic synthetic as well as over-the-air radio data demonstrate that the proposed framework reliably and efficiently classifies received radio signals, often demonstrating superior performance compared to state-of-the-art methods.      
### 30.Switching Device-Cognizant Sequential Distribution System Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2011.08236.pdf)
>  This paper presents an optimization framework for sequential reconfiguration using an assortment of switching devices and repair process in distribution system restoration. Compared to existing studies, this paper considers types, capabilities and operational limits of different switching devices, making it applicable in practice. We develop a novel multi-phase method to find the optimal sequential operation of various switching devices and repair faulted areas. We consider circuit breakers, reclosers, sectionalizers, load breaker switches, and fuses. The switching operation problem is decomposed into two mixed-integer linear programming (MILP) subproblems. The first subproblem determines the optimal network topology and estimates the number of steps to reach that topology, while the second subproblem generates a sequence of switching operations to coordinate the switches. For repairing the faults, we design an MILP model that dispatches repair crews to clear faults and replace melted fuses. After clearing a fault, we update the topology of the network by generating a new sequence of switching operations, and the process continues until all faults are cleared. To improve the computational efficiency, a network reduction algorithm is developed to group line sections, such that only switchable sections are present in the reduced network. The proposed method is validated on the IEEE 123-bus system.      
### 31.Tensor-Decomposition-based Hybrid Beamforming Design for mmWave OFDM Massive MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2011.08800.pdf)
>  In this paper, we propose a novel joint hybrid precoder and combiner design for maximizing the average achievable sum-rate of single-user orthogonal frequency division multiplexing millimeter wave massive MIMO systems. We formulate the analog precoder and combiner design as a constrained Tucker2 decomposition and solve it by using the projected alternate least square method. Such a formulation allows maximizing the sum of the effective baseband gains over all subcarriers, while suppressing the interference among the data streams in the same subcarrier. In turn, the digital precoder and combiner are obtained from the effective baseband channel's singular value decomposition on a per-subcarrier basis. Numerical simulation results show that the proposed method outperforms other existing designs.      
### 32.Iterative Semi-parametric Dynamics Model Learning For Autonomous Racing  [ :arrow_down: ](https://arxiv.org/pdf/2011.08750.pdf)
>  Accurately modeling robot dynamics is crucial to safe and efficient motion control. In this paper, we develop and apply an iterative learning semi-parametric model, with a neural network, to the task of autonomous racing with a Model Predictive Controller (MPC). We present a novel non-linear semi-parametric dynamics model where we represent the known dynamics with a parametric model, and a neural network captures the unknown dynamics. We show that our model can learn more accurately than a purely parametric model and generalize better than a purely non-parametric model, making it ideal for real-world applications where collecting data from the full state space is not feasible. We present a system where the model is bootstrapped on pre-recorded data and then updated iteratively at run time. Then we apply our iterative learning approach to the simulated problem of autonomous racing and show that it can safely adapt to modified dynamics online and even achieve better performance than models trained on data from manual driving.      
### 33.Control Strategies for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2011.08729.pdf)
>  This chapter focuses on the self-driving technology from a control perspective and investigates the control strategies used in autonomous vehicles and advanced driver-assistance systems from both theoretical and practical viewpoints. First, we introduce the self-driving technology as a whole, including perception, planning and control techniques required for accomplishing the challenging task of autonomous driving. We then dwell upon each of these operations to explain their role in the autonomous system architecture, with a prime focus on control strategies. The core portion of this chapter commences with detailed mathematical modeling of autonomous vehicles followed by a comprehensive discussion on control strategies. The chapter covers longitudinal as well as lateral control strategies for autonomous vehicles with coupled and de-coupled control schemes. We as well discuss some of the machine learning techniques applied to autonomous vehicle control task. Finally, we briefly summarize some of the research works that our team has carried out at the Autonomous Systems Lab and conclude the chapter with a few thoughtful remarks.      
### 34.Uncertainty Modelling in Deep Neural Networks for Image Data  [ :arrow_down: ](https://arxiv.org/pdf/2011.08712.pdf)
>  Quantifying uncertainty in a model's predictions is important as it enables, for example, the safety of an AI system to be increased by acting on the model's output in an informed manner. We cannot expect a system to be 100% accurate or perfect at its task, however, we can equip the system with some tools to inform us if it is not certain about a prediction. This way, a second check can be performed, or the task can be passed to a human specialist. This is crucial for applications where the cost of an error is high, such as in autonomous vehicle control, medical image analysis, financial estimations or legal fields. Deep Neural Networks are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging and yet on-going problem. Although there have been many efforts to equip NNs with tools to estimate uncertainty, such as Monte Carlo Dropout, most of the previous methods only focus on one of the three types of model, data or distributional uncertainty. In this paper we propose a complete framework to capture and quantify all of these three types of uncertainties in DNNs for image classification. This framework includes an ensemble of CNNs for model uncertainty, a supervised reconstruction auto-encoder to capture distributional uncertainty and using the output of activation functions in the last layer of the network, to capture data uncertainty. Finally we demonstrate the efficiency of our method on popular image datasets for classification.      
### 35.Denoising Score-Matching for Uncertainty Quantification in Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2011.08698.pdf)
>  Deep neural networks have proven extremely efficient at solving a wide rangeof inverse problems, but most often the uncertainty on the solution they provideis hard to quantify. In this work, we propose a generic Bayesian framework forsolving inverse problems, in which we limit the use of deep neural networks tolearning a prior distribution on the signals to recover. We adopt recent denoisingscore matching techniques to learn this prior from data, and subsequently use it aspart of an annealed Hamiltonian Monte-Carlo scheme to sample the full posteriorof image inverse problems. We apply this framework to Magnetic ResonanceImage (MRI) reconstruction and illustrate how this approach not only yields highquality reconstructions but can also be used to assess the uncertainty on particularfeatures of a reconstructed image.      
### 36.Controllable Emotion Transfer For End-to-End Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2011.08679.pdf)
>  Emotion embedding space learned from references is a straightforward approach for emotion transfer in encoder-decoder structured emotional text to speech (TTS) systems. However, the transferred emotion in the synthetic speech is not accurate and expressive enough with emotion category confusions. Moreover, it is hard to select an appropriate reference to deliver desired emotion strength. To solve these problems, we propose a novel approach based on Tacotron. First, we plug two emotion classifiers -- one after the reference encoder, one after the decoder output -- to enhance the emotion-discriminative ability of the emotion embedding and the predicted mel-spectrum. Second, we adopt style loss to measure the difference between the generated and reference mel-spectrum. The emotion strength in the synthetic speech can be controlled by adjusting the value of the emotion embedding as the emotion embedding can be viewed as the feature map of the mel-spectrum. Experiments on emotion transfer and strength control have shown that the synthetic speech of the proposed method is more accurate and expressive with less emotion category confusions and the control of emotion strength is more salient to listeners.      
### 37.User Clustering in mmWave-NOMA Systems with User Decoding Capability Constraints for B5G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.08670.pdf)
>  This paper proposes a millimeter wave-NOMA (mmWave-NOMA) system that takes into account the end-user signal processing capabilities, an important practical consideration. The implementation of NOMA in the downlink (DL) direction requires successive interference cancellation (SIC) to be performed at the user terminals, which comes at the cost of additional complexity. In NOMA, the weakest user only has to decode its own signal, while the strongest user has to decode the signals of all other users in the SIC procedure. Hence, the additional implementation complexity required of the user to perform SIC for DL NOMA depends on its position in the SIC decoding order. Beyond fifth-generation (B5G) communication systems are expected to support a wide variety of end-user devices, each with their own processing capabilities. We envision a system where users report their SIC decoding capability to the base station (BS), i.e., the number of other users signals a user is capable of decoding in the SIC procedure. We investigate the rate maximization problem in such a system, by breaking it down into a user clustering and ordering problem (UCOP), followed by a power allocation problem. We propose a NOMA minimum exact cover (NOMA-MEC) heuristic algorithm that converts the UCOP into a cluster minimization problem from a derived set of valid cluster combinations after factoring in the SIC decoding capability. The complexity of NOMA-MEC is analyzed for various algorithm and system parameters. For a homogeneous system of users that all have the same decoding capabilities, we show that this equates to a simple maximum number of users per cluster constraint and propose a lower complexity NOMA-best beam (NOMA-BB) algorithm. Simulation results demonstrate the performance superiority in terms of sum rate compared to orthogonal multiple access (OMA) and traditional NOMA      
### 38.Adversarial Training for Multi-domain Speaker Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2011.08623.pdf)
>  In real-life applications, the performance of speaker recognition systems always degrades when there is a mismatch between training and evaluation data. Many domain adaptation methods have been successfully used for eliminating the domain mismatches in speaker recognition. However, usually both training and evaluation data themselves can be composed of several subsets. These inner variances of each dataset can also be considered as different domains. Different distributed subsets in source or target domain dataset can also cause multi-domain mismatches, which are influential to speaker recognition performance. In this study, we propose to use adversarial training for multi-domain speaker recognition to solve the domain mismatch and the dataset variance problems. By adopting the proposed method, we are able to obtain both multi-domain-invariant and speaker-discriminative speech representations for speaker recognition. Experimental results on DAC13 dataset indicate that the proposed method is not only effective to solve the multi-domain mismatch problem, but also outperforms the compared unsupervised domain adaptation methods.      
### 39.Accent and Speaker Disentanglement in Many-to-many Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2011.08609.pdf)
>  This paper proposes an interesting voice and accent joint conversion approach, which can convert an arbitrary source speaker's voice to a target speaker with non-native accent. This problem is challenging as each target speaker only has training data in native accent and we need to disentangle accent and speaker information in the conversion model training and re-combine them in the conversion stage. In our recognition-synthesis conversion framework, we manage to solve this problem by two proposed tricks. First, we use accent-dependent speech recognizers to obtain bottleneck features for different accented speakers. This aims to wipe out other factors beyond the linguistic information in the BN features for conversion model training. Second, we propose to use adversarial training to better disentangle the speaker and accent information in our encoder-decoder based conversion model. Specifically, we plug an auxiliary speaker classifier to the encoder, trained with an adversarial loss to wipe out speaker information from the encoder output. Experiments show that our approach is superior to the baseline. The proposed tricks are quite effective in improving accentedness and audio quality and speaker similarity are well maintained.      
### 40.A Deep Neural Network for SSVEP-based Brain Computer Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2011.08562.pdf)
>  The target identification in brain-computer interface (BCI) speller systems refers to the multi-channel electroencephalogram (EEG) classification for predicting the target character that the user intends to spell. The EEG in such systems is known to include the steady-state visually evoked potentials (SSVEP) signal, which is the brain response when the user concentrates on the target while being visually presented a matrix of certain alphanumeric each of which flickers at a unique frequency. The SSVEP in this setting is characteristically dominated at varying degrees by the harmonics of the stimulation frequency; hence, a pattern analysis of the SSVEP can solve for the mentioned multi-class classification problem. To this end, we propose a novel deep neural network (DNN) architecture for the target identification in BCI SSVEP spellers. The proposed DNN is an end-to-end system: it receives the multi-channel SSVEP signal, proceeds with convolutions across the sub-bands of the harmonics, channels and time, and classifies at the fully connected layer. Our experiments are on two publicly available (the benchmark and the BETA) datasets consisting of in total 105 subjects with 40 characters. We train in two stages. The first stage obtains a global perspective into the whole SSVEP data by exploiting the commonalities, and transfers the global model to the second stage that fine tunes it down to each subject separately by exploiting the individual statistics. In our extensive comparisons, our DNN is demonstrated to significantly outperform the state-of-the-art on the both two datasets, by achieving the information transfer rates (ITR) 265.23 bits/min and 196.59 bits/min, respectively. To the best of our knowledge, our ITRs are the highest ever reported performance results on these datasets. The code, and the proposed DNN model are available at <a class="link-external link-https" href="https://github.com/osmanberke/Deep-SSVEP-BCI" rel="external noopener nofollow">this https URL</a>.      
### 41.Optimizing voice conversion network with cycle consistency loss of speaker identity  [ :arrow_down: ](https://arxiv.org/pdf/2011.08548.pdf)
>  We propose a novel training scheme to optimize voice conversion network with a speaker identity loss function. The training scheme not only minimizes frame-level spectral loss, but also speaker identity loss. We introduce a cycle consistency loss that constrains the converted speech to maintain the same speaker identity as reference speech at utterance level. While the proposed training scheme is applicable to any voice conversion networks, we formulate the study under the average model voice conversion framework in this paper. Experiments conducted on CMU-ARCTIC and CSTR-VCTK corpus confirm that the proposed method outperforms baseline methods in terms of speaker similarity.      
### 42.A Digital Image Processing Approach for Hepatic Diseases Staging based on the Glisson's Capsule  [ :arrow_down: ](https://arxiv.org/pdf/2011.08513.pdf)
>  Due to the need for quick and effective treatments for liver diseases, which are among the most common health problems in the world, staging fibrosis through non-invasive and economic methods has become of great importance. Taking inspiration from diagnostic laparoscopy, used in the past for hepatic diseases, in this paper ultrasound images of the liver are studied, focusing on a specific region of the organ where the Glisson's capsule is visible. In ultrasound images, the Glisson's capsule appears in the shape of a line which can be extracted via classical methods in literature. By making use of a combination of standard image processing techniques and Convolutional Neural Network approaches, the scope of this work is to give evidence to the idea that a great informative potential relies on smoothness of the Glisson's capsule surface. To this purpose, several classifiers are taken into consideration, which deal with different type of data, namely ultrasound images, binary images depicting the Glisson's line, and features vector extracted from the original image. This is a preliminary study that has been retrospectively conducted, based on the results of the elastosonography examination.      
### 43.FoolHD: Fooling speaker identification by Highly imperceptible adversarial Disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2011.08483.pdf)
>  Speaker identification models are vulnerable to carefully designed adversarial perturbations of their input signals that induce misclassification. In this work, we propose a white-box steganography-inspired adversarial attack that generates imperceptible adversarial perturbations against a speaker identification model. Our approach, FoolHD, uses a Gated Convolutional Autoencoder that operates in the DCT domain and is trained with a multi-objective loss function, in order to generate and conceal the adversarial perturbation within the original audio files. In addition to hindering speaker identification performance, this multi-objective loss accounts for human perception through a frame-wise cosine similarity between MFCC feature vectors extracted from the original and adversarial audio files. We validate the effectiveness of FoolHD with a 250-speaker identification x-vector network, trained using VoxCeleb, in terms of accuracy, success rate, and imperceptibility. Our results show that FoolHD generates highly imperceptible adversarial audio files (average PESQ scores above 4.30), while achieving a success rate of 99.6% and 99.2% in misleading the speaker identification model, for untargeted and targeted settings, respectively.      
### 44.Fine-grained Emotion Strength Transfer, Control and Prediction for Emotional Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2011.08477.pdf)
>  This paper proposes a unified model to conduct emotion transfer, control and prediction for sequence-to-sequence based fine-grained emotional speech synthesis. Conventional emotional speech synthesis often needs manual labels or reference audio to determine the emotional expressions of synthesized speech. Such coarse labels cannot control the details of speech emotion, often resulting in an averaged emotion expression delivery, and it is also hard to choose suitable reference audio during inference. To conduct fine-grained emotion expression generation, we introduce phoneme-level emotion strength representations through a learned ranking function to describe the local emotion details, and the sentence-level emotion category is adopted to render the global emotions of synthesized speech. With the global render and local descriptors of emotions, we can obtain fine-grained emotion expressions from reference audio via its emotion descriptors (for transfer) or directly from phoneme-level manual labels (for control). As for the emotional speech synthesis with arbitrary text inputs, the proposed model can also predict phoneme-level emotion expressions from texts, which does not require any reference audio or manual label.      
### 45.Beyond Cell-free MIMO: Energy Efficient Reconfigurable Intelligent Surface Aided Cell-free MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2011.08473.pdf)
>  Cell-free systems can effectively eliminate the inter-cell interference by enabling multiple base stations (BSs) to cooperatively serve users without cell boundaries at the expense of high costs of hardware and power sources due to the large-scale deployment of BSs. To tackle this issue, the low-cost reconfigurable intelligent surface (RIS) can serve as a promising technique to improve the energy efficiency of cell-free systems. In this paper, we consider an RIS aided cell-free MIMO system where multiple RISs are deployed around BSs and users to create favorable propagation conditions via reconfigurable reflections in a low-cost way, thereby enhancing cell-free MIMO communications. To maximize the energy efficiency, a hybrid beamforming (HBF) scheme consisting of the digital beamforming at BSs and the RIS-based analog beamforming is proposed. The energy efficiency maximization problem is formulated and an iterative algorithm is designed to solve this problem. The impact of the transmit power, the number of RIS, and the RIS size on energy efficiency are investigated. Both theoretical analysis and simulation results reveal that the optimal energy efficiency depends on the numbers of RISs and the RIS size. Numerical evaluations also show that the proposed system can achieve a higher energy efficiency than conventional ones.      
### 46.Cascade RNN-Transducer: Syllable Based Streaming On-device Mandarin Speech Recognition with a Syllable-to-Character Converter  [ :arrow_down: ](https://arxiv.org/pdf/2011.08469.pdf)
>  End-to-end models are favored in automatic speech recognition (ASR) because of its simplified system structure and superior performance. Among these models, recurrent neural network transducer (RNN-T) has achieved significant progress in streaming on-device speech recognition because of its high-accuracy and low-latency. RNN-T adopts a prediction network to enhance language information, but its language modeling ability is limited because it still needs paired speech-text data to train. Further strengthening the language modeling ability through extra text data, such as shallow fusion with an external language model, only brings a small performance gain. In view of the fact that Mandarin Chinese is a character-based language and each character is pronounced as a tonal syllable, this paper proposes a novel cascade RNN-T approach to improve the language modeling ability of RNN-T. Our approach firstly uses an RNN-T to transform acoustic feature into syllable sequence, and then converts the syllable sequence into character sequence through an RNN-T-based syllable-to-character converter. Thus a rich text repository can be easily used to strengthen the language model ability. By introducing several important tricks, the cascade RNN-T approach surpasses the character-based RNN-T by a large margin on several Mandarin test sets, with much higher recognition quality and similar latency.      
### 47.Learn2Sing: Target Speaker Singing Voice Synthesis by learning from a Singing Teacher  [ :arrow_down: ](https://arxiv.org/pdf/2011.08467.pdf)
>  Singing voice synthesis has been paid rising attention with the rapid development of speech synthesis area. In general, a studio-level singing corpus is usually necessary to produce a natural singing voice from lyrics and music-related transcription. However, such a corpus is difficult to collect since it's hard for many of us to sing like a professional singer. In this paper, we propose an approach -- Learn2Sing that only needs a singing teacher to generate the target speakers' singing voice without their singing voice data. In our approach, a teacher's singing corpus and speech from multiple target speakers are trained in a frame-level auto-regressive acoustic model where singing and speaking share the common speaker embedding and style tag embedding. Meanwhile, since there is no music-related transcription for the target speaker, we use log-scale fundamental frequency (LF0) as an auxiliary feature as the inputs of the acoustic model for building a unified input representation. In order to enable the target speaker to sing without singing reference audio in the inference stage, a duration model and an LF0 prediction model are also trained. Particularly, we employ domain adversarial training (DAT) in the acoustic model, which aims to enhance the singing performance of target speakers by disentangling style from acoustic features of singing and speaking data. Our experiments indicate that the proposed approach is capable of synthesizing singing voice for target speaker given only their speech samples.      
### 48.Edge Intelligence for Energy-efficient Computation Offloading and Resource Allocation in 5G Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2011.08442.pdf)
>  5G beyond is an end-edge-cloud orchestrated network that can exploit heterogeneous capabilities of the end devices, edge servers, and the cloud and thus has the potential to enable computation-intensive and delay-sensitive applications via computation offloading. However, in multi user wireless networks, diverse application requirements and the possibility of various radio access modes for communication among devices make it challenging to design an optimal computation offloading scheme. In addition, having access to complete network information that includes variables such as wireless channel state, and available bandwidth and computation resources, is a major issue. Deep Reinforcement Learning (DRL) is an emerging technique to address such an issue with limited and less accurate network information. In this paper, we utilize DRL to design an optimal computation offloading and resource allocation strategy for minimizing system energy consumption. We first present a multi-user end-edge-cloud orchestrated network where all devices and base stations have computation capabilities. Then, we formulate the joint computation offloading and resource allocation problem as a Markov Decision Process (MDP) and propose a new DRL algorithm to minimize system energy consumption. Numerical results based on a real-world dataset demonstrate that the proposed DRL-based algorithm significantly outperforms the benchmark policies in terms of system energy consumption. Extensive simulations show that learning rate, discount factor, and number of devices have considerable influence on the performance of the proposed algorithm.      
### 49.Reachability-based Trajectory Safeguard (RTS): A Safe and Fast Reinforcement Learning Safety Layer for Continuous Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.08421.pdf)
>  Reinforcement Learning (RL) algorithms have achieved remarkable performance in decision making and control tasks due to their ability to reason about long-term, cumulative reward using trial and error. However, during RL training, applying this trial-and-error approach to real-world robots operating in safety critical environment may lead to collisions. To address this challenge, this paper proposes a Reachability-based Trajectory Safeguard (RTS), which leverages trajectory parameterization and reachability analysis to ensure safety while a policy is being learned. This method ensures a robot with continuous action space can be trained from scratch safely in real-time. Importantly, this safety layer can still be applied after a policy has been learned. The efficacy of this method is illustrated on three nonlinear robot models, including a 12-D quadrotor drone, in simulation. By ensuring safety with RTS, this paper demonstrates that the proposed algorithm is not only safe, but can achieve a higher reward in a considerably shorter training time when compared to a non-safe counterpart.      
### 50.Noise adaptive beamforming for linear array photoacoustic imaging  [ :arrow_down: ](https://arxiv.org/pdf/2011.08414.pdf)
>  In linear array photoacoustic (PA) imaging systems, Delay-and-sum (DAS) based beamforming algorithms are omnipresent. DAS methods fundamentally rely on calculating beamformed signal with proper delaying and summing, and are uniquely characterised by fast execution and suitable for real-time PA imaging with on-device image formation. However, DAS algorithms suffer various drawbacks like low resolution, low contrast, high sidelobe artifacts and lack of visual coherence. To address these problems, several adaptive weighting based algorithm has been introduced to improve image quality. Unfortunately, these existing adaptive based algorithms demand an increased computational capacity of the processing hardware which makes it computationally expensive. In this article, we present a new adaptive weighting factor, named variational coherence factor (VCF) which takes into account the noise level variations of radio-frequency data. This proposed technique provides superior results in terms of image resolution, sidelobe reduction, signal-to-noise and contrast level improvement. In particular, the quantitative results of the numerical simulations and phantom experiments show that VCF assisted DAS method leads to about 55\% and 25\% improvement in FWHM, 57 percent and 32 percent improvement in SNR comparison with DAS and similar state-of-the-art methods. The results demonstrate that the proposed technique of introducing a noise-adaptive weighting function can effectively improve the quality of the reconstructed image in real-time beamforming of PA signal.      
### 51.Time-Resolved Focused Ion Beam Microscopy: Modeling, Estimation Methods, and Analyses  [ :arrow_down: ](https://arxiv.org/pdf/2011.08402.pdf)
>  In a focused ion beam (FIB) microscope, source particles interact with a small volume of a sample to generate secondary electrons that are detected, pixel by pixel, to produce a micrograph. Randomness of the number of incident particles causes excess variation in the micrograph, beyond the variation in the underlying particle-sample interaction. It was recently shown that joint processing of multiple measurements from a single pixel can mitigate this effect of source shot noise. This paper introduces continuous- and discrete-time abstractions of FIB microscopy with direct electron detection and estimation-theoretic limits of imaging performance under these measurement models. Novel estimators for use with continuous-time measurements are introduced and analyzed, and estimators for use with discrete-time measurements are analyzed and shown to approach their continuous-time counterparts as time resolution is increased. Simulated FIB microscopy results are consistent with theoretical analyses and demonstrate that substantial improvements over conventional FIB microscopy image formation are made possible by time-resolved measurement.      
### 52.AXES: Approximation Manager for Emerging Memory Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2011.08353.pdf)
>  Memory approximation techniques are commonly limited in scope, targeting individual levels of the memory hierarchy. Existing approximation techniques for a full memory hierarchy determine optimal configurations at design-time provided a goal and application. Such policies are rigid: they cannot adapt to unknown workloads and must be redesigned for different memory configurations and technologies. We propose AXES: the first self-optimizing runtime manager for coordinating configurable approximation knobs across all levels of the memory hierarchy. AXES continuously updates and optimizes its approximation management policy throughout runtime for diverse workloads. AXES optimizes the approximate memory configuration to minimize power consumption without compromising the quality threshold specified by application developers. AXES can (1) learn a policy at runtime to manage variable application quality of service (QoS) constraints, (2) automatically optimize for a target metric within those constraints, and (3) coordinate runtime decisions for interdependent knobs and subsystems. We demonstrate AXES' ability to efficiently provide functions 1-3 on a RISC-V Linux platform with approximate memory segments in the on-chip cache and main memory. We demonstrate AXES' ability to save up to 37% energy in the memory subsystem without any design-time overhead. We show AXES' ability to reduce QoS violations by 75% with $&lt;5\%$ additional energy.      
### 53.Optimal Transport-based Coverage Control for Swarm Robot Systems: Generalization of the Voronoi Tessellation-based Method  [ :arrow_down: ](https://arxiv.org/pdf/2011.08337.pdf)
>  Swarm robot systems, which consist of many cooperating mobile robots, have attracted attention for their environmental adaptability and fault tolerance advantages. One of the most important tasks for such systems is coverage control, in which robots autonomously deploy to approximate a given spatial distribution. In this study, we formulate a coverage control paradigm using the concept of optimal transport and propose a novel control technique, which we have termed the optimal transport-based coverage control (OTCC) method. The proposed OTCC, derived via the gradient flow of the cost function in the Kantorovich dual problem, is shown to covers a widely used existing control method as a special case. We also perform a Lyapunov stability analysis of the controlled system, and provide numerical calculations to show that the OTCC reproduces target distributions with better performance than the existing control method.      
### 54.Asymptotic Rate Analysis for Impairments-Aware Multi-Carrier FD Massive MIMO Relay Networks utilizing MRT/MRC Strategy  [ :arrow_down: ](https://arxiv.org/pdf/2011.08303.pdf)
>  In this paper, we analyze the asymptotic rate for a multi-carrier (MC) full-duplex (FD) massive multiple input multiple output (mMIMO) decode and forward (DF) relay system which serves multiple MC single-antenna half-duplex (HD) nodes. We take into account the impact of hardware distortions resulting in residual self-interference (SI) and inter-carrier leakage (ICL) as well as the impact of imperfect channel state information (CSI). We derive the asymptotic rate expression of our system employed with maximum ratio transmitting (MRT)/ maximum ratio combining (MRC) strategy when the number of the antenna becomes large (goes to $\infty$). It is noticed that the impact of hardware distortion becomes remarkable in a large-scale antenna array regime. On contrary to the effect of multi-user interference and receiver noise, which vanishes as the number of relay antenna goes to infinity, the residual SI and ICL caused by the hardware impairments remains in the MC system.      
### 55.Clinical Micro-CT Empowered by Interior Tomography, Robotic Scanning, and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.08297.pdf)
>  While micro-CT systems are instrumental in preclinical research, clinical micro-CT imaging has long been desired with cochlear implantation as a primary example. The structural details of the cochlear implant and the temporal bone require a significantly higher image resolution than that (about 0.2 mm) provided by current medical CT scanners. In this paper, we propose a clinical micro-CT (CMCT) system design integrating conventional spiral cone-beam CT, contemporary interior tomography, deep learning techniques, and technologies of micro-focus X-ray source, photon-counting detector (PCD), and robotic arms for ultrahigh resolution localized tomography of a freely-selected volume of interest (VOI) at a minimized radiation dose level. The whole system consists of a standard CT scanner for a clinical CT exam and VOI specification, and a robotic-arm based micro-CT scanner for a local scan at much higher spatial and spectral resolution as well as much reduced radiation dose. The prior information from global scan is also fully utilized for background compensation to improve interior tomography from local data for accurate and stable VOI reconstruction. Our results and analysis show that the proposed hybrid reconstruction algorithm delivers superior local reconstruction, being insensitive to the misalignment of the isocenter position and initial view angle in the data/image registration while the attenuation error caused by scale mismatch can be effectively addressed with bias correction. These findings demonstrate the feasibility of our system design. We envision that deep learning techniques can be leveraged for optimized imaging performance. With high resolution imaging, high dose efficiency and low system cost synergistically, our proposed CMCT system has great potentials in temporal bone imaging as well as various other clinical applications.      
### 56.Machine Learning and Soil Humidity Sensing: Signal Strength Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.08273.pdf)
>  The IoT vision of ubiquitous and pervasive computing gives rise to future smart irrigation systems comprising physical and digital world. Smart irrigation ecosystem combined with Machine Learning can provide solutions that successfully solve the soil humidity sensing task in order to ensure optimal water usage. Existing solutions are based on data received from the power hungry/expensive sensors that are transmitting the sensed data over the wireless channel. Over time, the systems become difficult to maintain, especially in remote areas due to the battery replacement issues with large number of devices. Therefore, a novel solution must provide an alternative, cost and energy effective device that has unique advantage over the existing solutions. This work explores a concept of a novel, low-power, LoRa-based, cost-effective system which achieves humidity sensing using Deep learning techniques that can be employed to sense soil humidity with the high accuracy simply by measuring signal strength of the given underground beacon device.      
### 57.Sufficient Conditions for Feasibility of Optimal Control Problems Using Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2011.08248.pdf)
>  It has been shown that satisfying state and control constraints while optimizing quadratic costs subject to desired (sets of) state convergence for affine control systems can be reduced to a sequence of quadratic programs (QPs) by using Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs). One of the main challenges in this approach is ensuring the feasibility of these QPs, especially under tight control bounds and safety constraints of high relative degree. In this paper, we provide sufficient conditions for guranteed feasibility. The sufficient conditions are captured by a single constraint that is enforced by a CBF, which is added to the QPs such that their feasibility is always guaranteed. The additional constraint is designed to be always compatible with the existing constraints, therefore, it cannot make a feasible set of constraints infeasible - it can only increase the overall feasibility. We illustrate the effectiveness of the proposed approach on an adaptive cruise control problem.      
### 58.End-to-end spoken language understanding using transformer networks and self-supervised pre-trained features  [ :arrow_down: ](https://arxiv.org/pdf/2011.08238.pdf)
>  Transformer networks and self-supervised pre-training have consistently delivered state-of-art results in the field of natural language processing (NLP); however, their merits in the field of spoken language understanding (SLU) still need further investigation. In this paper we introduce a modular End-to-End (E2E) SLU transformer network based architecture which allows the use of self-supervised pre-trained acoustic features, pre-trained model initialization and multi-task training. Several SLU experiments for predicting intent and entity labels/values using the ATIS dataset are performed. These experiments investigate the interaction of pre-trained model initialization and multi-task training with either traditional filterbank or self-supervised pre-trained acoustic features. Results show not only that self-supervised pre-trained acoustic features outperform filterbank features in almost all the experiments, but also that when these features are used in combination with multi-task training, they almost eliminate the necessity of pre-trained model initialization.      
### 59.Assistive Diagnostic Tool for Brain Tumor Detection using Computer Vision  [ :arrow_down: ](https://arxiv.org/pdf/2011.08185.pdf)
>  Today, over 700,000 people are living with brain tumors in the United States. Brain tumors can spread very quickly to other parts of the brain and the spinal cord unless necessary preventive action is taken. Thus, the survival rate for this disease is less than 40% for both men and women. A conclusive and early diagnosis of a brain tumor could be the difference between life and death for some. However, brain tumor detection and segmentation are tedious and time-consuming processes as it can only be done by radiologists and clinical experts. The use of computer vision techniques, such as Mask R Convolutional Neural Network (Mask R CNN), to detect and segment brain tumors can mitigate the possibility of human error while increasing prediction accuracy rates. The goal of this project is to create an assistive diagnostics tool for brain tumor detection and segmentation. Transfer learning was used with the Mask R CNN, and necessary parameters were accordingly altered, as a starting point. The model was trained with 20 epochs and later tested. The prediction segmentation matched 90% with the ground truth. This suggests that the model was able to perform at a high level. Once the model was finalized, the application running on Flask was created. The application will serve as a tool for medical professionals. It allows doctors to upload patient brain tumor MRI images in order to receive immediate results on the diagnosis and segmentation for each patient.      
### 60.Obstacle avoidance-driven controller for safety-critical aerial robots  [ :arrow_down: ](https://arxiv.org/pdf/2011.08178.pdf)
>  The goal of this thesis is to propose the combination of Control-Barrier-Functions (CBF) with Model-Predictive-Control (MPC) resulting in the novel Model-Predictive-Control-Barrier-Function (MPCBF). It can be shown, that the performance of the MPCBF surpasses the performance of the CBF due to the increased time horizon of the MPC. Moreover, the MPCBF was applied to a quadrotor, a system strongly in need of fast and predictive control. Using the MPCBF, the quadrotor was able to avoid obstacles, which the CBF failed to avoid due to the relative speed of the obstacle. The results of this work are experimentally validated.      
### 61.A Negotiation-based Right-of-way Assignment Strategy to Ensure Traffic Safety and Efficiency in Lane Change  [ :arrow_down: ](https://arxiv.org/pdf/1904.06500.pdf)
>  Generally, verifying the safety of autonomous driving strategy requires a substantial body of simulation testing and road testing. In recent years, the formal safety methods represented by RSS has brought a favorable turn for low-cost autonomous driving safety research, benefitting from its accurate assessment of safety and clear division of responsibilities. However, how to maintain traffic efficiency while ensuring safety remains tricky. To address this problem, this paper proposed a formulized negotiation-based lane-changing strategy, to make a trade-off between safety and efficiency. Both theoretical analysis and numerical testing results are provided to show the effectiveness of the proposed strategy. Experiments demonstrate that this new strategy can maintain collision avoidance and facilitate traffic efficiency.      

# ArXiv eess --Mon, 23 Nov 2020
### 1.MRAC-RL: A Framework for On-Line Policy Adaptation Under Parametric Model Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2011.10562.pdf)
>  Reinforcement learning (RL) algorithms have been successfully used to develop control policies for dynamical systems. For many such systems, these policies are trained in a simulated environment. Due to discrepancies between the simulated model and the true system dynamics, RL trained policies often fail to generalize and adapt appropriately when deployed in the real-world environment. Current research in bridging this sim-to-real gap has largely focused on improvements in simulation design and on the development of improved and specialized RL algorithms for robust control policy generation. In this paper we apply principles from adaptive control and system identification to develop the model-reference adaptive control &amp; reinforcement learning (MRAC-RL) framework. We propose a set of novel MRAC algorithms applicable to a broad range of linear and nonlinear systems, and derive the associated control laws. The MRAC-RL framework utilizes an inner-loop adaptive controller that allows a simulation-trained outer-loop policy to adapt and operate effectively in a test environment, even when parametric model uncertainty exists. We demonstrate that the MRAC-RL approach improves upon state-of-the-art RL algorithms in developing control policies that can be applied to systems with modeling errors.      
### 2.A Function Based on Chebyshev Polynomials as an Alternative to the Sinc Function in FIR Filter Design  [ :arrow_down: ](https://arxiv.org/pdf/2011.10546.pdf)
>  The sinc function is often used as the basis for the design of discrete linear-phase FIR filters. However the Fourier transform of the truncated sinc function exhibits ripple in the pass band due to the Gibbs phenomenon. This paper introduces an alternative function based on Chebyshev polynomials whose Fourier transform decreases monotonically in the pass band. Furthermore this function features an integrated window function with an adjustable parameter influencing the Fourier transform in the transition and stop bands.      
### 3.Performance vs. Spectral Properties For Single-Sideband Continuous Phase Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2011.10541.pdf)
>  This study reports on a single side band spectrum directly generated by a continuous phase modulation (CPM) signal. This signal is analyzed in terms of modulation indices, pulse lengths, and pulse widths, all of which affect error probabilities, bandwidths, and SSB property. The error probability performance is based on an approximation of the minimum Euclidean distance. A numerical power spectral density calculation for this particular SSB modulation in terms of modulation index is presented. Reasonable tradeoffs in designing modulation schemes have been defined using multi-objective optimization to ensure sizable improvements in bit error rate (BER) and spectral efficiencies, without losing the property of being a SSB signal. Performance comparisons are made with known CPM schemes, e.g., Gaussian Minimum Shift Keying (GMSK) and Raised Cosine based CPM (RC).      
### 4.Improving RNN-T ASR Accuracy Using Untranscribed Context Audio  [ :arrow_down: ](https://arxiv.org/pdf/2011.10538.pdf)
>  We present a new training scheme for streaming automatic speech recognition (ASR) based on recurrent neural network transducers (RNN-T) which allows the encoder network to benefit from longer audio streams as input, while only requiring partial transcriptions of such streams during training. We show that this extension of the acoustic context during training and inference can lead to word error rate reductions of more than 6% in a realistic production setting. We investigate its effect on acoustically challenging data containing background speech and present data points which indicate that this approach helps the network learn both speaker and environment adaptation. Finally, we visualize RNN-T loss gradients with respect to the input features in order to illustrate the ability of a long short-term memory (LSTM) based ASR encoder to exploit long-term context.      
### 5.Multi-Scale Speaker Diarization With Neural Affinity Score Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2011.10527.pdf)
>  Identifying the identity of the speaker of short segments in human dialogue has been considered one of the most challenging problems in speech signal processing. Speaker representations of short speech segments tend to be unreliable, resulting in poor fidelity of speaker representations in tasks requiring speaker recognition. In this paper, we propose an unconventional method that tackles the trade-off between temporal resolution and the quality of the speaker representations. To find a set of weights that balance the scores from multiple temporal scales of segments, a neural affinity score fusion model is presented. Using the CALLHOME dataset, we show that our proposed multi-scale segmentation and integration approach can achieve a state-of-the-art diarization performance.      
### 6.Delay Constrained Buffer-Aided Relay Selection in the Internet of Things with Decision-Assisted Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.10524.pdf)
>  This paper investigates the reinforcement learning for the relay selection in the delay-constrained buffer-aided networks. The buffer-aided relay selection significantly improves the outage performance but often at the price of higher latency. On the other hand, modern communication systems such as the Internet of Things often have strict requirement on the latency. It is thus necessary to find relay selection policies to achieve good throughput performance in the buffer-aided relay network while stratifying the delay constraint. With the buffers employed at the relays and delay constraints imposed on the data transmission, obtaining the best relay selection becomes a complicated high-dimensional problem, making it hard for the reinforcement learning to converge. In this paper, we propose the novel decision-assisted deep reinforcement learning to improve the convergence. This is achieved by exploring the a-priori information from the buffer-aided relay system. The proposed approaches can achieve high throughput subject to delay constraints. Extensive simulation results are provided to verify the proposed algorithms.      
### 7.Quickest Detection of COVID-19 Pandemic Onset  [ :arrow_down: ](https://arxiv.org/pdf/2011.10502.pdf)
>  When should restrictive measures be taken to contain the COVID-19 pandemic explosion? An important role for interpreting the pandemic data in a fully rational manner, and thus proactively supporting the political decision makers, is played by signal processing tools. In this paper, we exploit quickest-detection theory applied to pandemic time-series to predict the explosion of COVID-19 infection on a large scale. We develop a version of the celebrated Page's CUSUM test, specifically tailored to pandemic data. Its application to the publicly-available sequence of new positive individuals per day, from different countries, is detailed in [1].      
### 8.State Estimation of Open Dynamical Systems with Slow Inputs: Entropy, Bit Rates, and relation with Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.10496.pdf)
>  Finding the minimal bit rate needed to estimate the state of a dynamical system is a fundamental problem. Several notions of topological entropy have been proposed to solve this problem for closed and switched systems. In this paper, we extend these notions to open nonlinear dynamical systems with slowly-varying inputs to lower bound the bit rate needed to estimate their states. Our entropy definition represents the rate of exponential increase of the number of functions needed to approximate the trajectories of the system up to a specified $\eps$ error. We show that alternative entropy definitions using spanning or separating trajectories bound ours from both sides. On the other hand, we show that the existing definitions of entropy that consider supremum over all $\eps$ or require exponential convergence of estimation error, are not suitable for open systems. Since the actual value of entropy is generally hard to compute, we derive an upper bound instead and compute it for two examples. We show that as the bound on the input variation decreases, we recover a previously known bound on estimation entropy for closed nonlinear systems. For the sake of computing the bound, we present an algorithm that, given sampled and quantized measurements from a trajectory and an input signal up to a time bound $T&gt;0$, constructs a function that approximates the trajectory up to an $\eps$ error. We show that this algorithm can also be used for state estimation if the input signal can indeed be sensed. Finally, we relate the computed bound with a previously known upper bound on the entropy for switched nonlinear systems. We show that a bound on the divergence between the different modes of a switched system is needed to get a meaningful bound on its entropy.      
### 9.Analysing the Data-Driven Approach of Dynamically Estimating Positioning Accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2011.10478.pdf)
>  The primary expectation from positioning systems is for them to provide the users with reliable estimates of their position. An additional information that can greatly help the users utilize the position estimate is the level of uncertainty that a positioning system assigns to the position estimate it produced. The concept of dynamically estimating the accuracy of position estimates of fingerprinting positioning systems has been sporadically discussed over the last decade in the literature of the field, where mainly handcrafted rules based on domain knowledge have been proposed. The emergence of IoT devices and the proliferation of data from Low Power Wide Area Networks (LPWANs) has facilitated the conceptualization of data-driven methods of determining the estimated certainty over position estimates. In this work, we analyze the data-driven based determination of the Dynamic Accuracy Estimation (DAE), considering it in the broader context of a positioning system. More specifically, with the use of a public LoRaWAN dataset, the current work analyses: the repartition of the available training set between the tasks of determining the location estimates and the DAE, the concept of selecting a subset of the most reliable estimates, and the impact that the spatial distribution of the data has to the accuracy of the DAE. The work provides a wide overview of the data-driven approach of DAE determination in the context of the overall design of a positioning system.      
### 10.A Remote Carrier Synchronization Technique for Coherent Distributed Remote Sensing Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.10404.pdf)
>  Phase, frequency, and time synchronization are crucial requirements for many applications, such as multi-static remote sensing and communication systems. Moreover, the synchronization solution becomes even more challenging when the nodes are orbiting or flying on airborne or spaceborne platforms. This paper compares the available technologies used for the synchronization and coordination of nodes in distributed remote sensing applications. Additionally, this paper proposes a general system model and identifies preliminary guidelines and critical elements for implementing the synchronization mechanisms exploiting the inter-satellite communication link. The distributed phase synchronization loop introduced in this work deals with the self-interference in a full-duplex point to point scenario by transmitting two carriers at each node. All carriers appear with different frequency offsets around a central frequency, called the application central-frequency or the beamforming frequency. This work includes a detailed analysis of the proposed algorithm and the required simulations to verify its performance for different phase noise, AWGN, and Doppler shift scenarios.      
### 11.Data-Driven Modulation and Antenna Classification of Wireless Digital Communication Signals  [ :arrow_down: ](https://arxiv.org/pdf/2011.10377.pdf)
>  In this paper we are interested to learn from a wireless digitally modulated signal the number of antennas that the transmitter (Tx) of this signal uses, as well as its specific modulation scheme (from phase-shift keying (PSK) or quadrature amplitude modulation (QAM)). Formally, these are modulation and antenna classification problems. We examine the problems with data-driven machine learning (ML)-based techniques. The two sub-problems of modulation and number of transmitter antenna classification are initially examined independently for a variety for system parameters, namely the SNR, number of receiver (Rx) antennas, and classification algorithms. Then we consider the joint problem where we follow two approaches. One, where the sub-problems are solved independently and in parallel, and one where the antenna classifier waits on the result of the modulation classifier. The two proposed schemes do not require any knowledge/details of the used modulation schemes and the way the Tx antennas are used (spatial multiplexing, space-time codes,etc.) as it is fully data-driven and not decision-theoretic based. The results of our approach are characterized by high classification accuracy and they pave the way for more ML-based data-driven techniques that reveal more characteristics of the Tx.      
### 12.Deep Multi-Frame MVDR Filtering for Single-Microphone Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2011.10345.pdf)
>  Multi-frame algorithms for single-microphone speech enhancement, e.g., the multi-frame minimum variance distortionless response (MFMVDR) filter, are able to exploit speech correlation across adjacent time frames in the short-time Fourier transform (STFT) domain. Provided that accurate estimates of the required speech interframe correlation vector and the noise correlation matrix are available, it has been shown that the MFMVDR filter yields a substantial noise reduction while hardly introducing any speech distortion. Aiming at merging the speech enhancement potential of the MFMVDR filter and the estimation capability of temporal convolutional networks (TCNs), in this paper we propose to embed the MFMVDR filter within a deep learning framework. The TCNs are trained to map the noisy speech STFT coefficients to the required quantities by minimizing the scale-invariant signal-to-distortion ratio loss function at the MFMVDR filter output. Experimental results show that the proposed deep MFMVDR filter achieves a competitive speech enhancement performance on the Deep Noise Suppression Challenge dataset. In particular, the results show that estimating the parameters of an MFMVDR filter yields a higher performance in terms of PESQ and STOI than directly estimating the multi-frame filter or single-frame masks and than Conv-TasNet.      
### 13.Improvement of accuracy for measurement of 100-km fibre latency with Correlation OTDR  [ :arrow_down: ](https://arxiv.org/pdf/2011.10325.pdf)
>  We measured the latency of a 100 km fibre link using a Correlation OTDR. Improvements over previous results were achieved by increasing the probe signal rate to 10 Gbit/s, using dispersion compensation gratings, and coupling the receiver time base to an external PPS signal.      
### 14.Deep Learning Applied to Beamforming in Synthetic Aperture Ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2011.10321.pdf)
>  Deep learning methods can be found in many medical imaging applications. Recently, those methods were applied directly to the RF ultrasound multi-channel data to enhance the quality of the reconstructed images. In this paper, we apply a deep neural network to medical ultrasound imaging in the beamforming stage. Specifically, we train the network using simulated multi-channel data from two arrays with different sizes, using a variety of direction of arrival (DOA) angles, and test its generalization performance on real cardiac data. We demonstrate that our method can be used to improve image quality over standard methods, both in terms of resolution and contrast. Alternatively, it can be used to reduce the number of elements in the array, while maintaining the image quality. The utility of our method is demonstrated on both simulated and real data.      
### 15.Synchronization Instability of Inverter-Based Generation During Asymmetrical Grid Faults  [ :arrow_down: ](https://arxiv.org/pdf/2011.10316.pdf)
>  Regardless of symmetrical or asymmetrical faults, transient stability of traditional power systems is concerned with the ability of generators to stay synchronized with the positive-sequence voltage of the network. In contrast, both positive- and negative-sequence synchronization should be of concern for inverter-based generation (IBG) during asymmetrical faults. This is because the latest grid codes stipulate that IBG should inject dual-sequence current when riding through asymmetrical faults. Currently, much less is known about the synchronization stability during asymmetrical faults. This significantly differs from the positive-sequence synchronization alone because the coupled dual-sequence synchronization is involved. This paper aims to fill this gap. Considering the sequence coupling under asymmetrical faults, the dual-sequence synchronization model of IBG is developed. Based on the model, the conditions that steady-state equilibrium points should follow are identified. The conditions throw light on the possible types of synchronization instability, including the positive sequence dominated instability and the negative-sequence dominated one. For different types of instability, the dominant factors are analyzed quantitatively, which are reflected by the limit on the current injection magnitude. Exceeding the limit will lead to the loss of synchronism in both the sequences. The model and the analysis are verified by simulations.      
### 16.Edge Adaptive Hybrid Regularization Model For Image Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2011.10260.pdf)
>  A spatially fixed parameter of regularization item for whole images doesn't perform well both at edges and smooth areas. A large parameter of regularization item reduces noise better in smooth area but blurs edges, while a small parameter sharpens edges but causes residual noise. In this paper, an automated spatially dependent regularization parameter hybrid regularization model is proposed for reconstruction of noisy and blurred images which combines the harmonic and TV models. The algorithm detects image edges and spatially adjusts the parameters of Tikhonov and TV regularization terms for each pixel according to edge information. In addition, the edge information matrix will be dynamically updated with the iteration process. Computationally, the newly-established model is convex, then it can be solved by the semi-proximal alternating direction method of multipliers (sPADMM) with a linear-rate convergence. Numerical simulation results demonstrate that the proposed model effectively protects the image edge while eliminating noise and blur and outperforms the state-of-the-art algorithms in terms of PSNR, SSIM and visual quality.      
### 17.Discriminative Localized Sparse Representations for Breast Cancer Screening  [ :arrow_down: ](https://arxiv.org/pdf/2011.10201.pdf)
>  Breast cancer is the most common cancer among women both in developed and developing countries. Early detection and diagnosis of breast cancer may reduce its mortality and improve the quality of life. Computer-aided detection (CADx) and computer-aided diagnosis (CAD) techniques have shown promise for reducing the burden of human expert reading and improve the accuracy and reproducibility of results. Sparse analysis techniques have produced relevant results for representing and recognizing imaging patterns. In this work we propose a method for Label Consistent Spatially Localized Ensemble Sparse Analysis (LC-SLESA). In this work we apply dictionary learning to our block based sparse analysis method to classify breast lesions as benign or malignant. The performance of our method in conjunction with LC-KSVD dictionary learning is evaluated using 10-, 20-, and 30-fold cross validation on the MIAS dataset. Our results indicate that the proposed sparse analyses may be a useful component for breast cancer screening applications.      
### 18.Deep unfolding-based output feedback control design for linear systems with input saturation  [ :arrow_down: ](https://arxiv.org/pdf/2011.10196.pdf)
>  In this paper, we propose a deep unfolding-based framework for the output feedback control of systems with input saturation. Although saturation commonly arises in several practical control systems, there is still a scarce of effective design methodologies that can directly deal with the severe non-linearity of the saturation operator. In this paper, we aim to design an anti-windup controller for enlarging the region of stability of the closed-loop system by learning from the numerical simulations of the closed-loop system. The data-driven framework we propose in this paper is based on a deep-learning technique called Neural Ordinary Differential Equations. Within our framework, we first obtain a candidate controller by using the deep-learning technique, which is then tested by the existing theoretical results already established in the literature, thereby avoiding the computational challenge in the conventional design methodologies as well as theoretically guaranteeing the performance of the system. Our numerical simulation shows that the proposed framework can significantly outperform a conventional design methodology based on linear matrix inequalities.      
### 19.Targeted Self Supervision for Classification on a Small COVID-19 CT Scan Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2011.10188.pdf)
>  Traditionally, convolutional neural networks need large amounts of data labelled by humans to train. Self supervision has been proposed as a method of dealing with small amounts of labelled data. The aim of this study is to determine whether self supervision can increase classification performance on a small COVID-19 CT scan dataset. This study also aims to determine whether the proposed self supervision strategy, targeted self supervision, is a viable option for a COVID-19 imaging dataset. A total of 10 experiments are run comparing the classification performance of the proposed method of self supervision with different amounts of data. The experiments run with the proposed self supervision strategy perform significantly better than their non-self supervised counterparts. We get almost 8% increase in accuracy with full self supervision when compared to no self supervision. The results suggest that self supervision can improve classification performance on a small COVID-19 CT scan dataset. Code for targeted self supervision can be found at this link: <a class="link-external link-https" href="https://github.com/Mewtwo/Targeted-Self-Supervision/tree/main/COVID-CT" rel="external noopener nofollow">this https URL</a>      
### 20.Impact of COVID-19 on Mobility and Electric Vehicle Charging Load  [ :arrow_down: ](https://arxiv.org/pdf/2011.10182.pdf)
>  The COVID-19 pandemic has depressed overall mobility across the country. The changes seen reflect responses to new COVID-19 cases, local health guidelines, and seasonality, making the relationship between mobility and COVID-19 unique from region to region. This paper presents a data-driven case study of electric vehicle (EV) charging and mobility in the wake of COVID-19. The study shows that the number of EV charging sessions and total energy consumed per day dropped by 40% immediately after the arrival of the first COVID-19 case in Utah. By contrast, the energy consumed per charging session fell by just 8% over the same periods and the distribution of session start and end times remained consistent throughout the year. While EV mobility dropped more dramatically than total vehicle mobility during the first wave of COVID-19 cases, and returned more slowly, both returned to stable levels near their mean values by September 2020, despite a dramatic third wave in new infections.      
### 21.Flight Sensor Data and Beamforming based Integrated UAV Tracking with Channel Estimation using Gaussian Process Regression  [ :arrow_down: ](https://arxiv.org/pdf/2011.10177.pdf)
>  With explosively increasing demands for unmanned aerial vehicle (UAV) applications, reliable link acquisition for serving UAVs is required. Considering the dynamic characteristics of UAV, it is hugely challenging to persist a reliable link without beam misalignment. In this paper, we propose a flight sensor data and beamforming signal based integrated UAV tracking scheme to deal with this problem. The proposed scheme provides a compatible integrated system considering the practical specification of the flight sensor data and the beamforming pilot signal. The UAV position tracking is comprised of two steps: 1) UAV position prediction by the flight sensor data and 2) position update with the beamforming signal using Gaussian process regression (GPR) method, which is a nonparametric machine learning. The flight sensor data can assist ground station (GS) or UAV nodes in designing the precoding and the receive beamforming matrix with drastically reduced overheads. The beamforming signal can accomplish high beamforming gain to be maintained even when the flight sensor data is absent. Therefore, the proposed scheme can support the moving target continuously by utilizing these two signals. The simulation results are provided to confirm that the proposed scheme outperforms other conventional beam tracking schemes. We also derive 3-dimensional (3D) beamforming gain and spectral efficiency (SE) from the mean absolute error (MAE) of the angular value estimation, which can be used as beamforming performance metrics of the data transmission link in advance.      
### 22.A Unified Model of Feature Extraction and Clustering for Spike Sorting  [ :arrow_down: ](https://arxiv.org/pdf/2011.10163.pdf)
>  Spike sorting plays an irreplaceable role in understanding brain codes. Traditional spike sorting technologies perform feature extraction and clustering separately after spikes are well detected. However, it may often cause many additional processes and further lead to low-accurate and/or unstable results especially when there are noises and/or overlapping spikes in datasets. To address these issues, in this paper, we proposed a unified optimisation model integrating feature extraction and clustering for spike sorting. Interestingly, instead of the widely used combination strategies, i.e., performing the principal component analysis (PCA) for spike feature extraction and K-means (KM) for clustering in sequence, we unified PCA and KM into one optimisation model, which reduces additional processes with fewer iteration times. Subsequently, by embedding the K-means++ strategy for initialising and a comparison updating rule in the solving process, the proposed model can well handle the noises and/or overlapping interference. Finally, taking the best of the clustering validity indices into the proposed model, we derive an automatic spike sorting method. Plenty of experimental results on both synthetic and real-world datasets confirm that our proposed method outperforms the related state-of-the-art approaches.      
### 23.Full-Duplex Non-Orthogonal Multiple Access Cooperative Overlay Spectrum-Sharing Networks with SWIPT  [ :arrow_down: ](https://arxiv.org/pdf/2011.10133.pdf)
>  This paper proposes a novel non-orthogonal multiple access (NOMA) assisted cooperative spectrum sharing network, in which one of the full-duplex (FD) secondary transmitters (STs) is chosen among many for forwarding the primary transmitter's and its own information to primary receiver and secondary receivers, respectively, using NOMA technique. To stimulate the ST to conduct cooperative transmission and sustain its operations, the simultaneous wireless information and power transfer (SWIPT) technique is utilized by the ST to harvest the primary signal's energy. In order to evaluate the proposed system's performance, the outage probability and system throughput for the primary and secondary networks are derived in tight closed-form approximations. Further, the sum rate optimization problem is formulated for the proposed cooperative network and a rapid convergent iterative algorithm is proposed to obtain the optimized power allocation coefficients. Numerical results show that FD, SWIPT, and NOMA techniques greatly boost the performance of cooperative spectrum-sharing network in terms of outage probability, system throughput, and sum rate compared to that of half-duplex NOMA and the conventional orthogonal multiple access-time division multiple access networks.      
### 24.Identification of NARX Models for Compesation Design  [ :arrow_down: ](https://arxiv.org/pdf/2011.10109.pdf)
>  This report presents the modeling results for three systems, two numerical and one experimental. In the numerical examples, we use mathematical models previously obtained in the literature as the systems to be identified. The first numerical example is a heating system with a polynomial nonlinearity that is described by a Hammerstein model. The second is a Bouc-Wen model that represents the hysteretic behavior in a piezoelectric actuator. Finally, the experimental example is a pneumatic valve that presents a variety of nonlinearities, including hysteresis. For each example, a Nonlinear AutoRegressive model with eXogenous inputs (NARX) is identified using two well-established techniques together, the Error Reduction Ratio (ERR) method to hierarchically select the regressors and the Akaike's Information Criterion (AIC) to truncate the number of terms. Using both approaches, the structure selection is achieved. The design of the excitation input is based on preserving the frequencies of interest and force the system to achieve different points of operation. Hence, having the structure previously selected with ERR and AIC, we use the Extended Least Squares (ELS) algorithm to estimate the parameters. The results show that it is possible to identify the referred systems with no more than five terms. These identified models will be used for nonlinearity compensation in future works.      
### 25.Compartment model-based nonlinear unmixing for kinetic analysis of dynamic PET images  [ :arrow_down: ](https://arxiv.org/pdf/2011.10097.pdf)
>  When no arterial input function is available, quantification of dynamic PET images requires a previous step devoted to the extraction of a reference time-activity curve (TAC). Factor analysis is often applied for this purpose. This paper introduces a novel approach that conducts a new kind of nonlinear factor analysis relying on a compartment model, and computes the kinetic parameters of specific binding tissues jointly. To this end, it capitalizes on data-driven parametric imaging methods to provide a physical description of the underlying PET data, directly relating the specific binding with the kinetics of the non-specific binding in the corresponding tissues. This characterization is introduced into the factor analysis formulation to yield a novel nonlinear unmixing model designed for PET image analysis. This model also explicitly introduces global kinetic parameters that allow for a direct estimation of the binding potential with respect to the free fractions in each non-specific binding tissue. The performance of the method is evaluated on synthetic and real data to demonstrate its potential interest.      
### 26.Locally-Aware Constrained Games on Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.10095.pdf)
>  Network games have been instrumental in understanding strategic behaviors over networks for applications such as critical infrastructure networks, social networks, and cyber-physical systems. One critical challenge of network games is that the behaviors of the players are constrained by the underlying physical laws or safety rules, and the players may not have complete knowledge of network-wide constraints. To this end, this paper proposes a game framework to study constrained games on networks, where the players are locally aware of the constraints. We use \textit{awareness levels} to capture the scope of the network constraints that players are aware of. We first define and show the existence of generalized Nash equilibria (GNE) of the game, and point out that higher awareness levels of the players would lead to a larger set of GNE solutions. We use necessary and sufficient conditions to characterize the GNE, and propose the concept of the dual game to show that one can convert a locally-aware constrained game into a two-layer unconstrained game problem. We use linear quadratic games as case studies to corroborate the analytical results, and in particular, show the duality between Bertrand games and Cournot games.%, where each layer comprises an unconstrained game.      
### 27.Hierarchical Multi-timescale Framework For Operation of Dynamic Community Microgrid  [ :arrow_down: ](https://arxiv.org/pdf/2011.10087.pdf)
>  Distribution system integrated community microgrids (CMGs) can restore loads during extended outages. The CMG is challenged with limited resource availability, absence of a robust grid-support, and demand-supply uncertainty. To address these challenges, this paper proposes a three-stage hierarchical multi-timescale framework for scheduling and real-time (RT) dispatch of CMGs. The CMG's ability to dynamically expand its boundary to support the neighboring grid sections is also considered. The first stage solves a stochastic day-ahead (DA) scheduling problem to obtain referral plans for optimal resource rationing. The intermediate near real-time scheduling stage updates the DA schedule closer to the dispatch time, followed by the RT dispatch stage. The proposed methodology is validated via numerical simulations on a modified IEEE 123-bus system, which shows superior performance in terms of RT load supplied under different forecast error cases, outage duration scenarios, and against the traditionally used two-stage approach.      
### 28.Seismic Facies Analysis: A Deep Domain Adaptation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.10510.pdf)
>  Deep neural networks (DNNs) can learn accurately from large quantities of labeled input data, but DNNs sometimes fail to generalize to test data sampled from different input distributions. Unsupervised Deep Domain Adaptation (DDA) proves useful when no input labels are available, and distribution shifts are observed in the target domain (TD). Experiments are performed on seismic images of the F3 block 3D dataset from offshore Netherlands (source domain; SD) and Penobscot 3D survey data from Canada (target domain; TD). Three geological classes from SD and TD that have similar reflection patterns are considered. In the present study, an improved deep neural network architecture named EarthAdaptNet (EAN) is proposed to semantically segment the seismic images. We specifically use a transposed residual unit to replace the traditional dilated convolution in the decoder block. The EAN achieved a pixel-level accuracy &gt;84% and an accuracy of ~70% for the minority classes, showing improved performance compared to existing architectures. In addition, we introduced the CORAL (Correlation Alignment) method to the EAN to create an unsupervised deep domain adaptation network (EAN-DDA) for the classification of seismic reflections fromF3 and Penobscot. Maximum class accuracy achieved was ~99% for class 2 of Penobscot with &gt;50% overall accuracy. Taken together, EAN-DDA has the potential to classify target domain seismic facies classes with high accuracy.      
### 29.Synthetic Image Rendering Solves Annotation Problem in Deep Learning Nanoparticle Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2011.10505.pdf)
>  Nanoparticles occur in various environments as a consequence of man-made processes, which raises concerns about their impact on the environment and human health. To allow for proper risk assessment, a precise and statistically relevant analysis of particle characteristics (such as e.g. size, shape and composition) is required that would greatly benefit from automated image analysis procedures. While deep learning shows impressive results in object detection tasks, its applicability is limited by the amount of representative, experimentally collected and manually annotated training data. Here, we present an elegant, flexible and versatile method to bypass this costly and tedious data acquisition process. We show that using a rendering software allows to generate realistic, synthetic training data to train a state-of-the art deep neural network. Using this approach, we derive a segmentation accuracy that is comparable to man-made annotations for toxicologically relevant metal-oxide nanoparticle ensembles which we chose as examples. Our study paves the way towards the use of deep learning for automated, high-throughput particle detection in a variety of imaging techniques such as microscopies and spectroscopies, for a wide variety of studies and applications, including the detection of plastic micro- and nanoparticles.      
### 30.High contrast and resolution 3-D ultrasonography with a clinical linear transducer array scanned in a rotate-translate geometry  [ :arrow_down: ](https://arxiv.org/pdf/2011.10500.pdf)
>  We propose a novel solution for volumetric ultrasound imaging using single-side access 3-D synthetic-aperture scanning of a clinical linear array. This solution is based on an advanced scanning geometry and a software-based ultrasound platform. The rotate-translate scanning scheme increases the elevation angular aperture by pivoting the array [-45{\textdegree} to 45{\textdegree}] around its array axis (axis along the row of its elements) and then, scans the imaged object for each pivoted angle by translating the array perpendicularly to the rotation axis. A theoretical basis is presented so that the angular and translational scan sampling periods can be best adjusted for any linear transducer array. We experimentally implemented scanning with a 5-MHz array. In vitro characterization was performed with phantoms designed to test resolution and contrast. Spatial resolution assessed based on the full-width half-maximum of images from isolated microspheres was increased by a factor 3 along the translational direction from a simple translation scan of the array. Moreover, the resolution is uniform over a cross-sectional area of 4.5 cm 2. Angular sampling periods were optimized and tapered to decrease the scan duration while maintaining image contrast (contrast at the center of a 5 mm cyst on the order of-26 dB for 4{\textdegree} angular period and a scan duration of 10 s for a 9cm 3 volume). We demonstrate that superior 3-D US imaging can be obtained with a clinical array using our scanning strategy. This technique offers a promising and flexible alternative to development of costly matrix arrays toward the development of sensitive volumetric ultrasonography.      
### 31.Utilizing ROS 1 and the Turtlebot3 in a Multi-Robot System  [ :arrow_down: ](https://arxiv.org/pdf/2011.10488.pdf)
>  ROS (Robot Operating System) has become ubiquitous for testing new algorithms, alternative hardware configurations, and prototyping. By performing research with its modular framework, it can streamline sharing new work and integrations. However, it has many features and new terms that can take a considerable amount of time to learn for a new user. This paper will explore how to set up and configure ROS and ROS packages to work with a multi-robot system on a single master network.      
### 32.DeepPhaseCut: Deep Relaxation in Phase for Unsupervised Fourier Phase Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2011.10475.pdf)
>  Fourier phase retrieval is a classical problem of restoring a signal only from the measured magnitude of its Fourier transform. Although Fienup-type algorithms, which use prior knowledge in both spatial and Fourier domains, have been widely used in practice, they can often stall in local minima. Modern methods such as PhaseLift and PhaseCut may offer performance guarantees with the help of convex relaxation. However, these algorithms are usually computationally intensive for practical use. To address this problem, we propose a novel, unsupervised, feed-forward neural network for Fourier phase retrieval which enables immediate high quality reconstruction. Unlike the existing deep learning approaches that use a neural network as a regularization term or an end-to-end blackbox model for supervised training, our algorithm is a feed-forward neural network implementation of PhaseCut algorithm in an unsupervised learning framework. Specifically, our network is composed of two generators: one for the phase estimation using PhaseCut loss, followed by another generator for image reconstruction, all of which are trained simultaneously using a cycleGAN framework without matched data. The link to the classical Fienup-type algorithms and the recent symmetry-breaking learning approach is also revealed. Extensive experiments demonstrate that the proposed method outperforms all existing approaches in Fourier phase retrieval problems.      
### 33.Probabilistic Radio-Visual Active Sensing for Search and Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2011.10474.pdf)
>  Active Search and Tracking for search and rescue missions or collaborative mobile robotics relies on the actuation of a sensing platform to detect and localize a target. In this paper we focus on visually detecting a radio-emitting target with an aerial robot equipped with a radio receiver and a camera. Visual-based tracking provides high accuracy, but the directionality of the sensing domain often requires long search times before detecting the target. Conversely,radio signals have larger coverage, but lower tracking accuracy. Thus, we design a Recursive Bayesian Estimation scheme that uses camera observations to refine radio measurements. To regulate the camera pose, we design an optimal controller whose cost function is built upon a probabilistic map. Theoretical results support the proposed algorithm, while numerical analyses show higher robustness and efficiency with respect to visual and radio-only baselines.      
### 34.Empirical Evaluation of Deep Learning Model Compression Techniques on the WaveNet Vocoder  [ :arrow_down: ](https://arxiv.org/pdf/2011.10469.pdf)
>  WaveNet is a state-of-the-art text-to-speech vocoder that remains challenging to deploy due to its autoregressive loop. In this work we focus on ways to accelerate the original WaveNet architecture directly, as opposed to modifying the architecture, such that the model can be deployed as part of a scalable text-to-speech system. We survey a wide variety of model compression techniques that are amenable to deployment on a range of hardware platforms. In particular, we compare different model sparsity methods and levels, and seven widely used precisions as targets for quantization; and are able to achieve models with a compression ratio of up to 13.84 without loss in audio fidelity compared to a dense, single-precision floating-point baseline. All techniques are implemented using existing open source deep learning frameworks and libraries to encourage their wider adoption.      
### 35.RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2011.10359.pdf)
>  We consider the problem of simultaneously estimating a dense depth map and camera pose for a large set of images of an indoor scene. While classical SfM pipelines rely on a two-step approach where cameras are first estimated using a bundle adjustment in order to ground the ensuing multi-view stereo stage, both our poses and dense reconstructions are a direct output of an altered bundle adjuster. To this end, we parametrize each depth map with a linear combination of a limited number of basis "depth-planes" predicted in a monocular fashion by a deep net. Using a set of high-quality sparse keypoint matches, we optimize over the per-frame linear combinations of depth planes and camera poses to form a geometrically consistent cloud of keypoints. Although our bundle adjustment only considers sparse keypoints, the inferred linear coefficients of the basis planes immediately give us dense depth maps. RidgeSfM is able to collectively align hundreds of frames, which is its main advantage over recent memory-heavy deep alternatives that can align at most 10 frames. Quantitative comparisons reveal performance superior to a state-of-the-art large-scale SfM pipeline.      
### 36.Experiences from Large-Scale Model Checking: Verification of a Vehicle Control System  [ :arrow_down: ](https://arxiv.org/pdf/2011.10351.pdf)
>  In the age of autonomously driving vehicles, functionality and complexity of embedded systems are increasing tremendously. Safety aspects become more important and require such systems to operate with the highest possible level of fault tolerance. Simulation and systematic testing techniques have reached their limits in this regard. Here, formal verification as a long established technique can be an appropriate complement. However, the necessary preparatory work like adequately modeling a system and specifying properties in temporal logic are anything but trivial. In this paper, we report on our experiences applying model checking to verify the arbitration logic of a Vehicle Control System. We balance pros and cons of different model checking techniques and tools, and reason about our choice of the symbolic model checker NuSMV. We describe the process of modeling the architecture, resulting in ~1500 LOC, 69 state variables and 38 LTL constraints. To handle this large-scale model, we automate and optimize the model checking procedure for use on multi-core CPUs and employ Bounded Model Checking to avoid the state explosion problem. We share our lessons learned and provide valuable insights for architects, developers, and test engineers involved in this highly present topic.      
### 37.Distributed Power Flow and Distributed Optimization -- Formulation, Solution, and Open Source Implementation  [ :arrow_down: ](https://arxiv.org/pdf/2011.10322.pdf)
>  Solving the power flow problem in a distributed fashion empowers different grid operators to compute the overall grid state without having to share grid models-this is a practical problem to which industry does not have off-the-shelf answers. In cooperation with a German transmission system operator we propose two physically consistent problem formulations (feasibility, least-squares) amenable to two solution methods from distributed optimization (the Alternating direction method of multipliers (ADMM), and the Augmented Lagrangian based Alternating Direction Inexact Newton method (Aladin)); with Aladin there come convergence guarantees for the distributed power flow problem. In addition, we provide open source matlab code for rapid prototyping for distributed power flow (rapidPF), a fully matpower-compatible software that facilitates the laborious task of formulating power flow problems as distributed optimization problems; the code is available under <a class="link-external link-https" href="https://github.com/KIT-IAI/rapidPF/" rel="external noopener nofollow">this https URL</a>. The approach to solving distributed power flow problems that we present is flexible, modular, consistent, and reproducible. Simulation results for systems ranging from 53 buses (with 3 regions) up to 4662 buses (with 5 regions) show that the least-squares formulation solved with aladin requires just about half a dozen coordinating steps before the power flow problem is solved.      
### 38.Reconfigurable Intelligent Surface Enabled Federated Learning: A Unified Communication-Learning Design Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.10282.pdf)
>  To exploit massive amounts of data generated at mobile edge networks, federated learning (FL) has been proposed as an attractive substitute for centralized machine learning (ML). By collaboratively training a shared learning model at edge devices, FL avoids direct data transmission and thus overcomes high communication latency and privacy issues as compared to centralized ML. To improve the communication efficiency in FL model aggregation, over-the-air computation has been introduced to support a large number of simultaneous local model uploading by exploiting the inherent superposition property of wireless channels. However, due to the heterogeneity of communication capacities among edge devices, over-the-air FL suffers from the straggler issue in which the device with the weakest channel acts as a bottleneck of the model aggregation performance. This issue can be alleviated by device selection to some extent, but the latter still suffers from a tradeoff between data exploitation and model communication. In this paper, we leverage the reconfigurable intelligent surface (RIS) technology to relieve the straggler issue in over-the-air FL. Specifically, we develop a learning analysis framework to quantitatively characterize the impact of device selection and model aggregation error on the convergence of over-the-air FL. Then, we formulate a unified communication-learning optimization problem to jointly optimize device selection, over-the-air transceiver design, and RIS configuration. Numerical experiments show that the proposed design achieves substantial learning accuracy improvements compared with the state-of-the-art approaches, especially when channel conditions vary dramatically across edge devices.      
### 39.Cascade Attentive Dropout for Weakly Supervised Object Detection  [ :arrow_down: ](https://arxiv.org/pdf/2011.10258.pdf)
>  Weakly supervised object detection (WSOD) aims to classify and locate objects with only image-level supervision. Many WSOD approaches adopt multiple instance learning as the initial model, which is prone to converge to the most discriminative object regions while ignoring the whole object, and therefore reduce the model detection performance. In this paper, a novel cascade attentive dropout strategy is proposed to alleviate the part domination problem, together with an improved global context module. We purposely discard attentive elements in both channel and space dimensions, and capture the inter-pixel and inter-channel dependencies to induce the model to better understand the global context. Extensive experiments have been conducted on the challenging PASCAL VOC 2007 benchmarks, which achieve 49.8% mAP and 66.0% CorLoc, outperforming state-of-the-arts.      
### 40.GAN based ball screw drive picture database enlargement for failure classification  [ :arrow_down: ](https://arxiv.org/pdf/2011.10235.pdf)
>  The lack of reliable large datasets is one of the biggest difficulties of using modern machine learning methods in the field of failure detection in the manufacturing industry. In order to develop the function of failure classification for ball screw surface, sufficient image data of surface failures is necessary. When training a neural network model based on a small dataset, the trained model may lack the generalization ability and may perform poorly in practice. The main goal of this paper is to generate synthetic images based on the generative adversarial network (GAN) to enlarge the image dataset of ball screw surface failures. Pitting failure and rust failure are two possible failure types on ball screw surface chosen in this paper to represent the surface failure classes. The quality and diversity of generated images are evaluated afterwards using qualitative methods including expert observation, t-SNE visualization and the quantitative method of FID score. To verify whether the GAN based generated images can increase failure classification performance, the real image dataset was augmented and replaced by GAN based generated images to do the classification task. The authors successfully created GAN based images of ball screw surface failures which showed positive effect on classification test performance.      
### 41.One Shot Learning for Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2011.10233.pdf)
>  Despite the recent success of speech separation models, they fail to separate sources properly while facing different sets of people or noisy environments. To tackle this problem, we proposed to apply meta-learning to the speech separation task. We aimed to find a meta-initialization model, which can quickly adapt to new speakers by seeing only one mixture generated by those people. In this paper, we use model-agnostic meta-learning(MAML) algorithm and almost no inner loop(ANIL) algorithm in Conv-TasNet to achieve this goal. The experiment results show that our model can adapt not only to a new set of speakers but also noisy environments. Furthermore, we found out that the encoder and decoder serve as the feature-reuse layers, while the separator is the task-specific module.      
### 42.Deep Snapshot HDR Imaging Using Multi-Exposure Color Filter Array  [ :arrow_down: ](https://arxiv.org/pdf/2011.10232.pdf)
>  In this paper, we propose a deep snapshot high dynamic range (HDR) imaging framework that can effectively reconstruct an HDR image from the RAW data captured using a multi-exposure color filter array (ME-CFA), which consists of a mosaic pattern of RGB filters with different exposure levels. To effectively learn the HDR image reconstruction network, we introduce the idea of luminance normalization that simultaneously enables effective loss computation and input data normalization by considering relative local contrasts in the "normalized-by-luminance" HDR domain. This idea makes it possible to equally handle the errors in both bright and dark areas regardless of absolute luminance levels, which significantly improves the visual image quality in a tone-mapped domain. Experimental results using two public HDR image datasets demonstrate that our framework outperforms other snapshot methods and produces high-quality HDR images with fewer visual artifacts.      
### 43.MobileDepth: Efficient Monocular Depth Prediction on Mobile Devices  [ :arrow_down: ](https://arxiv.org/pdf/2011.10189.pdf)
>  Depth prediction is fundamental for many useful applications on computer vision and robotic systems. On mobile phones, the performance of some useful applications such as augmented reality, autofocus and so on could be enhanced by accurate depth prediction. In this work, an efficient fully convolutional network architecture for depth prediction has been proposed, which uses RegNetY 06 as the encoder and split-concatenate shuffle blocks as decoder. At the same time, an appropriate combination of data augmentation, hyper-parameters and loss functions to efficiently train the lightweight network has been provided. Also, an Android application has been developed which can load CNN models to predict depth map by the monocular images captured from the mobile camera and evaluate the average latency and frame per second of the models. As a result, the network achieves 82.7% {\delta}1 accuracy on NYU Depth v2 dataset and at the same time, have only 62ms latency on ARM A76 CPUs so that it can predict the depth map from the mobile camera in real-time.      
### 44.Online Multi-Object Tracking with delta-GLMB Filter based on Occlusion and Identity Switch Handling  [ :arrow_down: ](https://arxiv.org/pdf/2011.10111.pdf)
>  In this paper, we propose an online multi-object tracking (MOT) method in a delta Generalized Labeled Multi-Bernoulli (delta-GLMB) filter framework to address occlusion and miss-detection issues, reduce false alarms, and recover identity switch (ID switch). To handle occlusion and miss-detection issues, we propose a measurement-to-disappeared track association method based on one-step delta-GLMB filter, so it is possible to manage these difficulties by jointly processing occluded or miss-detected objects. This part of proposed method is based on a proposed similarity metric which is responsible for defining the weight of hypothesized reappeared tracks. We also extend the delta-GLMB filter to efficiently recover switched IDs using the cardinality density, size and color features of the hypothesized tracks. We also propose a novel birth model to achieve more effective clutter removal performance. In both occlusion/miss-detection handler and newly-birthed object detector sections of the proposed method, unassigned measurements play a significant role, since they are used as the candidates for reappeared or birth objects. In addition, we perform an ablation study which confirms the effectiveness of our contributions in comparison with the baseline method. We evaluate the proposed method on well-known and publicly available MOT15 and MOT17 test datasets which are focused on pedestrian tracking. Experimental results show that the proposed tracker performs better or at least at the same level of the state-of-the-art online and offline MOT methods. It effectively handles the occlusion and ID switch issues and reduces false alarms as well.      
### 45.Lidar-based exploration and discretization for mobile robot planning  [ :arrow_down: ](https://arxiv.org/pdf/2011.10066.pdf)
>  In robotic applications, the control, and actuation deal with a continuous description of the system and environment, while high-level planning usually works with a discrete description. This paper considers the problem of bridging the low-level control and high-level planning for robotic systems via sensor data. In particular, we propose a discretization algorithm that identifies free polytopes via lidar point cloud data. A transition graph is then constructed where each node corresponds to a free polytope and two nodes are connected with an edge if the two corresponding free polytopes intersect. Furthermore, a distance measure is associated with each edge, which allows for the assessment of quality (or cost) of the transition for high-level planning. For the low-level control, the free polytopes act as a convenient encoding of the environment and allow for the planning of collision-free trajectories that realizes the high-level plan. The results are demonstrated in high-fidelity ROS simulations and experiments with a drone and a Segway.      

# ArXiv eess --Wed, 4 Nov 2020
### 1.Base Station and Passive Reflectors Placement for Urban mmWave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.01920.pdf)
>  The use of millimeter-wave (mmWave) bands in 5G networks introduce a new set of challenges to network planning. Vulnerability to blockages and high path loss at mmWave frequencies require careful planning of the network to achieve the desired service quality. In this paper, we propose a novel 3D geometry-based framework for deploying mmWave base stations (gNBs) in urban environments by considering first-order reflection effects. We also provide a solution for the optimum deployment of passive metallic reflectors (PMRs) to extend radio coverage to non-line-of-sight (NLoS) areas. In particular, we perform visibility analysis to find the direct and indirect visibility regions, and using these, we derive a geometry-and-blockage-aided path loss model. We then formulate the network planning problem as two independent optimization problems, placement of gNB(s) and PMRs, to maximize the coverage area with a certain quality-of-service constraint and minimum cost. We test the efficacy of our proposed approach using a generic map and compare our simulation results with the ray-tracing solution. Our simulation results show that considering the first-order reflections in planning the mmWave network helps reduce the number of PMRs required to cover the NLoS area and the gNB placement aided with PMRs requires fewer gNBs to cover the same area, which in turn reduces the deployment cost.      
### 2.Fisher Identifiability Analysis of Longitudinal Vehicle Dynamics: Theory and Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2011.01918.pdf)
>  This paper examines the impact of mean-square terrain variability on longitudinal chassis parameter identifiability. This analysis is motivated by the immediate value of effective parameter estimation in various applications, including chassis model validation and active safety. Relevant literature addresses this demand through algorithms capable of estimating chassis parameters for diverse computational and on-road conditions. While the limitations of such algorithms' accuracy with respect to some driving conditions have been studied, their dependence on road grade variability remains largely unexplored. We address this open question by presenting two key contributions. First, this paper presents analytic derivations of the Fisher information matrix associated with estimating mass, drag, and rolling resistance parameters from longitudinal dynamics. We validate the analytic sensitivity expressions using simulations and experimental data gathered from an instrumented Volvo VNL300 heavy-duty freight truck. Then, this paper presents Monte Carlo simulations which illustrate the average improvements in chassis parameter identifiability associated with drive-cycles characterized by higher mean-square road grade. Our simulation studies demonstrate this result under a variety of drive cycles.      
### 3.Iterative Best Response for Multi-Body Asset-Guarding Games  [ :arrow_down: ](https://arxiv.org/pdf/2011.01893.pdf)
>  We present a numerical approach to finding optimal trajectories for players in a multi-body, asset-guarding game with nonlinear dynamics and non-convex constraints. Using the Iterative Best Response (IBR) scheme, we solve for each player's optimal strategy assuming the other players' trajectories are known and fixed. Leveraging recent advances in Sequential Convex Programming (SCP), we use SCP as a subroutine within the IBR algorithm to efficiently solve an approximation of each player's constrained trajectory optimization problem. We apply the approach to an asset-guarding game example involving multiple pursuers and a single evader (i.e., n-versus-1 engagements). Resulting evader trajectories are tested in simulation to verify successful evasion against pursuers using conventional intercept guidance laws.      
### 4.Fast Adaptive Fault Accommodation in Floating Offshore Wind Turbines via Model-Based Fault Diagnosis and Subspace Predictive Repetitive Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.01855.pdf)
>  As Floating Offshore Wind Turbines (FOWTs) operate in deep waters and are subjected to stressful wind and wave induced loads, they are more prone than onshore counterparts to experience faults and failure. In particular, the pitch system may experience Pitch Actuator Stuck (PAS) type of faults, which will result in a complete loss of control authority. In this paper, a novel fast and adaptive solution is developed by integrating a model-based Fault Diagnosis (FD) scheme and the Subspace Predictive Repetitive Control (SPRC). The FD role is to quickly detect and isolate the failed pitch actuator. Based on the fault isolation results, a pre-tuned adaptive SPRC is switched online in place of the existing one, whose initial values of the parameters has been tuned offline to match the specific faulty case. After that, SPRC employs subspace identification to continuously identify a linear model of the wind turbine over a moving time window, and thereby formulate an adaptive control law to alleviate the PAS-induced loads. Results show that the developed architecture allows to achieve a considerable reduction of the PAS-induced blade loads. More importantly, the time needed to reduce the PAS-induced loads are significantly shortened, thus avoiding further damage to other components during the adaption time and allowing continued power generation.      
### 5.A Deep Learning based Detection Method for Combined Integrity-Availability Cyber Attacks in Power System  [ :arrow_down: ](https://arxiv.org/pdf/2011.01816.pdf)
>  As one of the largest and most complex systems on earth, power grid (PG) operation and control have stepped forward as a compound analysis on both physical and cyber layers which makes it vulnerable to assaults from economic and security considerations. A new type of attack, namely as combined data Integrity-Availability attack, has been recently proposed, where the attackers can simultaneously manipulate and blind some measurements on SCADA system to mislead the control operation and keep stealthy. Compared with traditional FDIAs, this combined attack can further complicate and vitiate the model-based detection mechanism. To detect such attack, this paper proposes a novel random denoising LSTM-AE (LSTMRDAE) framework, where the spatial-temporal correlations of measurements can be explicitly captured and the unavailable data is countered by the random dropout layer. The proposed algorithm is evaluated and the performance is verified on a standard IEEE 118-bus system under various unseen attack attempts.      
### 6.Fast High Resolution Blood Flow Estimation and Clutter Rejection via an Alternating Optimization Problem  [ :arrow_down: ](https://arxiv.org/pdf/2011.01811.pdf)
>  This paper introduces a computationally efficient technique for estimating high-resolution Doppler blood flow from an ultrafast ultrasound image sequence. More precisely, it consists in a new fast alternating minimization algorithm that implements a blind deconvolution method based on robust principal component analysis. Numerical investigation carried out on \textit{in vivo} data shows the efficiency of the proposed approach in comparison with state-of-the-art methods.      
### 7.Point of Care Image Analysis for COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2011.01789.pdf)
>  Early detection of COVID-19 is key in containing the pandemic. Disease detection and evaluation based on imaging is fast and cheap and therefore plays an important role in COVID-19 handling. COVID-19 is easier to detect in chest CT, however, it is expensive, non-portable, and difficult to disinfect, making it unfit as a point-of-care (POC) modality. On the other hand, chest X-ray (CXR) and lung ultrasound (LUS) are widely used, yet, COVID-19 findings in these modalities are not always very clear. Here we train deep neural networks to significantly enhance the capability to detect, grade and monitor COVID-19 patients using CXRs and LUS. Collaborating with several hospitals in Israel we collect a large dataset of CXRs and use this dataset to train a neural network obtaining above 90% detection rate for COVID-19. In addition, in collaboration with ULTRa (Ultrasound Laboratory Trento, Italy) and hospitals in Italy we obtained POC ultrasound data with annotations of the severity of disease and trained a deep network for automatic severity grading.      
### 8.Predicting intubation support requirement of patients using Chest X-ray with Deep Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.01787.pdf)
>  Recent developments in medical imaging with Deep Learning presents evidence of automated diagnosis and prognosis. It can also be a complement to currently available diagnosis methods. Deep Learning can be leveraged for diagnosis, severity prediction, intubation support prediction and many similar tasks. We present prediction of intubation support requirement for patients from the Chest X-ray using Deep representation learning. We release our source code publicly at <a class="link-external link-https" href="https://github.com/aniketmaurya/covid-research" rel="external noopener nofollow">this https URL</a>.      
### 9.Extensive frequency response and inertia analysis under high renewable energy source integration scenarios: application to the European interconnected power system  [ :arrow_down: ](https://arxiv.org/pdf/2011.01749.pdf)
>  Traditionally, power system's inertia has been estimated according to the rotating masses directly connected to the grid. However, a new generation mix scenario is currently identified, where conventional supply-side is gradually replaced by renewable sources decoupled from the grid by electronic converters (i.e., wind and photovoltaic power plants). Due to the significant penetration of such renewable generation units, the conventional grid inertia is decreasing, subsequently affecting both reliability analysis and grid stability. As a result, concepts such as 'synthetic inertia', 'hidden inertia' or 'virtual inertia', together with alternative spinning reserves, are currently under discussion to ensure power system stability and reliability. Under this new framework, an algorithm to estimate the minimum inertia needed to fulfil the ENTSO-E requirements for ROCOF values is proposed and assessed under a relevant variety of imbalanced conditions. The additional active power needed to be within the frequency dynamic range is also estimated and determined. Both inertia and additional active power can come from different sources, such as storage solutions, renewable sources decoupled from the grid including some frequency control strategies, interconnections with other grids, or a combination of them. The power system under consideration includes thermal, hydro-power plants, and renewable generation units, in line with most current and future European supply-side power systems. More than 700 generation mix scenarios are identified and simulated, varying the renewable integration, the power imbalance, and the inertia constant of conventional power plants. In fact, the solutions studied here provide important information to ease the massive integration of renewable resources, without reducing the capacity of the grid in terms of stability and response to contingencies.      
### 10.Solving Inverse Problems with Hybrid Deep Image Priors: the challenge of preventing overfitting  [ :arrow_down: ](https://arxiv.org/pdf/2011.01748.pdf)
>  We mainly analyze and solve the overfitting problem of deep image prior (DIP). Deep image prior can solve inverse problems such as super-resolution, inpainting and denoising. The main advantage of DIP over other deep learning approaches is that it does not need access to a large dataset. However, due to the large number of parameters of the neural network and noisy data, DIP overfits to the noise in the image as the number of iterations grows. In the thesis, we use hybrid deep image priors to avoid overfitting. The hybrid priors are to combine DIP with an explicit prior such as total variation or with an implicit prior such as a denoising algorithm. We use the alternating direction method-of-multipliers (ADMM) to incorporate the new prior and try different forms of ADMM to avoid extra computation caused by the inner loop of ADMM steps. We also study the relation between the dynamics of gradient descent, and the overfitting phenomenon. The numerical results show the hybrid priors play an important role in preventing overfitting. Besides, we try to fit the image along some directions and find this method can reduce overfitting when the noise level is large. When the noise level is small, it does not considerably reduce the overfitting problem.      
### 11.Convolution Neural Networks for Semantic Segmentation: Application to Small Datasets of Biomedical Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.01747.pdf)
>  This thesis studies how the segmentation results, produced by convolutional neural networks (CNN), is different from each other when applied to small biomedical datasets. We use different architectures, parameters and hyper-parameters, trying to find out the better configurations for our task, and trying to find out underlying regularities. Two working datasets are from biomedical area of research. We conducted a lot of experiments with the two types of networks and the received results have shown the preference of some conditions of experiments and parameters of the networks over the others. All testing results are given in the tables and some selected resulting graphs and segmentation predictions are shown for better illustration.      
### 12.Blind multi-frame deconvolution for the correction of space-variant blur in images  [ :arrow_down: ](https://arxiv.org/pdf/2011.01738.pdf)
>  This paper demonstrates a practical method that can correct spatial varying blur from a set of images of the same object. The algorithm jointly estimates the object and local point spread functions~(PSF). The method prioritizes sections with small spatial variation in the PSF for deconvolution. This novel approach can handle large translations in the local PSFs, hence the algorithm is able to correct for morph in the images. Robustness to noise is demonstrated in numerical simulations. Numerical experiments are conducted where the performance of the algorithm is compared to a state-of-the-art method found in literature. The algorithm can be used in situation with space-temporal variation of the PSF and can be applied in situations where the signal-to-noise ratio is low.      
### 13.DNN-based mask estimation for distributed speech enhancement in spatially unconstrained microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2011.01714.pdf)
>  Deep neural network (DNN)-based speech enhancement algorithms in microphone arrays have now proven to be efficient solutions to speech understanding and speech recognition in noisy environments. However, in the context of ad-hoc microphone arrays, many challenges remain and raise the need for distributed processing. In this paper, we propose to extend a previously introduced distributed DNN-based time-frequency mask estimation scheme that can efficiently use spatial information in form of so-called compressed signals which are pre-filtered target estimations. We study the performance of this algorithm under realistic acoustic conditions and investigate practical aspects of its optimal application. We show that the nodes in the microphone array cooperate by taking profit of their spatial coverage in the room. We also propose to use the compressed signals not only to convey the target estimation but also the noise estimation in order to exploit the acoustic diversity recorded throughout the microphone array.      
### 14.A Study of Incorporating Articulatory Movement Information in Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2011.01691.pdf)
>  Although deep-learning algorithms have made great advances on speech enhancement (SE), SE performance is still limited against highly challenging conditions, such as unseen noise types or very low signal-to-noise ratios (SNRs). Given that the mechanisms of vocal articulation are robust or even unaffected by changes in the auditory environment, we propose a novel multimodal audio-articulatory-movement SE model (AAMSE) to improve performance in such challenging conditions. We combine articulatory movement features and audio data for both waveform-mapping-based and spectral-mapping-based SE systems with three fusion strategies. Experimental results confirm that by combining the modalities, AAMSE notably improves the SE performance in both speech quality and intelligibility compared to the audio-only SE baselines. Furthermore, AAMSE shows robust results under very low SNRs and unseen noise type conditions.      
### 15.Improved End-to-End Dysarthric Speech Recognition via Meta-learning Based Model Re-initialization  [ :arrow_down: ](https://arxiv.org/pdf/2011.01686.pdf)
>  Dysarthric speech recognition is a challenging task as dysarthric data is limited and its acoustics deviate significantly from normal speech. Model-based speaker adaptation is a promising method by using the limited dysarthric speech to fine-tune a base model that has been pre-trained from large amounts of normal speech to obtain speaker-dependent models. However, statistic distribution mismatches between the normal and dysarthric speech data limit the adaptation performance of the base model. To address this problem, we propose to re-initialize the base model via meta-learning to obtain a better model initialization. Specifically, we focus on end-to-end models and extend the model-agnostic meta learning (MAML) and Reptile algorithms to meta update the base model by repeatedly simulating adaptation to different dysarthric speakers. As a result, the re-initialized model acquires dysarthric speech knowledge and learns how to perform fast adaptation to unseen dysarthric speakers with improved performance. Experimental results on UASpeech dataset show that the best model with proposed methods achieves 54.2% and 7.6% relative word error rate reduction compared with the base model without finetuning and the model directly fine-tuned from the base model, respectively, and it is comparable with the state-of-the-art hybrid DNN-HMM model.      
### 16.Explicit Prosodic Modelling and Deep Speaker Embedding Learning for Non-standard Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2011.01678.pdf)
>  Though significant progress has been made for the voice conversion (VC) of standard speech, VC for non-standard speech, e.g., dysarthric and second-language (L2) speech, remains a challenge, since it involves correcting for atypical prosody while maintaining speaker identity. To address this issue, we propose a VC system with explicit prosody modelling and deep speaker embedding (DSE) learning. First, a speech-encoder strives to extract robust phoneme embeddings from non-standard speech. Second, a prosody corrector takes in phoneme embeddings to infer standard phoneme duration and pitch values. Third, a conversion model takes phoneme embeddings and standard prosody features as inputs to generate the converted speech, conditioned on the target DSE that is learned via speaker encoder or speaker adaptation. Extensive experiments demonstrate that speaker encoder based conversion model can significantly reduce dysarthric and non-native pronunciation patterns to generate near-normal and near-native speech respectively, and speaker adaptation can achieve higher speaker similarity.      
### 17.Generalized Wasserstein Dice Score, Distributionally Robust Deep Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge  [ :arrow_down: ](https://arxiv.org/pdf/2011.01614.pdf)
>  Training a deep neural network is an optimization problem with four main ingredients: the design of the deep neural network, the per-sample loss function, the population loss function, and the optimizer. However, methods developed to compete in recent BraTS challenges tend to focus only on the design of deep neural network architectures, while paying less attention to the three other aspects. In this paper, we experimented with adopting the opposite approach. We stuck to a generic and state-of-the-art 3D U-Net architecture and experimented with a non-standard per-sample loss function, the generalized Wasserstein Dice loss, a non-standard population loss function, corresponding to distributionally robust optimization, and a non-standard optimizer, Ranger. Those variations were selected specifically for the problem of multi-class brain tumor segmentation. The generalized Wasserstein Dice loss is a per-sample loss function that allows taking advantage of the hierarchical structure of the tumor regions labeled in BraTS. Distributionally robust optimization is a generalization of empirical risk minimization that accounts for the presence of underrepresented subdomains in the training dataset. Ranger is a generalization of the widely used Adam optimizer that is more stable with small batch size and noisy labels. We found that each of those variations of the optimization of deep neural networks for brain tumor segmentation leads to improvements in terms of Dice scores and Hausdorff distances. With an ensemble of three deep neural networks trained with various optimization procedures, we achieved promising results on the validation dataset of the BraTS 2020 challenge. Our ensemble ranked fourth out of the 693 registered teams for the segmentation task of the BraTS 2020 challenge.      
### 18.An approach to measure route quality and refine the route during the voyage using characteristic coefficients  [ :arrow_down: ](https://arxiv.org/pdf/2011.01607.pdf)
>  The paper presents a method to validate and refine the ship's route during the voyage. The method is based on computing several characteristic coefficients that represent and measure route properties. Thru the analysis of the values of these coefficient, one can analyse the overall route quality and detect possibly dangerous discrepancies between the actual route and the planned route.The paper describes the proposed characteristic coefficients, the process of route refinement and the method for prediction and validation of the route's future changes.      
### 19.Improving RNN transducer with normalized jointer network  [ :arrow_down: ](https://arxiv.org/pdf/2011.01576.pdf)
>  Recurrent neural transducer (RNN-T) is a promising end-to-end (E2E) model in automatic speech recognition (ASR). It has shown superior performance compared to traditional hybrid ASR systems. However, training RNN-T from scratch is still challenging. We observe a huge gradient variance during RNN-T training and suspect it hurts the performance. In this work, we analyze the cause of the huge gradient variance in RNN-T training and proposed a new \textit{normalized jointer network} to overcome it. We also propose to enhance the RNN-T network with a modified conformer encoder network and transformer-XL predictor networks to achieve the best performance. Experiments are conducted on the open 170-hour AISHELL-1 and industrial-level 30000-hour mandarin speech dataset. On the AISHELL-1 dataset, our RNN-T system gets state-of-the-art results on AISHELL-1's streaming and non-streaming benchmark with CER 6.15\% and 5.37\% respectively. We further compare our RNN-T system with our well trained commercial hybrid system on 30000-hour-industry audio data and get 9\% relative improvement without pre-training or external language model.      
### 20.Dynamic latency speech recognition with asynchronous revision  [ :arrow_down: ](https://arxiv.org/pdf/2011.01570.pdf)
>  In this work we propose an inference technique, asynchronous revision, to unify streaming and non-streaming speech recognition models. Specifically, we achieve dynamic latency with only one model by using arbitrary right context during inference. The model is composed of a stack of convolutional layers for audio encoding. In inference stage, the history states of encoder and decoder can be asynchronously revised to trade off between the latency and the accuracy of the model. To alleviate training and inference mismatch, we propose a training technique, segment cropping, which randomly splits input utterances into several segments with forward connections. This allows us to have dynamic latency speech recognition results with large improvements in accuracy. Experiments show that our dynamic latency model with asynchronous revision gives 8\%-14\% relative improvements over the streaming models.      
### 21.Enhanced RSS-based UAV Localization via Trajectory and Multi-base Stations  [ :arrow_down: ](https://arxiv.org/pdf/2011.01558.pdf)
>  To improve the localization precision of unmanned aerial vehicle (UAV), a novel framework is established by jointly utilizing multiple measurements of received signal strength (RSS) from multiple base stations (BSs) and multiple points on trajectory. First, a joint maximum likelihood (ML) of exploiting both trajectory information and multi-BSs is proposed. To reduce its high complexity, two low-complexity localization methods are designed. The first method is from BS to trajectory (BST), called LCSL-BST. First, fixing the nth BS, by exploiting multiple measurements along trajectory, the position of UAV is computed by ML rule. Finally, all computed positions of UAV for different BSs are combined to form the resulting position. The second method reverses the order, called LCSL-TBS. We also derive the Cramer-Rao lower boundary (CRLB) of the joint ML method. From simulation results, we can see that the proposed joint ML and separate LCSL-BST methods have made a significant improvement over conventional ML method without use of trajectory knowledge in terms of location performance. The former achieves the joint CRLB and the latter is of low-complexity.      
### 22.StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with Temporal Adaptive Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2011.01557.pdf)
>  In recent years, neural vocoders have surpassed classical speech generation approaches in naturalness and perceptual quality of the synthesized speech. Computationally heavy models like WaveNet and WaveGlow achieve best results, while lightweight GAN models, e.g. MelGAN and Parallel WaveGAN, remain inferior in terms of perceptual quality. We therefore propose StyleMelGAN, a lightweight neural vocoder allowing synthesis of high-fidelity speech with low computational complexity. StyleMelGAN employs temporal adaptive normalization to style a low-dimensional noise vector with the acoustic features of the target speech. For efficient training, multiple random-window discriminators adversarially evaluate the speech signal analyzed by a filter bank, with regularization provided by a multi-scale spectral reconstruction loss. The highly parallelizable speech generation is several times faster than real-time on CPUs and GPUs. MUSHRA and P.800 listening tests show that StyleMelGAN outperforms prior neural vocoders in copy-synthesis and Text-to-Speech scenarios.      
### 23.A note on the existence of stabilizing switching signals for switched linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.01530.pdf)
>  This paper deals with stability of discrete-time switched linear systems whose all subsystems are unstable. We present sufficient conditions on the subsystems matrices such that a switched system is globally exponentially stable under a set of purely time-dependent switching signals that are allowed to activate all subsystems. The main apparatuses for our analysis are (matrix) commutation relations between certain products of the subsystems matrices and graph-theoretic arguments. We present a numerical experiment to demonstrate our results.      
### 24.Higher-Order Moment-Based Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2011.01522.pdf)
>  The identification of anomalies is a critical component of operating complex, and possibly large-scale and geo-graphically distributed cyber-physical systems. While designing anomaly detectors, it is common to assume Gaussian noise models to maintain tractability; however, this assumption can lead to the actual false alarm rate being significantly higher than expected. Here we design a distributionally robust threshold of detection using finite and fixed higher-order moments of the residual data such that it guarantees the actual false alarm rate to be upper bounded by the desired one. Further, we bound the states reachable through the action of a stealthy attack and identify the trade-off between this impact of attacks that cannot be detected and the worst-case false alarm rate. Through numerical experiments, we illustrate how knowledge of higher-order moments results in a tightened threshold, thereby restricting an attacker's potential impact.      
### 25.Time regularization as a solution to mitigate quantization induced performance degradation  [ :arrow_down: ](https://arxiv.org/pdf/2011.01520.pdf)
>  Reset control is known to be able to outperform PID and the like linear controllers. However, in motion control systems, quantization can cause severe performance degradation. This paper shows the application of time regularization to mitigate this practical issue in reset control systems. Numerical simulations have been conducted in order to analyze the cause of the quantization induced performance degradation and the effectiveness of time regularization to mitigate this degradation; with tuning guidelines for the time regularization parameter also provided. Moreover, a robustness analysis is performed. The solution is also tested experimentally on a high precision motion system for validation. It is estimated by numerical simulations that time regularization can reduce quantization induced performance degradation by almost 10 dB. Experiments have similarly shown a reduction of several dB for the high precision motion stage.      
### 26.Energy Efficient Pairing and Power Optimization for NOMA UAV Network under QoS Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2011.01449.pdf)
>  Due to an increasing number of unmanned aerial vehicles (UAVs) with generally limited battery power, energy efficient data transmission schemes with massive connectivity capabilities are required for future wireless networks. Non-orthogonal multiple access (NOMA) is one of the promising techniques that provide such massive connectivity by allowing superposed data transmission of multiple users over the same resource block. Unlike existing literature, this paper presents a user pairing and power allocation technique for energy efficient and quality of service (QoS) aware NOMA transmission for cellular-connected mobile UAVs. The aim is to minimize the power consumption of the mobile UAVs during uplink data transmission and guarantee their required transmission rate by jointly optimizing the UAV pairing and power allocation. Furthermore, the performance and pairing complexity for mobile UAVs is analyzed to show that the proposed pairing technique efficiently fulfills their QoS requirements. Numerical and simulation results show the performance gain of the proposed technique compared to the conventional NOMA techniques.      
### 27.Learning-based Load Balancing Handover in Mobile Millimeter Wave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.01420.pdf)
>  Millimeter-wave (mmWave) communication is a promising solution to the high data rate demands in the upcoming 5G and beyond communication networks. When it comes to supporting seamless connectivity in mobile scenarios, resource and handover management are two of the main challenges in mmWave networks. In this paper, we address these two problems jointly and propose a learning-based load balancing handover in multi-user mobile mmWave networks. Our handover algorithm selects a backup base station and allocates the resource to maximize the sum rate of all the users while ensuring a target rate threshold and preventing excessive handovers. We model the user association as a non-convex optimization problem. Then, by applying a deep deterministic policy gradient (DDPG) method, we approximate the solution of the optimization problem. Through simulations, we show that our proposed algorithm minimizes the number of the events where a user's rate is less than its minimum rate requirement and minimizes the number of handovers while increasing the sum rate of all users.      
### 28.Foveated Model Observers for Visual Search in 3D Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2011.01405.pdf)
>  Model observers have a long history of success in predicting human observer performance in clinically-relevant detection tasks. New 3D image modalities provide more signal information but vastly increase the search space to be scrutinized. Here, we compared standard linear model observers (ideal observers, non-pre-whitening matched filter with eye filter, and various versions of Channelized Hotelling models) to human performance searching in 3D 1/f$^{2.8}$ filtered noise images and assessed its relationship to the more traditional location known exactly detection tasks and 2D search. We investigated two different signal types that vary in their detectability away from the point of fixation (visual periphery). We show that the influence of 3D search on human performance interacts with the signal's detectability in the visual periphery. Detection performance for signals difficult to detect in the visual periphery deteriorates greatly in 3D search but not in 3D location known exactly and 2D search. Standard model observers do not predict the interaction between 3D search and signal type. A proposed extension of the Channelized Hotelling model (foveated search model) that processes the image with reduced spatial detail away from the point of fixation, explores the image through eye movements, and scrolls across slices can successfully predict the interaction observed in humans and also the types of errors in 3D search. Together, the findings highlight the need for foveated model observers for image quality evaluation with 3D search.      
### 29.Centre of pressure estimation during walking using only inertial-measurement units and end-to-end statistical modelling  [ :arrow_down: ](https://arxiv.org/pdf/2011.01303.pdf)
>  Estimation of the centre of pressure (COP) is an important part of the gait analysis, for example, when evaluating the functional capacity of individuals affected by motor impairment. Inertial measurement units (IMUs) and force sensors are commonly used to measure gait characteristic of healthy and impaired subjects. We present a methodology for estimating the COP solely from raw gyroscope, accelerometer, and magnetometer data from IMUs using statistical modelling. We demonstrate the viability of the method using an example of two models: a linear model and a non-linear Long-Short-Term Memory (LSTM) neural network model. Models were trained on the COP ground truth data measured using an instrumented treadmill and achieved the average intra-subject root mean square (RMS) error between estimated and ground truth COP of 12.3mm and the average inter-subject RMS error of 23.7mm which is comparable or better than similar studies so far. We show that the calibration procedure in the instrumented treadmill can be as short as a couple of minutes without the decrease in our model performance. We also show that the magnetic component of the recorded IMU signal, which is most sensitive to environmental changes, can be safely dropped without a significant decrease in model performance. Finally, we show that the number of IMUs can be reduced to five without deterioration in the model performance.      
### 30.Precoding for Satellite Communications: Why, How and What next?  [ :arrow_down: ](https://arxiv.org/pdf/2011.01293.pdf)
>  Precoding has stood out as a promising multi-user transmission technique to meet the emerging throughput demand of satellite communication systems while awaiting the technological maturity for exploiting higher bands. Precoding enables the reduction of interference among co-channel beams through spatial processing while promoting aggressive frequency reuse and improving spectral efficiency. Satellite systems offer multitude of system and service configurations, resulting in different precoder design methodologies. This article explores the motivation for the introduction of precoding, offers an insight to their theoretical development in a diverse scenarios and presents some avenues for future development.      
### 31.A Feasibility Governor for Enlarging the Region of Attraction of Linear Model Predictive Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2011.01924.pdf)
>  This paper proposes a method for enlarging the region of attraction of Linear Model Predictive Controllers (MPC) when tracking piecewise-constant references in the presence of pointwise-in-time constraints. It consists of an add-on unit, the Feasibility Governor (FG), that manipulates the reference command so as to ensure that the optimal control problem that underlies the MPC feedback law remains feasible. Offline polyhedral projection algorithms based on multi-objective linear programming are employed to compute the set of feasible states and reference commands. Online, the action of the FG is computed by solving a convex quadratic program. The closed-loop system is shown to satisfy constraints, be asymptotically stable, exhibit zero-offset tracking, and display finite-time convergence of the reference.      
### 32.Gradient Coding with Dynamic Clustering for Straggler Mitigation  [ :arrow_down: ](https://arxiv.org/pdf/2011.01922.pdf)
>  In distributed synchronous gradient descent (GD) the main performance bottleneck for the per-iteration completion time is the slowest \textit{straggling} workers. To speed up GD iterations in the presence of stragglers, coded distributed computation techniques are implemented by assigning redundant computations to workers. In this paper, we propose a novel gradient coding (GC) scheme that utilizes dynamic clustering, denoted by GC-DC, to speed up the gradient calculation. Under time-correlated straggling behavior, GC-DC aims at regulating the number of straggling workers in each cluster based on the straggler behavior in the previous iteration. We numerically show that GC-DC provides significant improvements in the average completion time (of each iteration) with no increase in the communication load compared to the original GC scheme.      
### 33.Policy Transfer via Kinematic Domain Randomization and Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2011.01891.pdf)
>  Transferring reinforcement learning policies trained in physics simulation to the real hardware remains a challenge, known as the "sim-to-real" gap. Domain randomization is a simple yet effective technique to address dynamics discrepancies across source and target domains, but its success generally depends on heuristics and trial-and-error. In this work we investigate the impact of randomized parameter selection on policy transferability across different types of domain discrepancies. Contrary to common practice in which kinematic parameters are carefully measured while dynamic parameters are randomized, we found that virtually randomizing kinematic parameters (e.g., link lengths) during training in simulation generally outperforms dynamic randomization. Based on this finding, we introduce a new domain adaptation algorithm that utilizes simulated kinematic parameters variation. Our algorithm, Multi-Policy Bayesian Optimization, trains an ensemble of universal policies conditioned on virtual kinematic parameters and efficiently adapts to the target environment using a limited number of target domain rollouts. We showcase our findings on a simulated quadruped robot in five different target environments covering different aspects of domain discrepancies.      
### 34.Learning unbiased registration and joint segmentation: evaluation on longitudinal diffusion MRI  [ :arrow_down: ](https://arxiv.org/pdf/2011.01869.pdf)
>  Analysis of longitudinal changes in imaging studies often involves both segmentation of structures of interest and registration of multiple timeframes. The accuracy of such analysis could benefit from a tailored framework that jointly optimizes both tasks to fully exploit the information available in the longitudinal data. Most learning-based registration algorithms, including joint optimization approaches, currently suffer from bias due to selection of a fixed reference frame and only support pairwise transformations. We here propose an analytical framework based on an unbiased learning strategy for group-wise registration that simultaneously registers images to the mean space of a group to obtain consistent segmentations. We evaluate the proposed method on longitudinal analysis of a white matter tract in a brain MRI dataset with 2-3 time-points for 3249 individuals, i.e., 8045 images in total. The reproducibility of the method is evaluated on test-retest data from 97 individuals. The results confirm that the implicit reference image is an average of the input image. In addition, the proposed framework leads to consistent segmentations and significantly lower processing bias than that of a pair-wise fixed-reference approach. This processing bias is even smaller than those obtained when translating segmentations by only one voxel, which can be attributed to subtle numerical instabilities and interpolation. Therefore, we postulate that the proposed mean-space learning strategy could be widely applied to learning-based registration tasks. In addition, this group-wise framework introduces a novel way for learning-based longitudinal studies by direct construction of an unbiased within-subject template and allowing reliable and efficient analysis of spatio-temporal imaging biomarkers.      
### 35.Nonlinear Two-Time-Scale Stochastic Approximation: Convergence and Finite-Time Performance  [ :arrow_down: ](https://arxiv.org/pdf/2011.01868.pdf)
>  Two-time-scale stochastic approximation, a generalized version of the popular stochastic approximation, has found broad applications in many areas including stochastic control, optimization, and machine learning. Despite of its popularity, theoretical guarantees of this method, especially its finite-time performance, are mostly achieved for the linear case while the results for the nonlinear counterpart are very sparse. Motivated by the classic control theory for singularly perturbed systems, we study in this paper the asymptotic convergence and finite-time analysis of the nonlinear two-time-scale stochastic approximation. Under some fairly standard assumptions, we provide a formula that characterizes the rate of convergence of the main iterates to the desired solutions. In particular, we show that the method achieves a convergence in expectation at a rate $\mathcal{O}(1/k^{2/3})$, where $k$ is the number of iterations. The key idea in our analysis is to properly choose the two step sizes to characterize the coupling between the fast and slow-time-scale iterates.      
### 36.Federated LQR: Learning through Sharing  [ :arrow_down: ](https://arxiv.org/pdf/2011.01815.pdf)
>  In many multi-agent reinforcement learning applications such as flocking, multi-robot applications and smart manufacturing, distinct agents share similar dynamics but face different objectives. In these applications, an important question is how the similarities amongst the agents can accelerate learning in spite of the agents' differing goals. We study a distributed LQR (Linear Quadratic Regulator) tracking problem which models this setting, where the agents, acting independently, share identical (unknown) dynamics and cost structure but need to track different targets. In this paper, we propose a communication-efficient, federated model-free zeroth-order algorithm that provably achieves a convergence speedup linear in the number of agents compared with the communication-free setup where each agent's problem is treated independently. We support our arguments with numerical simulations of both linear and nonlinear systems.      
### 37.Problems using deep generative models for probabilistic audio source separation  [ :arrow_down: ](https://arxiv.org/pdf/2011.01761.pdf)
>  Recent advancements in deep generative modeling make it possible to learn prior distributions from complex data that subsequently can be used for Bayesian inference. However, we find that distributions learned by deep generative models for audio signals do not exhibit the right properties that are necessary for tasks like audio source separation using a probabilistic approach. We observe that the learned prior distributions are either discriminative and extremely peaked or smooth and non-discriminative. We quantify this behavior for two types of deep generative models on two audio datasets.      
### 38.Small footprint Text-Independent Speaker Verification for Embedded Systems  [ :arrow_down: ](https://arxiv.org/pdf/2011.01709.pdf)
>  Deep neural network approaches to speaker verification have proven successful, but typical computational requirements of State-Of-The-Art (SOTA) systems make them unsuited for embedded applications. In this work, we present a two-stage model architecture orders of magnitude smaller than common solutions (237.5K learning parameters, 11.5MFLOPS) reaching a competitive result of 3.31% Equal Error Rate (EER) on the well established VoxCeleb1 verification test set. We demonstrate the possibility of running our solution on small devices typical of IoT systems such as the Raspberry Pi 3B with a latency smaller than 200ms on a 5s long utterance. Additionally, we evaluate our model on the acoustically challenging VOiCES corpus. We report a limited increase in EER of 2.6 percentage points with respect to the best scoring model of the 2019 VOiCES from a Distance Challenge, against a reduction of 25.6 times in the number of learning parameters.      
### 39.Vision-Based Control for Robots by a Fully Spiking Neural System Relying on Cerebellar Predictive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2011.01641.pdf)
>  The cerebellum plays a distinctive role within our motor control system to achieve fine and coordinated motions. While cerebellar lesions do not lead to a complete loss of motor functions, both action and perception are severally impacted. Hence, it is assumed that the cerebellum uses an internal forward model to provide anticipatory signals by learning from the error in sensory states. In some studies, it was demonstrated that the learning process relies on the joint-space error. However, this may not exist. This work proposes a novel fully spiking neural system that relies on a forward predictive learning by means of a cellular cerebellar model. The forward model is learnt thanks to the sensory feedback in task-space and it acts as a Smith predictor. The latter predicts sensory corrections in input to a differential mapping spiking neural network during a visual servoing task of a robot arm manipulator. In this paper, we promote the developed control system to achieve more accurate target reaching actions and reduce the motion execution time for the robotic reaching tasks thanks to the cerebellar predictive capabilities.      
### 40.Two Heads Are Better Than One: A Two-Stage Approach for Monaural Noise Reduction in the Complex Domain  [ :arrow_down: ](https://arxiv.org/pdf/2011.01561.pdf)
>  In low signal-to-noise ratio conditions, it is difficult to effectively recover the magnitude and phase information simultaneously. To address this problem, this paper proposes a two-stage algorithm to decouple the joint optimization problem w.r.t. magnitude and phase into two sub-tasks. In the first stage, only magnitude is optimized, which incorporates noisy phase to obtain a coarse complex clean speech spectrum estimation. In the second stage, both the magnitude and phase components are refined. The experiments are conducted on the WSJ0-SI84 corpus, and the results show that the proposed approach significantly outperforms previous baselines in terms of PESQ, ESTOI, and SDR.      
### 41.Penetrating RF Fingerprinting-based Authentication with a Generative Adversarial Attack  [ :arrow_down: ](https://arxiv.org/pdf/2011.01538.pdf)
>  Physical layer authentication relies on detecting unique imperfections in signals transmitted by radio devices to isolate their fingerprint. Recently, deep learning-based authenticators have increasingly been proposed to classify devices using these fingerprints, as they achieve higher accuracies compared to traditional approaches. However, it has been shown in other domains that adding carefully crafted perturbations to legitimate inputs can fool such classifiers. This can undermine the security provided by the authenticator. Unlike adversarial attacks applied in other domains, an adversary has no control over the propagation environment. Therefore, to investigate the severity of this type of attack in wireless communications, we consider an unauthorized transmitter attempting to have its signals classified as authorized by a deep learning-based authenticator. We demonstrate a reinforcement learning-based attack where the impersonator--using only the authenticator's binary authentication decision--distorts its signals in order to penetrate the system. Extensive simulations and experiments on a software-defined radio testbed indicate that at appropriate channel conditions and bounded by a maximum distortion level, it is possible to fool the authenticator reliably at more than 90% success rate.      
### 42.ShaneRun System Description to VoxCeleb Speaker Recognition Challenge 2020  [ :arrow_down: ](https://arxiv.org/pdf/2011.01518.pdf)
>  In this report, we describe the submission of ShaneRun's team to the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020. We use ResNet-34 as encoder to extract the speaker embeddings, which is referenced from the open-source voxceleb-trainer. We also provide a simple method to implement optimum fusion using t-SNE normalized distance of testing utterance pairs instead of original negative Euclidean distance from the encoder. The final submitted system got 0.3098 minDCF and 5.076 % ERR for Fixed data track, which outperformed the baseline by 1.3 % minDCF and 2.2 % ERR respectively.      
### 43.Training Wake Word Detection with Synthesized Speech Data on Confusion Words  [ :arrow_down: ](https://arxiv.org/pdf/2011.01460.pdf)
>  Confusing-words are commonly encountered in real-life keyword spotting applications, which causes severe degradation of performance due to complex spoken terms and various kinds of words that sound similar to the predefined keywords. To enhance the wake word detection system's robustness on such scenarios, we investigate two data augmentation setups for training end-to-end KWS systems. One is involving the synthesized data from a multi-speaker speech synthesis system, and the other augmentation is performed by adding random noise to the acoustic feature. Experimental results show that augmentations help improve the system's robustness. Moreover, by augmenting the training set with the synthetic data generated by the multi-speaker text-to-speech system, we achieve a significant improvement regarding confusing words scenario.      
### 44.A Two-Stage Approach to Device-Robust Acoustic Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2011.01447.pdf)
>  To improve device robustness, a highly desirable key feature of a competitive data-driven acoustic scene classification (ASC) system, a novel two-stage system based on fully convolutional neural networks (CNNs) is proposed. Our two-stage system leverages on an ad-hoc score combination based on two CNN classifiers: (i) the first CNN classifies acoustic inputs into one of three broad classes, and (ii) the second CNN classifies the same inputs into one of ten finer-grained classes. Three different CNN architectures are explored to implement the two-stage classifiers, and a frequency sub-sampling scheme is investigated. Moreover, novel data augmentation schemes for ASC are also investigated. Evaluated on DCASE 2020 Task 1a, our results show that the proposed ASC system attains a state-of-the-art accuracy on the development set, where our best system, a two-stage fusion of CNN ensembles, delivers a 81.9% average accuracy among multi-device test data, and it obtains a significant improvement on unseen devices. Finally, neural saliency analysis with class activation mapping (CAM) gives new insights on the patterns learnt by our models.      
### 45.Developing High Quality Training Samples for Deep Learning Based Local Climate Classification in Korea  [ :arrow_down: ](https://arxiv.org/pdf/2011.01436.pdf)
>  Two out of three people will be living in urban areas by 2050, as projected by the United Nations, emphasizing the need for sustainable urban development and monitoring. Common urban footprint data provide high-resolution city extents but lack essential information on the distribution, pattern, and characteristics. The Local Climate Zone (LCZ) offers an efficient and standardized framework that can delineate the internal structure and characteristics of urban areas. Global-scale LCZ mapping has been explored, but are limited by low accuracy, variable labeling quality, or domain adaptation challenges. Instead, this study developed a custom LCZ data to map key Korean cities using a multi-scale convolutional neural network. Results demonstrated that using a novel, custom LCZ data with deep learning can generate more accurate LCZ map results compared to conventional community-based LCZ mapping with machine learning as well as transfer learning of the global So2Sat dataset.      
### 46.GAGE: Geometry Preserving Attributed Graph Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2011.01422.pdf)
>  Node representation learning is the task of extracting concise and informative feature embeddings of certain entities that are connected in a network. Many real world network datasets include information about both node connectivity and certain node attributes, in the form of features or time-series data. Modern representation learning techniques utilize both connectivity and attribute information of the nodes to produce embeddings in an unsupervised manner. In this context, deriving embeddings that preserve the geometry of the network and the attribute vectors would be highly desirable, as they would reflect both the topological neighborhood structure and proximity in feature space. While this is fairly straightforward to maintain when only observing the connectivity or attributed information of the network, preserving the geometry of both types of information is challenging. A novel tensor factorization approach for node embedding in attributed networks that preserves the distances of both the connections and the attributes is proposed in this paper, along with an effective and lightweight algorithm to tackle the learning task. Judicious experiments with multiple state-of-art baselines suggest that the proposed algorithm offers significant performance improvements in node classification and link prediction tasks.      
### 47.Sampling and Recovery of Graph Signals based on Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2011.01412.pdf)
>  We propose interpretable graph neural networks for sampling and recovery of graph signals, respectively. To take informative measurements, we propose a new graph neural sampling module, which aims to select those vertices that maximally express their corresponding neighborhoods. Such expressiveness can be quantified by the mutual information between vertices' features and neighborhoods' features, which are estimated via a graph neural network. To reconstruct an original graph signal from the sampled measurements, we propose a graph neural recovery module based on the algorithm-unrolling technique. Compared to previous analytical sampling and recovery, the proposed methods are able to flexibly learn a variety of graph signal models from data by leveraging the learning ability of neural networks; compared to previous neural-network-based sampling and recovery, the proposed methods are designed through exploiting specific graph properties and provide interpretability. We further design a new multiscale graph neural network, which is a trainable multiscale graph filter bank and can handle various graph-related learning tasks. The multiscale network leverages the proposed graph neural sampling and recovery modules to achieve multiscale representations of a graph. In the experiments, we illustrate the effects of the proposed graph neural sampling and recovery modules and find that the modules can flexibly adapt to various graph structures and graph signals. In the task of active-sampling-based semi-supervised learning, the graph neural sampling module improves the classification accuracy over 10% in Cora dataset. We further validate the proposed multiscale graph neural network on several standard datasets for both vertex and graph classification. The results show that our method consistently improves the classification accuracies.      
### 48.Hybrid Visual Servoing Tracking Control of Uncalibrated Robotic Systems for Dynamic Dwarf Culture Orchards Harvest  [ :arrow_down: ](https://arxiv.org/pdf/2011.01408.pdf)
>  The paper is concerned with the dynamic tracking problem of SNAP orchards harvesting robots in the presence of multiple uncalibrated model parameters in the application of dwarf culture orchards harvest. A new hybrid visual servoing adaptive tracking controller and three adaptive laws are proposed to guarantee harvesting robots to finish the dynamic harvesting task and the adaption to unknown parameters including camera intrinsic and extrinsic model and robot dynamics. By the Lyapunov theory, asymptotic convergence of the closed-loop system with the proposed control scheme is rigorously proven. Experimental and simulation results have been conducted to verify the performance of the proposed control scheme. The results demonstrate its effectiveness and superiority.      
### 49.Data-Driven Control of the COVID-19 Outbreak via Non-Pharmaceutical Interventions: A Geometric Programming Approach  [ :arrow_down: ](https://arxiv.org/pdf/2011.01392.pdf)
>  In this paper we propose a data-driven model for the spread of SARS-CoV-2 and use it to design optimal control strategies of human-mobility restrictions that both curb the epidemic and minimize the economic costs associated with implementing non-pharmaceutical interventions. We develop an extension of the SEIR epidemic model that captures the effects of changes in human mobility on the spread of the disease. The parameters of our data-driven model are learned using a multitask learning approach that leverages both data on the number of deaths across a set of regions, and cellphone data on individuals' mobility patterns specific to each region. We propose an optimal control problem on this data-driven model with a tractable solution provided by geometric programming. The result of this framework is a mobility-based intervention strategy that curbs the spread of the epidemic while obeying a budget on the economic cost incurred. Furthermore, in the absence of a straightforward mapping from human mobility data to economic costs, we propose a practical method by which a budget on economic losses incurred may be chosen to eliminate excess deaths due to over-utilization of hospital resources. Our results are demonstrated with numerical simulations using real data from the Philadelphia metropolitan area.      
### 50.Exact Asymptotics for Linear Quadratic Adaptive Control  [ :arrow_down: ](https://arxiv.org/pdf/2011.01364.pdf)
>  Recent progress in reinforcement learning has led to remarkable performance in a range of applications, but its deployment in high-stakes settings remains quite rare. One reason is a limited understanding of the behavior of reinforcement algorithms, both in terms of their regret and their ability to learn the underlying system dynamics---existing work is focused almost exclusively on characterizing rates, with little attention paid to the constants multiplying those rates that can be critically important in practice. To start to address this challenge, we study perhaps the simplest non-bandit reinforcement learning problem: linear quadratic adaptive control (LQAC). By carefully combining recent finite-sample performance bounds for the LQAC problem with a particular (less-recent) martingale central limit theorem, we are able to derive asymptotically-exact expressions for the regret, estimation error, and prediction error of a rate-optimal stepwise-updating LQAC algorithm. In simulations on both stable and unstable systems, we find that our asymptotic theory also describes the algorithm's finite-sample behavior remarkably well.      
### 51.The study of calibration for the hybrid pixel detector with single photon counting in HEPS-BPIX  [ :arrow_down: ](https://arxiv.org/pdf/2011.01342.pdf)
>  The calibration process for the hybrid array pixel detector designed for High Energy Photon Source in China, we called HEPS-BPIX, is presented in this paper. Based on the threshold scanning, the relationship between energy and threshold is quantified for the threshold calibration. For the threshold trimming, the precise algorithm basing on LDAC characteristic and fast algorithm basing on LDAC scanning are proposed in this paper to study the performance of the threshold DACs which will be applied to the pixel. The threshold dispersion has been reduced from 46.28 mV without algorithm to 6.78 mV with the precise algorithm, whereas it is 7.61 mV with fast algorithm. For the temperature from 5 to 60 , the threshold dispersion of precise algorithm varies in the range of about 5.69 mV, whereas it is about 33.21 mV with the fast algorithm which can be re-corrected to 1.49 mV. The measurement results show that the fast algorithm could get the applicable threshold dispersion for a silicon pixel module and take a shorter time, while the precise algorithm could get better threshold dispersion, but time consuming. The temperature dependence of the silicon pixel module noise is also studied to assess the detector working status. The minimum detection energy can be reduced about 0.83 keV at a 20 lower temperature.      
### 52.New Results for Pearson Type III Family of Distributions and Application in Wireless Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2011.01332.pdf)
>  Pearson and log Pearson type III distributions have been considered in several scientific fields, as in hydrology and seismology. In this paper, we present new results for these distributions and we utilize them, for first time in the literature, to investigate the statistical behavior of wireless power transfer (WPT), assuming that the harvested energy follows a well-established nonlinear energy harvesting model based on the logistic function. Specifically, we present new closed-form expressions for the statistical properties of a general form of Pearson and log Pearson type III distributions and we utilize them to introduce a new member of the Pearson type III family, the logit Pearson type III distribution, through which the logit gamma distribution is also defined. Moreover, we derive closed-form expressions for the probability density function, the cumulative distribution function and moments of the distributions of the sum, the log sum and the logit sum of Pearson type III random variables. Furthermore, taking into account that Pearson type III family of distributions is closely related to the considered nonlinear harvesting model the statistical properties of the distribution of the harvested power and derived, for both single input single output and multiple input single output scenarios.      
### 53.A Lane-Changing Prediction Method Based on Temporal Convolution Network  [ :arrow_down: ](https://arxiv.org/pdf/2011.01224.pdf)
>  Lane-changing is an important driving behavior and unreasonable lane changes can result in potentially dangerous traffic collisions. Advanced Driver Assistance System (ADAS) can assist drivers to change lanes safely and efficiently. To capture the stochastic time series of lane-changing behavior, this study proposes a temporal convolutional network (TCN) to predict the long-term lane-changing trajectory and behavior. In addition, the convolutional neural network (CNN) and recurrent neural network (RNN) methods are considered as the benchmark models to demonstrate the learning ability of the TCN. The lane-changing dataset was collected by the driving simulator. The prediction performance of TCN is demonstrated from three aspects: different input variables, different input dimensions and different driving scenarios. Prediction results show that the TCN can accurately predict the long-term lane-changing trajectory and driving behavior with shorter computational time compared with two benchmark models. The TCN can provide accurate lane-changing prediction, which is one key information for the development of accurate ADAS.      
### 54.A Low-Power Time-to-Digital Converter for the CMS Endcap Timing Layer (ETL) Upgrade  [ :arrow_down: ](https://arxiv.org/pdf/2011.01222.pdf)
>  We present the design and test results of a Time-to-Digital-Converter (TDC). The TDC will be a part of the readout ASIC, called ETROC, to read out Low-Gain Avalanche Detectors (LGADs) for the CMS Endcap Timing Layer (ETL) of High-Luminosity LHC upgrade. One of the challenges of the ETROC design is that the TDC is required to consume less than 200 W for each pixel at the nominal hit occupancy of 1%. To meet the low-power requirement, we use a single delay line for both the Time of Arrival (TOA) and the Time over Threshold (TOT) measurements without delay control. A double-strobe self-calibration scheme is used to compensate for process variation, temperature, and power supply voltage. The TDC is fabricated in a 65 nm CMOS technology. The overall performances of the TDC have been evaluated. The TOA has a bin size of 17.8 ps within its effective dynamic range of 11.6 ns. The effective measurement precision of the TOA is 5.6 ps and 9.9 ps with and without the nonlinearity correction, respectively. The TDC block consumes 97 W at the hit occupancy of 1%. Over a temperature range from 23 C to 78 C and a power supply voltage range from 1.05 V to 1.35 V (the nominal value of 1.20 V), the self-calibrated bin size of the TOA varies within 0.4%. The measured TDC performances meet the requirements except that more tests will be performed in the future to verify that the TDC complies with the radiation-tolerance specifications.      
### 55.Signal Clustering with Class-independent Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/1911.07590.pdf)
>  Radar signals have been dramatically increasing in complexity, limiting the source separation ability of traditional approaches. In this paper we propose a Deep Learning-based clustering method, which encodes concurrent signals into images, and, for the first time, tackles clustering with image segmentation. Novel loss functions are introduced to optimize a Neural Network to separate the input pulses into pure and non-fragmented clusters. Outperforming a variety of baselines, the proposed approach is capable of clustering inputs directly with a Neural Network, in an end-to-end fashion.      

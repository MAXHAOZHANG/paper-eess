# ArXiv eess --Tue, 16 Mar 2021
### 1.Which K-Space Sampling Schemes is good for Motion Artifact Detection in Magnetic Resonance Imaging?  [ :arrow_down: ](https://arxiv.org/pdf/2103.08516.pdf)
>  Motion artifacts are a common occurrence in the Magnetic Resonance Imaging (MRI) exam. Motion during acquisition has a profound impact on workflow efficiency, often requiring a repeat of sequences. Furthermore, motion artifacts may escape notice by technologists, only to be revealed at the time of reading by the radiologists, affecting their diagnostic quality. Designing a computer-aided tool for automatic motion detection and elimination can improve the diagnosis, however, it needs a deep understanding of motion characteristics. Motion artifacts in MRI have a complex nature and it is directly related to the k-space sampling scheme. In this study we investigate the effect of three conventional k-space samplers, including Cartesian, Uniform Spiral and Radial on motion induced image distortion. In this regard, various synthetic motions with different trajectories of displacement and rotation are applied to T1 and T2-weighted MRI images, and a convolutional neural network is trained to show the difficulty of motion classification. The results show that the spiral k-space sampling method get less effect of motion artifact in image space as compared to radial k-space sampled images, and radial k-space sampled images are more robust than Cartesian ones. Cartesian samplers, on the other hand, are the best in terms of deep learning motion detection because they can better reflect motion.      
### 2.DiaRet: A browser-based application for the grading of Diabetic Retinopathy with Integrated Gradients  [ :arrow_down: ](https://arxiv.org/pdf/2103.08501.pdf)
>  Diabetes is a metabolic disorder that results from defects in autoimmune beta-cell destruction in Type 1, peripheral resistance to insulin action in Type 2 or, most commonly, both. Patients with long-standing diabetes often fall prey to Diabetic Retinopathy (DR) resulting in changes in the retina of the human eye, which may lead to loss of vision in extreme cases. The aim of this study is two-fold: (a) create deep learning models that were trained to grade degraded retinal fundus images and (b) to create a browser-based application that will aid in diagnostic procedures by highlighting the key features of the fundus image. Deep learning has proven to be a success for computer-aided DR diagnosis resulting in early-detection and prevention of blindness. In this research work, we have emulated the images plagued by distortions by degrading the images based on multiple different combinations of Light Transmission Disturbance, Image Blurring and insertion of Retinal Artifacts. These degraded images were used for the training of multiple Deep Learning based Convolutional Neural Networks. We have trained InceptionV3, ResNet-50 and InceptionResNetV2 on multiple datasets. These models were used to classify the fundus images in terms of DR severity level. The models were further used in the creation of a browser-based application, which demonstrates the models prediction and the probability associated with each class. It will also show the Integration Gradient (IG) Attribution Mask superimposed onto the input image. The creation of the browser-based application would aid in the diagnostic procedures performed by ophthalmologists by highlighting the key features of the fundus image based on an educated prediction made by the model.      
### 3.Predictive Optimal Control with Data-Based Disturbance Scenario Tree Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2103.08451.pdf)
>  Efficiently computing the optimal control policy concerning a complicated future with stochastic disturbance has always been a challenge. The predicted stochastic future disturbance can be represented by a scenario tree, but solving the optimal control problem with a scenario tree is usually computationally demanding. In this paper, we propose a data-based clustering approximation method for the scenario tree representation. Differently from the popular Markov chain approximation, the proposed method can retain information from previous steps while keeping the state space size small. Then the predictive optimal control problem can be approximately solved with reduced computational load using dynamic programming. The proposed method is evaluated in numerical examples and compared with the method which considers the disturbance as a non-stationary Markov chain. The results show that the proposed method can achieve better control performance than the Markov chain method.      
### 4.Reconfigurable Intelligent Surface-Assisted Ambient Backscatter Communications -- Experimental Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2103.08427.pdf)
>  Sixth generation (6G) mobile networks may include new passive technologies, such as ambient backscatter communication or the use of reconfigurable intelligent surfaces, to avoid the emission of waves and the corresponding energy consumption. On the one hand, a reconfigurable intelligent surface improves the network performance by adding electronically controlled reflected paths in the radio propagation channel. On the other hand, in an ambient backscatter system, a device, named tag, communicates towards a reader by backscattering the waves of an ambient source (such as a TV tower). However, the tag's backscattered signal is weak and strongly interfered by the direct signal from the ambient source. In this paper, we propose a new reconfigurable intelligent surface assisted ambient backscatter system. The proposed surface has two features: it controls the reflection of an incident wave coming from the exact source location towards the tag and reader locations (creating hot spots at their locations), thanks to passive reflected beams from a predefined codebook. The surface also applies a common phase-shift to the beam. We demonstrate experimentally that by tuning the beam and the phase-shift of the reconfigurable intelligent surface, we can improve significantly the performance of ambient backscatter communications.      
### 5.Distributed Linear-Quadratic Control with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.08417.pdf)
>  Controlling network systems has become a problem of paramount importance. Optimally controlling a network system with linear dynamics and minimizing a quadratic cost is a particular case of the well-studied linear-quadratic problem. When the specific topology of the network system is ignored, the optimal controller is readily available. However, this results in a centralized controller, facing limitations in terms of implementation and scalability. Finding the optimal distributed controller, on the other hand, is intractable in the general case. In this paper, we propose the use of graph neural networks (GNNs) to parametrize and design a distributed controller. GNNs exhibit many desirable properties, such as being naturally distributed and scalable. We cast the distributed linear-quadratic problem as a self-supervised learning problem, which is then used to train the GNN-based controllers. We also obtain sufficient conditions for the resulting closed-loop system to be input-state stable, and derive an upper bound on the trajectory deviation when the system is not accurately known. We run extensive simulations to study the performance of GNN-based distributed controllers and show that they are computationally efficient and scalable.      
### 6.Wav2vec-C: A Self-supervised Model for Speech Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.08393.pdf)
>  Wav2vec-C introduces a novel representation learning technique combining elements from wav2vec 2.0 and VQ-VAE. Our model learns to reproduce quantized representations from partially masked speech encoding using a contrastive loss in a way similar to Wav2vec 2.0. However, the quantization process is regularized by an additional consistency network that learns to reconstruct the input features to the wav2vec 2.0 network from the quantized representations in a way similar to a VQ-VAE model. The proposed self-supervised model is trained on 10k hours of unlabeled data and subsequently used as the speech encoder in a RNN-T ASR model and fine-tuned with 1k hours of labeled data. This work is one of only a few studies of self-supervised learning on speech tasks with a large volume of real far-field labeled data. The Wav2vec-C encoded representations achieves, on average, twice the error reduction over baseline and a higher codebook utilization in comparison to wav2vec 2.0      
### 7.Learning Frequency-aware Dynamic Network for Efficient Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.08357.pdf)
>  Deep learning based methods, especially convolutional neural networks (CNNs) have been successfully applied in the field of single image super-resolution (SISR). To obtain better fidelity and visual quality, most of existing networks are of heavy design with massive computation. However, the computation resources of modern mobile devices are limited, which cannot easily support the expensive cost. To this end, this paper explores a novel frequency-aware dynamic network for dividing the input into multiple parts according to its coefficients in the discrete cosine transform (DCT) domain. In practice, the high-frequency part will be processed using expensive operations and the lower-frequency part is assigned with cheap operations to relieve the computation burden. Since pixels or image patches belong to low-frequency areas contain relatively few textural details, this dynamic network will not affect the quality of resulting super-resolution images. In addition, we embed predictors into the proposed dynamic network to end-to-end fine-tune the handcrafted frequency-aware masks. Extensive experiments conducted on benchmark SISR models and datasets show that the frequency-aware dynamic network can be employed for various SISR neural architectures to obtain the better tradeoff between visual quality and computational complexity. For instance, we can reduce the FLOPs of EDSR model by approximate $50\%$ while preserving state-of-the-art SISR performance.      
### 8.The QXS-SAROPT Dataset for Deep Learning in SAR-Optical Data Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2103.08259.pdf)
>  Deep learning techniques have made an increasing impact on the field of remote sensing. However, deep neural networks based fusion of multimodal data from different remote sensors with heterogenous characteristics has not been fully explored, due to the lack of availability of big amounts of perfectly aligned multi-sensor image data with diverse scenes of high resolution, especially for synthetic aperture radar (SAR) data and optical imagery. In this paper, we publish the QXS-SAROPT dataset to foster deep learning research in SAR-optical data fusion. QXS-SAROPT comprises 20,000 pairs of corresponding image patches, collected from three port cities: San Diego, Shanghai and Qingdao acquired by the SAR satellite GaoFen-3 and optical satellites of Google Earth. Besides a detailed description of the dataset, we show exemplary results for two representative applications, namely SAR-optical image matching and SAR ship detection boosted by cross-modal information from optical images. Since QXS-SAROPT is a large open dataset with multiple scenes of the highest resolution of this kind, we believe it will support further developments in the field of deep learning based SAR-optical data fusion for remote sensing.      
### 9.Iterative Reweighted Algorithms for Joint User Identification and Channel Estimation in Spatially Correlated Massive MTC  [ :arrow_down: ](https://arxiv.org/pdf/2103.08242.pdf)
>  Joint user identification and channel estimation (JUICE) is a main challenge in grant-free massive machine-type communications (mMTC). The sparse pattern in users' activity allows to solve the JUICE as a compressed sensing problem in a multiple measurement vector (MMV) setup. This paper addresses the JUICE under the practical spatially correlated fading channel. We formulate the JUICE as an iterative reweighted $\ell_{2,1}$-norm optimization. We develop a computationally efficient alternating direction method of multipliers (ADMM) approach to solve it. In particular, by leveraging the second-order statistics of the channels, we reformulate the JUICE problem to exploit the covariance information and we derive its ADMM-based solution. The simulation results highlight the significant improvements brought by the proposed approach in terms of channel estimation and activity detection performances.      
### 10.Solving the Conflict-Free Electric Vehicle Routing Problem Using SMT Solvers  [ :arrow_down: ](https://arxiv.org/pdf/2103.08217.pdf)
>  The Vehicle Routing Problem (VRP) is the combinatorial optimization problem of computing routes to serve customers while minimizing a cost function, typically the travelled distance or the number of vehicles required for a given performance. Industrial applications of the problem in manufacturing plants is the scheduling and routing of Automated Guided Vehicles (AGVs) to deliver material between storage areas and assembly stations. For large fleets of vehicles it is necessary to take the limited space of plant floor into account during scheduling and routing in order to limit the number of AGVs that are at certain locations at a given time. In addition, AGVs are most often powered by batteries and therefore have limited operating range and non-negligible charging time that will also affect the scheduling and routing decisions. In this paper we provide a model formulation for the scheduling and routing of AGVs with given time-windows for delivering material, restricted by capacity constraints on the path network, and with the need for periodic recharge. The problem is modelled and solved using optimizing Satisfiability Modulo Theory (SMT) solvers. The approach is evaluated on a set of generated problem instances, showing that the solver can handle medium size instances in a reasonable amount of time.      
### 11.Performance versus Complexity Study of Neural Network Equalizers in Coherent Optical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.08212.pdf)
>  We present the results of the comparative analysis of the performance versus complexity for several types of artificial neural networks (NNs) used for nonlinear channel equalization in coherent optical communication systems. The comparison has been carried out using an experimental set-up with transmission dominated by the Kerr nonlinearity and component imperfections. For the first time, we investigate the application to the channel equalization of the convolution layer (CNN) in combination with a bidirectional long short-term memory (biLSTM) layer and the design combining CNN with a multi-layer perceptron. Their performance is compared with the one delivered by the previously proposed NN equalizer models: one biLSTM layer, three-dense-layer perceptron, and the echo state network. Importantly, all architectures have been initially optimized by a Bayesian optimizer. We present the derivation of the computational complexity associated with each NN type -- in terms of real multiplications per symbol so that these results can be applied to a large number of communication systems. We demonstrated that in the specific considered experimental system the convolutional layer coupled with the biLSTM (CNN+biLSTM) provides the highest Q-factor improvement compared to the reference linear chromatic dispersion compensation (2.9 dB improvement). We examine the trade-off between the computational complexity and performance of all equalizers and demonstrate that the CNN+biLSTM is the best option when the computational complexity is not constrained, while when we restrict the complexity to lower levels, the three-layer perceptron provides the best performance. Our complexity analysis for different NNs is generic and can be applied in a wide range of physical and engineering systems.      
### 12.XLST: Cross-lingual Self-training to Learn Multilingual Representation for Low Resource Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.08207.pdf)
>  In this paper, we propose a weakly supervised multilingual representation learning framework, called cross-lingual self-training (XLST). XLST is able to utilize a small amount of annotated data from high-resource languages to improve the representation learning on multilingual un-annotated data. Specifically, XLST uses a supervised trained model to produce initial representations and another model to learn from them, by maximizing the similarity between output embeddings of these two models. Furthermore, the moving average mechanism and multi-view data augmentation are employed, which are experimentally shown to be crucial to XLST. Comprehensive experiments have been conducted on the CommonVoice corpus to evaluate the effectiveness of XLST. Results on 5 downstream low-resource ASR tasks shows that our multilingual pretrained model achieves relatively 18.6% PER reduction over the state-of-the-art self-supervised method, with leveraging additional 100 hours of annotated English data.      
### 13.Echo State Network based Symbol Detection in Chaotic Baseband Wireless Communication  [ :arrow_down: ](https://arxiv.org/pdf/2103.08159.pdf)
>  In some Internet of Things (IoT) applications, multi-path propagation is a main constraint of communication channel. Recently, the chaotic baseband wireless communication system (CBWCS) is promising to eliminate the inter-symbol interference (ISI) caused by multipath propagation. However, the current technique is only capable of removing the partial effect of ISI, due to only past decoded bits are available for the suboptimal decoding threshold calculation. However, the future transmitting bits also contribute to the threshold. The unavailable future information bits needed by the optimal decoding threshold are an obstacle to further improve the bit error rate (BER) performance. Different from the previous method using echo state network (ESN) to predict one future information bit, the proposed method in this paper predicts the optimal threshold directly using ESN. The proposed ESN-based threshold prediction method simplifies the symbol decoding operation by removing the threshold calculation from the transmitting symbols and channel information, which achieves better BER performance as compared to the previous method. The reason for this superior result lies in two folds, first, the proposed ESN is capable of using more future symbols information conveyed by the ESN input to get more accurate threshold; second, the proposed method here does not need to estimate the channel information using Least Square method, which avoids the extra error caused by inaccurate channel information estimation. By this way, the calculation complexity is decreased as compared to the previous method. Simulation results and experiment based on a wireless open-access research platform under a practical wireless channel, show the effectiveness and superiority of the proposed method.      
### 14.Fast Antenna and Beam Switching Method for mmWave Handsets with Hand Blockage  [ :arrow_down: ](https://arxiv.org/pdf/2103.08151.pdf)
>  Many operators have been bullish on the role of millimeter-wave (mmWave) communications in fifth-generation (5G) mobile broadband because of its capability of delivering extreme data speeds and capacity. However, mmWave comes with challenges related to significantly high path loss and susceptibility to blockage. Particularly, when mmWave communication is applied to a mobile terminal device, communication can be frequently broken because of rampant hand blockage. Although a number of mobile phone companies have suggested configuring multiple sets of antenna modules at different locations on a mobile phone to circumvent this problem, identifying an optimal antenna module and a beam pair by simultaneously opening multiple sets of antenna modules causes the problem of excessive power consumption and device costs. In this study, a fast antenna and beam switching method termed Fast-ABS is proposed. In this method, only one antenna module is used for the reception to predict the best beam of other antenna modules. As such, unmasked antenna modules and their corresponding beam pairs can be rapidly selected for switching to avoid the problem of poor quality or disconnection of communications caused by hand blockage. Thorough analysis and extensive simulations, which include the derivation of relevant Cramér-Rao lower bounds, show that the performance of Fast-ABS is close to that of an oracle solution that can instantaneously identify the best beam of other antenna modules even in complex multipath scenarios. Furthermore, Fast-ABS is implemented on a software defined radio and integrated into a 5G New Radio physical layer. Over-the-air experiments reveal that Fast-ABS can achieve efficient and seamless connectivity despite hand blockage.      
### 15.Exergy-based analysis for hybrid and electric ground vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.08145.pdf)
>  The exergy, or availability, is a thermodynamic concept representing the useful work that can be extracted from a system which moves from a given state to an equilibrium point with the environment. It is also a system metric, formulated from the first and the second law of thermodynamics, encompassing the interactions between subsystems and their irreversibilities. Thus, an exergy-based analysis allows to identify the valuable portion of a system's energy, which can be converted into useful work. Within this framework, an exergy-based analysis for ground vehicles, namely, Electric Vehicles (EVs) and Hybrid Electric Vehicles (HEVs), is proposed. This study, a first to the authors' knowledge, builds a comprehensive modeling framework, accounting for the different energy storage/conversion devices of the powertrain, which can be employed to quantify how efficiencies and inefficiencies are distributed among the components of the propulsion system and drivetrain. This information is of paramount importance and can be employed for further optimization of the vehicle design or for the development of exergy management strategies aiming at minimizing inefficiencies, rather than fuel consumption. Eventually, the effectiveness and potentialities of the proposed approach are shown considering two case studies based on an EV and a parallel HEV, respectively.      
### 16.$ω-$nonblocking supervisory control of discrete-event systems with infinite behavior  [ :arrow_down: ](https://arxiv.org/pdf/2103.08133.pdf)
>  In the supervisory control framework of discrete-event systems (DES) with infinite behavior initiated by Thistle and Wonham, a supervisor satisfying the minimal acceptable specification and the maximal legal specification is synthesized. However, this supervisor may incur livelocks as it cannot ensure that the infinite behavior under supervision will always visit some marker states. To tackle this problem, we propose the definition of markability by requiring that all infinite cycles include at least one marker state. Then we formulate the problem of $\omega-$nonblocking supervisory control of DES with infinite behavior to synthesize an $\omega-$nonblocking (i.e. nonblocking, deadlock-free and livelock-free) supervisor. An algorithm is proposed to achieve $\omega-$nonblockingness by computing the supremal $*-$controllable, $*-$closed, $\omega-$controllable and markable sublanguage. We utilize the example of a robot as a running example.      
### 17.Safe Controller Synthesis with Tunable Input-to-State Safe Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2103.08041.pdf)
>  To bring complex systems into real world environments in a safe manner, they will have to be robust to uncertainties - both in the environment and the system. This paper investigates the safety of control systems under input disturbances, wherein the disturbances can capture uncertainties in the system. Safety, framed as forward invariance of sets in the state space, is ensured with the framework of control barrier functions (CBFs). Concretely, the definition of input to state safety (ISSf) is generalized to allow the synthesis of non-conservative, tunable controllers that are provably safe under varying disturbances. This is achieved by formulating the concept of tunable input to state safe control barrier functions (TISSf-CBFs) which guarantee safety for disturbances that vary with state and, therefore, provide less conservative means of accommodating uncertainty. The theoretical results are demonstrated with a simple control system with input disturbance and also applied to design a safe connected cruise controller for a heavy duty truck.      
### 18.A Combination 5-DOF Active Magnetic Bearing For Energy Storage Flywheel  [ :arrow_down: ](https://arxiv.org/pdf/2103.08004.pdf)
>  Conventional active magnetic bearing (AMB) systems use several separate radial and thrust bearings to provide a 5 degree of freedom (DOF) levitation control. This paper presents a novel combination 5-DOF active magnetic bearing (C5AMB) designed for a shaft-less, hub-less, high-strength steel energy storage flywheel (SHFES), which enables doubled energy density compared to prior technologies. As a single device, the C5AMB provides radial, axial, and tilting levitations simultaneously. In addition, it utilizes low-cost and more available materials to replace silicon steels and laminations, which results in reduced costs and more convenient assemblies. Apart from the unique structure and the use of low magnetic grade material, other design challenges include shared flux paths, large dimensions, and relatively small air gaps. The finite element method (FEM) is too computationally intensive for early-stage analysis. An equivalent magnetic circuit method (EMCM) is developed for modeling and analysis. Nonlinear FEM is then used for detailed simulations. Both permanent magnets (PM) and electromagnetic (EM) control currents provide the weight-balancing lifting force. The C5AMB successfully levitates a 5440 kg and 2 m diameter flywheel at an air gap of 1.143 mm. Its current and position stiffnesses are verified experimentally.      
### 19.COVID-19 Infection Localization and Severity Grading from Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.07985.pdf)
>  Coronavirus disease 2019 (COVID-19) has been the main agenda of the whole world, since it came into sight in December 2019 as it has significantly affected the world economy and healthcare system. Given the effects of COVID-19 on pulmonary tissues, chest radiographic imaging has become a necessity for screening and monitoring the disease. Numerous studies have proposed Deep Learning approaches for the automatic diagnosis of COVID-19. Although these methods achieved astonishing performance in detection, they have used limited chest X-ray (CXR) repositories for evaluation, usually with a few hundred COVID-19 CXR images only. Thus, such data scarcity prevents reliable evaluation with the potential of overfitting. In addition, most studies showed no or limited capability in infection localization and severity grading of COVID-19 pneumonia. In this study, we address this urgent need by proposing a systematic and unified approach for lung segmentation and COVID-19 localization with infection quantification from CXR images. To accomplish this, we have constructed the largest benchmark dataset with 33,920 CXR images, including 11,956 COVID-19 samples, where the annotation of ground-truth lung segmentation masks is performed on CXRs by a novel human-machine collaborative approach. An extensive set of experiments was performed using the state-of-the-art segmentation networks, U-Net, U-Net++, and Feature Pyramid Networks (FPN). The developed network, after an extensive iterative process, reached a superior performance for lung region segmentation with Intersection over Union (IoU) of 96.11% and Dice Similarity Coefficient (DSC) of 97.99%. Furthermore, COVID-19 infections of various shapes and types were reliably localized with 83.05% IoU and 88.21% DSC. Finally, the proposed approach has achieved an outstanding COVID-19 detection performance with both sensitivity and specificity values above 99%.      
### 20.Progressive residual learning for single image dehazing  [ :arrow_down: ](https://arxiv.org/pdf/2103.07973.pdf)
>  The recent physical model-free dehazing methods have achieved state-of-the-art performances. However, without the guidance of physical models, the performances degrade rapidly when applied to real scenarios due to the unavailable or insufficient data problems. On the other hand, the physical model-based methods have better interpretability but suffer from multi-objective optimizations of parameters, which may lead to sub-optimal dehazing results. In this paper, a progressive residual learning strategy has been proposed to combine the physical model-free dehazing process with reformulated scattering model-based dehazing operations, which enjoys the merits of dehazing methods in both categories. Specifically, the global atmosphere light and transmission maps are interactively optimized with the aid of accurate residual information and preliminary dehazed restorations from the initial physical model-free dehazing process. The proposed method performs favorably against the state-of-the-art methods on public dehazing benchmarks with better model interpretability and adaptivity for complex hazy data.      
### 21.Ultrasound differential phase contrast using backscattering and the memory effect  [ :arrow_down: ](https://arxiv.org/pdf/2103.07949.pdf)
>  We describe a simple and fast technique to perform ultrasound differential phase contrast (DPC) imaging in arbitrarily thick scattering media. Though configured in a reflection geometry, DPC is based on transmission imaging and is a direct analogue of optical differential interference contrast (DIC). DPC exploits the memory effect and works in combination with standard pulse-echo imaging, with no additional hardware or data requirements, enabling complementary phase contrast (in the transverse direction) without any need for intensive numerical computation. We experimentally demonstrate the principle of DPC using tissue phantoms with calibrated speed-of-sound inclusions.      
### 22.Distributed Clustering for User Devices Under Unmanned Aerial Vehicle Coverage Area during Disaster Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2103.07931.pdf)
>  An Unmanned Aerial Vehicle (UAV) is a promising technology for providing wireless coverage to ground user devices. For all the infrastructure communication networks destroyed in disasters, UAVs battery life is challenging during service delivery in a post-disaster scenario. Therefore, selecting cluster heads among user devices plays a vital role in detecting UAV signals and processing data for improving UAV energy efficacy and reliable Connectivity. This paper focuses on the performance evaluation of the clustering approach performance in detecting wireless coverage services with improving energy efficiency. The evaluation performance is a realistic simulation for the ground to air channel Line of Sight (LoS). The results show that the cluster head can effectively link the UAVs and cluster members at minimal energy expenditure. The UAVs altitudes and path loss exponent affected user devices for detecting wireless coverage. Moreover, the bit error rate in the cluster heads is considered for reliable Connectivity in post disaster. Clustering stabilizes the clusters linking the uncovered nodes to the UAV, and its effectiveness in doing so resulted in its ubiquity in emergency communication systems.      
### 23.Rate-Splitting Multiple Access for Multi-Antenna Joint Radar and Communications  [ :arrow_down: ](https://arxiv.org/pdf/2103.07914.pdf)
>  Dual-Functional Radar-Communication (DFRC) system is an essential and promising technique for beyond 5G. In this work, we propose a powerful and unified multi-antenna DFRC transmission framework, where an additional radar sequence is transmitted apart from communication streams to enhance radar beampattern matching capability, and Rate-Splitting Multiple Access (RSMA) is adopted to better manage the interference. RSMA relies on multi-antenna Rate-Splitting (RS) with Successive Interference Cancellation (SIC) receivers, and the split and encoding of messages into common and private streams. We design the message split and the precoders of the radar sequence and communication streams to jointly maximize the Weighted Sum Rate (WSR) and minimize the radar beampattern approximation Mean Square Error (MSE) subject to the per antenna power constraint. An iterative algorithm based on Alternating Direction Method of Multipliers (ADMM) is developed to solve the problem. Numerical results first show that RSMA-assisted DFRC achieves a better tradeoff between WSR and beampattern approximation than Space-Division Multiple Access (SDMA)-assisted DFRC with or without radar sequence, and other simpler radar-communication strategies using orthogonal resources. We also show that the RSMA-assisted DFRC frameworks with and without radar sequence achieve the same tradeoff performance. This is because that the common stream is better exploited in the proposed framework. The common stream of RSMA fulfils the triple function of managing interference among communication users, managing interference between communication and radar, and beampattern approximation. Therefore, by enabling RSMA in DFRC, the system performance is enhanced while the system architecture is simplified since there is no need to use additional radar sequence and SIC. We conclude that RSMA is a more powerful multiple access for DFRC.      
### 24.Decision Making of Connected Automated Vehicles at An Unsignalized Roundabout Considering Personalized Driving Behaviours  [ :arrow_down: ](https://arxiv.org/pdf/2103.07910.pdf)
>  To improve the safety and efficiency of the intelligent transportation system, particularly in complex urban scenarios, in this paper a game theoretic decision-making framework is designed for connected automated vehicles (CAVs) at unsignalized roundabouts considering their personalized driving behaviours. Within the decision-making framework, a motion prediction module is designed and optimized using model predictive control (MPC) to enhance the effectiveness and accuracy of the decision-making algorithm. Besides, the payoff function of decision making is defined with the consideration of vehicle safety, ride comfort and travel efficiency. Additionally, the constraints of the decision-making problem are constructed. Based on the established decision-making model, Stackelberg game and grand coalition game approaches are adopted to address the decision making of CAVs at an unsignalized roundabout. Three testing cases considering personalized driving behaviours are carried out to verify the performance of the developed decision-making algorithms. The testing results show that the proposed game theoretic decision-making framework is able to make safe and reasonable decisions for CAVs in the complex urban scenarios, validating its feasibility and effectiveness. Stackelberg game approach shows its advantage in guaranteeing personalized driving objectives of individuals, while the grand coalition game approach is advantageous regarding the efficiency improvement of the transportation system.      
### 25.Cooperative Decision Making of Connected Automated Vehicles at Multi-lane Merging Zone: A Coalitional Game Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.07887.pdf)
>  To address the safety and efficiency issues of vehicles at multi-lane merging zones, a cooperative decision-making framework is designed for connected automated vehicles (CAVs) using a coalitional game approach. Firstly, a motion prediction module is established based on the simplified single-track vehicle model for enhancing the accuracy and reliability of the decision-making algorithm. Then, the cost function and constraints of the decision making are designed considering multiple performance indexes, i.e. the safety, comfort and efficiency. Besides, in order to realize human-like and personalized smart mobility, different driving characteristics are considered and embedded in the modeling process. Furthermore, four typical coalition models are defined for CAVS at the scenario of a multi-lane merging zone. Then, the coalitional game approach is formulated with model predictive control (MPC) to deal with decision making of CAVs at the defined scenario. Finally, testings are carried out in two cases considering different driving characteristics to evaluate the performance of the developed approach. The testing results show that the proposed coalitional game based method is able to make reasonable decisions and adapt to different driving characteristics for CAVs at the multi-lane merging zone. It guarantees the safety and efficiency of CAVs at the complex dynamic traffic condition, and simultaneously accommodates the objectives of individual vehicles, demonstrating the feasibility and effectiveness of the proposed approach.      
### 26.Statistical Assessment of Renewable Energy Generation in Optimizing Qatar Green Buildings  [ :arrow_down: ](https://arxiv.org/pdf/2103.07881.pdf)
>  The residential electrical energy scheduling of solar Photovoltaics (PV) is an important research area of the modern green buildings. On the demand side, factors such as building load, and the renewable PV energy resources are integrated together as a nonlinear, indefinite and time varying complex system, which is very difficult to forecast and optimize. These energy sources are greatly depending on the climatic conditions. It further makes the residential building energy management complex. To address this problem, we present statistical models for the effective utilization of the renewables and reducing the burden on the distribution network. The effect of weather parameters such as temperature, dust in the air, humidity and solar irradiation on the green buildings energy infrastructure is taken into account. The details are analyzed and presented in the manuscript. The real time data is analyzed in the SPSS software tool. The presented results show that the statistical models are necessary for the controller to take action for the efficient and reliable integration of the renewables.      
### 27.Dynamic Control Allocation between Onboard and Delayed Remote Control for Unmanned Aircraft System Detect-and-Avoid  [ :arrow_down: ](https://arxiv.org/pdf/2103.07820.pdf)
>  This paper develops and evaluates the performance of an allocation agent to be potentially integrated into the onboard Detect and Avoid (DAA) computer of an Unmanned Aircraft System (UAS). We consider a UAS that can be fully controlled by the onboard DAA system and by a remote human pilot. With a communication channel prone to latency, we consider a mixed initiative interaction environment, where the control authority of the UAS is dynamically allocated by the allocation agent. In an encounter with a dynamic intruder, the probability of collision may increase in the absence of pilot commands in the presence of latency. Moreover, a delayed pilot command may not result in safe resolution of the current scenario and need to be improvised. We design an optimization algorithm to reduce collision risk and refine delayed pilot commands. Towards this end, a Markov Decision Process (MDP)and its solution are employed to create a wait time map. The map consists of estimated times that the UAS can wait for the remote pilot commands at each state. A command blending algorithm is designed to select an avoidance maneuver that prioritizes the pilot intention extracted from the pilot commands. The wait time map and the command blending algorithm are implemented and integrated into a closed-loop simulator. We conduct ten thousands fast-time Monte Carlo simulations and compare the performance of the integrated setup with a standalone DAA setup. The simulation results show that the allocation agent enables the UAS to wait without inducing any near mid air collision (NMAC) and severe loss of well clear (LoWC) while positively improve pilot involvement in the encounter resolution.      
### 28.Accelerating the timeline for climate action in California  [ :arrow_down: ](https://arxiv.org/pdf/2103.07801.pdf)
>  The climate emergency increasingly threatens our communities, ecosystems, food production, health, and economy. It disproportionately impacts lower income communities, communities of color, and the elderly. Assessments since the 2018 IPCC 1.5 Celsius report show that current national and sub-national commitments and actions are insufficient. Fortunately, a suite of solutions exists now to mitigate the climate crisis if we initiate and sustain actions today. California, which has a strong set of current targets in place and is home to clean energy and high technology innovation, has fallen behind in its climate ambition compared to a number of major governments. California, a catalyst for climate action globally, can and should ramp up its leadership by aligning its climate goals with the most recent science, coordinating actions to make 2030 a point of significant accomplishment. This entails dramatically accelerating its carbon neutrality and net-negative emissions goal from 2045 to 2030, including advancing clean energy and clean transportation standards, and accelerating nature-based solutions on natural and working lands. It also means changing its current greenhouse gas reduction goals both in the percentage and the timing: cutting emissions by 80 percent (instead of 40 percent) below 1990 levels much closer to 2030 than 2050. These actions will enable California to save lives, benefit underserved and frontline communities, and save trillions of dollars. This rededication takes heed of the latest science, accelerating equitable, job-creating climate policies. While there are significant challenges to achieving these goals, California can establish policy now that will unleash innovation and channel market forces, as has happened with solar, and catalyze positive upward-scaling tipping points for accelerated global climate action.      
### 29.VMAF And Variants: Towards A Unified VQA  [ :arrow_down: ](https://arxiv.org/pdf/2103.07770.pdf)
>  Video quality assessment (VQA) is now a fastgrowing subject, beginning to mature in the full reference (FR) case, while the burgeoning no reference (NR) case remains challenging. We investigate variants of the popular VMAF video quality assessment algorithm for the FR case, using support vector regression and feedforward neural networks, and extend it to the NR case, using the same learning architectures, to develop a partially unified framework for VQA. When heavily trained, algorithms such as VMAF perform well on test datasets, with 90%+ match; but predicting performance in the wild is better done by training/testing from scratch, as we do. Even from scratch, we achieve 90%+ performance in FR, with gains over VMAF. And we greatly reduce complexity vs. leading recent NR algorithms, VIDEVAL, RAPIQUE, yet exceed 80% in SRCC. In our preliminary testing, we find the improvements in trainability, while also constraining computational complexity, as quite encouraging, suggesting further study and analysis.      
### 30.Fine-grained MRI Reconstruction using Attentive Selection Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.07672.pdf)
>  Compressed sensing (CS) leverages the sparsity prior to provide the foundation for fast magnetic resonance imaging (fastMRI). However, iterative solvers for ill-posed problems hinder their adaption to time-critical applications. Moreover, such a prior can be neither rich to capture complicated anatomical structures nor applicable to meet the demand of high-fidelity reconstructions in modern MRI. Inspired by the state-of-the-art methods in image generation, we propose a novel attention-based deep learning framework to provide high-quality MRI reconstruction. We incorporate large-field contextual feature integration and attention selection in a generative adversarial network (GAN) framework. We demonstrate that the proposed model can produce superior results compared to other deep learning-based methods in terms of image quality, and relevance to the MRI reconstruction in an extremely low sampling rate diet.      
### 31.Spatio-temporal Modeling for Large-scale Vehicular Networks Using Graph Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.07636.pdf)
>  The effective deployment of connected vehicular networks is contingent upon maintaining a desired performance across spatial and temporal domains. In this paper, a graph-based framework, called SMART, is proposed to model and keep track of the spatial and temporal statistics of vehicle-to-infrastructure (V2I) communication latency across a large geographical area. SMART first formulates the spatio-temporal performance of a vehicular network as a graph in which each vertex corresponds to a subregion consisting of a set of neighboring location points with similar statistical features of V2I latency and each edge represents the spatio-correlation between latency statistics of two connected vertices. Motivated by the observation that the complete temporal and spatial latency performance of a vehicular network can be reconstructed from a limited number of vertices and edge relations, we develop a graph reconstruction-based approach using a graph convolutional network integrated with a deep Q-networks algorithm in order to capture the spatial and temporal statistic of feature map pf latency performance for a large-scale vehicular network. Extensive simulations have been conducted based on a five-month latency measurement study on a commercial LTE network. Our results show that the proposed method can significantly improve both the accuracy and efficiency for modeling and reconstructing the latency performance of large vehicular networks.      
### 32.Efficient Precoding for Single Carrier Modulation in Multi-User Massive MIMO Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.07631.pdf)
>  By processing in the frequency domain (FD), massive MIMO systems can approach the theoretical per-user capacity using a single carrier modulation (SCM) waveform with a cyclic prefix. Minimum mean squared error (MMSE) detection and zero forcing (ZF) precoding have been shown to effectively cancel multi-user interference while compensating for inter-symbol interference. In this paper, we present a modified downlink precoding approach in the FD based on regularized zero forcing (RZF), which reuses the matrix inverses calculated as part of the FD MMSE uplink detection. By reusing these calculations, the computational complexity of the RZF precoder is drastically lowered, compared to the ZF precoder. Introduction of the regularization in RZF leads to a bias in the detected data symbols at the user terminals. We show this bias can be removed by incorporating a scaling factor at the receiver. Furthermore, it is noted that user powers have to be optimized to strike a balance between noise and interference seen at each user terminal. The resulting performance of the RZF precoder exceeds that of the ZF precoder for low and moderate input signal-to-noise ratio (SNR) conditions, and performance is equal for high input SNR. These results are established and confirmed by analysis and simulation.      
### 33.Early Prediction and Diagnosis of Retinoblastoma Using Deep Learning Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2103.07622.pdf)
>  Retinoblastoma is the most prominent childhood primary intraocular malignancy that impacts the vision of children and adults worldwide. In contrasting and comparing with adults it is uveal melanoma. It is an aggressive tumor that can fill and destroy the eye and the surrounding structures. Therefore early detection of retinoblastoma in childhood is the key. The major impact of the research is to identify the tumor cells in the retina. Also is to find out the stages of the tumor and its corresponding group. The proposed systems assist the ophthalmologists for accurate prediction and diagnosis of retinoblastoma cancer disease at the earliest. The contribution of the proposed approach is to save the life of infants and the grown-up children from vision impairment. The proposed methodology consists of three phases namely, preprocessing, segmentation, and classification. Initially, the fundus images are preprocessed using the Liner Predictive Decision based Median Filter (LPDMF). It removes the noise introduced in the image due to illumination while capturing or scanning the eye of the patients. The preprocessed images are segmented using the Convolutional Neural Network (CNN) to distinguish the foreground tumor cells from the background.      
### 34.Efficient Android Based Invisible Broken Wire Detector  [ :arrow_down: ](https://arxiv.org/pdf/2103.07619.pdf)
>  The system to include an android based underground broken wire detection which works by detecting the electromagnetic field around a live underground cable is proposed. The transmission cables undergo stress and strain as they are under the ground. This may lead to short circuits or various kinds of snapping in the wire. If these faults are not treated, it may cause an interruption in the power supply and permanent damage. The proposed method distinguishes the short circuit fault in the underground links. The existing and traditional techniques for detection are reviewed and only the methods for spotting the short circuit error are included. Thus the proposed system provides a cost-efficient way of detecting the short circuit shortcomings in underground cables.      
### 35.RL-Controller: a reinforcement learning framework for active structural control  [ :arrow_down: ](https://arxiv.org/pdf/2103.07616.pdf)
>  To maintain structural integrity and functionality during the designed life cycle of a structure, engineers are expected to accommodate for natural hazards as well as operational load levels. Active control systems are an efficient solution for structural response control when a structure is subjected to unexpected extreme loads. However, development of these systems through traditional means is limited by their model dependent nature. Recent advancements in adaptive learning methods, in particular, reinforcement learning (RL), for real-time decision making problems, along with rapid growth in high-performance computational resources, help structural engineers to transform the classic model-based active control problem to a purely data-driven one. In this paper, we present a novel RL-based approach for designing active controllers by introducing RL-Controller, a flexible and scalable simulation environment. The RL-Controller includes attributes and functionalities that are defined to model active structural control mechanisms in detail. We show that the proposed framework is easily trainable for a five story benchmark building with 65% reductions on average in inter story drifts (ISD) when subjected to strong ground motions. In a comparative study with LQG active control method, we demonstrate that the proposed model-free algorithm learns more optimal actuator forcing strategies that yield higher performance, e.g., 25% more ISD reductions on average with respect to LQG, without using prior information about the mechanical properties of the system.      
### 36.Untrained networks for compressive lensless photography  [ :arrow_down: ](https://arxiv.org/pdf/2103.07609.pdf)
>  Compressive lensless imagers enable novel applications in an extremely compact device, requiring only a phase or amplitude mask placed close to the sensor. They have been demonstrated for 2D and 3D microscopy, single-shot video, and single-shot hyperspectral imaging; in each of these cases, a compressive-sensing-based inverse problem is solved in order to recover a 3D data-cube from a 2D measurement. Typically, this is accomplished using convex optimization and hand-picked priors. Alternatively, deep learning-based reconstruction methods offer the promise of better priors, but require many thousands of ground truth training pairs, which can be difficult or impossible to acquire. In this work, we propose the use of untrained networks for compressive image recovery. Our approach does not require any labeled training data, but instead uses the measurement itself to update the network weights. We demonstrate our untrained approach on lensless compressive 2D imaging as well as single-shot high-speed video recovery using the camera's rolling shutter, and single-shot hyperspectral imaging. We provide simulation and experimental verification, showing that our method results in improved image quality over existing methods.      
### 37.Mining Artifacts in Mycelium SEM Micrographs  [ :arrow_down: ](https://arxiv.org/pdf/2103.07573.pdf)
>  Mycelium is a promising biomaterial based on fungal mycelium, a highly porous, nanofibrous structure. Scanning electron micrographs are used to characterize its network, but the currently available tools for nanofibrous microstructures do not contemplate the particularities of biomaterials. The adoption of a software for artificial nanofibrous in mycelium characterization adds the uncertainty of imaging artifact formation to the analysis. The reported work combines supervised and unsupervised machine learning methods to automate the identification of artifacts in the mapped pores of mycelium microstructure. <br>Keywords: Machine learning; unsupervised learning; image processing; mycelium; microstructure informatics      
### 38.VMAF-based Bitrate Ladder Estimation for Adaptive Streaming  [ :arrow_down: ](https://arxiv.org/pdf/2103.07564.pdf)
>  In HTTP Adaptive Streaming, video content is conventionally encoded by adapting its spatial resolution and quantization level to best match the prevailing network state and display characteristics. It is well known that the traditional solution, of using a fixed bitrate ladder, does not result in the highest quality of experience for the user. Hence, in this paper, we consider a content-driven approach for estimating the bitrate ladder, based on spatio-temporal features extracted from the uncompressed content. The method implements a content-driven interpolation. It uses the extracted features to train a machine learning model to infer the curvature points of the Rate-VMAF curves in order to guide a set of initial encodings. We employ the VMAF quality metric as a means of perceptually conditioning the estimation. When compared to exhaustive encoding that produces the reference ladder, the estimated ladder is composed by 74.3% of identical Rate-VMAF points with the reference ladder. The proposed method offers a significant reduction of the number of encodes required, 77.4%, at a small average Bjøntegaard Delta Rate cost, 1.12%.      
### 39.Signal Processing Techniques to Reduce the Limit of Detection for Thin Film Biosensors  [ :arrow_down: ](https://arxiv.org/pdf/2103.07524.pdf)
>  The ultimate detection limit of optical biosensors is often limited by various noise sources, including those introduced by the optical measurement setup. While sophisticated modifications to instrumentation may reduce noise, a simpler approach that can benefit all sensor platforms is the application of signal processing to minimize the deleterious effects of noise. In this work, we show that applying complex Morlet wavelet convolution to Fabry-Pérot interference fringes characteristic of thin film reflectometric biosensors effectively filters out white noise and low frequency reflectance variations. Subsequent calculation of an average difference in phase between the filtered analyte and reference signals enables a significant reduction in the limit of detection (LOD) enabling closer competition with current state-of-the-art techniques. This method is applied on experimental data sets of thin film porous silicon sensors (PSi) in buffered solution and complex media obtained from two different laboratories. The demonstrated improvement in LOD achieved using wavelet convolution and average phase difference paves the way for PSi optical biosensors to operate with clinically relevant detection limits for medical diagnostics, environmental monitoring, and food safety.      
### 40.Estimación del Exponente de Hurst en Flujos de Tráfico Autosimilares  [ :arrow_down: ](https://arxiv.org/pdf/2103.08592.pdf)
>  In this paper it presents, develops and discusses the existence of a process with long scope memory structure, representing of the independence between the degree of randomness of the traffic generated by the sources and flow pattern exhibited by the network. The process existence is presented in term of a new algorithmic that is a variant of the maximum likelihood estimator (MLE) of Whittle, for the calculation of the Hurst exponent (H) of self-similar stationary second order time series of the flows of the individual sources and their aggregation. Also, it is discussed the additional problems introduced by the phenomenon of the locality of the Hurst exponent, that appears when the traffic flows consist of diverse elements with different Hurst exponents. The instance is exposed with the intention of being considered as a new and alternative approach for modeling and simulating traffic in existing computer networks.      
### 41.Analyzing Collective Motion Using Graph Fourier Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.08583.pdf)
>  Collective motion in animal groups, such as swarms of insects, flocks of birds, and schools of fish, are some of the most visually striking examples of emergent behavior. Empirical analysis of these behaviors in experiment or computational simulation primarily involves the use of "swarm-averaged" metrics or order parameters such as velocity alignment and angular momentum. Recently, tools from computational topology have been applied to the analysis of swarms to further understand and automate the detection of fundamentally different swarm structures evolving in space and time. Here, we show how the field of graph signal processing can be used to fuse these two approaches by collectively analyzing swarm properties using graph Fourier harmonics that respect the topological structure of the swarm. This graph Fourier analysis reveals hidden structure in a number of common swarming states and forms the basis of a flexible analysis framework for collective motion.      
### 42.Is Medical Chest X-ray Data Anonymous?  [ :arrow_down: ](https://arxiv.org/pdf/2103.08562.pdf)
>  With the rise and ever-increasing potential of deep learning techniques in recent years, publicly available medical data sets became a key factor to enable reproducible development of diagnostic algorithms in the medical domain. Medical data contains sensitive patient-related information and is therefore usually anonymized by removing patient identifiers, e.g., patient names before publication. To the best of our knowledge, we are the first to show that a well-trained deep learning system is able to recover the patient identity from chest X-ray data. We demonstrate this using the publicly available large-scale ChestX-ray14 dataset, a collection of 112,120 frontal-view chest X-ray images from 30,805 unique patients. Our verification system is able to identify whether two frontal chest X-ray images are from the same person with an AUC of 0.9940 and a classification accuracy of 95.55%. We further highlight that the proposed system is able to reveal the same person even ten and more years after the initial scan. When pursuing a retrieval approach, we observe an mAP@R of 0.9748 and a precision@1 of 0.9963. Based on this high identification rate, a potential attacker may leak patient-related information and additionally cross-reference images to obtain more information. Thus, there is a great risk of sensitive content falling into unauthorized hands or being disseminated against the will of the concerned patients. Especially during the COVID-19 pandemic, numerous chest X-ray datasets have been published to advance research. Therefore, such data may be vulnerable to potential attacks by deep learning-based re-identification algorithms.      
### 43.Intermittent control as a model of mouse movements  [ :arrow_down: ](https://arxiv.org/pdf/2103.08558.pdf)
>  We present Intermittent Control (IC) models as a candidate framework for modelling human input movements in Human--Computer Interaction (HCI). IC differs from continuous control in that users are not assumed to use feedback to adjust their movements continuously, but only when the difference between the observed pointer position and predicted pointer positions become large. We use a parameter optimisation approach to identify the parameters of an intermittent controller from experimental data, where users performed one-dimensional mouse movements in a reciprocal pointing task. Compared to previous published work with continuous control models, based on the Kullback-Leibler divergence from the experimental observations, IC is better able to generatively reproduce the distinctive dynamical features and variability of the pointing task across participants and over repeated tasks. IC is compatible with current physiological and psychological theory and provides insight into the source of variability in HCI tasks.      
### 44.Lasry-Lions Envelopes and Nonconvex Optimization: A Homotopy Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.08533.pdf)
>  In large-scale optimization, the presence of nonsmooth and nonconvex terms in a given problem typically makes it hard to solve. A popular approach to address nonsmooth terms in convex optimization is to approximate them with their respective Moreau envelopes. In this work, we study the use of Lasry-Lions double envelopes to approximate nonsmooth terms that are also not convex. These envelopes are an extension of the Moreau ones but exhibit an additional smoothness property that makes them amenable to fast optimization algorithms. Lasry-Lions envelopes can also be seen as an "intermediate" between a given function and its convex envelope, and we make use of this property to develop a method that builds a sequence of approximate subproblems that are easier to solve than the original problem. We discuss convergence properties of this method when used to address composite minimization problems; additionally, based on a number of experiments, we discuss settings where it may be more useful than classical alternatives in two domains: signal decoding and spectral unmixing.      
### 45.BrainNetGAN: Data augmentation of brain connectivity using generative adversarial network for dementia classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.08494.pdf)
>  Alzheimer's disease (AD) is the most common age-related dementia. It remains a challenge to identify the individuals at risk of dementia for precise management. Brain MRI offers a noninvasive biomarker to detect brain aging. Previous evidence shows that the brain structural change detected by diffusion MRI is associated with dementia. Mounting studies has conceptualised the brain as a complex network, which has shown the utility of this approach in characterising various neurological and psychiatric disorders. Therefore, the structural connectivity shows promise in dementia classification. The proposed BrainNetGAN is a generative adversarial network variant to augment the brain structural connectivity matrices for binary dementia classification tasks. Structural connectivity matrices between separated brain regions are constructed using tractography on diffusion MRI data. The BrainNetGAN model is trained to generate fake brain connectivity matrices, which are expected to reflect latent distribution of the real brain network data. Finally, a convolutional neural network classifier is proposed for binary dementia classification. Numerical results show that the binary classification performance in the testing set was improved using the BrainNetGAN augmented dataset. The proposed methodology allows quick synthesis of an arbitrary number of augmented connectivity matrices and can be easily transferred to similar classification tasks.      
### 46.Uncertainty-Based Biological Age Estimation of Brain MRI Scans  [ :arrow_down: ](https://arxiv.org/pdf/2103.08491.pdf)
>  Age is an essential factor in modern diagnostic procedures. However, assessment of the true biological age (BA) remains a daunting task due to the lack of reference ground-truth labels. Current BA estimation approaches are either restricted to skeletal images or rely on non-imaging modalities that yield a whole-body BA assessment. However, various organ systems may exhibit different aging characteristics due to lifestyle and genetic factors. In this initial study, we propose a new framework for organ-specific BA estimation utilizing 3D magnetic resonance image (MRI) scans. As a first step, this framework predicts the chronological age (CA) together with the corresponding patient-dependent aleatoric uncertainty. An iterative training algorithm is then utilized to segregate atypical aging patients from the given population based on the predicted uncertainty scores. In this manner, we hypothesize that training a new model on the remaining population should approximate the true BA behavior. We apply the proposed methodology on a brain MRI dataset containing healthy individuals as well as Alzheimer's patients. We demonstrate the correlation between the predicted BAs and the expected cognitive deterioration in Alzheimer's patients.      
### 47.Ensemble approach for detection of depression using EEG features  [ :arrow_down: ](https://arxiv.org/pdf/2103.08467.pdf)
>  Depression is a public health issue which severely affects one's well being and cause negative social and economic effect for society. To rise awareness of these problems, this publication aims to determine if long lasting effects of depression can be determined from electoencephalographic (EEG) signals. The article contains accuracy comparison for SVM, LDA, NB, kNN and D3 binary classifiers which were trained using linear (relative band powers, APV, SASI) and non-linear (HFD, LZC, DFA) EEG features. The age and gender matched dataset consisted of 10 healthy subjects and 10 subjects with depression diagnosis at some point in their lifetime. Several of the proposed feature selection and classifier combinations reached accuracy of 90% where all models where evaluated using 10-fold cross validation and averaged over 100 repetitions with random sample permutations.      
### 48.Task-driven assessment of experimental designs in diffusion MRI: a computational framework  [ :arrow_down: ](https://arxiv.org/pdf/2103.08438.pdf)
>  Purpose: To propose a task-driven computational framework for assessing diffusion MRI experimental designs which, rather than relying on parameter-estimation metrics, directly measures quantitative task performance. <br>Theory: Traditional computational experimental design (CED) methods may be ill-suited to tasks, such as clinical classification, where outcome does not depend on parameter-estimation accuracy or precision alone. Current assessment metrics evaluate experiments' ability to faithfully recover microstructure parameters rather than their associated task performance. This work proposes a novel CED assessment method that addresses this shortcoming. For a given experimental design (protocol, parameter-estimation method, model, etc.), experiments are simulated start-to-finish and task performance is computed from receiver operating characteristic (ROC) curves and summary metrics such as area under the curve (AUC). <br>Methods: Two experiments were performed: first a validation of the pipeline's task performance predictions in two clinical datasets, comparing in-silico predictions to real-world ROC/AUC; and second, a demonstration of the pipeline's advantages over traditional CED approaches, using two simulated clinical classification tasks. <br>Results: Our computational method accurately predicts (a) the qualitative form of ROC curves, (b) the relative performance of different experimental designs, and (c) the absolute performance (AUC) of each experimental design. Furthermore, our method is shown to outperform traditional task-agnostic assessment methods. <br>Conclusions: The proposed pipeline produces accurate, quantitative predictions of real-world task performance. Compared to current approaches, such task-driven assessment is more likely to identify experimental design that perform well in practice. It provides the foundation for developing future task-driven CED frameworks.      
### 49.Gradient Policy on "CartPole" game and its' expansibility to F1Tenth Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.08396.pdf)
>  Policy gradient is an effective way to estimate continuous action on the environment. This paper, it about explaining the mathematical formula and code implementation. In the end, comparing between the rotation angle of the stick on CartPole , and the angle of the Autonomous vehicle when turning, and utilizing the Bicycle Model, a simple Kinematic dynamic model, are the purpose to discover the similarity between these two models, so as to facilitate the model transfer from CartPole to the F1tenth Autonomous vehicle.      
### 50.I-Nema: A Biological Image Dataset for Nematode Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.08335.pdf)
>  Nematode worms are one of most abundant metazoan groups on the earth, occupying diverse ecological niches. Accurate recognition or identification of nematodes are of great importance for pest control, soil ecology, bio-geography, habitat conservation and against climate changes. Computer vision and image processing have witnessed a few successes in species recognition of nematodes; however, it is still in great demand. In this paper, we identify two main bottlenecks: (1) the lack of a publicly available imaging dataset for diverse species of nematodes (especially the species only found in natural environment) which requires considerable human resources in field work and experts in taxonomy, and (2) the lack of a standard benchmark of state-of-the-art deep learning techniques on this dataset which demands the discipline background in computer science. With these in mind, we propose an image dataset consisting of diverse nematodes (both laboratory cultured and naturally isolated), which, to our knowledge, is the first time in the community. We further set up a species recognition benchmark by employing state-of-the-art deep learning networks on this dataset. We discuss the experimental results, compare the recognition accuracy of different networks, and show the challenges of our dataset. We make our dataset publicly available at: <a class="link-external link-https" href="https://github.com/xuequanlu/I-Nema" rel="external noopener nofollow">this https URL</a>      
### 51.EmoNet: A Transfer Learning Framework for Multi-Corpus Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.08310.pdf)
>  In this manuscript, the topic of multi-corpus Speech Emotion Recognition (SER) is approached from a deep transfer learning perspective. A large corpus of emotional speech data, EmoSet, is assembled from a number of existing SER corpora. In total, EmoSet contains 84181 audio recordings from 26 SER corpora with a total duration of over 65 hours. The corpus is then utilised to create a novel framework for multi-corpus speech emotion recognition, namely EmoNet. A combination of a deep ResNet architecture and residual adapters is transferred from the field of multi-domain visual recognition to multi-corpus SER on EmoSet. Compared against two suitable baselines and more traditional training and transfer settings for the ResNet, the residual adapter approach enables parameter efficient training of a multi-domain SER model on all 26 corpora. A shared model with only $3.5$ times the number of parameters of a model trained on a single database leads to increased performance for 21 of the 26 corpora in EmoSet. Measured by McNemar's test, these improvements are further significant for ten datasets at $p&lt;0.05$ while there are just two corpora that see only significant decreases across the residual adapter transfer experiments. Finally, we make our EmoNet framework publicly available for users and developers at <a class="link-external link-https" href="https://github.com/EIHW/EmoNet" rel="external noopener nofollow">this https URL</a>. EmoNet provides an extensive command line interface which is comprehensively documented and can be used in a variety of multi-corpus transfer learning settings.      
### 52.Scaling a Blockchain-based Railway Control System Prototype for Mainline Railways: a Progress Report  [ :arrow_down: ](https://arxiv.org/pdf/2103.08304.pdf)
>  Railway operations require control systems to ensure safety and efficiency, and to coordinate infrastructure elements such as switches, signals and train protection. To compete with the traditional approaches to these systems, a blockchain-based approach has been proposed, with the intent to build a more resilient, integrated and cost-efficient system. Additionally, the developed blockchain-based architecture enables to run safety-relevant and security-focused business logic on off-the-shelf platforms such as cloud, rather than on specialized (and expensive) secure hardware. After implementing a prototype of the blockchain-based railway control system, scaling the approach to real-world mainline and branch operations required a thorough validation of the design choices. In this technical report, we show how performance calculations, long-term technology perspectives and law-mandated norms have impacted the architecture, the technology choices, and the make-buy-reuse decisions.      
### 53.TinyOL: TinyML with Online-Learning on Microcontrollers  [ :arrow_down: ](https://arxiv.org/pdf/2103.08295.pdf)
>  Tiny machine learning (TinyML) is a fast-growing research area committed to democratizing deep learning for all-pervasive microcontrollers (MCUs). Challenged by the constraints on power, memory, and computation, TinyML has achieved significant advancement in the last few years. However, the current TinyML solutions are based on batch/offline settings and support only the neural network's inference on MCUs. The neural network is first trained using a large amount of pre-collected data on a powerful machine and then flashed to MCUs. This results in a static model, hard to adapt to new data, and impossible to adjust for different scenarios, which impedes the flexibility of the Internet of Things (IoT). To address these problems, we propose a novel system called TinyOL (TinyML with Online-Learning), which enables incremental on-device training on streaming data. TinyOL is based on the concept of online learning and is suitable for constrained IoT devices. We experiment TinyOL under supervised and unsupervised setups using an autoencoder neural network. Finally, we report the performance of the proposed solution and show its effectiveness and feasibility.      
### 54.Improving reproducibility in synchrotron tomography using implementation-adapted filters  [ :arrow_down: ](https://arxiv.org/pdf/2103.08288.pdf)
>  For reconstructing large tomographic datasets fast, filtered backprojection-type or Fourier-based algorithms are still the method of choice, as they have been for decades. These robust and computationally efficient algorithms have been integrated in a broad range of software packages. Despite the fact that the underlying mathematical formulas used for image reconstruction are unambiguous, variations in discretisation and interpolation result in quantitative differences between reconstructed images obtained from different software. This hinders reproducibility of experimental results. <br>In this paper, we propose a way to reduce such differences by optimising the filter used in analytical algorithms. These filters can be computed using a wrapper routine around a black-box implementation of a reconstruction algorithm, and lead to quantitatively similar reconstructions. We demonstrate use cases for our approach by computing implementation-adapted filters for several open-source implementations and applying it to simulated phantoms and real-world data acquired at the synchrotron. Our contribution to a reproducible reconstruction step forms a building block towards a fully reproducible synchrotron tomography data processing pipeline.      
### 55.Robust MAML: Prioritization task buffer with adaptive learning process for model-agnostic meta-learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.08233.pdf)
>  Model agnostic meta-learning (MAML) is a popular state-of-the-art meta-learning algorithm that provides good weight initialization of a model given a variety of learning tasks. The model initialized by provided weight can be fine-tuned to an unseen task despite only using a small amount of samples and within a few adaptation steps. MAML is simple and versatile but requires costly learning rate tuning and careful design of the task distribution which affects its scalability and generalization. This paper proposes a more robust MAML based on an adaptive learning scheme and a prioritization task buffer(PTB) referred to as Robust MAML (RMAML) for improving scalability of training process and alleviating the problem of distribution mismatch. RMAML uses gradient-based hyper-parameter optimization to automatically find the optimal learning rate and uses the PTB to gradually adjust train-ing task distribution toward testing task distribution over the course of training. Experimental results on meta reinforcement learning environments demonstrate a substantial performance gain as well as being less sensitive to hyper-parameter choice and robust to distribution mismatch.      
### 56.Computational timbre and tonal system similarity analysis of the music of Northern Myanmar-based Kachin compared to Xinjiang-based Uyghur ethnic groups  [ :arrow_down: ](https://arxiv.org/pdf/2103.08203.pdf)
>  The music of Northern Myanmar Kachin ethnic group is compared to the music of western China, Xijiang based Uyghur music, using timbre and pitch feature extraction and machine learning. Although separated by Tibet, the muqam tradition of Xinjiang might be found in Kachin music due to myths of Kachin origin, as well as linguistic similarities, e.g., the Kachin term 'makan' for a musical piece. Extractions were performed using the apollon and COMSAR (Computational Music and Sound Archiving) frameworks, on which the Ethnographic Sound Recordings Archive (ESRA) is based, using ethnographic recordings from ESRA next to additional pieces. In terms of pitch, tonal systems were compared using Kohonen self-organizing map (SOM), which clearly clusters Kachin and Uyghur musical pieces. This is mainly caused by the Xinjiang muqam music showing just fifth and fourth, while Kachin pieces tend to have a higher fifth and fourth, next to other dissimilarities. Also, the timbre features of spectral centroid and spectral sharpness standard deviation clearly tells Uyghur from Kachin pieces, where Uyghur music shows much larger deviations. Although more features will be compared in the future, like rhythm or melody, these already strong findings might introduce an alternative comparison methodology of ethnic groups beyond traditional linguistic definitions.      
### 57.Performance Analysis of Dual-Hop Relaying for THz-RF Wireless Link with Asymmetrical Fading  [ :arrow_down: ](https://arxiv.org/pdf/2103.08188.pdf)
>  Terahertz (THz) frequency bands can be promising for data transmissions between the core network and access points (AP) for next-generation wireless systems. In this paper, we analyze the performance of a dual-hop THz-RF wireless system where an AP facilitates data transmission between a core network and user equipment (UE). We consider a generalized model for the end-to-end channel with an independent and not identically distributed (i.ni.d.) fading model for THz and RF links using the $\alpha$-$\mu$ distribution, the THz link with pointing errors, and asymmetrical relay position. We derive a closed-form expression of the cumulative distribution function (CDF) of the end-to-end signal-to-noise ratio (SNR) for the THz-RF link, which is valid for continuous values of $\mu$ for a generalized performance analysis over THz fading channels. Using the derived CDF, we analyze the performance of the THz-RF relayed system using decode-and-forward (DF) protocol by deriving analytical expressions of diversity order, moments of SNR, ergodic capacity, and average BER in terms of system parameters. We also analyze the considered system with an i.i.d. model and develop simplified performance to provide insight on the system behavior analytically under various practically relevant scenarios. Simulation and numerical analysis show a significant effect of fading parameters of the THz link and a nominal effect of normalized beam-width on the performance of the relay-assisted THz-RF system.      
### 58.Shape-induced obstacle attraction and repulsion during dynamic locomotion  [ :arrow_down: ](https://arxiv.org/pdf/2103.08176.pdf)
>  Robots still struggle to dynamically traverse complex 3-D terrain with many large obstacles, an ability required for many critical applications. Body-obstacle interaction is often inevitable and induces perturbation and uncertainty in motion that challenges closed-form dynamic modeling. Here, inspired by recent discovery of a terradynamic streamlined shape, we studied how two body shapes interacting with obstacles affect turning and pitching motions of an open-loop multi-legged robot and cockroaches during dynamic locomotion. With a common cuboidal body, the robot was attracted towards obstacles, resulting in pitching up and flipping-over. By contrast, with an elliptical body, the robot was repelled by obstacles and readily traversed. The animal displayed qualitatively similar turning and pitching motions induced by these two body shapes. However, unlike the cuboidal robot, the cuboidal animal was capable of escaping obstacle attraction and subsequent high pitching and flipping over, which inspired us to develop an empirical pitch-and-turn strategy for cuboidal robots. Considering the similarity of our self-propelled body-obstacle interaction with part-feeder interaction in robotic part manipulation, we developed a quasi-static potential energy landscape model to explain the dependence of dynamic locomotion on body shape. Our experimental and modeling results also demonstrated that obstacle attraction or repulsion is an inherent property of locomotor body shape and insensitive to obstacle geometry and size. Our study expanded the concept and usefulness of terradynamic shapes for passive control of robot locomotion to traverse large obstacles using physical interaction. Our study is also a step in establishing an energy landscape approach to locomotor transitions.      
### 59.Resolution Limits of 20 Questions Search Strategies for Moving Targets  [ :arrow_down: ](https://arxiv.org/pdf/2103.08097.pdf)
>  We establish fundamental limits of tracking a moving target over the unit cube under the framework of 20 questions with measurement-dependent noise. In this problem, there is an oracle who knows the instantaneous location of a target. Our task is to query the oracle as few times as possible to accurately estimate the trajectory of the moving target, whose initial location and velocity is \emph{unknown}. We study the case where the oracle's answer to each query is corrupted by random noise with query-dependent discrete distribution. In our formulation, the performance criterion is the resolution, which is defined as the maximal absolute value between the true location and estimated location at each discrete time during the searching process. We are interested in the minimal resolution of any non-adaptive searching procedure with a finite number of queries and derive approximations to this optimal resolution via the second-order asymptotic analysis.      
### 60.Towards Robust Speech-to-Text Adversarial Attack  [ :arrow_down: ](https://arxiv.org/pdf/2103.08095.pdf)
>  This paper introduces a novel adversarial algorithm for attacking the state-of-the-art speech-to-text systems, namely DeepSpeech, Kaldi, and Lingvo. Our approach is based on developing an extension for the conventional distortion condition of the adversarial optimization formulation using the Cramèr integral probability metric. Minimizing over this metric, which measures the discrepancies between original and adversarial samples' distributions, contributes to crafting signals very close to the subspace of legitimate speech recordings. This helps to yield more robust adversarial signals against playback over-the-air without employing neither costly expectation over transformation operations nor static room impulse response simulations. Our approach outperforms other targeted and non-targeted algorithms in terms of word error rate and sentence-level-accuracy with competitive performance on the crafted adversarial signals' quality. Compared to seven other strong white and black-box adversarial attacks, our proposed approach is considerably more resilient against multiple consecutive playbacks over-the-air, corroborating its higher robustness in noisy environments.      
### 61.Multi-Discriminator Sobolev Defense-GAN Against Adversarial Attacks for End-to-End Speech Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.08086.pdf)
>  This paper introduces a defense approach against end-to-end adversarial attacks developed for cutting-edge speech-to-text systems. The proposed defense algorithm has four major steps. First, we represent speech signals with 2D spectrograms using the short-time Fourier transform. Second, we iteratively find a safe vector using a spectrogram subspace projection operation. This operation minimizes the chordal distance adjustment between spectrograms with an additional regularization term. Third, we synthesize a spectrogram with such a safe vector using a novel GAN architecture trained with Sobolev integral probability metric. To improve the model's performance in terms of stability and the total number of learned modes, we impose an additional constraint on the generator network. Finally, we reconstruct the signal from the synthesized spectrogram and the Griffin-Lim phase approximation technique. We evaluate the proposed defense approach against six strong white and black-box adversarial attacks benchmarked on DeepSpeech, Kaldi, and Lingvo models. Our experimental results show that our algorithm outperforms other state-of-the-art defense algorithms both in terms of accuracy and signal quality.      
### 62.Competition among Ride Service Providers with Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.08051.pdf)
>  Autonomous vehicles (AVs) are attractive for ride service providers (RSPs) in part because they eliminate the need to compete for human drivers. We investigate a scenario where two RSPs with AVs compete for customers. We model the problem as a game where the RSPs select prices for each origin-destination pair over multiple time periods in an underlying graph representing the customers' desired trips. Each RSP also decides the number of AVs to be stationed at each node at each time period to serve the customers' demands. The number of customers who avail of the service of an RSP depends on the price selected by the RSP and its competitor. Since the strategy choices available to an RSP depends on its competitor, we seek to compute a Generalized Nash equilibrium (GNE). We show that there may be multiple GNEs. However, when an RSP selects prices in order to deter its competitor when it is not serving a source-destination pair, the game has a potential function and admits a unique GNE. We also compare the competitive prices with a monopoly price where only one RSP is in the market. Numerically, we show that if a network consists of two equal-size spatial clusters of demand where the demand between clusters is low, the RSPs may partition the market, i.e, one cluster is served by only one RSP. Hence, the competitive price may become close to the monopoly price.      
### 63.Transient growth of accelerated first-order methods for strongly convex optimization problems  [ :arrow_down: ](https://arxiv.org/pdf/2103.08017.pdf)
>  Optimization algorithms are increasingly being used in applications with limited time budgets. In many real-time and embedded scenarios, only a few iterations can be performed and traditional convergence metrics cannot be used to evaluate performance in these non-asymptotic regimes. In this paper, we examine the transient behavior of accelerated first-order optimization algorithms. For quadratic optimization problems, we employ tools from linear systems theory to show that transient growth arises from the presence of non-normal dynamics. We identify the existence of modes that yield an algebraic growth in early iterations and quantify the transient excursion from the optimal solution caused by these modes. For strongly convex smooth optimization problems, we utilize the theory of integral quadratic constraints to establish an upper bound on the magnitude of the transient response of Nesterov's accelerated method. We show that both the Euclidean distance between the optimization variable and the global minimizer and the rise time to the transient peak are proportional to the square root of the condition number of the problem. Finally, for problems with large condition numbers, we demonstrate tightness of the bounds that we derive up to constant factors.      
### 64.SaNet: Scale-aware neural Network for Parsing Multiple Spatial Resolution Aerial Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.07935.pdf)
>  Assigning the geospatial objects of aerial images with categorical information at the pixel-level is a basic task in urban scene understanding. However, the huge differencc in remote sensing sensors makes the acqured aerial images in multiple spatial resolution (MSR), which brings two issues: the increased scale variation of geospatial objects and informative feature loss as spatial resolution drops. To address the two issues, we propose a novel scale-aware neural network (SaNet) for parsing MSR aerial images. For coping with the imbalanced segmentation quality between larger and smaller objects caused by the scale variation, the SaNet deploys a densely connected feature network (DCFPN) module to capture quality multi-scale context with large receptive fields. To alleviate the informative feature loss, a SFR module is incorporated into the network to learn scale-invariant features with spatial relation enhancement. Extensive experimental results on the ISPRS Vaihingen 2D Dataset and ISPRS Potsdam 2D Dataset demonstrate the outstanding cross-resolution segmentation ability of the proposed SaNet compared to other state-of-the-art networks.      
### 65.Gym-ANM: Reinforcement Learning Environments for Active Network Management Tasks in Electricity Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.07932.pdf)
>  Active network management (ANM) of electricity distribution networks include many complex stochastic sequential optimization problems. These problems need to be solved for integrating renewable energies and distributed storage into future electrical grids. In this work, we introduce Gym-ANM, a framework for designing reinforcement learning (RL) environments that model ANM tasks in electricity distribution networks. These environments provide new playgrounds for RL research in the management of electricity networks that do not require an extensive knowledge of the underlying dynamics of such systems. Along with this work, we are releasing an implementation of an introductory toy-environment, ANM6-Easy, designed to emphasize common challenges in ANM. We also show that state-of-the-art RL algorithms can already achieve good performance on ANM6-Easy when compared against a model predictive control (MPC) approach. Finally, we provide guidelines to create new Gym-ANM environments differing in terms of (a) the distribution network topology and parameters, (b) the observation space, (c) the modelling of the stochastic processes present in the system, and (d) a set of hyperparameters influencing the reward signal. Gym-ANM can be downloaded at <a class="link-external link-https" href="https://github.com/robinhenry/gym-anm" rel="external noopener nofollow">this https URL</a>.      
### 66.Simulation Studies on Deep Reinforcement Learning for Building Control with Human Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2103.07919.pdf)
>  The building sector consumes the largest energy in the world, and there have been considerable research interests in energy consumption and comfort management of buildings. Inspired by recent advances in reinforcement learning (RL), this paper aims at assessing the potential of RL in building climate control problems with occupant interaction. We apply a recent RL approach, called DDPG (deep deterministic policy gradient), for the continuous building control tasks and assess its performance with simulation studies in terms of its ability to handle (a) the partial state observability due to sensor limitations; (b) complex stochastic system with high-dimensional state-spaces, which are jointly continuous and discrete; (c) uncertainties due to ambient weather conditions, occupant's behavior, and comfort feelings. Especially, the partial observability and uncertainty due to the occupant interaction significantly complicate the control problem. Through simulation studies, the policy learned by DDPG demonstrates reasonable performance and computational tractability.      
### 67.Blind Estimation of Room Acoustic Parameters and Speech Transmission Index using MTF-based CNNs  [ :arrow_down: ](https://arxiv.org/pdf/2103.07904.pdf)
>  This paper proposes a blind estimation method based on the modulation transfer function and Schroeder model for estimating reverberation time in seven-octave bands. Therefore, the speech transmission index and five room-acoustic parameters can be estimated.      
### 68.Convolutional Free-space Optical Neural Networks for Image Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.07862.pdf)
>  With its unique parallel processing capability, optical neural network has shown low-power consumption in image recognition and speech processing. At present, the manufacturing technology of programmable photonic chip is not mature, and the realization of optical neural network in free-space is still a hot spot of photonic AI. In this letter, based on MNIST datasets and 4f system, one- and three-layer optical neural networks are constructed, whose recognition accuracy can reach 86.06% and 93.66%, respectively. Our network is better than the existing free-space optical neural network in terms of spatial complexity, and the three-layer's accuracy.      
### 69.A Few-Shot Learning Approach for Accelerated MRI via Fusion of Data-Driven and Subject-Driven Priors  [ :arrow_down: ](https://arxiv.org/pdf/2103.07790.pdf)
>  Deep neural networks (DNNs) have recently found emerging use in accelerated MRI reconstruction. DNNs typically learn data-driven priors from large datasets constituting pairs of undersampled and fully-sampled acquisitions. Acquiring such large datasets, however, might be impractical. To mitigate this limitation, we propose a few-shot learning approach for accelerated MRI that merges subject-driven priors obtained via physical signal models with data-driven priors obtained from a few training samples. Demonstrations on brain MR images from the NYU fastMRI dataset indicate that the proposed approach requires just a few samples to outperform traditional parallel imaging and DNN algorithms.      
### 70.Multi-Object Tracking using Poisson Multi-Bernoulli Mixture Filtering for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.07783.pdf)
>  The ability of an autonomous vehicle to perform 3D tracking is essential for safe planing and navigation in cluttered environments. The main challenges for multi-object tracking (MOT) in autonomous driving applications reside in the inherent uncertainties regarding the number of objects, when and where the objects may appear and disappear, and uncertainties regarding objects' states. Random finite set (RFS) based approaches can naturally model these uncertainties accurately and elegantly, and they have been widely used in radar-based tracking applications. In this work, we developed an RFS-based MOT framework for 3D LiDAR data. In partiuclar, we propose a Poisson multi-Bernoulli mixture (PMBM) filter to solve the amodal MOT problem for autonomous driving applications. To the best of our knowledge, this represents a first attempt for employing an RFS-based approach in conjunction with 3D LiDAR data for MOT applications with comprehensive validation using challenging datasets made available by industry leaders. The superior experimental results of our PMBM tracker on public Waymo and Argoverse datasets clearly illustrate that an RFS-based tracker outperforms many state-of-the-art deep learning-based and Kalman filter-based methods, and consequently, these results indicate a great potential for further exploration of RFS-based frameworks for 3D MOT applications.      
### 71.Heterogeneity in Neuronal Calcium Spike Trains based on Empirical Distance  [ :arrow_down: ](https://arxiv.org/pdf/2103.07772.pdf)
>  Statistical similarities between neuronal spike trains could reveal significant information on complex underlying processing. In general, the similarity between synchronous spike trains is somewhat easy to identify. However, the similar patterns also potentially appear in an asynchronous manner. However, existing methods for their identification tend to converge slowly, and cannot be applied to short sequences. In response, we propose Hellinger distance measure based on empirical probabilities, which we show to be as accurate as existing techniques, yet faster to converge for synthetic as well as experimental spike trains. Further, we cluster pairs of neuronal spike trains based on statistical similarities and found two non-overlapping classes, which could indicate functional similarities in neurons. Significantly, our technique detected functional heterogeneity in pairs of neuronal responses with the same performance as existing techniques, while exhibiting faster convergence. We expect the proposed method to facilitate large-scale studies of functional clustering, especially involving short sequences, which would in turn identify signatures of various diseases in terms of clustering patterns.      
### 72.Mean Field Behaviour of Collaborative Multi-Agent Foragers  [ :arrow_down: ](https://arxiv.org/pdf/2103.07714.pdf)
>  Collaborative multi-agent robotic systems where agents coordinate by modifying a shared environment often result in undesired dynamical couplings that complicate the analysis and experiments when solving a specific problem or task. Simultaneously, biologically-inspired robotics rely on simplifying agents and increasing their number to obtain more efficient solutions to such problems, drawing similarities with natural processes. In this work we focus on the problem of a biologically-inspired multi-agent system solving collaborative foraging. We show how mean field techniques can be used to re-formulate such a stochastic multi-agent problem into a deterministic au- tonomous system. This de-couples agent dynamics, enabling the computation of limit behaviours and the analysis of optimality guarantees. Furthermore, we analyse how having finite number of agents affects the performance when compared to the mean field limit and we discuss the implications of such limit approximations in this multi-agent system, which have impact on more general collaborative stochastic problems.      
### 73.Embedding Calibration for Music Semantic Similarity using Auto-regressive Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2103.07656.pdf)
>  One of the advantages of using natural language processing (NLP) technology for music is to fully exploit the embedding based representation learning paradigm that can easily handle classical tasks such as semantic similarity. However, recent researches have revealed the poor performance issue of common baseline methods for semantic similarity in NLP. They show that some simple embedding calibration methods can easily promote the performance of semantic similarity without extra training hence is ready-to-use. Nevertheless, it is still unclear which is the best combination of calibration methods and by how much can we further improve the performance with such methods. Most importantly, previous works are based on auto-encoder Transformer, hence the performance under auto-regressive model for music is unclear. These render the following open questions: does embedding based semantic similarity also apply for auto-regressive music model, does poor baseline issue for semantic similarity also exists, and if so, are there unexplored embedding calibration methods to better promote the performance of music semantic similarity? In this paper, we answer these questions by exploring different combination of embedding calibration under auto-regressive language model for symbolic music. Our results show that music semantic similarity works under auto-regressive model, and also suffers from poor baseline issues like in NLP. Furthermore, we provide optimal combination of embedding calibration that has not been explored in previous researches. Results show that such combination of embedding calibration can greatly improve music semantic similarity without further training tasks.      
### 74.A Distributed Optimisation Framework Combining Natural Gradient with Hessian-Free for Discriminative Sequence Training  [ :arrow_down: ](https://arxiv.org/pdf/2103.07554.pdf)
>  This paper presents a novel natural gradient and Hessian-free (NGHF) optimisation framework for neural network training that can operate efficiently in a distributed manner. It relies on the linear conjugate gradient (CG) algorithm to combine the natural gradient (NG) method with local curvature information from Hessian-free (HF) or other second-order methods. A solution to a numerical issue in CG allows effective parameter updates to be generated with far fewer CG iterations than usually used (e.g. 5-8 instead of 200). This work also presents a novel preconditioning approach to improve the progress made by individual CG iterations for models with shared parameters. Although applicable to other training losses and model structures, NGHF is investigated in this paper for lattice-based discriminative sequence training for hybrid hidden Markov model acoustic models using a standard recurrent neural network, long short-term memory, and time delay neural network models for output probability calculation. Automatic speech recognition experiments are reported on the multi-genre broadcast data set for a range of different acoustic model types. These experiments show that NGHF achieves larger word error rate reductions than standard stochastic gradient descent or Adam, while requiring orders of magnitude fewer parameter updates.      
### 75.Chaotic Logistic Map Forecast using Fuzzy Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2103.07550.pdf)
>  This paper deals with the problem of forecast the Logistic Chaotic Map using Fuzzy Times Series (FTS). Chaotic Systems are very sensible to changes in its parameters and in the initial conditions, turning them into hard systems to model and forecast. In this case, we relay in the robustness of Fuzzy Time Series to model and forecast the logistic map. We use the Akaike Information Criterion (AIC) as an index to determine the number of sub intervals for the definition of the fuzzy set.      
### 76.On Incorporating Forecasts into Linear State Space Model Markov Decision Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.07533.pdf)
>  Weather forecast information will very likely find increasing application in the control of future energy systems. In this paper, we introduce an augmented state space model formulation with linear dynamics, within which one can incorporate forecast information that is dynamically revealed alongside the evolution of the underlying state variable. We use the martingale model for forecast evolution (MMFE) to enforce the necessary consistency properties that must govern the joint evolution of forecasts with the underlying state. The formulation also generates jointly Markovian dynamics that give rise to Markov decision processes (MDPs) that remain computationally tractable. This paper is the first to enforce MMFE consistency requirements within an MDP formulation that preserves tractability.      
### 77.Safe Sampling-Based Air-Ground Rendezvous Algorithm for Complex Urban Environments  [ :arrow_down: ](https://arxiv.org/pdf/2103.07519.pdf)
>  Demand for fast and economical parcel deliveries in urban environments has risen considerably in recent years. A framework envisions efficient last-mile delivery in urban environments by leveraging a network of ride-sharing vehicles, where Unmanned Aerial Systems (UASs) drop packages on said vehicles, which then cover the majority of the distance before final aerial delivery. Notably, we consider the problem of planning a rendezvous path for the UAS to reach a human driver, who may choose between N possible paths and has uncertain behavior, while meeting strict safety constraints. The long planning horizon and safety constraints require robust heuristics that combine learning and optimal control using Gaussian Process Regression, sampling-based optimization, and Model Predictive Control. The resulting algorithm is computationally efficient and shown to be effective in a variety of qualitative scenarios.      
### 78.Design of a Self Decoupled 16 Channel Transmitter for Human Brain MRI at 447MHz  [ :arrow_down: ](https://arxiv.org/pdf/2103.07516.pdf)
>  Transmitter arrays play a critical role in ultra high field Magnetic Resonance Imaging (MRI), especially given the advantages made possible via parallel transmission (pTx) techniques. One of the challenges in design and construction of transmit arrays has traditionally been finding effective strategies for decoupling elements of the transmit array. Here, we present the design of the first self-decoupled, loop-based transmit array for human brain MRI at 10.5T / 447MHz. We demonstrate, using full-wave electromagnetic simulations, effective decoupling of the transmit elements without requiring the conventional overlap or inductive decoupling techniques.      

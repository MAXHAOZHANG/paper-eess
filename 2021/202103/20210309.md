# ArXiv eess --Tue, 9 Mar 2021
### 1.Tripartite and Sign Consensus for Clustering Balanced Social Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.04938.pdf)
>  In this paper, we address two forms of consensus for multi-agent systems with undirected, signed, weighted, and connected communication graphs, under the assumption that the agents can be partitioned into three clusters, representing the decision classes on a given specific topic, for instance, the in favour, abstained and opponent agents. We will show that under some assumptions on the cooperative/antagonistic relationships among the agents, simple modifications of DeGroot's algorithm allow to achieve tripartite consensus(if the opinions of agents belonging to the same class all converge to the same decision) or sign consensus (if the opinions of the agents in the three clusters converge to positive, zero and negative values, respectively).      
### 2.Risk Aware Optimization of Water Sensor Placement  [ :arrow_down: ](https://arxiv.org/pdf/2103.04862.pdf)
>  Optimal sensor placement (SP) usually minimizes an impact measure, such as the amount of contaminated water or the number of inhabitants affected before detection. The common choice is to minimize the minimum detection time (MDT) averaged over a set of contamination events, with contaminant injected at a different location. Given a SP, propagation is simulated through a hydraulic software model of the network to obtain spatio-temporal concentrations and the average MDT. Searching for an optimal SP is NP-hard: even for mid-size networks, efficient search methods are required, among which evolutionary approaches are often used. A bi-objective formalization is proposed: minimizing the average MDT and its standard deviation, that is the risk to detect some contamination event too late than the average MDT. We propose a data structure (sort of spatio-temporal heatmap) collecting simulation outcomes for every SP and particularly suitable for evolutionary optimization. Indeed, the proposed data structure enabled a convergence analysis of a population-based algorithm, leading to the identification of indicators for detecting problem-specific converge issues which could be generalized to other similar problems. We used Pymoo, a recent Python framework flexible enough to incorporate our problem specific termination criterion. Results on a benchmark and a real-world network are presented.      
### 3.On the Analysis and Design of High-Frequency Transformers for Dual and Triple Active Bridge Converters in More Electric Aircraft  [ :arrow_down: ](https://arxiv.org/pdf/2103.04860.pdf)
>  DC-DC converters with galvanic isolation are a key element in the aircraft DC distribution system and Dual and Triple Active Bridge converters are one of the most interesting candidates in this application. The high-frequency transformer leakage inductances play a key role in the AC Link of these converters. This leakage inductances determine the power transfer capability of the converter and shape the AC link currents. The leakage inductance value is related to the distribution of the transformer windings and it changes with the RMS value of the AC link current. In this paper, first a high frequency transformer is designed for a Dual and Triple Active Bridge converter for the More Electric Aircraft DC power system. Then, an Ansys/Maxwell Finite Element analysis is performed on the leakage inductances of the transformer in three different winding configurations and in different AC link RMS current values. Finally, the transient performance of the design is validated by the Ansys/Maxwell Transient.      
### 4.Spatial- and Range- ISLR Trade-off in MIMO Radar via Waveform Correlation Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.04851.pdf)
>  This paper aims to design a set of transmitting waveforms in cognitive colocated Multi-Input Multi-Output (MIMO) radar systems considering the simultaneous minimization of spatial- and the range- Integrated Sidelobe Level Ratio (ISLR). The design problem is formulated as a bi-objective Pareto optimization under practical constraints on the waveforms, namely total transmit power, peak-to-average-power ratio (PAR), constant modulus, and discrete phase alphabet. A Coordinate Descent (CD) based approach is proposed, in which at every single variable update of the algorithm we obtain the solution of the uni-variable optimization problems. The novelty of the paper comes from deriving a flexible waveform design problem applicable for 4D imaging MIMO radars which is optimized directly over the different constraint sets. The simultaneous optimization leads to a trade-off between the two ISLRs and the simulation results illustrate significantly improved trade-off offered by the proposed methodologies.      
### 5.An Ultra-low Power RNN Classifier for Always-On Voice Wake-Up Detection Robust to Real-World Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2103.04792.pdf)
>  We present in this paper an ultra-low power (ULP) Recurrent Neural Network (RNN) based classifier for an always-on voice Wake-Up Sensor (WUS) with performances suitable for real-world applications. The purpose of our sensor is to bring down by at least a factor 100 the power consumption in background noise of always-on speech processing algorithms such as Automatic Speech Recognition, Keyword Spotting, Speaker Verification, etc. Unlike the other published approaches, we designed our wake-up sensor to be robust to unseen real-world noises for realistic levels of speech and noise by carefully designing the dataset and the loss function. We also specifically trained it to mark only the speech start rather than adopting a traditional Voice Activity Detection (VAD) approach. We achieve less than 3% No Trigger Rate (NTR) for a duty cycle less than 1% in challenging background noises pooled using a model of an analogue front-end. We demonstrate the superiority of RNNs on this task compared to the other tested approaches, with an estimated power consumption of 45 nW for the RNN itself in 65nm CMOS and a minimal memory footprint of 0.52 kB.      
### 6.CDLNet: Robust and Interpretable Denoising Through Deep Convolutional Dictionary Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.04779.pdf)
>  Deep learning based methods hold state-of-the-art results in image denoising, but remain difficult to interpret due to their construction from poorly understood building blocks such as batch-normalization, residual learning, and feature domain processing. Unrolled optimization networks propose an interpretable alternative to constructing deep neural networks by deriving their architecture from classical iterative optimization methods, without use of tricks from the standard deep learning tool-box. So far, such methods have demonstrated performance close to that of state-of-the-art models while using their interpretable construction to achieve a comparably low learned parameter count. In this work, we propose an unrolled convolutional dictionary learning network (CDLNet) and demonstrate its competitive denoising performance in both low and high parameter count regimes. Specifically, we show that the proposed model outperforms the state-of-the-art denoising models when scaled to similar parameter count. In addition, we leverage the model's interpretable construction to propose an augmentation of the network's thresholds that enables state-of-the-art blind denoising performance and near-perfect generalization on noise-levels unseen during training.      
### 7.Optimal Scheduling of Integrated Demand Response-Enabled Integrated Energy Systems with Uncertain Renewable Generations: A Stackelberg Game Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.04723.pdf)
>  In order to balance the interests of integrated energy operator (IEO) and users, a novel Stackelberg game-based optimization framework is proposed for the optimal scheduling of integrated demand response (IDR)-enabled integrated energy systems with uncertain renewable generations, where the IEO acts as the leader who pursues the maximization of his profits by setting energy prices, while the users are the follower who adjusts energy consumption plans to minimize their energy costs. Taking into account the inherent uncertainty of renewable generations, the probabilistic spinning reserve is written in the form of a chance constraint; in addition, a district heating network model is built considering the characteristics of time delay and thermal attenuation by fully exploiting its potential, and the flexible thermal comfort requirements of users in IDR are considered by introducing a predicted mean vote (PMV) index. To solve the raised model, sequence operation theory is introduced to convert the chance constraint into its deterministic equivalent form, and thereby, the leader-follower Stackelberg game is tackled into a mixed-integer quadratic programming formulation through Karush-Kuhn-Tucker optimality conditions and is finally solved by the CPLEX optimizer. The results of two case studies demonstrate that the proposed Stackelberg game-based approach manages to achieve the Stackelberg equilibrium between IEO and users by the coordination of renewable generations and IDR. Furthermore, the study on a real integrated energy system in China verifies the applicability of the proposed approach for real-world applications.      
### 8.CUHK-EE voice cloning system for ICASSP 2021 M2VoC challenge  [ :arrow_down: ](https://arxiv.org/pdf/2103.04699.pdf)
>  This paper presents the CUHK-EE voice cloning system for ICASSP 2021 M2VoC challenge. The challenge provides two Mandarin speech corpora: the AIShell-3 corpus of 218 speakers with noise and reverberation and the MST corpus including high-quality speech of one male and one female speakers. 100 and 5 utterances of 3 target speakers in different voice and style are provided in track 1 and 2 respectively, and the participants are required to synthesize speech in target speaker's voice and style. We take part in the track 1 and carry out voice cloning based on 100 utterances of target speakers. An end-to-end voicing cloning system is developed to accomplish the task, which includes: 1. a text and speech front-end module with the help of forced alignment, 2. an acoustic model combining Tacotron2 and DurIAN to predict melspectrogram, 3. a Hifigan vocoder for waveform generation. Our system comprises three stages: multi-speaker training stage, target speaker adaption stage and target speaker synthesis stage. Our team is identified as T17. The subjective evaluation results provided by the challenge organizer demonstrate the effectiveness of our system. Audio samples are available at our demo page: <a class="link-external link-https" href="https://daxintan-cuhk.github.io/CUHK-EE-system-M2VoC-challenge/" rel="external noopener nofollow">this https URL</a> .      
### 9.Voting in Transfer Learning System for Ground-Based Cloud Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.04667.pdf)
>  Clouds classification is a great challenge in meteorological research. The different types of clouds, currently known and present in our skies, can produce radioactive effects that impact on the variation of atmospheric conditions, with the consequent strong dominance over the earth's climate and weather. Therefore, identifying their main visual features becomes a crucial aspect. In this paper, the goal is to adopt a pretrained deep neural networks based architecture for clouds image description, and subsequently, classification. The approach is pyramidal. Proceeding from the bottom up, it partially extracts previous knowledge of deep neural networks related to original task and transfers it to the new task. The updated knowledge is integrated in a voting context to provide a classification prediction. The framework trains the neural models on unbalanced sets, a condition that makes the task even more complex, and combines the provided predictions through statistical measures. Experimental phase on different cloud image datasets is performed and results achieved show the effectiveness of the proposed approach with respect to state of the art competitors.      
### 10.On Joint Reconstruction of State and Input-Output Injection Attacks for Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.04579.pdf)
>  We address the problem of robust state reconstruction for discrete-time nonlinear systems when the actuators and sensors are injected with (potentially unbounded) attack signals. Exploiting redundancy in sensors and actuators and using a bank of unknown input observers (UIOs), we propose an observer-based estimator capable of providing asymptotic estimates of the system state and attack signals under the condition that the numbers of sensors and actuators under attack are sufficiently small. Using the proposed estimator, we provide methods for isolating the compromised actuators and sensors. Numerical examples are provided to demonstrate the effectiveness of our methods.      
### 11.OUTCOMES: Rapid Under-sampling Optimization achieves up to 50% improvements in reconstruction accuracy for multi-contrast MRI sequences  [ :arrow_down: ](https://arxiv.org/pdf/2103.04566.pdf)
>  Multi-contrast Magnetic Resonance Imaging (MRI) acquisitions from a single scan have tremendous potential to streamline exams and reduce imaging time. However, maintaining clinically feasible scan time necessitates significant undersampling, pushing the limits on compressed sensing and other low-dimensional techniques. During MRI scanning, one of the possible solutions is by using undersampling designs which can effectively improve the acquisition and achieve higher reconstruction accuracy. However, existing undersampling optimization methods are time-consuming and the limited performance prevents their clinical applications. In this paper, we proposed an improved undersampling trajectory optimization scheme to generate an optimized trajectory within seconds and apply it to subsequent multi-contrast MRI datasets on a per-subject basis, where we named it OUTCOMES. By using a data-driven method combined with improved algorithm design, GPU acceleration, and more efficient computation, the proposed method can optimize a trajectory within 5-10 seconds and achieve 30%-50% reconstruction improvement with the same acquisition cost, which makes real-time under-sampling optimization possible for clinical applications.      
### 12.Human-Machine Adaptive Shared Control for Safe Automated Driving under Automation Degradation  [ :arrow_down: ](https://arxiv.org/pdf/2103.04563.pdf)
>  In this paper, a human-machine adaptive shared control method is proposed for automated vehicles (AVs) under automation performance degradation. First, a novel risk assessment module is proposed to monitor driving behavior and evaluate automation performance degradation for AVs. Then, an adaptive control authority allocation module is developed. In the event of any performance degradation detection, the allocated control authority of the automation system is decreased based on the assessed risk to reduce the potential risk of vehicle motion. Consequently, the control authority allocated to the human driver is adaptively increased and thus requires more driver engagement in the control loop to compensate for the automation degradation and ensure AV safety. Experimental validation is conducted under different driving scenarios. The testing results show that the proposed approach is able to effectively compensate for the performance degradation of vehicle automation through the human-machine adaptive shared control, ensuring the safety of automated driving      
### 13.Anytime Ellipsoidal Over-approximation of Forward Reach Sets of Uncertain Linear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.04545.pdf)
>  Computing tight over-approximation of reach sets of a controlled uncertain dynamical system is a common practice in verification of safety-critical cyber-physical systems (CPS). While several algorithms are available for this purpose, they tend to be computationally demanding in CPS applications since here, the computational resources such as processor availability tend to be scarce, time-varying and difficult to model. A natural idea then is to design "computation-aware" algorithms that can dynamically adapt with respect to the processor availability in a provably safe manner. Even though this idea should be applicable in broader context, here we focus on ellipsoidal over-approximations. We demonstrate that the algorithms for ellipsoidal over-approximation of reach sets of uncertain linear systems, are well-suited for anytime implementation in the sense the quality of the over-approximation can be dynamically traded off depending on the computational time available, all the while guaranteeing safety. We give a numerical example to illustrate the idea, and point out possible future directions.      
### 14.Weather Analogs with a Machine Learning Similarity Metric for Renewable Resource Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2103.04530.pdf)
>  The Analog Ensemble (AnEn) technique has been shown effective on several weather problems. Unlike previous weather analogs that are sought within a large spatial domain and an extended temporal window, AnEn strictly confines space and time, and independently generates results at each grid point within a short time window. AnEn can find similar forecasts that lead to accurate and calibrated ensemble forecasts. <br>The central core of the AnEn technique is a similarity metric that sorts historical forecasts with respect to a new target prediction. A commonly used metric is Euclidean distance. However, a significant difficulty using this metric is the definition of the weights for all the parameters. Generally, feature selection and extensive weight search are needed. <br>This paper proposes a novel definition of weather analogs through a Machine Learning (ML) based similarity metric. The similarity metric uses neural networks that are trained and instantiated to search for weather analogs. This new metric allows incorporating all variables without requiring a prior feature selection and weight optimization. Experiments are presented on the application of this new metric to forecast wind speed and solar irradiance. Results show that the ML metric generally outperforms the original metric. The ML metric has a better capability to correct for larger errors and to take advantage of a larger search repository. Spatial predictions using a learned metric also show the ability to define effective latent features that are transferable to other locations.      
### 15.Split Computing and Early Exiting for Deep Learning Applications: Survey and Research Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2103.04505.pdf)
>  Mobile devices such as smartphones and autonomous vehicles increasingly rely on deep neural networks (DNNs) to execute complex inference tasks such as image classification and speech recognition, among others. However, continuously executing the entire DNN on the mobile device can quickly deplete its battery. Although task offloading to edge devices may decrease the mobile device's computational burden, erratic patterns in channel quality, network and edge server load can lead to a significant delay in task execution. Recently, approaches based on split computing (SC) have been proposed, where the DNN is split into a head and a tail model, executed respectively on the mobile device and on the edge device. Ultimately, this may reduce bandwidth usage as well as energy consumption. Another approach, called early exiting (EE), trains models to present multiple "exits" earlier in the architecture, each providing increasingly higher target accuracy. Therefore, the trade-off between accuracy and delay can be tuned according to the current conditions or application demands. In this paper, we provide a comprehensive survey of the state of the art in SC and EE strategies, by presenting a comparison of the most relevant approaches. We conclude the paper by providing a set of compelling research challenges.      
### 16.Learning Distributed Stabilizing Controllers for Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.04480.pdf)
>  We address the problem of model-free distributed stabilization of heterogeneous multi-agent systems using reinforcement learning (RL). Two algorithms are developed. The first algorithm solves a centralized linear quadratic regulator (LQR) problem without knowing any initial stabilizing gain in advance. The second algorithm builds upon the results of the first algorithm, and extends it to distributed stabilization of multi-agent systems with predefined interaction graphs. Rigorous proofs are provided to show that the proposed algorithms achieve guaranteed convergence if specific conditions hold. A simulation example is presented to demonstrate the theoretical results.      
### 17.Secrecy Performance of Small-Cell Networks with Transmitter Selection and Unreliable Backhaul under Spectrum Sharing Environment  [ :arrow_down: ](https://arxiv.org/pdf/2103.04479.pdf)
>  We investigate the secrecy performance of an underlay small-cell cognitive radio network under unreliable backhaul connections. The small-cell network shares the same spectrum with the primary network, ensuring that a desired outage probability constraint is always met in the primary network. {To improve the security of the small-cell cognitive network, we propose three sub-optimal small-cell transmitter selection schemes,} namely sub-optimal transmitter selection, minimal interference selection, and minimal eavesdropping selection. Closed-form expressions of the non-zero secrecy rate, secrecy outage probability, and ergodic secrecy capacity are provided for the schemes along with asymptotic expressions. {We also propose an optimal selection scheme and compare performances with the sub-optimal selection schemes.} {Computable expressions for the non-zero secrecy rate and secrecy outage probability are presented for the optimal selection scheme.} Our results show that by increasing the primary transmitter's power and the number of small-cell transmitters, the system performance improves. The selection scheme, the backhaul reliability, and the primary user quality-of-service constraint also have a significant impact on secrecy performance.      
### 18.Secrecy Outage of Dual-hop Regenerative Multi-relay System with Relay Selection  [ :arrow_down: ](https://arxiv.org/pdf/2103.04478.pdf)
>  Relay selection is considered to enhance the secrecy of a dual-hop regenerative multi-relay system with an eavesdropper. Without assuming perfect decoding at the relays, the secrecy outage probability of a single relay system is obtained first. Secrecy outage of optimal, traditional and suboptimal relay selection schemes is then evaluated. To reduce the power consumption, partial relay selection schemes based only on either of the source-relay or relay-destination instantaneous channel state information (ICSI) are introduced. Its secrecy outage is evaluated and compared with the other schemes. Secrecy outage of all the selection schemes are obtained in closed-form. An optimal relay selection scheme is proposed using secrecy outage which does not require any ICSI. Asymptotic and diversity gain analysis of the secrecy outage is presented when source-relay and relay-destination average SNRs are same or different. We observe that the improvement in eavesdropper link quality affects the secrecy outage more when required secrecy rate is low as compared to the case when rate is high. We also observe that relay selection improves performance more when number of relays are more. It is important to note that either of the source-relay or the relay-destination link quality can equally limit the secrecy outage performance even if the other link quality is infinitely good.      
### 19.Ergodic Secrecy Rate of Optimal Source Selection in a Multi-Source System with Unreliable Backhaul  [ :arrow_down: ](https://arxiv.org/pdf/2103.04477.pdf)
>  The use of multiple source nodes with wireless backhaul is considered for secrecy enhancement through source node selection in future wireless networks. The ergodic secrecy rate (ESR) of {optimal source node selection in the presence of multiple eavesdroppers} over independent non-identically distributed (INID) Rayleigh fading channels is evaluated in closed-form. At high signal-to-noise ratio (SNR), {the ESR is expressed as a simple weighted summation where each term relates to the contribution of an individual source and eavesdropper}. An asymptotic analysis shows the effect of the system parameters and backhaul reliability on the performance. {The proposed method can provide a generalized solution for the ESR of optimal \textit{transmit antenna} selection in multi-antenna systems, optimal \textit{source node} selection, and optimal \textit{relay selection} with or without unreliable backhaul.      
### 20.Presenting the Multi-Objective Optimization Model of Search and Rescue Network  [ :arrow_down: ](https://arxiv.org/pdf/2103.04426.pdf)
>  The Search and Rescue Network (SAR) is a kind of emergency network that pursuit people in need or imminent danger. This paper aims using a priori optimization to demonstrate the optimal assignment of HFDF receivers to the Generalized Search and Rescue (GSAR) network, which is independent of the weighting of the transmitter areas. The mathematical model seeks two objectives, the first one is maximizing the expected number of LOBs for HFDF receivers. The second is providing a fair share number of HFDF receivers allowed to cover the frequency. The result shown the efficiency of presented model ran by CPLEX toolbox of MATLAB 2020 software.      
### 21.Adaptive Detection of Dim Maneuvering Targets in Adjacent Range Cells  [ :arrow_down: ](https://arxiv.org/pdf/2103.04367.pdf)
>  This letter addresses the detection problem of dim maneuvering targets in the presence of range cell migration. Specifically, it is assumed that the moving target can appear in more than one range cell within the transmitted pulse train. Then, the Bayesian information criterion and the generalized likelihood ratio test design procedure are jointly exploited to come up with six adaptive decision schemes capable of estimating the range indices related to the target migration. The computational complexity of the proposed detectors is also studied and suitably reduced. Simulation results show the effectiveness of the newly proposed solutions also for a limited set of training data and in comparison with suitable counterparts.      
### 22.An Optimized Signal Processing Pipeline for Syllable Detection and Speech Rate Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2103.04346.pdf)
>  Syllable detection is an important speech analysis task with applications in speech rate estimation, word segmentation, and automatic prosody detection. Based on the well understood acoustic correlates of speech articulation, it has been realized by local peak picking on a frequency-weighted energy contour that represents vowel sonority. While several of the analysis parameters are set based on known speech signal properties, the selection of the frequency-weighting coefficients and peak-picking threshold typically involves heuristics, raising the possibility of data-based optimisation. In this work, we consider the optimization of the parameters based on the direct minimization of naturally arising task-specific objective functions. The resulting non-convex cost function is minimized using a population-based search algorithm to achieve a performance that exceeds previously published performance results on the same corpus using a relatively low amount of labeled data. Further, the optimisation of system parameters on a different corpus is shown to result in an explainable change in the optimal values.      
### 23.HTMD-Net: A Hybrid Masking-Denoising Approach to Time-Domain Monaural Singing Voice Separation  [ :arrow_down: ](https://arxiv.org/pdf/2103.04336.pdf)
>  The advent of deep learning has led to the prevalence of deep neural network architectures for monaural music source separation, with end-to-end approaches that operate directly on the waveform level increasingly receiving research attention. Among these approaches, transformation of the input mixture to a learned latent space, and multiplicative application of a soft mask to the latent mixture, achieves the best performance, but is prone to the introduction of artifacts to the source estimate. To alleviate this problem, in this paper we propose a hybrid time-domain approach, termed the HTMD-Net, combining a lightweight masking component and a denoising module, based on skip connections, in order to refine the source estimated by the masking procedure. Evaluation of our approach in the task of monaural singing voice separation in the musdb18 dataset indicates that our proposed method achieves competitive performance compared to methods based purely on masking when trained under the same conditions, especially regarding the behavior during silent segments, while achieving higher computational efficiency.      
### 24.One-batch Preempt Deterioration-effect Multi-state Multi-rework Network Reliability Problem and Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2103.04325.pdf)
>  A rework network is a distinct multi-state network that exists in many real-life industrial manufacturing systems for fixing defective products using rework processes to improve the utility and productivity of the systems. To provide a more general model of rework networks, a novel one-batch preempt multi-state multi-rework network is proposed to achieve real-life applications without numerous impractical and unreasonable limitations. Accordingly, a new algorithm based on two different multi-state types of binary addition tree algorithms (BATs) is proposed to calculate the reliability of the proposed rework. Furthermore, the proposed BAT-based algorithm is applied to four rework problems to validate its effectiveness and performance for the rework reliability problem.      
### 25.An eigen decomposition based closed-form solution for the Discrete Lyapunov and Stein Equations  [ :arrow_down: ](https://arxiv.org/pdf/2103.04315.pdf)
>  A simple closed-form solution to the discrete Lyapunov equation (DLE) is established for certain families of matrices. This solution is expressed in terms of the eigen decomposition (ED) for which closed-form solutions are known for all 2x2; 3x3 and certain families of matrices. For general matrices, the proposed ED based closed-form solution can be used as an efficient numerical solution when the ED can be computed. The result is then extended to give closed-form solutions for a generalization of the DLE, called the Stein equation. The proposed explicit solution's complexity is of the same order as iterative solutions and significantly smaller than known closed-form solutions. These solutions may prove convenient for analysis and synthesis problems related to these equations due to their compact form.      
### 26.Preliminary Study on Forced Oscillation of Power System with Quadratic Nonlinearity  [ :arrow_down: ](https://arxiv.org/pdf/2103.04240.pdf)
>  Forced oscillation (FO) is a significant concern threating the power system stability. Its mechanisms are mostly studied via linear models. However, FO amplitude is increasing, e.g., Nordic and Western American FOs, which can stimulate power system nonlinearity. Hence, this paper incorporates nonlinearity in FO mechanism analysis. The multi-scale technique is employed in solving the forced oscillation equation to handle the quadratic nonlinearity. The amplitude-frequency characteristic curves and first-order approximate expressions are derived. The frequency deviation and jumping phenomenon caused by nonlinearity are discovered and further analyzed by comparing with linear models. This paper provides a preliminary research for nonlinear FOs of power system, and more characteristics should be further analysis in the near future.      
### 27.Graph-based Pyramid Global Context Reasoning with a Saliency-aware Projection for COVID-19 Lung Infections Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.04235.pdf)
>  Coronavirus Disease 2019 (COVID-19) has rapidly spread in 2020, emerging a mass of studies for lung infection segmentation from CT images. Though many methods have been proposed for this issue, it is a challenging task because of infections of various size appearing in different lobe zones. To tackle these issues, we propose a Graph-based Pyramid Global Context Reasoning (Graph-PGCR) module, which is capable of modeling long-range dependencies among disjoint infections as well as adapt size variation. We first incorporate graph convolution to exploit long-term contextual information from multiple lobe zones. Different from previous average pooling or maximum object probability, we propose a saliency-aware projection mechanism to pick up infection-related pixels as a set of graph nodes. After graph reasoning, the relation-aware features are reversed back to the original coordinate space for the down-stream tasks. We further con- struct multiple graphs with different sampling rates to handle the size variation problem. To this end, distinct multi-scale long-range contextual patterns can be captured. Our Graph- PGCR module is plug-and-play, which can be integrated into any architecture to improve its performance. Experiments demonstrated that the proposed method consistently boost the performance of state-of-the-art backbone architectures on both of public and our private COVID-19 datasets.      
### 28.Multitasking Deep Learning Model for Detection of Five Stages of Diabetic Retinopathy  [ :arrow_down: ](https://arxiv.org/pdf/2103.04207.pdf)
>  This paper presents a multitask deep learning model to detect all the five stages of diabetic retinopathy (DR) consisting of no DR, mild DR, moderate DR, severe DR, and proliferate DR. This multitask model consists of one classification model and one regression model, each with its own loss function. Noting that a higher severity level normally occurs after a lower severity level, this dependency is taken into consideration by concatenating the classification and regression models. The regression model learns the inter-dependency between the stages and outputs a score corresponding to the severity level of DR generating a higher score for a higher severity level. After training the regression model and the classification model separately, the features extracted by these two models are concatenated and inputted to a multilayer perceptron network to classify the five stages of DR. A modified Squeeze Excitation Densely Connected deep neural network is developed to implement this multitasking approach. The developed multitask model is then used to detect the five stages of DR by examining the two large Kaggle datasets of APTOS and EyePACS. A multitasking transfer learning model based on Xception network is also developed to evaluate the proposed approach by classifying DR into five stages. It is found that the developed model achieves a weighted Kappa score of 0.90 and 0.88 for the APTOS and EyePACS datasets, respectively, higher than any existing methods for detection of the five stages of DR      
### 29.Light Field Image Coding Using VVC standard and View Synthesis based on Dual Discriminator GAN  [ :arrow_down: ](https://arxiv.org/pdf/2103.04201.pdf)
>  Light field (LF) technology is considered as a promising way for providing a high-quality virtual reality (VR) content. However, such an imaging technology produces a large amount of data requiring efficient LF image compression solutions. In this paper, we propose a LF image coding method based on a view synthesis and view quality enhancement techniques. Instead of transmitting all the LF views, only a sparse set of reference views are encoded and transmitted, while the remaining views are synthesized at the decoder side. The transmitted views are encoded using the versatile video coding (VVC) standard and are used as reference views to synthesize the dropped views. The selection of non-reference dropped views is performed using a rate-distortion optimization based on the VVC temporal scalability. The dropped views are reconstructed using the LF dual discriminator GAN (LF-D2GAN) model. In addition, to ensure that the quality of the views is consistent, at the decoder, a quality enhancement procedure is performed on the reconstructed views allowing smooth navigation across views. Experimental results show that the proposed method provides high coding performance and overcomes the state-of-the-art LF image compression methods by -36.22% in terms of BD-BR and 1.35 dB in BD-PSNR. The web page of this work is available at <a class="link-external link-https" href="https://naderbakir79.github.io/LFD2GAN.html" rel="external noopener nofollow">this https URL</a>.      
### 30.Decentralized Microgrid Energy Management: A Multi-agent Correlated Q-learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.04154.pdf)
>  Microgrids (MG) are anticipated to be important players in the future smart grid. For proper operation of MGs an Energy Management System (EMS) is essential. The EMS of an MG could be rather complicated when renewable energy resources (RER), energy storage system (ESS) and demand side management (DSM) need to be orchestrated. Furthermore, these systems may belong to different entities and competition may exist between them. Nash equilibrium is most commonly used for coordination of such entities however the convergence and existence of Nash equilibrium can not always be guaranteed. To this end, we use the correlated equilibrium to coordinate agents, whose convergence can be guaranteed. In this paper, we build an energy trading model based on mid-market rate, and propose a correlated Q-learning (CEQ) algorithm to maximize the revenue of each agent. Our results show that CEQ is able to balance the revenue of agents without harming total benefit. In addition, compared with Q-learning without correlation, CEQ could save 19.3% cost for the DSM agent and 44.2% more benefits for the ESS agent.      
### 31.Correlated Deep Q-learning based Microgrid Energy Management  [ :arrow_down: ](https://arxiv.org/pdf/2103.04152.pdf)
>  Microgrid (MG) energy management is an important part of MG operation. Various entities are generally involved in the energy management of an MG, e.g., energy storage system (ESS), renewable energy resources (RER) and the load of users, and it is crucial to coordinate these entities. Considering the significant potential of machine learning techniques, this paper proposes a correlated deep Q-learning (CDQN) based technique for the MG energy management. Each electrical entity is modeled as an agent which has a neural network to predict its own Q-values, after which the correlated Q-equilibrium is used to coordinate the operation among agents. In this paper, the Long Short Term Memory networks (LSTM) based deep Q-learning algorithm is introduced and the correlated equilibrium is proposed to coordinate agents. The simulation result shows 40.9% and 9.62% higher profit for ESS agent and photovoltaic (PV) agent, respectively.      
### 32.Investigating on Incorporating Pretrained and Learnable Speaker Representations for Multi-Speaker Multi-Style Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2103.04088.pdf)
>  The few-shot multi-speaker multi-style voice cloning task is to synthesize utterances with voice and speaking style similar to a reference speaker given only a few reference samples. In this work, we investigate different speaker representations and proposed to integrate pretrained and learnable speaker representations. Among different types of embeddings, the embedding pretrained by voice conversion achieves the best performance. The FastSpeech 2 model combined with both pretrained and learnable speaker representations shows great generalization ability on few-shot speakers and achieved 2nd place in the one-shot track of the ICASSP 2021 M2VoC challenge.      
### 33.Using Image Processing Techniques to Increase Safety in Shooting Ranges  [ :arrow_down: ](https://arxiv.org/pdf/2103.04052.pdf)
>  Accidents are a leading cause of deaths in armed forces. The Aim of this paper is to minimize the accidents caused using weapons in the armed forces. Developing artificial intelligence technologies aim to increase efficiency more and more wherever people exist. Giving guns to inexperienced, untrained, or unpredictable mentally unhealthy people in shooting ranges used for gun training can be risky and fatal. With the use of image processing technologies in these shooting ranges, it is aimed to minimize the risk of life-threatening accidents that may be caused by this people. Artificial intelligence is trained for the targets to be used in shooting ranges. When the camera of weapon sees these targets, it switches from safe mode to firing mode. When a risky situation occurs in shooting range, the gun turns itself into safe mode with various additional security measures.      
### 34.Memory-efficient Learning for High-Dimensional MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2103.04003.pdf)
>  Deep learning (DL) based unrolled reconstructions have shown state-of-the-art performance for under-sampled magnetic resonance imaging (MRI). Similar to compressed sensing, DL can leverage high-dimensional data (e.g. 3D, 2D+time, 3D+time) to further improve performance. However, network size and depth are currently limited by the GPU memory required for backpropagation. Here we use a memory-efficient learning (MEL) framework which favorably trades off storage with a manageable increase in computation during training. Using MEL with multi-dimensional data, we demonstrate improved image reconstruction performance for in-vivo 3D MRI and 2D+time cardiac cine MRI. MEL uses far less GPU memory while marginally increasing the training time, which enables new applications of DL to high-dimensional MRI.      
### 35.On the LRD of the Aggregated Traffic Flows in High-Speed Computer Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.03981.pdf)
>  This paper studies and analyses the behavior of the Long-Range Dependence in network traffic after classifying traffic flows in aggregated time series. Following Differentiated Services architecture principles, the generic Quality of Service applications that requirements and use the transport control protocol, a basic classification criterion of time series is established. Using the fractal theory, the resulting time series are analyzed. The Hurst exponent is estimated and used as a measure of traffic burstiness and Long-Range Dependency in each traffic class. The traffic volume per class is also measured. The study uses traffic traces collected at the core switch at the Electric Engineering Department at Universidad de Santiago de Chile in different periods of network activity.      
### 36.Incorporating Wireless Communication Parameters into the E-Model Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2103.03970.pdf)
>  Telecommunication service providers have to guarantee acceptable speech quality during a phone call to avoid a negative impact on the users' quality of experience. Currently, there are different speech quality assessment methods. ITU-T Recommendation G.107 describes the E-model algorithm, which is a computational model developed for network planning purposes focused on narrowband (NB) networks. Later, ITU-T Recommendations G.107.1 and G.107.2 were developed for wideband (WB) and fullband (FB) networks. These algorithms use different impairment factors, each one related to different speech communication steps. However, the NB, WB, and FB E-model algorithms do not consider wireless techniques used in these networks, such as Multiple-Input-Multiple-Output (MIMO) systems, which are used to improve the communication system robustness in the presence of different types of wireless channel degradation. In this context, the main objective of this study is to propose a general methodology to incorporate wireless network parameters into the NB and WB E-model algorithms. To accomplish this goal, MIMO and wireless channel parameters are incorporated into the E-model algorithms, specifically into the $I_{e,eff}$ and $I_{e,eff,WB}$ impairment factors. For performance validation, subjective tests were carried out, and the proposed methodology reached a Pearson correlation coefficient (PCC) and a root mean square error (RMSE) of $0.9732$ and $0.2351$, respectively. It is noteworthy that our proposed methodology does not affect the rest of the E-model input parameters, and it intends to be useful for wireless network planning in speech communication services.      
### 37.ODAS: Open embeddeD Audition System  [ :arrow_down: ](https://arxiv.org/pdf/2103.03954.pdf)
>  Artificial audition aims at providing hearing capabilities to machines, computers and robots. Existing frameworks in robot audition offer interesting sound source localization, tracking and separation performance, but involve a significant amount of computations that limit their use on robots with embedded computing capabilities. This paper presents ODAS, the Open embeddeD Audition System framework, which includes strategies to reduce the computational load and perform robot audition tasks on low-cost embedded computing systems. It presents key features of ODAS, along with cases illustrating its uses in different robots and artificial audition applications.      
### 38.Sampled-Data Stabilization with Control Lyapunov Functions via Quadratically Constrained Quadratic Programs  [ :arrow_down: ](https://arxiv.org/pdf/2103.03937.pdf)
>  Controller design for nonlinear systems with Control Lyapunov Function (CLF) based quadratic programs has recently been successfully applied to a diverse set of difficult control tasks. These existing formulations do not address the gap between design with continuous time models and the discrete time sampled implementation of the resulting controllers, often leading to poor performance on hardware platforms. We propose an approach to close this gap by synthesizing sampled-data counterparts to these CLF-based controllers, specified as quadratically constrained quadratic programs (QCQPs). Assuming feedback linearizability and stable zero-dynamics of a system's continuous time model, we derive practical stability guarantees for the resulting sampled-data system. We demonstrate improved performance of the proposed approach over continuous time counterparts in simulation.      
### 39.Prosumer Behavior: Decision Making with Bounded Horizon  [ :arrow_down: ](https://arxiv.org/pdf/2103.03932.pdf)
>  Most studies of prosumer decision making in the smart grid have focused on single, temporally discrete decisions within the framework of expected utility theory (EUT) and behavioral theories such as prospect theory. In this work, we study prosumer decision making in a more natural, ongoing market situation in which a prosumer has to decide every day whether to sell any surplus energy units generated by the solar panels on her roof or hold (store) the energy units in anticipation of a future sale at a better price. Within this context, we propose a new behavioral model that extends EUT to take into account the notion of a bounded temporal horizon over which various decision parameters are considered. Specifically, we introduce the notion of a bounded time window (the number of upcoming days over which a prosumer evaluates the probability that each possible price will be the highest) that prosumers implicitly impose on their decision making in arriving at hold or sell decisions. The new behavioral model assumes that humans make decisions that will affect their lives within a bounded time window regardless of how far into the future their units may be sold. Modeling the utility of the prosumer using parameters such as the offered price on a day, the number of energy units the prosumer has available for sale on a day, and the probabilities of the forecast prices, we fit both traditional EUT and the proposed behavioral model with bounded time windows to data collected from 57 homeowners over 68 days in a simulated energy market. Each prosumer generated surplus units of solar power and had the opportunity to sell those units to the local utility at the price set that day by the utility or hold the units for sale in the future. For most participants, a bounded horizon in the range of 4-5 days provided a much better fit to their responses than was found for the traditional (unbounded) EUT model      
### 40.Hybrid Relay-Reflecting Intelligent Surface-Assisted Wireless Communication  [ :arrow_down: ](https://arxiv.org/pdf/2103.03900.pdf)
>  Reconfigurable intelligent surface (RIS) has emerged as a cost- and energy-efficient solution to enhance the wireless communication capacity. However, recent studies show that a very large surface is required for a RIS-assisted communication system; otherwise, they may be outperformed by the conventional relay. Furthermore, the performance gain of a RIS can be considerably degraded by hardware impairments such as limited-resolution phase shifters. To overcome those challenges, we propose a novel concept of hybrid relay-reflecting intelligent surface (HR-RIS), in which a single or few elements are deployed with power amplifiers (PAs) to serve as active relays, while the remaining elements only reflect the incident signals. Two architectures are proposed, including the fixed and dynamic HR-RIS. Their coefficient matrices are obtained based on alternating optimization (AO) and power allocation strategies, which enable understanding the fundamental performances of RIS and relaying-based systems with a trade-off between the two. The simulation results show that a significant improvement in both the spectral efficiency (SE) and energy efficiency (EE) with respect to the conventional RIS-aided system can be attained by the proposed schemes, especially, by the dynamic HR-RIS. In particular, the favorable design and deployment of the HR-RIS are analytically derived and numerically justified.      
### 41.Neural network-based image reconstruction in swept-source optical coherence tomography using undersampled spectral data  [ :arrow_down: ](https://arxiv.org/pdf/2103.03877.pdf)
>  Optical Coherence Tomography (OCT) is a widely used non-invasive biomedical imaging modality that can rapidly provide volumetric images of samples. Here, we present a deep learning-based image reconstruction framework that can generate swept-source OCT (SS-OCT) images using undersampled spectral data, without any spatial aliasing artifacts. This neural network-based image reconstruction does not require any hardware changes to the optical set-up and can be easily integrated with existing swept-source or spectral domain OCT systems to reduce the amount of raw spectral data to be acquired. To show the efficacy of this framework, we trained and blindly tested a deep neural network using mouse embryo samples imaged by an SS-OCT system. Using 2-fold undersampled spectral data (i.e., 640 spectral points per A-line), the trained neural network can blindly reconstruct 512 A-lines in ~6.73 ms using a desktop computer, removing spatial aliasing artifacts due to spectral undersampling, also presenting a very good match to the images of the same samples, reconstructed using the full spectral OCT data (i.e., 1280 spectral points per A-line). We also successfully demonstrate that this framework can be further extended to process 3x undersampled spectral data per A-line, with some performance degradation in the reconstructed image quality compared to 2x spectral undersampling. This deep learning-enabled image reconstruction approach can be broadly used in various forms of spectral domain OCT systems, helping to increase their imaging speed without sacrificing image resolution and signal-to-noise ratio.      
### 42.Model Predictive Control of a Vehicle using Koopman Operator  [ :arrow_down: ](https://arxiv.org/pdf/2103.04978.pdf)
>  This paper continues in the work from <a class="link-https" data-arxiv-id="1903.06103" href="https://arxiv.org/abs/1903.06103">arXiv:1903.06103</a> [math.OC] where a nonlinear vehicle model was approximated in a purely data-driven manner by a linear predictor of higher order, namely the Koopman operator. The vehicle system typically features a lot of nonlinearities such as rigid-body dynamics, coordinate system transformations and most importantly the tire. These nonlinearities are approximated in a predefined subset of the state-space by the linear Koopman operator and used for a linear Model Predictive Control (MPC) design in the high-dimension state space where the nonlinear system dynamics evolve linearly. The result is a nonlinear MPC designed by linear methodologies. It is demonstrated that the Koopman-based controller is able to recover from a very unusual state of the vehicle where all the aforementioned nonlinearities are dominant. The controller is compared with a controller based on a classic local linearization and shortcomings of this approach are discussed.      
### 43.A Crash Course on Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.04910.pdf)
>  The emerging field of Reinforcement Learning (RL) has led to impressive results in varied domains like strategy games, robotics, etc. This handout aims to give a simple introduction to RL from control perspective and discuss three possible approaches to solve an RL problem: Policy Gradient, Policy Iteration, and Model-building. Dynamical systems might have discrete action-space like cartpole where two possible actions are +1 and -1 or continuous action space like linear Gaussian systems. Our discussion covers both cases.      
### 44.Deep learning, machine vision in agriculture in 2021  [ :arrow_down: ](https://arxiv.org/pdf/2103.04893.pdf)
>  Over the past decade, unprecedented progress in the development of neural networks influenced dozens of different industries, including weed recognition in the agro-industrial sector. The use of neural networks in agro-industrial activity in the task of recognizing cultivated crops is a new direction. The absence of any standards significantly complicates the understanding of the real situation of the use of the neural network in the agricultural sector. The manuscript presents the complete analysis of researches over the past 10 years on the use of neural networks for the classification and tracking of weeds due to neural networks. In particular, the analysis of the results of using various neural network algorithms for the task of classification and tracking was presented. As a result, we presented the recommendation for the use of neural networks in the tasks of recognizing a cultivated object and weeds. Using this standard can significantly improve the quality of research on this topic and simplify the analysis and understanding of any paper.      
### 45.The Weakly-Labeled Rand Index  [ :arrow_down: ](https://arxiv.org/pdf/2103.04872.pdf)
>  Synthetic Aperture Sonar (SAS) surveys produce imagery with large regions of transition between seabed types. Due to these regions, it is difficult to label and segment the imagery and, furthermore, challenging to score the image segmentations appropriately. While there are many approaches to quantify performance in standard crisp segmentation schemes, drawing hard boundaries in remote sensing imagery where gradients and regions of uncertainty exist is inappropriate. These cases warrant weak labels and an associated appropriate scoring approach. In this paper, a labeling approach and associated modified version of the Rand index for weakly-labeled data is introduced to address these issues. Results are evaluated with the new index and compared to traditional segmentation evaluation methods. Experimental results on a SAS data set containing must-link and cannot-link labels show that our Weakly-Labeled Rand index scores segmentations appropriately in reference to qualitative performance and is more suitable than traditional quantitative metrics for scoring weakly-labeled data.      
### 46.Geometrical Representation for Number-theoretic Transforms  [ :arrow_down: ](https://arxiv.org/pdf/2103.04832.pdf)
>  This short note introduces a geometric representation for binary (or ternary) sequences. The proposed representation is linked to multivariate data plotting according to the radar chart. As an illustrative example, the binary Hamming transform recently proposed is geometrically interpreted. It is shown that codewords of standard Hamming code $\mathcal{H}(N=7,k=4,d=3)$ are invariant vectors under the Hamming transform. These invariant are eigenvectors of the binary Hamming transform. The images are always inscribed in a regular polygon of unity side, resembling triangular rose petals and/or ``thorns''. A geometric representation of the ternary Golay transform, based on the extended Golay $\mathcal{G}(N=12, k=6, d=6)$ code over $\operatorname{GF}(3)$ is also showed. This approach is offered as an alternative representation of finite-length sequences over finite prime fields.      
### 47.Stability assessment of reaction-diffusion PDEs coupled at the boundaries with an ODE  [ :arrow_down: ](https://arxiv.org/pdf/2103.04775.pdf)
>  This paper addresses the derivation of sufficient linear matrix inequality conditions ensuring the stability of a coupled system composed of a reaction-diffusion partial differential equation (PDE), with possibly spatially-varying coefficients, and a finite-dimensional linear time invariant ordinary differential equation (ODE). The coupling of the PDE with the ODE is located at both left and right boundary conditions of the reaction-diffusion equation and takes the form of the input and output of the ODE. We investigate the four possible sets of left/right boundary couplings among Dirichlet and Neumann traces. The adopted approach relies on the spectral reduction of the problem by projecting the trajectory of the PDE into a Hilbert basis composed of the eigenvectors of the underlying Sturm-Liouville operator. We propose numerical examples, consisting of an unstable reaction-diffusion equation and an unstable ODE, such that the application of the derived stability conditions ensure the stability of the resulting coupled PDE-ODE system.      
### 48.Applicability and Surrogacy of Uncorrelated Airspace Encounter Models at Low Altitudes  [ :arrow_down: ](https://arxiv.org/pdf/2103.04753.pdf)
>  The National Airspace System (NAS) is a complex and evolving system that enables safe and efficient aviation. Advanced air mobility concepts and new airspace entrants, such as unmanned aircraft, must integrate into the NAS without degrading overall safety or efficiency. For instance, regulations, standards, and systems are required to mitigate the risk of a midair collision between aircraft. Monte Carlo simulations have been a foundational capability for decades to develop, assess, and certify aircraft conflict avoidance systems. These are often validated through human-in-the-loop experiments and flight testing. <br>For many aviation safety studies, manned aircraft behavior is represented using dynamic Bayesian networks. The original statistical models were developed from 2008-2013 to support safety simulations for altitudes above 500 feet Above Ground Level (AGL). However, these models were not sufficient to assess the safety of smaller UAS operations below 500 feet AGL. In response, newer models with altitude floors below 500 feet AGL have been in development since 2018. Many of the models assume that aircraft behavior is uncorrelated and not dependent on air traffic services or nearby aircraft. <br>Our research objective was to compare the various uncorrelated models of conventional aircraft and identify how the models differ. Particularly if models of rotorcraft were sufficiently different than models of fixed-wing aircraft to require type specific models. The primary contribution is guidance on which uncorrelated models to leverage when evaluating the performance of a collision avoidance system designed for low altitude operations. We also address which models can be surrogates for noncooperative aircraft without transponders.      
### 49.Sparse Kronecker-Product Coding for Unsourced Multiple Access  [ :arrow_down: ](https://arxiv.org/pdf/2103.04722.pdf)
>  In this paper, a sparse Kronecker-product (SKP) coding scheme is proposed for unsourced multiple access. Specifically, the data of each active user is encoded as the Kronecker product of two component codewords with one being sparse and the other being forward-error-correction (FEC) coded. At the receiver, an iterative decoding algorithm is developed, consisting of matrix factorization for the decomposition of the Kronecker product and soft-in soft-out decoding for the component sparse code and the FEC code. The cyclic redundancy check (CRC) aided interference cancelation technique is further incorporated for performance improvement. Numerical results show that the proposed scheme outperforms the state-of-the-art counterparts, and approaches the random coding bound within a gap of only 0.1 dB at the code length of 30000 when the number of active users is less than 75, and the error rate can be made much lower than the existing schemes, especially when the number of active users is relatively large.      
### 50.Bayesian imaging using Plug &amp; Play priors: when Langevin meets Tweedie  [ :arrow_down: ](https://arxiv.org/pdf/2103.04715.pdf)
>  Since the seminal work of Venkatakrishnan et al. (2013), Plug &amp; Play (PnP) methods have become ubiquitous in Bayesian imaging. These methods derive Minimum Mean Square Error (MMSE) or Maximum A Posteriori (MAP) estimators for inverse problems in imaging by combining an explicit likelihood function with a prior that is implicitly defined by an image denoising algorithm. The PnP algorithms proposed in the literature mainly differ in the iterative schemes they use for optimisation or for sampling. In the case of optimisation schemes, some recent works guarantee the convergence to a fixed point, albeit not necessarily a MAP estimate. In the case of sampling schemes, to the best of our knowledge, there is no known proof of convergence. There also remain important open questions regarding whether the underlying Bayesian models and estimators are well defined, well-posed, and have the basic regularity properties required to support these numerical schemes. To address these limitations, this paper develops theory, methods, and provably convergent algorithms for performing Bayesian inference with PnP priors. We introduce two algorithms: 1) PnP-ULA (Unadjusted Langevin Algorithm) for Monte Carlo sampling and MMSE inference; and 2) PnP-SGD (Stochastic Gradient Descent) for MAP inference. Using recent results on the quantitative convergence of Markov chains, we establish detailed convergence guarantees for these two algorithms under realistic assumptions on the denoising operators used, with special attention to denoisers based on deep neural networks. We also show that these algorithms approximately target a decision-theoretically optimal Bayesian model that is well-posed. The proposed algorithms are demonstrated on several canonical problems such as image deblurring, inpainting, and denoising, where they are used for point estimation as well as for uncertainty visualisation and quantification.      
### 51.An auditory cortex model for sound processing  [ :arrow_down: ](https://arxiv.org/pdf/2103.04608.pdf)
>  The reconstruction mechanisms built by the human auditory system during sound reconstruction are still a matter of debate. The purpose of this study is to refine the auditory cortex model introduced in [9], and inspired by the geometrical modelling of vision. The algorithm transforms the degraded sound in an 'image' in the time-frequency domain via a short-time Fourier transform. Such an image is then lifted in the Heisenberg group and it is reconstructed via a Wilson-Cowan differo-integral equation. Numerical experiments on a library of speech recordings are provided, showing the good reconstruction properties of the algorithm.      
### 52.Implicit Linear Algebra and Basic Circuit Theory II: port behaviour of rigid multiports  [ :arrow_down: ](https://arxiv.org/pdf/2103.04592.pdf)
>  n this paper, we define the notion of rigidity for linear electrical multiports and for matroid pairs. We show the parallel between the two and study the consequences of this parallel. We <br>present applications to testing, using purely matroidal methods, whether a connection of rigid multiports yields a <br>linear network with unique solution. We also indicate that rigidity can be regarded as the closest notion to duality that can be hoped for, <br>when the spaces correspond to different physical constraints, such as topological and device characteristic. <br>A multiport is an ordered pair $(\V^1_{AB},\A^2_{B}),$ where $\V^1_{AB}$ is the solution space on $A\uplus B$ of the Kirchhoff current and voltage equations of the graph of the multiport and $\A^2_{B}\equivd \alpha_B+\V^2_B$ is the device characteristic of the multiport, with $A$ corresponding to port voltages and currents and $B$ corresponding to internal voltages and currents. <br>The pair $\{\V^1_{AB},\alpha_B+\V^2_{B}\}$ is said to be rigid iff it has a solution $(x_A,x_B)$ for every vector $\alpha_B$ and given a restriction $x_A$ of the solution, $x_B$ is unique. <br>A matroid $\M_S$ on $S,$ is a family of `independent' sets with the property that maximal independent sets contained in any given subset of $S$ have the same cardinality <br>The pair $\{\M^1_{AB},\M^2_{B}\}$ is said to be rigid iff the two matroids have disjoint bases which cover $B.$ We show that the properties of rigid pairs of matroids closely parallel those of rigid multiports. <br>We use the methods developed in the paper to show that a multiport with independent and controlled sources and positive or negative resistors, whose parameters can be taken to be algebraically independent over $\Q,$ is rigid, if certain simple topological conditions are satisfied by the device edges.      
### 53.Deep Gradient Projection Networks for Pan-sharpening  [ :arrow_down: ](https://arxiv.org/pdf/2103.04584.pdf)
>  Pan-sharpening is an important technique for remote sensing imaging systems to obtain high resolution multispectral images. Recently, deep learning has become the most popular tool for pan-sharpening. This paper develops a model-based deep pan-sharpening approach. Specifically, two optimization problems regularized by the deep prior are formulated, and they are separately responsible for the generative models for panchromatic images and low resolution multispectral images. Then, the two problems are solved by a gradient projection algorithm, and the iterative steps are generalized into two network blocks. By alternatively stacking the two blocks, a novel network, called gradient projection based pan-sharpening neural network, is constructed. The experimental results on different kinds of satellite datasets demonstrate that the new network outperforms state-of-the-art methods both visually and quantitatively. The codes are available at <a class="link-external link-https" href="https://github.com/xsxjtu/GPPNN" rel="external noopener nofollow">this https URL</a>.      
### 54.Learning Unstable Dynamics with One Minute of Data: A Differentiation-based Gaussian Process Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.04548.pdf)
>  We present a straightforward and efficient way to estimate dynamics models for unstable robotic systems. Specifically, we show how to exploit the differentiability of Gaussian processes to create a state-dependent linearized approximation of the true continuous dynamics. Our approach is compatible with most Gaussian process approaches for system identification, and can learn an accurate model using modest amounts of training data. We validate our approach by iteratively learning the system dynamics of an unstable system such as a 9-D segway (using only one minute of data) and we show that the resulting controller is robust to unmodelled dynamics and disturbances, while state-of-the-art control methods based on nominal models can fail under small perturbations.      
### 55.Phase Reduction and Synchronization of Coupled Noisy Oscillators  [ :arrow_down: ](https://arxiv.org/pdf/2103.04492.pdf)
>  We study the synchronization behavior of a noisy network in which each system is driven by two sources of state-dependent noise: (1) an intrinsic noise which is common among all systems and can be generated by the environment or any internal fluctuations, and (2) a coupling noise which is generated by interactions with other systems. After providing sufficient conditions that foster synchronization in networks of general noisy systems, we focus on weakly coupled networks of noisy oscillators and, using the first- and second-order phase response curves (PRCs), we derive a reduced order stochastic differential equation to describe the corresponding phase evolutions. Finally, we derive synchronization conditions based on the PRCs and illustrate the theoretical results on a couple of models.      
### 56.Adaptive-Control-Oriented Meta-Learning for Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.04490.pdf)
>  Real-time adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With a nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.      
### 57.Decentralized 2-Robot Transportation with Local and Indirect Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2103.04460.pdf)
>  In this paper, we propose a leader-follower hierarchical strategy for two robots collaboratively transporting an object in a partially known environment with obstacles. Both robots sense the local surrounding environment and react to obstacles in their proximity. We consider no explicit communication, so the local environment information and the control actions are not shared between the robots. At any given time step, the leader solves a model predictive control (MPC) problem with its known set of obstacles and plans a feasible trajectory to complete the task. The follower estimates the inputs of the leader and uses a policy to assist the leader while reacting to obstacles in its proximity. The leader infers obstacles in the follower's vicinity by using the difference between the predicted and the real-time estimated follower control action. A method to switch the leader-follower roles is used to improve the control performance in tight environments. The efficacy of our approach is demonstrated with detailed comparisons to two alternative strategies, where it achieves the highest success rate, while completing the task fastest.      
### 58.Correct-by-Construction Navigation Functions with Application to Sensor Based Robot Navigation  [ :arrow_down: ](https://arxiv.org/pdf/2103.04445.pdf)
>  This paper brings together the concepts of navigation transformation and harmonic functions to form navigation functions that are correct-by-construction in the sense that no tuning is required. The form of the navigation function is explicitly related to the number of obstacles in the environment. This enables application of navigation functions for autonomous robot navigation in partially or fully unknown environments, with the capability of on-the-fly adjustment of the navigation function when new obstacles are discovered by the robot. Appropriate navigation controllers, applicable to robots with local, sector bounded sensing, are presented and analyzed for a~kinematic point-mass robot and then for the dynamic point-mass robot system. The closed form nature of the proposed navigation scheme provides for online, fast-feedback based navigation. In addition to the analytic guarantees, simulation studies are presented to verify the effectiveness of the methodology.      
### 59.LQG control over unreliable channels-Full Proof  [ :arrow_down: ](https://arxiv.org/pdf/2103.04394.pdf)
>  In this paper LQG control over unreliable communication links is derived. That is to say, the communication channels between the controller and the actuators and between the sensors and the controller are unreliable. Previous solutions to finite horizon discrete time hold-input LQG control for this case do not fully utilize the available information. Here a new solution is presented which resolves this limitation. The focus is to derive and present a full mathematical proof to derive the optimal control sequence.      
### 60.Robopheus: A Virtual-Physical Interactive Mobile Robotic Testbed  [ :arrow_down: ](https://arxiv.org/pdf/2103.04391.pdf)
>  The mobile robotic testbed is an essential and critical support to verify the effectiveness of mobile robotics research. This paper introduces a novel multi-robot testbed, named Robopheus, which exploits the ideas of virtual-physical modeling in digital-twin. Unlike most existing testbeds, the developed Robopheus constructs a bridge that connects the traditional physical hardware and virtual simulation testbeds, providing scalable, interactive, and high-fidelity simulations-tests on both sides. Another salient feature of the Robopheus is that it enables a new form to learn the actual models from the physical environment dynamically and is compatible with heterogeneous robot chassis and controllers. In turn, the virtual world's learned models are further leveraged to approximate the robot dynamics online on the physical side. Extensive experiments demonstrate the extraordinary performance of the Robopheus. Significantly, the physical-virtual interaction design increases the trajectory accuracy of a real robot by 300%, compared with that of not using the interaction.      
### 61.Markov Cricket: Using Forward and Inverse Reinforcement Learning to Model, Predict And Optimize Batting Performance in One-Day International Cricket  [ :arrow_down: ](https://arxiv.org/pdf/2103.04349.pdf)
>  In this paper, we model one-day international cricket games as Markov processes, applying forward and inverse Reinforcement Learning (RL) to develop three novel tools for the game. First, we apply Monte-Carlo learning to fit a nonlinear approximation of the value function for each state of the game using a score-based reward model. We show that, when used as a proxy for remaining scoring resources, this approach outperforms the state-of-the-art Duckworth-Lewis-Stern method used in professional matches by 3 to 10 fold. Next, we use inverse reinforcement learning, specifically a variant of guided-cost learning, to infer a linear model of rewards based on expert performances, assumed here to be play sequences of winning teams. From this model we explicitly determine the optimal policy for each state and find this agrees with common intuitions about the game. Finally, we use the inferred reward models to construct a game simulator that models the posterior distribution of final scores under different policies. We envisage our prediction and simulation techniques may provide a fairer alternative for estimating final scores in interrupted games, while the inferred reward model may provide useful insights for the professional game to optimize playing strategy. Further, we anticipate our method of applying RL to this game may have broader application to other sports with discrete states of play where teams take turns, such as baseball and rounders.      
### 62.Inter-Carrier Interference Mitigation for Differentially Coherent Detection in Underwater Acoustic OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.04341.pdf)
>  Suppressing the inter-carrier interference (ICI) is crucial for differentially coherent detection in underwater acoustic (UWA) orthogonal frequency division multiplexing (OFDM) systems due to the fact that the UWA channel is inherently violently Doppler-shifted. In this paper, we propose a new ICI suppression method, referred to as the partially-shifted fast Fourier transform (PS-FFT), which eliminates the ICI from both the time and frequency domains. Specifically, the PS-FFT first divides the received signal in the entire block duration into several short non-overlapping ones to reduce the channel variation in the time domain. It then applies the Fourier transform at several predefined frequencies to the received signal in each of these intervals to compensate Doppler shifts in the frequency domain. Finally, it weightedly combines the multiple demodulator outputs at each carrier as one output for symbol detection, with the combiner weights being solved by the stochastic gradient algorithm. Simulation results show that the PS-FFT dramatically outperforms the existing classical methods, the partial fast Fourier transform (P-FFT) and the fractional fast Fourier transform (F-FFT), for both medium and high Doppler factors and large carrier numbers in terms of the mean squared error (MSE). Numerically, the MSE of the PS-FFT is reduced by $\bf{61.83\%-84.89\%}$ compared to that of the F-FFT when the input signal-to-noise ratio (SNR) at the receiver ranges from 10 dB to 30 dB at a Doppler factor of $\bf{3\times 10^{-4}}$ and a carrier number of 1024 where the P-FFT even cannot work.      
### 63.Resource Distribution Under Spatiotemporal Uncertainty of Disease Spread: Stochastic versus Robust Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2103.04266.pdf)
>  Speeding up testing and vaccination is essential to controlling the coronavirus disease 2019 (COVID-19) pandemic that has became a global health crisis. In this paper, we develop mathematical frameworks for optimizing locations of distribution centers and plans for distributing resources such as test kits and vaccines under spatiotemporal uncertainties of infection and demand trends. We aim to balance between operational cost (including costs of deploying facilities, shipping and storage) and quality of service (reflected by delivery speed and demand coverage), while ensuring equity and fairness of resource distribution based on historical infection data and demographics of estimated demand. Using weighted multiple objectives, we formulate a stochastic integer program and also seek robust solutions against the distributional ambiguity of demand. For the latter, we propose a distributionally robust optimization model using a moment ambiguity set, and derive monolithic reformulations depending on specific forms of this set. We compare different approaches by solving instances generated using real COVID-19 infection data for distributing vaccines and test kits over the United States and the State of Michigan, respectively. We demonstrate results over distinct phases of the pandemic to estimate cost and speed of resource distribution depending on the scales and coverage. approaches always outperform the deterministic one. If we prioritize the worst-case performance in terms of unmet demand (i.e., untested or unvaccinated people who qualify), then the distributionally robust approach is preferred despite of its higher overall cost. Nevertheless, the stochastic programming approach can provide an intermediate plan under budgetary restrictions without significant compromises in demand coverage.      
### 64.Cascaded Filtering Using the Sigma Point Transformation (Extended Version)  [ :arrow_down: ](https://arxiv.org/pdf/2103.04249.pdf)
>  It is often convenient to separate a state estimation task into smaller "local" tasks, where each local estimator estimates a subset of the overall system state. However, neglecting cross-covariance terms between state estimates can result in overconfident estimates, which can ultimately degrade the accuracy of the estimator. Common cascaded filtering techniques focus on the problem of modelling cross-covariances when the local estimators share a common state vector. This letter introduces a novel cascaded and decentralized filtering approach that approximates the cross-covariances when the local estimators consider distinct state vectors. The proposed estimator is validated in simulations and in experiments on a three-dimensional attitude and position estimation problem. The proposed approach is compared to a naive cascaded filtering approach that neglects cross-covariance terms, a sigma point-based Covariance Intersection filter, and a full-state filter. In both simulations and experiments, the proposed filter outperforms the naive and the Covariance Intersection filters, while performing comparatively to the full-state filter.      
### 65.Selective Encryption of the Versatile Video Coding Standard  [ :arrow_down: ](https://arxiv.org/pdf/2103.04203.pdf)
>  Versatile video coding (VVC) is the next generation video coding standard developed by the joint video experts team (JVET) and released in July 2020. VVC introduces several new coding tools providing a significant coding gain over the high efficiency video coding (HEVC) standard. It is well known that increasing the coding efficiency adds more dependencies in the video bitstream making format-compliant encryption with the standard more challenging. In this paper we tackle the problem of selective encryption of the VVC standard in format-compliant and constant bitrate. These two constraints ensure that the encrypted bitstream can be decoded by any VVC decoder while the bitrate remains unchanged by the encryption. The selective encryption of all possible VVC syntax elements is investigated. A new algorithm is proposed to encrypt in format-compliant and constant bitrate the transform coefficients (TCs) together with other syntax elements at the level of the entropy encoder. The proposed solution was integrated and assessed under the VVC reference software model version 6.0. Experimental results showed that the encryption drastically decreases the video quality while the encryption is robust against several types of attacks. The encryption space is estimated in the range of 15% to 26% of the bitstream size resulting in a lightweight encryption process. The web page of this work is available at <a class="link-external link-https" href="https://gugautie.github.io/sevvc/" rel="external noopener nofollow">this https URL</a>.      
### 66.High Perceptual Quality Image Denoising with a Posterior Sampling CGAN  [ :arrow_down: ](https://arxiv.org/pdf/2103.04192.pdf)
>  The vast work in Deep Learning (DL) has led to a leap in image denoising research. Most DL solutions for this task have chosen to put their efforts on the denoiser's architecture while maximizing distortion performance. However, distortion driven solutions lead to blurry results with sub-optimal perceptual quality, especially in immoderate noise levels. In this paper we propose a different perspective, aiming to produce sharp and visually pleasing denoised images that are still faithful to their clean sources. Formally, our goal is to achieve high perceptual quality with acceptable distortion. This is attained by a stochastic denoiser that samples from the posterior distribution, trained as a generator in the framework of conditional generative adversarial networks (CGANs). Contrary to distortion-based regularization terms that conflict with perceptual quality, we introduce to the CGANs objective a theoretically founded penalty term that does not force a distortion requirement on individual samples, but rather on their mean. We showcase our proposed method with a novel denoiser architecture that achieves the reformed denoising goal and produces vivid and diverse outcomes in immoderate noise levels.      
### 67.Signal Processing on the Permutahedron: Tight Spectral Frames for Ranked Data Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.04150.pdf)
>  Ranked data sets, where m judges/voters specify a preference ranking of n objects/candidates, are increasingly prevalent in contexts such as political elections, computer vision, recommender systems, and bioinformatics. The vote counts for each ranking can be viewed as an n! data vector lying on the permutahedron, which is a Cayley graph of the symmetric group with vertices labeled by permutations and an edge when two permutations differ by an adjacent transposition. Leveraging combinatorial representation theory and recent progress in signal processing on graphs, we investigate a novel, scalable transform method to interpret and exploit structure in ranked data. We represent data on the permutahedron using an overcomplete dictionary of atoms, each of which captures both smoothness information about the data (typically the focus of spectral graph decomposition methods in graph signal processing) and structural information about the data (typically the focus of symmetry decomposition methods from representation theory). These atoms have a more naturally interpretable structure than any known basis for signals on the permutahedron, and they form a Parseval frame, ensuring beneficial numerical properties such as energy preservation. We develop specialized algorithms and open software that take advantage of the symmetry and structure of the permutahedron to improve the scalability of the proposed method, making it more applicable to the high-dimensional ranked data found in applications.      
### 68.Linear Regression over Networks with Communication Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2103.04140.pdf)
>  A key functionality of emerging connected autonomous systems such as smart cities, smart transportation systems, and the industrial Internet-of-Things, is the ability to process and learn from data collected at different physical locations. This is increasingly attracting attention under the terms of distributed learning and federated learning. However, in connected autonomous systems, data transfer takes place over communication networks with often limited resources. This paper examines algorithms for communication-efficient learning for linear regression tasks by exploiting the informativeness of the data. The developed algorithms enable a tradeoff between communication and learning with theoretical performance guarantees and efficient practical implementations.      
### 69.Perception Framework through Real-Time Semantic Segmentation and Scene Recognition on a Wearable System for the Visually Impaired  [ :arrow_down: ](https://arxiv.org/pdf/2103.04136.pdf)
>  As the scene information, including objectness and scene type, are important for people with visual impairment, in this work we present a multi-task efficient perception system for the scene parsing and recognition tasks. Building on the compact ResNet backbone, our designed network architecture has two paths with shared parameters. In the structure, the semantic segmentation path integrates fast attention, with the aim of harvesting long-range contextual information in an efficient manner. Simultaneously, the scene recognition path attains the scene type inference by passing the semantic features into semantic-driven attention networks and combining the semantic extracted representations with the RGB extracted representations through a gated attention module. In the experiments, we have verified the systems' accuracy and efficiency on both public datasets and real-world scenes. This system runs on a wearable belt with an Intel RealSense LiDAR camera and an Nvidia Jetson AGX Xavier processor, which can accompany visually impaired people and provide assistive scene information in their navigation tasks.      
### 70.Panoptic Lintention Network: Towards Efficient Navigational Perception for the Visually Impaired  [ :arrow_down: ](https://arxiv.org/pdf/2103.04128.pdf)
>  Classic computer vision algorithms, instance segmentation, and semantic segmentation can not provide a holistic understanding of the surroundings for the visually impaired. In this paper, we utilize panoptic segmentation to assist the navigation of visually impaired people by offering both things and stuff awareness in the proximity of the visually impaired efficiently. To this end, we propose an efficient Attention module -- Lintention which can model long-range interactions in linear time using linear space. Based on Lintention, we then devise a novel panoptic segmentation model which we term Panoptic Lintention Net. Experiments on the COCO dataset indicate that the Panoptic Lintention Net raises the Panoptic Quality (PQ) from 39.39 to 41.42 with 4.6\% performance gain while only requiring 10\% fewer GFLOPs and 25\% fewer parameters in the semantic branch. Furthermore, a real-world test via our designed compact wearable panoptic segmentation system, indicates that our system based on the Panoptic Lintention Net accomplishes a relatively stable and exceptionally remarkable panoptic segmentation in real-world scenes.      
### 71.Analysis and Assessment of Controllability of an Expressive Deep Learning-based TTS system  [ :arrow_down: ](https://arxiv.org/pdf/2103.04097.pdf)
>  In this paper, we study the controllability of an Expressive TTS system trained on a dataset for a continuous control. The dataset is the Blizzard 2013 dataset based on audiobooks read by a female speaker containing a great variability in styles and expressiveness. Controllability is evaluated with both an objective and a subjective experiment. The objective assessment is based on a measure of correlation between acoustic features and the dimensions of the latent space representing expressiveness. The subjective assessment is based on a perceptual experiment in which users are shown an interface for Controllable Expressive TTS and asked to retrieve a synthetic utterance whose expressiveness subjectively corresponds to that a reference utterance.      
### 72.Gradient-augmented Supervised Learning of Optimal Feedback Laws Using State-dependent Riccati Equations  [ :arrow_down: ](https://arxiv.org/pdf/2103.04091.pdf)
>  A supervised learning approach for the solution of large-scale nonlinear stabilization problems is presented. A stabilizing feedback law is trained from a dataset generated from State-dependent Riccati Equation solves. The training phase is enriched by the use gradient information in the loss function, which is weighted through the use of hyperparameters. High-dimensional nonlinear stabilization tests demonstrate that real-time sequential large-scale Algebraic Riccati Equation solves can be substituted by a suitably trained feedforward neural network.      
### 73.Morphological Operation Residual Blocks: Enhancing 3D Morphological Feature Representation in Convolutional Neural Networks for Semantic Segmentation of Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.04026.pdf)
>  The shapes and morphology of the organs and tissues are important prior knowledge in medical imaging recognition and segmentation. The morphological operation is a well-known method for morphological feature extraction. As the morphological operation is performed well in hand-crafted image segmentation techniques, it is also promising to design an approach to approximate morphological operation in the convolutional networks. However, using the traditional convolutional neural network as a black-box is usually hard to specify the morphological operation action. Here, we introduced a 3D morphological operation residual block to extract morphological features in end-to-end deep learning models for semantic segmentation. This study proposed a novel network block architecture that embedded the morphological operation as an infinitely strong prior in the convolutional neural network. Several 3D deep learning models with the proposed morphological operation block were built and compared in different medical imaging segmentation tasks. Experimental results showed the proposed network achieved a relatively higher performance in the segmentation tasks comparing with the conventional approach. In conclusion, the novel network block could be easily embedded in traditional networks and efficiently reinforce the deep learning models for medical imaging segmentation.      
### 74.Bilateral Control-Based Imitation Learning for Velocity-Controlled Robot  [ :arrow_down: ](https://arxiv.org/pdf/2103.04004.pdf)
>  Machine learning is now playing important role in robotic object manipulation. In addition, force control is necessary for manipulating various objects to achieve robustness against perturbations of configurations and stiffness. The author's group revealed that fast and dynamic object manipulation with force control can be obtained by bilateral control-based imitation learning. However, the method is applicable only in robots that can control torque, while it is not applicable in robots that can only follow position and velocity commands like many commercially available robots. Then, in this research, a way to implement bilateral control-based imitation learning to velocity-controlled robots is proposed. The validity of the proposed method is experimentally verified by a mopping task.      
### 75.On the relation between information and power in stochastic thermodynamic engines  [ :arrow_down: ](https://arxiv.org/pdf/2103.03986.pdf)
>  The common saying, that information is power, takes a rigorous form in stochastic thermodynamics, where a quantitative equivalence between the two helps explain the paradox of Maxwell's demon in its ability to reduce entropy. In the present paper, we build on earlier work on the interplay between the relative cost and benefits of information in producing work in cyclic operation of thermodynamic engines (by Sandberg etal. 2014). Specifically, we study the general case of overdamped particles in a time-varying potential (control action) in feedback that utilizes continuous measurements (nonlinear filtering) of a thermodynamic ensemble, to produce suitable adaptations of the second law of thermodynamics that involve information.      
### 76.Traffic Flows Analysis in High-Speed Computer Networks Using Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2103.03984.pdf)
>  This article explores the required amount of time series points from a high-speed traffic network to accurately estimate the Hurst exponent. The methodology consists in designing an experiment using estimators that are applied to time series, followed by addressing the minimum amount of points required to obtain accurate estimates of the Hurst exponent in real-time. The methodology addresses the exhaustive analysis of the Hurst exponent considering bias behavior, standard deviation, mean square error, and convergence using fractional gaussian noise signals with stationary increases. Our results show that the Whittle estimator successfully estimates the Hurst exponent in series with few points. Based on the results obtained, a minimum length for the time series is empirically proposed. Finally, to validate the results, the methodology is applied to real traffic captures in a high-speed network based on the IEEE 802.3ab standard.      
### 77.AudioVisual Speech Synthesis: A brief literature review  [ :arrow_down: ](https://arxiv.org/pdf/2103.03927.pdf)
>  This brief literature review studies the problem of audiovisual speech synthesis, which is the problem of generating an animated talking head given a text as input. Due to the high complexity of this problem, we approach it as the composition of two problems. Specifically, that of Text-to-Speech (TTS) synthesis as well as the voice-driven talking head animation. For TTS, we present models that are used to map text to intermediate acoustic representations, e.g. mel-spectrograms, as well as models that generate voice signals conditioned on these intermediate representations, i.e vocoders. For the talking-head animation problem, we categorize approaches based on whether they produce human faces or anthropomorphic figures. An attempt is also made to discuss the importance of the choice of facial models in the second case. Throughout the review, we briefly describe the most important work in audiovisual speech synthesis, trying to highlight the advantages and disadvantages of the various approaches.      
### 78.Fast On-Device Adaptation for Spiking Neural Networks via Online-Within-Online Meta-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.03901.pdf)
>  Spiking Neural Networks (SNNs) have recently gained popularity as machine learning models for on-device edge intelligence for applications such as mobile healthcare management and natural language processing due to their low power profile. In such highly personalized use cases, it is important for the model to be able to adapt to the unique features of an individual with only a minimal amount of training data. Meta-learning has been proposed as a way to train models that are geared towards quick adaptation to new tasks. The few existing meta-learning solutions for SNNs operate offline and require some form of backpropagation that is incompatible with the current neuromorphic edge-devices. In this paper, we propose an online-within-online meta-learning rule for SNNs termed OWOML-SNN, that enables lifelong learning on a stream of tasks, and relies on local, backprop-free, nested updates.      
### 79.Inverse response behaviour in the bright ring radius measurement of the Czochralski process I: Investigation  [ :arrow_down: ](https://arxiv.org/pdf/2103.03899.pdf)
>  This is the first part of a two-article series that deals with the investigation of the anomalous behaviour in the radius measurement signal of the Czochralski (Cz) process and its mitigation in a feedback control system. The inverse or anomalous behaviour is indeed a measurement signal response, which initially is opposite to that of the expected response. This is a crucial and limiting factor in feedback control system design. The paper presents the development of a rigorous 3D ray-tracing method to investigate the inverse response behaviour in the measurement signal. The results of this study provide an insight into the dynamic behaviour of the Cz growth process. It can serve as a guideline for achieving effective crystal radius control, which is addressed in the second part of this article series.      

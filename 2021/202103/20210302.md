# ArXiv eess --Tue, 2 Mar 2021
### 1.Assessing deep learning methods for the identification of kidney stones in endoscopic images  [ :arrow_down: ](https://arxiv.org/pdf/2103.01146.pdf)
>  Knowing the type (i.e., the biochemical composition) of kidney stones is crucial to prevent relapses with an appropriate treatment. During ureteroscopies, kidney stones are fragmented, extracted from the urinary tract, and their composition is determined using a morpho-constitutional analysis. This procedure is time consuming (the morpho-constitutional analysis results are only available after some days) and tedious (the fragment extraction lasts up to an hour). Identifying the kidney stone type only with the in-vivo endoscopic images would allow for the dusting of the fragments, while the morpho-constitutional analysis could be avoided. Only few contributions dealing with the in vivo identification of kidney stones were published. This paper discusses and compares five classification methods including deep convolutional neural networks (DCNN)-based approaches and traditional (non DCNN-based) ones. Even if the best method is a DCCN approach with a precision and recall of 98% and 97% over four classes, this contribution shows that a XGBoost classifier exploiting well-chosen feature vectors can closely approach the performances of DCNN classifiers for a medical application with a limited number of annotated data.      
### 2.Trilevel Scheduling Model Considering Residential Demand Flexibility of Aggregated HVACs and EVs under Distribution LMP  [ :arrow_down: ](https://arxiv.org/pdf/2103.01091.pdf)
>  Residential loads, especially heating, ventilation, and air conditioners (HVACs) and electric vehicles (EVs) have great potentials to provide demand flexibility which is an attribute of Grid-interactive Efficient Buildings (GEB). Under this new paradigm, first, EV and HVAC aggregator models are developed in this paper to represent the fleet of GEBs, in which the aggregated parameters are obtained based on a new approach of data generation and least-squares parameter estimation (DG-LSPE), which can deal with heterogenous HVACs. Then, a tri-level bidding and dispatching framework is established based on competitive distribution operation with distribution locational marginal price (DLMP). The first two levels form a bilevel model to optimize the aggregators payment and to represent the interdependency between load aggregators and the distribution system operator (DSO) using DLMP, while the third level is to dispatch the optimal load aggregation to all residents by the proposed priority list-based demand dispatching algorithm. Finally, case studies on a modified IEEE 33-Bus system illustrate three main technical reasons for payment reduction due to demand flexibility: load shift, DLMP step changes, and power losses. They can be used as general guidelines for better decision-making for future planning and operation of demand response programs.      
### 3.Comparing acoustic analyses of speech data collected remotely  [ :arrow_down: ](https://arxiv.org/pdf/2103.01059.pdf)
>  Face-to-face speech data collection has been next to impossible globally due to COVID-19 restrictions. To address this problem, simultaneous recordings of three repetitions of the cardinal vowels were made using a Zoom H6 Handy Recorder with external microphone (henceforth H6) and compared with two alternatives accessible to potential participants at home: the Zoom meeting application (henceforth Zoom) and two lossless mobile phone applications (Awesome Voice Recorder, and Recorder; henceforth Phone). F0 was tracked accurately by all devices; however, for formant analysis (F1, F2, F3) Phone performed better than Zoom, i.e. more similarly to H6. Zoom recordings also exhibited unexpected drops in intensity. The results suggest that lossless format phone recordings present a viable option for at least some phonetic studies.      
### 4.High Accuracy Visible Light Positioning Based on Multi-target Tracking Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2103.01053.pdf)
>  In this paper, we propose a multi-target image tracking algorithm based on continuously apative mean-shift (Cam-shift) and unscented Kalman filter. We improved the single-lamp tracking algorithm proposed in our previous work to multi-target tracking, and achieved better robustness in the case of occlusion, the real-time performance to complete one positioning and relatively high accuracy by dynamically adjusting the weights of the multi-target motion states. Our previous algorithm is limited to the analysis of tracking error. In this paper, the results of the tracking algorithm are evaluated with the tracking error we defined. Then combined with the double-lamp positioning algorithm, the real position of the terminal is calculated and evaluated with the positioning error we defined. Experiments show that the defined tracking error is 0.61cm and the defined positioning error for 3-D positioning is 3.29cm with the average processing time of 91.63ms per frame. Even if nearly half of the LED area is occluded, the tracking error remains at 5.25cm. All of this shows that the proposed visible light positioning (VLP) method can track multiple targets for positioning at the same time with good robustness, real-time performance and accuracy. In addition, the definition and analysis of tracking errors and positioning errors indicates the direction for future efforts to reduce errors.      
### 5.On performance bound estimation in NMPC with time-varying terminal cost  [ :arrow_down: ](https://arxiv.org/pdf/2103.01015.pdf)
>  Model predictive control (MPC) schemes are commonly designed with fixed, i.e., time-invariant, horizon length and cost functions. If no stabilizing terminal ingredients are used, stability can be guaranteed via a sufficiently long horizon. A suboptimality index can be derived that gives bounds on the performance of the MPC law over an infinite-horizon (IH). While for time-invariant schemes such index can be computed offline, less attention has been paid to time-varying strategies with adapting cost function which can be found, e.g., in learning-based optimal control. This work addresses the performance bounds of nonlinear MPC with stabilizing horizon and time-varying terminal cost. A scheme is proposed that uses the decay of the optimal finite-horizon cost and convolutes a history stack to predict the bounds on the IH performance. Based on online information on the decay rate, the performance bound estimate is improved while the terminal cost is adapted using methods from adaptive dynamic programming. The adaptation of the terminal cost leads to performance improvement over a time-invariant scheme with the same horizon length. The approach is demonstrated in a case study.      
### 6.AdaSpeech: Adaptive Text to Speech for Custom Voice  [ :arrow_down: ](https://arxiv.org/pdf/2103.00993.pdf)
>  Custom voice, a specific text to speech (TTS) service in commercial speech platforms, aims to adapt a source TTS model to synthesize personal voice for a target speaker using few speech data. Custom voice presents two unique challenges for TTS adaptation: 1) to support diverse customers, the adaptation model needs to handle diverse acoustic conditions that could be very different from source speech data, and 2) to support a large number of customers, the adaptation parameters need to be small enough for each target speaker to reduce memory usage while maintaining high voice quality. In this work, we propose AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices. We design several techniques in AdaSpeech to address the two challenges in custom voice: 1) To handle different acoustic conditions, we use two acoustic encoders to extract an utterance-level vector and a sequence of phoneme-level vectors from the target speech during training; in inference, we extract the utterance-level vector from a reference speech and use an acoustic predictor to predict the phoneme-level vectors. 2) To better trade off the adaptation parameters and voice quality, we introduce conditional layer normalization in the mel-spectrogram decoder of AdaSpeech, and fine-tune this part in addition to speaker embedding for adaptation. We pre-train the source TTS model on LibriTTS datasets and fine-tune it on VCTK and LJSpeech datasets (with different acoustic conditions from LibriTTS) with few adaptation data, e.g., 20 sentences, about 1 minute speech. Experiment results show that AdaSpeech achieves much better adaptation quality than baseline methods, with only about 5K specific parameters for each speaker, which demonstrates its effectiveness for custom voice. Audio samples are available at <a class="link-external link-https" href="https://speechresearch.github.io/adaspeech/" rel="external noopener nofollow">this https URL</a>.      
### 7.Fixed-Time Convergent Control Barrier Functions for Coupled Multi-Agent Systems Under STL Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2103.00986.pdf)
>  This paper presents a control strategy based on a new notion of time-varying fixed-time convergent control barrier functions (TFCBFs) for a class of coupled multi-agent systems under signal temporal logic (STL) tasks. In this framework, each agent is assigned a local STL task regradless of the tasks of other agents. Each task may be dependent on the behavior of other agents which may cause conflicts on the satisfaction of all tasks. Our approach finds a robust solution to guarantee the fixed-time satisfaction of STL tasks in a least violating way and independent of the agents' initial condition in the presence of undesired violation effects of the neighbor agents. Particularly, the robust performance of the task satisfactions can be adjusted in a user-specified way.      
### 8.Flexibility Evaluation of Domestic Electric Water Heater Aggregates  [ :arrow_down: ](https://arxiv.org/pdf/2103.00966.pdf)
>  In this paper, a method to evaluate the flexibility of aggregates of domestic electric water heaters is proposed and applied to the Italian case. Flexibility is defined as the capability of the aggregate to vary its power demand for a given time interval. The evaluation method consists of a Monte Carlo analysis, that uses the thermal model of electric water heaters and a proper elaboration of the external inputs, such as ambient and cold water temperatures, and hot water demand. The case of large aggregates defined along the Italian territory has been studied showing the dependence of flexibility on seasons and on time.      
### 9.LADMM-Net: An Unrolled Deep Network For Spectral Image Fusion From Compressive Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.00940.pdf)
>  Hyperspectral (HS) and multispectral (MS) image fusion aims at estimating a high-resolution spectral image from a low-spatial-resolution HS image and a low-spectral-resolution MS image. Compressive spectral imaging (CSI) has emerged as an acquisition framework that captures the relevant information of spectral images using a reduced number of snapshots. Various spectral image fusion methods from multi-sensor CSI measurements have been proposed. Nevertheless, these methods exhibit high running times and face the drawback of choosing a representation transform. In this work, a deep learning architecture under the algorithm unrolling approach is proposed for solving the fusion problem from HS and MS compressive measurements. This architecture, dubbed LADMM-Net, casts each iteration of a linearized version of the alternating direction method of multipliers into a processing layer whose concatenation forms a deep network. The linearized approach leads to estimate the target variable without resorting to expensive matrix operations. This approach also estimates the image high-frequency component included in both the auxiliary variable and the Lagrange multiplier. The performance of the proposed technique is evaluated on two spectral image databases and one dataset captured at the laboratory. Extensive simulations show that the proposed method outperforms the state-of-the-art approaches that fuse spectral images from compressive data.      
### 10.Computing the sampling performance of event-triggered control  [ :arrow_down: ](https://arxiv.org/pdf/2103.00919.pdf)
>  In the context of networked control systems, event-triggered control (ETC) has emerged as a major topic due to its alleged resource usage reduction capabilities. However, this is mainly supported by numerical simulations, and very little is formally known about the traffic generated by ETC. This work devises a method to estimate, and in some cases to determine exactly, the minimum average inter-sample time (MAIST) generated by periodic event-triggered control (PETC) of linear systems. The method involves abstracting the traffic model using a bisimulation refinement algorithm and finding the cycle of minimum average length in the graph associated to it. This always gives a lower bound to the actual MAIST. Moreover, if this cycle turns out to be related to a periodic solution of the closed-loop PETC system, the performance metric is exact.      
### 11.A Secure Sensor Fusion Framework for Connected and Automated Vehicles under Sensor Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2103.00883.pdf)
>  By using various sensors to measure the surroundings and sharing local sensor information with the surrounding vehicles through wireless networks, connected and automated vehicles (CAVs) are expected to increase safety, efficiency, and capacity of our transportation systems. However, the increasing usage of sensors has also increased the vulnerability of CAVs to sensor faults and adversarial attacks. Anomalous sensor values resulting from malicious cyberattacks or faulty sensors may cause severe consequences or even fatalities. In this paper, we increase the resilience of CAVs to faults and attacks by using multiple sensors for measuring the same physical variable to create redundancy. We exploit this redundancy and propose a sensor fusion algorithm for providing a robust estimate of the correct sensor information with bounded errors independent of the attack signals, and for attack detection and isolation. The proposed sensor fusion framework is applicable to a large class of security-critical Cyber-Physical Systems (CPSs). To minimize the performance degradation resulting from the usage of estimation for control, we provide an $H_{\infty}$ controller for CACC-equipped CAVs capable of stabilizing the closed-loop dynamics of each vehicle in the platoon while reducing the joint effect of estimation errors and communication channel noise on the tracking performance and string behavior of the vehicle platoon. Numerical examples are presented to illustrate the effectiveness of our methods.      
### 12.Secure Estimation and Attack Isolation for Connected and Automated Driving in the Presence of Malicious Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.00878.pdf)
>  Connected and Automated Vehicles (CAVs) rely on the correctness of position and other vehicle kinematics information to fulfill various driving tasks such as vehicle following, lane change, and collision avoidance. However, a malicious vehicle may send false sensor information to the other vehicles intentionally or unintentionally, which may cause traffic inconvenience or loss of human lives. Here, we take the advantage of cloud-computing and increase the resilience of CAVs to malicious vehicles by assuming each vehicle shares its local sensor information with other vehicles to create information redundancy on the cloud side. We exploit this redundancy and propose a sensor fusion algorithm for the cloud, capable of providing a robust state estimation of all vehicles in the cloud under the condition that the number of malicious information is sufficiently small. Using the proposed estimator, we provide an algorithm for isolating malicious vehicles. We use numerical examples to illustrate the effectiveness of our methods.      
### 13.Path-specific Underwater Acoustic Channel Tracking and its Application in Passive Time Reversal Mirror  [ :arrow_down: ](https://arxiv.org/pdf/2103.00874.pdf)
>  We consider the underwater acoustic channel which is time-variant and doubly-spread in this work. Since conventional channel estimation and decision feedback equalizer (DFE) can not work well for this type of channel, a path-specific underwater acoustic channel tracking is proposed. It is based on the framework of Kalman filter. We provide a simplified sound propagation model as the state transition model. A multipath tracker is proposed which is tolerant of the model-mismatch. Then we can obtain the time-variant path number and path-specific parameters such as delay and Doppler scaling factor. We also consider the application of the proposed path-specific underwater acoustic channel tracking. We propose two types of passive time reversal mirror (PTRM) with our path-specific parameters for time-variant and doubly-spread underwater acoustic channel. With the path-specific parameters obtained by the proposed channel tracking, the proposed PTRM can not only match the time dispersion as conventional PTRM, but also the doubly-spread channel, since the path-specific delay and Doppler scaler factor can help to match the channel in both time and frequency domain. For extensive doubly-spread channel, we can further apply the path-specific compensation to the PTRM. Both simulations and experimental results by data from 2016 Qiandao Lake experiment show the efficiency of proposed path-specific channel tracking and proposed PTRMs with path-specific parameters.      
### 14.Dynamic Underwater Acoustic Channel Tracking for Correlated Rapidly Time-varying Channels  [ :arrow_down: ](https://arxiv.org/pdf/2103.00859.pdf)
>  In this work, we focus on the model-mismatch problem for model-based subspace channel tracking in the correlated underwater acoustic channel. A model based on the underwater acoustic channel's correlation can be used as the state-space model in the Kalman filter to improve the underwater acoustic channel tracking compared that without a model. Even though the data support the assumption that the model is slow-varying and uncorrelated to some degree, to improve the tracking performance further, we can not ignore the model-mismatch problem because most channel models encounter this problem in the underwater acoustic channel. Therefore, in this work, we provide a dynamic time-variant state-space model for underwater acoustic channel tracking. This model is tolerant to the slight correlation after decorrelation. Moreover, a forward-backward Kalman filter is combined to further improve the tracking performance. The performance of our proposed algorithm is demonstrated with the same at-sea data as that used for conventional channel tracking. Compared with the conventional algorithms, the proposed algorithm shows significant improvement, especially in rough sea conditions in which the channels are fast-varying.      
### 15.Sandglasset: A Light Multi-Granularity Self-attentive Network For Time-Domain Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2103.00819.pdf)
>  One of the leading single-channel speech separation (SS) models is based on a TasNet with a dual-path segmentation technique, where the size of each segment remains unchanged throughout all layers. In contrast, our key finding is that multi-granularity features are essential for enhancing contextual modeling and computational efficiency. We introduce a self-attentive network with a novel sandglass-shape, namely Sandglasset, which advances the state-of-the-art (SOTA) SS performance at significantly smaller model size and computational cost. Forward along each block inside Sandglasset, the temporal granularity of the features gradually becomes coarser until reaching half of the network blocks, and then successively turns finer towards the raw signal level. We also unfold that residual connections between features with the same granularity are critical for preserving information after passing through the bottleneck layer. Experiments show our Sandglasset with only 2.3M parameters has achieved the best results on two benchmark SS datasets -- WSJ0-2mix and WSJ0-3mix, where the SI-SNRi scores have been improved by absolute 0.6 dB and 2.4 dB, respectively, comparing to the prior SOTA results.      
### 16.Contrastive Separative Coding for Self-supervised Representation Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.00816.pdf)
>  To extract robust deep representations from long sequential modeling of speech data, we propose a self-supervised learning approach, namely Contrastive Separative Coding (CSC). Our key finding is to learn such representations by separating the target signal from contrastive interfering signals. First, a multi-task separative encoder is built to extract shared separable and discriminative embedding; secondly, we propose a powerful cross-attention mechanism performed over speaker representations across various interfering conditions, allowing the model to focus on and globally aggregate the most critical information to answer the "query" (current bottom-up embedding) while paying less attention to interfering, noisy, or irrelevant parts; lastly, we form a new probabilistic contrastive loss which estimates and maximizes the mutual information between the representations and the global speaker vector. While most prior unsupervised methods have focused on predicting the future, neighboring, or missing samples, we take a different perspective of predicting the interfered samples. Moreover, our contrastive separative loss is free from negative sampling. The experiment demonstrates that our approach can learn useful representations achieving a strong speaker verification performance in adverse conditions.      
### 17.Physical Watermarking for Replay Attack Detection in Continuous-time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00790.pdf)
>  Physical watermarking is a well established technique for replay attack detection in cyber-physical systems (CPSs). Most of the watermarking methods proposed in the literature are designed for discrete-time systems. In general, real physical systems evolve in continuous time. In this paper, we analyze the effect of watermarking on sampled-data continuous-time systems controlled via a Zero-Order Hold. We investigate the effect of sampling on detection performance and we provide a procedure to find a suitable sampling period that ensures detectability and acceptable control performance. Simulations on a quadrotor system are used to illustrate the effectiveness of the theoretical results.      
### 18.Towards Unbiased COVID-19 Lesion Localisation and Segmentation via Weakly Supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.00780.pdf)
>  Despite tremendous efforts, it is very challenging to generate a robust model to assist in the accurate quantification assessment of COVID-19 on chest CT images. Due to the nature of blurred boundaries, the supervised segmentation methods usually suffer from annotation biases. To support unbiased lesion localisation and to minimise the labeling costs, we propose a data-driven framework supervised by only image-level labels. The framework can explicitly separate potential lesions from original images, with the help of a generative adversarial network and a lesion-specific decoder. Experiments on two COVID-19 datasets demonstrate the effectiveness of the proposed framework and its superior performance to several existing methods.      
### 19.Sensor Selection and Optimal Precision in $\mathcal{H}_2/\mathcal{H}_{\infty}$ Estimation Framework: Theory and Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2103.00750.pdf)
>  We consider the problem of sensor selection for designing observer and filter for continuous linear time invariant systems such that the sensor precisions are minimized, and the estimation errors are bounded by the prescribed $\mathcal{H}_2/\mathcal{H}_{\infty}$ performance criteria. The proposed integrated framework formulates the precision minimization as a convex optimization problem subject to linear matrix inequalities, and it is solved using an algorithm based on the alternating direction method of multipliers (ADMM). We also present a greedy approach for sensor selection and demonstrate the performance of the proposed algorithms using numerical simulations.      
### 20.SmartON: Just-in-Time Active Event Detection on Energy Harvesting Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00749.pdf)
>  We propose SmartON, a batteryless system that learns to wake up proactively at the right moment in order to detect events of interest. It does so by adapting the duty cycle to match the distribution of event arrival times under the constraints of harvested energy. While existing energy harvesting systems either wake up periodically at a fixed rate to sense and process the data, or wake up only in accordance with the availability of the energy source, SmartON employs a three-phase learning framework to learn the energy harvesting pattern as well as the pattern of events at run-time, and uses that knowledge to wake itself up when events are most likely to occur. The three-phase learning framework enables rapid adaptation to environmental changes in both short and long terms. Being able to remain asleep more often than a CTID (charging-then-immediate-discharging) wake-up system and adapt to the event pattern, SmartON is able to reduce energy waste, increase energy efficiency, and capture more events. To realize SmartON we have developed a dedicated hardware platform whose power management module activates capacitors on-the-fly to dynamically increase its storage capacitance. We conduct both simulation-driven and real-system experiments to demonstrate that SmartON captures 1X--7X more events and is 8X--17X more energy-efficient than a CTID system.      
### 21.Sparse Sensing Architectures with Optimal Precision for Tracking Multi-agent Systems in Sensing-denied Environments  [ :arrow_down: ](https://arxiv.org/pdf/2103.00739.pdf)
>  In this paper the tracking problem of multi-agent systems, in a particular scenario where a segment of agents entering a sensing-denied environment or behaving as non-cooperative targets, is considered. The focus is on determining the optimal sensor precisions while simultaneously promoting sparseness in the sensor measurements to guarantee a specified estimation performance. The problem is formulated in the discrete-time centralized Kalman filtering framework. A semi-definite program subject to linear matrix inequalities is solved to minimize the trace of precision matrix which is defined to be the inverse of sensor noise covariance matrix. Simulation results expose a trade-off between sensor precisions and sensing frequency.      
### 22.Infrastructure Assisted Constrained Connected Automated Vehicle Trajectory Optimization on Curved Roads: A Spatial Formulation on a Curvilinear Coordinate  [ :arrow_down: ](https://arxiv.org/pdf/2103.00699.pdf)
>  Vehicle trajectory optimization is essential to ensure vehicles travel efficiently and safely. This paper presents an infrastructure assisted constrained connected automated vehicles (CAVs) trajectory optimization method on curved roads. This paper systematically formulates the problem based on a curvilinear coordinate which is flexible to model complex road geometries. Further, to deal with the spatial varying road obstacles, traffic regulations, and geometric characteristics, two-dimensional vehicle kinematics is given in a spatial formulation with exact road information provided by the infrastructure. Consequently, we applied a multi-objective model predictive control (MPC) approach to optimize the trajectories in a rolling horizon while satisfying the collision avoidances and vehicle kinematics constraints. To verify the efficiency of our method, a numerical simulation is conducted. As the results suggest, the proposed method can provide smooth vehicular trajectories, avoid road obstacles, and simultaneously follow traffic regulations, which is robust to road geometries and disturbances.      
### 23.Distribution Grid Modeling Using Smart Meter Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.00660.pdf)
>  The knowledge of distribution grid models, including topologies and line impedances, is essential to grid monitoring, control and protection. However, this information is often unavailable, incomplete or outdated. The increasing deployment of smart meters (SMs) provides a unique opportunity to address this issue. This paper proposes a two-stage data-driven framework for distribution grid modeling using SM data. In the first stage, we propose to identify the topology via reconstructing a weighted Laplacian matrix of distribution networks, which is mathematically proven to be robust against moderately heterogeneous R/X profiles. In the second stage, we develop nonlinear least absolute deviations (LAD) and least squares (LS) regression models to estimate line impedances of single branches based on a nonlinear inverse power flow, which is then embedded within a bottom-up sweep algorithm to achieve the identification across the network in a branch-wise manner. Because the estimation models are inherently non-convex programs and NP-hard, we specially address their tractable convex relaxations and verify the exactness. In addition, we design a conductor library to significantly narrow down the solution space. Numerical results on the modified IEEE 13-bus, 37-bus and 69-bus test feeders validate the effectiveness of the proposed methods.      
### 24.Rejection of Smooth GPS Time Synchronization Attacks via Sparse Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2103.00650.pdf)
>  This paper presents a novel time synchronization attack (TSA) model for the Global Positioning System (GPS) based on clock data behavior changes in a higher-order derivative domain. Further, the time synchronization attack rejection and mitigation based on sparse domain (TSARM-S) is presented. TSAs affect stationary GPS receivers in applications where precise timing is required, such as cellular communications, financial transactions, and monitoring of the electric power grid. In the present work, the clock bias and clock drift are monitored at higher-order clock data derivatives where the TSA is seen as a sparse spike-like event. The smoothness of the attack relates to the derivative order where the sparsity is observed. The proposed method jointly estimates a dynamic solution for GPS timing and rejects behavior changes based on such sparse events. An evaluation procedure is presented for two testbeds, namely a commercial receiver and a software-defined radio. Further, the proposed method is evaluated against distinct real-dataset Texas Spoofing Test Battery (TEXBAT) scenarios. Combined synthetic and real-data results show an average RMS clock bias error of 12.08 m for the SDR platform, and 45.74 m for the commercial device. Further, the technique is evaluated against state-of-the-art mitigation techniques and in a spoofing-plus-multipath scenario for robustness. Finally, TSARM-S can be potentially optimized and implemented in commercial devices via a firmware upgrade.      
### 25.DMPC: A Data-and Model-Driven Approach to Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.00644.pdf)
>  This work presents DMPC (Data-and Model-Driven Predictive Control) to solve control problems in which some of the constraints or parts of the objective function are known, while others are entirely unknown to the controller. It is assumed that there is an exogenous ``black box'' system, e.g. a machine learning technique, that predicts the value of the unknown functions for a given trajectory. DMPC (1) provides an approach to merge both the model-based and black-box systems; (2) can cope with very little data and is sample efficient, building its solutions based on recently generated trajectories; and (3) improves its cost in each iteration until converging to an optimal trajectory, typically needing only a few trials even for nonlinear dynamics and objectives. Theoretical analysis of the algorithm is presented, proving that the quality of the trajectory does not worsen with each new iteration, as well as providing bounds on the complexity. We apply the DMPC algorithm to the motion planning of an autonomous vehicle with nonlinear dynamics.      
### 26.TransCT: Transformer based Low Dose Computed Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2103.00634.pdf)
>  Low dose computed tomography (LDCT) has attracted more and more attention in routine clinical diagnosis assessment, therapy planning, etc., which can reduce the dose of X-ray radiation to patients. However, the noise caused by low X-ray exposure degrades the CT image quality and then affects clinical diagnosis accuracy. In this paper, we train a transformer-based neural network to enhance the final CT image quality. To be specific, we first decompose the noisy LDCT image into two parts: high-frequency (HF) and low-frequency (LF) compositions and then extract LF context features and latent HF texture features from the LF part, as well as HF embeddings from the HF part. Next, we feed these features and embeddings into a modified transformer with three encoders and decoders to encourage the restoration of high-quality LDCT images with the assistance of piecewise reconstruction. Extensive experiments on Mayo LDCT dataset show that our method produces superior results and outperforms other methods.      
### 27.Physical-Layer Security via Distributed Beamforming in the Presence of Adversaries with Unknown Locations  [ :arrow_down: ](https://arxiv.org/pdf/2103.00630.pdf)
>  We study the problem of securely communicating a sequence of information bits with a client in the presence of multiple adversaries at unknown locations in the environment. We assume that the client and the adversaries are located in the far-field region, and all possible directions for each adversary can be expressed as a continuous interval of directions. In such a setting, we develop a periodic transmission strategy, i.e., a sequence of joint beamforming gain and artificial noise pairs, that prevents the adversaries from decreasing their uncertainty on the information sequence by eavesdropping on the transmission. We formulate a series of nonconvex semi-infinite optimization problems to synthesize the transmission strategy. We show that the semi-definite program (SDP) relaxations of these nonconvex problems are exact under an efficiently verifiable sufficient condition. We approximate the SDP relaxations, which are subject to infinitely many constraints, by randomly sampling a finite subset of the constraints and establish the probability with which optimal solutions to the obtained finite SDPs and the semi-infinite SDPs coincide. We demonstrate with numerical simulations that the proposed periodic strategy can ensure the security of communication in scenarios in which all stationary strategies fail to guarantee security.      
### 28.An Intelligent Multi-Speed Advisory System using Improved Whale Optimisation Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2103.00548.pdf)
>  An intelligent speed advisory system can be used to recommend speed for vehicles travelling in a given road network in cities. In this paper, we extend our previous work where a distributed speed advisory system has been devised to recommend an optimal consensus speed for a fleet of Internal Combustion Engine Vehicles (ICEVs) in a highway scenario. In particular, we propose a novel optimisation framework where the exact format of each vehicle's cost function can be implicit, and our algorithm can be used to recommend multiple consensus speeds for vehicles travelling on different lanes in an urban highway scenario. Our studies show that the proposed scheme based on an improved whale optimisation algorithm can effectively reduce CO2 emission generated from ICEVs while providing different recommended speed options for groups of vehicles.      
### 29.Alignment Knowledge Distillation for Online Streaming Attention-based Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.00422.pdf)
>  This article describes an efficient training method for online streaming attention-based encoder-decoder (AED) automatic speech recognition (ASR) systems. AED models have achieved competitive performance in offline scenarios by jointly optimizing all components. They have recently been extended to an online streaming framework via models such as monotonic chunkwise attention (MoChA). However, the elaborate attention calculation process is not robust for long-form speech utterances. Moreover, the sequence-level training objective and time-restricted streaming encoder cause a nonnegligible delay in token emission during inference. To address these problems, we propose CTC synchronous training (CTC-ST), in which CTC alignments are leveraged as a reference for token boundaries to enable a MoChA model to learn optimal monotonic input-output alignments. We formulate a purely end-to-end training objective to synchronize the boundaries of MoChA to those of CTC. The CTC model shares an encoder with the MoChA model to enhance the encoder representation. Moreover, the proposed method provides alignment information learned in the CTC branch to the attention-based decoder. Therefore, CTC-ST can be regarded as self-distillation of alignment knowledge from CTC to MoChA. Experimental evaluations on a variety of benchmark datasets show that the proposed method significantly reduces recognition errors and emission latency simultaneously, especially for long-form and noisy speech. We also compare CTC-ST with several methods that distill alignment knowledge from a hybrid ASR system and show that the CTC-ST can achieve a comparable tradeoff of accuracy and latency without relying on external alignment information. The best MoChA system shows performance comparable to that of RNN-transducer (RNN-T).      
### 30.LQG Reference Tracking with Safety and Reachability Guarantees under Unknown False Data Injection Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2103.00387.pdf)
>  We investigate a linear quadratic Gaussian (LQG) tracking problem with safety and reachability constraints in the presence of an adversary who mounts an FDI attack on an unknown set of sensors. For each possible set of compromised sensors, we maintain a state estimator disregarding the sensors in that set, and calculate the optimal LQG control input at each time based on this estimate. We propose a control policy which constrains the control input to lie within a fixed distance of the optimal control input corresponding to each state estimate. The control input is obtained at each time step by solving a quadratically constrained quadratic program (QCQP). We prove that our policy can achieve a desired probability of safety and reachability using the barrier certificate method. Our control policy is evaluated via a numerical case study.      
### 31.The Property of Frequency Shift in 2D-FRFT Domain with Application to Image Encryption  [ :arrow_down: ](https://arxiv.org/pdf/2103.00365.pdf)
>  The Fractional Fourier Transform (FRFT) has been playing a unique and increasingly important role in signal and image processing. In this letter, we investigate the property of frequency shift in two-dimensional FRFT (2D-FRFT) domain. It is shown that the magnitude of image reconstruction from phase information is frequency shift-invariant in 2D-FRFT domain, enhancing the robustness of image encryption, an important multimedia security task. Experiments are conducted to demonstrate the effectiveness of this property against the frequency shift attack, improving the robustness of image encryption.      
### 32.Silent versus modal multi-speaker speech recognition from ultrasound and video  [ :arrow_down: ](https://arxiv.org/pdf/2103.00333.pdf)
>  We investigate multi-speaker speech recognition from ultrasound images of the tongue and video images of the lips. We train our systems on imaging data from modal speech, and evaluate on matched test sets of two speaking modes: silent and modal speech. We observe that silent speech recognition from imaging data underperforms compared to modal speech recognition, likely due to a speaking-mode mismatch between training and testing. We improve silent speech recognition performance using techniques that address the domain mismatch, such as fMLLR and unsupervised model adaptation. We also analyse the properties of silent and modal speech in terms of utterance duration and the size of the articulatory space. To estimate the articulatory space, we compute the convex hull of tongue splines, extracted from ultrasound tongue images. Overall, we observe that the duration of silent speech is longer than that of modal speech, and that silent speech covers a smaller articulatory space than modal speech. Although these two properties are statistically significant across speaking modes, they do not directly correlate with word error rates from speech recognition.      
### 33.Optimal control of point-to-point navigation in turbulent time-dependent flows using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.00329.pdf)
>  We present theoretical and numerical results concerning the problem to find the path that minimizes the time to navigate between two given points in a complex fluid under realistic navigation constraints. We contrast deterministic Optimal Navigation (ON) control with stochastic policies obtained by Reinforcement Learning (RL) algorithms. We show that Actor-Critic RL algorithms are able to find quasi-optimal solutions in the presence of either time-independent or chaotically evolving flow configurations. For our application, ON solutions develop unstable behavior within the typical duration of the navigation process, and are therefore not useful in practice. We first explore navigation of turbulent flow using a constant propulsion speed. Based on a discretized phase-space, the propulsion direction is adjusted with the aim to minimize the time spent to reach the target. Further, we explore a case where additional control is obtained by allowing the engine to power off. Exploiting advection of the underlying flow, allows the target to be reached with less energy consumption. In this case, we optimize a linear combination between the total navigation time and the total time the engine is switched off. Our approach can be generalized to other setups, for example, navigation under imperfect environmental forecast or with different models for the moving vessel.      
### 34.Terahertz-Band Joint Ultra-Massive MIMO Radar-Communications: Model-Based and Model-Free Hybrid Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2103.00328.pdf)
>  Wireless communications and sensing at terahertz (THz) band are increasingly investigated as promising short-range technologies because of the availability of high operational bandwidth at THz. In order to address the extremely high attenuation at THz, ultra-massive multiple-input multiple-output (UM-MIMO) antenna systems have been proposed for THz communications to compensate propagation losses. However, the cost and power associated with fully digital beamformers of these huge antenna arrays are prohibitive. In this paper, we develop THz hybrid beamformers based on both model-based and model-free techniques for a new group-of-subarrays (GoSA) UM-MIMO structure. Further, driven by the recent developments to save the spectrum, we propose beamformers for a joint UM-MIMO radar-communications system, wherein the base station serves multi-antenna user equipment (RX), and tracks radar targets by generating multiple beams toward both RX and the targets. We formulate the GoSA beamformer design as an optimization problem to provide a trade-off between the unconstrained communications beamformers and the desired radar beamformers. Additionally, our design also exploits second-order channel statistics so that an infrequent channel feedback from the RX is achieved with less channel overhead. To further decrease the UM-MIMO computational complexity and enhance robustness, we also implement deep learning solutions to the proposed model-based hybrid beamformers. Numerical experiments demonstrate that both techniques outperform the conventional approaches in terms of spectral efficiency and radar beampatterns, as well as exhibiting less hardware cost and computation time.      
### 35.Exploiting ultrasound tongue imaging for the automatic detection of speech articulation errors  [ :arrow_down: ](https://arxiv.org/pdf/2103.00324.pdf)
>  Speech sound disorders are a common communication impairment in childhood. Because speech disorders can negatively affect the lives and the development of children, clinical intervention is often recommended. To help with diagnosis and treatment, clinicians use instrumented methods such as spectrograms or ultrasound tongue imaging to analyse speech articulations. Analysis with these methods can be laborious for clinicians, therefore there is growing interest in its automation. In this paper, we investigate the contribution of ultrasound tongue imaging for the automatic detection of speech articulation errors. Our systems are trained on typically developing child speech and augmented with a database of adult speech using audio and ultrasound. Evaluation on typically developing speech indicates that pre-training on adult speech and jointly using ultrasound and audio gives the best results with an accuracy of 86.9%. To evaluate on disordered speech, we collect pronunciation scores from experienced speech and language therapists, focusing on cases of velar fronting and gliding of /r/. The scores show good inter-annotator agreement for velar fronting, but not for gliding errors. For automatic velar fronting error detection, the best results are obtained when jointly using ultrasound and audio. The best system correctly detects 86.6% of the errors identified by experienced clinicians. Out of all the segments identified as errors by the best system, 73.2% match errors identified by clinicians. Results on automatic gliding detection are harder to interpret due to poor inter-annotator agreement, but appear promising. Overall findings suggest that automatic detection of speech articulation errors has potential to be integrated into ultrasound intervention software for automatically quantifying progress during speech therapy.      
### 36.Automatic evaluation of human oocyte developmental potential from microscopy images  [ :arrow_down: ](https://arxiv.org/pdf/2103.00302.pdf)
>  Infertility is becoming an issue for an increasing number of couples. The most common solution, in vitro fertilization, requires embryologists to carefully examine light microscopy images of human oocytes to determine their developmental potential. We propose an automatic system to improve the speed, repeatability, and accuracy of this process. We first localize individual oocytes and identify their principal components using CNN (U-Net) segmentation. We calculate several descriptors based on geometry and texture. The final step is an SVM classifier. Both the segmentation and classification training are based on expert annotations. The presented approach leads to the classification accuracy of 70%.      
### 37.Visual Navigation with a 2-pixel Camera---Possibilities and Limitations  [ :arrow_down: ](https://arxiv.org/pdf/2103.00285.pdf)
>  Borrowing terminology from fluid mechanics, the concepts of {\em Eulerian} and {\em Lagrangian optical flow sensing} are introduced. Eulerian optical flow sensing assumes that each photoreceptor in the camera or eye can instantaneously detect feature image points and their velocities on the retina. If this assumption is satisfied, even a two pixel imaging system can provide a moving agent with information about its movement along a corridor that is sufficiently precise as to be used as a robustly reliable steering signal. Implementing Eulerian optical flow sensing poses significant challenges, however. Lagrangian optical flow, on the other hand, tracks feature image points as they move on the retina. This form of visual sensing is the basis for many standard computer vision implementations, including Lukas-Kanade and Horn-Schunck. Lagrangian optical flow has its own challenges, not least of which is that it is badly confounded by rotational components of motion. Combined steering and sensing strategies for mitigating the effects of rotational motions are considered.      
### 38.PA-ResSeg: A Phase Attention Residual Network for Liver Tumor Segmentation from Multi-phase CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.00274.pdf)
>  In this paper, we propose a phase attention residual network (PA-ResSeg) to model multi-phase features for accurate liver tumor segmentation, in which a phase attention (PA) is newly proposed to additionally exploit the images of arterial (ART) phase to facilitate the segmentation of portal venous (PV) phase. The PA block consists of an intra-phase attention (Intra-PA) module and an inter-phase attention (Inter-PA) module to capture channel-wise self-dependencies and cross-phase interdependencies, respectively. Thus it enables the network to learn more representative multi-phase features by refining the PV features according to the channel dependencies and recalibrating the ART features based on the learned interdependencies between phases. We propose a PA-based multi-scale fusion (MSF) architecture to embed the PA blocks in the network at multiple levels along the encoding path to fuse multi-scale features from multi-phase images. Moreover, a 3D boundary-enhanced loss (BE-loss) is proposed for training to make the network more sensitive to boundaries. To evaluate the performance of our proposed PA-ResSeg, we conducted experiments on a multi-phase CT dataset of focal liver lesions (MPCT-FLLs). Experimental results show the effectiveness of the proposed method by achieving a dice per case (DPC) of 0.77.87, a dice global (DG) of 0.8682, a volumetric overlap error (VOE) of 0.3328 and a relative volume difference (RVD) of 0.0443 on the MPCT-FLLs. Furthermore, to validate the effectiveness and robustness of PA-ResSeg, we conducted extra experiments on another multi-phase liver tumor dataset and obtained a DPC of 0.8290, a DG of 0.9132, a VOE of 0.2637 and a RVD of 0.0163. The proposed method shows its robustness and generalization capability in different datasets and different backbones.      
### 39.Quantification of Bore Path Uncertainty in Borehole Heat Exchanger Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2103.00271.pdf)
>  Borehole heat exchanger arrays have become a common implement for the utilization of thermal energy in the soil. Building these facilities is expensive, especially the drilling of boreholes, into which closed-pipe heat exchangers are inserted. Therefore, cost-reducing drilling methods are common practice, which can produce inaccuracies of varying degree. This brings into question how much these inaccuracies could potentially affect the performance of a planned system. In the presented case study, an uncertainty quantification for seasonally operated borehole heat exchanger arrays is performed to analyze the bore paths' deviations impact. We introduce an adaptive, anisotropic stochastic collocation method, known as the generalized Smolyak algorithm, which was previously unused in this context and apply it to a numerical model of the borehole heat exchanger array. Our results show that the borehole heat exchanger array performance is surprisingly reliable even with potentially severe implementation errors during their construction. This, coupled with the potential uses of the presented method in similar applications gives planners and investors valuable information regarding the viability of borehole heat exchanger arrays in the face of uncertainty. With this paper, we hope to provide a powerful statistical tool to the field of geothermal energy, in which uncertainty quantification methods are still rarely used at this point. The discussed case study represents a jumping-off point for further investigations on the effects of uncertainty on borehole heat exchanger arrays and borehole thermal energy storage systems.      
### 40.Generalized Current-State Opacity With Dynamically Changing Secrets  [ :arrow_down: ](https://arxiv.org/pdf/2103.00234.pdf)
>  Opacity, an information-flow property related to the privacy and security of a system, has been extensively studied in the context of discrete event systems. Although various notions of opacity have been proposed, in all cases the considered secret was constant. This work focuses on current-state opacity, considering a scenario where the secret changes dynamically with the system evolution. In other words, we propose the new notion of generalized current-state opacity (GCSO), which is with respect to a dynamic-secret model rather than a constant secret. Moreover, we provide a method to verify GCSO based on the construction of the GCSO-verifier. Finally, a practical example is given to illustrate the proposed notion and the method for its verification.      
### 41.Structural Identifiability of Impedance Spectroscopy Fractional-Order Equivalent Circuit Models With Two Constant Phase Elements  [ :arrow_down: ](https://arxiv.org/pdf/2103.00226.pdf)
>  Structural identifiability analysis of fractional-order equivalent circuit models (FO-ECMs), obtained through electrochemical impedance spectroscopy (EIS) is still a challenging problem. No peer-reviewed analytical or numerical proof does exist showing that whether impedance spectroscopy FO-ECMs are structurally identifiable or not, regardless of practical issues such as measurement noises and the selection of excitation signals. By using the coefficient mapping technique, this paper proposes novel computationally-efficient algebraic equations for the numerical structural identifiability analysis of a widely used FO-ECM with Grünwald-Letnikov fractional derivative approximation and two constant phase elements (CPEs) including the Warburg term. The proposed numerical structural identifiability analysis method is applied to an example from batteries, and the results are discussed. Matlab codes are available on github.      
### 42.Application of the unified control and detection framework to detecting stealthy integrity cyber-attacks on feedback control systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00210.pdf)
>  This draft addresses issues of detecting stealthy integrity cyber-attacks on automatic control systems in the unified control and detection framework. A general form of integrity cyber-attacks that cannot be detected using the well-established observer-based technique is first introduced as kernel attacks. The well-known replay, zero dynamics and covert attacks are special forms of kernel attacks. Furthermore, the existence conditions for kernel attacks are presented. It is demonstrated, in the unified framework of control and detection, that all kernel attacks can be structurally detected when not only the observer-based residual, but also the control signal based residual signals are generated and used for the detection purpose. Based on the analytical results, two schemes for detecting kernel attacks are then proposed, which allow reliable detection of kernel attacks without loss of control performance. While the first scheme is similar to the well-established moving target method and auxiliary system aided detection scheme, the second detector is realised with the encrypted transmissions of control and monitoring signals in the feedback control system that prevents adversary to gain system knowledge by means of eavesdropping attacks. Both schemes are illustrated by examples of detecting replay, zero dynamics and covert attacks and an experimental study on a three tank control system.      
### 43.Super-resolution-based Change Detection Network with Stacked Attention Module for Images with Different Resolutions  [ :arrow_down: ](https://arxiv.org/pdf/2103.00188.pdf)
>  Change detection, which aims to distinguish surface changes based on bi-temporal images, plays a vital role in ecological protection and urban planning. Since high resolution (HR) images cannot be typically acquired continuously over time, bi-temporal images with different resolutions are often adopted for change detection in practical applications. Traditional subpixel-based methods for change detection using images with different resolutions may lead to substantial error accumulation when HR images are employed; this is because of intraclass heterogeneity and interclass similarity. Therefore, it is necessary to develop a novel method for change detection using images with different resolutions, that is more suitable for HR images. To this end, we propose a super-resolution-based change detection network (SRCDNet) with a stacked attention module. The SRCDNet employs a super resolution (SR) module containing a generator and a discriminator to directly learn SR images through adversarial learning and overcome the resolution difference between bi-temporal images. To enhance the useful information in multi-scale features, a stacked attention module consisting of five convolutional block attention modules (CBAMs) is integrated to the feature extractor. The final change map is obtained through a metric learning-based change decision module, wherein a distance map between bi-temporal features is calculated. The experimental results demonstrate the superiority of the proposed method, which not only outperforms all baselines -with the highest F1 scores of 87.40% on the building change detection dataset and 92.94% on the change detection dataset -but also obtains the best accuracies on experiments performed with images having a 4x and 8x resolution difference. The source code of SRCDNet will be available at <a class="link-external link-https" href="https://github.com/liumency/SRCDNet" rel="external noopener nofollow">this https URL</a>.      
### 44.Structural Characterization of Oscillations in Brain Networks with Rate Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2103.00134.pdf)
>  Among the versatile forms of dynamical patterns of activity exhibited by the brain, oscillations are one of the most salient and extensively studied, yet are still far from being well understood. In this paper, we provide various structural characterizations of the existence of oscillatory behavior in neural networks using a classical neural mass model of mesoscale brain activity called the linear-threshold model. Exploiting the switched-affine nature of linear-threshold dynamics, we obtain various necessary and/or sufficient conditions for the existence of oscillations in (i) two-dimensional excitatory-inhibitory networks (E-I pairs), (ii) networks with one inhibitory but arbitrary number of excitatory nodes, (iii) purely inhibitory networks with an arbitrary number of nodes, and (iv) networks of E-I pairs. Throughout our treatment, and given the arbitrary dimensionality of the considered dynamics, we rely on the lack of stable equilibria as a system-based proxy for the existence of oscillations, and provide extensive numerical results to support its tight relationship with the more standard, signal-based definition of oscillations in computational neuroscience.      
### 45.Coordinated Cyber-Attack Detection Model of Cyber-Physical Power System Based on the Operating State Data Link  [ :arrow_down: ](https://arxiv.org/pdf/2103.00133.pdf)
>  Existing coordinated cyber-attack detection methods have low detection accuracy and efficiency and poor generalization ability due to difficulties dealing with unbalanced attack data samples, high data dimensionality, and noisy data sets. This paper proposes a model for cyber and physical data fusion using a data link for detecting attacks on a Cyber-Physical Power System (CPPS). Two-step principal component analysis (PCA) is used for classifying the system's operating status. An adaptive synthetic sampling algorithm is used to reduce the imbalance in the categories' samples. The loss function is improved according to the feature intensity difference of the attack event, and an integrated classifier is established using a classification algorithm based on the cost-sensitive gradient boosting decision tree (CS-GBDT). The simulation results show that the proposed method provides higher accuracy, recall, and F-Score than comparable algorithms.      
### 46.A Low-Complexity ADMM-based Massive MIMO Detectors via Deep Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.00131.pdf)
>  An alternate direction method of multipliers (ADMM)-based detectors can achieve good performance in both small and large-scale multiple-input multiple-output (MIMO) systems. However, due to the difficulty of choosing the optimal penalty parameters, their performance is limited. This paper presents a deep neural network (DNN)-based massive MIMO detection method which can overcome the above limitation. It exploits the unfolding technique and learns to estimate the penalty parameters. Additionally, a computationally cheaper detector is also proposed. The proposed methods can handle the higher-order modulation signals. Numerical results are presented to demonstrate the performances of the proposed methods compared with the existing works.      
### 47.Uniquely Decomposable Constellation Group for SCMA Codebook Design  [ :arrow_down: ](https://arxiv.org/pdf/2103.00126.pdf)
>  Sparse code multiple access (SCMA), which helps improve spectrum efficiency (SE) and enhance connectivity, has been proposed as a non-orthogonal multiple access (NOMA) scheme for 5G systems. In SCMA, codebook design determines system overload ratio and detection performance at a receiver. In this paper, an SCMA codebook design approach is proposed based on uniquely decomposable constellation group (UDCG). We show that there are $N+1 (N \geq 1)$ constellations in the proposed UDCG, each of which has $M (M \geq 2)$ constellation points. These constellations are allocated to users sharing the same resource. Combining the constellations allocated on multiple resources of each user, we can obtain UDCG-based codebook sets. Bit error ratio (BER) performance will be discussed in terms of coding gain maximization with superimposed constellations and UDCG-based codebooks. Simulation results demonstrate that the superimposed constellation of each resource has large minimum Euclidean distance (MED) and meets uniquely decodable constraint. Thus, BER performance of the proposed codebook design approach outperforms that of the existing codebook design schemes in both uncoded and coded SCMA systems, especially for large-size codebooks.      
### 48.Deep Learning-based Compressive Beam Alignment in mmWave Vehicular Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00125.pdf)
>  Millimeter wave vehicular channels exhibit structure that can be exploited for beam alignment with fewer channel measurements compared to exhaustive beam search. With fixed layouts of roadside buildings and regular vehicular moving trajectory, the dominant path directions of channels will likely be among a subset of beam directions instead of distributing randomly over the whole beamspace. In this paper, we propose a deep learning-based technique to design a structured compressed sensing (CS) matrix that is well suited to the underlying channel distribution for mmWave vehicular beam alignment. The proposed approach leverages both sparsity and the particular spatial structure that appears in vehicular channels. We model the compressive channel acquisition by a two-dimensional (2D) convolutional layer followed by dropout. We design fully-connected layers to optimize channel acquisition and beam alignment. We incorporate the low-resolution phase shifter constraint during neural network training by using projected gradient descent for weight updates. Furthermore, we exploit channel spectral structure to optimize the power allocated for different subcarriers. Simulations indicate that our deep learning-based approach achieves better beam alignment than standard CS techniques which use random phase shift-based design. Numerical experiments also show that one single subcarrier is sufficient to provide necessary information for beam alignment.      
### 49.CXR-Net: An Artificial Intelligence Pipeline for Quick Covid-19 Screening of Chest X-Rays  [ :arrow_down: ](https://arxiv.org/pdf/2103.00087.pdf)
>  CXR-Net is a two-module Artificial Intelligence pipeline for the quick detection of SARS-CoV-2 from chest X-rays (CXRs). Module 1 was trained on a public dataset of 6395 CXRs with radiologist annotated lung contours to generate masks of the lungs that overlap the heart and large vasa. Module 2 is a hybrid convnet in which the first convolutional layer with learned coefficients is replaced by a layer with fixed coefficients provided by the Wavelet Scattering Transform (WST). Module 2 takes as inputs the patients CXRs and corresponding lung masks calculated by Module 1, and produces as outputs a class assignment (Covid vs. non-Covid) and high resolution heat maps that identify the SARS associated lung regions. Module 2 was trained on a dataset of CXRs from non-Covid and RT-PCR confirmed Covid patients acquired at the Henry Ford Health System (HFHS) Hospital in Detroit. All non-Covid CXRs were from pre-Covid era (2018-2019), and included images from both normal lungs and lungs affected by non-Covid pathologies. Training and test sets consisted of 2265 CXRs (1417 Covid negative, 848 Covid positive), and 1532 CXRs (945 Covid negative, 587 Covid positive), respectively. Six distinct cross-validation models, each trained on 1887 images and validated against 378 images, were combined into an ensemble model that was used to classify the CXR images of the test set with resulting Accuracy = 0.789, Precision = 0.739, Recall = 0.693, F1 score = 0.715, ROC(AUC) = 0.852.      
### 50.Laser Inter-Satellite Links in a Starlink Constellation  [ :arrow_down: ](https://arxiv.org/pdf/2103.00056.pdf)
>  Laser inter-satellite links (LISLs) are envisioned between satellites in upcoming satellite constellations, such as Phase I of SpaceX's Starlink. Within a constellation, satellites can establish LISLs with other satellites in the same orbital plane or in different orbital planes. We present a classification of LISLs based on the location of satellites within a constellation and the duration of LISLs. Then, using satellite constellation for Phase I of Starlink, we study the effect of varying a satellite's LISL range on the number of different types of LISLs it can establish with other satellites. In addition to permanent LISLs, we observe a significant number of temporary LISLs between satellites in crossing orbital planes. Such LISLs can play a vital role in achieving low-latency paths within next-generation optical wireless satellite networks.      
### 51.Constructing Dampened LTI Systems Generating Polynomial Bases  [ :arrow_down: ](https://arxiv.org/pdf/2103.00051.pdf)
>  We present an alternative derivation of the LTI system underlying the Legendre Delay Network (LDN). To this end, we first construct an LTI system that generates the Legendre polynomials. We then dampen the system by approximating a windowed impulse response, using what we call a "delay re-encoder". The resulting LTI system is equivalent to the LDN system. The same technique can be applied to arbitrary polynomial bases, although there typically is no set of closed form equations that can be used to construct the corresponding LTI systems.      
### 52.Validating Clustering Frameworks for Electric Load Demand Profiles  [ :arrow_down: ](https://arxiv.org/pdf/2103.00030.pdf)
>  Large-scale deployment of smart meters has made it possible to collect sufficient and high-resolution data of residential electric demand profiles. Clustering analysis of these profiles is important to further analyze and comment on electricity consumption patterns. Although many clustering techniques have been proposed in the literature over the years, it is often noticed that different techniques fit best for different datasets. To identify the most suitable technique, standard clustering validity indices are often used. These indices focus primarily on the intrinsic characteristics of the clustering results. Moreover, different indices often give conflicting recommendations which can only be clarified with heuristics about the dataset and/or the expected cluster structures -- information that is rarely available in practical situations. This paper presents a novel scheme to validate and compare the clustering results objectively. Additionally, the proposed scheme considers all the steps prior to the clustering algorithm, including the pre-processing and dimensionality reduction steps, in order to provide recommendations over the complete framework. Accordingly, the proposed strategy is shown to provide better, unbiased, and uniform recommendations as compared to the standard Clustering Validity Indices.      
### 53.ECGT2T: Electrocardiogram synthesis from Two asynchronous leads to Ten leads  [ :arrow_down: ](https://arxiv.org/pdf/2103.00006.pdf)
>  The electrocardiogram (ECG) records electrical signals in a non-invasive way to observe the condition of the heart. It consists of 12 leads that look at the heart from different directions. Recently, various wearable devices have enabled immediate access to the ECG without the use of wieldy equipment. However, they only provide ECGs with one or two leads. This results in an inaccurate diagnosis of cardiac disease. We propose a deep generative model for ECG synthesis from two asynchronous leads to ten leads (ECGT2T). It first represents a heart condition referring to two leads, and then generates ten leads based on the represented heart condition. Both the rhythm and amplitude of leads generated by ECGT2T resemble those of the original ones, while the technique removes noise and the baseline wander appearing in the original leads. As a data augmentation method, ECGT2T improves the classification performance of models compared with models using ECGs with a couple of leads.      
### 54.3D coherent x-ray imaging via deep convolutional neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.00001.pdf)
>  As a critical component of coherent X-ray diffraction imaging (CDI), phase retrieval has been extensively applied in X-ray structural science to recover the 3D morphological information inside measured particles. Despite meeting all the oversampling requirements of Sayre and Shannon, current phase retrieval approaches still have trouble achieving a unique inversion of experimental data in the presence of noise. Here, we propose to overcome this limitation by incorporating a 3D Machine Learning (ML) model combining (optional) supervised training with unsupervised refinement. The trained ML model can rapidly provide an immediate result with high accuracy, which will benefit real-time experiments. More significantly, the Neural Network model can be used without any prior training to learn the missing phases of an image based on minimization of an appropriate loss function alone. We demonstrate significantly improved performance with experimental Bragg CDI data over traditional iterative phase retrieval algorithms.      
### 55.Gradient Coding with Dynamic Clustering for Straggler-Tolerant Distributed Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.01206.pdf)
>  Distributed implementations are crucial in speeding up large scale machine learning applications. Distributed gradient descent (GD) is widely employed to parallelize the learning task by distributing the dataset across multiple workers. A significant performance bottleneck for the per-iteration completion time in distributed synchronous GD is $straggling$ workers. Coded distributed computation techniques have been introduced recently to mitigate stragglers and to speed up GD iterations by assigning redundant computations to workers. In this paper, we consider gradient coding (GC), and propose a novel dynamic GC scheme, which assigns redundant data to workers to acquire the flexibility to dynamically choose from among a set of possible codes depending on the past straggling behavior. In particular, we consider GC with clustering, and regulate the number of stragglers in each cluster by dynamically forming the clusters at each iteration; hence, the proposed scheme is called $GC$ $with$ $dynamic$ $clustering$ (GC-DC). Under a time-correlated straggling behavior, GC-DC gains from adapting to the straggling behavior over time such that, at each iteration, GC-DC aims at distributing the stragglers across clusters as uniformly as possible based on the past straggler behavior. For both homogeneous and heterogeneous worker models, we numerically show that GC-DC provides significant improvements in the average per-iteration completion time without an increase in the communication load compared to the original GC scheme.      
### 56.Unsupervised Classification of Voiced Speech and Pitch Tracking Using Forward-Backward Kalman Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2103.01173.pdf)
>  The detection of voiced speech, the estimation of the fundamental frequency, and the tracking of pitch values over time are crucial subtasks for a variety of speech processing techniques. Many different algorithms have been developed for each of the three subtasks. We present a new algorithm that integrates the three subtasks into a single procedure. The algorithm can be applied to pre-recorded speech utterances in the presence of considerable amounts of background noise. We combine a collection of standard metrics, such as the zero-crossing rate, for example, to formulate an unsupervised voicing classifier. The estimation of pitch values is accomplished with a hybrid autocorrelation-based technique. We propose a forward-backward Kalman filter to smooth the estimated pitch contour. In experiments, we are able to show that the proposed method compares favorably with current, state-of-the-art pitch detection algorithms.      
### 57.Deep Perceptual Image Quality Assessment for Compression  [ :arrow_down: ](https://arxiv.org/pdf/2103.01114.pdf)
>  Lossy Image compression is necessary for efficient storage and transfer of data. Typically the trade-off between bit-rate and quality determines the optimal compression level. This makes the image quality metric an integral part of any imaging system. While the existing full-reference metrics such as PSNR and SSIM may be less sensitive to perceptual quality, the recently introduced learning methods may fail to generalize to unseen data. In this paper we propose the largest image compression quality dataset to date with human perceptual preferences, enabling the use of deep learning, and we develop a full reference perceptual quality assessment metric for lossy image compression that outperforms the existing state-of-the-art methods. We show that the proposed model can effectively learn from thousands of examples available in the new dataset, and consequently it generalizes better to other unseen datasets of human perceptual preference.      
### 58.Stochastic Model Predictive Control for tracking of distributed linear systems with additive uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2103.01087.pdf)
>  In this paper, we propose a chance constrained stochastic model predictive control scheme for reference tracking of distributed linear time-invariant systems with additive stochastic uncertainty. The chance constraints are reformulated analytically based on mean-variance information, where we design suitable Probabilistic Reachable Sets for constraint tightening. Furthermore, the chance constraints are proven to be satisfied in closed-loop operation. The design of an invariant set for tracking complements the controller and ensures convergence to arbitrary admissible reference points, while a conditional initialization scheme provides the fundamental property of recursive feasibility. The paper closes with a numerical example, highlighting the convergence to changing output references and empirical constraint satisfaction.      
### 59.Inductive biases, pretraining and fine-tuning jointly account for brain responses to speech  [ :arrow_down: ](https://arxiv.org/pdf/2103.01032.pdf)
>  Our ability to comprehend speech remains, to date, unrivaled by deep learning models. This feat could result from the brain's ability to fine-tune generic sound representations for speech-specific processes. To test this hypothesis, we compare i) five types of deep neural networks to ii) human brain responses elicited by spoken sentences and recorded in 102 Dutch subjects using functional Magnetic Resonance Imaging (fMRI). Each network was either trained on an acoustics scene classification, a speech-to-text task (based on Bengali, English, or Dutch), or not trained. The similarity between each model and the brain is assessed by correlating their respective activations after an optimal linear projection. The differences in brain-similarity across networks revealed three main results. First, speech representations in the brain can be accounted for by random deep networks. Second, learning to classify acoustic scenes leads deep nets to increase their brain similarity. Third, learning to process phonetically-related speech inputs (i.e., Dutch vs English) leads deep nets to reach higher levels of brain-similarity than learning to process phonetically-distant speech inputs (i.e. Dutch vs Bengali). Together, these results suggest that the human brain fine-tunes its heavily-trained auditory hierarchy to learn to process speech.      
### 60.Periodic trajectories in P-time event graphs and the non-positive circuit weight problem  [ :arrow_down: ](https://arxiv.org/pdf/2103.01024.pdf)
>  P-time event graphs (P-TEGs) are specific timed discrete-event systems, in which the timing of events is constrained by intervals. An important problem is to check, for all natural numbers $d$, the existence of consistent $d$-periodic trajectories for a given P-TEG. Let us consider a different, seemingly unrelated problem in graph theory: given three arbitrary square matrices $P$, $I$ and $C$ with elements in $\mathbb{R}\cup\{-\infty\}$, find all real values of parameter $\lambda$ such that the parametric directed graph having arcs weights of the form $w((j,i)) = \max(P_{ij} + \lambda, I_{ij} - \lambda, C_{ij})$ (for all arcs $(j,i)$) does not contain circuits with positive weight. In a related paper, we have proposed a strongly polynomial algorithm that solves the latter problem faster than other algorithms reported in literature. In the present paper, we show that the first problem can be formulated as an instance of the second; consequently, we prove that the same algorithm can be used to find $d$-periodic trajectories in P-TEGs faster than with previous approaches.      
### 61.Low-Complexity Zero-Forcing Precoding for XL-MIMO Transmissions  [ :arrow_down: ](https://arxiv.org/pdf/2103.00971.pdf)
>  Deploying antenna arrays with an asymptotically large aperture will be central to achieving the theoretical gains of massive MIMO in beyond-5G systems. Such extra-large MIMO (XL-MIMO) systems experience propagation conditions which are not typically observed in conventional massive MIMO systems, such as spatial non-stationarities and near-field propagation. Moreover, standard precoding schemes, such as zero-forcing (ZF), may not apply to XL-MIMO transmissions due to the prohibitive complexity associated with such a large-scale scenario. We propose two novel precoding schemes that aim at reducing the complexity without losing much performance. The proposed schemes leverage a plane-wave approximation and user grouping to obtain a low-complexity approximation of the ZF precoder. Our simulation results show that the proposed schemes offer a possibility for a performance and complexity trade-off compared to the benchmark schemes.      
### 62.Automatic Stockpile Volume Monitoring using Multi-view Stereo from SkySat Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2103.00945.pdf)
>  This paper proposes a system for automatic surface volume monitoring from time series of SkySat pushframe imagery. A specific challenge of building and comparing large 3D models from SkySat data is to correct inconsistencies between the camera models associated to the multiple views that are necessary to cover the area at a given time, where these camera models are represented as Rational Polynomial Cameras (RPCs). We address the problem by proposing a date-wise RPC refinement, able to handle dynamic areas covered by sets of partially overlapping views. The cameras are refined by means of a rotation that compensates for errors due to inaccurate knowledge of the satellite attitude. The refined RPCs are then used to reconstruct multiple consistent Digital Surface Models (DSMs) from different stereo pairs at each date. RPC refinement strengthens the consistency between the DSMs of each date, which is extremely beneficial to accurately measure volumes in the 3D surface models. The system is tested in a real case scenario, to monitor large coal stockpiles. Our volume estimates are validated with measurements collected on site in the same period of time.      
### 63.Latent linear dynamics in spatiotemporal medical data  [ :arrow_down: ](https://arxiv.org/pdf/2103.00930.pdf)
>  Spatiotemporal imaging is common in medical imaging, with applications in e.g. cardiac diagnostics, surgical guidance and radiotherapy monitoring. In this paper, we present an unsupervised model that identifies the underlying dynamics of the system, only based on the sequential images. The model maps the input to a low-dimensional latent space wherein a linear relationship holds between a hidden state process and the observed latent process. Knowledge of the system dynamics enables denoising, imputation of missing values and extrapolation of future image frames. We use a Variational Auto-Encoder (VAE) for the dimensionality reduction and a Linear Gaussian State Space Model (LGSSM) for the latent dynamics. The model, known as a Kalman Variational Auto-Encoder, is end-to-end trainable and the weights, both in the VAE and LGSSM, are simultaneously updated by maximizing the evidence lower bound of the marginal log likelihood. Our experiment, on cardiac ultrasound time series, shows that the dynamical model provide better reconstructions than a similar model without dynamics. And also possibility to impute and extrapolate for missing samples.      
### 64.DR-TANet: Dynamic Receptive Temporal Attention Network for Street Scene Change Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.00879.pdf)
>  Street scene change detection continues to capture researchers' interests in the computer vision community. It aims to identify the changed regions of the paired street-view images captured at different times. The state-of-the-art network based on the encoder-decoder architecture leverages the feature maps at the corresponding level between two channels to gain sufficient information of changes. Still, the efficiency of feature extraction, feature correlation calculation, even the whole network requires further improvement. This paper proposes the temporal attention and explores the impact of the dependency-scope size of temporal attention on the performance of change detection. In addition, based on the Temporal Attention Module (TAM), we introduce a more efficient and light-weight version - Dynamic Receptive Temporal Attention Module (DRTAM) and propose the Concurrent Horizontal and Vertical Attention (CHVA) to improve the accuracy of the network on specific challenging entities. On street scene datasets `GSV', `TSUNAMI' and `VL-CMU-CD', our approach gains excellent performance, establishing new state-of-the-art scores without bells and whistles, while maintaining high efficiency applicable in autonomous vehicles.      
### 65.Panoramic Panoptic Segmentation: Towards Complete Surrounding Understanding via Unsupervised Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.00868.pdf)
>  In this work, we introduce panoramic panoptic segmentation as the most holistic scene understanding both in terms of field of view and image level understanding. A complete surrounding understanding provides a maximum of information to the agent, which is essential for any intelligent vehicle in order to make informed decisions in a safety-critical dynamic environment such as real-world traffic. In order to overcome the lack of annotated panoramic images, we propose a framework which allows model training on standard pinhole images and transfers the learned features to a different domain. Using our proposed method, we manage to achieve significant improvements of over 5\% measured in PQ over non-adapted models on our Wild Panoramic Panoptic Segmentation (WildPPS) dataset. We show that our proposed Panoramic Robust Feature (PRF) framework is not only suitable to improve performance on panoramic images but can be beneficial whenever model training and deployment are executed on data taken from different distributions. As an additional contribution, we publish WildPPS: The first panoramic panoptic image dataset to foster progress in surrounding perception.      
### 66.Robust stability analysis of a simple data-driven model predictive control approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.00851.pdf)
>  In this paper, we provide a theoretical analysis of closed-loop properties of a simple data-driven model predictive control (MPC) scheme. The formulation does not involve any terminal ingredients, thus allowing for a simple implementation without (potential) feasibility issues. The proposed approach relies on an implicit description of linear time-invariant systems based on behavioral systems theory, which only requires one input-output trajectory of an unknown system. For the nominal case with noise-free data, we prove that the data-driven MPC scheme ensures exponential stability for the closed loop if the prediction horizon is sufficiently long. Moreover, we analyze the robust data-driven MPC scheme for noisy output measurements for which we prove closed-loop practical exponential stability. The advantages of the presented approach are illustrated with a numerical example.      
### 67.Fast threshold optimization for multi-label audio tagging using Surrogate gradient learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.00833.pdf)
>  Multi-label audio tagging consists of assigning sets of tags to audio recordings. At inference time, thresholds are applied on the confidence scores outputted by a probabilistic classifier, in order to decide which classes are detected active. In this work, we consider having at disposal a trained classifier and we seek to automatically optimize the decision thresholds according to a performance metric of interest, in our case F-measure (micro-F1). We propose a new method, called SGL-Thresh for Surrogate Gradient Learning of Thresholds, that makes use of gradient descent. Since F1 is not differentiable, we propose to approximate the thresholding operation gradients with the gradients of a sigmoid function. We report experiments on three datasets, using state-of-the-art pre-trained deep neural networks. In all cases, SGL-Thresh outperformed three other approaches: a default threshold value (defThresh), an heuristic search algorithm and a method estimating F1 gradients numerically. It reached 54.9\% F1 on AudioSet eval, compared to 50.7% with defThresh. SGL-Thresh is very fast and scalable to a large number of tags. To facilitate reproducibility, data and source code in Pytorch are available online: <a class="link-external link-https" href="https://github.com/topel/SGL-Thresh" rel="external noopener nofollow">this https URL</a>      
### 68.6G Downlink Transmission via Rate Splitting Space Division Multiple Access Based on Grouped Code Index Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2103.00829.pdf)
>  A novel rate splitting space division multiple access (SDMA) scheme based on grouped code index modulation (GrCIM) is proposed for the sixth generation (6G) downlink transmission. The proposed RSMA-GrCIM scheme transmits information to multiple user equipments (UEs) through the space division multiple access (SDMA) technique, and exploits code index modulation for rate splitting. Since the CIM scheme conveys information bits via the index of the selected Walsh code and binary phase shift keying (BPSK) signal, our RSMA scheme transmits the private messages of each user through the indices, and the common messages via the BPSK signal. Moreover, the Walsh code set is grouped into several orthogonal subsets to eliminate the interference from other users. A maximum likelihood (ML) detector is used to recovery the source bits, and a mathematical analysis is provided for the upper bound bit error ratio (BER) of each user. Comparisons are also made between our proposed scheme and the traditional SDMA scheme in spectrum utilization, number of available UEs, etc. Numerical results are given to verify the effectiveness of the proposed SDMA-GrCIM scheme.      
### 69.Enhancement for Robustness of Koopman Operator-based Data-driven Mobile Robotic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00812.pdf)
>  Koopman operator theory has served as the basis to extract dynamics for nonlinear system modeling and control across settings, including non-holonomic mobile robot control. Despite its widespread use, research on safety guarantees for systems the dynamics of which are extracted via the Koopman operator, has started receiving attention only recently. In this paper, we propose a way to quantify the prediction error because of noisy measurements when the Koopman operator is approximated via Extended Dynamic Mode Decomposition. We further develop an enhanced robot control strategy to endow robustness to a class of data-driven (robotic) systems that rely on Koopman operator theory, and we show how part of the strategy can happen offline in an effort to make our algorithm capable of real-time implementation. We perform a parametric study to evaluate the (theoretical) performance of the algorithm using a Van der Pol oscillator, and conduct a series of simulated experiments in Gazebo using a non-holonomic wheeled robot.      
### 70.Diffusion-weighted MRI-guided needle biopsies permit quantitative tumor heterogeneity assessment and cell load estimation  [ :arrow_down: ](https://arxiv.org/pdf/2103.00714.pdf)
>  Quantitative information on tumor heterogeneity and cell load could assist in designing effective and refined personalized treatment strategies. It was recently shown by us that such information can be inferred from the diffusion parameter D derived from the diffusion-weighted MRI (DWI) if a relation between D and cell density can be established. However, such relation cannot a priori be assumed to be constant for all patients and tumor types. Hence to assist in clinical decisions in palliative settings, the relation needs to be established without tumor resection. It is here demonstrated that biopsies may contain sufficient information for this purpose if the localization of biopsies is chosen as systematically elaborated in this paper. A superpixel-based method for automated optimal localization of biopsies from the DWI D-map is proposed. The performance of the DWI-guided procedure is evaluated by extensive simulations of biopsies. Needle biopsies yield sufficient histological information to establish a quantitative relationship between D-value and cell density, provided they are taken from regions with high, intermediate, and low D-value in DWI. The automated localization of the biopsy regions is demonstrated from a NSCLC patient tumor. In this case, even two or three biopsies give a reasonable estimate. Simulations of needle biopsies under different conditions indicate that the DWI-guidance highly improves the estimation results. Tumor cellularity and heterogeneity in solid tumors may be reliably investigated from DWI and a few needle biopsies that are sampled in regions of well-separated D-values, excluding adipose tissue. This procedure could provide a way of embedding in the clinical workflow assistance in cancer diagnosis and treatment based on personalized information.      
### 71.Bayesian filtering for nonlinear stochastic systems using holonomic gradient method with integral transform  [ :arrow_down: ](https://arxiv.org/pdf/2103.00675.pdf)
>  This paper proposes a symbolic-numeric Bayesian filtering method for a class of discrete-time nonlinear stochastic systems to achieve high accuracy with a relatively small online computational cost. The proposed method is based on the holonomic gradient method (HGM), which is a symbolic-numeric method to evaluate integrals efficiently depending on several parameters. By approximating the posterior probability density function (PDF) of the state as a Gaussian PDF, the update process of its mean and variance can be formulated as evaluations of several integrals that exactly take into account the nonlinearity of the system dynamics. An integral transform is used to evaluate these integrals more efficiently using the HGM than our previous method. Further, a numerical example is provided to demonstrate the efficiency of the proposed method compared to other existing methods.      
### 72.Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training  [ :arrow_down: ](https://arxiv.org/pdf/2103.00673.pdf)
>  Normalization techniques have become a basic component in modern convolutional neural networks (ConvNets). In particular, many recent works demonstrate that promoting the orthogonality of the weights helps train deep models and improve robustness. For ConvNets, most existing methods are based on penalizing or normalizing weight matrices derived from concatenating or flattening the convolutional kernels. These methods often destroy or ignore the benign convolutional structure of the kernels; therefore, they are often expensive or impractical for deep ConvNets. In contrast, we introduce a simple and efficient ``convolutional normalization'' method that can fully exploit the convolutional structure in the Fourier domain and serve as a simple plug-and-play module to be conveniently incorporated into any ConvNets. Our method is inspired by recent work on preconditioning methods for convolutional sparse coding and can effectively promote each layer's channel-wise isometry. Furthermore, we show that convolutional normalization can reduce the layerwise spectral norm of the weight matrices and hence improve the Lipschitzness of the network, leading to easier training and improved robustness for deep ConvNets. Applied to classification under noise corruptions and generative adversarial network (GAN), we show that convolutional normalization improves the robustness of common ConvNets such as ResNet and the performance of GAN. We verify our findings via extensive numerical experiments on CIFAR-10, CIFAR-100, and ImageNet.      
### 73.OpenICS: Open Image Compressive Sensing Toolbox and Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2103.00652.pdf)
>  We present OpenICS, an image compressive sensing toolbox that includes multiple image compressive sensing and reconstruction algorithms proposed in the past decade. Due to the lack of standardization in the implementation and evaluation of the proposed algorithms, the application of image compressive sensing in the real-world is limited. We believe this toolbox is the first framework that provides a unified and standardized implementation of multiple image compressive sensing algorithms. In addition, we also conduct a benchmarking study on the methods included in this framework from two aspects: reconstruction accuracy and reconstruction efficiency. We wish this toolbox and benchmark can serve the growing research community of compressive sensing and the industry applying image compressive sensing to new problems as well as developing new methods more efficiently. Code and models are available at <a class="link-external link-https" href="https://github.com/PSCLab-ASU/OpenICS" rel="external noopener nofollow">this https URL</a>. The project is still under maintenance, and we will keep this document updated.      
### 74.Dynamic collision avoidance for multiple robotic manipulators based on a non-cooperative multi-agent game  [ :arrow_down: ](https://arxiv.org/pdf/2103.00583.pdf)
>  A flexible operation of multiple robotic manipulators in a shared workspace requires an online trajectory planning with static and dynamic collision avoidance. In this work, we propose a real-time capable motion control algorithm, based on non-linear model predictive control, which accounts for static and dynamic collision avoidance. The proposed algorithm is formulated as a non-cooperative game, where each robot is considered as an agent. Each agent optimizes its own motion and accounts for the predicted movement of surrounding agents. We propose a novel approach to formulate the dynamic collision constraints. Additionally, we account for deadlocks that might occur in a setup of multiple robotic manipulators. We validate our algorithm on a pick and place scenario for four collaborative robots operating in a common workspace in the simulation environment Gazebo. The robots are controlled by the Robot Operating System (ROS). We demonstrate, that our approach is real-time capable and, due to the distributed nature of the approach, easily scales to an arbitrary number of robot manipulators in a shared workspace.      
### 75.Deepfakes Generation and Detection: State-of-the-art, open challenges, countermeasures, and way forward  [ :arrow_down: ](https://arxiv.org/pdf/2103.00484.pdf)
>  Easy access to audio-visual content on social media, combined with the availability of modern tools such as Tensorflow or Keras, open-source trained models, and economical computing infrastructure, and the rapid evolution of deep-learning (DL) methods, especially Generative Adversarial Networks (GAN), have made it possible to generate deepfakes to disseminate disinformation, revenge porn, financial frauds, hoaxes, and to disrupt government functioning. The existing surveys have mainly focused on deepfake video detection only. No attempt has been made to review approaches for detection and generation of both audio and video deepfakes. This paper provides a comprehensive review and detailed analysis of existing tools and machine learning (ML) based approaches for deepfake generation and the methodologies used to detect such manipulations for the detection and generation of both audio and video deepfakes. For each category of deepfake, we discuss information related to manipulation approaches, current public datasets, and key standards for the performance evaluation of deepfake detection techniques along with their results. Additionally, we also discuss open challenges and enumerate future directions to guide future researchers on issues that need to be considered to improve the domains of both the deepfake generation and detection. This work is expected to assist the readers in understanding the creation and detection mechanisms of deepfake, along with their current limitations and future direction.      
### 76.Passive Beamforming Design and Channel Estimation for IRS Communication System with Few-Bit ADCs  [ :arrow_down: ](https://arxiv.org/pdf/2103.00463.pdf)
>  Utilizing intelligent reflecting surface (IRS) was proven to be efficient in improving the energy efficiency for wireless networks. In this paper, we investigate the passive beamforming and channel estimation for IRS assisted wireless communications with low-resolution analog-to-digital converters (ADCs) at the receiver. We derive the approximate achievable rate by using the Bussgang theorem. Based on the derived analytical achievable rate expression, we maximize the achievable rate by using semidefinite programming (SDP), branch-and-bound (BB), and gradient-based approaches. A maximum likelihood (ML) estimator is then proposed for channel estimation by considering the $\mathrm{1}$-bit quantization ADC. Numerical result shows that the proposed beamforming design and channel estimation method significantly outperforms the existing methods.      
### 77.Integrating Over-the-Air Federated Learning and Non-Orthogonal Multiple Access: What Role can RIS Play?  [ :arrow_down: ](https://arxiv.org/pdf/2103.00435.pdf)
>  With the aim of integrating over-the-air federated learning (AirFL) and non-orthogonal multiple access (NOMA) into an on-demand universal framework, this paper proposes a novel reconfigurable intelligent surface (RIS)-aided hybrid network by leveraging the RIS to flexibly adjust the signal processing order of heterogeneous data. The objective of this work is to maximize the achievable hybrid rate by jointly optimizing the transmit power, controlling the receive scalar, and designing the phase shifts. Since the concurrent transmissions of all computation and communication signals are aided by the discrete phase shifts at the RIS, the considered problem (P0) is a challenging mixed integer programming problem. To tackle this intractable issue, we decompose the original problem (P0) into a non-convex problem (P1) and a combinatorial problem (P2), which are characterized by the continuous and discrete variables, respectively. For the transceiver design problem (P1), the power allocation subproblem is first solved by invoking the difference-of-convex programming, and then the receive control subproblem is addressed by using the successive convex approximation, where the closed-form expressions of simplified cases are derived to obtain deep insights. For the reflection design problem (P2), the relaxation-then-quantization method is adopted to find a suboptimal solution for striking a trade-off between complexity and performance. Afterwards, an alternating optimization algorithm is developed to solve the non-linear and non-convex problem (P0) iteratively. Finally, simulation results reveal that 1) the proposed RIS-aided hybrid network can support the on-demand communication and computation efficiently, 2) the performance gains can be improved by properly selecting the location of the RIS, and 3) the designed algorithms are also applicable to conventional networks with only AirFL or NOMA users.      
### 78.Learning-Based Phase Compression and Quantization for Massive MIMO CSI Feedback with Magnitude-Aided Information  [ :arrow_down: ](https://arxiv.org/pdf/2103.00432.pdf)
>  In frequency-division duplexing (FDD) massive multiple-input multiple-output (MIMO) wireless systems, deep learning techniques are regarded as one of the most efficient solutions for CSI recovery. In recent times, to achieve better CSI magnitude recovery at base stations, advanced learning-based CSI feedback solutions decouple magnitude and phase recovery to fully leverage the strong correlation between current CSI magnitudes and those of previous time slots, uplink band, and near locations. However, the CSI phase recovery is a major challenge to further enhance the CSI recovery owing to its complicated patterns. In this letter, we propose a learning-based CSI feedback framework based on limited feedback and magnitude-aided information. In contrast to previous works, our proposed framework with a proposed loss function enables end-to-end learning to jointly optimize the CSI magnitude and phase recovery performance. Numerical simulations show that, the proposed loss function outperform alternate approaches for phase recovery over the overall CSI recovery in both indoor and outdoor scenarios. The performance of the proposed framework was also examined using different core layer designs.      
### 79.Training Generative Adversarial Networks in One Stage  [ :arrow_down: ](https://arxiv.org/pdf/2103.00430.pdf)
>  Generative Adversarial Networks (GANs) have demonstrated unprecedented success in various image generation tasks. The encouraging results, however, come at the price of a cumbersome training process, during which the generator and discriminator are alternately updated in two stages. In this paper, we investigate a general training scheme that enables training GANs efficiently in only one stage. Based on the adversarial losses of the generator and discriminator, we categorize GANs into two classes, Symmetric GANs and Asymmetric GANs, and introduce a novel gradient decomposition method to unify the two, allowing us to train both classes in one stage and hence alleviate the training effort. Computational analysis and experimental results on several datasets and various network architectures demonstrate that, the proposed one-stage training scheme yields a solid 1.5$\times$ acceleration over conventional training schemes, regardless of the network architectures of the generator and discriminator. Furthermore, we show that the proposed method is readily applicable to other adversarial-training scenarios, such as data-free knowledge distillation. Our source code will be published soon.      
### 80.Exploiting Attention-based Sequence-to-Sequence Architectures for Sound Event Localization  [ :arrow_down: ](https://arxiv.org/pdf/2103.00417.pdf)
>  Sound event localization frameworks based on deep neural networks have shown increased robustness with respect to reverberation and noise in comparison to classical parametric approaches. In particular, recurrent architectures that incorporate temporal context into the estimation process seem to be well-suited for this task. This paper proposes a novel approach to sound event localization by utilizing an attention-based sequence-to-sequence model. These types of models have been successfully applied to problems in natural language processing and automatic speech recognition. In this work, a multi-channel audio signal is encoded to a latent representation, which is subsequently decoded to a sequence of estimated directions-of-arrival. Herein, attentions allow for capturing temporal dependencies in the audio signal by focusing on specific frames that are relevant for estimating the activity and direction-of-arrival of sound events at the current time-step. The framework is evaluated on three publicly available datasets for sound event localization. It yields superior localization performance compared to state-of-the-art methods in both anechoic and reverberant conditions.      
### 81.Brain Signals to Rescue Aphasia, Apraxia and Dysarthria Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.00383.pdf)
>  In this paper, we propose a deep learning-based algorithm to improve the performance of automatic speech recognition (ASR) systems for aphasia, apraxia, and dysarthria speech by utilizing electroencephalography (EEG) features recorded synchronously with aphasia, apraxia, and dysarthria speech. We demonstrate a significant decoding performance improvement by more than 50\% during test time for isolated speech recognition task and we also provide preliminary results indicating performance improvement for the more challenging continuous speech recognition task by utilizing EEG features. The results presented in this paper show the first step towards demonstrating the possibility of utilizing non-invasive neural signals to design a real-time robust speech prosthetic for stroke survivors recovering from aphasia, apraxia, and dysarthria. Our aphasia, apraxia, and dysarthria speech-EEG data set will be released to the public to help further advance this interesting and crucial research.      
### 82.Towards Continual, Online, Unsupervised Depth  [ :arrow_down: ](https://arxiv.org/pdf/2103.00369.pdf)
>  Although depth extraction with passive sensors has seen remarkable improvement with deep learning, these approaches may fail to obtain correct depth if they are exposed to environments not observed during training. Online adaptation, where the neural network trains while deployed, with unsupervised learning provides a convenient solution. However, online adaptation causes a neural network to forget the past. Thus, past training is wasted and the network is not able to provide good results if it observes past scenes. This work deals with practical online-adaptation where the input is online and temporally-correlated, and training is completely unsupervised. Regularization and replay-based methods without task boundaries are proposed to avoid catastrophic forgetting while adapting to online data. Experiments are performed on different datasets with both structure-from-motion and stereo. Results of forgetting as well as adaptation are provided, which are superior to recent methods. The proposed approach is more inline with the artificial general intelligence paradigm as the neural network learns the scene where it is deployed without any supervision (target labels and tasks) and without forgetting about the past. Code is available at <a class="link-external link-http" href="http://github.com/umarKarim/cou-stereo" rel="external noopener nofollow">this http URL</a> and <a class="link-external link-http" href="http://github.com/umarKarim/cou-sfm" rel="external noopener nofollow">this http URL</a>.      
### 83.A Holistic Motion Planning and Control Solution to Challenge a Professional Racecar Driver  [ :arrow_down: ](https://arxiv.org/pdf/2103.00358.pdf)
>  We present a holistically designed three layer control architecture capable of outperforming a professional driver racing the same car. Our approach focuses on the co-design of the motion planning and control layers, extracting the full potential of the connected system. First, a high-level planner computes an optimal trajectory around the track, then in real-time the mid-level nonlinear model predictive controller follows this path using the high-level information as guidance. Finally a high frequency, low-level controller tracks the states predicted by the mid-level controller. Tracking the predicted behavior has two advantages: it reduces the mismatch between the model used in the upper layers and the real car, and allows for a torque vectoring command to be optimized by the higher level motion planners. The tailored design of the low-level controller proved to be crucial for bridging the gap between planning and control, unlocking unseen performance in autonomous racing. The proposed approach was verified on a full size racecar, resulting in a considerable improvement over the state-of-the-art results achieved on the same vehicle. Finally, we also show that the proposed co-design approach outperforms a professional racecar driver.      
### 84.End-to-end Uncertainty-based Mitigation of Adversarial Attacks to Automated Lane Centering  [ :arrow_down: ](https://arxiv.org/pdf/2103.00345.pdf)
>  In the development of advanced driver-assistance systems (ADAS) and autonomous vehicles, machine learning techniques that are based on deep neural networks (DNNs) have been widely used for vehicle perception. These techniques offer significant improvement on average perception accuracy over traditional methods, however, have been shown to be susceptible to adversarial attacks, where small perturbations in the input may cause significant errors in the perception results and lead to system failure. Most prior works addressing such adversarial attacks focus only on the sensing and perception modules. In this work, we propose an end-to-end approach that addresses the impact of adversarial attacks throughout perception, planning, and control modules. In particular, we choose a target ADAS application, the automated lane centering system in OpenPilot, quantify the perception uncertainty under adversarial attacks, and design a robust planning and control module accordingly based on the uncertainty analysis. We evaluate our proposed approach using both the public dataset and production-grade autonomous driving simulator. The experiment results demonstrate that our approach can effectively mitigate the impact of adversarial attacks and can achieve 55% to 90% improvement over the original OpenPilot.      
### 85.BiconNet: An Edge-preserved Connectivity-based Approach for Salient Object Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.00334.pdf)
>  Salient object detection (SOD) is viewed as a pixel-wise saliency modeling task by traditional deep learning-based methods. Although great progress has been made, a challenge of modern SOD models is the insufficient utilization of inter-pixel information, which usually results in imperfect segmentations near the edge regions. As we demonstrate, using a saliency map as the network output is a sub-optimal choice. To address this problem, we propose a connectivity-based approach named bilateral connectivity network (BiconNet), which uses a connectivity map instead of a saliency map as the network output for effective modeling of inter-pixel relationships and object saliency. Moreover, we propose a bilateral voting module to enhance the output connectivity map and a novel edge feature enhancement method that efficiently utilizes edge-specific features with negligible parameter increase. We show that our model can use any existing saliency-based SOD framework as its backbone. Through comprehensive experiments on five benchmark datasets, we demonstrate that our proposed method outperforms state-of-the-art SOD approaches.      
### 86.A Novel Adaptive Deep Network for Building Footprint Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.00286.pdf)
>  Building footprint segmentations for high resolution images are increasingly demanded for many remote sensing applications. By the emerging deep learning approaches, segmentation networks have made significant advances in the semantic segmentation of objects. However, these advances and the increased access to satellite images require the generation of accurate object boundaries in satellite images. In the current paper, we propose a novel network-based on Pix2Pix methodology to solve the problem of inaccurate boundaries obtained by converting satellite images into maps using segmentation networks in order to segment building footprints. To define the new network named G2G, our framework includes two generators where the first generator extracts localization features in order to merge them with the boundary features extracted from the second generator to segment all detailed building edges. Moreover, different strategies are implemented to enhance the quality of the proposed networks' results, implying that the proposed network outperforms state-of-the-art networks in segmentation accuracy with a large margin for all evaluation metrics. The implementation is available at <a class="link-external link-https" href="https://github.com/A2Amir/A-Novel-Adaptive-Deep-Network-for-Building-Footprint-Segmentation" rel="external noopener nofollow">this https URL</a>.      
### 87.On the Solution of the Travelling Salesman Problem for Nonlinear Salesman Dynamics using Symbolic Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.00260.pdf)
>  This paper proposes an algorithmic method to heuristically solve the famous Travelling Salesman Problem (TSP) when the salesman's path evolves in continuous state space and discrete time but with otherwise arbitrary (nonlinear) dynamics. The presented method is based on the framework of Symbolic Control. In this way, our method returns a provably correct state-feedback controller for the underlying coverage specification, which is the TSP leaving out the requirement for optimality on the route. In addition, we utilize the Lin-Kernighan-Helsgaun TSP solver to heuristically optimize the cost for the overall taken route. Two examples, an urban parcel delivery task and a UAV reconnaissance mission, greatly illustrate the powerfulness of the proposed heuristic.      
### 88.Expert decision support system for aeroacoustic classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.00255.pdf)
>  This paper presents an expert decision support system for time-invariant aeroacoustic source classification. The system comprises two steps: first, the calculation of acoustic properties based on spectral and spatial information; and second, the clustering of the sources based on these properties. Example data of two scaled airframe half-model wind tunnel measurements is evaluated based on deconvolved beamforming maps. A variety of aeroacoustic features are proposed that capture the characteristics and properties of the spectra. These features represent aeroacoustic properties that can be interpreted by both the machine and experts. The features are independent of absolute flow parameters such as the observed Mach numbers. This enables the proposed method to analyze data which is measured at different flow configurations. The aeroacoustic sources are clustered based on these features to determine similar or atypical behavior. For the given example data, the method results in source type clusters that correspond to human expert classification of the source types. Combined with a classification confidence and the mean feature values for each cluster, these clusters help aeroacoustic experts in classifying the identified sources and support them in analyzing their typical behavior and identifying spurious sources in-situ during measurement campaigns.      
### 89.UAV-Enabled Wireless Power Transfer: A Tutorial Overview  [ :arrow_down: ](https://arxiv.org/pdf/2103.00207.pdf)
>  Unmanned aerial vehicle (UAV)-enabled wireless power transfer (WPT) has recently emerged as a promising technique to provide sustainable energy supply for widely distributed low-power ground devices (GDs) in large-scale wireless networks. Compared with the energy transmitters (ETs) in conventional WPT systems which are deployed at fixed locations, UAV-mounted aerial ETs can fly flexibly in the three-dimensional (3D) space to charge nearby GDs more efficiently. This paper provides a tutorial overview on UAV-enabled WPT and its appealing applications, in particular focusing on how to exploit UAVs' controllable mobility via their 3D trajectory design to maximize the amounts of energy transferred to all GDs in a wireless network with fairness. First, we consider the single-UAV-enabled WPT scenario with one UAV wirelessly charging multiple GDs at known locations. To solve the energy maximization problem in this case, we present a general trajectory design framework consisting of three innovative approaches to optimize the UAV trajectory, which are multi-location hovering, successive-hover-and-fly, and time-quantization-based optimization, respectively. Next, we consider the multi-UAV-enabled WPT scenario where multiple UAVs cooperatively charge many GDs in a large area. Building upon the single-UAV trajectory design, we propose two efficient schemes to jointly optimize multiple UAVs' trajectories, based on the principles of UAV swarming and GD clustering, respectively. Furthermore, we consider two important extensions of UAV-enabled WPT, namely UAV-enabled wireless powered communication networks (WPCN) and UAV-enabled wireless powered mobile edge computing (MEC).      
### 90.Characterization of Neural Networks Automatically Mapped on Automotive-grade Microcontrollers  [ :arrow_down: ](https://arxiv.org/pdf/2103.00201.pdf)
>  Nowadays, Neural Networks represent a major expectation for the realization of powerful Deep Learning algorithms, which can determine several physical systems' behaviors and operations. Computational resources required for model, training, and running are large, especially when related to the amount of data that Neural Networks typically need to generalize. The latest TinyML technologies allow integrating pre-trained models on embedded systems, allowing making computing at the edge faster, cheaper, and safer. Although these technologies originated in the consumer and industrial worlds, many sectors can greatly benefit from them, such as the automotive industry. In this paper, we present a framework for implementing Neural Network-based models on a family of automotive Microcontrollers, showing their efficiency in two case studies applied to vehicles: intrusion detection on the Controller Area Network bus and residual capacity estimation in Lithium-Ion batteries, widely used in Electric Vehicles.      
### 91.Economic Dispatch of a Single Micro-Gas Turbine Under CHP Operation with Uncertain Demands  [ :arrow_down: ](https://arxiv.org/pdf/2103.00185.pdf)
>  This work considers the economic dispatch problem for a single micro-gas turbine, governed by a discrete state-space model, under combined heat and power (CHP) operation. If the exact power and heat demands are given, it is known that graph-theory based algorithms can be used to give a quick optimal solution to the economic dispatch problem. However, in practice, the power and heat demands are not known exactly, but are rather predicted, resulting in an estimate and a bound on the estimation error. We consider the case in which the power and heat demands are unknown, and present a robust optimization-based approach for scheduling the turbine's generation, in which the demand is assumed to be inside an uncertainty set. Multiple different choices for the uncertainty set are presented, with different advantages, and am efficient algorithm is presented for both cases. We also demonstrate the algorithms using detailed case studies using real data on energy demand profiles and electricity tariffs.      
### 92.Analysis, Prediction, and Control of Epidemics: A Survey from Scalar to Dynamic Network Models  [ :arrow_down: ](https://arxiv.org/pdf/2103.00181.pdf)
>  During the ongoing COVID-19 pandemic, mathematical models of epidemic spreading have emerged as powerful tools to produce valuable predictions of the evolution of the pandemic, helping public health authorities decide which intervention policies should be implemented. The study of these models -- grounded in the systems theory and often analyzed using control-theoretic tools -- is an extremely important research area for many researchers from different fields, including epidemiology, engineering, physics, mathematics, computer science, sociology, economics, and management. In this survey, we review the history and present the state of the art in the modeling, analysis, and control of epidemic dynamics. We discuss different approaches to epidemic modeling, either deterministic or stochastic, ranging from the first implementations of scalar systems of differential equations to describing the epidemic spreading at the population level, and to more recent models on dynamic networks, which capture the spatial spread and the time-varying nature of human interactions.      
### 93.Music Genre Bars  [ :arrow_down: ](https://arxiv.org/pdf/2103.00129.pdf)
>  Music Genres, as a popular meta-data of music, are very useful to organize, explore or search music datasets. Soft music genres are weighted multiple-genre annotations to songs. In this initial work, we propose horizontally stacked bar charts to represent a music dataset annotated by these soft music genres. For this purpose, we take an example of a toy dataset consisting of songs labelled with help of three music genres; Blues, Jazz and Country. We demonstrate how such a stacked bar chart can be used as a slider for user-input in an interface. We implement this by embedding this genre bar in a streaming application prototype and show its utility in choosing playlists. We finally conclude by proposing further work and future explorations on our proposed preliminary research.      
### 94.MBNet: MOS Prediction for Synthesized Speech with Mean-Bias Network  [ :arrow_down: ](https://arxiv.org/pdf/2103.00110.pdf)
>  Mean opinion score (MOS) is a popular subjective metric to assess the quality of synthesized speech, and usually involves multiple human judges to evaluate each speech utterance. To reduce the labor cost in MOS test, multiple methods have been proposed to automatically predict MOS scores. To our knowledge, for a speech utterance, all previous works only used the average of multiple scores from different judges as the training target and discarded the score of each individual judge, which did not well exploit the precious MOS training data. In this paper, we propose MBNet, a MOS predictor with a mean subnet and a bias subnet to better utilize every judge score in MOS datasets, where the mean subnet is used to predict the mean score of each utterance similar to that in previous works, and the bias subnet to predict the bias score (the difference between the mean score and each individual judge score) and capture the personal preference of individual judges. Experiments show that compared with MOSNet baseline that only leverages mean score for training, MBNet improves the system-level spearmans rank correlation co-efficient (SRCC) by 2.9% on VCC 2018 dataset and 6.7% on VCC 2016 dataset.      
### 95.Dynamic Oversampling Tecniques for 1-Bit ADCs in Large-Scale MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.00103.pdf)
>  In this work, we investigate dynamic oversampling techniques for large-scale multiple-antenna systems equipped with low-cost and low-power 1-bit analog-to-digital converters at the base stations. To compensate for the performance loss caused by the coarse quantization, oversampling is applied at the receiver. Unlike existing works that use uniform oversampling, which samples the signal at a constant rate, a novel dynamic oversampling scheme is proposed. The basic idea is to perform time-varying nonuniform oversampling, which selects samples with nonuniform patterns that vary over time. We consider two system design criteria: a design that maximizes the achievable sum rate and another design that minimizes the mean square error of detected symbols. Dynamic oversampling is carried out using a dimension reduction matrix $\mathbf{\Delta}$, which can be computed by the generalized eigenvalue decomposition or by novel submatrix-level feature selection algorithms. Moreover, the proposed scheme is analyzed in terms of convergence, computational complexity and power consumption at the receiver. Simulations show that systems with the proposed dynamic oversampling outperform those with uniform oversampling in terms of computational cost, achievable sum rate and symbol error rate performance.      
### 96.Scalable Multiagent Driving Policies For Reducing Traffic Congestion  [ :arrow_down: ](https://arxiv.org/pdf/2103.00058.pdf)
>  Traffic congestion is a major challenge in modern urban settings. The industry-wide development of autonomous and automated vehicles (AVs) motivates the question of how can AVs contribute to congestion reduction. Past research has shown that in small scale mixed traffic scenarios with both AVs and human-driven vehicles, a small fraction of AVs executing a controlled multiagent driving policy can mitigate congestion. In this paper, we scale up existing approaches and develop new multiagent driving policies for AVs in scenarios with greater complexity. We start by showing that a congestion metric used by past research is manipulable in open road network scenarios where vehicles dynamically join and leave the road. We then propose using a different metric that is robust to manipulation and reflects open network traffic efficiency. Next, we propose a modular transfer reinforcement learning approach, and use it to scale up a multiagent driving policy to outperform human-like traffic and existing approaches in a simulated realistic scenario, which is an order of magnitude larger than past scenarios (hundreds instead of tens of vehicles). Additionally, our modular transfer learning approach saves up to 80% of the training time in our experiments, by focusing its data collection on key locations in the network. Finally, we show for the first time a distributed multiagent policy that improves congestion over human-driven traffic. The distributed approach is more realistic and practical, as it relies solely on existing sensing and actuation capabilities, and does not require adding new communication infrastructure.      
### 97.Yoneda Hacking: The Algebra of Attacker Actions  [ :arrow_down: ](https://arxiv.org/pdf/2103.00044.pdf)
>  Our work focuses on modeling security of systems from their component-level designs. Towards this goal we develop a categorical formalism to model attacker actions. Equipping the categorical formalism with algebras produces two interesting results for security modeling. First, using the Yoneda lemma, we are able to model attacker reconnaissance missions. In this context, the Yoneda lemma formally shows us that if two system representations, one being complete and the other being the attacker's incomplete view, agree at every possible test, then they behave the same. The implication is that attackers can still successfully exploit the system even with incomplete information. Second, we model the possible changes that can occur to the system via an exploit. An exploit either manipulates the interactions between system components, for example, providing the wrong values to a sensor, or changes the components themselves, for example, manipulating the firmware of a global positioning system (GPS). One additional benefit of using category theory is that mathematical operations can be represented as formal diagrams, which is useful for applying this analysis in a model-based design setting. We illustrate this modeling framework using a cyber-physical system model of an unmanned aerial vehicle (UAV). We demonstrate and model two types of attacks (1) a rewiring attack, which violates data integrity, and (2) a rewriting attack, which violates availability.      
### 98.Serverless Workflows with Durable Functions and Netherite  [ :arrow_down: ](https://arxiv.org/pdf/2103.00033.pdf)
>  Serverless is an increasingly popular choice for service architects because it can provide elasticity and load-based billing with minimal developer effort. A common and important use case is to compose serverless functions and cloud storage into reliable workflows. However, existing solutions for authoring workflows provide a rudimentary experience compared to writing standard code in a modern programming language. Furthermore, executing workflows reliably in an elastic serverless environment poses significant performance challenges. <br>To address these, we propose Durable Functions, a programming model for serverless workflows, and Netherite, a distributed execution engine to execute them efficiently. Workflows in Durable Functions are expressed as task-parallel code in a host language of choice. Internally, the workflows are translated to fine-grained stateful communicating processes, which are load-balanced over an elastic cluster. The main challenge is to minimize the cost of reliably persisting progress to storage while supporting elastic scale. Netherite solves this by introducing partitioning, recovery logs, asynchronous snapshots, and speculative communication. <br>Our results show that Durable Functions simplifies the expression of complex workflows, and that Netherite achieves lower latency and higher throughput than the prevailing approaches for serverless workflows in Azure and AWS, by orders of magnitude in some cases.      
### 99.Graph Community Detection from Coarse Measurements: Recovery Conditions for the Coarsened Weighted Stochastic Block Model  [ :arrow_down: ](https://arxiv.org/pdf/2102.13135.pdf)
>  We study the problem of community recovery from coarse measurements of a graph. In contrast to the problem of community recovery of a fully observed graph, one often encounters situations when measurements of a graph are made at low-resolution, each measurement integrating across multiple graph nodes. Such low-resolution measurements effectively induce a coarse graph with its own communities. Our objective is to develop conditions on the graph structure, the quantity, and properties of measurements, under which we can recover the community organization in this coarse graph. In this paper, we build on the stochastic block model by mathematically formalizing the coarsening process, and characterizing its impact on the community members and connections. Through this novel setup and modeling, we characterize an error bound for community recovery. The error bound yields simple and closed-form asymptotic conditions to achieve the perfect recovery of the coarse graph communities.      
### 100.On Maximal Robust Positively Invariant Sets in Constrained Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/1904.01985.pdf)
>  In this technical communique we study the maximal robust positively invariant set for state-constrained continuous-time nonlinear systems subjected to a bounded disturbance. Extending results from the theory of barriers, we show that this set is closed and that its boundary consists of two complementary parts, one of which we name the invariance barrier, which consists of trajectories that satisfy the maximum principle.      

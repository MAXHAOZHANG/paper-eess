# ArXiv eess --Thu, 25 Mar 2021
### 1.Are energy savings the only reason for the emergence of bird echelon formation?  [ :arrow_down: ](https://arxiv.org/pdf/2103.13381.pdf)
>  We analyze the conditions under which the emergence of frequently observed echelon formation can be explained solely by the maximization of energy savings. We consider a two-dimensional multi-agent echelon formation, where each agent receives a benefit that depends on its position relative to the others, and adjusts its position to increase this benefit. We analyze the selfish case where each agent maximizes its own benefit, leading to a Nash-equilibrium problem, and the collaborative case in which agents maximize the global benefit of the group. We provide conditions on the benefit function under which the frequently observed echelon formations cannot be Nash equilbriums or group optimums. <br>We then show that these conditions are satisfied by the conventionally used fixed-wing wake benefit model. This implies that energy saving alone is not sufficient to explain the emergence of the migratory formations observed, based on the fixed-wing model. Hence, either non-aerodynamic aspects or a more accurate model of bird dynamics should be considered to construct such formations.      
### 2.Continuous-Domain Formulation of Inverse Problems for Composite Sparse-Plus-Smooth Signals  [ :arrow_down: ](https://arxiv.org/pdf/2103.13380.pdf)
>  We present a novel framework for the reconstruction of 1D composite signals assumed to be a mixture of two additive components, one sparse and the other smooth, given a finite number of linear measurements. We formulate the reconstruction problem as a continuous-domain regularized inverse problem with multiple penalties. We prove that these penalties induce reconstructed signals that indeed take the desired form of the sum of a sparse and a smooth component. We then discretize this problem using Riesz bases, which yields a discrete problem that can be solved by standard algorithms. Our discretization is exact in the sense that we are solving the continuous-domain problem over the search space specified by our bases without any discretization error. We propose a complete algorithmic pipeline and demonstrate its feasibility on simulated data.      
### 3.Incremental Nonlinear Stability Analysis for Stochastic Systems Perturbed by Lévy Noise  [ :arrow_down: ](https://arxiv.org/pdf/2103.13338.pdf)
>  We present a theoretical framework for characterizing incremental stability of nonlinear stochastic systems perturbed by additive noise of two types: compound Poisson shot noise and bounded-measure Lévy noise. For each type, we show that trajectories of the system with distinct initial conditions and noise sample paths exponentially converge towards a bounded error ball of each other in the expected mean-squared sense under certain boundedness assumptions. The practical utilities of this study include the model-based design of stochastic controllers/observers that are able to handle a much broader class of noise than Gaussian white. We demonstrate our results using three case studies.      
### 4.Fine-tuning of Pre-trained End-to-end Speech Recognition with Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.13329.pdf)
>  Adversarial training of end-to-end (E2E) ASR systems using generative adversarial networks (GAN) has recently been explored for low-resource ASR corpora. GANs help to learn the true data representation through a two-player min-max game. However, training an E2E ASR model using a large ASR corpus with a GAN framework has never been explored, because it might take excessively long time due to high-variance gradient updates and face convergence issues. In this paper, we introduce a novel framework for fine-tuning a pre-trained ASR model using the GAN objective where the ASR model acts as a generator and a discriminator tries to distinguish the ASR output from the real data. Since the ASR model is pre-trained, we hypothesize that the ASR model output (soft distribution vectors) helps to get higher scores from the discriminator and makes the task of the discriminator harder within our GAN framework, which in turn improves the performance of the ASR model in the fine-tuning stage. Here, the pre-trained ASR model is fine-tuned adversarially against the discriminator using an additional adversarial loss. Experiments on full LibriSpeech dataset show that our proposed approach outperforms baselines and conventional GAN-based adversarial models.      
### 5.MONAIfbs: MONAI-based fetal brain MRI deep learning segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.13314.pdf)
>  In fetal Magnetic Resonance Imaging, Super Resolution Reconstruction (SRR) algorithms are becoming popular tools to obtain high-resolution 3D volume reconstructions from low-resolution stacks of 2D slices, acquired at different orientations. To be effective, these algorithms often require accurate segmentation of the region of interest, such as the fetal brain in suspected pathological cases. In the case of Spina Bifida, Ebner, Wang et al. (NeuroImage, 2020) combined their SRR algorithm with a 2-step segmentation pipeline (2D localisation followed by a 2D segmentation network). However, if the localisation step fails, the second network is not able to recover a correct brain mask, thus requiring manual corrections for an effective SRR. In this work, we aim at improving the fetal brain segmentation for SRR in Spina Bifida. We hypothesise that a well-trained single-step UNet can achieve accurate performance, avoiding the need of a 2-step approach. We propose a new tool for fetal brain segmentation called MONAIfbs, which takes advantage of the Medical Open Network for Artificial Intelligence (MONAI) framework. Our network is based on the dynamic UNet (dynUNet), an adaptation of the nnU-Net framework. When compared to the original 2-step approach proposed in Ebner-Wang, and the same Ebner-Wang approach retrained with the expanded dataset available for this work, the dynUNet showed to achieve higher performance using a single step only. It also showed to reduce the number of outliers, as only 28 stacks obtained Dice score less than 0.9, compared to 68 for Ebner-Wang and 53 Ebner-Wang expanded. The proposed dynUNet model thus provides an improvement of the state-of-the-art fetal brain segmentation techniques, reducing the need for manual correction in automated SRR pipelines. Our code and our trained model are made publicly available at <a class="link-external link-https" href="https://github.com/gift-surg/MONAIfbs" rel="external noopener nofollow">this https URL</a>.      
### 6.Information-based Disentangled Representation Learning for Unsupervised MR Harmonization  [ :arrow_down: ](https://arxiv.org/pdf/2103.13283.pdf)
>  Accuracy and consistency are two key factors in computer-assisted magnetic resonance (MR) image analysis. However, contrast variation from site to site caused by lack of standardization in MR acquisition impedes consistent measurements. In recent years, image harmonization approaches have been proposed to compensate for contrast variation in MR images. Current harmonization approaches either require cross-site traveling subjects for supervised training or heavily rely on site-specific harmonization models to encourage harmonization accuracy. These requirements potentially limit the application of current harmonization methods in large-scale multi-site studies. In this work, we propose an unsupervised MR harmonization framework, CALAMITI (Contrast Anatomy Learning and Analysis for MR Intensity Translation and Integration), based on information bottleneck theory. CALAMITI learns a disentangled latent space using a unified structure for multi-site harmonization without the need for traveling subjects. Our model is also able to adapt itself to harmonize MR images from a new site with fine tuning solely on images from the new site. Both qualitative and quantitative results show that the proposed method achieves superior performance compared with other unsupervised harmonization approaches.      
### 7.Non-Episodic Learning for Online LQR of Unknown Linear Gaussian System  [ :arrow_down: ](https://arxiv.org/pdf/2103.13278.pdf)
>  This paper considers the data-driven linear-quadratic regulation (LQR) problem where the system parameters are unknown and need to be identified online. In particular, the system operator is not allowed to perform multiple experiments by resetting the system to an initial state, a common approach in system identification and data-driven control literature. Instead, we propose an algorithm that gains knowledge about the system from a single trajectory, and guarantee that both the identification error and the suboptimality of control performance in this trajectory converge \emph{simultaneously} with probability one. Furthermore, we characterize the almost sure convergence rates of identification and control, and reveal an optimal trade-off between exploration and exploitation. A numerical example is provided to illustrate the effectiveness of our proposed strategy.      
### 8.PAT image reconstruction using augmented sparsity regularization with semi-automated tuning of regularization weight  [ :arrow_down: ](https://arxiv.org/pdf/2103.13261.pdf)
>  Among all tissue imaging modalities, photo-acoustic tomography (PAT) has been getting increasing attention in the recent past due to the fact that it has high contrast, high penetrability, and has capability of retrieving high resolution. The reconstruction methods used in PAT plays a crucial role in the applicability of PAT, and PAT finds particularly a wider applicability if a model-based regularized reconstruction method is used. A crucial factor that determines the quality of reconstruction in such methods is the choice of regularization weight. Unfortunately, an appropriately tuned value of regularization weight varies significantly with variation in the noise level, as well as, with the variation in the high resolution contents of the image, in a way that has not been well understood. There has been attempts to determine optimum regularization weight from the measured data in the context of using elementary and general purpose regularizations. In this paper, we develop a method for semi-automated tuning of the regularization weight in the context of using a modern type of regularization that was specifically designed for PAT image reconstruction. As a first step, we introduce a relative smoothness constraint with a parameter; this parameter computationally maps into the actual regularization weight, but, its tuning does not vary significantly with variation in the noise level, and with the variation in the high resolution contents of the image. Next, we construct an algorithm that integrates the task of determining this mapping along with obtaining the reconstruction. Finally we demonstrate experimentally that we can run this algorithm with a nominal value of the relative smoothness parameter -- a value independent of the noise level and the structure of the underlying image -- to obtain good quality reconstructions.      
### 9.Mostly electric assisted airplanes (MEAP) for regional aviation: A South Asian perspective  [ :arrow_down: ](https://arxiv.org/pdf/2103.13259.pdf)
>  Aircraft manufacturing relies on pre-order bookings. The configuration of the to be assembled aircraft is fixed by the design assisted market surveys. The sensitivity of the supply chain to the market conditions, makes, the relationship between the product (aircraft) and the associated service (aviation), precarious. Traditional model to mitigate this risk to profitability rely on increasing the scales of operations. However, the emergence of new standards of air quality monitoring and insistence on the implementation, demands additional corrective measures. In the quest for a solution, this research commentary establishes a link, between the airport taxes and the nature of the transporting unit. It warns, that merely, increasing the number of mid haulage range aircrafts (MHA) in the fleet, may not be enough, to overcome this challenge. In a two-pronged approach, the communication proposes, the use of mostly electric assisted air planes, and small sized airports as the key to solving this complex problem. As a side-note the appropriateness of South Asian region, as a test-bed for MEAP based aircrafts is also investigated. The success of this the idea can be potentially extended, to any other aviation friendly region of the world.      
### 10.Assets Defending Differential Games with Partial Information and Selected Observations  [ :arrow_down: ](https://arxiv.org/pdf/2103.13230.pdf)
>  In this paper, we consider a linear-quadratic-Gaussian defending assets differential game (DADG) where the attacker and the defender do not know each other's state information while they know the trajectory of a moving asset. Both players can choose to observe the other player's state information by paying a cost. The defender and the attacker have to craft both control strategies and observation strategies. We obtain a closed-form feedback solution that characterizes the Nash control strategies. We show that the trajectory of the asset does not affect both players' observation choices. Moreover, we show that the observation choices of the defender and the attacker can be decoupled and the Nash observation strategies can be found by solving two independent optimization problems. A set of necessary conditions is developed to characterize the optimal observation instances. Based on the necessary conditions, an effective algorithm is proposed to numerically compute the optimal observation instances. A case study is presented to demonstrate the effectiveness of the optimal observation instances.      
### 11.Topology Design for GNSSs Considering Both Inter-satellite Links and Ground-satellite Links  [ :arrow_down: ](https://arxiv.org/pdf/2103.13197.pdf)
>  Inter-satellite links (ISLs) are adopted in global navigation satellite systems (GNSSs) for high-precision orbit determination and space-based end-to-end telemetry telecommand control and communications. Due to limited onboard ISL terminals, the polling time division duplex (PTDD) mechanism is usually proposed for space link layer networking. By extending the polling mechanism to ground-satellite links (GSLs), a unified management system of the space segment and the ground segment can be realized. However, under the polling system how to jointly design the topology of ISLs and GSLs during every slot to improve data interaction has not been studied. In this paper, we formulate the topology design problem as an integer linear programming, aiming at minimizing the average delay of data delivery from satellites to ground stations while satisfying the ranging requirement for the orbit determination. To tackle the computational complexity problem, we first present a novel modeling method of delay to reduce the number of decision variables. Further, we propose a more efficient heuristic based on maximum weight matching algorithms. Simulation results demonstrate the feasibility of the proposed methods for practical operation in GNSSs. Comparing the two methods, the heuristic can achieve similar performance with respect to average delay but with significantly less complexity.      
### 12.RSS-based Cooperative Localization and Orientation Estimation Exploiting Directive Antenna Patterns  [ :arrow_down: ](https://arxiv.org/pdf/2103.13181.pdf)
>  In this paper, we propose a factor-graph-based cooperative positioning algorithm that uses RSS radio measurements and accounts for the directivity of the antennas. This is achieved by modeling the directivity with a parametric antenna pattern and jointly estimating position and orientation of the agents. We propose two different approaches whereas the first one uses a continuous representation of the orientation state and the second one a discrete representation. We validate our proposed methods with simulations and measurements in a static sensor network with more than 900 agents in an indoor environment and show that the positioning accuracy can be improved significantly by considering the influence of orientations.      
### 13.Asymptotic Security by Model-based Incident Handlers for Markov Decision Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.13121.pdf)
>  This study investigates general model-based incident handler's asymptotic behaviors in time against cyber attacks to control systems. The attacker's and the defender's dynamic decision making is modeled as an equilibrium of a dynamic signaling game. It is shown that the defender's belief on existence of an attacker converges over time for any attacker's strategy provided that the stochastic dynamics of the control system is known to the defender. This fact implies that the rational behavior of the attacker converges to a harmless action as long as the defender possesses an effective counteraction. The obtained result supports the powerful protection capability achieved by model-based defense mechanisms.      
### 14.Light Field Reconstruction Using Convolutional Network on EPI and Extended Applications  [ :arrow_down: ](https://arxiv.org/pdf/2103.13043.pdf)
>  In this paper, a novel convolutional neural network (CNN)-based framework is developed for light field reconstruction from a sparse set of views. We indicate that the reconstruction can be efficiently modeled as angular restoration on an epipolar plane image (EPI). The main problem in direct reconstruction on the EPI involves an information asymmetry between the spatial and angular dimensions, where the detailed portion in the angular dimensions is damaged by undersampling. Directly upsampling or super-resolving the light field in the angular dimensions causes ghosting effects. To suppress these ghosting effects, we contribute a novel "blur-restoration-deblur" framework. First, the "blur" step is applied to extract the low-frequency components of the light field in the spatial dimensions by convolving each EPI slice with a selected blur kernel. Then, the "restoration" step is implemented by a CNN, which is trained to restore the angular details of the EPI. Finally, we use a non-blind "deblur" operation to recover the spatial high frequencies suppressed by the EPI blur. We evaluate our approach on several datasets, including synthetic scenes, real-world scenes and challenging microscope light field data. We demonstrate the high performance and robustness of the proposed framework compared with state-of-the-art algorithms. We further show extended applications, including depth enhancement and interpolation for unstructured input. More importantly, a novel rendering approach is presented by combining the proposed framework and depth information to handle large disparities.      
### 15.Flatness-based MPC for underactuated surface vessels in confined areas  [ :arrow_down: ](https://arxiv.org/pdf/2103.13040.pdf)
>  A two-phase model predictive controller (MPC) is proposed for underactuated surface vessel operation in confined environments. For general driving maneuvers (phase one) the ship's geometry is not considered explicitly while in more restricted areas (stage two) which occur, e.g., in mooring maneuvers, the ship's geometry is approximated to ensure collision avoidance. To remove the dynamical constraint in the problem setup, the differential flatness of the fully actuated system is exploited and the flat outputs are parameterized using B-spline functions. Underactuated behavior is retained by means of inequality constraints that are imposed on the non-controllable input. In an effort to solve the MPC, a static nonlinear optimization problem is formulated and feasibility w.r.t. obstacles and actuator constraints is ensured at collocation points. Static obstacles are considered as constructive solid geometry functions in the MPC which also takes into account disturbances induced by wind.      
### 16.Lightweight Image Super-Resolution with Multi-scale Feature Interaction Network  [ :arrow_down: ](https://arxiv.org/pdf/2103.13028.pdf)
>  Recently, the single image super-resolution (SISR) approaches with deep and complex convolutional neural network structures have achieved promising performance. However, those methods improve the performance at the cost of higher memory consumption, which is difficult to be applied for some mobile devices with limited storage and computing resources. To solve this problem, we present a lightweight multi-scale feature interaction network (MSFIN). For lightweight SISR, MSFIN expands the receptive field and adequately exploits the informative features of the low-resolution observed images from various scales and interactive connections. In addition, we design a lightweight recurrent residual channel attention block (RRCAB) so that the network can benefit from the channel attention mechanism while being sufficiently lightweight. Extensive experiments on some benchmarks have confirmed that our proposed MSFIN can achieve comparable performance against the state-of-the-arts with a more lightweight model.      
### 17.Enhanced Robust Adaptive Beamforming Designs for General-Rank Signal Model via an Induced Norm of Matrix Errors  [ :arrow_down: ](https://arxiv.org/pdf/2103.13014.pdf)
>  The robust adaptive beamforming (RAB) problem for general-rank signal model with an uncertainty set defined through a matrix induced norm is considered. The worst-case signal-to-interference-plus-noise ratio (SINR) maximization RAB problem is formulated by decomposing the presumed covariance of the desired signal into a product between a matrix and its Hermitian, and putting an error term into the matrix and its Hermitian. In the literature, the norm of the matrix errors often is the Frobenius norm in the maximization problem. Herein, the closed-form optimal value for a minimization problem of the least-squares residual over the matrix errors with an induced $l_{p,q}$-norm constraint is first derived. Then, the worst-case SINR maximization problem is reformulated into the maximization of the difference between an $l_2$-norm function and a $l_q$-norm function, subject to a convex quadratic constraint. It is shown that for any $q$ in the set of rational numbers greater than or equal to one, the maximization problem can be approximated by a sequence of second-order cone programming (SOCP) problems, with the ascent optimal values. The resultant beamvector for some $q$ in the set, corresponding to the maximal actual array output SINR, is treated as the best candidate such that the RAB design is improved the most. In addition, a generalized RAB problem of maximizing the difference between an $l_p$-norm function and an $l_q$-norm function subject to the convex quadratic constraint is studied, and the actual array output SINR is further enhanced by properly selecting $p$ and $q$. Simulation examples are presented to demonstrate the improved performance of the robust beamformers for certain matrix induced $l_{p,q}$-norms, in terms of the actual array output SINR and the CPU-time for the sequential SOCP approximation algorithm.      
### 18.A Marker-free Head Tracker Using Vision-based Head Pose Estimation with Adaptive Kalman Filter  [ :arrow_down: ](https://arxiv.org/pdf/2103.13006.pdf)
>  The immersion and the interaction are the important features of the driving simulator. To improve these characteristics, this paper proposes a low-cost and mark-less driver head tracking framework based on the head pose estimation model, which makes the view of the simulator can automatically align with the driver's head pose. The proposed method only uses the RGB camera without the other hardware or marker. To handle the error of the head pose estimation model, this paper proposes an adaptive Kalman Filter. By analyzing the error distribution of the estimation model and user experience, the proposed Kalman Filter includes the adaptive observation noise coefficient and loop closure module, which can adaptive moderate the smoothness of the curve and keep the curve stable near the initial position. The experiments show that the proposed method is feasible, and it can be used with different head pose estimation models.      
### 19.Resonant Scanning Design and Control for Fast Spatial Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2103.12996.pdf)
>  Two-dimensional, resonant scanners have been utilized in a large variety of imaging modules due to their compact form, low power consumption, large angular range, and high speed. However, resonant scanners have problems with non-optimal and inflexible scanning patterns and inherent phase uncertainty, which limit practical applications. Here we propose methods for optimized design and control of the scanning trajectory of two-dimensional resonant scanners under various physical constraints, including high frame-rate and limited actuation amplitude. First, we propose an analytical design rule for uniform spatial sampling. We demonstrate theoretically and experimentally that by including non-repeating scanning patterns, the proposed designs outperform previous designs in terms of scanning range and fill factor. Second, we show that we can create flexible scanning patterns that allow focusing on user-defined Regions-of-Interest (RoI) by modulation of the scanning parameters. The scanning parameters are found by an optimization algorithm. In simulations, we demonstrate the benefits of these designs with standard metrics and higher-level computer vision tasks (LiDAR odometry and 3D object detection). Finally, we experimentally implement and verify both unmodulated and modulated scanning modes using a two-dimensional, resonant MEMS scanner. Central to the implementations is high bandwidth monitoring of the phase of the angular scans in both dimensions. This task is carried out with a position-sensitive photodetector combined with high-bandwidth electronics, enabling fast spatial sampling at ~ 100Hz frame-rate.      
### 20.Failure-Tolerant Contract-Based Design of an Automated Valet Parking System using a Directive-Response Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2103.12919.pdf)
>  Increased complexity in cyber-physical systems calls for modular system design methodologies that guarantee correct and reliable behavior, both in normal operations and in the presence of failures. This paper aims to extend the contract-based design approach using a directive-response architecture to enable reactivity to failure scenarios. The architecture is demonstrated on a modular automated valet parking (AVP) system. The contracts for the different components in the AVP system are explicitly defined, implemented, and validated against a Python implementation.      
### 21.A Time-Temperature Dataset for the Strawberry Cold Chain Across Multiple Shipments and Locations  [ :arrow_down: ](https://arxiv.org/pdf/2103.12895.pdf)
>  This article describes location aware temperature profiles from six strawberry shipments across the continental United States. Three pallets were instrumented in each shipment with three vertically placed loggers to take a longitudinal and latitudinal snapshot of 9 strategically different locations (including the top, middle and bottom layers of the pallets placed in the back, middle and the front of the shipping container) for a combined 54 measurement points across shipments of varying lengths. The sensors were instrumented in the field, right at the point of harvest, recorded temperatures every every 5 to 10 minutes depending on the shipment, and uploaded their data periodically via cellular radios on each device. The data is a result of significant collaboration between stakeholders from farmers to distributors to retailers to academics, which can play an important role for researchers and educators in food engineering, cold-chain, machine learning, and data mining, as well as in other disciplines related to food and transportation.      
### 22.Smoothing-Averse Control: Covertness and Privacy from Smoothers  [ :arrow_down: ](https://arxiv.org/pdf/2103.12881.pdf)
>  In this paper we investigate the problem of controlling a partially observed stochastic dynamical system such that its state is difficult to infer using a (fixed-interval) Bayesian smoother. This problem arises naturally in applications in which it is desirable to keep the entire state trajectory of a system concealed. We pose our smoothing-averse control problem as the problem of maximising the (joint) entropy of smoother state estimates (i.e., the joint conditional entropy of the state trajectory given the history of measurements and controls). We show that the entropy of Bayesian smoother estimates for general nonlinear state-space models can be expressed as the sum of entropies of marginal state estimates given by Bayesian filters. This novel additive form allows us to reformulate the smoothing-averse control problem as a fully observed stochastic optimal control problem in terms of the usual concept of the information (or belief) state, and solve the resulting problem via dynamic programming. We illustrate the applicability of smoothing-averse control to privacy in cloud-based control and covert robotic navigation.      
### 23.Multipath-based SLAM using Belief Propagation with Interacting Multiple Dynamic Models  [ :arrow_down: ](https://arxiv.org/pdf/2103.12809.pdf)
>  In this paper, we present a Bayesian multipath-based simultaneous localization and mapping (SLAM) algorithm that continuously adapts interacting multiple models (IMM) parameters to describe the mobile agent state dynamics. The time-evolution of the IMM parameters is described by a Markov chain and the parameters are incorporated into the factor graph structure that represents the statistical structure of the SLAM problem. The proposed belief propagation (BP)-based algorithm adapts, in an online manner, to time-varying system models by jointly inferring the model parameters along with the agent and map feature states. The performance of the proposed algorithm is finally evaluating with a simulated scenario. Our numerical simulation results show that the proposed multipath-based SLAM algorithm is able to cope with strongly changing agent state dynamics.      
### 24.FBMC Receiver Design and Analysis for Medium and Large Scale Antenna Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.12806.pdf)
>  In this paper, we design receivers for filter bank multicarrier-based (FBMC-based) massive MIMO considering practical aspects such as channel estimation and equalization. In particular, we propose a spectrally efficient pilot structure and a channel estimation technique in the uplink to jointly estimate all the users' channel impulse responses. We mathematically analyze our proposed channel estimator and find the statistics of the channel estimation errors. These statistics are incorporated into our proposed equalizers to deal with the imperfect channel state information (CSI) effect. We revisit the channel equalization problem for FBMC-based massive MIMO, address the shortcomings of the existing equalizers in the literature, and make them more applicable to practical scenarios. The proposed receiver in this paper consists of two stages. In the first stage, a linear combining of the received signals at the base station (BS) antennas provides a coarse channel equalization and removes any multiuser interference. In the second stage, a per subcarrier fractionally spaced equalizer (FSE) takes care of any residual distortion of the channel for the user of interest. We propose an FSE design based on the equivalent channel at the linear combiner output. This enables the applicability of our proposed technique to small and/or distributed antenna setups such as cell-free massive MIMO. Finally, the efficacy of the proposed techniques is corroborated through numerical analysis.      
### 25.Precoding for PAPR Reduction in UW-OFDM  [ :arrow_down: ](https://arxiv.org/pdf/2103.12774.pdf)
>  Unique Word Orthogonal Frequency Division multiplexing (UW-OFDM) is a variant of the multicarrier technique that has shown better bit error performance compared to cyclic prefixed (CP-)OFDM. Like other multicarrier techniques, UW-OFDM suffers from the high peak-to-average-power ratio (PAPR) problem, which is an obstacle ahead of practical implementation of UW-OFDM. In this paper, the generator matrix, which is inherent to UW-OFDM, is not only used to create the specific UW-OFDM system, but also to reduce the PAPR. To do so, a suitable optimization problem is developed, and solved using the Procrustes method. The main advantage of the proposed method is that the built-in generator matrix should be calculated only once for each system setting, and the PAPR reduction (PAPR-R) is achieved without any overhead redundancy. Simulation results are provided for evaluating the PAPR-R performance of the proposed method.      
### 26.Delay and Power consumption Analysis for Queue State Dependent Service Rate Control in WirelessHart System  [ :arrow_down: ](https://arxiv.org/pdf/2103.13306.pdf)
>  To solve the problem of power supply limitation of machines working in wireless industry automation, we evaluated the workload aware service rate control design implanted in the medium access control component of these small devices and proposed a bio-intelligence based algorithm to optimise the design regarding the delay constraint while minimizing power consumption. To achieve this, we provide an accurate analysis of the delay cost of this design and for the first time pinpoint an exact departure process model in order to evaluate the overall delay cost in consideration of the medium access time.      
### 27.Automatic Cough Classification for Tuberculosis Screening in a Real-World Environment  [ :arrow_down: ](https://arxiv.org/pdf/2103.13300.pdf)
>  We present first results showing that it is possible to automatically discriminate between the coughing sounds produced by patients with tuberculosis (TB) and those produced by patients with other lung ailments in a real-world noisy environment. Our experiments are based on a dataset of cough recordings obtained in a real-world clinic setting from 16 patients confirmed to be suffering from TB and 33 patients that are suffering from respiratory conditions, confirmed as other than TB. We have trained and evaluated several machine learning classifiers, including logistic regression (LR), support vector machines (SVM), k-nearest neighbour (KNN), multilayer perceptrons (MLP) and convolutional neural networks (CNN) inside a nested k-fold cross-validation and find that, although classification is possible in all cases, the best performance is achieved using the LR classifier. In combination with feature selection by sequential forward search (SFS), our best LR system achieves an area under the ROC curve (AUC) of 0.94 using 23 features selected from a set of 78 high-resolution mel-frequency cepstral coefficients (MFCCs). This system achieves a sensitivity of 93% at a specificity of 95% and thus exceeds the 90\% sensitivity at 70% specificity specification considered by the WHO as minimal requirements for community-based TB triage test. We conclude that automatic classification of cough audio sounds is promising as a viable means of low-cost easily-deployable front-line screening for TB, which will greatly benefit developing countries with a heavy TB burden.      
### 28.Energy-aware Resource Management for Federated Learning in Multi-access Edge Computing Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13293.pdf)
>  In Federated Learning (FL), a global statistical model is developed by encouraging mobile users to perform the model training on their local data and aggregating the output local model parameters in an iterative manner. However, due to limited energy and computation capability at the mobile devices, the performance of the model training is always at stake to meet the objective of local energy minimization. In this regard, Multi-access Edge Computing (MEC)-enabled FL addresses the tradeoff between the model performance and the energy consumption of the mobile devices by allowing users to offload a portion of their local dataset to an edge server for the model training. Since the edge server has high computation capability, the time consumption of the model training at the edge server is insignificant. However, the time consumption for dataset offloading from mobile users to the edge server has a significant impact on the total time consumption. Thus, resource management in MEC-enabled FL is challenging, where the objective is to reduce the total time consumption while saving the energy consumption of the mobile devices. In this paper, we formulate an energy-aware resource management for MEC-enabled FL in which the model training loss and the total time consumption are jointly minimized, while considering the energy limitation of mobile devices. In addition, we recast the formulated problem as a Generalized Nash Equilibrium Problem (GNEP) to capture the coupling constraints between the radio resource management and dataset offloading. We then analyze the impact of the dataset offloading and computing resource allocation on the model training loss, time, and the energy consumption.      
### 29.AcinoSet: A 3D Pose Estimation Dataset and Baseline Models for Cheetahs in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2103.13282.pdf)
>  Animals are capable of extreme agility, yet understanding their complex dynamics, which have ecological, biomechanical and evolutionary implications, remains challenging. Being able to study this incredible agility will be critical for the development of next-generation autonomous legged robots. In particular, the cheetah (acinonyx jubatus) is supremely fast and maneuverable, yet quantifying its whole-body 3D kinematic data during locomotion in the wild remains a challenge, even with new deep learning-based methods. In this work we present an extensive dataset of free-running cheetahs in the wild, called AcinoSet, that contains 119,490 frames of multi-view synchronized high-speed video footage, camera calibration files and 7,588 human-annotated frames. We utilize markerless animal pose estimation to provide 2D keypoints. Then, we use three methods that serve as strong baselines for 3D pose estimation tool development: traditional sparse bundle adjustment, an Extended Kalman Filter, and a trajectory optimization-based method we call Full Trajectory Estimation. The resulting 3D trajectories, human-checked 3D ground truth, and an interactive tool to inspect the data is also provided. We believe this dataset will be useful for a diverse range of fields such as ecology, neuroscience, robotics, biomechanics as well as computer vision.      
### 30.Proximally Optimal Predictive Control Algorithm for Path Tracking of Self-Driving Cars  [ :arrow_down: ](https://arxiv.org/pdf/2103.13240.pdf)
>  This work presents proximally optimal predictive control algorithm, which is essentially a model-based lateral controller for steered autonomous vehicles that selects an optimal steering command within the neighborhood of previous steering angle based on the predicted vehicle location. The proposed algorithm was formulated with an aim of overcoming the limitations associated with the existing control laws for autonomous steering - namely PID, Pure-Pursuit and Stanley controllers. Particularly, our approach was aimed at bridging the gap between tracking efficiency and computational cost, thereby ensuring effective path tracking in real-time. The effectiveness of our approach was investigated through a series of dynamic simulation experiments pertaining to autonomous path tracking, employing an adaptive control law for longitudinal motion control of the vehicle. We measured the latency of the proposed algorithm in order to comment on its real-time factor and validated our approach by comparing it against the established control laws in terms of both crosstrack and heading errors recorded throughout the respective path tracking simulations.      
### 31.Transfer Learning for Piano Sustain-Pedal Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.13219.pdf)
>  Detecting piano pedalling techniques in polyphonic music remains a challenging task in music information retrieval. While other piano-related tasks, such as pitch estimation and onset detection, have seen improvement through applying deep learning methods, little work has been done to develop deep learning models to detect playing techniques. In this paper, we propose a transfer learning approach for the detection of sustain-pedal techniques, which are commonly used by pianists to enrich the sound. In the source task, a convolutional neural network (CNN) is trained for learning spectral and temporal contexts when the sustain pedal is pressed using a large dataset generated by a physical modelling virtual instrument. The CNN is designed and experimented through exploiting the knowledge of piano acoustics and physics. This can achieve an accuracy score of 0.98 in the validation results. In the target task, the knowledge learned from the synthesised data can be transferred to detect the sustain pedal in acoustic piano recordings. A concatenated feature vector using the activations of the trained convolutional layers is extracted from the recordings and classified into frame-wise pedal press or release. We demonstrate the effectiveness of our method in acoustic piano recordings of Chopin's music. From the cross-validation results, the proposed transfer learning method achieves an average F-measure of 0.89 and an overall performance of 0.84 obtained using the micro-averaged F-measure. These results outperform applying the pre-trained CNN model directly or the model with a fine-tuned last layer.      
### 32.End-Effector Stabilization of a 10-DOF Mobile Manipulator using Nonlinear Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.13153.pdf)
>  Motion control of mobile manipulators (a robotic arm mounted on a mobile base) can be challenging for complex tasks such as material and package handling. In this paper, a task-space stabilization controller based on Nonlinear Model Predictive Control (NMPC) is designed and implemented to a 10 Degrees of Freedom (DOF) mobile manipulator which consists of a 7-DOF robotic arm and a 3-DOF mobile base. The system model is based on kinematic models where the end-effector orientation is parameterized directly by a rotation matrix. The state and control constraints as well as singularity constraints are explicitly included in the NMPC formulation. The controller is tested using real-time simulations, which demonstrate high positioning accuracy with tractable computational cost.      
### 33.Energy-Efficient Resource Allocation in Massive MIMO-NOMA Networks with Wireless Power Transfer: A Distributed ADMM Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.13146.pdf)
>  In multicell massive multiple-input multiple-output (MIMO) non-orthogonal multiple access (NOMA) networks, base stations (BSs) with multiple antennas deliver their radio frequency energy in the downlink, and Internet-of-Things (IoT) devices use their harvested energy to support uplink data transmission. This paper investigates the energy efficiency (EE) problem for multicell massive MIMO NOMA networks with wireless power transfer (WPT). To maximize the EE of the network, we propose a novel joint power, time, antenna selection, and subcarrier resource allocation scheme, which can properly allocate the time for energy harvesting and data transmission. Both perfect and imperfect channel state information (CSI) are considered, and their corresponding EE performance is analyzed. Under quality-of-service (QoS) requirements, an EE maximization problem is formulated, which is non-trivial due to non-convexity. We first adopt nonlinear fraction programming methods to convert the problem to be convex, and then, develop a distributed alternating direction method of multipliers (ADMM)- based approach to solve the problem. Simulation results demonstrate that compared to alternative methods, the proposed algorithm can converge quickly within fewer iterations, and can achieve better EE performance.      
### 34.Machine Learning based Indicators to Enhance Process Monitoring by Pattern Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.13058.pdf)
>  In industrial manufacturing, modern high-tech equipment delivers an increasing volume of data, which exceeds the capacities of human observers. Complex data formats like images make the detection of critical events difficult and require pattern recognition, which is beyond the scope of state-of-the-art process monitoring systems. Approaches that bridge the gap between conventional statistical tools and novel machine learning (ML) algorithms are required, but insufficiently studied. We propose a novel framework for ML based indicators combining both concepts by two components: pattern type and intensity. Conventional tools implement the intensity component, while the pattern type accounts for error modes and tailors the indicator to the production environment. In a case-study from semiconductor industry, our framework goes beyond conventional process control and achieves high quality experimental results. Thus, the suggested concept contributes to the integration of ML in real-world process monitoring problems and paves the way to automated decision support in manufacturing.      
### 35.Noise Detection with Spectator Qubits and Quantum Feature Engineering  [ :arrow_down: ](https://arxiv.org/pdf/2103.13018.pdf)
>  Designing optimal control pulses that drive a noisy qubit to a target state is a challenging and crucial task for quantum engineering. In a situation where the properties of the quantum noise affecting the system are dynamic, a periodic characterization procedure is essential to ensure the models are updated. As a result, the operation of the qubit is disrupted frequently. In this paper, we propose a protocol that addresses this challenge by making use of a spectator qubit to monitor the noise in real-time. We develop a quantum machine-learning-based quantum feature engineering approach for designing the protocol. The complexity of the protocol is front-loaded in a characterization phase, which allow real-time execution during the quantum computations. We present the results of numerical simulations that showcase the favorable performance of the protocol.      
### 36.Peak Estimation for Uncertain and Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.13017.pdf)
>  Peak estimation bounds extreme values of a function of state along trajectories of a dynamical system. This paper focuses on extending peak estimation to continuous and discrete settings with time-independent and time-dependent uncertainty. Techniques from optimal control are used to incorporate uncertainty into an existing occupation measure-based peak estimation framework, which includes special consideration for handling switching uncertainties. The resulting infinite-dimensional linear programs can be solved approximately with Linear Matrix Inequalities arising from the moment-SOS hierarchy.      
### 37.Industrial Machine Tool Component Surface Defect Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2103.13003.pdf)
>  Using machine learning (ML) techniques in general and deep learning techniques in specific needs a certain amount of data often not available in large quantities in technical domains. The manual inspection of machine tool components and the manual end-of-line check of products are labor-intensive tasks in industrial applications that companies often want to automate. To automate classification processes and develop reliable and robust machine learning-based classification and wear prognostics models, one needs real-world datasets to train and test the models. The dataset is available under <a class="link-external link-https" href="https://doi.org/10.5445/IR/1000129520" rel="external noopener nofollow">this https URL</a>.      
### 38.A VAE-Based Bayesian Bidirectional LSTM for Renewable Energy Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2103.12969.pdf)
>  The advancement in distributed generation technologies in modern power systems has led to a widespread integration of renewable power generation at customer side. However, the intermittent nature of renewable energy pose new challenges to the network operational planning with underlying uncertainties. This paper proposes a novel Bayesian probabilistic technique for forecasting renewable power generation by addressing data and model uncertainties by integrating bidirectional long short-term memory (BiLSTM) neural networks while compressing the weight parameters using variational autoencoder (VAE). Existing Bayesian deep learning methods suffer from high computational complexities as they require to draw a large number of samples from weight parameters expressed in the form of probability distributions. The proposed method can deal with uncertainty present in model and data in a more computationally efficient manner by reducing the dimensionality of model parameters. The proposed method is evaluated using pinball loss, reconstruction error, and other forecasting evaluation metrics. It is inferred from the numerical results that VAE-Bayesian BiLSTM outperforms other probabilistic deep learning methods in terms of forecasting accuracy and computational efficiency for different sizes of the dataset.      
### 39.Receding Horizon Motion Planning for Multi-Agent Systems: A Velocity Obstacle Based Probabilistic Method  [ :arrow_down: ](https://arxiv.org/pdf/2103.12968.pdf)
>  In this paper, a novel and innovative methodology for feasible motion planning in the multi-agent system is developed. On the basis of velocity obstacles characteristics, the chance constraints are formulated in the receding horizon control (RHC) problem, and geometric information of collision cones is used to generate the feasible regions of velocities for the host agent. By this approach, the motion planning is conducted at the velocity level instead of the position level. Thus, it guarantees a safer collision-free trajectory for the multi-agent system, especially for the systems with high-speed moving agents. Moreover, a probability threshold of potential collisions can be satisfied during the motion planning process. In order to validate the effectiveness of the methodology, different scenarios for multiple agents are investigated, and the simulation results clearly show that the proposed approach can effectively avoid potential collisions with a collision probability less than a specific threshold.      
### 40.Convergence Analysis of Nonconvex Distributed Stochastic Zeroth-order Coordinate Method  [ :arrow_down: ](https://arxiv.org/pdf/2103.12954.pdf)
>  This paper investigates the stochastic distributed nonconvex optimization problem of minimizing a global cost function formed by the summation of $n$ local cost functions. We solve such a problem by involving zeroth-order (ZO) information exchange. In this paper, we propose a ZO distributed primal-dual coordinate method (ZODIAC) to solve the stochastic optimization problem. Agents approximate their own local stochastic ZO oracle along with coordinates with an adaptive smoothing parameter. We show that the proposed algorithm achieves the convergence rate of $\mathcal{O}(\sqrt{p}/\sqrt{T})$ for general nonconvex cost functions. We demonstrate the efficiency of proposed algorithms through a numerical example in comparison with the existing state-of-the-art centralized and distributed ZO algorithms.      
### 41.On Imitation Learning of Linear Control Policies: Enforcing Stability and Robustness Constraints via LMI Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2103.12945.pdf)
>  When applying imitation learning techniques to fit a policy from expert demonstrations, one can take advantage of prior stability/robustness assumptions on the expert's policy and incorporate such control-theoretic prior knowledge explicitly into the learning process. In this paper, we formulate the imitation learning of linear policies as a constrained optimization problem, and present efficient methods which can be used to enforce stability and robustness constraints during the learning processes. Specifically, we show that one can guarantee the closed-loop stability and robustness by posing linear matrix inequality (LMI) constraints on the fitted policy. Then both the projected gradient descent method and the alternating direction method of multipliers (ADMM) method can be applied to solve the resulting constrained policy fitting problem. Finally, we provide numerical results to demonstrate the effectiveness of our methods in producing linear polices with various stability and robustness guarantees.      
### 42.Beyond Visual Attractiveness: Physically Plausible Single Image HDR Reconstruction for Spherical Panoramas  [ :arrow_down: ](https://arxiv.org/pdf/2103.12926.pdf)
>  HDR reconstruction is an important task in computer vision with many industrial needs. The traditional approaches merge multiple exposure shots to generate HDRs that correspond to the physical quantity of illuminance of the scene. However, the tedious capturing process makes such multi-shot approaches inconvenient in practice. In contrast, recent single-shot methods predict a visually appealing HDR from a single LDR image through deep learning. But it is not clear whether the previously mentioned physical properties would still hold, without training the network to explicitly model them. In this paper, we introduce the physical illuminance constraints to our single-shot HDR reconstruction framework, with a focus on spherical panoramas. By the proposed physical regularization, our method can generate HDRs which are not only visually appealing but also physically plausible. For evaluation, we collect a large dataset of LDR and HDR images with ground truth illuminance measures. Extensive experiments show that our HDR images not only maintain high visual quality but also top all baseline methods in illuminance prediction accuracy.      
### 43.SETGAN: Scale and Energy Trade-off GANs for Image Applications on Mobile Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2103.12896.pdf)
>  We consider the task of photo-realistic unconditional image generation (generate high quality, diverse samples that carry the same visual content as the image) on mobile platforms using Generative Adversarial Networks (GANs). In this paper, we propose a novel approach to trade-off image generation accuracy of a GAN for the energy consumed (compute) at run-time called Scale-Energy Tradeoff GAN (SETGAN). GANs usually take a long time to train and consume a huge memory hence making it difficult to run on edge devices. The key idea behind SETGAN for an image generation task is for a given input image, we train a GAN on a remote server and use the trained model on edge devices. We use SinGAN, a single image unconditional generative model, that contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. During the training process, we determine the optimal number of scales for a given input image and the energy constraint from the target edge device. Results show that with SETGAN's unique client-server-based architecture, we were able to achieve a 56% gain in energy for a loss of 3% to 12% SSIM accuracy. Also, with the parallel multi-scale training, we obtain around 4x gain in training time on the server.      
### 44.Learned complex masks for multi-instrument source separation  [ :arrow_down: ](https://arxiv.org/pdf/2103.12864.pdf)
>  Music source separation in the time-frequency domain is commonly achieved by applying a soft or binary mask to the magnitude component of (complex) spectrograms. The phase component is usually not estimated, but instead copied from the mixture and applied to the magnitudes of the estimated isolated sources. While this method has several practical advantages, it imposes an upper bound on the performance of the system, where the estimated isolated sources inherently exhibit audible "phase artifacts". In this paper we address these shortcomings by directly estimating masks in the complex domain, extending recent work from the speech enhancement literature. The method is particularly well suited for multi-instrument musical source separation since residual phase artifacts are more pronounced for spectrally overlapping instrument sources, a common scenario in music. We show that complex masks result in better separation than masks that operate solely on the magnitude component.      
### 45.Embracing the Disharmony in Heterogeneous Medical Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.12857.pdf)
>  Heterogeneity in medical imaging data is often tackled, in the context of machine learning, using domain invariance, i.e. deriving models that are robust to domain shifts, which can be both within domain (e.g. demographics) and across domains (e.g. scanner/protocol characteristics). However this approach can be detrimental to performance because it necessitates averaging across intra-class variability and reduces discriminatory power of learned models, in order to achieve better intra- and inter-domain generalization. This paper instead embraces the heterogeneity and treats it as a multi-task learning problem to explicitly adapt trained classifiers to both inter-site and intra-site heterogeneity. We demonstrate that the error of a base classifier on challenging 3D brain magnetic resonance imaging (MRI) datasets can be reduced by 2-3 times, in certain tasks, by adapting to the specific demographics of the patients, and different acquisition protocols. Learning the characteristics of domain shifts is achieved via auxiliary learning tasks leveraging commonly available data and variables, e.g. demographics. In our experiments, we use gender classification and age regression as auxiliary tasks helping the network weights trained on a source site adapt to data from a target site; we show that this approach improves classification accuracy by 5-30 % across different datasets on the main classification tasks, e.g. disease classification.      
### 46.Bandit Learning for Dynamic Colonel Blotto Game with a Budget Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2103.12833.pdf)
>  We consider a dynamic Colonel Blotto game (CBG) in which one of the players is the learner and has limited troops (budget) to allocate over a finite time horizon. At each stage, the learner strategically determines the budget and its distribution to allocate among the battlefields based on past observations. The other player is the adversary, who chooses its budget allocation strategies randomly from some fixed but unknown distribution. The learner's objective is to minimize the regret, which is defined as the difference between the optimal payoff in terms of the best dynamic policy and the realized payoff by following a learning algorithm. The dynamic CBG is analyzed under the framework of combinatorial bandit and bandit with knapsacks. We first convert the dynamic CBG with the budget constraint to a path planning problem on a graph. We then devise an efficient dynamic policy for the learner that uses a combinatorial bandit algorithm Edge on the path planning graph as a subroutine for another algorithm LagrangeBwK. A high-probability regret bound is derived, and it is shown that under the proposed policy, the learner's regret in the budget-constrained dynamic CBG matches (up to a logarithmic factor) that of the repeated CBG without budget constraints.      
### 47.Neural Architecture Search From Fréchet Task Distance  [ :arrow_down: ](https://arxiv.org/pdf/2103.12827.pdf)
>  We formulate a Fréchet-type asymmetric distance between tasks based on Fisher Information Matrices. We show how the distance between a target task and each task in a given set of baseline tasks can be used to reduce the neural architecture search space for the target task. The complexity reduction in search space for task-specific architectures is achieved by building on the optimized architectures for similar tasks instead of doing a full search without using this side information. Experimental results demonstrate the efficacy of the proposed approach and its improvements over the state-of-the-art methods.      
### 48.Detecting micro fractures with X-ray computed tomography  [ :arrow_down: ](https://arxiv.org/pdf/2103.12821.pdf)
>  Studying porous rock materials with X-Ray Computed Tomography (XRCT) has been established as a standard procedure for the non-destructive visualization of flow and transport in opaque porous media. Despite the recent advances in the field of XRCT, some challenges still remain due to the inherent noise and imaging artefacts in the produced data. These issues become even more profound when the objective is the identification of fractures, and/or fracture networks. The challenge is the limited contrast between the regions of interest and the neighboring areas. This limited contrast can mostly be attributed to the minute aperture of the fractures. In order to overcome this challenge, it has been a common approach to apply digital image processing, such as filtering, to enhance the signal-to-noise ratio. Additionally, segmentation methods based on threshold-/morphology schemes can be employed to obtain enhanced information from the features of interest. However, this workflow needs a skillful operator to fine-tune its input parameters, and the required computation time significantly increases due to the complexity of the available methods, and the large volume of the data-set. In this study, based on a data-set produced by the successful visualization of a fracture network in Carrara marble with XRCT, we present the segmentation results from a number of segmentation methods. Three conventional and two machine-learning-based methods are evaluated. The segmentation results from all five methods are compared to each other in terms of segmentation quality and time efficiency. Due to memory limitations, and in order to accomplish a fair comparison, all the methods are employed in a 2D scheme. The output of the 2D U-net model, which is one of the adopted machine-learning-based segmentation methods, shows the best performance regarding the quality of segmentation and the required processing time.      
### 49.Single pixel structured imaging through fog  [ :arrow_down: ](https://arxiv.org/pdf/2103.12789.pdf)
>  We describe the application of structured imaging with a single pixel camera to imaging through fog. We demonstrate the use of a high-pass filter on the detected bucket signals to suppress the effects of temporal variations of fog density and enable an effective reconstruction of the image. A quantitative analysis and comparison of several high-pass filters are demonstrated for the application. Both computational ghost imaging and compressive sensing techniques were used for image reconstruction and compressive sensing was observed to give a higher reconstructed image quality.      
### 50.Stochastic Optimal Control via Hilbert Space Embeddings of Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2103.12759.pdf)
>  Kernel embeddings of distributions have recently gained significant attention in the machine learning community as a data-driven technique for representing probability distributions. Broadly, these techniques enable efficient computation of expectations by representing integral operators as elements in a reproducing kernel Hilbert space. We apply these techniques to the area of stochastic optimal control theory and present a method to compute approximately optimal policies for stochastic systems with arbitrary disturbances. Our approach reduces the optimization problem to a linear program, which can easily be solved via the Lagrangian dual, without resorting to gradient-based optimization algorithms. We focus on discrete-time dynamic programming, and demonstrate our proposed approach on a linear regulation problem, and on a nonlinear target tracking problem. This approach is broadly applicable to a wide variety of optimal control problems, and provides a means of working with stochastic systems in a data-driven setting.      
### 51.PI(D) tuning for Flight Control Systems via Incremental Nonlinear Dynamic Inversion  [ :arrow_down: ](https://arxiv.org/pdf/1701.08981.pdf)
>  Previous results reported in the robotics literature show the relationship between time-delay control (TDC) and proportional-integral-derivative control (PID). In this paper, we show that incremental nonlinear dynamic inversion (INDI) - more familiar in the aerospace community - are in fact equivalent to TDC. This leads to a meaningful and systematic method for PI(D)-control tuning of robust nonlinear flight control systems via INDI. We considered a reformulation of the plant dynamics inversion which removes effector blending models from the resulting control law, resulting in robust model-free control laws like PI(D)-control.      

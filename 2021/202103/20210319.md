# ArXiv eess --Fri, 19 Mar 2021
### 1.Efficient approximations of the multi-sensor labelled multi-Bernoulli filter  [ :arrow_down: ](https://arxiv.org/pdf/2103.10396.pdf)
>  In this paper, we propose two efficient, approximate formulations of the multi-sensor labelled multi-Bernoulli (LMB) filter, which both allow the sensors' measurement updates to be computed in parallel. Our first filter is based on the direct mathematical manipulation of the multi-sensor, multi-object Bayes filter's posterior distribution. Unfortunately, it requires the division of probability distributions and its extension beyond linear Gaussian applications is not obvious. Our second filter is based on covariance intersection and it approximates the multi-sensor, multi-object Bayes filter's posterior distribution using the geometric mean of each sensor's measurement-updated distribution. This filter can be used for distributed fusion under non-linear conditions; however, it is not as accurate as our first filter. In both cases, we approximate the LMB filter's measurement update using an existing loopy belief propagation algorithm, which we adapt to account for object existence. Both filters have a constant complexity in the number of sensors, and linear complexity in both number of measurements and objects. This is an improvement on an iterated-corrector LMB filter, which has linear complexity in the number of sensors. We evaluate both filters' performances on simulated data and the results indicate that the filters are accurate.      
### 2.A Subjective Study on Videos at Various Bit Depths  [ :arrow_down: ](https://arxiv.org/pdf/2103.10363.pdf)
>  Bit depth adaptation, where the bit depth of a video sequence is reduced before transmission and up-sampled during display, can potentially reduce data rates with limited impact on perceptual quality. In this context, we conducted a subjective study on a UHD video database, BVI-BD, to explore the relationship between bit depth and visual quality. In this work, three bit depth adaptation methods are investigated, including linear scaling, error diffusion, and a novel adaptive Gaussian filtering approach. The results from a subjective experiment indicate that above a critical bit depth, bit depth adaptation has no significant impact on perceptual quality, while reducing the amount information that is required to be transmitted. Below the critical bit depth, advanced adaptation methods can be used to retain `good' visual quality (on average) down to around 2 bits per color channel for the outlined experimental setup - a large reduction compared to the typically used 8 bits per color channel. A selection of image quality metrics were subsequently bench-marked on the subjective data, and analysis indicates that a bespoke quality metric is required for bit depth adaptation.      
### 3.Constrained Radar Waveform Design for Range Profiling  [ :arrow_down: ](https://arxiv.org/pdf/2103.10320.pdf)
>  Range profiling refers to the measurement of target response along the radar slant range. It plays an important role in automatic target recognition. In this paper, we consider the design of transmit waveform to improve the range profiling performance of radar systems. Two design metrics are adopted for the waveform optimization problem: one is to maximize the mutual information between the received signal and the target impulse response (TIR); the other is to minimize the minimum mean-square error for estimating the TIR. In addition, practical constraints on the waveforms are considered, including an energy constraint, a peak-to-average-power-ratio constraint, and a spectral constraint. Based on minorization-maximization, we propose a unified optimization framework to tackle the constrained waveform design problem. Numerical examples show the superiority of the waveforms synthesized by the proposed algorithms.      
### 4.In-flight actuator failure recovery of a hexrotor via multiple models and extended high-gain observers  [ :arrow_down: ](https://arxiv.org/pdf/2103.10318.pdf)
>  We study an in-flight actuator failure recovery problem for a hexrotor UAV. The hexrotor may experience external disturbances and modeling error, which are accounted for in the control design and distinguished from an actuator failure. A failure of any one actuator occurs during flight and must be identified quickly and accurately. This is achieved through the use of a multiple-model, multiple extended high-gain observer (EHGO) based output feedback control strategy. The family of EHGOs are responsible for estimating states, disturbances, and are used to select the appropriate model based on the system dynamics after a failure has occurred. The proposed method is theoretically analyzed and validated through simulations and experiments.      
### 5.Data-driven inference on optimal input-output properties of polynomial systems with focus on nonlinearity measures  [ :arrow_down: ](https://arxiv.org/pdf/2103.10306.pdf)
>  In the context of dynamical systems, nonlinearity measures quantify the strength of their nonlinearity by means of the distance of their input-output behaviour to a set of linear input-output mappings. In this paper, we establish a framework to determine nonlinearity measures and other optimal input-output properties for nonlinear polynomial systems without explicitly identifying a model but directly from a finite number of input-state measurements which are subject to noise. To this end, we deduce from noisy data for the unidentified ground-truth system three set-membership representations for which we prove asymptotic consistency with respect to the number of samples. Then, we leverage these representations to compute guaranteed upper bounds on nonlinearity measures and the corresponding optimal linear approximation model via semi-definite programming. Furthermore, we apply the framework to determine optimal input-output properties described by certain classes of time domain hard integral quadratic inequalities.      
### 6.Advances in 3D scattering tomography of cloud micro-physics  [ :arrow_down: ](https://arxiv.org/pdf/2103.10305.pdf)
>  We introduce new adjustments and advances in space-borne 3D volumetric scattering-tomography of cloud micro-physics. The micro-physical properties retrieved are the liquid water content and effective radius within a cloud. New adjustments include an advanced perspective polarization imager model, and the assumption of 3D variation of the effective radius. Under these assumptions, we advanced the retrieval to yield results that (compared to the simulated ground-truth) have smaller errors than the prior art. Elements of our advancement include initialization by a parametric horizontally-uniform micro-physical model. The parameters of this initialization are determined by a grid search of the cost function. Furthermore, we added viewpoints corresponding to single-scattering angles, where polarization yields enhanced sensitivity to the droplet micro-physics (i.e., the cloudbow region). In addition, we introduce an optional adjustment, in which optimization of the liquid water content and effective radius are separated to alternating periods. The suggested initialization model and additional advances have been evaluated by retrieval of a set of large-eddy simulation clouds.      
### 7.Error Analysis of Douglas-Rachford Algorithm for Linear Inverse Problems: Asymptotics of Proximity Operator for Squared Loss  [ :arrow_down: ](https://arxiv.org/pdf/2103.10300.pdf)
>  Proximal splitting-based convex optimization is a promising approach to linear inverse problems because we can use some prior knowledge of the unknown variables explicitly. In this paper, we firstly analyze the asymptotic property of the proximity operator for the squared loss function, which appears in the update equations of some proximal splitting methods for linear inverse problems. The analysis shows that the output of the proximity operator can be characterized with a scalar random variable in the large system limit. Moreover, we investigate the asymptotic behavior of the Douglas-Rachford algorithm, which is one of the famous proximal splitting methods. From the asymptotic result, we can predict the evolution of the mean-square-error (MSE) in the algorithm for large-scale linear inverse problems. Simulation results demonstrate that the MSE performance of the Douglas-Rachford algorithm can be well predicted by the analytical result in compressed sensing with the $\ell_{1}$ optimization.      
### 8.How I failed machine learning in medical imaging -- shortcomings and recommendations  [ :arrow_down: ](https://arxiv.org/pdf/2103.10292.pdf)
>  Medical imaging is an important research field with many opportunities for improving patients' health. However, there are a number of challenges that are slowing down the progress of the field as a whole, such optimizing for publication. In this paper we reviewed several problems related to choosing datasets, methods, evaluation metrics, and publication strategies. With a review of literature and our own analysis, we show that at every step, potential biases can creep in. On a positive note, we also see that initiatives to counteract these problems are already being started. Finally we provide a broad range of recommendations on how to further these address problems in the future. For reproducibility, data and code for our analyses are available on \url{<a class="link-external link-https" href="https://github.com/GaelVaroquaux/ml_med_imaging_failures" rel="external noopener nofollow">this https URL</a>}      
### 9.Formation Control for Multiple Connected and Automated Vehicles on Multi-lane Roads  [ :arrow_down: ](https://arxiv.org/pdf/2103.10287.pdf)
>  Coordinated decision making and control can improve traffic efficiency while guaranteeing driving safety. This paper proposes a formation control method for multiple Connected and Automated Vehicles (CAVs) on multi-lane roads. A bi-level planning framework is proposed to smoothly and effectively switch the structure of the formation in different scenarios. The relative coordinate system is established and the conflict-free relative paths are planned in the upper level. Multi-stage trajectory planning and tracking are performed in the lower level. Case study is conducted to verify the function of the proposed method and simulation in the lane-drop bottleneck scenario is carried out under different traffic volume. Numerical results indicate that the proposed method can improve traffic efficiency at high traffic volume.      
### 10.Local Electricity Market Design Utilizing Dynamic Network Usage Tariff  [ :arrow_down: ](https://arxiv.org/pdf/2103.10175.pdf)
>  The new technologies emerging in the energy sector pose new requirements for both the regulation and operation of the electricity grid. Revised tariff structures and the introduction of local markets are two approaches that could tackle the issues resulting from the increasing number of active end-users. However, a smooth transition from the traditional schemes is critical, thus creating the need for architecture that can be implemented in the current circumstances. This paper proposes a local market concept and a corresponding dynamic tariff system, which can be operated parallel to the current retail market. The participants of the market can trade energy peer-to-peer via a platform that allocates proper network charges to all transactions. The calculated tariffs consider the physical effect of the transactions on the grid in terms of nodal voltage deviations, branch current flows, and overall system losses. The proposed method is tested on the IEEE European LV test feeder through market simulations. The results imply that with the proper tuning of DNUT (Dynamic Network Usage Tariff) components, the end-users can realize surplus, while the security of network operation is also ensured.      
### 11.A Physics-based and Data-driven Linear Three-Phase Power Flow Model for Distribution Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.10147.pdf)
>  Distribution power systems (DPSs) are mostly unbalanced, and their loads may have notable static voltage characteristics (ZIP loads). Hence, despite abundant papers on linear single-phase power flow models, it is still necessary to study linear three-phase distribution power flow models. To this end, this paper proposes a physics-based and data-driven linear three-phase power flow model for DPSs. We first formulate how to amalgamate data-driven techniques into a physics-based power flow model to obtain our linear model. This amalgamation makes our linear model independent of the assumptions commonly used in the literature (e.g., nodal voltages are nearly 1.0 p.u.) and thus have a relatively high accuracy generally - even when those assumptions become invalid. We then reveal how to apply our model to the DPSs with ZIP loads. We also show that with the Huber penalty function employed, the adverse impact of bad data on our model's accuracy is significantly reduced, rendering our model robust against poor data quality. Case studies have demonstrated that our model generally has 2 to over 10-fold smaller average errors than other linear power flow models, enjoys a satisfying accuracy against bad data, and facilitates a faster solution to DPS analysis and optimization problems.      
### 12.Finite-word-length FPGA implementation of model predictive control for ITER resistive wall mode control  [ :arrow_down: ](https://arxiv.org/pdf/2103.10146.pdf)
>  In advanced tokamak scenarios, active feedback control of unstable resistive wall modes (RWM) may be required. A RWM is an instability due to plasma kink at higher plasma pressure, moderated by the presence of a resistive wall surrounding the plasma. We address the dominant kink instability associated with the main nonaxisymmetric (n = 1) RWM, described by the CarMa model. Model predictive control (MPC) is used, with the aim of enlarging the domain of attraction of the unstable RWM modes subject to power-supply voltage constraints. The implementation of MPC is challenging, because the related quadratic programming (QP) on-line optimization problems must be solved at a sub-ms sampling rate. Using complexity-reduction pre-processing techniques and a primal fast gradient method (FGM) QP solver, sufficiently short computation times for ITER are reachable using a standard personal computer (PC). In this work we explore even faster finite-word-length (FWL) implementation using field-programmable gate arrays (FPGA), which would facilitate experimental testing of such control algorithms on dynamically faster medium-sized tokamaks, and compare the computational accuracy and time with the PC implementation.      
### 13.Robust optimal periodic control using guaranteed Euler's method  [ :arrow_down: ](https://arxiv.org/pdf/2103.10125.pdf)
>  In this paper, we consider the application of optimal periodic control sequences to switched dynamical systems. The control sequence is obtained using a finite-horizon optimal method based on dynamic programming. We then consider Euler approximate solutions for the system extended with bounded perturbations. The main result gives a simple condition on the perturbed system for guaranteeing the existence of a stable limit cycle of the unperturbed system. An illustrative numerical example is provided which demonstrates the applicability of the method.      
### 14.Robust and Guided Bayesian Reconstruction of Single-Photon 3D Lidar Data: Application to Multispectral and Underwater Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2103.10122.pdf)
>  3D Lidar imaging can be a challenging modality when using multiple wavelengths, or when imaging in high noise environments (e.g., imaging through obscurants). This paper presents a hierarchical Bayesian algorithm for the robust reconstruction of multispectral single-photon Lidar data in such environments. The algorithm exploits multi-scale information to provide robust depth and reflectivity estimates together with their uncertainties to help with decision making. The proposed weight-based strategy allows the use of available guide information that can be obtained by using state-of-the-art learning based algorithms. The proposed Bayesian model and its estimation algorithm are validated on both synthetic and real images showing competitive results regarding the quality of the inferences and the computational complexity when compared to the state-of-the-art algorithms.      
### 15.On feedback passivation under sampling  [ :arrow_down: ](https://arxiv.org/pdf/2103.10078.pdf)
>  In this paper we show that feedback passivation under sampling can be preserved under digital control through the redefinition of a passifying output map which depends on the sampling period. The design is constructive and approximate solutions make sense. The procedure is applied to port Hamiltonian dynamics and Interconnection and Damping Assignment feedback. Performances are illustrated over the gravity pendulum example.      
### 16.Behavioural Approach to Distributed Control of Interconnected Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.10063.pdf)
>  This paper formulates a framework for the analysis and distributed control of interconnected systems from the behavioural perspective. The discussions are carried out from the viewpoint of set theory and the results are completely representation-free. The core of a dynamical system can be represented as the set of all trajectories admissible through the system and interconnections are interpreted as constraints on the choice of trajectories. We develop a structure in which the interconnected behaviour can be directly built from the behaviours of the subsystems in an explicit way without any presumed forms of representations. We show that the interconnected behaviour can also be fully obtained from local observations of the subsystem. Furthermore, we develop the necessary and sufficient conditions for the existence of distributed controller behaviours and their explicit construction. Due to the entirely representation-free nature of this framework, it unites various representations and descriptions of features of dynamical systems (e.g. models, dissipativity, data, etc.) as behaviours, allowing for the formation of a unified platform for the analysis and distributed control for interconnected systems.      
### 17.Dementia Severity Classification under Small Sample Size and Weak Supervision in Thick Slice MRI  [ :arrow_down: ](https://arxiv.org/pdf/2103.10056.pdf)
>  Early detection of dementia through specific biomarkers in MR images plays a critical role in developing support strategies proactively. Fazekas scale facilitates an accurate quantitative assessment of the severity of white matter lesions and hence the disease. Imaging Biomarkers of dementia are multiple and comprehensive documentation of them is time-consuming. Therefore, any effort to automatically extract these biomarkers will be of clinical value while reducing inter-rater discrepancies. To tackle this problem, we propose to classify the disease severity based on the Fazekas scale through the visual biomarkers, namely the Periventricular White Matter (PVWM) and the Deep White Matter (DWM) changes, in the real-world setting of thick-slice MRI. Small training sample size and weak supervision in form of assigning severity labels to the whole MRI stack are among the main challenges. To combat the mentioned issues, we have developed a deep learning pipeline that employs self-supervised representation learning, multiple instance learning, and appropriate pre-processing steps. We use pretext tasks such as non-linear transformation, local shuffling, in- and out-painting for self-supervised learning of useful features in this domain. Furthermore, an attention model is used to determine the relevance of each MRI slice for predicting the Fazekas scale in an unsupervised manner. We show the significant superiority of our method in distinguishing different classes of dementia compared to state-of-the-art methods in our mentioned setting, which improves the macro averaged F1-score of state-of-the-art from 61% to 76% in PVWM, and from 58% to 69.2% in DWM.      
### 18.Probabilistic Simplex Component Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.10027.pdf)
>  This study presents PRISM, a probabilistic simplex component analysis approach to identifying the vertices of a data-circumscribing simplex from data. The problem has a rich variety of applications, the most notable being hyperspectral unmixing in remote sensing and non-negative matrix factorization in machine learning. PRISM uses a simple probabilistic model, namely, uniform simplex data distribution and additive Gaussian noise, and it carries out inference by maximum likelihood. The inference model is sound in the sense that the vertices are provably identifiable under some assumptions, and it suggests that PRISM can be effective in combating noise when the number of data points is large. PRISM has strong, but hidden, relationships with simplex volume minimization, a powerful geometric approach for the same problem. We study these fundamental aspects, and we also consider algorithmic schemes based on importance sampling and variational inference. In particular, the variational inference scheme is shown to resemble a matrix factorization problem with a special regularizer, which draws an interesting connection to the matrix factorization approach. Numerical results are provided to demonstrate the potential of PRISM.      
### 19.COVIDx-US -- An open-access benchmark dataset of ultrasound imaging data for AI-driven COVID-19 analytics  [ :arrow_down: ](https://arxiv.org/pdf/2103.10003.pdf)
>  The COVID-19 pandemic continues to have a devastating effect on the health and well-being of the global population. Apart from the global health crises, the pandemic has also caused significant economic and financial difficulties and socio-physiological implications. Effective screening, triage, treatment planning, and prognostication of outcome plays a key role in controlling the pandemic. Recent studies have highlighted the role of point-of-care ultrasound imaging for COVID-19 screening and prognosis, particularly given that it is non-invasive, globally available, and easy-to-sanitize. Motivated by these attributes and the promise of artificial intelligence tools to aid clinicians, we introduce COVIDx-US, an open-access benchmark dataset of COVID-19 related ultrasound imaging data that is the largest of its kind. The COVIDx-US dataset was curated from multiple sources and consists of 93 lung ultrasound videos and 10,774 processed images of patients infected with SARS-CoV-2 pneumonia, non-SARS-CoV-2 pneumonia, as well as healthy control cases. The dataset was systematically processed and validated specifically for the purpose of building and evaluating artificial intelligence algorithms and models.      
### 20.On Stability Analysis of Power Grids with Synchronous Generators and Grid-Forming Converters under DC-side Current Limitation  [ :arrow_down: ](https://arxiv.org/pdf/2103.09966.pdf)
>  Stability of power grids with synchronous generators (SGs) and renewable generation interfaced with grid-forming converters (GFCs) under dc-side current limitation is studied. To that end, we first consider a simple 2-bus test system and reduced-order models to highlight the fundamental difference between two classes of GFC controls -- (A) droop, dispatchable virtual oscillator control (dVOC) and virtual synchronous machine (VSM), and (B) matching control. Next, we study Lyapunov stability and input-output stability of the dc voltage dynamics of class-A GFCs for the simple system and extend it to a generic system. Next, we provide a sufficiency condition for input-to-state stability of the 2-bus system with a class-B GFC and extend it for a generic system. Finally, time-domain simulations from a reduced-order averaged model of the simple test system and a detailed switched model of the GFC validate the proposed conditions.      
### 21.TSTNN: Two-stage Transformer based Neural Network for Speech Enhancement in the Time Domain  [ :arrow_down: ](https://arxiv.org/pdf/2103.09963.pdf)
>  In this paper, we propose a transformer-based architecture, called two-stage transformer neural network (TSTNN) for end-to-end speech denoising in the time domain. The proposed model is composed of an encoder, a two-stage transformer module (TSTM), a masking module and a decoder. The encoder maps input noisy speech into feature representation. The TSTM exploits four stacked two-stage transformer blocks to efficiently extract local and global information from the encoder output stage by stage. The masking module creates a mask which will be multiplied with the encoder output. Finally, the decoder uses the masked encoder feature to reconstruct the enhanced speech. Experimental results on the benchmark dataset show that the TSTNN outperforms most state-of-the-art models in time or frequency domain while having significantly lower model complexity.      
### 22.Demand for shared mobility to replace private mobility using connected and automated vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.09951.pdf)
>  We examine how introduction of Shared Connected and Automated vehicles (SCAVs) as a new mobility mode could affect travel demand, welfare, as well as traffic congestion in the network. To do so, we adapt an agent-based day-to-day adjustment process and develop a central dispatching system, which is implemented on an in-house traffic microsimulator. We consider a two-sided market in which demand and SCAV fleet size change endogenously. For dispatching SCAV fleet size, we take changing traffic conditions into account. There are two available transport modes: private Connected Automated Vehicles (CAVs) and SCAVs. The designed system is applied on downtown Toronto network using real data. The results show that demand of SCAVs goes up by 43 per cent over seven study days from 670 trips on the first day to 959 trips on the seventh day. Whereas, there is a 10 per cent reduction in private CAV demand from 2807 trips to 2518 trips during the same duration. Moreover, total travel time of the network goes down by seven per cent indicating that traffic congestion was reduced in the network.      
### 23.Detection and Isolation of Small Faults in Lithium-Ion Batteries via the Asymptotic Local Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.09936.pdf)
>  This contribution presents a diagnosis scheme for batteries to detect and isolate internal faults in the form of small parameter changes. This scheme is based on an electrochemical reduced-order model of the battery, which allows the inclusion of physically meaningful faults that might affect the battery performance. The sensitivity properties of the model are analyzed. The model is then used to compute residuals based on an unscented Kalman filter. Primary residuals and a limiting covariance matrix are obtained thanks to the local approach, allowing for fault detection and isolation by chi-squared statistical tests. Results show that faults resulting in limited 0.15% capacity and 0.004% power fade can be effectively detected by the local approach. The algorithm is also able to correctly isolate faults related with sensitive parameters, whereas parameters with low sensitivity or linearly correlated are more difficult to precise.      
### 24.Environment and Person Independent Activity Recognition with a Commodity IEEE 802.11ac Access Point  [ :arrow_down: ](https://arxiv.org/pdf/2103.09924.pdf)
>  Here, we propose an original approach for human activity recognition (HAR) with commercial IEEE 802.11ac (WiFi) devices, which generalizes across different persons, days and environments. To achieve this, we devise a technique to extract, clean and process the received phases from the channel frequency response (CFR) of the WiFi channel, obtaining an estimate of the Doppler shift at the receiver of the communication link. The Doppler shift reveals the presence of moving scatterers in the environment, while not being affected by (environment specific) static objects. The proposed HAR framework is trained on data collected as a person performs four different activities and is tested on unseen setups, to assess its performance as the person, the day and/or the environment change with respect to those considered at training time. In the worst case scenario, the proposed HAR technique reaches an average accuracy higher than 95%, validating the effectiveness of the extracted Doppler information, used in conjunction with a learning algorithm based on a neural network, in recognizing human activities in a subject and environment independent fashion.      
### 25.Demand for shared mobility to complement public transportation: Human driven and autonomous vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.09918.pdf)
>  Recent advances in communication technologies and automated vehicles have opened doors for alternative mobility systems (taxis, carpool, demand-responsive services, peer-to-peer ridesharing, and car sharing, shared autonomous vehicles/shuttles). These new mobility services have gathered interest from researchers, public and private sectors as potential solutions to address last-mile problem--especially in low density areas where implementation of high frequency buses is not feasible. In this study we investigate the effects of ride-sharing service on travel demand and welfare, as it complements public transportation under different scenarios. Two types of management and vehicle types are considered: crowdsourced human driven vehicles (HDV) (e.g. Uber, Lyft) and centrally operated shared autonomous vehicles (SAV). The influence of fare discount on demand and mode shift is also investigated. A case study of Oakville road network in Ontario, Canada is conducted using real data. The results reveal that ride-sharing having the potential of increasing ridership by 76 per cent and decreasing wait time by 47 per cent under centrally operated shared autonomous vehicles with 50 per cent fare discount for sharing.      
### 26.A Novel Approach to Disturbance Rejection in Constrained Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.09865.pdf)
>  This thesis is concerned with the rejection of time-varying disturbances in linear model predictive control of discrete-time systems. In the literature, disturbances are widely rejected by using velocity models, disturbance model with observer approach or a scheme that combines the compensation of a disturbance observer and the feedback regulation of MPC. Contrary to the widely used methods, the technique proposed in this research work utilises the increment model of plants to formulate a control law to reject varying-disturbance. The uniqueness of the method stems from the compensation for disturbance magnitude and rate of change. By proposing a cost function where the increment form of the system disturbance is taken as an optimisation variable, a control signal that is a function of a computed optimal disturbance increment is formulated to ensure that the plant is driven according to the minimisation of the cost function. The degree of freedom introduced by using the optimal disturbance in the control law was exploited to introduce the estimated disturbance increment into the control signal such that it is always in opposition to the external disturbance increment. Moreover, the proposed cost function provides a weighting matrix that can be used to manipulate the impacts of the exogenous disturbances on the response of the system. To estimate the unmeasurable disturbances, a combined state and disturbance observer is designed based on a convex optimisation stated in terms of an H2-minimisation problem. Simulations of three different systems are used to show the benefits the proposed algorithm has over conventional offset-free MPC techniques. The results demonstrated that the proposed scheme may give better output tracking and regulation and it is particularly more tolerant of actuator saturation.      
### 27.Fast AC Steady-State Power Grid Simulation and Optimization Using Prior Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2103.09853.pdf)
>  Fast and accurate optimization and simulation is widely becoming a necessity for large scale transmission resiliency and planning studies such as N-1 SCOPF, batch contingency solvers, and stochastic power flow. Current commercial tools, however, prioritize speed of convergence over accuracy by relying on initial conditions that are taken from the steady state solution of similar network configurations that are not guaranteed to lie within a convex region of a valid solution. In this paper we introduce a globally convergent algorithm to facilitate fast and accurate AC steady state simulation and optimization based on prior knowledge from similar networks. The approach uses a homotopy method that gradually and efficiently translates a previously known network configuration to the current network configuration. The proposed formulation is highly scalable, and its efficacy is demonstrated for resiliency study and optimization of large networks up to 70k buses.      
### 28.Computer Vision Aided URLL Communications: Proactive Service Identification and Coexistence  [ :arrow_down: ](https://arxiv.org/pdf/2103.10419.pdf)
>  The support of coexisting ultra-reliable and low-latency (URLL) and enhanced Mobile BroadBand (eMBB) services is a key challenge for the current and future wireless communication networks. Those two types of services introduce strict, and in some time conflicting, resource allocation requirements that may result in a power-struggle between reliability, latency, and resource utilization in wireless networks. The difficulty in addressing that challenge could be traced back to the predominant reactive approach in allocating the wireless resources. This allocation operation is carried out based on received service requests and global network statistics, which may not incorporate a sense of \textit{proaction}. Therefore, this paper proposes a novel framework termed \textit{service identification} to develop novel proactive resource allocation algorithms. The developed framework is based on visual data (captured for example by RGB cameras) and deep learning (e.g., deep neural networks). The ultimate objective of this framework is to equip future wireless networks with the ability to analyze user behavior, anticipate incoming services, and perform proactive resource allocation. To demonstrate the potential of the proposed framework, a wireless network scenario with two coexisting URLL and eMBB services is considered, and two deep learning algorithms are designed to utilize RGB video frames and predict incoming service type and its request time. An evaluation dataset based on the considered scenario is developed and used to evaluate the performance of the two algorithms. The results confirm the anticipated value of proaction to wireless networks; the proposed models enable efficient network performance ensuring more than $85\%$ utilization of the network resources at $\sim 98\%$ reliability. This highlights a promising direction for the future vision-aided wireless communication networks.      
### 29.MILP for the Multi-objective VM Reassignment Problem  [ :arrow_down: ](https://arxiv.org/pdf/2103.10410.pdf)
>  Machine Reassignment is a challenging problem for constraint programming (CP) and mixed-integer linear programming (MILP) approaches, especially given the size of data centres. The multi-objective version of the Machine Reassignment Problem is even more challenging and it seems unlikely for CP or MILP to obtain good results in this context. As a result, the first approaches to address this problem have been based on other optimisation methods, including metaheuristics. In this paper we study under which conditions a mixed-integer optimisation solver, such as IBM ILOG CPLEX, can be used for the Multi-objective Machine Reassignment Problem. We show that it is useful only for small or medium-scale data centres and with some relaxations, such as an optimality tolerance gap and a limited number of directions explored in the search space. Building on this study, we also investigate a hybrid approach, feeding a metaheuristic with the results of CPLEX, and we show that the gains are important in terms of quality of the set of Pareto solutions (+126.9% against the metaheuristic alone and +17.8% against CPLEX alone) and number of solutions (8.9 times more than CPLEX), while the processing time increases only by 6% in comparison to CPLEX for execution times larger than 100 seconds.      
### 30.Investigate Indistinguishable Points in Semantic Segmentation of 3D Point Cloud  [ :arrow_down: ](https://arxiv.org/pdf/2103.10339.pdf)
>  This paper investigates the indistinguishable points (difficult to predict label) in semantic segmentation for large-scale 3D point clouds. The indistinguishable points consist of those located in complex boundary, points with similar local textures but different categories, and points in isolate small hard areas, which largely harm the performance of 3D semantic segmentation. To address this challenge, we propose a novel Indistinguishable Area Focalization Network (IAF-Net), which selects indistinguishable points adaptively by utilizing the hierarchical semantic features and enhances fine-grained features for points especially those indistinguishable points. We also introduce multi-stage loss to improve the feature representation in a progressive way. Moreover, in order to analyze the segmentation performances of indistinguishable areas, we propose a new evaluation metric called Indistinguishable Points Based Metric (IPBM). Our IAF-Net achieves the comparable results with state-of-the-art performance on several popular 3D point cloud datasets e.g. S3DIS and ScanNet, and clearly outperforms other methods on IPBM.      
### 31.Analyzing Uplink Grant-free Sparse Code Multiple Access System in Massive IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.10241.pdf)
>  Grant-free sparse code multiple access (GF-SCMA) is considered to be a promising multiple access candidate for future wireless networks. In this paper, we focus on characterizing the performance of uplink GF-SCMA schemes in a network with ubiquitous connections, such as the Internet of Things (IoT) networks. To provide a tractable approach to evaluate the performance of GF-SCMA, we first develop a theoretical model taking into account the property of multi-user detection (MUD) in the SCMA system. We then analyze the error rate performance of GF-SCMA in the case of codebook collision to investigate the reliability of GF-SCMA when reusing codebook in massive IoT networks. For performance evaluation, accurate approximations for both success probability and average symbol error probability (ASEP) are derived. To elaborate further, we utilize the analytical results to discuss the impact of codeword sparse degree in GFSCMA. After that, we conduct a comparative study between SCMA and its variant, dense code multiple access (DCMA), with GF transmission to offer insights into the effectiveness of these two schemes. This facilitates the GF-SCMA system design in practical implementation. Simulation results show that denser codebooks can help to support more UEs and increase the reliability of data transmission in a GF-SCMA network. Moreover, a higher success probability can be achieved by GFSCMA with denser UE deployment at low detection thresholds since SCMA can achieve overloading gain.      
### 32.On the Characterizations of OTFS Modulation over multipath Rapid Fading Channel  [ :arrow_down: ](https://arxiv.org/pdf/2103.10199.pdf)
>  Orthogonal time frequency space (OTFS) modulation has been verified to provide significant performance advantages against Doppler in high-mobility scenarios. The core feature of OTFS is that the time-variant channel is converted into a non-fading 2D channel in the delay-Doppler (DD) domain so that all symbols experience the same channel gain. In now available literatures, the channel is assumed to be quasi-static over an OTFS frame. As for more practical channels, the input-output relation will be time-variant as the environment or medium changes. In this paper, we analyze the characterizations of OTFS Modulation over a more general multipath Channel, where the signal of each path has experienced a unique rapid fading. First, we derive the explicit input-output relationship of OTFS in the DD domain for the case of ideal pulse and rectangular pulse. It is shown that the rapid fading will produce extra Doppler dispersion without impacting on delay domain. We next domenstrate that OTFS can be interpreted as an efficient time diversity technology that combines space-time encoding and interleaving. The simulation results reveal that OTFS is insensitive to rapid fading and still outperforms orthogonal frequency-division multiplexing (OFDM) in such channel.      
### 33.A Cooperative Architecture of Data Offloading and Sharing for Blockchain-based Healthcare Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.10186.pdf)
>  The healthcare industry has witnessed significant transformations in e-health services where Electronic Health Records (EHRs) are transferred to mobile edge clouds to facilitate healthcare. Many edge cloud-based system designs have been proposed, but some technical challenges still remain, such as low quality of services (QoS), data privacy and system security due to centralized healthcare architectures. In this paper, we propose a novel hybrid approach of data offloading and data sharing for healthcare using edge cloud and blockchain. First, an efficient data offloading scheme is proposed where IoT health data can be offloaded to nearby edge servers for data processing with privacy awareness. Then, a data sharing scheme is integrated to enable data exchange among healthcare users via blockchain. Particularly, a trustworthy access control mechanism is developed using smart contracts for access authentication to achieve secure EHRs sharing. Implementation results from extensive real-world experiments show the superior advantages of the proposal over the existing schemes in terms of improved QoS, enhanced data privacy and security, and low smart contract costs.      
### 34.Bayesian Imaging With Data-Driven Priors Encoded by Neural Networks: Theory, Methods, and Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2103.10182.pdf)
>  This paper proposes a new methodology for performing Bayesian inference in imaging inverse problems where the prior knowledge is available in the form of training data. Following the manifold hypothesis and adopting a generative modelling approach, we construct a data-driven prior that is supported on a sub-manifold of the ambient space, which we can learn from the training data by using a variational autoencoder or a generative adversarial network. We establish the existence and well-posedness of the associated posterior distribution and posterior moments under easily verifiable conditions, providing a rigorous underpinning for Bayesian estimators and uncertainty quantification analyses. Bayesian computation is performed by using a parallel tempered version of the preconditioned Crank-Nicolson algorithm on the manifold, which is shown to be ergodic and robust to the non-convex nature of these data-driven models. In addition to point estimators and uncertainty quantification analyses, we derive a model misspecification test to automatically detect situations where the data-driven prior is unreliable, and explain how to identify the dimension of the latent space directly from the training data. The proposed approach is illustrated with a range of experiments with the MNIST dataset, where it outperforms alternative image reconstruction approaches from the state of the art. A model accuracy analysis suggests that the Bayesian probabilities reported by the data-driven models are also remarkably accurate under a frequentist definition of probability.      
### 35.OmniPose: A Multi-Scale Framework for Multi-Person Pose Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2103.10180.pdf)
>  We propose OmniPose, a single-pass, end-to-end trainable framework, that achieves state-of-the-art results for multi-person pose estimation. Using a novel waterfall module, the OmniPose architecture leverages multi-scale feature representations that increase the effectiveness of backbone feature extractors, without the need for post-processing. OmniPose incorporates contextual information across scales and joint localization with Gaussian heatmap modulation at the multi-scale feature extractor to estimate human pose with state-of-the-art accuracy. The multi-scale representations, obtained by the improved waterfall module in OmniPose, leverage the efficiency of progressive filtering in the cascade architecture, while maintaining multi-scale fields-of-view comparable to spatial pyramid configurations. Our results on multiple datasets demonstrate that OmniPose, with an improved HRNet backbone and waterfall module, is a robust and efficient architecture for multi-person pose estimation that achieves state-of-the-art results.      
### 36.Discriminative Singular Spectrum Classifier with Applications on Bioacoustic Signal Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.10166.pdf)
>  Automatic analysis of bioacoustic signals is a fundamental tool to evaluate the vitality of our planet. Frogs and bees, for instance, may act like biological sensors providing information about environmental changes. This task is fundamental for ecological monitoring still includes many challenges such as nonuniform signal length processing, degraded target signal due to environmental noise, and the scarcity of the labeled samples for training machine learning. To tackle these challenges, we present a bioacoustic signal classifier equipped with a discriminative mechanism to extract useful features for analysis and classification efficiently. The proposed classifier does not require a large amount of training data and handles nonuniform signal length natively. Unlike current bioacoustic recognition methods, which are task-oriented, the proposed model relies on transforming the input signals into vector subspaces generated by applying Singular Spectrum Analysis (SSA). Then, a subspace is designed to expose discriminative features. The proposed model shares end-to-end capabilities, which is desirable in modern machine learning systems. This formulation provides a segmentation-free and noise-tolerant approach to represent and classify bioacoustic signals and a highly compact signal descriptor inherited from SSA. The validity of the proposed method is verified using three challenging bioacoustic datasets containing anuran, bee, and mosquito species. Experimental results on three bioacoustic datasets have shown the competitive performance of the proposed method compared to commonly employed methods for bioacoustics signal classification in terms of accuracy.      
### 37.Data-Driven Wireless Communication Using Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.10134.pdf)
>  Data-driven paradigms are well-known and salient demands of future wireless communication. Empowered by big data and machine learning, next-generation data-driven communication systems will be intelligent with the characteristics of expressiveness, scalability, interpretability, and especially uncertainty modeling, which can confidently involve diversified latent demands and personalized services in the foreseeable future. In this paper, we review and present a promising family of nonparametric Bayesian machine learning methods, i.e., Gaussian processes (GPs), and their applications in wireless communication due to their interpretable learning ability with uncertainty. Specifically, we first envision three-level motivations of data-driven wireless communication using GPs. Then, we provide the background of the GP model in terms of covariance structure and model inference. The expressiveness of the GP model is introduced by using various interpretable kernel designs, namely, stationary, non-stationary, deep, and multi-task kernels. Furthermore, we review the distributed GP with promising scalability, which is suitable for applications in wireless networks with a large number of distributed edge devices. Finally, we provide representative solutions and promising techniques that adopting GPs in wireless communication systems.      
### 38.Danish Fungi 2020 -- Not Just Another Image Recognition Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2103.10107.pdf)
>  We introduce a novel fine-grained dataset and benchmark, the Danish Fungi 2020 (DF20). The dataset, constructed from observations submitted to the Danish Fungal Atlas, is unique in its taxonomy-accurate class labels, small number of errors, highly unbalanced long-tailed class distribution, rich observation metadata, and well-defined class hierarchy. DF20 has zero overlap with ImageNet, allowing unbiased comparison of models fine-tuned from publicly available ImageNet checkpoints. The proposed evaluation protocol enables testing the ability to improve classification using metadata -- e.g. precise geographic location, habitat, and substrate, facilitates classifier calibration testing, and finally allows to study the impact of the device settings on the classification performance. Experiments using Convolutional Neural Networks (CNN) and the recent Vision Transformers (ViT) show that DF20 presents a challenging task. Interestingly, ViT achieves results superior to CNN baselines with 81.25% accuracy, reducing the CNN error by 13%. A baseline procedure for including metadata into the decision process improves the classification accuracy by more than 3.5 percentage points, reducing the error rate by 20%. The source code for all methods and experiments is available at <a class="link-external link-https" href="https://sites.google.com/view/danish-fungi-dataset" rel="external noopener nofollow">this https URL</a>.      
### 39.Audio Description from Image by Modal Translation Network  [ :arrow_down: ](https://arxiv.org/pdf/2103.10018.pdf)
>  Audio is the main form for the visually impaired to obtain information. In reality, all kinds of visual data always exist, but audio data does not exist in many cases. In order to help the visually impaired people to better perceive the information around them, an image-to-audio-description (I2AD) task is proposed to generate audio descriptions from images in this paper. To complete this totally new task, a modal translation network (MT-Net) from visual to auditory sense is proposed. The proposed MT-Net includes three progressive sub-networks: 1) feature learning, 2) cross-modal mapping, and 3) audio generation. First, the feature learning sub-network aims to learn semantic features from image and audio, including image feature learning and audio feature learning. Second, the cross-modal mapping sub-network transforms the image feature into a cross-modal representation with the same semantic concept as the audio feature. In this way, the correlation of inter-modal data is effectively mined for easing the heterogeneous gap between image and audio. Finally, the audio generation sub-network is designed to generate the audio waveform from the cross-modal representation. The generated audio waveform is interpolated to obtain the corresponding audio file according to the sample frequency. Being the first attempt to explore the I2AD task, three large-scale datasets with plenty of manual audio descriptions are built. Experiments on the datasets verify the feasibility of generating intelligible audio from an image directly and the effectiveness of proposed method.      
### 40.A Soft-Aided Staircase Decoder Using Three-Level Channel Reliabilities  [ :arrow_down: ](https://arxiv.org/pdf/2103.09991.pdf)
>  The soft-aided bit-marking (SABM) algorithm is based on the idea of marking bits as highly reliable bits (HRBs), highly unreliable bits (HUBs), and uncertain bits to improve the performance of hard-decision (HD) decoders. The HRBs and HUBs are used to assist the HD decoders to prevent miscorrections and to decode those originally uncorrectable cases via bit flipping (BF), respectively. In this paper, an improved SABM algorithm (called iSABM) is proposed for staircase codes (SCCs). Similar to the SABM, iSABM marks bits with the help of channel reliabilities, i.e., using the absolute values of the log-likelihood ratios. The improvements offered by iSABM include: (i) HUBs being classified using a reliability threshold, (ii) BF randomly selecting HUBs, and (iii) soft-aided decoding over multiple SCC blocks. The decoding complexity of iSABM is comparable of that of SABM. This is due to the fact that on the one hand no sorting is required (lower complexity) because of the use of a threshold for HUBs, while on the other hand multiple SCC blocks use soft information (higher complexity). Additional gains of up to 0.53 dB with respect to SABM and 0.91 dB with respect to standard SCC decoding at a bit error rate of $10^{-6}$ are reported. Furthermore, it is shown that using 1-bit reliability marking, i.e., only having HRBs and HUBs, only causes a gain penalty of up to 0.25 dB with a significantly reduced memory requirement.      
### 41.Advancing RNN Transducer Technology for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.09935.pdf)
>  We investigate a set of techniques for RNN Transducers (RNN-Ts) that were instrumental in lowering the word error rate on three different tasks (Switchboard 300 hours, conversational Spanish 780 hours and conversational Italian 900 hours). The techniques pertain to architectural changes, speaker adaptation, language model fusion, model combination and general training recipe. First, we introduce a novel multiplicative integration of the encoder and prediction network vectors in the joint network (as opposed to additive). Second, we discuss the applicability of i-vector speaker adaptation to RNN-Ts in conjunction with data perturbation. Third, we explore the effectiveness of the recently proposed density ratio language model fusion for these tasks. Last but not least, we describe the other components of our training recipe and their effect on recognition performance. We report a 5.9% and 12.5% word error rate on the Switchboard and CallHome test sets of the NIST Hub5 2000 evaluation and a 12.7% WER on the Mozilla CommonVoice Italian test set.      
### 42.Reviewing two decades of Energy system analysis with bibliometrics  [ :arrow_down: ](https://arxiv.org/pdf/2103.09917.pdf)
>  The field of Energy System Analysis (ESA) has experienced exponential growth in the number of publications since at least the year 2000. This paper presents a comprehensive bibliometric analysis on ESA by employing different algorithms in Matlab and R. The focus of results is on quantitative indicators relating to number and type of publication outputs, collaboration links between institutions, authors and countries, and dynamic trends within the field. The five and twelve most productive countries have 50% and 80% of ESA publications respectively. The dominant institutions are even more concentrated within a small number of countries. A significant concentration of published papers within countries and institutions was also confirmed by analysing collaboration networks. These show dominant collaboration within the same university or at least the same country. There is also is a strong link among the most successful journals, authors and institutions. The Energy journal has had the most publications in the field, and its editor-in-chief Lund H is the author with most of the publications in the field, as well as the author with most of the highly cited publications in the field. In terms of the dynamics within the field in the past decade, recent years have seen a higher impact of topics related to flexibility and hybrid/integrated energy systems alongside a decline in individual technologies. This paper provides a holistic overview of two decades' research output and enables interested readers to obtain a comprehensive overview of the key trends in this active field.      
### 43.Fused Deep Features Based Classification Framework for COVID-19 Classification with Optimized MLP  [ :arrow_down: ](https://arxiv.org/pdf/2103.09904.pdf)
>  The new type of Coronavirus disease called COVID-19 continues to spread quite rapidly. Although it shows some specific symptoms, this disease, which can show different symptoms in almost every individual, has caused hundreds of thousands of patients to die. Although healthcare professionals work hard to prevent further loss of life, the rate of disease spread is very high. For this reason, the help of computer aided diagnosis (CAD) and artificial intelligence (AI) algorithms is vital. In this study, a method based on optimization of convolutional neural network (CNN) architecture, which is the most effective image analysis method of today, is proposed to fulfill the mentioned COVID-19 detection needs. First, COVID-19 images are trained using ResNet-50 and VGG-16 architectures. Then, features in the last layer of these two architectures are combined with feature fusion. These new image features matrices obtained with feature fusion are classified for COVID detection. A multi-layer perceptron (MLP) structure optimized by the whale optimization algorithm is used for the classification process. The obtained results show that the performance of the proposed framework is almost 4.5% higher than VGG-16 performance and almost 3.5% higher than ResNet-50 performance.      
### 44.Intelligent Reflecting Surface Enabled Random Rotations Scheme for the MISO Broadcast Channel  [ :arrow_down: ](https://arxiv.org/pdf/2103.09898.pdf)
>  The current literature on intelligent reflecting surface (IRS) focuses on optimizing the IRS phase shifts to yield coherent beamforming gains, under the assumption of perfect channel state information (CSI) of individual IRS-assisted links, which is highly impractical. This work, instead, considers the random rotations scheme at the IRS in which the reflecting elements only employ random phase rotations without requiring any CSI. The only CSI then needed is at the base station (BS) of the overall channel to implement the beamforming transmission scheme. Under this framework, we derive the sum-rate scaling laws in the large number of users regime for the IRS-assisted multiple-input single-output (MISO) broadcast channel, with optimal dirty paper coding (DPC) scheme and the lower-complexity random beamforming (RBF) and deterministic beamforming (DBF) schemes at the BS. The random rotations scheme increases the sum-rate by exploiting multi-user diversity, but also compromises the gain to some extent due to correlation. Finally, energy efficiency maximization problems in terms of the number of BS antennas, IRS elements and transmit power are solved using the derived scaling laws. Simulation results show the proposed scheme to improve the sum-rate, with performance becoming close to that under coherent beamforming for a large number of users.      
### 45.Self-Supervised Learning of Audio Representations from Permutations with Differentiable Ranking  [ :arrow_down: ](https://arxiv.org/pdf/2103.09879.pdf)
>  Self-supervised pre-training using so-called "pretext" tasks has recently shown impressive performance across a wide range of modalities. In this work, we advance self-supervised learning from permutations, by pre-training a model to reorder shuffled parts of the spectrogram of an audio signal, to improve downstream classification performance. We make two main contributions. First, we overcome the main challenges of integrating permutation inversions into an end-to-end training scheme, using recent advances in differentiable ranking. This was heretofore sidestepped by casting the reordering task as classification, fundamentally reducing the space of permutations that can be exploited. Our experiments validate that learning from all possible permutations improves the quality of the pre-trained representations over using a limited, fixed set. Second, we show that inverting permutations is a meaningful pretext task for learning audio representations in an unsupervised fashion. In particular, we improve instrument classification and pitch estimation of musical notes by reordering spectrogram patches in the time-frequency space.      
### 46.Decentralized Fictitious Play in Near-Potential Games with Time-Varying Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.09845.pdf)
>  We study the convergence properties of decentralized fictitious play (DFP) for the class of near-potential games where the incentives of agents are nearly aligned with a potential function. In DFP, agents share information only with their current neighbors in a sequence of time-varying networks, keep estimates of other agents' empirical frequencies, and take actions to maximize their expected utility functions computed with respect to the estimated empirical frequencies. We show that empirical frequencies of actions converge to a set of strategies with potential function values that are larger than the potential function values obtained by approximate Nash equilibria of the closest potential game. This result establishes that DFP has identical convergence guarantees in near-potential games as the standard fictitious play in which agents observe the past actions of all the other agents.      

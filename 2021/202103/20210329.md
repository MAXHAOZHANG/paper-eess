# ArXiv eess --Mon, 29 Mar 2021
### 1.Finite Element Reconstruction Of Stiffness Images In MR Elastography Using Statistical Physical Forward Modeling And Proximal Optimization Methods  [ :arrow_down: ](https://arxiv.org/pdf/2103.14632.pdf)
>  Quantitative characterization of tissue properties, known as elasticity imaging, can be cast as solving an ill-posed inverse problem. The finite element methods (FEMs) in magnetic resonance elastography (MRE) imaging are based on solving a constrained optimization problem consisting of a physical forward model and a regularizer as the data-fidelity term and the prior term, respectively. In existing formulation for the elasticity forward model, physical laws that arise from equilibrium equation of harmonic motion, indicate a deterministic relationship between MRE-measured data and unknown elasticity distribution which leads to the poor and unstable elasticity distribution estimation in the presence of noise. Toward this end, we propose an efficient statistical methodology for physical forward model refinement by formulating it as linear algebraic representation with respect to the unknown elasticity distribution and incorporating an analytical noise model. To solve the subsequent total variation regularized optimization task, we benefit from a fixed-point scheme involving proximal gradient methods. Simulation results of elasticity reconstruction in various SNR conditions verify the effectiveness of the proposed approach.      
### 2.LPV Modeling of Nonlinear Systems: A Multi-Path Feedback Linearization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.14622.pdf)
>  This paper introduces a systematic approach to synthesize linear parameter-varying (LPV) representations of nonlinear (NL) systems which are described by input affine state-space (SS) representations. The conversion approach results in LPV-SS representations in the observable canonical form. Based on the relative degree concept, first the SS description of a given NL representation is transformed to a normal form. In the SISO case, all nonlinearities of the original system are embedded into one NL function, which is factorized, based on a proposed algorithm, to construct an LPV representation of the original NL system. The overall procedure yields an LPV model in which the scheduling variable depends on the inputs and outputs of the system and their derivatives, achieving a practically applicable transformation of the model in case of low order derivatives. In addition, if the states of the NL model can be measured or estimated, then a modified procedure is proposed to provide LPV models scheduled by these states. Examples are included to demonstrate both approaches.      
### 3.Training a Better Loss Function for Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2103.14616.pdf)
>  Central to the application of neural networks in image restoration problems, such as single image super resolution, is the choice of a loss function that encourages natural and perceptually pleasing results. A popular choice for a loss function is a pre-trained network, such as VGG and LPIPS, which is used as a feature extractor for computing the difference between restored and reference images. However, such an approach has multiple drawbacks: it is computationally expensive, requires regularization and hyper-parameter tuning, and involves a large network trained on an unrelated task. In this work, we explore the question of what makes a good loss function for an image restoration task. First, we observe that a single natural image is sufficient to train a lightweight feature extractor that outperforms state-of-the-art loss functions in single image super resolution, denoising, and JPEG artefact removal. We propose a novel Multi-Scale Discriminative Feature (MDF) loss comprising a series of discriminators, trained to penalize errors introduced by a generator. Second, we show that an effective loss function does not have to be a good predictor of perceived image quality, but instead needs to be specialized in identifying the distortions for a given restoration method.      
### 4.A Convex Programming Approach to Data-Driven Risk-Averse Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.14606.pdf)
>  This paper presents a model-free reinforcement learning (RL) algorithm to solve the risk-averse optimal control (RAOC) problem for discrete-time nonlinear systems. While successful RL algorithms have been presented to learn optimal control solutions under epistemic uncertainties (i.e., lack of knowledge of system dynamics), they do so by optimizing the expected utility of outcomes, which ignores the variance of cost under aleatory uncertainties (i.e., randomness). Performance-critical systems, however, must not only optimize the expected performance, but also reduce its variance to avoid performance fluctuation during RL's course of operation. To solve the RAOC problem, this paper presents the following three variants of RL algorithms and analyze their advantages and preferences for different situations/systems: 1) a one-shot static convex program -based RL, 2) an iterative value iteration (VI) algorithm that solves a linear programming (LP) optimization at each iteration, and 3) an iterative policy iteration (PI) algorithm that solves a convex optimization at each iteration and guarantees the stability of the consecutive control policies. Convergence of the exact optimization problems, which are infinite-dimensional in all three cases, to the optimal risk-averse value function is shown. To turn these optimization problems into standard optimization problems with finite decision variables and constraints, function approximation for value estimations as well as constraint sampling are leveraged. Data-driven implementations of these algorithms are provided based on Q-function which enables learning the optimal value without any knowledge of the system dynamics. The performance of the approximated solutions is also verified through a weighted sup-norm bound and the Lyapunov bound. A simulation example is provided to verify the effectiveness of the presented approach.      
### 5.Data Quality as Predictor of Voice Anti-Spoofing Generalization  [ :arrow_down: ](https://arxiv.org/pdf/2103.14602.pdf)
>  Voice anti-spoofing aims at classifying a given speech input either as a bonafide human sample, or a spoofing attack (e.g. synthetic or replayed sample). Numerous voice anti-spoofing methods have been proposed but most of them fail to generalize across domains (corpora) -- and we do not know \emph{why}. We outline a novel interpretative framework for gauging the impact of data quality upon anti-spoofing performance. Our within- and between-domain experiments pool data from seven public corpora and three anti-spoofing methods based on Gaussian mixture and convolutive neural network models. We assess the impacts of long-term spectral information, speaker population (through x-vector speaker embeddings), signal-to-noise ratio, and selected voice quality features.      
### 6.Real-time implementation of MPC for tracking in embedded systems: Application to a two-wheeled inverted pendulum  [ :arrow_down: ](https://arxiv.org/pdf/2103.14571.pdf)
>  This article presents the real-time implementation of the model predictive control for tracking formulation to control a two-wheeled inverted pendulum robot. This formulation offers several advantages over standard MPC formulations at the expense of the addition of a small number of decision variables, which complicates the inner structure of the matrices of the optimization problem. We implement a sparse solver, based on an extension of the alternating direction method of multipliers, in the system's embedded hardware. The results indicate that the solver is suitable for controlling a real system with sample times in the range of milliseconds using current, readily-available hardware.      
### 7.Classification of Pneumonia and Tuberculosis from Chest X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2103.14562.pdf)
>  Artificial intelligence (AI) and specifically machine learning is making inroads into number of fields. Machine learning is replacing and/or complementing humans in a certain type of domain to make systems perform tasks more efficiently and independently. Healthcare is a worthy domain to merge with AI and Machine learning to get things to work smoother and efficiently. The X-ray based detection and classification of diseases related to chest is much needed in this modern era due to the low number of quality radiologists. This thesis focuses on the classification of Pneumonia and Tuberculosis two major chest diseases from the chest X-rays. This system provides an opinion to the user whether one is having a disease or not, thereby helping doctors and medical staff to make a quick and informed decision about the presence of disease. As compared to previous work our model can detect two types of abnormality. Our model can detect whether X-ray is normal or having abnormality which can be pneumonia and tuberculosis 92.97% accurately.      
### 8.A cloud-IoT platform for passive radio sensing: challenges and application case studies  [ :arrow_down: ](https://arxiv.org/pdf/2103.14554.pdf)
>  We propose a platform for the integration of passive radio sensing and vision technologies into a cloud-IoT framework that performs real-time channel quality information (CQI) time series processing and analytics. Radio sensing and vision technologies allow to passively detect and track objects or persons by using radio waves as probe signals that encode a 2D/3D view of the environment they propagate through. View reconstruction from the received radio signals, or CQI, is based on real-time data processing tools, that combine multiple radio measurements from possibly heterogeneous IoT networks. The proposed platform is designed to efficiently store and analyze CQI time series of different types and provides formal semantics for CQI data manipulation (ontology models). Post-processed data can be then accessible to third parties via JSON-REST calls. Finally, the proposed system supports the reconfiguration of CQI data collection based on the respective application. The performance of the proposed tools are evaluated through two experimental case studies that focus on assisted living applications in a smart-space environment and on driver behavior recognition for in-car control services. Both studies adopt and compare different CQI manipulation models and radio devices as supported by current and future (5G) standards.      
### 9.A Multisensory Edge-Cloud Platform for Opportunistic Radio Sensing in Cobot Environments  [ :arrow_down: ](https://arxiv.org/pdf/2103.14546.pdf)
>  Worker monitoring and protection in collaborative robot (cobots) industrial environments requires advanced sensing capabilities and flexible solutions to monitor the movements of the operator in close proximity of moving robots. Collaborative robotics is an active research area where Internet of Things (IoT) and novel sensing technologies are expected to play a critical role. Considering that no single technology can currently solve the problem of continuous worker monitoring, the paper targets the development of an IoT multisensor data fusion (MDF) platform. It is based on an edge-cloud architecture that supports the combination and transformation of multiple sensing technologies to enable the passive and anonymous detection of workers. Multidimensional data acquisition from different IoT sources, signal pre-processing, feature extraction, data distribution and fusion, along with machine learning (ML) and computing methods are described. The proposed IoT platform also comprises a practical solution for data fusion and analytics. It is able to perform opportunistic and real-time perception of workers by fusing and analyzing radio signals obtained from several interconnected IoT components, namely a multi-antenna WiFi installation (2.4-5 GHz), a sub-THz imaging camera (100 GHz), a network of radars (122 GHz) and infrared sensors (8-13 {\mu}m). The performance of the proposed IoT platform is validated through real use case scenarios inside a pilot industrial plant in which protective human--robot distance must be guaranteed considering latency and detection uncertainties.      
### 10.Individual Altruism Cannot Overcome Congestion Effects in a Global Pandemic Game  [ :arrow_down: ](https://arxiv.org/pdf/2103.14538.pdf)
>  A key challenge in responding to public health crises such as COVID-19 is the difficulty of predicting the results of feedback interconnections between the disease and society. As a step towards understanding these interconnections, we pose a simple game-theoretic model of a global pandemic in which individuals can choose where to live, and we investigate the global behavior that may emerge as a result of individuals reacting locally to the competing costs of isolation and infection. We study the game-theoretic equilibria that emerge from this setup when the population is composed of either selfish or altruistic individuals. First, we demonstrate that as is typical in these types of games, selfish equilibria are in general not optimal, but that all stable selfish equilibria are within a constant factor of optimal. Second, there exist infinitely-many stable altruistic equilibria; all but finitely-many of these are worse than the worst selfish equilibrium, and the social cost of altruistic equilibria is unbounded. Our work is in sharp contrast to recent work in network congestion games in which all altruistic equilibria are socially optimal. This suggests that a population without central coordination may react very poorly to a pandemic, and that individual altruism could even exacerbate the problem.      
### 11.Detection, growth quantification and malignancy prediction of pulmonary nodules using deep convolutional networks in follow-up CT scans  [ :arrow_down: ](https://arxiv.org/pdf/2103.14537.pdf)
>  We address the problem of supporting radiologists in the longitudinal management of lung cancer. Therefore, we proposed a deep learning pipeline, composed of four stages that completely automatized from the detection of nodules to the classification of cancer, through the detection of growth in the nodules. In addition, the pipeline integrated a novel approach for nodule growth detection, which relied on a recent hierarchical probabilistic U-Net adapted to report uncertainty estimates. Also, a second novel method was introduced for lung cancer nodule classification, integrating into a two stream 3D-CNN network the estimated nodule malignancy probabilities derived from a pretrained nodule malignancy network. The pipeline was evaluated in a longitudinal cohort and reported comparable performances to the state of art.      
### 12.Agent with Warm Start and Adaptive Dynamic Termination for Plane Localization in 3D Ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2103.14502.pdf)
>  Accurate standard plane (SP) localization is the fundamental step for prenatal ultrasound (US) diagnosis. Typically, dozens of US SPs are collected to determine the clinical diagnosis. 2D US has to perform scanning for each SP, which is time-consuming and operator-dependent. While 3D US containing multiple SPs in one shot has the inherent advantages of less user-dependency and more efficiency. Automatically locating SP in 3D US is very challenging due to the huge search space and large fetal posture variations. Our previous study proposed a deep reinforcement learning (RL) framework with an alignment module and active termination to localize SPs in 3D US automatically. However, termination of agent search in RL is important and affects the practical deployment. In this study, we enhance our previous RL framework with a newly designed adaptive dynamic termination to enable an early stop for the agent searching, saving at most 67% inference time, thus boosting the accuracy and efficiency of the RL framework at the same time. Besides, we validate the effectiveness and generalizability of our algorithm extensively on our in-house multi-organ datasets containing 433 fetal brain volumes, 519 fetal abdomen volumes, and 683 uterus volumes. Our approach achieves localization error of 2.52mm/10.26 degrees, 2.48mm/10.39 degrees, 2.02mm/10.48 degrees, 2.00mm/14.57 degrees, 2.61mm/9.71 degrees, 3.09mm/9.58 degrees, 1.49mm/7.54 degrees for the transcerebellar, transventricular, transthalamic planes in fetal brain, abdominal plane in fetal abdomen, and mid-sagittal, transverse and coronal planes in uterus, respectively. Experimental results show that our method is general and has the potential to improve the efficiency and standardization of US scanning.      
### 13.A Robust CNN Framework with Dual Feedback Feature Accumulation for Detecting Pneumonia Opacity from Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.14461.pdf)
>  Pneumonia is one of the most acute respiratory diseases having remarkably high prevalence and mortality rate. Chest X-ray (CXR) has been widely utilized for the diagnosis of this disease owing to its availability, diagnostic speed and accuracy. However, even for an expert radiologist, it is quite challenging to readily determine pneumonia opacity by examining CXRs. Therefore, this study has been structured to automate the pneumonia detection process by introducing a robust deep learning framework. The proposed network comprises of Process Convolution (Pro_Conv) blocks for feature accumulation inside Dual Feedback (DF) blocks to propagate the feature maps towards a viable detection. Experimental analysis showcase: (1) the proposed network proficiently distinguishes between normal and pneumonia opacity containing CXRs with the mean accuracy, sensitivity and specificity of 97.78%, 98.84% and 95.04%, respectively; (2) the network is constructed with significantly low parameters than the traditional ImageNets to reduce memory consumption for deployment in memory constrained mobile platforms; (3) the trade-off between accuracy and number of parameters of the model outperforms the considered classical networks by a remarkable margin; and (4) the false-negatives are lower than the false-positives (both of which are low in count) which prove the model's low-fatality prediction. Hence, the proposed network can be deployed for a rapid screening of pneumonia and can act as a great assistive tool for the radiologists in the diagnosis process.      
### 14.A novel S-shape based NURBS interpolation with acc-jerk- Continuity and round-off error elimination  [ :arrow_down: ](https://arxiv.org/pdf/2103.14433.pdf)
>  Feedrate scheduling is a key step in computer numerical control (CNC) machining, as it has a close relationship with machining time and surface quality, and has now become a hot issue in industry and academia. To reduce high chord errors and round-off errors, and generate continuous velocity, acceleration, and jerk profile of parametric interpolation, a novel and complete S-shape based feedrate scheduling algorithm is presented in this paper. The algorithm consists of three modules: bidirectional scanning module, velocity scheduling module and round-off error elimination module. The bidirectional scanning module with the limitations of chord error, normal acceleration/jerk and command feedrate aims to guarantee the continuity of the feed rate at the junctions between successive NURBS sub-curves. After the NURBS sub-curves have been classified into two cases, the velocity scheduling module firstly calculates the actual maximum federate, and then generates the feed rate profiles of all NURBS sub-curves according to our velocity scheduling function. Later, the round-off error elimination module is proposed to make the total interpolating time become an integer multiple of the interpolation period, which leads to the elimination of round-off errors. Finally, benchmarks are conducted to verify the applicability of the proposed method compared with some other methods.      
### 15.Guaranteed $\mathcal{H}_\infty$ performance analysis and controller synthesis for interconnected linear systems from noisy input-state data  [ :arrow_down: ](https://arxiv.org/pdf/2103.14399.pdf)
>  The increase in available data and complexity of dynamical systems has sparked the research on data-based system performance analysis and controller design. Recent approaches can guarantee performance and robust controller synthesis based on noisy input-state data of a single dynamical system. In this paper, we extend a recent data-based approach for guaranteed performance analysis to distributed analysis of interconnected linear systems. We present a new set of sufficient LMI conditions based on noisy input-state data that guarantees $\mathcal{H}_\infty$ performance and have a structure that lends itself well to distributed controller synthesis from data. Sufficient LMI conditions based on noisy data are provided for the existence of a dynamic distributed controller that achieves $\mathcal{H}_\infty$ performance. The presented approach enables scalable analysis and control of large-scale interconnected systems from noisy input-state data sets.      
### 16.Improved stability conditions for systems under aperiodic sampling: model- and data-based analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.14353.pdf)
>  Discrete-time systems under aperiodic sampling may serve as a modeling abstraction for a multitude of problems arising in cyber-physical and networked control systems. Recently, model- and data-based stability conditions for such systems were obtained by rewriting them as an interconnection of a linear time-invariant system and a delay operator, and subsequently, performing a robust stability analysis using a known bound on the gain of this operator. In this paper, we refine this approach: First, we show that the delay operator is input-feedforward passive and second, we compute its gain exactly. Based on these findings, we derive improved stability conditions both in case of full model knowledge and in case only data are available. In the latter, we require only a finite-length and potentially noisy state-input trajectory of the unknown system. In two examples, we illustrate the reduced conservativeness of the proposed stability conditions over existing ones.      
### 17.Deep Koopman-operator based model predictive control for closed-loop electrical neurostimulation in epilepsy  [ :arrow_down: ](https://arxiv.org/pdf/2103.14321.pdf)
>  Electrical neuromodulation as a palliative treatment has been increasingly applied to epilepsy. However, most of the current neuromodulation implement pre-determined actuation strategies rather than closed-loop neurofeedback. In this paper, rooted in optimal control theory, we propose a novel framework for real-time closed-loop electrical neuromodulation in epilepsy. Our framework combines a deep Koopman-operator based model for seizure prediction in an approximated finite dimensional linear dynamics and the model predictive control (MPC) for designing optimal seizure suppression strategies. We validate our model with synthetic seizure data from Jansen-Rit Model which generates neural dynamics in a single cortical column and two distant cortical columns. The results demonstrate that the deep Koopman-operator based model has great capabilities to map the nonlinear neural dynamics into finite dimensional linear dynamics, which is suitable for real-time seizure prediction and naturally compatible with the optimal-based linear MPC design for seizure suppression. Our framework opens a new window for the development and implementation of robust real-time closed-loop electrical neuromodulation in epileptic seizure suppression and sheds light on understanding the neurodynamics and feedback control policies.      
### 18.Evaluation of Preprocessing Techniques for U-Net Based Automated Liver Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.14301.pdf)
>  To extract liver from medical images is a challenging task due to similar intensity values of liver with adjacent organs, various contrast levels, various noise associated with medical images and irregular shape of liver. To address these issues, it is important to preprocess the medical images, i.e., computerized tomography (CT) and magnetic resonance imaging (MRI) data prior to liver analysis and quantification. This paper investigates the impact of permutation of various preprocessing techniques for CT images, on the automated liver segmentation using deep learning, i.e., U-Net architecture. The study focuses on Hounsfield Unit (HU) windowing, contrast limited adaptive histogram equalization (CLAHE), z-score normalization, median filtering and Block-Matching and 3D (BM3D) filtering. The segmented results show that combination of three techniques; HU-windowing, median filtering and z-score normalization achieve optimal performance with Dice coefficient of 96.93%, 90.77% and 90.84% for training, validation and testing respectively.      
### 19.CNN-based Discriminative Training for Domain Compensation in Acoustic Event Detection with Frame-wise Classifier  [ :arrow_down: ](https://arxiv.org/pdf/2103.14297.pdf)
>  Domain mismatch is a noteworthy issue in acoustic event detection tasks, as the target domain data is difficult to access in most real applications. In this study, we propose a novel CNN-based discriminative training framework as a domain compensation method to handle this issue. It uses a parallel CNN-based discriminator to learn a pair of high-level intermediate acoustic representations. Together with a binary discriminative loss, the discriminators are forced to maximally exploit the discrimination of heterogeneous acoustic information in each audio clip with target events, which results in a robust paired representations that can well discriminate the target events and background/domain variations separately. Moreover, to better learn the transient characteristics of target events, a frame-wise classifier is designed to perform the final classification. In addition, a two-stage training with the CNN-based discriminator initialization is further proposed to enhance the system training. All experiments are performed on the DCASE 2018 Task3 datasets. Results show that our proposal significantly outperforms the official baseline on cross-domain conditions in AUC by relative $1.8-12.1$% without any performance degradation on in-domain evaluation conditions.      
### 20.Boundary Control of Traffic Congestion Modeled as a Non-stationary Stochastic Process  [ :arrow_down: ](https://arxiv.org/pdf/2103.14278.pdf)
>  In this paper, we introduce a new conservation-based approach to model traffic dynamics, and apply the model predictive control (MPC) approach to control the boundary traffic inflow and outflow, so that the traffic congestion is reduced. We establish an interface between the Simulation of Urban Mobility (SUMO) software and MATLAB to define a network of interconnected roads (NOIR) as a directed graph, and present traffic congestion management as a network control problem. By formally specifying the traffic feasibility conditions, and using the linear temporal logic, we present the proposed MPC-based boundary control problem as a quadratic programming with linear equality and inequality constraints. The success of the proposed traffic boundary control is demonstrated by simulation of traffic congestion control in Center City Philadelphia.      
### 21.Provably Correct Controller Synthesis of Switched Stochastic Systems with Metric Temporal Logic Specifications: A Case Study on Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.14264.pdf)
>  In this paper, we present a provably correct controller synthesis approach for switched stochastic control systems with metric temporal logic (MTL) specifications with provable probabilistic guarantees. We first present the stochastic control bisimulation function for switched stochastic control systems, which bounds the trajectory divergence between the switched stochastic control system and its nominal deterministic control system in a probabilistic fashion. We then develop a method to compute optimal control inputs by solving an optimization problem for the nominal trajectory of the deterministic control system with robustness against initial state variations and stochastic uncertainties. We implement our robust stochastic controller synthesis approach on both a four-bus power system and a nine-bus power system under generation loss disturbances, with MTL specifications expressing requirements for the grid frequency deviations, wind turbine generator rotor speed variations and the power flow constraints at different power lines.      
### 22.Robust Pandemic Control Synthesis with Formal Specifications: A Case Study on COVID-19 Pandemic  [ :arrow_down: ](https://arxiv.org/pdf/2103.14262.pdf)
>  Pandemics can bring a range of devastating consequences to public health and the world economy. Identifying the most effective control strategies has been the imperative task all around the world. Various public health control strategies have been proposed and tested against pandemic diseases (e.g., COVID-19). We study two specific pandemic control models: the susceptible, exposed, infectious, recovered (SEIR) model with vaccination control; and the SEIR model with shield immunity control. We express the pandemic control requirement in metric temporal logic (MTL) formulas. We then develop an iterative approach for synthesizing the optimal control strategies with MTL specifications. We provide simulation results in two different scenarios for robust control of the COVID-19 pandemic: one for vaccination control, and another for shield immunity control, with the model parameters estimated from data in Lombardy, Italy. The results show that the proposed synthesis approach can generate control inputs such that the time-varying numbers of individuals in each category (e.g., infectious, immune) satisfy the MTL specifications with robustness against initial state and parameter uncertainties.      
### 23.Mixing-AdaSIN: Constructing a de-biased dataset using Adaptive Structural Instance Normalization and texture Mixing  [ :arrow_down: ](https://arxiv.org/pdf/2103.14255.pdf)
>  Following the pandemic outbreak, several works have proposed to diagnose COVID-19 with deep learning in computed tomography (CT); reporting performance on-par with experts. However, models trained/tested on the same in-distribution data may rely on the inherent data biases for successful prediction, failing to generalize on out-of-distribution samples or CT with different scanning protocols. Early attempts have partly addressed bias-mitigation and generalization through augmentation or re-sampling, but are still limited by collection costs and the difficulty of quantifying bias in medical images. In this work, we propose Mixing-AdaSIN; a bias mitigation method that uses a generative model to generate de-biased images by mixing texture information between different labeled CT scans with semantically similar features. Here, we use Adaptive Structural Instance Normalization (AdaSIN) to enhance de-biasing generation quality and guarantee structural consistency. Following, a classifier trained with the generated images learns to correctly predict the label without bias and generalizes better. To demonstrate the efficacy of our method, we construct a biased COVID-19 vs. bacterial pneumonia dataset based on CT protocols and compare with existing state-of-the-art de-biasing methods. Our experiments show that classifiers trained with de-biased generated images report improved in-distribution performance and generalization on an external COVID-19 dataset.      
### 24.Supervised Chorus Detection for Popular Music Using Convolutional Neural Network and Multi-task Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.14253.pdf)
>  This paper presents a novel supervised approach to detecting the chorus segments in popular music. Traditional approaches to this task are mostly unsupervised, with pipelines designed to target some quality that is assumed to define "chorusness," which usually means seeking the loudest or most frequently repeated sections. We propose to use a convolutional neural network with a multi-task learning objective, which simultaneously fits two temporal activation curves: one indicating "chorusness" as a function of time, and the other the location of the boundaries. We also propose a post-processing method that jointly takes into account the chorus and boundary predictions to produce binary output. In experiments using three datasets, we compare our system to a set of public implementations of other segmentation and chorus-detection algorithms, and find our approach performs significantly better.      
### 25.Embedding Power Flow into Machine Learning for Parameter and State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2103.14251.pdf)
>  Modern state and parameter estimations in power systems consist of two stages: the outer problem of minimizing the mismatch between network observation and prediction over the network parameters, and the inner problem of predicting the system state for given values of the parameters. The standard solution of the combined problem is iterative: (a) set the parameters, e.g. to priors on the power line characteristics, (b) map input observation to prediction of the output, (c) compute the mismatch between predicted and observed output, (d) make a gradient descent step in the space of parameters to minimize the mismatch, and loop back to (a). We show how modern Machine Learning (ML), and specifically training guided by automatic differentiation, allows to resolve the iterative loop more efficiently. Moreover, we extend the scheme to the case of incomplete observations, where Phasor Measurement Units (reporting real and reactive powers, voltage and phase) are available only at the generators (PV buses), while loads (PQ buses) report (via SCADA controls) only active and reactive powers. Considering it from the implementation perspective, our methodology of resolving the parameter and state estimation problem can be viewed as embedding of the Power Flow (PF) solver into the training loop of the Machine Learning framework (PyTorch, in this study). We argue that this embedding can help to resolve high-level optimization problems in power system operations and planning.      
### 26.Thermal Fault Detection and Localization Framework for Large Format Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2103.14229.pdf)
>  Safety against thermal failures is crucial in battery systems. Real-time thermal diagnostics can be a key enabler of such safer batteries. Thermal fault diagnostics in large format pouch or prismatic cells pose additional challenges compared to cylindrical cells. These challenges arise from the fact that the temperature distribution in large format cells is at least two-dimensional in nature (along length and breadth) while such distribution can be reasonably approximated in one dimension (along radial direction) in cylindrical cells. This difference makes the placement of temperature sensor(s) non-trivial and the design of detection algorithm challenging. In this work, we address these issues by proposing a framework that (i) optimizes the sensor locations to improve detectability and isolability of thermal faults, and (ii) designs a filtering scheme for fault detection and localization based on a two-dimensional thermal model. The proposed framework is illustrated by experimental and simulation studies on a commercial battery cell.      
### 27.A Hybrid Queuing Model for Coordinated Vehicle Platooning on Mixed-Autonomy Highways: Training and Validation  [ :arrow_down: ](https://arxiv.org/pdf/2103.14202.pdf)
>  Platooning of connected and autonomous vehicles (CAVs) is an emerging technology with a strong potential for throughput improvement and fuel reduction. Adequate macroscopic models are critical for system-level efficiency and reliability of platooning. In this paper, we consider a hybrid queuing model for a mixed-autonomy highway section and develop an easy-to-use training algorithm. The model predicts CAV and non-CAV counts according to the traffic demand as well as key parameters of the highway section. The training algorithm learns the highway parameters from observed data in real time. We test the model and the algorithm in Simulation of Urban Mobility (SUMO) and show that the prediction error is around 15% in a stationary setting and around 25% in a non-stationary setting. We also show that the trained model leads to a platoon headway regulation policy very close to the simulated optimum. The proposed model and algorithm can directly support model-predictive decision-making for platooning in mixed autonomy.      
### 28.Control Synthesis using Signal Temporal Logic Specifications with Integral and Derivative Predicates  [ :arrow_down: ](https://arxiv.org/pdf/2103.14193.pdf)
>  In many applications, the integrals and derivatives of signals carry valuable information (e.g., cumulative success over a time window, the rate of change) regarding the behavior of the underlying system. In this paper, we extend the expressiveness of Signal Temporal Logic (STL) by introducing predicates that can define rich properties related to the integral and derivative of a signal. For control synthesis, the new predicates are encoded into mixed-integer linear inequalities and are used in the formulation of a mixed-integer linear program to find a trajectory that satisfies an STL specification. We discuss the benefits of using the new predicates and illustrate them in a case study showing the influence of the new predicates on the trajectories of an autonomous robot.      
### 29.Barrier Function-based Safe Reinforcement Learning for Emergency Control of Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.14186.pdf)
>  Under voltage load shedding has been considered as a standard and effective measure to recover the voltage stability of the electric power grid under emergency and severe conditions. However, this scheme usually trips a massive amount of load which can be unnecessary and harmful to customers. Recently, deep reinforcement learning (RL) has been regarded and adopted as a promising approach that can significantly reduce the amount of load shedding. However, like most existing machine learning (ML)-based control techniques, RL control usually cannot guarantee the safety of the systems under control. In this paper, we introduce a novel safe RL method for emergency load shedding of power systems, that can enhance the safe voltage recovery of the electric power grid after experiencing faults. Unlike the standard RL method, the safe RL method has a reward function consisting of a Barrier function that goes to minus infinity when the system state goes to the safety bounds. Consequently, the optimal control policy can render the power system to avoid the safety bounds. This method is general and can be applied to other safety-critical control problems. Numerical simulations on the 39-bus IEEE benchmark is performed to demonstrate the effectiveness of the proposed safe RL emergency control, as well as its adaptive capability to faults not seen in the training.      
### 30.Capacitive imaging using fused amplitude and phase information for improved defect detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.14170.pdf)
>  This paper introduces an improved image processing method usable in capacitive imaging applications. Standard capacitive imaging tends to prefer amplitude-based images over the use of phase due to better signal-to-noise ratios. The new approach exploits the best features of both types of information by combining them to form clearer images, hence improving both defect detection and characterization in non-destructive evaluation. The methodology is demonstrated and optimized using a benchmark sample. Additional experiments on glass fibre composite sample illustrate the advantages of the technique.      
### 31.Distributed Experiment Design and Control for Multi-agent Systems with Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.14156.pdf)
>  This paper focuses on distributed learning-based control of decentralized multi-agent systems where the agents' dynamics are modeled by Gaussian Processes (GPs). Two fundamental problems are considered: the optimal design of experiment for concurrent learning of the agents' GP models, and the distributed coordination given the learned models. Using a Distributed Model Predictive Control (DMPC) approach, the two problems are formulated as distributed optimization problems, where each agent's sub-problem includes both local and shared objectives and constraints. To solve the resulting complex and non-convex DMPC problems efficiently, we develop an algorithm called Alternating Direction Method of Multipliers with Convexification (ADMM-C) that combines a distributed ADMM algorithm and a Sequential Convexification method. The computational efficiency of our proposed method comes from the facts that the computation for solving the DMPC problem is distributed to all agents and that efficient convex optimization solvers are used at the agents for solving the convexified sub-problems. We also prove that, under some technical assumptions, the ADMM-C algorithm converges to a stationary point of the penalized optimization problem. The effectiveness of our approach is demonstrated in numerical simulations of a multi-vehicle formation control example.      
### 32.Residual Energy-Based Models for End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.14152.pdf)
>  End-to-end models with auto-regressive decoders have shown impressive results for automatic speech recognition (ASR). These models formulate the sequence-level probability as a product of the conditional probabilities of all individual tokens given their histories. However, the performance of locally normalised models can be sub-optimal because of factors such as exposure bias. Consequently, the model distribution differs from the underlying data distribution. In this paper, the residual energy-based model (R-EBM) is proposed to complement the auto-regressive ASR model to close the gap between the two distributions. Meanwhile, R-EBMs can also be regarded as utterance-level confidence estimators, which may benefit many downstream tasks. Experiments on a 100hr LibriSpeech dataset show that R-EBMs can reduce the word error rates (WERs) by 8.2%/6.7% while improving areas under precision-recall curves of confidence scores by 12.6%/28.4% on test-clean/test-other sets. Furthermore, on a state-of-the-art model using self-supervised learning (wav2vec 2.0), R-EBMs still significantly improves both the WER and confidence estimation performance.      
### 33.Vehicle Following On A Ring Road Under Safety Constraints: Role of Connectivity and Coordination  [ :arrow_down: ](https://arxiv.org/pdf/2103.14142.pdf)
>  A fundamental problem in traffic networks is driving under safety and limited physical space constraints. In this paper, we design longitudinal vehicle controllers and study the dynamics of a system of homogeneous vehicles on a single-lane ring road in order to understand the interplay of limited space, speed, and safety. Each vehicle in the system either operates in the cruise control mode or follows a vehicle ahead by keeping a safe time headway. We show that if the number of vehicles is less than a certain critical threshold, vehicles can occupy the limited space in many different configurations, i.e., different platoons of different sizes, and they converge to a uniform maximum speed while attenuating errors in the relative spacing upstream a platoon. If the number of vehicles exceeds the threshold, vehicles converge to a unique symmetric configuration and the equilibrium speed decreases as the number of vehicles increases. Next, we consider vehicle-to-vehicle (V2V) communication and show that it increases the critical number of vehicles that can travel with the maximum speed. Finally, we consider central coordination and show that the proposed controllers can force vehicles to converge to a desired configuration specified by the coordinator while maintaining safety and comfort. We demonstrate the performance of the proposed controllers via simulation.      
### 34.FDLP-Spectrogram: Capturing Speech Dynamics in Spectrograms for End-to-end Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.14129.pdf)
>  We propose a technique to compute spectrograms using Frequency Domain Linear Prediction (FDLP) that uses all-pole models to fit the Hilbert envelope of speech in different frequency sub-bands. The spectrogram of a complete speech utterance is computed by overlap-add of contiguous all-pole model responses. The long context window of 1.5 seconds allows us to capture the low frequency temporal modulations of speech in the spectrogram. For an end-to-end automatic speech recognition task, the FDLP-spectrogram performs at-par with the standard mel-spectrogram features for clean read speech training and test data. For more realistic mismatched train-test situations and noisy, reverberated training data, the FDLP-spectrogram shows up to 25% and 22% WER improvements over mel-spectrogram respectively.      
### 35.Flexible MPC-based Conflict Resolution Using Online Adaptive ADMM  [ :arrow_down: ](https://arxiv.org/pdf/2103.14118.pdf)
>  Decentralized conflict resolution for autonomous vehicles is needed in many places where a centralized method is not feasible, e.g., parking lots, rural roads, merge lanes, etc. However, existing methods generally do not fully utilize optimization in decentralized conflict resolution. We propose a decentralized conflict resolution method for autonomous vehicles based on a novel extension to the Alternating Directions Method of Multipliers (ADMM), called Online Adaptive ADMM (OA-ADMM), and on Model Predictive Control (MPC). OA-ADMM is tailored to online systems, where fast and adaptive real-time optimization is crucial, and allows the use of safety information about the physical system to improve safety in real-time control. We prove convergence in the static case and give requirements for online convergence. Combining OA-ADMM and MPC allows for robust decentralized motion planning and control that seamlessly integrates decentralized conflict resolution. The effectiveness of our proposed method is shown through simulations in CARLA, an open-source vehicle simulator, resulting in a reduction of 47.93% in mean added delay compared with the next best method.      
### 36.Robust Data-Driven Predictive Control using Reachability Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.14110.pdf)
>  We present a robust data-driven control scheme for unknown linear systems with a bounded process and measurement noise. Instead of depending on a system model as in traditional predictive control, a controller utilizing data-driven reachable regions is proposed. The data-driven reachable regions are based on a matrix zonotope recursion and are computed based on only noisy input-output data of a trajectory of the system. We assume that measurement and process noise are contained in bounded sets. While we assume knowledge of these bounds, no knowledge about the statistical properties of the noise is assumed. In the noise-free case, we prove that the presented purely data-driven control scheme results in an equivalent closed-loop behavior to a nominal model predictive control scheme. In the case of measurement and process noise, our proposed scheme guarantees robust constraint satisfaction, which is essential in safety-critical applications. Numerical experiments show the effectiveness of the proposed data-driven controller in comparison to model-based control schemes.      
### 37.Ultrasound Elasticity Imaging Using Physics-based Models And Learning-based Plug-And-Play Priors  [ :arrow_down: ](https://arxiv.org/pdf/2103.14096.pdf)
>  Existing physical model-based imaging methods for ultrasound elasticity reconstruction utilize fixed variational regularizers that may not be appropriate for the application of interest or may not capture complex spatial prior information about the underlying tissues. On the other hand, end-to-end learning-based methods count solely on the training data, not taking advantage of the governing physical laws of the imaging system. Integrating learning-based priors with physical forward models for ultrasound elasticity imaging, we present a joint reconstruction framework which guarantees that learning driven reconstructions are consistent with the underlying physics. For solving the elasticity inverse problem as a regularized optimization problem, we propose a plug-and-play (PnP) reconstruction approach in which each iteration of the elasticity image estimation process involves separate updates incorporating data fidelity and learning-based regularization. In this methodology, the data fidelity term is developed using a statistical linear algebraic model of quasi-static equilibrium equation revealing the relationship of the observed displacement fields \cmmnt{measured deformation data} to the unobserved elastic modulus. The regularizer comprises a convolutional neural network (CNN) based denoiser that captures the learned prior structure of the underlying tissues. Preliminary simulation results demonstrate the robustness and effectiveness of the proposed approach with limited training datasets and noisy displacement measurements.      
### 38.A privacy-preserving distributed computational approach for distributed locational marginal prices  [ :arrow_down: ](https://arxiv.org/pdf/2103.14094.pdf)
>  An important issue in today's electricity markets is the management of flexibilities offered by new practices, such as smart home appliances or electric vehicles. By inducing changes in the behavior of residential electric utilities, demand response (DR) seeks to adjust the demand of power to the supply for increased grid stability and better integration of renewable energies. A key role in DR is played by emergent independent entities called load aggregators (LAs). We develop a new decentralized algorithm to solve a convex relaxation of the classical Alternative Current Optimal Power Flow (ACOPF) problem, which relies on local information only. Each computational step can be performed in an entirely privacy-preserving manner, and system-wide coordination is achieved via node-specific distribution locational marginal prices (DLMPs). We demonstrate the efficiency of our approach on a 15-bus radial distribution network.      
### 39.Hybrid analysis and modeling, eclecticism, and multifidelity computing toward digital twin revolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.14629.pdf)
>  Most modeling approaches lie in either of the two categories: physics-based or data-driven. Recently, a third approach which is a combination of these deterministic and statistical models is emerging for scientific applications. To leverage these developments, our aim in this perspective paper is centered around exploring numerous principle concepts to address the challenges of (i) trustworthiness and generalizability in developing data-driven models to shed light on understanding the fundamental trade-offs in their accuracy and efficiency, and (ii) seamless integration of interface learning and multifidelity coupling approaches that transfer and represent information between different entities, particularly when different scales are governed by different physics, each operating on a different level of abstraction. Addressing these challenges could enable the revolution of digital twin technologies for scientific and engineering applications.      
### 40.Distributed formation control of manipulators' end-effector with internal model-based disturbance rejection  [ :arrow_down: ](https://arxiv.org/pdf/2103.14595.pdf)
>  This paper addresses the problem of end-effector formation control for manipulators that are subjected to external disturbances: input disturbance torques and disturbance forces at each end-effector. The disturbances are assumed to be non-vanishing and are superposition of finite number of sinusoidal and step signals. The formation control objective is achieved by assigning virtual springs between end-effectors, by adding damping terms at joints, and by incorporating internal model-based dynamic compensators to counteract the effect of the disturbances; all of which presents a clear physical interpretation of the proposed approach. Simulation results are presented to illustrate the effectiveness of the proposed approach.      
### 41.Leveraging neural representations for facilitating access to untranscribed speech from endangered languages  [ :arrow_down: ](https://arxiv.org/pdf/2103.14583.pdf)
>  For languages with insufficient resources to train speech recognition systems, query-by-example spoken term detection (QbE-STD) offers a way of accessing an untranscribed speech corpus by helping identify regions where spoken query terms occur. Yet retrieval performance can be poor when the query and corpus are spoken by different speakers and produced in different recording conditions. Using data selected from a variety of speakers and recording conditions from 7 Australian Aboriginal languages and a regional variety of Dutch, all of which are endangered or vulnerable, we evaluated whether QbE-STD performance on these languages could be improved by leveraging representations extracted from the pre-trained English wav2vec 2.0 model. Compared to the use of Mel-frequency cepstral coefficients and bottleneck features, we find that representations from the middle layers of the wav2vec 2.0 Transformer offer large gains in task performance (between 56% and 86%). While features extracted using the pre-trained English model yielded improved detection on all the evaluation languages, better detection performance was associated with the evaluation language's phonological similarity to English.      
### 42.Parallel Tacotron 2: A Non-Autoregressive Neural TTS Model with Differentiable Duration Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2103.14574.pdf)
>  This paper introduces Parallel Tacotron 2, a non-autoregressive neural text-to-speech model with a fully differentiable duration model which does not require supervised duration signals. The duration model is based on a novel attention mechanism and an iterative reconstruction loss based on Soft Dynamic Time Warping, this model can learn token-frame alignments as well as token durations automatically. Experimental results show that Parallel Tacotron 2 outperforms baselines in subjective naturalness in several diverse multi speaker evaluations. Its duration control capability is also demonstrated.      
### 43.Deep Unsupervised Learning for Generalized Assignment Problems: A Case-Study of User-Association in Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.14548.pdf)
>  There exists many resource allocation problems in the field of wireless communications which can be formulated as the generalized assignment problems (GAP). GAP is a generic form of linear sum assignment problem (LSAP) and is more challenging to solve owing to the presence of both equality and inequality constraints. We propose a novel deep unsupervised learning (DUL) approach to solve GAP in a time-efficient manner. More specifically, we propose a new approach that facilitates to train a deep neural network (DNN) using a customized loss function. This customized loss function constitutes the objective function and penalty terms corresponding to both equality and inequality constraints. Furthermore, we propose to employ a Softmax activation function at the output of DNN along with tensor splitting which simplifies the customized loss function and guarantees to meet the equality constraint. As a case-study, we consider a typical user-association problem in a wireless network, formulate it as GAP, and consequently solve it using our proposed DUL approach. Numerical results demonstrate that the proposed DUL approach provides near-optimal results with significantly lower time-complexity.      
### 44.Improved Initialization of State-Space Artificial Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.14516.pdf)
>  The identification of black-box nonlinear state-space models requires a flexible representation of the state and output equation. Artificial neural networks have proven to provide such a representation. However, as in many identification problems, a nonlinear optimization problem needs to be solved to obtain the model parameters (layer weights and biases). A well-thought initialization of these model parameters can often avoid that the nonlinear optimization algorithm converges to a poorly performing local minimum of the considered cost function. This paper introduces an improved initialization approach for nonlinear state-space models represented as a recurrent artificial neural network and emphasizes the importance of including an explicit linear term in the model structure. Some of the neural network weights are initialized starting from a linear approximation of the nonlinear system, while others are initialized using random values or zeros. The effectiveness of the proposed initialization approach over previously proposed methods is illustrated on two benchmark examples.      
### 45.Continual Speaker Adaptation for Text-to-Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2103.14512.pdf)
>  Training a multi-speaker Text-to-Speech (TTS) model from scratch is computationally expensive and adding new speakers to the dataset requires the model to be re-trained. The naive solution of sequential fine-tuning of a model for new speakers can cause the model to have poor performance on older speakers. This phenomenon is known as catastrophic forgetting. In this paper, we look at TTS modeling from a continual learning perspective where the goal is to add new speakers without forgetting previous speakers. Therefore, we first propose an experimental setup and show that serial fine-tuning for new speakers can result in the forgetting of the previous speakers. Then we exploit two well-known techniques for continual learning namely experience replay and weight regularization and we reveal how one can mitigate the effect of degradation in speech synthesis diversity in sequential training of new speakers using these methods. Finally, we present a simple extension to improve the results in extreme setups.      
### 46.Probabilistic Planning with Preferences over Temporal Goals  [ :arrow_down: ](https://arxiv.org/pdf/2103.14489.pdf)
>  We present a formal language for specifying qualitative preferences over temporal goals and a preference-based planning method in stochastic systems. Using automata-theoretic modeling, the proposed specification allows us to express preferences over different sets of outcomes, where each outcome describes a set of temporal sequences of subgoals. We define the value of preference satisfaction given a stochastic process over possible outcomes and develop an algorithm for time-constrained probabilistic planning in labeled Markov decision processes where an agent aims to maximally satisfy its preference formula within a pre-defined finite time duration. We present experimental results using a stochastic gridworld example and discuss possible extensions of the proposed preference model.      
### 47.aDWI-BIDS: an extension to the brain imaging data structure for advanced diffusion weighted imaging  [ :arrow_down: ](https://arxiv.org/pdf/2103.14485.pdf)
>  Diffusion weighted imaging techniques permit us to infer microstructural detail in biological tissue in vivo and noninvasively. Modern sequences are based on advanced diffusion encoding schemes, allowing probing of more revealing measures of tissue microstructure than the standard apparent diffusion coefficient or fractional anisotropy. Though these methods may result in faster or more revealing acquisitions, they generally demand prior knowledge of sequence-specific parameters for which there is no accepted sharing standard. Here, we present a metadata labelling scheme suitable for the needs of developers and users within the diffusion neuroimaging community alike: a lightweight, unambiguous parametric map relaying acqusition parameters. This extensible scheme supports a wide spectrum of diffusion encoding methods, from single diffusion encoding to highly complex sequences involving arbitrary gradient waveforms. Built under the brain imaging data structure (BIDS), it allows storage of advanced diffusion MRI data comprehensively alongside any other neuroimaging information, facilitating processing pipelines and multimodal analyses. We illustrate the usefulness of this BIDS-extension with a range of example data, and discuss the extension's impact on pre- and post-processing software.      
### 48.COLREGs-Informed RRT* for Collision Avoidance of Marine Crafts  [ :arrow_down: ](https://arxiv.org/pdf/2103.14426.pdf)
>  The paper proposes novel sampling strategies to compute the optimal path alteration of a surface vessel sailing in close quarters. Such strategy directly encodes the rules for safe navigation at sea, by exploiting the concept of minimal ship domain to determine the compliant region where the path deviation is to be generated. The sampling strategy is integrated within the optimal rapidly-exploring random tree algorithm, which minimizes the length of the path deviation. Further, the feasibility of the path with respect to the steering characteristics of own ship is verified by ensuring that the position of the new waypoints respects the minimum turning radius of the vessel. The proposed sampling strategy brings a significant performance improvement both in terms of optimal cost, computational speed and convergence rate.      
### 49.SegVisRL: Visuomotor Development for a Lunar Rover for Hazard Avoidance using Camera Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.14422.pdf)
>  The visuomotor system of any animal is critical for its survival, and the development of a complex one within humans is large factor in our success as a species on Earth. This system is an essential part of our ability to adapt to our environment. We use this system continuously throughout the day, when picking something up, or walking around while avoiding bumping into objects. Equipping robots with such capabilities will help produce more intelligent locomotion with the ability to more easily understand their surroundings and to move safely. In particular, such capabilities are desirable for traversing the lunar surface, as it is full of hazardous obstacles, such as rocks. These obstacles need to be identified and avoided in real time. This paper seeks to demonstrate the development of a visuomotor system within a robot for navigation and obstacle avoidance, with complex rock shaped objects representing hazards. Our approach uses deep reinforcement learning with only image data. In this paper, we compare the results from several neural network architectures and a preprocessing methodology which includes producing a segmented image and downsampling.      
### 50.Imitation Learning from MPC for Quadrupedal Multi-Gait Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.14331.pdf)
>  We present a learning algorithm for training a single policy that imitates multiple gaits of a walking robot. To achieve this, we use and extend MPC-Net, which is an Imitation Learning approach guided by Model Predictive Control (MPC). The strategy of MPC-Net differs from many other approaches since its objective is to minimize the control Hamiltonian, which derives from the principle of optimality. To represent the policies, we employ a mixture-of-experts network (MEN) and observe that the performance of a policy improves if each expert of a MEN specializes in controlling exactly one mode of a hybrid system, such as a walking robot. We introduce new loss functions for single- and multi-gait policies to achieve this kind of expert selection behavior. Moreover, we benchmark our algorithm against Behavioral Cloning and the original MPC implementation on various rough terrain scenarios. We validate our approach on hardware and show that a single learned policy can replace its teacher to control multiple gaits.      
### 51.Guided Training: A Simple Method for Single-channel Speaker Separation  [ :arrow_down: ](https://arxiv.org/pdf/2103.14330.pdf)
>  Deep learning has shown a great potential for speech separation, especially for speech and non-speech separation. However, it encounters permutation problem for multi-speaker separation where both target and interference are speech. Permutation Invariant training (PIT) was proposed to solve this problem by permuting the order of the multiple speakers. Another way is to use an anchor speech, a short speech of the target speaker, to model the speaker identity. In this paper, we propose a simple strategy to train a long short-term memory (LSTM) model to solve the permutation problem in speaker separation. Specifically, we insert a short speech of target speaker at the beginning of a mixture as guide information. So, the first appearing speaker is defined as the target. Due to the powerful capability on sequence modeling, LSTM can use its memory cells to track and separate target speech from interfering speech. Experimental results show that the proposed training strategy is effective for speaker separation.      
### 52.Mutually-Constrained Monotonic Multihead Attention for Online ASR  [ :arrow_down: ](https://arxiv.org/pdf/2103.14302.pdf)
>  Despite the feature of real-time decoding, Monotonic Multihead Attention (MMA) shows comparable performance to the state-of-the-art offline methods in machine translation and automatic speech recognition (ASR) tasks. However, the latency of MMA is still a major issue in ASR and should be combined with a technique that can reduce the test latency at inference time, such as head-synchronous beam search decoding, which forces all non-activated heads to activate after a small fixed delay from the first head activation. In this paper, we remove the discrepancy between training and test phases by considering, in the training of MMA, the interactions across multiple heads that will occur in the test time. Specifically, we derive the expected alignments from monotonic attention by considering the boundaries of other heads and reflect them in the learning process. We validate our proposed method on the two standard benchmark datasets for ASR and show that our approach, MMA with the mutually-constrained heads from the training stage, provides better performance than baselines.      
### 53.Robotic Guide Dog: Leading a Human with Leash-Guided Hybrid Physical Interaction  [ :arrow_down: ](https://arxiv.org/pdf/2103.14300.pdf)
>  An autonomous robot that is able to physically guide humans through narrow and cluttered spaces could be a big boon to the visually-impaired. Most prior robotic guiding systems are based on wheeled platforms with large bases with actuated rigid guiding canes. The large bases and the actuated arms limit these prior approaches from operating in narrow and cluttered environments. We propose a method that introduces a quadrupedal robot with a leash to enable the robot-guiding human system to change its intrinsic dimension (by letting the leash go slack) in order to fit into narrow spaces. We propose a hybrid physical Human-Robot Interaction model that involves leash tension to describe the dynamical relationship in the robot-guiding human system. This hybrid model is utilized in a mixed-integer programming problem to develop a reactive planner that is able to utilize slack-taut switching to guide a blind-folded person to safely travel in a confined space. The proposed leash-guided robot framework is deployed on a Mini Cheetah quadrupedal robot and validated in experiments.      
### 54.Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots  [ :arrow_down: ](https://arxiv.org/pdf/2103.14295.pdf)
>  Developing robust walking controllers for bipedal robots is a challenging endeavor. Traditional model-based locomotion controllers require simplifying assumptions and careful modelling; any small errors can result in unstable control. To address these challenges for bipedal locomotion, we present a model-free reinforcement learning framework for training robust locomotion policies in simulation, which can then be transferred to a real bipedal Cassie robot. To facilitate sim-to-real transfer, domain randomization is used to encourage the policies to learn behaviors that are robust across variations in system dynamics. The learned policies enable Cassie to perform a set of diverse and dynamic behaviors, while also being more robust than traditional controllers and prior learning-based methods that use residual control. We demonstrate this on versatile walking behaviors such as tracking a target walking velocity, walking height, and turning yaw.      
### 55.Marine Snow Removal Benchmarking Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2103.14249.pdf)
>  This paper introduces a new benchmarking dataset for marine snow removal of underwater images. Marine snow is one of the main degradation sources of underwater images that are caused by small particles, e.g., organic matter and sand, between the underwater scene and photosensors. We mathematically model two typical types of marine snow from the observations of real underwater images. The modeled artifacts are synthesized with underwater images to construct large-scale pairs of ground-truth and degraded images to calculate objective qualities for marine snow removal and to train a deep neural network. We propose two marine snow removal tasks using the dataset and show the first benchmarking results of marine snow removal. The Marine Snow Removal Benchmarking Dataset is publicly available online.      
### 56.Super-Resolving Compressed Video in Coding Chain  [ :arrow_down: ](https://arxiv.org/pdf/2103.14247.pdf)
>  Scaling and lossy coding are widely used in video transmission and storage. Previous methods for enhancing the resolution of such videos often ignore the inherent interference between resolution loss and compression artifacts, which compromises perceptual video quality. To address this problem, we present a mixed-resolution coding framework, which cooperates with a reference-based DCNN. In this novel coding chain, the reference-based DCNN learns the direct mapping from low-resolution (LR) compressed video to their high-resolution (HR) clean version at the decoder side. We further improve reconstruction quality by devising an efficient deformable alignment module with receptive field block to handle various motion distances and introducing a disentangled loss that helps networks distinguish the artifact patterns from texture. Extensive experiments demonstrate the effectiveness of proposed innovations by comparing with state-of-the-art single image, video and reference-based restoration methods.      
### 57.On the Time Discretization of the Feynman-Kac Forward-Backward Stochastic Differential Equations for Value Function Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2103.14246.pdf)
>  Novel numerical estimators are proposed for the forward-backward stochastic differential equations (FBSDE) appearing in the Feynman-Kac representation of the value function. In contrast to the current numerical method approaches based on discretization of the continuous-time FBSDE results, we propose a converse approach, by first obtaining a discrete-time approximation of the on-policy value function, and then developing a discrete-time result which resembles the continuous-time counterpart. This approach yields improved numerical estimators in the function approximation phase, and demonstrates enhanced error analysis for those value function estimators. Numerical results and error analysis are demonstrated on a scalar nonlinear stochastic optimal control problem, and they show improvements in the performance of the proposed estimators in comparison with the state-of-the-art methodologies.      
### 58.Improve GAN-based Neural Vocoder using Pointwise Relativistic LeastSquare GAN  [ :arrow_down: ](https://arxiv.org/pdf/2103.14245.pdf)
>  Recently, GAN-based neural vocoders, such as Parallel WaveGAN and MelGAN have attracted great interest due to their lightweight and parallel structures, enabling them to generate high fidelity waveform in a real-time manner. In this paper, inspired by Relativistic GAN\cite{jolicoeur2018relativistic}, we introduce a novel variant of the LSGAN framework under the context of waveform synthesis, named Pointwise Relativistic LSGAN (PRLSGAN). In this approach, we take the truism score distribution into consideration and combine the original MSE loss with the proposed pointwise relative discrepancy loss to increase the difficulty of the generator to fool the discriminator, leading to improved generation quality. Moreover, PRLSGAN is a general-purposed framework that can be combined with any GAN-based neural vocoder to enhance its generation quality. Experiments have shown a consistent performance boost based on Parallel WaveGAN and MelGAN, demonstrating the effectiveness and strong generalization ability of our proposed PRLSGAN neural vocoders.      
### 59.Subspace-based compressive sensing algorithm for raypath separation in a shallow-water waveguide  [ :arrow_down: ](https://arxiv.org/pdf/2103.14236.pdf)
>  Compressive sensing (CS) has been applied to estimate the direction of arrival (DOA) in underwater acoustics. However, the key problem needed to be resolved in a {multipath} propagation environment is to suppress the interferences between the raypaths. Thus, in this paper, {a subspace-based compressive sensing algorithm that formulates the statistic information of the signal subspace in a CS framework is proposed.} The experiment results show that (1) the proposed algorithm enables the separation of raypaths that arrive closely at the {receiver} array and (2) the existing algorithms fail, especially in a low signal-to-noise ratio (SNR) environment.      
### 60.SD-VEC: Software-Defined Vehicular Edge Computing with Ultra-Low Latency  [ :arrow_down: ](https://arxiv.org/pdf/2103.14225.pdf)
>  New paradigm shifts and 6G technological revolution in vehicular services have emerged toward unmanned driving, automated transportation, and self-driving vehicles. As the technology for autonomous vehicles becomes mature, real challenges come from reliable, safe, real-time connected transportation operations to achieve ubiquitous and prompt information exchanges with massive connected and autonomous vehicles. This article aims at introducing novel wireless distributed architectures that embed the edge computing capability inside software-defined vehicular networking infrastructure. Such edge networks consist of open-loop grant-free communications and computing-based control frameworks, which enable dynamic eco-routing with ultra-low latency and mobile data-driven orchestration. Thus, this work advances the frontiers of machine learning potentials and next-generation mobile system realization in vehicular networking applications.      
### 61.Modeling the Compatibility of Stem Tracks to Generate Music Mashups  [ :arrow_down: ](https://arxiv.org/pdf/2103.14208.pdf)
>  A music mashup combines audio elements from two or more songs to create a new work. To reduce the time and effort required to make them, researchers have developed algorithms that predict the compatibility of audio elements. Prior work has focused on mixing unaltered excerpts, but advances in source separation enable the creation of mashups from isolated stems (e.g., vocals, drums, bass, etc.). In this work, we take advantage of separated stems not just for creating mashups, but for training a model that predicts the mutual compatibility of groups of excerpts, using self-supervised and semi-supervised methods. Specifically, we first produce a random mashup creation pipeline that combines stem tracks obtained via source separation, with key and tempo automatically adjusted to match, since these are prerequisites for high-quality mashups. To train a model to predict compatibility, we use stem tracks obtained from the same song as positive examples, and random combinations of stems with key and/or tempo unadjusted as negative examples. To improve the model and use more data, we also train on "average" examples: random combinations with matching key and tempo, where we treat them as unlabeled data as their true compatibility is unknown. To determine whether the combined signal or the set of stem signals is more indicative of the quality of the result, we experiment on two model architectures and train them using semi-supervised learning technique. Finally, we conduct objective and subjective evaluations of the system, comparing them to a standard rule-based system.      
### 62.Three dimensional higher-order raypath separation in a shallow-water waveguide  [ :arrow_down: ](https://arxiv.org/pdf/2103.14206.pdf)
>  Separating raypaths in a multipath shallow-water environment is a challenge problem due to the interferences between them and colored noise existing in ocean environment, especially for two raypaths arrive close to each other. Thus, in this paper, a three dimensional (3D) higher-order raypath separation in an array to array configuration is proposed. Performance tests using simulation data in a multipath environment, real data obtained in an ultrasonic waveguide and ocean shallow-water data, respectively, illustrate that the proposed algorithm achieves a higher resolution and a stronger robustness comparing to the existing algorithms.      
### 63.Image2Reverb: Cross-Modal Reverb Impulse Response Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2103.14201.pdf)
>  Measuring the acoustic characteristics of a space is often done by capturing its impulse response (IR), a representation of how a full-range stimulus sound excites it. This is the first work that generates an IR from a single image, which we call Image2Reverb. This IR is then applied to other signals using convolution, simulating the reverberant characteristics of the space shown in the image. Recording these IRs is both time-intensive and expensive, and often infeasible for inaccessible locations. We use an end-to-end neural network architecture to generate plausible audio impulse responses from single images of acoustic environments. We evaluate our method both by comparisons to ground truth data and by human expert evaluation. We demonstrate our approach by generating plausible impulse responses from diverse settings and formats including well known places, musical halls, rooms in paintings, images from animations and computer games, synthetic environments generated from text, panoramic images, and video conference backgrounds.      
### 64.InversionNet3D: Efficient and Scalable Learning for 3D Full Waveform Inversion  [ :arrow_down: ](https://arxiv.org/pdf/2103.14158.pdf)
>  Recent progress in the use of deep learning for Full Waveform Inversion (FWI) has demonstrated the advantage of data-driven methods over traditional physics-based approaches in terms of reconstruction accuracy and computational efficiency. However, due to high computational complexity and large memory consumption, the reconstruction of 3D high-resolution velocity maps via deep networks is still a great challenge. In this paper, we present InversionNet3D, an efficient and scalable encoder-decoder network for 3D FWI. The proposed method employs group convolution in the encoder to establish an effective hierarchy for learning information from multiple sources while cutting down unnecessary parameters and operations at the same time. The introduction of invertible layers further reduces the memory consumption of intermediate features during training and thus enables the development of deeper networks with more layers and higher capacity as required by different application scenarios. Experiments on the 3D Kimberlina dataset demonstrate that InversionNet3D achieves state-of-the-art reconstruction performance with lower computational cost and lower memory footprint compared to the baseline.      
### 65.Development of muon scattering tomography for a detection of reinforcement in concrete  [ :arrow_down: ](https://arxiv.org/pdf/2103.14054.pdf)
>  Inspection of ageing, reinforced concrete structures is a world-wide challenge. Existing non-destructive evaluation techniques in civil and structural engineering have limited penetration depth and don't allow to precisely ascertain the configuration of reinforcement within large concrete objects. The big challenge for critical infrastructure (bridges, dams, dry docks, nuclear bioshields etc.) is understanding the internal condition of the concrete and steel, not just the location of the reinforcement. In most new constructions the location should be known and recorded in the as-built drawings, where these might not exist due to poor record keeping for older structures. Muon scattering tomography is a non-destructive and non-invasive technique which shows great promise for high-depth 3D concrete imaging. Previously, we have demonstrated that individual bars with a diameter of 33.7 +- 7.3 mm at 50 cm depth can be located using muon scattering tomography. Here we present an improved method that exploits the periodicity of bar structures. With this new method, reinforcement with bars down to 6 mm thickness can be detected and imaged.      

# ArXiv eess --Tue, 30 Mar 2021
### 1.Physical model simulator-trained neural network for computational 3D phase imaging of multiple-scattering samples  [ :arrow_down: ](https://arxiv.org/pdf/2103.15795.pdf)
>  Recovering 3D phase features of complex, multiple-scattering biological samples traditionally sacrifices computational efficiency and processing time for physical model accuracy and reconstruction quality. This trade-off hinders the rapid analysis of living, dynamic biological samples that are often of greatest interest to biological research. Here, we overcome this bottleneck by combining annular intensity diffraction tomography (aIDT) with an approximant-guided deep learning framework. Using a novel physics model simulator-based learning strategy trained entirely on natural image datasets, we show our network can robustly reconstruct complex 3D biological samples of arbitrary size and structure. This approach highlights that large-scale multiple-scattering models can be leveraged in place of acquiring experimental datasets for achieving highly generalizable deep learning models. We devise a new model-based data normalization pre-processing procedure for homogenizing the sample contrast and achieving uniform prediction quality regardless of scattering strength. To achieve highly efficient training and prediction, we implement a lightweight 2D network structure that utilizes a multi-channel input for encoding the axial information. We demonstrate this framework's capabilities on experimental measurements of epithelial buccal cells and Caenorhabditis elegans worms. We highlight the robustness of this approach by evaluating dynamic samples on a living worm video, and we emphasize our approach's generalizability by recovering algae samples evaluated with different experimental setups. To assess the prediction quality, we develop a novel quantitative evaluation metric and show that our predictions are consistent with our experimental measurements and multiple-scattering physics.      
### 2.Residential smart plug with bluetooth communication  [ :arrow_down: ](https://arxiv.org/pdf/2103.15757.pdf)
>  Electricity forms the backbone of the modern world but increasing energy demand with the growth of urban areas in recent decades has overwhelmed the current power grid ecosystem. So, there is a need to move towards a more efficient and interconnected smart grid infrastructure. The growing popularity of the Internet of Things(IoT) has increased the demand for smart and connected devices. In this work we developed a hardware device based on the ATmega2560 microcontroller that can estimate the power consumption and control the state of electro-electronic devices interconnected to it through Bluetooth wireless technology. The developed hardware is a smart plug focusing on smart home applications. As a result, by using a smartphone device with Bluetooth communication, one can control and measure electrical parameters of the interconnected electro-electronic hardware such as the RMS (Root Mean Square) current and RMS power been consumed. The obtained results showed the technical viability in the construction of energy consumption measuring device using modules and components available in the Brazilian market.      
### 3.Progress in neural networks for EEG signal recognition in 2021  [ :arrow_down: ](https://arxiv.org/pdf/2103.15755.pdf)
>  In recent years, neural networks showed unprecedented growth that ultimately influenced dozens of different industries, including signal processing for the electroencephalography (EEG) process. Electroencephalography, although it appeared in the first half of the 20th century, was not changed the physical principles of work to this day. But signal processing technology made significant progress in this area through the use of neural networks. But many different models of neural networks complicate the process of understanding the real situation in this area. This manuscript summarizes the current state of knowledge on this topic, summarizes and describes the most significant achievements in various fields of application of neural networks for processing EEG signals. We discussed in detail the results presented in recent research papers for various fields in which EEG signals have been involved. We also examined in detail the process of extracting features from EEG signals using neural networks. In conclusion, we have provided recommendations for the correct demonstration of research results in manuscripts on the subject of neural networks and EEG.      
### 4.Hankel Singular Value Decomposition as a method of preprocessing the Magnetic Resonance Spectroscopy  [ :arrow_down: ](https://arxiv.org/pdf/2103.15754.pdf)
>  The signal resulting from magnetic resonance spectroscopy is occupied by noises and irregularities so in the further analysis preprocessing techniques have to be introduced. The main idea of the paper is to develop a model of a signal as a sum of harmonics and to find its parameters. Such an approach is based on singular value decomposition applied to the data arranged in the Hankel matrix (HSVD) and can be used in each step of preprocessing techniques. For that purpose a method has was tested on real phantom data.      
### 5.Design of Novel Hybrid CPDM-CO-OFDM FSO Communication System and its Performance Analysis under Diverse Weather Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2103.15751.pdf)
>  A comprehensive novel design is proposed for the free-space optical (FSO) communication system by hybridizing circular polarization division multiplexing (CPDM) with coherent optical orthogonal frequency division multiplexing (CO-OFDM) and its performance is investigated realistically under diverse turbulent weather conditions of Bangladesh. Here we consider Gamma-Gamma (G-G) distribution for the turbulent FSO channel model. Moreover, the proposed scheme presents an excellent performance since CPDM technique not only maximizes the link capacity of FSO system but also enhances the spectral efficiency (SE) of the system. Besides, multipath-fading, which is appeared during the FSO transmission, is significantly mitigated by OFDM modulation. The outcomes from simulation confirm the advantages of the proposed hybrid scheme and also it can serve as a reference for the FSO application even in the turbulent weather conditions. Performance analysis of the proposed model is described in terms of optical power spectrum (OPS), optical signal to noise ratio (OSNR), bit error rate (BER), Q factor, constellation diagrams, and eye diagrams.      
### 6.A New Frequency-Bin-Index LoRa System for High-Data-Rate Transmission: Design and Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.15733.pdf)
>  As an attempt to tackle the low-data-rate issue of the conventional LoRa systems, we propose two novel frequency-bin-index (FBI) LoRa schemes. In scheme I, the indices of starting frequency bins (SFBs) are utilized to carry the information bits. To facilitate the actual implementation, the SFBs of each LoRa signal are divided into several groups prior to the modulation process in the proposed FBI-LoRa system. To further improve the system flexibility, we formulate a generalized modulation scheme and propose scheme II by treating the SFB groups as an additional type of transmission entity. In scheme II, the combination of SFB indices and that of SFB group indices are both exploited to carry the information bits. We derive the theoretical expressions for bit-error-rate (BER) and throughput of the proposed FBI-LoRa system with two modulation schemes over additive white Gaussian noise (AWGN) and Rayleigh fading channels. Theoretical and simulation results show that the proposed FBI-LoRa schemes can significantly increases the transmission throughput compared with the existing LoRa systems at the expense of a slight loss in BER performance. Thanks to the appealing superiorities, the proposed FBI-LoRa system is a promising alternative for high-data-rate Internet of Things (IoT) applications.      
### 7.Slimmable Compressive Autoencoders for Practical Neural Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2103.15726.pdf)
>  Neural image compression leverages deep neural networks to outperform traditional image codecs in rate-distortion performance. However, the resulting models are also heavy, computationally demanding and generally optimized for a single rate, limiting their practical use. Focusing on practical image compression, we propose slimmable compressive autoencoders (SlimCAEs), where rate (R) and distortion (D) are jointly optimized for different capacities. Once trained, encoders and decoders can be executed at different capacities, leading to different rates and complexities. We show that a successful implementation of SlimCAEs requires suitable capacity-specific RD tradeoffs. Our experiments show that SlimCAEs are highly flexible models that provide excellent rate-distortion performance, variable rate, and dynamic adjustment of memory, computational cost and latency, thus addressing the main requirements of practical image compression.      
### 8.Polyp Segmentation in Colonoscopy Images using U-Net-MobileNetV2  [ :arrow_down: ](https://arxiv.org/pdf/2103.15715.pdf)
>  Colorectal cancer from the appearance of polyps that can be benign or malignant is one of the most fatal diseases in the world. To find these polyps in patients, colonoscopy is performed, which is a very efficient technique in this case. Clinically, detecting and segmenting these polyps in order to determine their presence or not is a very difficult process that requires a lot of time and experience from professionals, depending directly on these factors. Therefore, it becomes increasingly important to have an automatic, effective and reliable method of detecting and segmenting these polyps, making diagnoses faster and more accurate. In order to assist in the development of a method, we proposed the U-Net-MobileNetV2 model, which is the combination of two neural networks, where one acts as an encoder for the other and is responsible for learning image resources. Our experiments generated satisfactory results, demonstrating a good performance and good segmentation. U-Net-MobileNetV2 achieved a Dice Coefficient of 89.71% and an IoU of 81.64% for the Kvasir-SEG dataset, where both are higher than the results obtained by other state-of-the-art models.      
### 9.MIMO-OFDM Joint Radar-Communications: Is ICI Friend or Foe?  [ :arrow_down: ](https://arxiv.org/pdf/2103.15694.pdf)
>  Inter-carrier interference (ICI) poses a significant challenge for OFDM joint radar-communications (JRC) systems in high-mobility scenarios. In this paper, we propose a novel ICI-aware sensing algorithm for MIMO-OFDM JRC systems to detect the presence of multiple targets and estimate their delay-Doppler-angle parameters. First, leveraging the observation that spatial covariance matrix is independent of target delays and Dopplers, we perform angle estimation via the MUSIC algorithm. For each estimated angle, we next formulate the radar delay-Doppler estimation as a joint carrier frequency offset (CFO) and channel estimation problem via an APES (amplitude and phase estimation) spatial filtering approach by transforming the delay-Doppler parameterized radar channel into an unstructured form. To account for the presence of multiple targets at a given angle, we devise an iterative interference cancellation based orthogonal matching pursuit (OMP) procedure, where at each iteration the generalized likelihood ratio test (GLRT) detector is employed to form decision statistics, providing as by-products the maximum likelihood estimates (MLEs) of radar channels and CFOs. In the final step, target detection is performed in delay-Doppler domain using target-specific, ICI-decontaminated channel estimates over time and frequency, where CFO estimates are utilized to resolve Doppler ambiguities, thereby turning ICI from foe to friend. The proposed algorithm can further exploit the ICI effect to introduce an additional dimension (namely, CFO) for target resolvability, which enables resolving targets located at the same delay-Doppler-angle cell. Simulation results illustrate the ICI exploitation capability of the proposed approach and showcase its superior detection and estimation performance in high-mobility scenarios over conventional methods.      
### 10.Omniscient Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.15683.pdf)
>  Most recent video super-resolution (SR) methods either adopt an iterative manner to deal with low-resolution (LR) frames from a temporally sliding window, or leverage the previously estimated SR output to help reconstruct the current frame recurrently. A few studies try to combine these two structures to form a hybrid framework but have failed to give full play to it. In this paper, we propose an omniscient framework to not only utilize the preceding SR output, but also leverage the SR outputs from the present and future. The omniscient framework is more generic because the iterative, recurrent and hybrid frameworks can be regarded as its special cases. The proposed omniscient framework enables a generator to behave better than its counterparts under other frameworks. Abundant experiments on public datasets show that our method is superior to the state-of-the-art methods in objective metrics, subjective visual effects and complexity. Our code will be made public.      
### 11.Optimal Transmission Topology for Facilitating the Growth of Renewable Power Generation  [ :arrow_down: ](https://arxiv.org/pdf/2103.15677.pdf)
>  Transmission topology control is a tool used by system operators in the role of a control action taken into account as a preventive or corrective action relative to a specific outage or set of outages. However, their inclusion in most electricity market frameworks is limited. With the increasing penetration of intermittent energy sources, optimal topology can be used as a lever of flexibility to decrease the total system cost. This paper demonstrates the evolution of optimal topology control on systems with increasing quantities of intermittent renewable energy along two axes. First, the effects of the increased variable sources on the variations of optimal topology are explored. Second, we elaborate on the growing advantages of exploiting transmission level grid flexibility in terms of total system cost. Case studies are performed on a modified RTS-96 network.      
### 12.On data-driven stabilization of systems with quadratic nonlinearities  [ :arrow_down: ](https://arxiv.org/pdf/2103.15631.pdf)
>  In this paper, we directly design a state feedback controller that stabilizes a class of uncertain nonlinear systems solely based on input-state data collected from a finite-length experiment. Necessary and sufficient conditions are derived to guarantee that the system is absolutely stabilizable and a controller is designed. Results derived under some relaxed prior information about the system and strengthened data assumptions are also discussed. Numerical examples illustrate the method with different levels of prior information.      
### 13.Stability analysis of time-delay systems in the parametric space  [ :arrow_down: ](https://arxiv.org/pdf/2103.15629.pdf)
>  This paper presents a novel method for stability analysis of a wide class of linear, time-delay systems (TDS), including retarded non-neutral ones, as well as those incorporating incommensurate and distributed delays. The proposed method is based on frequency domain analysis and the application of Rouche's theorem. Given a parametrized TDS, and some parametric point for which the number of unstable poles is known, the proposed method is capable of identifying the maximum surrounding region in the parametric space for which the number of unstable poles remains invariant. First, a procedure for investigating stability along a line is developed. Then, the results are extended by the application of Holder's inequality to investigating stability within a region. Contrary to existing approaches, the proposed method is uniformly applicable to parameters of different types (delays, distributed delay limits, time constants, etc.). Efficacy of the proposed method is demonstrated using illustrative examples.      
### 14.Fixed-Time Convergent Higher Order Control Barrier Functions for Leader-Follower Multi-Agent Systems under STL Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2103.15604.pdf)
>  This paper presents a control strategy based on time-varying fixed-time convergent higher order control barrier functions for a class of leader-follower multi-agent systems under signal temporal logic (STL) tasks. Each agent is assigned a local STL task which may be dependent on the behavior of agents involved in other tasks. In each local task, one agent called the leader has knowledge on the associated tasks and controls the performance of the subgroup involved agents. Our approach finds a robust solution to guarantee the fixed-time satisfaction of STL tasks in a least violating way and independent of the agents' initial conditions. In particular, the robust performance of the task satisfaction is based on the knowledge of the leader from the followers and can be adjusted in a user-specified way.      
### 15.Bayesian Estimation of Graph Signals  [ :arrow_down: ](https://arxiv.org/pdf/2103.15520.pdf)
>  We consider the problem of recovering random graph signals from nonlinear measurements. For this case, closed-form Bayesian estimators are usually intractable and even numerical evaluation of these estimators may be hard to compute for large networks. In this paper, we propose a graph signal processing (GSP) framework for random graph signal recovery that utilizes the information of the structure behind the data. First, we develop the GSP-linear minimum mean-squared-error (GSP-LMMSE) estimator, which minimizes the mean-squared error (MSE) among estimators that are represented as an output of a graph filter. The GSP-LMMSE estimator is based on diagonal covariance matrices in the graph frequency domain, and thus, has reduced complexity compared with the LMMSE estimator. This property is especially important when using the sample-mean versions of these estimators that are based on a training dataset. We then state conditions under which the low-complexity GSP-LMMSE estimator coincides with the optimal LMMSE estimator. Next, we develop the approximated parametrization of the GSP-LMMSE estimator by shift-invariant graph filters by solving a weighted least squared (WLS) problem. We present three implementations of the parametric GSP-LMMSE estimator for typical graph filters. Parametric graph filters are more robust to outliers and to network topology changes. In our simulations, we evaluate the performance of the proposed GSP-LMMSE estimators for the problem of state estimation in power systems, which can be interpreted as a graph signal recovery task. We show that the proposed sample-GSP estimators outperform the sample-LMMSE estimator for a limited training dataset and that the parametric GSP-LMMSE estimators are more robust to topology changes in the form of adding/removing vertices/edges.      
### 16.Tuning of extended state observer with neural network-based control performance assessment  [ :arrow_down: ](https://arxiv.org/pdf/2103.15516.pdf)
>  The extended state observer (ESO) is an inherent element of robust observer-based control systems that allows estimating the impact of disturbance on system dynamics. Proper tuning of ESO parameters is necessary to ensure a good quality of estimated quantities and impacts the overall performance of the robust control structure. In this paper, we propose a neural network (NN) based tuning procedure that allows the user to prioritize between selected quality criteria such as the control and observation errors and the specified features of the control signal. The designed NN provides an accurate assessment of the control system performance and returns a set of ESO parameters that delivers a near-optimal solution to the user-defined cost function. The proposed tuning procedure, using an estimated state from the single closed-loop experiment produces near-optimal ESO gains within seconds.      
### 17.Data-driven generation of plausible tissue geometries for realistic photoacoustic image synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2103.15510.pdf)
>  Photoacoustic tomography (PAT) has the potential to recover morphological and functional tissue properties such as blood oxygenation with high spatial resolution and in an interventional setting. However, decades of research invested in solving the inverse problem of recovering clinically relevant tissue properties from spectral measurements have failed to produce solutions that can quantify tissue parameters robustly in a clinical setting. Previous attempts to address the limitations of model-based approaches with machine learning were hampered by the absence of labeled reference data needed for supervised algorithm training. While this bottleneck has been tackled by simulating training data, the domain gap between real and simulated images remains a huge unsolved challenge. As a first step to address this bottleneck, we propose a novel approach to PAT data simulation, which we refer to as "learning to simulate". Our approach involves subdividing the challenge of generating plausible simulations into two disjoint problems: (1) Probabilistic generation of realistic tissue morphology, represented by semantic segmentation maps and (2) pixel-wise assignment of corresponding optical and acoustic properties. In the present work, we focus on the first challenge. Specifically, we leverage the concept of Generative Adversarial Networks (GANs) trained on semantically annotated medical imaging data to generate plausible tissue geometries. According to an initial in silico feasibility study our approach is well-suited for contributing to realistic PAT image synthesis and could thus become a fundamental step for deep learning-based quantitative PAT.      
### 18.Joint Transmit and Receive Antenna Selection System for MIMO-NOMA with Energy Harvesting  [ :arrow_down: ](https://arxiv.org/pdf/2103.15504.pdf)
>  In this paper, outage probability (OP) of a joint transmit and receive antenna selection (JTRAS) scheme is analyzed in multiple-input multiple-output non orthogonal multiple access based downlink energy harvesting (EH) relaying networks. In this dual-hop and amplify-and-forward relaying based network, since the first and second hops are types of single-user and multi-user systems, respectively, the optimal JTRAS and suboptimal majority-based JTRAS schemes are employed in the first and second hops. The theoretical OP analysis is carried out over Nakagami-m fading channels in the cases of perfect and imperfect successive interference cancellation. Finally, Monte Carlo simulations are performed to substantiate the accuracy of the theoretical analysis. It is shown that the optimal power splitting ratios at the EH relay are different for users and the users with good channel conditions have minimum optimal ratios.      
### 19.Improved Meta-learning training for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2103.15421.pdf)
>  Meta-learning (ML) has recently become a research hotspot in speaker verification (SV). We introduce two methods to improve the meta-learning training for SV in this paper. For the first method, a backbone embedding network is first jointly trained with the conventional cross entropy loss and prototypical networks (PN) loss. Then, inspired by speaker adaptive training in speech recognition, additional transformation coefficients are trained with only the PN loss. The transformation coefficients are used to modify the original backbone embedding network in the x-vector extraction process. Furthermore, the random erasing (RE) data augmentation technique is applied to all support samples in each episode to construct positive pairs, and a contrastive loss between the augmented and the original support samples is added to the objective in model training. Experiments are carried out on the Speaker in the Wild (SITW) and VOiCES databases. Both of the methods can obtain consistent improvements over existing meta-learning training frameworks. By combining these two methods, we can observe further improvements on these two databases.      
### 20.Performance-based Trajectory Optimization for Path Following Control Using Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.15416.pdf)
>  Accurate positioning and fast traversal times determine the productivity in machining applications. This paper demonstrates a hierarchical contour control implementation for the increase of productivity in positioning systems. The high-level controller pre-optimizes the input to a low-level cascade controller, using a contouring predictive control approach. This control structure requires tuning of multiple parameters. We propose a sample-efficient joint tuning algorithm, where the performance metrics associated with the full geometry traversal are modelled as Gaussian processes and used to form the global cost and the constraints in a constrained Bayesian optimization algorithm. This approach enables the trade-off between fast traversal, high tracking accuracy, and suppression of vibrations in the system. The performance improvement is evaluated numerically when tuning different combinations of parameters. We demonstrate that jointly tuning the parameters of the contour- and the low-level controller achieves the best performance in terms of time, tracking accuracy, and minimization of the vibrations in the system.      
### 21.Distributionally Robust Trajectory Optimization Under Uncertain Dynamics via Relative-Entropy Trust Regions  [ :arrow_down: ](https://arxiv.org/pdf/2103.15388.pdf)
>  Trajectory optimization and model predictive control are essential techniques underpinning advanced robotic applications, ranging from autonomous driving to full-body humanoid control. State-of-the-art algorithms have focused on data-driven approaches that infer the system dynamics online and incorporate posterior uncertainty during planning and control. Despite their success, such approaches are still susceptible to catastrophic errors that may arise due to statistical learning biases, unmodeled disturbances or even directed adversarial attacks. In this paper, we tackle the problem of dynamics mismatch and propose a distributionally robust optimal control formulation that alternates between two relative-entropy trust region optimization problems. Our method finds the worst-case maximum-entropy Gaussian posterior over the dynamics parameters and the corresponding robust optimal policy. We show that our approach admits a closed-form backward-pass for a certain class of systems and demonstrate the resulting robustness on linear and nonlinear numerical examples.      
### 22.Rank Minimization-based Toeplitz Reconstruction for DoA Estimation Using Coprime Array  [ :arrow_down: ](https://arxiv.org/pdf/2103.15351.pdf)
>  In this paper, we address the problem of direction finding using coprime array, which is one of the most preferred sparse array configurations. Motivated by the fact that non-uniform element spacing hinders full utilization of the underlying information in the receive signals, we propose a direction-of-arrival (DoA) estimation algorithm based on low-rank reconstruction of the Toeplitz covariance matrix. The atomic-norm representation of the measurements from the interpolated virtual array is considered, and the equivalent dual-variable rank minimization problem is formulated and solved using a cyclic optimization approach. The recovered covariance matrix enables the application of conventional subspace-based spectral estimation algorithms, such as MUSIC, to achieve enhanced DoA estimation performance. The estimation performance of the proposed approach, in terms of the degrees-of-freedom and spatial resolution, is examined. We also show the superiority of the proposed method over the competitive approaches in the root-mean-square error sense.      
### 23.A Distributed Scheme for Stability Assessment in Large-Scale Structure-Preserving Models via Singular Perturbation  [ :arrow_down: ](https://arxiv.org/pdf/2103.15333.pdf)
>  Assessing small-signal stability of power systems composed of thousands of interacting generators is a computationally challenging task. To reduce the computational burden, this paper introduces a novel condition to assess and certify small-signal stability. Using this certificate, we can see the impact of network topology and system parameters (generators' damping and inertia) on the eigenvalues of the system. The proposed certificate is derived from rigorous analysis of the classical structure-preserving swing equation model and has a physically insightful interpretation related to the generators' parameters and reactive power. To develop the certificate, we use singular perturbation techniques, and in the process, we establish the relationship between the structure-preserving model and its singular perturbation counterpart. As the proposed method is fully distributed and uses only local measurements, its computational cost does not increase with the size of the system. The effectiveness of the scheme is numerically illustrated on the WSCC system.      
### 24.Stability of Multi-Microgrids: New Certificates, Distributed Control, and Braess's Paradox  [ :arrow_down: ](https://arxiv.org/pdf/2103.15308.pdf)
>  This paper investigates the theory of resilience and stability in multi-microgrid networks. We derive new sufficient conditions to guarantee small-signal stability of multi-microgrids in both lossless and lossy networks. The new stability certificate for lossy networks only requires local information, thus leads to a fully distributed control scheme. Moreover, we study the impact of network topology, interface parameters (virtual inertia and damping), and local measurements (voltage magnitude and reactive power) on the stability of the system. The proposed stability certificate suggests the existence of Braess's Paradox in the stability of multi-microgrids, i.e. adding more connections between microgrids could worsen the multi-microgrid system stability as a whole. We also extend the presented analysis to structure-preserving network models, and provide a stability certificate as a function of original network parameters, instead of the Kron reduced network parameters. We provide a detailed numerical study of the proposed certificate, the distributed control scheme, and a coordinated control approach with line switching. The simulation shows the effectiveness of the proposed stability conditions and control schemes in a four-microgrid network, IEEE 33-bus system, and several large-scale synthetic grids.      
### 25.Checkerboard Context Model for Efficient Learned Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2103.15306.pdf)
>  For learned image compression, the autoregressive context model is proved effective in improving the rate-distortion (RD) performance. Because it helps remove spatial redundancies among latent representations. However, the decoding process must be done in a strict scan order, which breaks the parallelization. We propose a parallelizable checkerboard context model (CCM) to solve the problem. Our two-pass checkerboard context calculation eliminates such limitations on spatial locations by re-organizing the decoding order. Speeding up the decoding process more than 40 times in our experiments, it achieves significantly improved computational efficiency with almost the same rate-distortion performance. To the best of our knowledge, this is the first exploration on parallelization-friendly spatial context model for learned image compression.      
### 26.Scaling sparsemax based channel selection for speech recognition with ad-hoc microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2103.15305.pdf)
>  Recently, speech recognition with ad-hoc microphone arrays has received much attention. It is known that channel selection is an important problem of ad-hoc microphone arrays, however, this topic seems far from explored in speech recognition yet, particularly with a large-scale ad-hoc microphone array. To address this problem, we propose a Scaling Sparsemax algorithm for the channel selection problem of the speech recognition with large-scale ad-hoc microphone arrays. Specifically, we first replace the conventional Softmax operator in the stream attention mechanism of a multichannel end-to-end speech recognition system with Sparsemax, which conducts channel selection by forcing the channel weights of noisy channels to zero. Because Sparsemax punishes the weights of many channels to zero harshly, we propose Scaling Sparsemax which punishes the channels mildly by setting the weights of very noisy channels to zero only. Experimental results with ad-hoc microphone arrays of over 30 channels under the conformer speech recognition architecture show that the proposed Scaling Sparsemax yields a word error rate of over 30% lower than Softmax on simulation data sets, and over 20% lower on semi-real data sets, in test scenarios with both matched and mismatched channel numbers.      
### 27.Best-Buddy GANs for Highly Detailed Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2103.15295.pdf)
>  We consider the single image super-resolution (SISR) problem, where a high-resolution (HR) image is generated based on a low-resolution (LR) input. Recently, generative adversarial networks (GANs) become popular to hallucinate details. Most methods along this line rely on a predefined single-LR-single-HR mapping, which is not flexible enough for the SISR task. Also, GAN-generated fake details may often undermine the realism of the whole image. We address these issues by proposing best-buddy GANs (Beby-GAN) for rich-detail SISR. Relaxing the immutable one-to-one constraint, we allow the estimated patches to dynamically seek the best supervision during training, which is beneficial to producing more reasonable details. Besides, we propose a region-aware adversarial learning strategy that directs our model to focus on generating details for textured areas adaptively. Extensive experiments justify the effectiveness of our method. An ultra-high-resolution 4K dataset is also constructed to facilitate future super-resolution research.      
### 28.On Anderson acceleration for partially observable Markov decision processes  [ :arrow_down: ](https://arxiv.org/pdf/2103.15275.pdf)
>  This paper proposes an accelerated method for approximately solving partially observable Markov decision process (POMDP) problems offline. Our method carefully combines two existing tools: Anderson acceleration (AA) and the fast informed bound (FIB) method. Adopting AA, our method rapidly solves an approximate Bellman equation with an efficient combination of previous solution estimates. Furthermore, the use of FIB alleviates the scalability issue inherent in POMDPs. We show the convergence of the overall algorithm to the suboptimal solution obtained by FIB. We further consider a simulation-based method and prove that the approximation error is bounded explicitly. The performance of our algorithm is evaluated on several benchmark problems. The results of our experiments demonstrate that the proposed algorithm converges significantly faster without degrading the quality of the solution compared to its standard counterpart.      
### 29.General framework for reversible data hiding in encrypted image by reserving room before encryption  [ :arrow_down: ](https://arxiv.org/pdf/2103.15240.pdf)
>  In this paper a general framework to adopt different predictors for reversible data hiding in encrypted image is presented. We propose innovative predictors that contribute more significantly than conventional ones results in accomplishing more payload. Reserving room before encryption (RRBE) is designated in the proposed scheme to make possible attaining high embedding capacity. In RRBE procedure, pre-processing is allowed before image encryption. In our scheme, pre-processing comprises of three main steps of computing prediction-errors, blocking and labeling of the errors. By blocking we obviate the need for lossless compression to when content-owner is not enthusiastic. Lossless compression is employed in recent state of the art schemes to improve payload. We surpass prior arts exploiting more proper predictors, more efficient labeling procedure and blocking      
### 30.Intelligent Reflecting Surfaces at Terahertz Bands: Channel Modeling and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.15239.pdf)
>  An intelligent reflecting surface (IRS) at terahertz (THz) bands is expected to have a massive number of reflecting elements to compensate for the severe propagation losses. However, as the IRS size grows, the conventional far-field assumption starts becoming invalid and the spherical wavefront of the radiated waves should be taken into account. In this work, we consider a spherical wave channel model and pursue a comprehensive study of IRS-aided multiple-input multiple-output (MIMO) in terms of power gain and energy efficiency (EE). Specifically, we first analyze the power gain under beamfocusing and beamforming, and show that the latter is suboptimal even for multiple meters away from the IRS. To this end, we derive an approximate, yet accurate, closed-form expression for the loss in the power gain under beamforming. Building on the derived model, we next show that an IRS can significantly improve the EE of MIMO when it operates in the radiating near-field and performs beamfocusing. Numerical results corroborate our analysis and provide novel insights into the design and performance of IRS-assisted THz communication.      
### 31.Synchronization and Control for Multi-Weighted and Directed Complex Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.15230.pdf)
>  The study of complex networks with multi-weights has been a hot topic recently. For a network with a single weight, previous studies have shown that they can promote synchronization. But for complex networks with multi-weights, there are no rigorous analysis to show that synchronization can be reached faster. In this paper, the complex network is allowed to be directed, which will make the synchronization analysis difficult for multiple couplings. In virtue of the normalized left eigenvectors (NLEVec) corresponding to the zero eigenvalue of coupling matrices, we prove that if the Chebyshev distance between NLEVec is less than some value, which is defined as the allowable deviation bound, then the synchronization and control will be realized with sufficiently large coupling strengths, i.e., all coupling matrices do accelerate synchronization. Moreover, adaptive rules are also designed for the coupling strength.      
### 32.Anomaly Detection Under Multiplicative Noise Model Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2103.15228.pdf)
>  State estimators are crucial components of anomaly detectors that are used to monitor cyber-physical systems. Many frequently used state estimators are susceptible to model risk as they rely critically on the availability of an accurate state-space model. Modeling errors make it more difficult to distinguish whether deviations from expected behavior are due to anomalies or simply a lack of knowledge about the system dynamics. In this research, we account for model uncertainty through a multiplicative noise framework. Specifically, we propose two different state estimators in this setting to hedge against the model uncertainty risk namely, 1) multiplicative noise LQG, and 2) Wasserstein distributionally robust Kalman filter. The size of the residual from either estimator can then be compared against a threshold to detect anomalies. Finally, the proposed detectors are validated using numerical simulations. Extension of state-of-the-art anomaly detection in cyber-physical systems to handle model uncertainty represents the main novel contribution of the present work.      
### 33.A Bulk-Controlled Low-Voltage CMOS Quadrature Oscillator  [ :arrow_down: ](https://arxiv.org/pdf/2103.15216.pdf)
>  In this paper, an schema for controlling the oscillation frequency of a quadrature oscillator is proposed. The method involves controlling the threshold voltage of the PMOS transistors in the inverter through control of the bulk bias voltage. Results obtained using HSPICE simulation are presented in a technology of 0.35{\mu}m, and experimental results using discrete elements (HEF4007) are also shown. Both sets of experiments show the effectiveness of the technique.      
### 34.Hidden Markov Model Based Approach for Diagnosing Cause of Alarm Signals  [ :arrow_down: ](https://arxiv.org/pdf/2103.15186.pdf)
>  When a fault occurs in a process, it slowly propagates within the system and affects the measurements triggering a sequence of alarms in the control room. The operators are required to diagnose the cause of alarms and take necessary corrective measures. The idea of representing the alarm sequence as the fault propagation path and using the propagation path to diagnose the fault is explored. A diagnoser based on hidden Markov model is built to identify the cause of the alarm signals. The proposed approach is applied to an industrial case study: Tennessee Eastman process. The results show that the proposed approach is successful in determining the probable cause of alarms generated with high accuracy. The model was able to identify the cause accurately, even when tested with short alarm sub-sequences. This allows for early identification of faults, providing more time to the operator to restore the system to normal operation.      
### 35.Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2103.15138.pdf)
>  The majority of model-based learned image reconstruction methods in medical imaging have been limited to uniform domains, such as pixelated images. If the underlying model is solved on nonuniform meshes, arising from a finite element method typical for nonlinear inverse problems, interpolation and embeddings are needed. To overcome this, we present a flexible framework to extend model-based learning directly to nonuniform meshes, by interpreting the mesh as a graph and formulating our network architectures using graph convolutional neural networks. This gives rise to the proposed iterative Graph Convolutional Newton's Method (GCNM), which directly includes the forward model into the solution of the inverse problem, while all updates are directly computed by the network on the problem specific mesh. We present results for Electrical Impedance Tomography, a severely ill-posed nonlinear inverse problem that is frequently solved via optimization-based methods, where the forward problem is solved by finite element methods. Results for absolute EIT imaging are compared to standard iterative methods as well as a graph residual network. We show that the GCNM has strong generalizability to different domain shapes, out of distribution data as well as experimental data, from purely simulated training data.      
### 36.Compressibility of Network Opinion and Spread States in the Laplacian-Eigenvector Basis  [ :arrow_down: ](https://arxiv.org/pdf/2103.15128.pdf)
>  Opinion-evolution and spread processes on networks (e.g., infectious disease spread, opinion formation in social networks) are not only high dimensional but also volatile and multiscale in nature. In this study, we explore whether snapshot data from these processes can admit terse representations. Specifically, using three case studies, we explore whether the data are compressible in the Laplacian-eigenvector basis, in the sense that each snapshot can be approximated well using a (possibly different) small set of basis vectors. The first case study is concerned with a linear consensus model that is subject to a stochastic input at an unknown location; both empirical and formal analyses are used to characterize compressibility. Second, compressibility of state snapshots for a stochastic voter model is assessed via an empirical study. Finally, compressibility is studied for state-level daily COVID-19 positivity-rate data. The three case studies indicate that state snapshots from opinion-evolution and spread processes allow terse representations, which nevertheless capture their rich propagative dynamics.      
### 37.Quantifying Bias in Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.15122.pdf)
>  Automatic speech recognition (ASR) systems promise to deliver objective interpretation of human speech. Practice and recent evidence suggests that the state-of-the-art (SotA) ASRs struggle with speech variance due to gender, age, speech impairment, race, and accents. Many factors can cause the bias of an ASR system, e.g. composition of the training material and articulation differences. Our overarching goal is to uncover bias in ASR systems to work towards proactive bias mitigation in ASR. This paper systematically quantifies the bias of a SotA ASR system against gender, age, regional accents and non-native accents. Word error rates are compared, and in-depth phoneme-level error analysis is conducted to understand where bias is occurring. We focus on bias due to articulation differences in the dataset. Based on our findings, we suggest bias mitigation strategies for ASR development.      
### 38.Libri-adhoc40: A dataset collected from synchronized ad-hoc microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2103.15118.pdf)
>  Recently, there is a research trend on ad-hoc microphone arrays. However, most research was conducted on simulated data. Although some data sets were collected with a small number of distributed devices, they were not synchronized which hinders the fundamental theoretical research to ad-hoc microphone arrays. To address this issue, this paper presents a synchronized speech corpus, named Libri-adhoc40, which collects the replayed Librispeech data from loudspeakers by ad-hoc microphone arrays of 40 strongly synchronized distributed nodes in a real office environment. Besides, to provide the evaluation target for speech frontend processing and other applications, we also recorded the replayed speech in an anechoic chamber. We trained several multi-device speech recognition systems on both the Libri-adhoc40 dataset and a simulated dataset. Experimental results demonstrate the validness of the proposed corpus which can be used as a benchmark to reflect the trend and difference of the models with different ad-hoc microphone arrays. The dataset is online available at <a class="link-external link-https" href="https://github.com/ISmallFish/Libri-adhoc40" rel="external noopener nofollow">this https URL</a>.      
### 39.Invertible Image Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2103.15061.pdf)
>  Unprocessed RAW data is a highly valuable image format for image editing and computer vision. However, since the file size of RAW data is huge, most users can only get access to processed and compressed sRGB images. To bridge this gap, we design an Invertible Image Signal Processing (InvISP) pipeline, which not only enables rendering visually appealing sRGB images but also allows recovering nearly perfect RAW data. Due to our framework's inherent reversibility, we can reconstruct realistic RAW data instead of synthesizing RAW data from sRGB images without any memory overhead. We also integrate a differentiable JPEG compression simulator that empowers our framework to reconstruct RAW data from JPEG images. Extensive quantitative and qualitative experiments on two DSLR demonstrate that our method obtains much higher quality in both rendered sRGB images and reconstructed RAW data than alternative methods.      
### 40.Manifold Optimization for High Accuracy Spatial Location Estimation Using Ultrasound Waves  [ :arrow_down: ](https://arxiv.org/pdf/2103.15050.pdf)
>  This paper designs a high accuracy spatial location estimation method using ultrasound waves by exploiting the fixed geometry of the transmitters. Assuming an equilateral triangle antenna configuration, where three antennas are placed as the vertices of an equilateral triangle, the spatial location problem can be formulated as a non-convex optimization problem whose interior is shown to admit a Riemannian manifold structure. The investigation of the geometry of the newly introduced manifold, i.e. the manifold of all equilateral triangles in R^3, allows the design of highly efficient optimization algorithms. Simulation results are presented to compare the performance of the proposed approach against popular methods from the literature. The results suggest that the proposed Riemannian-based methods outperform the state-of-the-art methods. Furthermore, the proposed Riemannian methods require much smaller computation time as compared with popular generic non-convex approaches.      
### 41.Connected and Automated Vehicle Distributed Control for On-ramp Merging Scenario: A Virtual Rotation Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.15047.pdf)
>  In this study, we propose a rotation-based connected automated vehicle (CAV) distributed cooperative control strategy for an on-ramp merging scenario. By assuming the mainline and ramp line are straight, we firstly design a virtual rotation approach that transfers the merging problem to a virtual car following (CF) problem to reduce the complexity and dimension of the cooperative CAVs merging control. Based on this concept, a multiple-predecessor virtual CF model and a unidirectional multi-leader communication topology are developed to determine the longitudinal behavior of each CAV. Specifically, we exploit a distributed feedback and feedforward longitudinal controller in preparation for actively generating gaps for merging CAVs, reducing the voids caused by merging, and ensuring safety and traffic efficiency during the process. To ensure the disturbance attenuation property of this system, practical string stability is mathematically proved for the virtual CF controllers to prohibit the traffic oscillation amplification through the traffic stream. Moreover, as a provision for extending the virtual CF application scenarios of any curvy ramp geometry, we utilize a curvilinear coordinate to model the two-dimensional merging control, and further design a local lateral controller based on an extended linear-quadratic regulator to regulate the position deviation and angular deviation of the lane centerlines. For the purpose of systematically evaluating the control performance of the proposed methods, numerical simulation experiments are conducted. As the results indicate, the proposed controllers can actively reduce the void and meanwhile guarantee the damping of traffic oscillations in the merging control area.      
### 42.Definition and Analytical Expression on State Observe Ability for Linear Discrete-time Systems with the Bounded Noise Energy  [ :arrow_down: ](https://arxiv.org/pdf/2103.15046.pdf)
>  In this article, the definition on the observe ability and its relation to the signal detecting performance are studied systematically for the linear discrete-time(LDT) systems. Firstly, to define and analyze the observe ability for the practical systems with the measured noise, six kinds of bounded noise models are classified. For the noise energy bounded case, the observability ellipsoid and the image observability ellipsoid are defined by the state observed error and then a novel concept on the LDT systems, called as the observe ability, is proposed. Based on that, some theorems and properties about the observe ability and the signal detecting performances are given and proven, and then the reason that to maximize the observe ability is to optimize the signal detecting performances is established. Secondly, a dual relation between the observability ellipsoid and the controllability ellipsoid, which volumes and radii are respectively with some inverse relations, is stated and proven. Accordingly, the analytical computing equations for the volume of the two observability ellipsoids are got and some analytical shape factors of these ellipsoids are deconstructed. Based on these effective compting for the volumes, radii, and shape factors, analyzing and optimizing for the observe ability can be carried out. Thirdly, to compare rationally the state observe ability between the different systems or different system parameters, the normalization of the output variables, the state variables, and the system models are discussed. Finally, some numerical experiments and their results show the effectiveness of the computing and comparing methods for the observe ability.      
### 43.Control Ability with Time Attributy for Linear Continous-time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.15038.pdf)
>  In this paper, the control ability with time attributy for the linear continuous-time (LCT) systems are defined and analyzed by the volume computing for the controllability region. Firstly, a relation theorem about the open-loop control ability, the control strategy space (\textit{i.e.}, the solution space of the input variable for control problems), and the some closed-loop performance for the LCT systems is purposed and proven. This theorem shows us the necessity to optimize the control ability for the practical engineering problems. Secondly, recurssive volume-computing algorithms with the low computing complexities for the finite-time controllability region are discussed. Finally, two analytical volume computations of the infinite-time controllability region for the systems with $n$ different and repeated real eigenvalues are deduced, and then by deconstructing the volume computing equations, 3 classes of the shape factors are constructed. These analytical volume and shape factors can describe accurately the size and shape of the controllability region. Because the time-attribute control ability for LCT systems is directly related to the controllability region with the unit input variables, based on these analytical expressions on the volume and shape factors, the time-attribute control ability can be computed and optimized conveniently.      
### 44.On the equivalence of contraction and Koopman approaches for nonlinear stability and control  [ :arrow_down: ](https://arxiv.org/pdf/2103.15033.pdf)
>  In this paper we prove new connections between two frameworks for analysis and control of nonlinear systems: the Koopman operator framework and contraction analysis. Each method, in different ways, provides exact and global analyses of nonlinear systems by way of linear systems theory. The main results of this paper show equivalence between contraction and Koopman approaches for a wide class of stability analysis and control design problems. In particular: stability or stablisability in the Koopman framework implies the existence of a contraction metric (resp. control contraction metric) for the nonlinear system. Further in certain cases the converse holds: contraction implies the existence of a set of observables with which stability can verified via the Koopman framework. Furthermore, the converse claims are based on an novel relations between the Koopman method and construction of a Kazantzis-Kravaris-Luenberger observer.      
### 45.On the benefits of robust models in modulation recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.14977.pdf)
>  Given the rapid changes in telecommunication systems and their higher dependence on artificial intelligence, it is increasingly important to have models that can perform well under different, possibly adverse, conditions. Deep Neural Networks (DNNs) using convolutional layers are state-of-the-art in many tasks in communications. However, in other domains, like image classification, DNNs have been shown to be vulnerable to adversarial perturbations, which consist of imperceptible crafted noise that when added to the data fools the model into misclassification. This puts into question the security of DNNs in communication tasks, and in particular in modulation recognition. We propose a novel framework to test the robustness of current state-of-the-art models where the adversarial perturbation strength is dependent on the signal strength and measured with the "signal to perturbation ratio" (SPR). We show that current state-of-the-art models are susceptible to these perturbations. In contrast to current research on the topic of image classification, modulation recognition allows us to have easily accessible insights on the usefulness of the features learned by DNNs by looking at the constellation space. When analyzing these vulnerable models we found that adversarial perturbations do not shift the symbols towards the nearest classes in constellation space. This shows that DNNs do not base their decisions on signal statistics that are important for the Bayes-optimal modulation recognition model, but spurious correlations in the training data. Our feature analysis and proposed framework can help in the task of finding better models for communication systems.      
### 46.Catalyzing Clinical Diagnostic Pipelines Through Volumetric Medical Image Segmentation Using Deep Neural Networks: Past, Present, &amp; Future  [ :arrow_down: ](https://arxiv.org/pdf/2103.14969.pdf)
>  Deep learning has made a remarkable impact in the field of natural image processing over the past decade. Consequently, there is a great deal of interest in replicating this success across unsolved tasks in related domains, such as medical image analysis. Core to medical image analysis is the task of semantic segmentation which enables various clinical workflows. Due to the challenges inherent in manual segmentation, many decades of research have been devoted to discovering extensible, automated, expert-level segmentation techniques. Given the groundbreaking performance demonstrated by recent neural network-based techniques, deep learning seems poised to achieve what classic methods have historically been unable. <br>This paper will briefly overview some of the state-of-the-art (SoTA) neural network-based segmentation algorithms with a particular emphasis on the most recent architectures, comparing and contrasting the contributions and characteristics of each network topology. Using ultrasonography as a motivating example, it will also demonstrate important clinical implications of effective deep learning-based solutions, articulate challenges unique to the modality, and discuss novel approaches developed in response to those challenges, concluding with the proposal of future directions in the field. <br>Given the generally observed ephemerality of the best deep learning approaches (i.e. the extremely quick succession of the SoTA), the main contributions of the paper are its contextualization of modern deep learning architectures with historical background and the elucidation of the current trajectory of volumetric medical image segmentation research.      
### 47.Improving prostate whole gland segmentation in t2-weighted MRI with synthetically generated data  [ :arrow_down: ](https://arxiv.org/pdf/2103.14955.pdf)
>  Whole gland (WG) segmentation of the prostate plays a crucial role in detection, staging and treatment planning of prostate cancer (PCa). Despite promise shown by deep learning (DL) methods, they rely on the availability of a considerable amount of annotated data. Augmentation techniques such as translation and rotation of images present an alternative to increase data availability. Nevertheless, the amount of information provided by the transformed data is limited due to the correlation between the generated data and the original. Based on the recent success of generative adversarial networks (GAN) in producing synthetic images for other domains as well as in the medical domain, we present a pipeline to generate WG segmentation masks and synthesize T2-weighted MRI of the prostate based on a publicly available multi-center dataset. Following, we use the generated data as a form of data augmentation. Results show an improvement in the quality of the WG segmentation when compared to standard augmentation techniques.      
### 48.ELM-based Frame Synchronization in Nonlinear Distortion Scenario Using Superimposed Training  [ :arrow_down: ](https://arxiv.org/pdf/2103.14929.pdf)
>  The requirement of high spectrum efficiency puts forward higher requirements on frame synchronization (FS) in wireless communication systems. Meanwhile, a large number of nonlinear devices or blocks will inevitably cause nonlinear distortion. To avoid the occupation of bandwidth resources and overcome the difficulty of nonlinear distortion, an extreme learning machine (ELM)-based network is introduced into the superimposed training-based FS with nonlinear distortion. Firstly, a preprocessing procedure is utilized to reap the features of synchronization metric (SM). Then, based on the rough features of SM, an ELM network is constructed to estimate the offset of frame boundary. The analysis and experiment results show that, compared with existing methods, the proposed method can improve the error probability of FS and bit error rate (BER) of symbol detection (SD). In addition, this improvement has its robustness against the impacts of parameter variations.      
### 49.Self-adaptive Torque Vectoring Controller Using Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.14892.pdf)
>  Continuous direct yaw moment control systems such as torque-vectoring controller are an essential part for vehicle stabilization. This controller has been extensively researched with the central objective of maintaining the vehicle stability by providing consistent stable cornering response. The ability of careful tuning of the parameters in a torque-vectoring controller can significantly enhance vehicle's performance and stability. However, without any re-tuning of the parameters, especially in extreme driving conditions e.g. low friction surface or high velocity, the vehicle fails to maintain the stability. In this paper, the utility of Reinforcement Learning (RL) based on Deep Deterministic Policy Gradient (DDPG) as a parameter tuning algorithm for torque-vectoring controller is presented. It is shown that, torque-vectoring controller with parameter tuning via reinforcement learning performs well on a range of different driving environment e.g., wide range of friction conditions and different velocities, which highlight the advantages of reinforcement learning as an adaptive algorithm for parameter tuning. Moreover, the robustness of DDPG algorithm are validated under scenarios which are beyond the training environment of the reinforcement learning algorithm. The simulation has been carried out using a four wheels vehicle model with nonlinear tire characteristics. We compare our DDPG based parameter tuning against a genetic algorithm and a conventional trial-and-error tunning of the torque vectoring controller, and the results demonstrated that the reinforcement learning based parameter tuning significantly improves the stability of the vehicle.      
### 50.Towards Fine-Grained Indoor Localization based on Massive MIMO-OFDM System: Perspective of Multipath Components  [ :arrow_down: ](https://arxiv.org/pdf/2103.14863.pdf)
>  Fine-grained indoor localization has attracted attention recently because of the rapidly growing demand for indoor location-based services (ILBS). Specifically, massive (large-scale) multiple-input and multiple-output (MIMO) systems have received increasing attention due to high angular resolution. This paper presents an indoor localization testbed based on a massive MIMO orthogonal frequency-division multiplexing (OFDM) system, which supports physical-layer channel measurements. Instead of exploiting channel state information (CSI) directly for localization, we focus on positioning from the perspective of multipath components (MPCs), which are extracted from the CSI through the space-alternating generalized expectation-maximization (SAGE) algorithm. On top of the available MPCs, we propose a generalized fingerprinting system based on different single-metric and hybrid-metric schemes. We evaluate the impact of varying antenna topologies, feeding metrics, sizes of the training set, and fingerprinting methods. The experimental results show that the proposed fingerprinting method can achieve centimeter-level positioning accuracy with a relatively small training set. Specifically, the distributed uniform linear array obtains the highest accuracy with about 1.63-2.5-cm mean absolute errors resulting from the high spatial resolution.      
### 51.Selective Encryption of VVC Encoded Video Streams for the Internet of Video Things  [ :arrow_down: ](https://arxiv.org/pdf/2103.14844.pdf)
>  Visual sensors serve as a critical component of the Internet of Things (IoT). There is an ever-increasing demand for broad applications and higher resolutions of videos and cameras in smart homes and smart cities, such as in security cameras. To utilize this large volume of video data generated from networks of visual sensors for various machine vision applications, it needs to be compressed and securely transmitted over the Internet. H.266/VVC, as the new compression standard, brings the highest compression for visual data. To provide security along with high compression, a selective encryption method for hiding information of videos is presented for this new compression standard. Selective encryption methods can lower the computation overhead of the encryption while keeping the video bitstream format which is useful when the video goes into untrusted blocks such as transcoding or watermarking. Syntax elements that represent considerable information are selected for the encryption, i.e., luma Intra Prediction Modes (IPMs), Motion Vector Difference (MVD), and residual signs., then the results of the proposed method are investigated in terms of visual security and bit rate change. Our experiments show that the encrypted videos provide higher visual security compared to other similar works in previous standards, and integration of the presented encryption scheme into the VVC encoder has little impact on the bit rate efficiency (results in 2% to 3% bit rate increase).      
### 52.A Self-Learning Disturbance Observer for Nonlinear Systems in Feedback-Error Learning Scheme  [ :arrow_down: ](https://arxiv.org/pdf/2103.14821.pdf)
>  This paper represents a novel online self-learning disturbance observer (SLDO) by benefiting from the combination of a type-2 neuro-fuzzy structure (T2NFS), feedback-error learning scheme and sliding mode control (SMC) theory. The SLDO is developed within a framework of feedback-error learning scheme in which a conventional estimation law and a T2NFS work in parallel. In this scheme, the latter learns uncertainties and becomes the leading estimator whereas the former provides the learning error to the T2NFS for learning system dynamics. A learning algorithm established on SMC theory is derived for an interval type-2 fuzzy logic system. In addition to the stability of the learning algorithm, the stability of the SLDO and the stability of the overall system are proven in the presence of time-varying disturbances. Thanks to learning process by the T2NFS, the simulation results show that the SLDO is able to estimate time-varying disturbances precisely as distinct from the basic nonlinear disturbance observer (BNDO) so that the controller based on the SLDO ensures robust control performance for systems with time-varying uncertainties, and maintains nominal performance in the absence of uncertainties.      
### 53.An Online Feedback-Based Linearized Power Flow Model for Unbalanced Distribution Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.14820.pdf)
>  The non-linearity and non-convexity of power flow models and the phase coupling challenge the analysis and optimization of unbalanced distribution networks. To tackle the challenges, this paper proposes an online feedback-based linearized power flow model for unbalanced distribution networks with both wye-connected and delta-connected loads. The online feedback-based linearized model is grounded on the first-order Taylor expansion of the branch flow model, and updates the model parameters via online feedback by leveraging the instantaneous measured voltages and load consumption at the previous time step. Its closed-loop nature can asymptotically mitigate the model mismatch, thus lending itself to a good performance. In addition, exploiting the connection structure of unbalanced radial distribution networks, we provide a unified matrix-vector compact form of the proposed linearized power flow model. Finally, the numerical tests on the IEEE 123-bus test system validate the effectiveness and superiority of the proposed model. A simple optimal power flow case is also provided to illustrate the application of the online feedback-based linearized model.      
### 54.Backup Plan Constrained Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.14819.pdf)
>  This article proposes a new safety concept: backup plan safety. The backup plan safety is defined as the ability to complete one of the alternative missions in the case of primary mission abortion. To incorporate this new safety concept in control problems, we formulate a feasibility maximization problem that adopts additional (virtual) input horizons toward the alternative missions on top of the input horizon toward the primary mission. Cost functions for the primary and alternative missions construct multiple objectives, and multi-horizon inputs evaluate them. To address the feasibility maximization problem, we develop a multi-horizon multi-objective model predictive path integral control (3M) algorithm. Model predictive path integral control (MPPI) is a sampling-based scheme that can help the proposed algorithm deal with nonlinear dynamic systems and achieve computational efficiency by parallel computation. Simulations of the aerial vehicle and ground vehicle control problems demonstrate the new concept of backup plan safety and the performance of the proposed algorithm.      
### 55.Scalable and Efficient Neural Speech Coding  [ :arrow_down: ](https://arxiv.org/pdf/2103.14776.pdf)
>  This work presents a scalable and efficient neural waveform codec (NWC) for speech compression. We formulate the speech coding problem as an autoencoding task, where a convolutional neural network (CNN) performs encoding and decoding as its feedforward routine. The proposed CNN autoencoder also defines quantization and entropy coding as a trainable module, so the coding artifacts and bitrate control are handled during the optimization process. We achieve efficiency by introducing compact model architectures to our fully convolutional network model, such as gated residual networks and depthwise separable convolution. Furthermore, the proposed models are with a scalable architecture, cross-module residual learning (CMRL), to cover a wide range of bitrates. To this end, we employ the residual coding concept to concatenate multiple NWC autoencoding modules, where an NWC module performs residual coding to restore any reconstruction loss that its preceding modules have created. CMRL can scale down to cover lower bitrates as well, for which it employs linear predictive coding (LPC) module as its first autoencoder. We redefine LPC's quantization as a trainable module to enhance the bit allocation tradeoff between LPC and its following NWC modules. Compared to the other autoregressive decoder-based neural speech coders, our decoder has significantly smaller architecture, e.g., with only 0.12 million parameters, more than 100 times smaller than a WaveNet decoder. Compared to the LPCNet-based speech codec, which leverages the speech production model to reduce the network complexity in low bitrates, ours can scale up to higher bitrates to achieve transparent performance. Our lightweight neural speech coding model achieves comparable subjective scores against AMR-WB at the low bitrate range and provides transparent coding quality at 32 kbps.      
### 56.Fully Automated 2D and 3D Convolutional Neural Networks Pipeline for Video Segmentation and Myocardial Infarction Detection in Echocardiography  [ :arrow_down: ](https://arxiv.org/pdf/2103.14734.pdf)
>  Cardiac imaging known as echocardiography is a non-invasive tool utilized to produce data including images and videos, which cardiologists use to diagnose cardiac abnormalities in general and myocardial infarction (MI) in particular. Echocardiography machines can deliver abundant amounts of data that need to be quickly analyzed by cardiologists to help them make a diagnosis and treat cardiac conditions. However, the acquired data quality varies depending on the acquisition conditions and the patient's responsiveness to the setup instructions. These constraints are challenging to doctors especially when patients are facing MI and their lives are at stake. In this paper, we propose an innovative real-time end-to-end fully automated model based on convolutional neural networks (CNN) to detect MI depending on regional wall motion abnormalities (RWMA) of the left ventricle (LV) from videos produced by echocardiography. Our model is implemented as a pipeline consisting of a 2D CNN that performs data preprocessing by segmenting the LV chamber from the apical four-chamber (A4C) view, followed by a 3D CNN that performs a binary classification to detect if the segmented echocardiography shows signs of MI. We trained both CNNs on a dataset composed of 165 echocardiography videos each acquired from a distinct patient. The 2D CNN achieved an accuracy of 97.18% on data segmentation while the 3D CNN achieved 90.9% of accuracy, 100% of precision and 95% of recall on MI detection. Our results demonstrate that creating a fully automated system for MI detection is feasible and propitious.      
### 57.Deception in Social Learning  [ :arrow_down: ](https://arxiv.org/pdf/2103.14729.pdf)
>  A common assumption in the social learning literature is that agents exchange information in an unselfish manner. In this work, we consider the scenario where a subset of agents aims at deceiving the network, meaning they aim at driving the network beliefs to the wrong hypothesis. The adversaries are unaware of the true hypothesis. However, they will "blend in" by behaving similarly to the other agents and will manipulate the likelihood functions used in the belief update process to launch inferential attacks. We will characterize the conditions under which the network is misled. Then, we will explain that it is possible for such attacks to succeed by showing that strategies exist that can be adopted by the malicious agents for this purpose. We examine both situations in which the agents have access to information about the network model as well as the case in which they do not. For the first case, we show that there always exists a way to construct fake likelihood functions such that the network is deceived regardless of the true hypothesis. For the latter case, we formulate an optimization problem and investigate the performance of the derived attack strategy by establishing conditions under which the network is deceived. We illustrate the learning performance of the network in the aforementioned adversarial setting via simulations. In a nutshell, we clarify when and how a network is deceived in the context of non-Bayesian social learning.      
### 58.Risk-Averse Stochastic Shortest Path Planning  [ :arrow_down: ](https://arxiv.org/pdf/2103.14727.pdf)
>  We consider the stochastic shortest path planning problem in MDPs, i.e., the problem of designing policies that ensure reaching a goal state from a given initial state with minimum accrued cost. In order to account for rare but important realizations of the system, we consider a nested dynamic coherent risk total cost functional rather than the conventional risk-neutral total expected cost. Under some assumptions, we show that optimal, stationary, Markovian policies exist and can be found via a special Bellman's equation. We propose a computational technique based on difference convex programs (DCPs) to find the associated value functions and therefore the risk-averse policies. A rover navigation MDP is used to illustrate the proposed methodology with conditional-value-at-risk (CVaR) and entropic-value-at-risk (EVaR) coherent risk measures.      
### 59.Tuning IR-cut Filter for Illumination-aware Spectral Reconstruction from RGB  [ :arrow_down: ](https://arxiv.org/pdf/2103.14708.pdf)
>  To reconstruct spectral signals from multi-channel observations, in particular trichromatic RGBs, has recently emerged as a promising alternative to traditional scanning-based spectral imager. It has been proven that the reconstruction accuracy relies heavily on the spectral response of the RGB camera in use. To improve accuracy, data-driven algorithms have been proposed to retrieve the best response curves of existing RGB cameras, or even to design brand new three-channel response curves. Instead, this paper explores the filter-array based color imaging mechanism of existing RGB cameras, and proposes to design the IR-cut filter properly for improved spectral recovery, which stands out as an in-between solution with better trade-off between reconstruction accuracy and implementation complexity. We further propose a deep learning based spectral reconstruction method, which allows to recover the illumination spectrum as well. Experiment results with both synthetic and real images under daylight illumination have shown the benefits of our IR-cut filter tuning method and our illumination-aware spectral reconstruction method.      
### 60.Personalized Adaptive Cruise Control and Impacts on Mixed Traffic  [ :arrow_down: ](https://arxiv.org/pdf/2103.14705.pdf)
>  This paper presents a personalized adaptive cruise control (PACC) design that can learn driver behavior and adaptively control the semi-autonomous vehicle (SAV) in the car-following scenario, and investigates its impacts on mixed traffic. In mixed traffic where the SAV and human-driven vehicles share the road, the SAV's driver can choose a PACC tuning that better fits the driver's preferred driving behaviors. The individual driver's preferences are learned through the inverse reinforcement learning (IRL) approach by recovering a unique cost function from the driver's demonstrated driving data that best explains the observed driving style. The proposed PACC design plans the motion of the SAV by minimizing the learned unique cost function considering the short preview information of the preceding human-driven vehicle. The results reveal that the learned driver model can identify and replicate the personalized driving behaviors accurately and consistently when following the preceding vehicle in a variety of traffic conditions. Furthermore, we investigated the impacts of the PACC with different drivers on mixed traffic by considering time headway, gap distance, and fuel economy assessments. A statistical investigation shows that the impacts of the PACC on mixed traffic vary among tested drivers due to their intrinsic driving preferences.      
### 61.Multi-Disease Detection in Retinal Imaging based on Ensembling Heterogeneous Deep Learning Models  [ :arrow_down: ](https://arxiv.org/pdf/2103.14660.pdf)
>  Preventable or undiagnosed visual impairment and blindness affect billion of people worldwide. Automated multi-disease detection models offer great potential to address this problem via clinical decision support in diagnosis. In this work, we proposed an innovative multi-disease detection pipeline for retinal imaging which utilizes ensemble learning to combine the predictive capabilities of several heterogeneous deep convolutional neural network models. Our pipeline includes state-of-the-art strategies like transfer learning, class weighting, real-time image augmentation and Focal loss utilization. Furthermore, we integrated ensemble learning techniques like heterogeneous deep learning models, bagging via 5-fold cross-validation and stacked logistic regression models. Through internal and external evaluation, we were able to validate and demonstrate high accuracy and reliability of our pipeline, as well as the comparability with other state-of-the-art pipelines for retinal disease prediction.      
### 62.High-Sensitivity Iodine Imaging by Combining Spectral CT Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2103.15735.pdf)
>  Spectral CT offers enhanced material discrimination over single-energy systems and enables quantitative estimation of basis material density images. Water/iodine decomposition in contrast-enhanced CT is one of the most widespread applications of this technology in the clinic. However, low concentrations of iodine can be difficult to estimate accurately, limiting potential clinical applications and/or raising injected contrast agent requirements. We seek high-sensitivity spectral CT system designs which minimize noise in water/iodine density estimates. In this work, we present a model-driven framework for spectral CT system design optimization to maximize material separability. We apply this tool to optimize the sensitivity spectra on a spectral CT test bench using a hybrid design which combines source kVp control and k-edge filtration. Following design optimization, we scanned a water/iodine phantom with the hybrid spectral CT system and performed dose-normalized comparisons to two single-technique designs which use only kVp control or only kedge filtration. The material decomposition results show that the hybrid system reduces both standard deviation and crossmaterial noise correlations compared to the designs where the constituent technologies are used individually.      
### 63.Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention  [ :arrow_down: ](https://arxiv.org/pdf/2103.15722.pdf)
>  Self-attention (SA), which encodes vector sequences according to their pairwise similarity, is widely used in speech recognition due to its strong context modeling ability. However, when applied to long sequence data, its accuracy is reduced. This is caused by the fact that its weighted average operator may lead to the dispersion of the attention distribution, which results in the relationship between adjacent signals ignored. To address this issue, in this paper, we introduce relative-position-awareness self-attention (RPSA). It not only maintains the global-range dependency modeling ability of self-attention, but also improves the localness modeling ability. Because the local window length of the original RPSA is fixed and sensitive to different test data, here we propose Gaussian-based self-attention (GSA) whose window length is learnable and adaptive to the test data automatically. We further generalize GSA to a new residual Gaussian self-attention (resGSA) for the performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based speech recognition respectively. Experimental results on the AISHELL-1 Mandarin speech recognition corpus demonstrate the effectiveness of the proposed methods. For example, the resGSA-Transformer achieves a character error rate (CER) of 5.86% on the test set, which is relative 7.8% lower than that of the SA-Transformer. Although the performance of the proposed resGSA-Transformer is only slightly better than that of the RPSA-Transformer, it does not have to tune the window length manually.      
### 64.Wall Detection Via IMU Data Classification In Autonomous Quadcopters  [ :arrow_down: ](https://arxiv.org/pdf/2103.15680.pdf)
>  An autonomous drone flying near obstacles needs to be able to detect and avoid the obstacles or it will collide with them. In prior work, drones can detect and avoid walls using data from camera, ultrasonic or laser sensors mounted either on the drone or in the environment. It is not always possible to instrument the environment, and sensors added to the drone consume payload and power - both of which are constrained for drones. <br>This paper studies how data mining classification techniques can be used to predict where an obstacle is in relation to the drone based only on monitoring air-disturbance. We modeled the airflow of the rotors physically to deduce higher level features for classification. Data was collected from the drone's IMU while it was flying with a wall to its direct left, front and right, as well as with no walls present. In total 18 higher level features were produced from the raw data. We used an 80%, 20% train-test scheme with the RandomForest (RF), K-Nearest Neighbor (KNN) and GradientBoosting (GB) classifiers. Our results show that with the RF classifier and with 90% accuracy it can predict which direction a wall is in relation to the drone.      
### 65.4D Dual-Tree Complex Wavelets for Time-Dependent Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.15674.pdf)
>  The dual-tree complex wavelet transform (DT-$\mathbb{C}$WT) is extended to the 4D setting. Key properties of 4D DT-$\mathbb{C}$WT, such as directional sensitivity and shift-invariance, are discussed and illustrated in a tomographic application. The inverse problem of reconstructing a dynamic three-dimensional target from X-ray projection measurements can be formulated as 4D space-time tomography. The results suggest that 4D DT-$\mathbb{C}$WT offers simple implementations combined with useful theoretical properties for tomographic reconstruction.      
### 66.Spatial Characterization of Electromagnetic Random Channels  [ :arrow_down: ](https://arxiv.org/pdf/2103.15666.pdf)
>  The majority of stochastic channel models rely on the electromagnetic far-field assumption. This assumption breaks down in future applications that push towards the electromagnetic near-field region such as those where the use of very large antenna arrays is envisioned. Motivated by this consideration, we show how physical principles can be used to derive a channel model that is also valid in the electromagnetic near-field. We show that wave propagation through a three-dimensional scattered medium can be generally modeled as a linear and space-variant system. We first review the physics principles that lead to a closed-form deterministic angular representation of the channel response. This serves as a basis for deriving a stochastic representation of the channel in terms of statistically independent Gaussian random coefficients for randomly spatially-stationary propagation environments. The very desirable property of spatial stationarity can always be retained by excluding reactive propagation mechanisms confined in the extreme near-field propagation region. Remarkably, the provided stochastic representation is directly connected to the Fourier spectral representation of a general spatially-stationary random field.      
### 67.Competing Adaptive Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.15664.pdf)
>  Adaptive networks have the capability to pursue solutions of global stochastic optimization problems by relying only on local interactions within neighborhoods. The diffusion of information through repeated interactions allows for globally optimal behavior, without the need for central coordination. Most existing strategies are developed for cooperative learning settings, where the objective of the network is common to all agents. We consider in this work a team setting, where a subset of the agents form a team with a common goal while competing with the remainder of the network. We develop an algorithm for decentralized competition among teams of adaptive agents, analyze its dynamics and present an application in the decentralized training of generative adversarial neural networks.      
### 68.Analyzing the Effects of COVID-19 Pandemic on the Energy Demand: the Case of Northern Italy  [ :arrow_down: ](https://arxiv.org/pdf/2103.15654.pdf)
>  The COVID-19 crisis is profoundly influencing the global economic framework due to restrictive measures adopted by governments worldwide. Finding real-time data to correctly quantify this impact is very significant but not as straightforward. Nevertheless, an analysis of the power demand profiles provides insight into the overall economic trends. To accurately assess the change in energy consumption patterns, in this work we employ a multi-layer feed-forward neural network that calculates an estimation of the aggregated power demand in the north of Italy, (i.e, in one of the European areas that were most affected by the pandemics) in the absence of the COVID-19 emergency. After assessing the forecasting model reliability, we compare the estimation with the ground truth data to quantify the variation in power consumption. Moreover, we correlate this variation with the change in mobility behaviors during the lockdown period by employing the Google mobility report data. From this unexpected and unprecedented situation, we obtain some intuition regarding the power system macro-structure and its relation with the overall people's mobility.      
### 69.Pyfectious: An individual-level simulator to discover optimal containment polices for epidemic diseases  [ :arrow_down: ](https://arxiv.org/pdf/2103.15561.pdf)
>  Simulating the spread of infectious diseases in human communities is critical for predicting the trajectory of an epidemic and verifying various policies to control the devastating impacts of the outbreak. Many existing simulators are based on compartment models that divide people into a few subsets and simulate the dynamics among those subsets using hypothesized differential equations. However, these models lack the requisite granularity to study the effect of intelligent policies that influence every individual in a particular way. In this work, we introduce a simulator software capable of modeling a population structure and controlling the disease's propagation at an individualistic level. In order to estimate the confidence of the conclusions drawn from the simulator, we employ a comprehensive probabilistic approach where the entire population is constructed as a hierarchical random variable. This approach makes the inferred conclusions more robust against sampling artifacts and gives confidence bounds for decisions based on the simulation results. To showcase potential applications, the simulator parameters are set based on the formal statistics of the COVID-19 pandemic, and the outcome of a wide range of control measures is investigated. Furthermore, the simulator is used as the environment of a reinforcement learning problem to find the optimal policies to control the pandemic. The obtained experimental results indicate the simulator's adaptability and capacity in making sound predictions and a successful policy derivation example based on real-world data. As an exemplary application, our results show that the proposed policy discovery method can lead to control measures that produce significantly fewer infected individuals in the population and protect the health system against saturation.      
### 70.Remote Sensing Image Translation via Style-Based Recalibration Module and Improved Style Discriminator  [ :arrow_down: ](https://arxiv.org/pdf/2103.15502.pdf)
>  Existing remote sensing change detection methods are heavily affected by seasonal variation. Since vegetation colors are different between winter and summer, such variations are inclined to be falsely detected as changes. In this letter, we proposed an image translation method to solve the problem. A style-based recalibration module is introduced to capture seasonal features effectively. Then, a new style discriminator is designed to improve the translation performance. The discriminator can not only produce a decision for the fake or real sample, but also return a style vector according to the channel-wise correlations. Extensive experiments are conducted on season-varying dataset. The experimental results show that the proposed method can effectively perform image translation, thereby consistently improving the season-varying image change detection performance. Our codes and data are available at <a class="link-external link-https" href="https://github.com/summitgao/RSIT_SRM_ISD" rel="external noopener nofollow">this https URL</a>.      
### 71.A hybrid controller for safe and efficient collision avoidance control  [ :arrow_down: ](https://arxiv.org/pdf/2103.15484.pdf)
>  We design and experimentally evaluate a hybrid safe-by-construction collision avoidance controller for autonomous vehicles. The controller combines into a single architecture the respective advantages of an adaptive controller and a discrete safe controller. The adaptive controller relies on model predictive control to achieve optimal efficiency in nominal conditions. The safe controller avoids collision by applying two different policies, for nominal and out-of-nominal conditions, respectively. We present design principles for both the adaptive and the safe controller and show how each one can contribute in the hybrid architecture to improve performance, road occupancy and passenger comfort while preserving safety. The experimental results confirm the feasibility of the approach and the practical relevance of hybrid controllers for safe and efficient driving.      
### 72.PeaceGAN: A GAN-based Multi-Task Learning Method for SAR Target Image Generation with a Pose Estimator and an Auxiliary Classifier  [ :arrow_down: ](https://arxiv.org/pdf/2103.15469.pdf)
>  Although Generative Adversarial Networks (GANs) are successfully applied to diverse fields, training GANs on synthetic aperture radar (SAR) data is a challenging task mostly due to speckle noise. On the one hands, in a learning perspective of human's perception, it is natural to learn a task by using various information from multiple sources. However, in the previous GAN works on SAR target image generation, the information on target classes has only been used. Due to the backscattering characteristics of SAR image signals, the shapes and structures of SAR target images are strongly dependent on their pose angles. Nevertheless, the pose angle information has not been incorporated into such generative models for SAR target images. In this paper, we firstly propose a novel GAN-based multi-task learning (MTL) method for SAR target image generation, called PeaceGAN that uses both pose angle and target class information, which makes it possible to produce SAR target images of desired target classes at intended pose angles. For this, the PeaceGAN has two additional structures, a pose estimator and an auxiliary classifier, at the side of its discriminator to combine the pose and class information more efficiently. In addition, the PeaceGAN is jointly learned in an end-to-end manner as MTL with both pose angle and target class information, thus enhancing the diversity and quality of generated SAR target images The extensive experiments show that taking an advantage of both pose angle and target class learning by the proposed pose estimator and auxiliary classifier can help the PeaceGAN's generator effectively learn the distributions of SAR target images in the MTL framework, so that it can better generate the SAR target images more flexibly and faithfully at intended pose angles for desired target classes compared to the recent state-of-the-art methods.      
### 73.Attention-guided Image Compression by Deep Reconstruction of Compressive Sensed Saliency Skeleton  [ :arrow_down: ](https://arxiv.org/pdf/2103.15368.pdf)
>  We propose a deep learning system for attention-guided dual-layer image compression (AGDL). In the AGDL compression system, an image is encoded into two layers, a base layer and an attention-guided refinement layer. Unlike the existing ROI image compression methods that spend an extra bit budget equally on all pixels in ROI, AGDL employs a CNN module to predict those pixels on and near a saliency sketch within ROI that are critical to perceptual quality. Only the critical pixels are further sampled by compressive sensing (CS) to form a very compact refinement layer. Another novel CNN method is developed to jointly decode the two compression layers for a much refined reconstruction, while strictly satisfying the transmitted CS constraints on perceptually critical pixels. Extensive experiments demonstrate that the proposed AGDL system advances the state of the art in perception-aware image compression.      
### 74.Infinite-horizon Risk-constrained Linear Quadratic Regulator with Average Cost  [ :arrow_down: ](https://arxiv.org/pdf/2103.15363.pdf)
>  The behaviour of a stochastic dynamical system may be largely influenced by those low-probability, yet extreme events. To address such occurrences, this paper proposes an infinite-horizon risk-constrained Linear Quadratic Regulator (LQR) framework with time-average cost. In addition to the standard LQR objective, the average one-stage predictive variance of the state penalty is constrained to lie within a user-specified level. By leveraging the duality, its optimal solution is first shown to be stationary and affine in the state, i.e., $u(x,\lambda^*) = -K(\lambda^*)x + l(\lambda^*)$, where $\lambda^*$ is an optimal multiplier, used to address the risk constraint. Then, we establish the stability of the resulting closed-loop system. Furthermore, we propose a primal-dual method with sublinear convergence rate to find an optimal policy $u(x,\lambda^*)$. Finally, a numerical example is provided to demonstrate the effectiveness of the proposed framework and the primal-dual method.      
### 75.Self-triggered Stabilization of Discrete-time Linear Systems with Quantized State Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2103.15362.pdf)
>  We study the problem of stabilizing a self-triggered control system with quantized state measurements. The state of the plant is measured by a collection of distributed sensors. A self-triggering mechanism determines the next sampling time from the quantized state, by estimating input errors due to quantization and aperiodic sampling. We propose an encoding and self-triggering strategy and derive a sufficient condition for the plant state to exponentially converge to the origin.      
### 76.Privacy-Assured Outsourcing of Compressed Sensing Reconstruction Service in Cloud  [ :arrow_down: ](https://arxiv.org/pdf/2103.15164.pdf)
>  Compressed sensing (CS), breaking the constriction of Shannon-Nyquist sampling theorem, is a very promising data acquisition technique in the era of multimedia big data. However, the high complexity of CS reconstruction algorithm is a big trouble for endusers who are hardly provided with great computing power. The combination of CS and cloud has the potential of freeing endusers from the resource constraint by cleverly transforming computational workload from the local cilent to the cloud platform. As a result, the low-complexity encoding virtue of CS is fully leveraged in the resource-constrained sensing devices but its highcomplexity decoding problem is effectively addressed in cloud. It seems to be perfect but privacy and security concerns are ignored. In this paper, a secure outsourcing scheme for CS reconstruction service is proposed. Experimental results and security analyses demonstrate that the proposed scheme can restrict malicious access, verify the integrity of the recovered data, and resist brute-force attack, ciphertext-only attack, and plaintext attack.      
### 77.Active RIS vs. Passive RIS: Which Will Prevail in 6G?  [ :arrow_down: ](https://arxiv.org/pdf/2103.15154.pdf)
>  From 1G to 5G, wireless channels have been traditionally considered to be uncontrollable. Thanks to the recent advances in meta-materials, reconfigurable intelligent surfaces (RISs) have emerged as a new paradigm for controlling wireless channels intelligently, thus making it a revolutionary technique for future 6G wireless communications. However, due to the "double fading" effect, RIS only achieves a negligible capacity gain in typical communication scenarios, which however has been widely ignored in many existing works. In this paper, the concept of active RIS is proposed to break this fundamental physical limit. Different from the existing passive RIS that reflects signals passively without amplification, active RIS can actively amplify the reflected signals. We then develop a signal model for active RIS, which is validated through experimental measurements. Based on this new signal model, we analyze the capacity gain achievable by active RIS and formulate the capacity maximization problem in an active RIS aided system. Next, a joint transmit and reflect precoding algorithm is proposed to solve this problem. Finally, extensive results show that, compared with the baseline without RIS, the existing passive RIS can realize a negligible capacity gain of only 3% in typical application scenarios, while the proposed active RIS can achieve a noticeable capacity gain of 129%, thus overcoming the fundamental limit of "double fading" effect.      
### 78.IUP: An Intelligent Utility Prediction Scheme for Solid-State Fermentation in 5G IoT  [ :arrow_down: ](https://arxiv.org/pdf/2103.15073.pdf)
>  At present, SOILD-STATE Fermentation (SSF) is mainly controlled by artificial experience, and the product quality and yield are not stable. Accurately predicting the quality and yield of SSF is of great significance for improving human food security and supply. In this paper, we propose an Intelligent Utility Prediction (IUP) scheme for SSF in 5G Industrial Internet of Things (IoT), including parameter collection and utility prediction of SSF process. This IUP scheme is based on the environmental perception and intelligent learning algorithms of the 5G Industrial IoT. We build a workflow model based on rewritable petri net to verify the correctness of the system model function and process. In addition, we design a utility prediction model for SSF based on the Generative Adversarial Networks (GAN) and Fully Connected Neural Network (FCNN). We design a GAN with constraint of mean square error (MSE-GAN) to solve the problem of few-shot learning of SSF, and then combine with the FCNN to realize the utility prediction (usually use the alcohol) of SSF. Based on the production of liquor in laboratory, the experiments show that the proposed method is more accurate than the other prediction methods in the utility prediction of SSF, and provide the basis for the numerical analysis of the proportion of preconfigured raw materials and the appropriate setting of cellar temperature.      
### 79.PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS  [ :arrow_down: ](https://arxiv.org/pdf/2103.15060.pdf)
>  This paper introduces PnG BERT, a new encoder model for neural TTS. This model is augmented from the original BERT model, by taking both phoneme and grapheme representations of text as input, as well as the word-level alignment between them. It can be pre-trained on a large text corpus in a self-supervised manner, and fine-tuned in a TTS task. Experimental results show that a neural TTS model using a pre-trained PnG BERT as its encoder yields more natural prosody and more accurate pronunciation than a baseline model using only phoneme input with no pre-training. Subjective side-by-side preference evaluations show that raters have no statistically significant preference between the speech synthesized using a PnG BERT and ground truth recordings from professional speakers.      
### 80.On the Stability of Nonlinear Receding Horizon Control: A Geometric Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2103.15010.pdf)
>  The widespread adoption of nonlinear Receding Horizon Control (RHC) strategies by industry has led to more than 30 years of intense research efforts to provide stability guarantees for these methods. However, current theoretical guarantees require that each (generally nonconvex) planning problem can be solved to (approximate) global optimality, which is an unrealistic requirement for the derivative-based local optimization methods generally used in practical implementations of RHC. This paper takes the first step towards understanding stability guarantees for nonlinear RHC when the inner planning problem is solved to first-order stationary points, but not necessarily global optima. Special attention is given to feedback linearizable systems, and a mixture of positive and negative results are provided. We establish that, under certain strong conditions, first-order solutions to RHC exponentially stabilize linearizable systems. Crucially, this guarantee requires that state costs applied to the planning problems are in a certain sense `compatible' with the global geometry of the system, and a simple counter-example demonstrates the necessity of this condition. These results highlight the need to rethink the role of global geometry in the context of optimization-based control.      
### 81.Dendritic trafficking regulation: homeostasis and distributed adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2103.15001.pdf)
>  Neurons regulate the distribution of signaling components across an extended tree-like cellular structure, using both local and global feedback control. This is hypothesized to allow homeostatic control of the electrical activity of a neuron and at the same time enable normalization of distribution of inputs received from other cells. The performance and robustness of these mechanisms are poorly understood, and are subject to nonlinearities, making analysis difficult. We show that tree morphology places a severe constraint on the performance and stability of a global controller that is alleviated by local action. However, local action reduces the ability of the system to normalize distributed inputs, resulting in a trade-off between stability and flexibility of regulation.      
### 82.Thermal transmittance prediction based on the application of artificial neural networks on heat flux method results  [ :arrow_down: ](https://arxiv.org/pdf/2103.14995.pdf)
>  Deep energy renovation of building stock came more into focus in the European Union due to energy efficiency related directives. Many buildings that must undergo deep energy renovation are old and may lack design/renovation documentation, or possible degradation of materials might have occurred in building elements over time. Thermal transmittance (i.e. U-value) is one of the most important parameters for determining the transmission heat losses through building envelope elements. It depends on the thickness and thermal properties of all the materials that form a building element. In-situ U-value can be determined by ISO 9869-1 standard (Heat Flux Method - HFM). Still, measurement duration is one of the reasons why HFM is not widely used in field testing before the renovation design process commences. This paper analyzes the possibility of reducing the measurement time by conducting parallel measurements with one heat-flux sensor. This parallelization could be achieved by applying a specific class of the Artificial Neural Network (ANN) on HFM results to predict unknown heat flux based on collected interior and exterior air temperatures. After the satisfying prediction is achieved, HFM sensor can be relocated to another measuring location. Paper shows a comparison of four ANN cases applied to HFM results for a measurement held on one multi-layer wall - multilayer perceptron with three neurons in one hidden layer, long short-term memory with 100 units, gated recurrent unit with 100 units and combination of 50 long short-term memory units and 50 gated recurrent units. The analysis gave promising results in term of predicting the heat flux rate based on the two input temperatures. Additional analysis on another wall showed possible limitations of the method that serves as a direction for further research on this topic.      
### 83.Effective GPU Parallelization of Distributed and Localized Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2103.14990.pdf)
>  To effectively control large-scale distributed systems online, model predictive control (MPC) has to swiftly solve the underlying high-dimensional optimization. There are multiple techniques applied to accelerate the solving process in the literature, mainly attributed to software-based algorithmic advancements and hardware-assisted computation enhancements. However, those methods focus on arithmetic accelerations and overlook the benefits of the underlying system's structure. In particular, the existing decoupled software-hardware algorithm design that naively parallelizes the arithmetic operations by the hardware does not tackle the hardware overheads such as CPU-GPU and thread-to-thread communications in a principled manner. Also, the advantages of parallelizable subproblem decomposition in distributed MPC are not well recognized and exploited. As a result, we have not reached the full potential of hardware acceleration for MPC. In this paper, we explore those opportunities by leveraging GPU to parallelize the distributed and localized MPC (DLMPC) algorithm. We exploit the locality constraints embedded in the DLMPC formulation to reduce the hardware-intrinsic communication overheads. Our parallel implementation achieves up to 50x faster runtime than its CPU counterparts under various parameters. Furthermore, we find that the locality-aware GPU parallelization could halve the optimization runtime comparing to the naive acceleration. Overall, our results demonstrate the performance gains brought by software-hardware co-design with the information exchange structure in mind.      
### 84.Realistic face animation generation from videos  [ :arrow_down: ](https://arxiv.org/pdf/2103.14984.pdf)
>  3D face reconstruction and face alignment are two fundamental and highly related topics in computer vision. Recently, some works start to use deep learning models to estimate the 3DMM coefficients to reconstruct 3D face geometry. However, the performance is restricted due to the limitation of the pre-defined face templates. To address this problem, some end-to-end methods, which can completely bypass the calculation of 3DMM coefficients, are proposed and attract much attention. In this report, we introduce and analyse three state-of-the-art methods in 3D face reconstruction and face alignment. Some potential improvement on PRN are proposed to further enhance its accuracy and speed.      
### 85.On the Finite-Sample Complexity of System Identification in Temporally Homogeneous Discrete-Time Fractional-Order Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.14975.pdf)
>  Discrete-time fractional-order dynamical systems (DT-FODS) have found innumerable applications in the context of modeling spatiotemporal behaviors associated with long-term memory. Applications include neurophysiological signals such as electroencephalogram (EEG) and electrocorticogram (ECoG). Although estimating the spatiotemporal parameters of DT-FODS is not a new problem, when dealing with neurophysiological signals we need to guarantee performance standards. Therefore, we need to understand the trade-offs between sample complexity and estimation accuracy of the system parameters. Simply speaking, we need to address the question of how many measurements we need to collect to identify the system parameters up to an uncertainty level. In this paper, we address this problem under the assumption that long-term memory dependencies at the state variables level do not change over time. The main result is the first result on non-asymptotic sample complexity guarantees of identifying DT-FODS. Finally, we provide evidence of the efficacy of our method in the context of forecasting real-life EEG time series.      
### 86.Transmitter Discovery through Radio-Visual Probabilistic Active Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2103.14965.pdf)
>  Multi-modal Probabilistic Active Sensing (MMPAS) uses sensor fusion and probabilistic models to control the perception process of robotic sensing platforms. MMPAS is successfully employed in environmental exploration, collaborative mobile robotics, and target tracking, being fostered by the high performance guarantees on autonomous perception. In this context, we propose a bi-Radio-Visual PAS scheme to solve the transmitter discovery problem. Specifically, we firstly exploit the correlation between radio and visual measurements to learn a target detection model in a self-supervised manner. Then, the model is combined with antenna radiation anisotropies into a Bayesian Optimization framework that controls the platform. We show that the proposed algorithm attains an accuracy of 92%, overcoming two other probabilistic active sensing baselines.      
### 87.From Morse Triangular Form of ODE Control Systems to Feedback Canonical Form of DAE Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.14913.pdf)
>  In this paper, we relate the feedback canonical form \textbf{FNCF} of differential-algebraic control systems (DACSs) with the famous Morse canonical form \textbf{MCF} of ordinary differential equation control systems (ODECSs). First, a procedure called an explicitation (with driving variables) is proposed to connect the two above categories of control systems by attaching to a DACS a class of ODECSs with two kinds of inputs (the original control input $u$ and a vector of driving variables $v$). Then, we show that any ODECS with two kinds of inputs can be transformed into its extended \textbf{MCF} via two intermediate forms: the extended Morse triangular form and the extended Morse normal form. Next, we illustrate that the \textbf{FNCF} of a DACS and the extended \textbf{MCF} of the explicitation system have a perfect one-to-one correspondence. At last, an algorithm is proposed to transform a given DACS into its \textbf{FBCF} via the explicitation procedure and a numerical example is given to show the efficiency of the proposed algorithm.      
### 88.Feature-based Representation for Violin Bridge Admittances  [ :arrow_down: ](https://arxiv.org/pdf/2103.14895.pdf)
>  Frequency Response Functions (FRFs) are one of the cornerstones of musical acoustic experimental research. They describe the way in which musical instruments vibrate in a wide range of frequencies and are used to predict and understand the acoustic differences between them. In the specific case of stringed musical instruments such as violins, FRFs evaluated at the bridge are known to capture the overall body vibration. These indicators, also called bridge admittances, are widely used in the literature for comparative analyses. However, due to their complex structure they are rather difficult to quantitatively compare and study. In this manuscript we present a way to quantify differences between FRFs, in particular violin bridge admittances, that separates the effects in frequency, amplitude and quality factor of the first resonance peaks characterizing the responses. This approach allows us to define a distance between FRFs and clusterise measurements according to this distance. We use two case studies, one based on Finite Element Analysis and another exploiting measurements on real violins, to prove the effectiveness of such representation. In particular, for simulated bridge admittances the proposed distance is able to highlight the different impact of consecutive simulation `steps' on specific vibrational properties and, for real violins, gives a first insight on similar styles of making, as well as opposite ones.      
### 89.On TasNet for Low-Latency Single-Speaker Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2103.14882.pdf)
>  In recent years, speech processing algorithms have seen tremendous progress primarily due to the deep learning renaissance. This is especially true for speech separation where the time-domain audio separation network (TasNet) has led to significant improvements. However, for the related task of single-speaker speech enhancement, which is of obvious importance, it is yet unknown, if the TasNet architecture is equally successful. In this paper, we show that TasNet improves state-of-the-art also for speech enhancement, and that the largest gains are achieved for modulated noise sources such as speech. Furthermore, we show that TasNet learns an efficient inner-domain representation, where target and noise signal components are highly separable. This is especially true for noise in terms of interfering speech signals, which might explain why TasNet performs so well on the separation task. Additionally, we show that TasNet performs poorly for large frame hops and conjecture that aliasing might be the main cause of this performance drop. Finally, we show that TasNet consistently outperforms a state-of-the-art single-speaker speech enhancement system.      
### 90.COVID-19 personal protective equipment detection using real-time deep learning methods  [ :arrow_down: ](https://arxiv.org/pdf/2103.14878.pdf)
>  The exponential spread of COVID-19 in over 215 countries has led WHO to recommend face masks and gloves for a safe return to school or work. We used artificial intelligence and deep learning algorithms for automatic face masks and gloves detection in public areas. We investigated and assessed the efficacy of two popular deep learning algorithms of YOLO (You Only Look Once) and SSD MobileNet for the detection and proper wearing of face masks and gloves trained over a data set of 8250 images imported from the internet. YOLOv3 is implemented using the DarkNet framework, and the SSD MobileNet algorithm is applied for the development of accurate object detection. The proposed models have been developed to provide accurate multi-class detection (Mask vs. No-Mask vs. Gloves vs. No-Gloves vs. Improper). When people wear their masks improperly, the method detects them as an improper class. The introduced models provide accuracies of (90.6% for YOLO and 85.5% for SSD) for multi-class detection. The systems' results indicate the efficiency and validity of detecting people who do not wear masks and gloves in public.      
### 91.Minimum directed information: A design principle for compliant robots  [ :arrow_down: ](https://arxiv.org/pdf/2103.14830.pdf)
>  A robot's dynamics -- especially the degree and location of compliance -- can significantly affect performance and control complexity. Passive dynamics can be designed with good regions of attraction or limit cycles for a specific task, but achieving flexibility on a range of tasks requires co-design of control. This paper takes an information perspective: the robot dynamics should reduce the amount of information required for a controller to achieve a threshold of performance in a range of tasks. Towards this goal, an iterative method is proposed to minimize the directed information from state to control on discrete-time nonlinear systems. iLQG is used to find a controller and value of information, then the design parameters of the dynamics (e.g. stiffness of end-effector or joint) are optimized to reduce directed information while maintaining a minimum bound on performance. The approach is validated in simulation, on a two-mass system in contact with an uncertain wall position and a high-DOF door opening task, and shown to improve noise robustness and reduce time variance of control gains.      
### 92.Control of Agreement and Disagreement Cascades with Distributed Inputs  [ :arrow_down: ](https://arxiv.org/pdf/2103.14764.pdf)
>  For a group of autonomous communicating agents, the ability to distinguish a meaningful input from disturbance, and come to collective agreement or disagreement in response to that input, is paramount for carrying out coordinated objectives. In this work we study how a cascade of opinion formation spreads through a group of networked decision-makers in response to a distributed input signal. Using a nonlinear opinion dynamics model with dynamic feedback modulation of an attention parameter, we show how the triggering of an opinion cascade and the collective decision itself depend on both the distributed input and the node agreement and disagreement centrality, determined by the spectral properties of the network graph. We further show how the attention dynamics introduce an implicit threshold that distinguishes between distributed inputs that trigger cascades and ones that are rejected as disturbance.      
### 93.Equivariant Imaging: Learning Beyond the Range Space  [ :arrow_down: ](https://arxiv.org/pdf/2103.14756.pdf)
>  In various imaging problems, we only have access to compressed measurements of the underlying signals, hindering most learning-based strategies which usually require pairs of signals and associated measurements for training. Learning only from compressed measurements is impossible in general, as the compressed observations do not contain information outside the range of the forward sensing operator. We propose a new end-to-end self-supervised framework that overcomes this limitation by exploiting the equivariances present in natural signals. Our proposed learning strategy performs as well as fully supervised methods. Experiments demonstrate the potential of this framework on inverse problems including sparse-view X-ray computed tomography on real clinical data and image inpainting on natural images. Code will be released.      
### 94.Construction of a Large-scale Japanese ASR Corpus on TV Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2103.14736.pdf)
>  This paper presents a new large-scale Japanese speech corpus for training automatic speech recognition (ASR) systems. This corpus contains over 2,000 hours of speech with transcripts built on Japanese TV recordings and their subtitles. We develop herein an iterative workflow to extract matching audio and subtitle segments from TV recordings based on a conventional method for lightly-supervised audio-to-text alignment. We evaluate a model trained with our corpus using an evaluation dataset built on Japanese TEDx presentation videos and confirm that the performance is better than that trained with the Corpus of Spontaneous Japanese (CSJ). The experiment results show the usefulness of our corpus for training ASR systems. This corpus is made public for the research community along with Kaldi scripts for training the models reported in this paper.      
### 95.Modeling the Nonsmoothness of Modern Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.14731.pdf)
>  Modern neural networks have been successful in many regression-based tasks such as face recognition, facial landmark detection, and image generation. In this work, we investigate an intuitive but understudied characteristic of modern neural networks, namely, the nonsmoothness. The experiments using synthetic data confirm that such operations as ReLU and max pooling in modern neural networks lead to nonsmoothness. We quantify the nonsmoothness using a feature named the sum of the magnitude of peaks (SMP) and model the input-output relationships for building blocks of modern neural networks. Experimental results confirm that our model can accurately predict the statistical behaviors of the nonsmoothness as it propagates through such building blocks as the convolutional layer, the ReLU activation, and the max pooling layer. We envision that the nonsmoothness feature can potentially be used as a forensic tool for regression-based applications of neural networks.      
### 96.Almost Surely Stable Deep Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2103.14722.pdf)
>  We introduce a method for learning provably stable deep neural network based dynamic models from observed data. Specifically, we consider discrete-time stochastic dynamic models, as they are of particular interest in practical applications such as estimation and control. However, these aspects exacerbate the challenge of guaranteeing stability. Our method works by embedding a Lyapunov neural network into the dynamic model, thereby inherently satisfying the stability criterion. To this end, we propose two approaches and apply them in both the deterministic and stochastic settings: one exploits convexity of the Lyapunov function, while the other enforces stability through an implicit output layer. We demonstrate the utility of each approach through numerical examples.      
### 97.Cyclic Defense GAN Against Speech Adversarial Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2103.14717.pdf)
>  This paper proposes a new defense approach for counteracting with state-of-the-art white and black-box adversarial attack algorithms. Our approach fits in the category of implicit reactive defense algorithms since it does not directly manipulate the potentially malicious input signals. Instead, it reconstructs a similar signal with a synthesized spectrogram using a cyclic generative adversarial network. This cyclic framework helps to yield a stable generative model. Finally, we feed the reconstructed signal into the speech-to-text model for transcription. The conducted experiments on targeted and non-targeted adversarial attacks developed for attacking DeepSpeech, Kaldi, and Lingvo models demonstrate the proposed defense's effectiveness in adverse scenarios.      
### 98.Model-Free Optimal Voltage Control via Continuous-Time Zeroth-Order Methods  [ :arrow_down: ](https://arxiv.org/pdf/2103.14703.pdf)
>  In power distribution systems, the growing penetration of renewable energy resources brings new challenges to maintaining voltage safety, which is further complicated by the limited model information of distribution systems. To address these challenges, we develop a model-free optimal voltage control algorithm based on projected primal-dual gradient dynamics and continuous-time zeroth-order method (extreme seeking control). This proposed algorithm i) operates purely based on voltage measurements and does not require any other model information, ii) can drive the voltage magnitudes back to the acceptable range, iii) satisfies the power capacity constraints all the time, iv) minimizes the total operating cost, and v) is implemented in a decentralized fashion where the privacy of controllable devices is preserved and plug-and-play operation is enabled. We prove that the proposed algorithm is semi-globally practically asymptotically stable and is structurally robust to measurement noises. Lastly, the performance of the proposed algorithm is further demonstrated via numerical simulations.      
### 99.Asymmetry underlies stability in power grids  [ :arrow_down: ](https://arxiv.org/pdf/2103.10952.pdf)
>  Behavioral homogeneity is often critical for the functioning of network systems of interacting entities. In power grids, whose stable operation requires generator frequencies to be synchronized--and thus homogeneous--across the network, previous work suggests that the stability of synchronous states can be improved by making the generators homogeneous. Here, we show that a substantial additional improvement is possible by instead making the generators suitably heterogeneous. We develop a general method for attributing this counterintuitive effect to converse symmetry breaking, a recently established phenomenon in which the system must be asymmetric to maintain a stable symmetric state. These findings constitute the first demonstration of converse symmetry breaking in real-world systems, and our method promises to enable identification of this phenomenon in other networks whose functions rely on behavioral homogeneity.      

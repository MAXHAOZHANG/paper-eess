# ArXiv eess --Mon, 15 Feb 2021
### 1.Bayesian Uncertainty Estimation of Learned Variational MRI Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2102.06665.pdf)
>  Recent deep learning approaches focus on improving quantitative scores of dedicated benchmarks, and therefore only reduce the observation-related (aleatoric) uncertainty. However, the model-immanent (epistemic) uncertainty is less frequently systematically analyzed. In this work, we introduce a Bayesian variational framework to quantify the epistemic uncertainty. To this end, we solve the linear inverse problem of undersampled MRI reconstruction in a variational setting. The associated energy functional is composed of a data fidelity term and the total deep variation (TDV) as a learned parametric regularizer. To estimate the epistemic uncertainty we draw the parameters of the TDV regularizer from a multivariate Gaussian distribution, whose mean and covariance matrix are learned in a stochastic optimal control problem. In several numerical experiments, we demonstrate that our approach yields competitive results for undersampled MRI reconstruction. Moreover, we can accurately quantify the pixelwise epistemic uncertainty, which can serve radiologists as an additional resource to visualize reconstruction reliability.      
### 2.Explicit Basis Function Kernel Methods for Cloud Segmentation in Infrared Sky Images  [ :arrow_down: ](https://arxiv.org/pdf/2102.06646.pdf)
>  Photovoltaic (PV) systems are sensitive to cloud shadow projection, which needs to be forecasted to reduce the noise impacting the short-term forecast of Global Solar Irradiance (GSI). We present a comparison between different kernel discriminative models for cloud detection. The models are solved in the primal formulation to make them feasible in real-time applications. The performances are compared using the j-statistic. The Infrared (IR) images have been preprocessed to remove debris, which increases the performance of the analyzed methods. The use of the pixels neighboring features also leads to a performance improvement. Discriminative models solved in the primal yield a dramatically lower computing time along with high performance in the segmentation.      
### 3.Discrete-Time Consensus Networks: Scalability, Grounding and Countermeasures  [ :arrow_down: ](https://arxiv.org/pdf/2102.06633.pdf)
>  We investigate the disruption of discrete-time consensus problems via grounding. Loosely speaking, grounding a network occurs if the state of one agent no longer responds to inputs from other agents and/or changes its dynamics. Then, the agent becomes a leader or a so-called stubborn agent. The disruption of the agent can be caused by internal faults, safety protocols or due to an external malicious attack. In this paper we investigate how grounding affects expander graph families that usually exhibit good scaling properties with increasing network size. It is shown that the algebraic connectivity and eigenratio of the network decrease due to the grounding causing the performance and scalability of the network to deteriorate, even to the point of losing consensusability. We then present possible countermeasures to such disruptions and discuss their practicality and limitations. In particular, for a specific countermeasure of deliberately grounding additional nodes, we investigate extensively how to select additional nodes to ground and how many nodes we need to ground to recover the consensus performance. Our findings are supported by a wide range of numerical simulations.      
### 4.A Generative Model for Hallucinating Diverse Versions of Super Resolution Images  [ :arrow_down: ](https://arxiv.org/pdf/2102.06624.pdf)
>  Traditionally, the main focus of image super-resolution techniques is on recovering the most likely high-quality images from low-quality images, using a one-to-one low- to high-resolution mapping. Proceeding that way, we ignore the fact that there are generally many valid versions of high-resolution images that map to a given low-resolution image. We are tackling in this work the problem of obtaining different high-resolution versions from the same low-resolution image using Generative Adversarial Models. Our learning approach makes use of high frequencies available in the training high-resolution images for preserving and exploring in an unsupervised manner the structural information available within these images. Experimental results on the CelebA dataset confirm the effectiveness of the proposed method, which allows the generation of both realistic and diverse high-resolution images from low-resolution images.      
### 5.Enhancing into the codec: Noise Robust Speech Coding with Vector-Quantized Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2102.06610.pdf)
>  Audio codecs based on discretized neural autoencoders have recently been developed and shown to provide significantly higher compression levels for comparable quality speech output. However, these models are tightly coupled with speech content, and produce unintended outputs in noisy conditions. Based on VQ-VAE autoencoders with WaveRNN decoders, we develop compressor-enhancer encoders and accompanying decoders, and show that they operate well in noisy conditions. We also observe that a compressor-enhancer model performs better on clean speech inputs than a compressor model trained only on clean speech.      
### 6.From System Level Synthesis to Robust Closed-loop Data-enabled Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2102.06553.pdf)
>  The Willem's fundamental lemma and the system level synthesis characterize trajectories generated by a linear system. While the former method is valid for deterministic LTI systems, the latter one is further effective for stochastic linear time varying systems. In this paper, these two methods offers equivalent characterization of stochastic LTI systems. Inspired by this observation, a robust closed-loop data-enabled predictive control scheme is proposed for stochastic LTI systems. A causal feedback structure is further derived, leading to an computational cost similar to standard robust MPC with full state measurements.      
### 7.Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images  [ :arrow_down: ](https://arxiv.org/pdf/2102.06535.pdf)
>  Despite the great efforts to find an effective way for COVID-19 prediction, the virus nature and mutation represent a critical challenge to diagnose the covered cases. However, developing a model to predict COVID-19 via Chest X-Ray (CXR) images with accurate performance is necessary to help in early diagnosis. In this paper, a hybrid quantum-classical convolutional Neural Networks (HQCNN) model used the random quantum circuits (RQCs) as a base to detect COVID-19 patients with CXR images. A collection of 6952 CXR images, including 1161 COVID-19, 1575 normal, and 5216 pneumonia images, were used as a dataset in this work. The proposed HQCNN model achieved higher performance with an accuracy of 98.4\% and a sensitivity of 99.3\% on the first dataset cases. Besides, it obtained an accuracy of 99\% and a sensitivity of 99.7\% on the second dataset cases. Also, it achieved accuracy, and sensitivity of 88.6\%, and 88.7\%, respectively, on the third multi-class dataset cases. Furthermore, the HQCNN model outperforms various models in balanced accuracy, precision, F1-measure, and AUC-ROC score. The experimental results are achieved by the proposed model prove its ability in predicting positive COVID-19 cases.      
### 8.Editorial: Introduction to the Issue on Deep Learning for Image/Video Restoration and Compression  [ :arrow_down: ](https://arxiv.org/pdf/2102.06531.pdf)
>  Recent works have shown that learned models can achieve significant performance gains, especially in terms of perceptual quality measures, over traditional methods. Hence, the state of the art in image restoration and compression is getting redefined. This special issue covers the state of the art in learned image/video restoration and compression to promote further progress in innovative architectures and training methods for effective and efficient networks for image/video restoration and compression.      
### 9.Mediastinal lymph nodes segmentation using 3D convolutional neural network ensembles and anatomical priors guiding  [ :arrow_down: ](https://arxiv.org/pdf/2102.06515.pdf)
>  As lung cancer evolves, the presence of enlarged and potentially malignant lymph nodes must be assessed to properly estimate disease progression and select the best treatment strategy. Following the clinical guidelines, estimation of short-axis diameter and mediastinum station are paramount for correct diagnosis. A method for accurate and automatic segmentation is hence decisive for quantitatively describing lymph nodes. In this study, the use of 3D convolutional neural networks, either through slab-wise schemes or the leveraging of downsampled entire volumes, is investigated. Furthermore, the potential impact from simple ensemble strategies is considered. As lymph nodes have similar attenuation values to nearby anatomical structures, we suggest using the knowledge of other organs as prior information to guide the segmentation task. To assess the segmentation and instance detection performances, a 5-fold cross-validation strategy was followed over a dataset of 120 contrast-enhanced CT volumes. For the 1178 lymph nodes with a short-axis diameter $\geq10$ mm, our best performing approach reached a patient-wise recall of 92%, a false positive per patient ratio of 5, and a segmentation overlap of 80.5%. The method performs similarly well across all stations. Fusing a slab-wise and a full volume approach within an ensemble scheme generated the best performances. The anatomical priors guiding strategy is promising, yet a larger set than four organs appears needed to generate an optimal benefit. A larger dataset is also mandatory, given the wide range of expressions a lymph node can exhibit (i.e., shape, location, and attenuation), and contrast uptake variations.      
### 10.Reducing Waiting Times at Charging Stations with Adaptive Electric Vehicle Route Planning  [ :arrow_down: ](https://arxiv.org/pdf/2102.06503.pdf)
>  Electric vehicles are becoming more popular all over the world. With increasing battery capacities and a growing fast-charging infrastructure, they are becoming suitable for long distance travel. However, queues at charging stations could lead to long waiting times, making efficient route planning even more important. In general, optimal multi-objective route planning is extremely computationally expensive. We propose an adaptive charging and routing strategy, which considers driving, waiting, and charging time. For this, we developed a multi-criterion shortest-path search algorithm using contraction hierarchies. To further reduce the computational effort, we precompute shortest-path trees between the known locations of the charging stations. We propose a central charging station database (CSDB) that helps estimating waiting times at charging stations ahead of time. This enables our adaptive charging and routing strategy to reduce these waiting times. In an extensive set of simulation experiments, we demonstrate the advantages of our concept, which reduces average waiting times at charging stations by up to 97 %. Even if only a subset of the cars uses the CSDB approach, we can substantially reduce waiting times and thereby the total travel time of electric vehicles.      
### 11.Guided Variational Autoencoder for Speech Enhancement With a Supervised Classifier  [ :arrow_down: ](https://arxiv.org/pdf/2102.06454.pdf)
>  Recently, variational autoencoders have been successfully used to learn a probabilistic prior over speech signals, which is then used to perform speech enhancement. However, variational autoencoders are trained on clean speech only, which results in a limited ability of extracting the speech signal from noisy speech compared to supervised approaches. In this paper, we propose to guide the variational autoencoder with a supervised classifier separately trained on noisy speech. The estimated label is a high-level categorical variable describing the speech signal (e.g. speech activity) allowing for a more informed latent distribution compared to the standard variational autoencoder. We evaluate our method with different types of labels on real recordings of different noisy environments. Provided that the label better informs the latent distribution and that the classifier achieves good performance, the proposed approach outperforms the standard variational autoencoder and a conventional neural network-based supervised approach.      
### 12.Identification of Edge Disconnections in Networks Based on Graph Filter Outputs  [ :arrow_down: ](https://arxiv.org/pdf/2102.06428.pdf)
>  Graphs are fundamental mathematical structures used in various fields to model statistical and physical relationships between data, signals, and processes. In some applications, such as data processing in graphs that represent physical networks, the initial network topology is known. However, disconnections of edges in the network change the topology and may affect the signals and processes over the network. In this paper, we consider the problem of edge disconnection identification in networks by using concepts from graph signal processing (GSP). We assume that the graph signals measured over the vertices of the network can be represented as white noise that has been filtered on the graph topology by a smooth graph filter. We develop the likelihood ratio test (LRT) to detect a specific set of edge disconnections. Then, we provide the maximum likelihood (ML) decision rule for identifying general scenarios of edge disconnections in the network. It is shown that the sufficient statistics of the LRT and ML decision rule are the graph frequency energy levels in the graph spectral domain. However, the ML decision rule leads to a high-complexity exhaustive search over the edges in the network and is practically infeasible. Thus, we propose a low-complexity greedy method that identifies a single disconnected edge at each iteration. Moreover, by using the smoothness of the considered graph filter, we suggest a local implementation of the decision rule, which is based solely on the measurements at neighboring vertices. Simulation results demonstrate that the proposed methods outperform existing detection and identification methods.      
### 13.Mind the beat: detecting audio onsets from EEG recordings of music listening  [ :arrow_down: ](https://arxiv.org/pdf/2102.06393.pdf)
>  We propose a deep learning approach to predicting audio event onsets in electroencephalogram (EEG) recorded from users as they listen to music. We use a publicly available dataset containing ten contemporary songs and concurrently recorded EEG. We generate a sequence of onset labels for the songs in our dataset and trained neural networks (a fully connected network (FCN) and a recurrent neural network (RNN)) to parse one second windows of input EEG to predict one second windows of onsets in the audio. We compare our RNN network to both the standard spectral-flux based novelty function and the FCN. We find that our RNN was able to produce results that reflected its ability to generalize better than the other methods. <br>Since there are no pre-existing works on this topic, the numbers presented in this paper may serve as useful benchmarks for future approaches to this research problem.      
### 14.Uncertainty-Aware Semi-supervised Method using Large Unlabelled and Limited Labeled COVID-19 Data  [ :arrow_down: ](https://arxiv.org/pdf/2102.06388.pdf)
>  The new coronavirus has caused more than 1 million deaths and continues to spread rapidly. This virus targets the lungs, causing respiratory distress which can be mild or severe. The X-ray or computed tomography (CT) images of lungs can reveal whether the patient is infected with COVID-19 or not. Many researchers are trying to improve COVID-19 detection using artificial intelligence. In this paper, relying on Generative Adversarial Networks (GAN), we propose a Semi-supervised Classification using Limited Labelled Data (SCLLD) for automated COVID-19 detection. Our motivation is to develop learning method which can cope with scenarios that preparing labelled data is time consuming or expensive. We further improved the detection accuracy of the proposed method by applying Sobel edge detection. The GAN discriminator output is a probability value which is used for classification in this work. The proposed system is trained using 10,000 CT scans collected from Omid hospital. Also, we validate our system using the public dataset. The proposed method is compared with other state of the art supervised methods such as Gaussian processes. To the best of our knowledge, this is the first time a COVID-19 semi-supervised detection method is presented. Our method is capable of learning from a mixture of limited labelled and unlabelled data where supervised learners fail due to lack of sufficient amount of labelled data. Our semi-supervised training method significantly outperforms the supervised training of Convolutional Neural Network (CNN) in case labelled training data is scarce. Our method has achieved an accuracy of 99.60%, sensitivity of 99.39%, and specificity of 99.80% where CNN (trained supervised) has achieved an accuracy of 69.87%, sensitivity of 94%, and specificity of 46.40%.      
### 15.Point Cloud Resampling Through Hypergraph Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2102.06376.pdf)
>  Three-dimensional (3D) point clouds serve as an important data representation for visualization applications. The rapidly growing utility and popularity of point cloud processing strongly motivate a plethora of research activities on large-scale point cloud processing and feature extraction. In this work, we investigate point cloud resampling based on hypergraph signal processing (HGSP). We develop a novel method to extract sharp object features and reduce the size of point cloud representation. By directly estimating hypergraph spectrum based on hypergraph stationary processing, we design a spectral kernel-based filter to capture high-dimensional interactions among the signal nodes of point clouds and to better preserve their surface outlines. Experimental results validate the effectiveness of hypergraph in representing point clouds, and demonstrate the robustness of the proposed resampling method in noisy environment.      
### 16.Alternating projections gridless covariance-based estimation for DOA  [ :arrow_down: ](https://arxiv.org/pdf/2102.06372.pdf)
>  We present a gridless sparse iterative covariance-based estimation method based on alternating projections for direction-of-arrival (DOA) estimation. The gridless DOA estimation is formulated in the reconstruction of Toeplitz-structured low rank matrix, and is solved efficiently with alternating projections. The method improves resolution by achieving sparsity, deals with single-snapshot data and coherent arrivals, and, with co-prime arrays, estimates more DOAs than the number of sensors. We evaluate the proposed method using simulation results focusing on co-prime arrays.      
### 17.Data Augmentation with Signal Companding for Detection of Logical Access Attacks  [ :arrow_down: ](https://arxiv.org/pdf/2102.06332.pdf)
>  The recent advances in voice conversion (VC) and text-to-speech (TTS) make it possible to produce natural sounding speech that poses threat to automatic speaker verification (ASV) systems. To this end, research on spoofing countermeasures has gained attention to protect ASV systems from such attacks. While the advanced spoofing countermeasures are able to detect known nature of spoofing attacks, they are not that effective under unknown attacks. In this work, we propose a novel data augmentation technique using a-law and mu-law based signal companding. We believe that the proposed method has an edge over traditional data augmentation by adding small perturbation or quantization noise. The studies are conducted on ASVspoof 2019 logical access corpus using light convolutional neural network based system. We find that the proposed data augmentation technique based on signal companding outperforms the state-of-the-art spoofing countermeasures showing ability to handle unknown nature of attacks.      
### 18.Joint Dereverberation and Separation with Iterative Source Steering  [ :arrow_down: ](https://arxiv.org/pdf/2102.06322.pdf)
>  We propose a new algorithm for joint dereverberation and blind source separation (DR-BSS). Our work builds upon the IRLMA-T framework that applies a unified filter combining dereverberation and separation. One drawback of this framework is that it requires several matrix inversions, an operation inherently costly and with potential stability issues. We leverage the recently introduced iterative source steering (ISS) updates to propose two algorithms mitigating this issue. Albeit derived from first principles, the first algorithm turns out to be a natural combination of weighted prediction error (WPE) dereverberation and ISS-based BSS, applied alternatingly. In this case, we manage to reduce the number of matrix inversion to only one per iteration and source. The second algorithm updates the ILRMA-T matrix using only sequential ISS updates requiring no matrix inversion at all. Its implementation is straightforward and memory efficient. Numerical experiments demonstrate that both methods achieve the same final performance as ILRMA-T in terms of several relevant objective metrics. In the important case of two sources, the number of iterations required is also similar.      
### 19.Segmentation-Renormalized Deep Feature Modulation for Unpaired Image Harmonization  [ :arrow_down: ](https://arxiv.org/pdf/2102.06315.pdf)
>  Deep networks are now ubiquitous in large-scale multi-center imaging studies. However, the direct aggregation of images across sites is contraindicated for downstream statistical and deep learning-based image analysis due to inconsistent contrast, resolution, and noise. To this end, in the absence of paired data, variations of Cycle-consistent Generative Adversarial Networks have been used to harmonize image sets between a source and target domain. Importantly, these methods are prone to instability, contrast inversion, intractable manipulation of pathology, and steganographic mappings which limit their reliable adoption in real-world medical imaging. In this work, based on an underlying assumption that morphological shape is consistent across imaging sites, we propose a segmentation-renormalized image translation framework to reduce inter-scanner heterogeneity while preserving anatomical layout. We replace the affine transformations used in the normalization layers within generative networks with trainable scale and shift parameters conditioned on jointly learned anatomical segmentation embeddings to modulate features at every level of translation. We evaluate our methodologies against recent baselines across several imaging modalities (T1w MRI, FLAIR MRI, and OCT) on datasets with and without lesions. Segmentation-renormalization for translation GANs yields superior image harmonization as quantified by Inception distances, demonstrates improved downstream utility via post-hoc segmentation accuracy, and improved robustness to translation perturbation and self-adversarial attacks.      
### 20.DEEPF0: End-To-End Fundamental Frequency Estimation for Music and Speech Signals  [ :arrow_down: ](https://arxiv.org/pdf/2102.06306.pdf)
>  We propose a novel pitch estimation technique called DeepF0, which leverages the available annotated data to directly learns from the raw audio in a data-driven manner. F0 estimation is important in various speech processing and music information retrieval applications. Existing deep learning models for pitch estimations have relatively limited learning capabilities due to their shallow receptive field. The proposed model addresses this issue by extending the receptive field of a network by introducing the dilated convolutional blocks into the network. The dilation factor increases the network receptive field exponentially without increasing the parameters of the model exponentially. To make the training process more efficient and faster, DeepF0 is augmented with residual blocks with residual connections. Our empirical evaluation demonstrates that the proposed model outperforms the baselines in terms of raw pitch accuracy and raw chroma accuracy even using 77.4% fewer network parameters. We also show that our model can capture reasonably well pitch estimation even under the various levels of accompaniment noise.      
### 21.COVID-19 detection from scarce chest x-ray image data using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.06285.pdf)
>  In the current COVID-19 pandemic situation, there is an urgent need to screen infected patients quickly and accurately. Using deep learning models trained on chest X-ray images can become an efficient method for screening COVID-19 patients in these situations. Deep learning approaches are already widely used in the medical community. However, they require a large amount of data to be accurate. The open-source community collectively has made efforts to collect and annotate the data, but it is not enough to train an accurate deep learning model. Few-shot learning is a sub-field of machine learning that aims to learn the objective with less amount of data. In this work, we have experimented with well-known solutions for data scarcity in deep learning to detect COVID-19. These include data augmentation, transfer learning, and few-shot learning, and unsupervised learning. We have also proposed a custom few-shot learning approach to detect COVID-19 using siamese networks. Our experimental results showcased that we can implement an efficient and accurate deep learning model for COVID-19 detection by adopting the few-shot learning approaches even with less amount of data. Using our proposed approach we were able to achieve 96.4% accuracy an improvement from 83% using baseline models.      
### 22.Disentanglement for audio-visual emotion recognition using multitask setup  [ :arrow_down: ](https://arxiv.org/pdf/2102.06269.pdf)
>  Deep learning models trained on audio-visual data have been successfully used to achieve state-of-the-art performance for emotion recognition. In particular, models trained with multitask learning have shown additional performance improvements. However, such multitask models entangle information between the tasks, encoding the mutual dependencies present in label distributions in the real world data used for training. This work explores the disentanglement of multimodal signal representations for the primary task of emotion recognition and a secondary person identification task. In particular, we developed a multitask framework to extract low-dimensional embeddings that aim to capture emotion specific information, while containing minimal information related to person identity. We evaluate three different techniques for disentanglement and report results of up to 13% disentanglement while maintaining emotion recognition performance.      
### 23.An Investigation of End-to-End Models for Robust Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.06237.pdf)
>  End-to-end models for robust automatic speech recognition (ASR) have not been sufficiently well-explored in prior work. With end-to-end models, one could choose to preprocess the input speech using speech enhancement techniques and train the model using enhanced speech. Another alternative is to pass the noisy speech as input and modify the model architecture to adapt to noisy speech. A systematic comparison of these two approaches for end-to-end robust ASR has not been attempted before. We address this gap and present a detailed comparison of speech enhancement-based techniques and three different model-based adaptation techniques covering data augmentation, multi-task learning, and adversarial learning for robust ASR. While adversarial learning is the best-performing technique on certain noise types, it comes at the cost of degrading clean speech WER. On other relatively stationary noise types, a new speech enhancement technique outperformed all the model-based adaptation techniques. This suggests that knowledge of the underlying noise type can meaningfully inform the choice of adaptation technique.      
### 24.Low precision logarithmic number systems: Beyond base-2  [ :arrow_down: ](https://arxiv.org/pdf/2102.06681.pdf)
>  Logarithmic number systems (LNS) are used to represent real numbers in many applications using a constant base raised to a fixed-point exponent making its distribution exponential. This greatly simplifies hardware multiply, divide and square root. LNS with base-2 is most common, but in this paper we show that for low-precision LNS the choice of base has a significant impact. <br>We make four main contributions. First, LNS is not closed under addition and subtraction, so the result is approximate. We show that choosing a suitable base can manipulate the distribution to reduce the average error. Second, we show that low-precision LNS addition and subtraction can be implemented efficiently in logic rather than commonly used ROM lookup tables, the complexity of which can be reduced by an appropriate choice of base. A similar effect is shown where the result of arithmetic has greater precision than the input. Third, where input data from external sources is not expected to be in LNS, we can reduce the conversion error by selecting a LNS base to match the expected distribution of the input. Thus, there is no one base which gives the global optimum, and base selection is a trade-off between different factors. Fourth, we show that circuits realized in LNS require lower area and power consumption for short word lengths.      
### 25.End-to-end Audio-visual Speech Recognition with Conformers  [ :arrow_down: ](https://arxiv.org/pdf/2102.06657.pdf)
>  In this work, we present a hybrid CTC/Attention model based on a ResNet-18 and Convolution-augmented transformer (Conformer), that can be trained in an end-to-end manner. In particular, the audio and visual encoders learn to extract features directly from raw pixels and audio waveforms, respectively, which are then fed to conformers and then fusion takes place via a Multi-Layer Perceptron (MLP). The model learns to recognise characters using a combination of CTC and an attention mechanism. We show that end-to-end training, instead of using pre-computed visual features which is common in the literature, the use of a conformer, instead of a recurrent network, and the use of a transformer-based language model, significantly improve the performance of our model. We present results on the largest publicly available datasets for sentence-level speech recognition, Lip Reading Sentences 2 (LRS2) and Lip Reading Sentences 3 (LRS3), respectively. The results show that our proposed models raise the state-of-the-art performance by a large margin in audio-only, visual-only, and audio-visual experiments.      
### 26.Analysis of Interpolation based Image In-painting Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2102.06564.pdf)
>  Interpolation and internal painting are one of the basic approaches in image internal painting, which is used to eliminate undesirable parts that occur in digital images or to enhance faulty parts. This study was designed to compare the interpolation algorithms used in image in-painting in the literature. Errors and noise generated on the colour and grayscale formats of some of the commonly used standard images in the literature were corrected by using Cubic, Kriging, Radial based function and High dimensional model representation approaches and the results were compared using standard image comparison criteria, namely, PSNR (peak signal-to-noise ratio), SSIM (Structural SIMilarity), Mean Square Error (MSE). According to the results obtained from the study, the absolute superiority of the methods against each other was not observed. However, Kriging and RBF interpolation give better results both for numerical data and visual evaluation for image in-painting problems with large area losses.      
### 27.CrossStack: A 3-D Reconfigurable RRAM Crossbar Inference Engine  [ :arrow_down: ](https://arxiv.org/pdf/2102.06536.pdf)
>  Deep neural network inference accelerators are rapidly growing in importance as we turn to massively parallelized processing beyond GPUs and ASICs. The dominant operation in feedforward inference is the multiply-and-accumlate process, where each column in a crossbar generates the current response of a single neuron. As a result, memristor crossbar arrays parallelize inference and image processing tasks very efficiently. In this brief, we present a 3-D active memristor crossbar array `CrossStack', which adopts stacked pairs of Al/TiO2/TiO2-x/Al devices with common middle electrodes. By designing CMOS-memristor hybrid cells used in the layout of the array, CrossStack can operate in one of two user-configurable modes as a reconfigurable inference engine: 1) expansion mode and 2) deep-net mode. In expansion mode, the resolution of the network is doubled by increasing the number of inputs for a given chip area, reducing IR drop by 22%. In deep-net mode, inference speed per-10-bit convolution is improved by 29\% by simultaneously using one TiO2/TiO2-x layer for read processes, and the other for write processes. We experimentally verify both modes on our $10\times10\times2$ array.      
### 28.Convex Synthesis of Accelerated Gradient Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2102.06520.pdf)
>  We present a convex solution for the design of generalized accelerated gradient algorithms for strongly convex objective functions with Lipschitz continuous gradients. We utilize integral quadratic constraints and the Youla parameterization from robust control theory to formulate a solution of the algorithm design problem as a convex semi-definite program. We establish explicit formulas for the optimal convergence rates and extend the proposed synthesis solution to extremum control problems.      
### 29.Customizable Stochastic High Fidelity Model of the Sensors and Camera onboard a Low SWaP Fixed Wing Autonomous Aircraft  [ :arrow_down: ](https://arxiv.org/pdf/2102.06492.pdf)
>  The navigation systems of autonomous aircraft rely on the readings provided by a suite of onboard sensors to estimate the aircraft state. In the case of fixed wing vehicles, the sensor suite is composed by triads of accelerometers, gyroscopes, and magnetometers, a Global Navigation Satellite System (GNSS) receiver, and an air data system (Pitot tube, air vanes, thermometer, and barometer), and is often complemented by one or more digital cameras. An accurate representation of the behavior and error sources of each of these sensors, together with the images generated by the cameras, in indispensable for flight simulation and the evaluation of novel inertial or visual navigation algorithms, and more so in the case of low SWaP (size, weight, and power) aircraft, in which the quality and price of the sensors is limited. This article presents realistic and customizable models for each of these sensors, which have been implemented as an open-source C ++ simulation. Provided with the true variation of the aircraft state with time, the simulation provides a time stamped series of the errors generated by all sensors, as well as realistic images of the Earth surface that resemble those taken from a real camera flying along the indicated state positions and attitudes.      
### 30.Content-Aware Speaker Embeddings for Speaker Diarisation  [ :arrow_down: ](https://arxiv.org/pdf/2102.06467.pdf)
>  Recent speaker diarisation systems often convert variable length speech segments into fixed-length vector representations for speaker clustering, which are known as speaker embeddings. In this paper, the content-aware speaker embeddings (CASE) approach is proposed, which extends the input of the speaker classifier to include not only acoustic features but also their corresponding speech content, via phone, character, and word embeddings. Compared to alternative methods that leverage similar information, such as multitask or adversarial training, CASE factorises automatic speech recognition (ASR) from speaker recognition to focus on modelling speaker characteristics and correlations with the corresponding content units to derive more expressive representations. CASE is evaluated for speaker re-clustering with a realistic speaker diarisation setup using the AMI meeting transcription dataset, where the content information is obtained by performing ASR based on an automatic segmentation. Experimental results showed that CASE achieved a 17.8% relative speaker error rate reduction over conventional methods.      
### 31.Deep Sound Field Reconstruction in Real Rooms: Introducing the ISOBEL Sound Field Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2102.06455.pdf)
>  Knowledge of loudspeaker responses are useful in a number of applications, where a sound system is located inside a room that alters the listening experience depending on position within the room. Acquisition of sound fields for sound sources located in reverberant rooms can be achieved through labor intensive measurements of impulse response functions covering the room, or alternatively by means of reconstruction methods which can potentially require significantly fewer measurements. This paper extends evaluations of sound field reconstruction at low frequencies by introducing a dataset with measurements from four real rooms. The ISOBEL Sound Field dataset is publicly available, and aims to bridge the gap between synthetic and real-world sound fields in rectangular rooms. Moreover, the paper advances on a recent deep learning-based method for sound field reconstruction using a very low number of microphones, and proposes an approach for modeling both magnitude and phase response in a U-Net-like neural network architecture. The complex-valued sound field reconstruction demonstrates that the estimated room transfer functions are of high enough accuracy to allow for personalized sound zones with contrast ratios comparable to ideal room transfer functions using 15 microphones below 150 Hz.      
### 32.VARA-TTS: Non-Autoregressive Text-to-Speech Synthesis based on Very Deep VAE with Residual Attention  [ :arrow_down: ](https://arxiv.org/pdf/2102.06431.pdf)
>  This paper proposes VARA-TTS, a non-autoregressive (non-AR) text-to-speech (TTS) model using a very deep Variational Autoencoder (VDVAE) with Residual Attention mechanism, which refines the textual-to-acoustic alignment layer-wisely. Hierarchical latent variables with different temporal resolutions from the VDVAE are used as queries for residual attention module. By leveraging the coarse global alignment from previous attention layer as an extra input, the following attention layer can produce a refined version of alignment. This amortizes the burden of learning the textual-to-acoustic alignment among multiple attention layers and outperforms the use of only a single attention layer in robustness. An utterance-level speaking speed factor is computed by a jointly-trained speaking speed predictor, which takes the mean-pooled latent variables of the coarsest layer as input, to determine number of acoustic frames at inference. Experimental results show that VARA-TTS achieves slightly inferior speech quality to an AR counterpart Tacotron 2 but an order-of-magnitude speed-up at inference; and outperforms an analogous non-AR model, BVAE-TTS, in terms of speech quality.      
### 33.Complete Power Reallocation for MU-MIMO under Per-Antenna Power Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2102.06392.pdf)
>  This paper proposes a beamforming method under a per-antenna power constraint (PAPC). Although many beamformer designs with the PAPC need to solve complex optimization problems, the proposed complete power reallocation (CPR) method can generate beamformers with excellent performance only with linear operations. CPR is designed to have a simple structure, making it highly flexible and practical. In this paper, three CPR variations considering algorithm convergence speed, sum-rate maximization, and robustness to channel uncertainty are developed. Simulation results verify that CPR and its variations satisfy their design criteria, and, hence, CPR can be readily utilized for various purposes.      
### 34.Neural Inverse Text Normalization  [ :arrow_down: ](https://arxiv.org/pdf/2102.06380.pdf)
>  While there have been several contributions exploring state of the art techniques for text normalization, the problem of inverse text normalization (ITN) remains relatively unexplored. The best known approaches leverage finite state transducer (FST) based models which rely on manually curated rules and are hence not scalable. We propose an efficient and robust neural solution for ITN leveraging transformer based seq2seq models and FST-based text normalization techniques for data preparation. We show that this can be easily extended to other languages without the need for a linguistic expert to manually curate them. We then present a hybrid framework for integrating Neural ITN with an FST to overcome common recoverable errors in production environments. Our empirical evaluations show that the proposed solution minimizes incorrect perturbations (insertions, deletions and substitutions) to ASR output and maintains high quality even on out of domain data. A transformer based model infused with pretraining consistently achieves a lower WER across several datasets and is able to outperform baselines on English, Spanish, German and Italian datasets.      
### 35.Contrastive Unsupervised Learning for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.06357.pdf)
>  Speech emotion recognition (SER) is a key technology to enable more natural human-machine communication. However, SER has long suffered from a lack of public large-scale labeled datasets. To circumvent this problem, we investigate how unsupervised representation learning on unlabeled datasets can benefit SER. We show that the contrastive predictive coding (CPC) method can learn salient representations from unlabeled datasets, which improves emotion recognition performance. In our experiments, this method achieved state-of-the-art concordance correlation coefficient (CCC) performance for all emotion primitives (activation, valence, and dominance) on IEMOCAP. Additionally, on the MSP- Podcast dataset, our method obtained considerable performance improvements compared to baselines.      
### 36.Physics-Informed Graphical Neural Network for Parameter &amp; State Estimations in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.06349.pdf)
>  Parameter Estimation (PE) and State Estimation (SE) are the most wide-spread tasks in the system engineering. They need to be done automatically, fast and frequently, as measurements arrive. Deep Learning (DL) holds the promise of tackling the challenge, however in so far, as PE and SE in power systems is concerned, (a) DL did not win trust of the system operators because of the lack of the physics of electricity based, interpretations and (b) DL remained illusive in the operational regimes were data is scarce. To address this, we present a hybrid scheme which embeds physics modeling of power systems into Graphical Neural Networks (GNN), therefore empowering system operators with a reliable and explainable real-time predictions which can then be used to control the critical infrastructure. To enable progress towards trustworthy DL for PE and SE, we build a physics-informed method, named Power-GNN, which reconstructs physical, thus interpretable, parameters within Effective Power Flow (EPF) models, such as admittances of effective power lines, and NN parameters, representing implicitly unobserved elements of the system. In our experiments, we test the Power-GNN on different realistic power networks, including these with thousands of loads and hundreds of generators. We show that the Power-GNN outperforms vanilla NN scheme unaware of the EPF physics.      
### 37.A Multi-View Approach To Audio-Visual Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2102.06291.pdf)
>  Although speaker verification has conventionally been an audio-only task, some practical applications provide both audio and visual streams of input. In these cases, the visual stream provides complementary information and can often be leveraged in conjunction with the acoustics of speech to improve verification performance. In this study, we explore audio-visual approaches to speaker verification, starting with standard fusion techniques to learn joint audio-visual (AV) embeddings, and then propose a novel approach to handle cross-modal verification at test time. Specifically, we investigate unimodal and concatenation based AV fusion and report the lowest AV equal error rate (EER) of 0.7% on the VoxCeleb1 dataset using our best system. As these methods lack the ability to do cross-modal verification, we introduce a multi-view model which uses a shared classifier to map audio and video into the same space. This new approach achieves 28% EER on VoxCeleb1 in the challenging testing condition of cross-modal verification.      
### 38.Speech-language Pre-training for End-to-end Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2102.06283.pdf)
>  End-to-end (E2E) spoken language understanding (SLU) can infer semantics directly from speech signal without cascading an automatic speech recognizer (ASR) with a natural language understanding (NLU) module. However, paired utterance recordings and corresponding semantics may not always be available or sufficient to train an E2E SLU model in a real production environment. In this paper, we propose to unify a well-optimized E2E ASR encoder (speech) and a pre-trained language model encoder (language) into a transformer decoder. The unified speech-language pre-trained model (SLP) is continually enhanced on limited labeled data from a target domain by using a conditional masked language model (MLM) objective, and thus can effectively generate a sequence of intent, slot type, and slot value for given input speech in the inference. The experimental results on two public corpora show that our approach to E2E SLU is superior to the conventional cascaded method. It also outperforms the present state-of-the-art approaches to E2E SLU with much less paired data.      
### 39.Towards DeepSentinel: An extensible corpus of labelled Sentinel-1 and -2 imagery and a general-purpose sensor-fusion semantic embedding model  [ :arrow_down: ](https://arxiv.org/pdf/2102.06260.pdf)
>  Earth observation offers new insight into anthropogenic changes to nature, and how these changes are effecting (and are effected by) the built environment and the real economy. With the global availability of medium-resolution (10-30m) synthetic aperture radar (SAR) Sentinel-1 and multispectral Sentinel-2 imagery, machine learning can be employed to offer these insights at scale, unbiased to the reporting of companies and countries. In this paper, I introduce DeepSentinel, a data pipeline and experimentation framework for producing general-purpose semantic embeddings of paired Sentinel-1 and Sentinel-2 imagery. I document the development of an extensible corpus of labelled and unlabelled imagery for the purposes of sensor fusion research. With this new dataset I develop a set of experiments applying popular self-supervision methods and encoder architectures to a land cover classification problem. Tile2vec spatial encoding with a self-attention enabled ResNet model outperforms deeper ResNet variants as well as pretraining with variational autoencoding and contrastive loss. All supporting and derived data and code are made publicly available.      
### 40.Federated mmWave Beam Selection Utilizing LIDAR Data  [ :arrow_down: ](https://arxiv.org/pdf/2102.02802.pdf)
>  Efficient link configuration in millimeter wave (mmWave) communication systems is a crucial yet challenging task due to the overhead imposed by beam selection on the network performance. For vehicle-to-infrastructure (V2I) networks, side information from LIDAR sensors mounted on the vehicles has been leveraged to reduce the beam search overhead. In this letter, we propose distributed LIDAR aided beam selection for V2I mmWave communication systems utilizing federated training. In the proposed scheme, connected vehicles collaborate to train a shared neural network (NN) on their locally available LIDAR data during normal operation of the system. We also propose an alternative reduced-complexity convolutional NN (CNN) architecture and LIDAR preprocessing, which significantly outperforms previous works in terms of both the performance and the complexity.      
### 41.FedRec: Federated Learning of Universal Receivers over Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2011.07271.pdf)
>  Wireless communications are often subject to fading conditions. Various models have been proposed to capture the inherent randomness of fading in wireless channels, and conventional model-based receiver methods rely on accurate knowledge of this underlying distribution, which in practice may be complex and intractable. In this work we propose a collaborative neural network-based symbol detection mechanism for downlink fading channels, referred to as FedRec, which is based on the maximum a-posteriori probability (MAP) detector. To facilitate training using a limited number of pilots, while capturing a diverse ensemble of fading realizations, we propose a federated training scheme in which multiple users collaborate to jointly learn a universal data-driven detector. The performance of the resulting FedRec receiver is shown to approach the MAP performance in diverse channel conditions without requiring knowledge of the fading statistics, while inducing a substantially reduced communication overhead in its training procedure compared to training in a centralized fashion.      
### 42.CNN-based Analog CSI Feedback in FDD MIMO-OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/1910.10428.pdf)
>  Massive multiple-input multiple-output (MIMO) systems require downlink channel state information (CSI) at the base station (BS) to better utilize the available spatial diversity and multiplexing gains. However, in a frequency division duplex (FDD) massive MIMO system, CSI feedback overhead degrades the overall spectral efficiency. Convolutional neural network (CNN)-based CSI feedback compression schemes has received a lot of attention recently due to significant improvements in compression efficiency; however, they still require reliable feedback links to convey the compressed CSI information to the BS. Instead, we propose here a CNN-based analog feedback scheme, called AnalogDeepCMC, which directly maps the downlink CSI to uplink channel input. Corresponding noisy channel outputs are used by another CNN to reconstruct the DL channel estimate. Not only the proposed outperforms existing digital CSI feedback schemes in terms of the achievable downlink rate, but also simplifies the operation as it does not require explicit quantization, coding and modulation, and provides a low-latency alternative particularly in rapidly changing MIMO channels, where the CSI needs to be estimated and fed back periodically.      

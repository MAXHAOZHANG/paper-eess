# ArXiv eess --Wed, 17 Feb 2021
### 1.Convergence of Nonlinear Observers on R^n with a Riemannian Metric (Part III)  [ :arrow_down: ](https://arxiv.org/pdf/2102.08340.pdf)
>  We consider observers contracting a Riemannian distance between the state of the system and its estimate. As shown in [1], such a contraction property holds if the system dynamics and the Riemannian metric satisfy two conditions: a differential detectability property (Condition A2 in [2]), and a geodesic monotonicity property (Condition A3 in [2]). Condition A2 is thoroughly studied in [2]. In this paper, we study Condition A3 in relationship to the nullity of the second fundamental form of the output function. We formulate sufficient and necessary conditions for Condition A3 to hold. We establish a link between Condition A3 and the infinite gain margin property, and we provide a systematic way for constructing a metric satisfying this condition. Finally, we illustrate cases where both the first and the second conditions hold and propose ways to facilitate the satisfaction of these two conditions together.      
### 2.Context-Aware Prosody Correction for Text-Based Speech Editing  [ :arrow_down: ](https://arxiv.org/pdf/2102.08328.pdf)
>  Text-based speech editors expedite the process of editing speech recordings by permitting editing via intuitive cut, copy, and paste operations on a speech transcript. A major drawback of current systems, however, is that edited recordings often sound unnatural because of prosody mismatches around edited regions. In our work, we propose a new context-aware method for more natural sounding text-based editing of speech. To do so, we 1) use a series of neural networks to generate salient prosody features that are dependent on the prosody of speech surrounding the edit and amenable to fine-grained user control 2) use the generated features to control a standard pitch-shift and time-stretch method and 3) apply a denoising neural network to remove artifacts induced by the signal manipulation to yield a high-fidelity result. We evaluate our approach using a subjective listening test, provide a detailed comparative analysis, and conclude several interesting insights.      
### 3.On Mathews Correlation Coefficient and Improved Distance Map Loss for Automatic Glacier Calving Front Segmentation in SAR Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2102.08312.pdf)
>  The vast majority of the outlet glaciers and ice streams of the polar ice sheets end in the ocean. Ice mass loss via calving of the glaciers into the ocean has increased over the last few decades. Information on the temporal variability of the calving front position provides fundamental information on the state of the glacier and ice stream, which can be exploited as calibration and validation data to enhance ice dynamics modeling. To identify the calving front position automatically, deep neural network-based semantic segmentation pipelines can be used to delineate the acquired SAR imagery. However, the extreme class imbalance is highly challenging for the accurate calving front segmentation in these images. Therefore, we propose the use of the Mathews correlation coefficient (MCC) as an early stopping criterion because of its symmetrical properties and its invariance towards class imbalance. Moreover, we propose an improvement to the distance map-based binary cross-entropy (BCE) loss function. The distance map adds context to the loss function about the important regions for segmentation and helps accounting for the imbalanced data. Using Mathews correlation coefficient as early stopping demonstrates an average 15% dice coefficient improvement compared to the commonly used BCE. The modified distance map loss further improves the segmentation performance by another 2%. These results are encouraging as they support the effectiveness of the proposed methods for segmentation problems suffering from extreme class imbalances.      
### 4.Robust multi-rate predictive control using multi-step prediction models learned from data  [ :arrow_down: ](https://arxiv.org/pdf/2102.08302.pdf)
>  This note extends a recently proposed algorithm for model identification and robust MPC of asymptotically stable, linear time-invariant systems subject to process and measurement disturbances. Independent output predictors for different steps ahead are estimated with Set Membership methods. It is here shown that the corresponding prediction error bounds are the least conservative in the considered model class. Then, a new multi-rate robust MPC algorithm is developed, employing said multi-step predictors to robustly enforce constraints and stability against disturbances and model uncertainty, and to reduce conservativeness. A simulation example illustrates the effectiveness of the approach.      
### 5.Going Beyond Saliency Maps: Training Deep Models to Interpret Deep Models  [ :arrow_down: ](https://arxiv.org/pdf/2102.08239.pdf)
>  Interpretability is a critical factor in applying complex deep learning models to advance the understanding of brain disorders in neuroimaging studies. To interpret the decision process of a trained classifier, existing techniques typically rely on saliency maps to quantify the voxel-wise or feature-level importance for classification through partial derivatives. Despite providing some level of localization, these maps are not human-understandable from the neuroscience perspective as they do not inform the specific meaning of the alteration linked to the brain disorder. Inspired by the image-to-image translation scheme, we propose to train simulator networks that can warp a given image to inject or remove patterns of the disease. These networks are trained such that the classifier produces consistently increased or decreased prediction logits for the simulated images. Moreover, we propose to couple all the simulators into a unified model based on conditional convolution. We applied our approach to interpreting classifiers trained on a synthetic dataset and two neuroimaging datasets to visualize the effect of the Alzheimer's disease and alcohol use disorder. Compared to the saliency maps generated by baseline approaches, our simulations and visualizations based on the Jacobian determinants of the warping field reveal meaningful and understandable patterns related to the diseases.      
### 6.Usability Aware Secret Protection with Minimum Cost  [ :arrow_down: ](https://arxiv.org/pdf/2102.08234.pdf)
>  In this paper we study a cybersecurity problem of protecting system's secrets with multiple protections and a required security level, while minimizing the associated cost due to implementation/maintenance of these protections as well as the affected system usability. The target system is modeled as a discrete-event system (DES) in which there are a subset of marker states denoting the services/functions provided to regular users, a subset of secret states, and multiple subsets of protectable events with different security levels. We first introduce usability-aware cost levels for the protectable events, and then formulate the security problem as to ensure that every system trajectory that reaches a secret state contains a specified number of protectable events with at least a certain security level, and the highest usability-aware cost level of these events is minimum. We first provide a necessary and sufficient condition under which this security problem is solvable, and when this condition holds we propose an algorithm to solve the problem based on the supervisory control theory of DES. Moreover, we extend the problem to the case of heterogeneous secrets with different levels of importance, and develop an algorithm to solve this extended problem. Finally, we demonstrate the effectiveness of our solutions with a network security example.      
### 7.Four Generations of Control Theory Development ?  [ :arrow_down: ](https://arxiv.org/pdf/2102.08190.pdf)
>  This short article presents an opinion that control system study up to date can be divided into four generations; namely, 1 transfer function based; 2 state-space based; 3 networked control systems; and 4 control in the new AI era.      
### 8.Beyond multi-view deconvolution for inherently-aligned fluorescence tomography  [ :arrow_down: ](https://arxiv.org/pdf/2102.08177.pdf)
>  In multi-view fluorescence microscopy, each angular acquisition needs to be aligned with care to obtain an optimal volumetric reconstruction. Here, instead, we propose a neat protocol based on auto-correlation inversion, that leads directly to the formation of inherently aligned tomographies. Our method generates sharp reconstructions, with the same accuracy reachable after sub-pixel alignment but with improved point-spread-function. The procedure can be performed simultaneously with deconvolution further increasing the reconstruction resolution.      
### 9.Transmitter Selection for Secrecy in Cognitive Small-Cell Networks with Backhaul Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2102.08119.pdf)
>  A small-cell network with multiple transmitters and unreliable wireless backhaul is considered for secrecy enhancement. The small-cell network is operating under a spectrum sharing agreement with a primary network in a cognitive radio system. A constraint on the desired outage probability at the primary receiver is assumed as a part of the spectrum sharing agreement. The reliability of the wireless backhaul links are modeled by a set of independent and identically distributed Bernoulli random variables. A sub-optimal and an optimal small-cell transmitter selection (TS) scheme is proposed to improve the performance of the system, depending on the availability of channel state information. Selection schemes are designed for the scenario where knowledge is available regarding which backhaul links are active. The corresponding secrecy outage probabilities along with their asymptotic expressions are derived. It is shown that the secrecy performance is significantly improved compared to the case where knowledge of the active backhaul links is unavailable.      
### 10.Recurrent Neural Network Assisted Transmitter Selection for Secrecy in Cognitive Radio Network  [ :arrow_down: ](https://arxiv.org/pdf/2102.08118.pdf)
>  In this paper, we apply the long short-term memory (LSTM), an advanced recurrent neural network based machine learning (ML) technique, to the problem of transmitter selection (TS) for secrecy in an underlay small-cell cognitive radio network with unreliable backhaul connections. The cognitive communication scenario under consideration has a secondary small-cell network that shares the same spectrum of the primary network with an agreement to always maintain a desired outage probability constraint in the primary network. Due to the interference from the secondary transmitter common to all primary transmissions, the secrecy rates for the different transmitters are correlated. LSTM exploits this correlation and matches the performance of the conventional technique when the number of transmitters is small. As the number grows, the performance degrades in the same manner as other ML techniques such as support vector machine, $k$-nearest neighbors, naive Bayes, and deep neural network. However, LSTM still significantly outperforms these techniques in misclassification ratio and secrecy outage probability. It also reduces the feedback overhead against conventional TS.      
### 11.Axial Residual Networks for CycleGAN-based Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2102.08075.pdf)
>  We propose a novel architecture and improved training objectives for non-parallel voice conversion. Our proposed CycleGAN-based model performs a shape-preserving transformation directly on a high frequency-resolution magnitude spectrogram, converting its style (i.e. speaker identity) while preserving the speech content. Throughout the entire conversion process, the model does not resort to compressed intermediate representations of any sort (e.g. mel spectrogram, low resolution spectrogram, decomposed network feature). We propose an efficient axial residual block architecture to support this expensive procedure and various modifications to the CycleGAN losses to stabilize the training process. We demonstrate via experiments that our proposed model outperforms Scyclone and shows a comparable or better performance to that of CycleGAN-VC2 even without employing a neural vocoder.      
### 12.On the use of generative deep neural networks to synthesize artificial multichannel EEG signals  [ :arrow_down: ](https://arxiv.org/pdf/2102.08061.pdf)
>  Recent promises of generative deep learning lately brought interest to its potential uses in neural engineering. In this paper we firstly review recently emerging studies on generating artificial electroencephalography (EEG) signals with deep neural networks. Subsequently, we present our feasibility experiments on generating condition-specific multichannel EEG signals using conditional variational autoencoders. By manipulating real resting-state EEG epochs, we present an approach to synthetically generate time-series multichannel signals that show spectro-temporal EEG patterns which are expected to be observed during distinct motor imagery conditions.      
### 13.Deep Learning Approach for Target Locating in Through-the-Wall Radar under Electromagnetic Complex Wall  [ :arrow_down: ](https://arxiv.org/pdf/2102.07990.pdf)
>  In this paper, we used the deep learning approach to perform two-dimensional, multi-target locating in Throughthe-Wall Radar under conditions where the wall is modeled as a complex electromagnetic media. We have assumed 5 models for the wall and 3 modes for the number of targets. The target modes are single, double and triple. The wall scenarios are homogeneous wall, wall with airgap, inhomogeneous wall, anisotropic wall and inhomogeneous-anisotropic wall. For this purpose, we have used the deep neural network algorithm. Using the Python FDTD library, we generated a dataset, and then modeled it with deep learning. Assuming the wall as a complex electromagnetic media, we achieved 97:7% accuracy for single-target 2D locating, and for two-targets, three-targets we achieved an accuracy of 94:1% and 62:2%, respectively.      
### 14.Semi-Supervised Singing Voice Separation with Noisy Self-Training  [ :arrow_down: ](https://arxiv.org/pdf/2102.07961.pdf)
>  Recent progress in singing voice separation has primarily focused on supervised deep learning methods. However, the scarcity of ground-truth data with clean musical sources has been a problem for long. Given a limited set of labeled data, we present a method to leverage a large volume of unlabeled data to improve the model's performance. Following the noisy self-training framework, we first train a teacher network on the small labeled dataset and infer pseudo-labels from the large corpus of unlabeled mixtures. Then, a larger student network is trained on combined ground-truth and self-labeled datasets. Empirical results show that the proposed self-training scheme, along with data augmentation methods, effectively leverage the large unlabeled corpus and obtain superior performance compared to supervised methods.      
### 15.Deep Learning based Multi-Source Localization with Source Splitting and its Effectiveness in Multi-Talker Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.07955.pdf)
>  Multi-source localization is an important and challenging technique for multi-talker conversation analysis. This paper proposes a novel supervised learning method using deep neural networks to estimate the direction of arrival (DOA) of all the speakers simultaneously from the audio mixture. At the heart of the proposal is a source splitting mechanism that creates source-specific intermediate representations inside the network. This allows our model to give source-specific posteriors as the output unlike the traditional multi-label classification approach. Existing deep learning methods perform a frame level prediction, whereas our approach performs an utterance level prediction by incorporating temporal selection and averaging inside the network to avoid post-processing. We also experiment with various loss functions and show that a variant of earth mover distance (EMD) is very effective in classifying DOA at a very high resolution by modeling inter-class relationships. In addition to using the prediction error as a metric for evaluating our localization model, we also establish its potency as a frontend with automatic speech recognition (ASR) as the downstream task. We convert the estimated DOAs into a feature suitable for ASR and pass it as an additional input feature to a strong multi-channel and multi-talker speech recognition baseline. This added input feature drastically improves the ASR performance and gives a word error rate (WER) of 6.3% on the evaluation data of our simulated noisy two speaker mixtures, while the baseline which doesn't use explicit localization input has a WER of 11.5%. We also perform ASR evaluation on real recordings with the overlapped set of the MC-WSJ-AV corpus in addition to simulated mixtures.      
### 16.Deep Equilibrium Architectures for Inverse Problems in Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2102.07944.pdf)
>  Recent efforts on solving inverse problems in imaging via deep neural networks use architectures inspired by a fixed number of iterations of an optimization method. The number of iterations is typically quite small due to difficulties in training networks corresponding to more iterations; the resulting solvers cannot be run for more iterations at test time without incurring significant errors. This paper describes an alternative approach corresponding to an {\em infinite} number of iterations, yielding up to a 4dB PSNR improvement in reconstruction accuracy above state-of-the-art alternatives and where the computational budget can be selected at test time to optimize context-dependent trade-offs between accuracy and computation. The proposed approach leverages ideas from Deep Equilibrium Models, where the fixed-point iteration is constructed to incorporate a known forward model and insights from classical optimization-based reconstruction methods.      
### 17.Attitude Trajectory Optimization for Agile Satellites in Autonomous Remote Sensing Constellation  [ :arrow_down: ](https://arxiv.org/pdf/2102.07940.pdf)
>  Agile attitude maneuvering maximizes the utility of remote sensing satellite constellations. By taking into account a satellite's physical properties and its actuator specifications, we may leverage the full performance potential of the attitude control system to conduct agile remote sensing beyond conventional slew-and-stabilize maneuvers. Employing a constellation of agile satellites, coordinated by an autonomous and responsive scheduler, can significantly increase overall response rate, revisit time and global coverage for the mission. In this paper, we use recent advances in sequential convex programming based trajectory optimization to enable rapid-target acquisition, pointing and tracking capabilities for a scheduler-based constellation. We present two problem formulations. The Minimum-Time Slew Optimal Control Problem determines the minimum time, required energy, and optimal trajectory to slew between any two orientations given nonlinear quaternion kinematics, gyrostat and actuator dynamics, and state/input constraints. By gridding the space of 3D rotations and efficiently solving this problem on the grid, we produce lookup tables or parametric fits off-line that can then be used on-line by a scheduler to compute accurate estimates of minimum-time and maneuver energy for real-time constellation scheduling. The Minimum-Effort Multi-Target Pointing Optimal Control Problem is used on-line by each satellite to produce continuous attitude-state and control-input trajectories that realize a given schedule while minimizing attitude error and control effort. The optimal trajectory may then be achieved by a low-level tracking controller. We demonstrate our approach with an example of a reference satellite in Sun-synchronous orbit passing over globally-distributed, Earth-observation targets.      
### 18.A Deep-Learning Approach For Direct Whole-Heart Mesh Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2102.07899.pdf)
>  Automated construction of surface geometries of cardiac structures from volumetric medical images is important for a number of clinical applications. While deep-learning based approaches have demonstrated promising reconstruction precision, these approaches have mostly focused on voxel-wise segmentation followed by surface reconstruction and post-processing techniques. However, such approaches suffer from a number of limitations including disconnected regions or incorrect surface topology due to erroneous segmentation and stair-case artifacts due to limited segmentation resolution. We propose a novel deep-learning-based approach that directly predicts whole heart surface meshes from volumetric CT and MR image data. Our approach leverages a graph convolutional neural network to predict deformation on mesh vertices from a pre-defined mesh template to reconstruct multiple anatomical structures in a 3D image volume. Our method demonstrated promising performance of generating high-resolution and high-quality whole heart reconstructions and outperformed prior deep-learning based methods on both CT and MR data in terms of precision and surface quality. Furthermore, our method can more efficiently produce temporally-consistent and feature-corresponding surface mesh predictions for heart motion from CT or MR cine sequences, and therefore can potentially be applied for efficiently constructing 4D whole heart dynamics.      
### 19.A multispeaker dataset of raw and reconstructed speech production real-time MRI video and 3D volumetric images  [ :arrow_down: ](https://arxiv.org/pdf/2102.07896.pdf)
>  Real-time magnetic resonance imaging (RT-MRI) of human speech production is enabling significant advances in speech science, linguistics, bio-inspired speech technology development, and clinical applications. Easy access to RT-MRI is however limited, and comprehensive datasets with broad access are needed to catalyze research across numerous domains. The imaging of the rapidly moving articulators and dynamic airway shaping during speech demands high spatio-temporal resolution and robust reconstruction methods. Further, while reconstructed images have been published, to-date there is no open dataset providing raw multi-coil RT-MRI data from an optimized speech production experimental setup. Such datasets could enable new and improved methods for dynamic image reconstruction, artifact correction, feature extraction, and direct extraction of linguistically-relevant biomarkers. The present dataset offers a unique corpus of 2D sagittal-view RT-MRI videos along with synchronized audio for 75 subjects performing linguistically motivated speech tasks, alongside the corresponding first-ever public domain raw RT-MRI data. The dataset also includes 3D volumetric vocal tract MRI during sustained speech sounds and high-resolution static anatomical T2-weighted upper airway MRI for each subject.      
### 20.Pre-demosaic Graph-based Light Field Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2102.07883.pdf)
>  A plenoptic light field (LF) camera places an array of microlenses in front of an image sensor in order to separately capture different directional rays arriving at an image pixel. Using a conventional Bayer pattern, data captured at each pixel is a single color component (R, G or B). The sensed data then undergoes demosaicking (interpolation of RGB components per pixel) and conversion to an array of sub-aperture images (SAIs). In this paper, we propose a new LF image coding scheme based on graph lifting transform (GLT), where the acquired sensor data are coded in the original captured form without pre-processing. Specifically, we directly map raw sensed color data to the SAIs, resulting in sparsely distributed color pixels on 2D grids, and perform demosaicking at the receiver after decoding. To exploit spatial correlation among the sparse pixels, we propose a novel intra-prediction scheme, where the prediction kernel is determined according to the local gradient estimated from already coded neighboring pixel blocks. We then connect the pixels by forming a graph, modeling the prediction residuals statistically as a Gaussian Markov Random Field (GMRF). The optimal edge weights are computed via a graph learning method using a set of training SAIs. The residual data is encoded via low-complexity GLT. Experiments show that at high PSNRs -- important for archiving and instant storage scenarios -- our method outperformed significantly a conventional light field image coding scheme with demosaicking followed by High Efficiency Video Coding (HEVC).      
### 21.Large Deviations Principle for Discrete-time Mean-field Games  [ :arrow_down: ](https://arxiv.org/pdf/2102.07865.pdf)
>  In this paper, under continuity of state-action dynamics, we establish a large deviations principle (LDP) for discrete-time mean-field games. The proof is based on transferring LDP for empirical measures of initial states and noise variables to the original game model via contraction principle, which was first suggested by Delarue, Lacker, and Ramanan to establish LDP for continuous-time mean-field games under common noise. We also compare our work with LDP results established in prior literature for interacting particle systems, which are in a sense uncontrolled versions of mean-field games.      
### 22.Dynamics and Control of a Flapping Wing UAV with Abdomen Undulation Inspired by Monarch Butterfly  [ :arrow_down: ](https://arxiv.org/pdf/2102.07851.pdf)
>  This paper presents a dynamic model and a control system for a flapping-wing unmanned aerial vehicle. Inspired by flight characteristics captured from live Monarch butterflies, a new dynamic model is presented to account the effects of low-frequency flapping and abdomen undulation. We developed it according to Lagrangian mechanics on a Lie group to obtain an elegant, global formulation of dynamics. Then, a feedback control system is presented to asymptotically stabilize periodic motions with active motion of abdomen, and its stability is verified according to Floquet theory. In particular, it is illustrated that the abdomen undulation has the desirable effects of reducing the variation of the total energy and also improving the stability of the proposed control system.      
### 23.Optimal Power Flow Considering Time of Use and Real-Time Pricing Demand Response Programs  [ :arrow_down: ](https://arxiv.org/pdf/2102.07828.pdf)
>  In recent years, the implementation of the demand response (DR) programs in the power systems scheduling and operation is increased. DR is used to improve the consumers' and power providers economic condition. That said, optimal power flow is a fundamental concept in the power system operation and control. The impact of exploiting DR programs in the power management of the systems is of significant importance. In this paper, the effect of time-based DR programs on the cost of 24-hour operation of a power system is presented. The effect of the time of use and real-time pricing programs with different participation factors are investigated. In addition, the systems operation cost is studied to analyze the DR programs' role in the current power grids. For this aim, the 14-bus IEEE test system is used to properly implement and simulate the proposed approach.      
### 24.Girasol, a Sky Imaging and Global Solar Irradiance Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2102.07814.pdf)
>  The energy available in Micro Grid (MG) that is powered by solar energy is tightly related to the weather conditions in the moment of generation. Very short-term forecast of solar irradiance provides the MG with the capability of automatically controlling the dispatch of energy. We propose to achieve this using a data acquisition systems (DAQ) that simultaneously records sky imaging and Global Solar Irradiance (GSI) measurements, with the objective of extracting features from clouds and use them to forecast the power produced by a Photovoltaic (PV) system. The DAQ system is nicknamed as the \emph{Girasol Machine} (Girasol means Sunflower in Spanish). The sky imaging system consists of a longwave infrared (IR) camera and a visible (VI) light camera with a fisheye lens attached to it. The cameras are installed inside a weatherproof enclosure that it is mounted on an outdoor tracker. The tracker updates its pan an tilt every second using a solar position algorithm to maintain the Sun in the center of the IR and VI images. A pyranometer is situated on a horizontal support next to the DAQ system to measure GSI. The dataset, composed of IR images, VI images, GSI measurements, and the Sun's positions, has been tagged with timestamps.      
### 25.Enhancing the Spatio-temporal Observability of Grid-Edge Resources in Distribution Grids  [ :arrow_down: ](https://arxiv.org/pdf/2102.07801.pdf)
>  Enhancing the spatio-temporal observability of distributed energy resources (DERs) is crucial for achieving secure and efficient operations in distribution grids. This paper puts forth a joint recovery framework for residential loads by leveraging the complimentary strengths of heterogeneous types of measurements. The proposed approaches integrate the low-resolution smart meter data collected for every load node with the fast-sampled feeder-level measurements provided by limited number of phasor measurement units. To address the lack of data, we exploit two key characteristics for the loads and DERs, namely the sparse changes due to infrequent activities of appliances and electric vehicles (EVs) and the locational dependence of solar photovoltaic (PV) generation. Accordingly, meaningful regularization terms are introduced to cast a convex load recovery problem, which will be further simplified to reduce computational complexity. The load recovery solutions can be utilized to identify the EV charging events at each load node and to infer the total behind-the-meter PV output. Numerical tests using real-world data have demonstrated the effectiveness of the proposed approaches in enhancing the visibility of these grid-edge DERs.      
### 26.PeriodNet: A non-autoregressive waveform generation model with a structure separating periodic and aperiodic components  [ :arrow_down: ](https://arxiv.org/pdf/2102.07786.pdf)
>  We propose PeriodNet, a non-autoregressive (non-AR) waveform generation model with a new model structure for modeling periodic and aperiodic components in speech waveforms. The non-AR waveform generation models can generate speech waveforms parallelly and can be used as a speech vocoder by conditioning an acoustic feature. Since a speech waveform contains periodic and aperiodic components, both components should be appropriately modeled to generate a high-quality speech waveform. However, it is difficult to decompose the components from a natural speech waveform in advance. To address this issue, we propose a parallel model and a series model structure separating periodic and aperiodic components. The features of our proposed models are that explicit periodic and aperiodic signals are taken as input, and external periodic/aperiodic decomposition is not needed in training. Experiments using a singing voice corpus show that our proposed structure improves the naturalness of the generated waveform. We also show that the speech waveforms with a pitch outside of the training data range can be generated with more naturalness.      
### 27.End-2-End COVID-19 Detection from Breath &amp; Cough Audio  [ :arrow_down: ](https://arxiv.org/pdf/2102.08359.pdf)
>  Our main contributions are as follows: (I) We demonstrate the first attempt to diagnose COVID-19 using end-to-end deep learning from a crowd-sourced dataset of audio samples, achieving ROC-AUC of 0.846; (II) Our model, the COVID-19 Identification ResNet, (CIdeR), has potential for rapid scalability, minimal cost and improving performance as more data becomes available. This could enable regular COVID-19 testing at apopulation scale; (III) We introduce a novel modelling strategy using a custom deep neural network to diagnose COVID-19 from a joint breath and cough representation; (IV) We release our four stratified folds for cross parameter optimisation and validation on a standard public corpus and details on the models for reproducibility and future reference.      
### 28.Successive Pruning for Model Compression via Rate Distortion Theory  [ :arrow_down: ](https://arxiv.org/pdf/2102.08329.pdf)
>  Neural network (NN) compression has become essential to enable deploying over-parameterized NN models on resource-constrained devices. As a simple and easy-to-implement method, pruning is one of the most established NN compression techniques. Although it is a mature method with more than 30 years of history, there is still a lack of good understanding and systematic analysis of why pruning works well even with aggressive compression ratios. In this work, we answer this question by studying NN compression from an information-theoretic approach and show that rate distortion theory suggests pruning to achieve the theoretical limits of NN compression. Our derivation also provides an end-to-end compression pipeline involving a novel pruning strategy. That is, in addition to pruning the model, we also find a minimum-length binary representation of it via entropy coding. Our method consistently outperforms the existing pruning strategies and reduces the pruned model's size by 2.5 times. We evaluate the efficacy of our strategy on MNIST, CIFAR-10 and ImageNet datasets using 5 distinct architectures.      
### 29.Sidelobe Modification for Reflector Antennas by Electronically-Reconfigurable Rim Scattering  [ :arrow_down: ](https://arxiv.org/pdf/2102.08274.pdf)
>  Dynamic modification of the pattern of a reflector antenna system traditionally requires an array of feeds. This paper presents an alternative approach in which the scattering from a fraction of the reflector around the rim is passively modified using, for example, an electronically-reconfigurable reflectarray. This facilitates flexible sidelobe modification, including sidelobe canceling, for systems employing a single feed. Applications for such a system include radio astronomy, where deleterious levels of interference from satellites enter through sidelobes. We show that an efficient reconfigurable surface occupying about 11% of the area around the rim of an axisymmetric circular paraboloidal reflector antenna fed from the prime focus is sufficient to null interference arriving from any direction outside the main lobe with at most 0.3% and potentially zero change in main lobe gain. We further show that the required surface area is independent of frequency and that the same performance can be obtained using 1-bit phase control of the constituent unit cells for a reconfigurable surface occupying an additional 6% of the reflector surface.      
### 30.Optimal Mixed Discrete-Continuous Planningfor Linear Hybrid Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.08261.pdf)
>  Planning in hybrid systems with both discrete and continuous control variables is important for dealing with real-world applications such as extra-planetary exploration and multi-vehicle transportation systems. Meanwhile, generating high-quality solutions given certain hybrid planning specifications is crucial to building high-performance hybrid systems. However, since hybrid planning is challenging in general, most methods use greedy search that is guided by various heuristics, which is neither complete nor optimal and often falls into blind search towards an infinite-action plan. In this paper, we present a hybrid automaton planning formalism and propose an optimal approach that encodes this planning problem as a Mixed Integer Linear Program (MILP) by fixing the action number of automaton runs. We also show an extension of our approach for reasoning over temporally concurrent goals. By leveraging an efficient MILP optimizer, our method is able to generate provably optimal solutions for complex mixed discrete-continuous planning problems within a reasonable time. We use several case studies to demonstrate the extraordinary performance of our hybrid planning method and show that it outperforms a state-of-the-art hybrid planner, Scotty, in both efficiency and solution qualities.      
### 31.Probabilistic Localization of Insect-Scale Drones on Floating-Gate Inverter Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2102.08247.pdf)
>  We propose a novel compute-in-memory (CIM)-based ultra-low-power framework for probabilistic localization of insect-scale drones. The conventional probabilistic localization approaches rely on the three-dimensional (3D) Gaussian Mixture Model (GMM)-based representation of a 3D map. A GMM model with hundreds of mixture functions is typically needed to adequately learn and represent the intricacies of the map. Meanwhile, localization using complex GMM map models is computationally intensive. Since insect-scale drones operate under extremely limited area/power budget, continuous localization using GMM models entails much higher operating energy -- thereby, limiting flying duration and/or size of the drone due to a larger battery. Addressing the computational challenges of localization in an insect-scale drone using a CIM approach, we propose a novel framework of 3D map representation using a harmonic mean of "Gaussian-like" mixture (HMGM) model. The likelihood function useful for drone localization can be efficiently implemented by connecting many multi-input inverters in parallel, each programmed with the parameters of the 3D map model represented as HMGM. When the depth measurements are projected to the input of the implementation, the summed current of the inverters emulates the likelihood of the measurement. We have characterized our approach on an RGB-D indoor localization dataset. The average localization error in our approach is $\sim$0.1125 m which is only slightly degraded than software-based evaluation ($\sim$0.08 m). Meanwhile, our localization framework is ultra-low-power, consuming as little as $\sim$17 $\mu$W power while processing a depth frame in 1.33 ms over hundred pose hypotheses in the particle-filtering (PF) algorithm used to localize the drone.      
### 32.A Novel Stochastic Epidemic Model with Application to COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2102.08213.pdf)
>  In this paper we propose a novel SEIR stochastic epidemic model. A distinguishing feature of this new model is that it allows us to consider a set up under general latency and infectious period distributions. To some extent, queuing systems with infinitely many servers and a Markov chain with time-varying transition rate are the very technical underpinning of the paper. Although more general, the Markov chain is as tractable as previous models for exponentially distributed latency and infection periods. It is also significantly simpler and more tractable than semi-Markov models with a similar level of generality. Based on the notion of stochastic stability, we derive a sufficient condition for a shrinking epidemic in terms of the queuing system's occupation rate that drives the dynamics. Relying on this condition, we propose a class of ad-hoc stabilising mitigation strategies that seek to keep a balanced occupation rate after a prescribed mitigation-free period. We validate the approach in the light of recent data on the COVID-19 epidemic and assess the effect of different stabilising strategies. The results suggest that it is possible to curb the epidemic with various occupation rate levels, as long as the mitigation is not excessively procrastinated.      
### 33.Improper Learning with Gradient-based Policy Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2102.08201.pdf)
>  We consider an improper reinforcement learning setting where the learner is given M base controllers for an unknown Markov Decision Process, and wishes to combine them optimally to produce a potentially new controller that can outperform each of the base ones. We propose a gradient-based approach that operates over a class of improper mixtures of the controllers. The value function of the mixture and its gradient may not be available in closed-form; however, we show that we can employ rollouts and simultaneous perturbation stochastic approximation (SPSA) for explicit gradient descent optimization. We derive convergence and convergence rate guarantees for the approach assuming access to a gradient oracle. Numerical results on a challenging constrained queueing task show that our improper policy optimization algorithm can stabilize the system even when each constituent policy at its disposal is unstable.      
### 34.A Survey on 360-Degree Video: Coding, Quality of Experience and Streaming  [ :arrow_down: ](https://arxiv.org/pdf/2102.08192.pdf)
>  The commercialization of Virtual Reality (VR) headsets has made immersive and 360-degree video streaming the subject of intense interest in the industry and research communities. While the basic principles of video streaming are the same, immersive video presents a set of specific challenges that need to be addressed. In this survey, we present the latest developments in the relevant literature on four of the most important ones: (i) omnidirectional video coding and compression, (ii) subjective and objective Quality of Experience (QoE) and the factors that can affect it, (iii) saliency measurement and Field of View (FoV) prediction, and (iv) the adaptive streaming of immersive 360-degree videos. The final objective of the survey is to provide an overview of the research on all the elements of an immersive video streaming system, giving the reader an understanding of their interplay and performance.      
### 35.Improving Deep-learning-based Semi-supervised Audio Tagging with Mixup  [ :arrow_down: ](https://arxiv.org/pdf/2102.08183.pdf)
>  Recently, semi-supervised learning (SSL) methods, in the framework of deep learning (DL), have been shown to provide state-of-the-art results on image datasets by exploiting unlabeled data. Most of the time tested on object recognition tasks in images, these algorithms are rarely compared when applied to audio tasks. In this article, we adapted four recent SSL methods to the task of audio tagging. The first two methods, namely Deep Co-Training (DCT) and Mean Teacher (MT) involve two collaborative neural networks. The two other algorithms, called MixMatch (MM) and FixMatch (FM), are single-model methods that rely primarily on data augmentation strategies. Using the Wide ResNet 28-2 architecture in all our experiments, 10% of labeled data and the remaining 90\% as unlabeled, we first compare the four methods' accuracy on three standard benchmark audio event datasets: Environmental Sound Classification (ESC-10), UrbanSound8K (UBS8K), and Google Speech Commands (GSC). MM and FM outperformed MT and DCT significantly, MM being the best method in most experiments. On UBS8K and GSC, in particular, MM achieved 18.02% and 3.25% error rates (ER), outperforming models trained with 100% of the available labeled data, which reached 23.29% and 4.94% ER, respectively. Second, we explored the benefits of using the mixup augmentation in the four algorithms. In almost all cases, mixup brought significant gains. For instance, on GSC, FM reached 4.44% and 3.31% ER without and with mixup.      
### 36.Does deep machine vision have just noticeable difference (JND)?  [ :arrow_down: ](https://arxiv.org/pdf/2102.08168.pdf)
>  As an important perceptual characteristic of the Human Visual System (HVS), the Just Noticeable Difference (JND) has been studied for decades with image/video processing (e.g., perceptual image/video coding). However, there is little exploration on the existence of JND for AI, like Deep Machine Vision (DMV), although the DMV has made great strides in many machine vision tasks. In this paper, we take an initial attempt, and demonstrate that DMV does have the JND, termed as DMVJND. Besides, we propose a JND model for the classification task in DMV. It has been discovered that DMV can tolerate distorted images with average PSNR of only 9.56dB (the lower the better), by generating JND via unsupervised learning with our DMVJND-NET. In particular, a semantic-guided redundancy assessment strategy is designed to constrain the magnitude and spatial distribution of the JND. Experimental results on classification tasks demonstrate that we successfully find and model the JND for deep machine vision. Meanwhile, our DMV-JND paves a possible direction for DMV oriented image/video compression, watermarking, quality assessment, deep neural network security, and so on.      
### 37.Flow-Mixup: Classifying Multi-labeled Medical Images with Corrupted Labels  [ :arrow_down: ](https://arxiv.org/pdf/2102.08148.pdf)
>  In clinical practice, medical image interpretation often involves multi-labeled classification, since the affected parts of a patient tend to present multiple symptoms or comorbidities. Recently, deep learning based frameworks have attained expert-level performance on medical image interpretation, which can be attributed partially to large amounts of accurate annotations. However, manually annotating massive amounts of medical images is impractical, while automatic annotation is fast but imprecise (possibly introducing corrupted labels). In this work, we propose a new regularization approach, called Flow-Mixup, for multi-labeled medical image classification with corrupted labels. Flow-Mixup guides the models to capture robust features for each abnormality, thus helping handle corrupted labels effectively and making it possible to apply automatic annotation. Specifically, Flow-Mixup decouples the extracted features by adding constraints to the hidden states of the models. Also, Flow-Mixup is more stable and effective comparing to other known regularization methods, as shown by theoretical and empirical analyses. Experiments on two electrocardiogram datasets and a chest X-ray dataset containing corrupted labels verify that Flow-Mixup is effective and insensitive to corrupted labels.      
### 38.Quantitative analysis of image quality in low-dose CT imaging for Covid-19 patients  [ :arrow_down: ](https://arxiv.org/pdf/2102.08128.pdf)
>  We set out to simulate four reduced dose-levels (60%-dose, 40%-dose, 20%-dose, and 10%-dose) of standard CT imaging using Beer-Lambert's law across 49 patients infected with COVID-19. Then, three denoising filters, namely Gaussian, Bilateral, and Median, were applied to the different low-dose CT images, the quality of which was assessed prior to and after the application of the various filters via calculation of peak signal-to-noise ratio (PSNR), root mean square error (RMSE), structural similarity index measure (SSIM), and relative CT-value bias, separately for the lung tissue and whole-body. The quantitative evaluation indicated that 10%-dose CT images have inferior quality (with RMSE=322.1-+104.0 HU and bias=11.44-+4.49% in the lung) even after the application of the denoising filters. The bilateral filter exhibited superior performance to suppress the noise and recover the underlying signals in low-dose CT images compared to the other denoising techniques. The bilateral filter led to RMSE and bias of 100.21-+16.47 HU, -0.21-+1.20%, respectively in the lung regions for 20%-dose CT images compared to the Gaussian filter with RMSE=103.46-+15.70 HU and bias=1.02-+1.68%, median filter with RMSE=129.60-+18.09 HU and bias=-6.15-+2.24%, and the nonfiltered 20%-dose CT with RMSE=217.37-+64.66 HU and bias=4.30-+1.85%. In conclusion, the 20%-dose CT imaging followed by the bilateral filtering introduced a reasonable compromise between image quality and patient dose reduction.      
### 39.Simple statistical models and sequential deep learning for Lithium-ion batteries degradation under dynamic conditions: Fractional Polynomials vs Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.08111.pdf)
>  Longevity and safety of Lithium-ion batteries are facilitated by efficient monitoring and adjustment of the battery operating conditions: hence, it is crucial to implement fast and accurate algorithms for State of Health (SoH) monitoring on the Battery Management System. The task is challenging due to the complexity and multitude of the factors contributing to the battery capacity degradation, especially because the different degradation processes occur at various timescales and their interactions play an important role. This paper proposes and compares two data-driven approaches: a Long Short-Term Memory neural network, from the field of deep learning, and a Multivariable Fractional Polynomial regression, from classical statistics. Models from both classes are trained from historical data of one exhausted cell and used to predict the SoH of other cells. This work uses data provided by the NASA Ames Prognostics Center of Excellence, characterised by varying loads which simulate dynamic operating conditions. Two hypothetical scenarios are considered: one assumes that a recent true capacity measurement is known, the other relies solely on the cell nominal capacity. Both methods are effective, with low prediction errors, and the advantages of one over the other in terms of interpretability and complexity are discussed in a critical way.      
### 40.Just Noticeable Difference for Machine Perception and Generation of Regularized Adversarial Images with Minimal Perturbation  [ :arrow_down: ](https://arxiv.org/pdf/2102.08079.pdf)
>  In this study, we introduce a measure for machine perception, inspired by the concept of Just Noticeable Difference (JND) of human perception. Based on this measure, we suggest an adversarial image generation algorithm, which iteratively distorts an image by an additive noise until the machine learning model detects the change in the image by outputting a false label. The amount of noise added to the original image is defined as the gradient of the cost function of the machine learning model. This cost function explicitly minimizes the amount of perturbation applied on the input image and it is regularized by bounded range and total variation functions to assure perceptual similarity of the adversarial image to the input. We evaluate the adversarial images generated by our algorithm both qualitatively and quantitatively on CIFAR10, ImageNet, and MS COCO datasets. Our experiments on image classification and object detection tasks show that adversarial images generated by our method are both more successful in deceiving the recognition/detection model and less perturbed compared to the images generated by the state-of-the-art methods.      
### 41.Semi Supervised Learning For Few-shot Audio Classification By Episodic Triplet Mining  [ :arrow_down: ](https://arxiv.org/pdf/2102.08074.pdf)
>  Few-shot learning aims to generalize unseen classes that appear during testing but are unavailable during training. Prototypical networks incorporate few-shot metric learning, by constructing a class prototype in the form of a mean vector of the embedded support points within a class. The performance of prototypical networks in extreme few-shot scenarios (like one-shot) degrades drastically, mainly due to the desuetude of variations within the clusters while constructing prototypes. In this paper, we propose to replace the typical prototypical loss function with an Episodic Triplet Mining (ETM) technique. The conventional triplet selection leads to overfitting, because of all possible combinations being used during training. We incorporate episodic training for mining the semi hard positive and the semi hard negative triplets to overcome the overfitting. We also propose an adaptation to make use of unlabeled training samples for better modeling. Experimenting on two different audio processing tasks, namely speaker recognition and audio event detection; show improved performances and hence the efficacy of ETM over the prototypical loss function and other meta-learning frameworks. Further, we show improved performances when unlabeled training samples are used.      
### 42.Steadily Learn to Drive with Virtual Memory  [ :arrow_down: ](https://arxiv.org/pdf/2102.08072.pdf)
>  Reinforcement learning has shown great potential in developing high-level autonomous driving. However, for high-dimensional tasks, current RL methods suffer from low data efficiency and oscillation in the training process. This paper proposes an algorithm called Learn to drive with Virtual Memory (LVM) to overcome these problems. LVM compresses the high-dimensional information into compact latent states and learns a latent dynamic model to summarize the agent's experience. Various imagined latent trajectories are generated as virtual memory by the latent dynamic model. The policy is learned by propagating gradient through the learned latent model with the imagined latent trajectories and thus leads to high data efficiency. Furthermore, a double critic structure is designed to reduce the oscillation during the training process. The effectiveness of LVM is demonstrated by an image-input autonomous driving task, in which LVM outperforms the existing method in terms of data efficiency, learning stability, and control performance.      
### 43.A Multiscale Graph Convolutional Network for Change Detection in Homogeneous and Heterogeneous Remote Sensing Images  [ :arrow_down: ](https://arxiv.org/pdf/2102.08041.pdf)
>  Change detection (CD) in remote sensing images has been an ever-expanding area of research. To date, although many methods have been proposed using various techniques, accurately identifying changes is still a great challenge, especially in the high resolution or heterogeneous situations, due to the difficulties in effectively modeling the features from ground objects with different patterns. In this paper, a novel CD method based on the graph convolutional network (GCN) and multiscale object-based technique is proposed for both homogeneous and heterogeneous images. First, the object-wise high level features are obtained through a pre-trained U-net and the multiscale segmentations. Treating each parcel as a node, the graph representations can be formed and then, fed into the proposed multiscale graph convolutional network with each channel corresponding to one scale. The multiscale GCN propagates the label information from a small number of labeled nodes to the other ones which are unlabeled. Further, to comprehensively incorporate the information from the output channels of multiscale GCN, a fusion strategy is designed using the father-child relationships between scales. Extensive Experiments on optical, SAR and heterogeneous optical/SAR data sets demonstrate that the proposed method outperforms some state-of the-art methods in both qualitative and quantitative evaluations. Besides, the Influences of some factors are also discussed.      
### 44.Joint self-supervised blind denoising and noise estimation  [ :arrow_down: ](https://arxiv.org/pdf/2102.08023.pdf)
>  We propose a novel self-supervised image blind denoising approach in which two neural networks jointly predict the clean signal and infer the noise distribution. Assuming that the noisy observations are independent conditionally to the signal, the networks can be jointly trained without clean training data. Therefore, our approach is particularly relevant for biomedical image denoising where the noise is difficult to model precisely and clean training data are usually unavailable. Our method significantly outperforms current state-of-the-art self-supervised blind denoising algorithms, on six publicly available biomedical image datasets. We also show empirically with synthetic noisy data that our model captures the noise distribution efficiently. Finally, the described framework is simple, lightweight and computationally efficient, making it useful in practical cases.      
### 45.Improving speech recognition models with small samples for air traffic control systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.08015.pdf)
>  In the domain of air traffic control (ATC) systems, efforts to train a practical automatic speech recognition (ASR) model always faces the problem of small training samples since the collection and annotation of speech samples are expert- and domain-dependent task. In this work, a novel training approach based on pretraining and transfer learning is proposed to address this issue, and an improved end-to-end deep learning model is developed to address the specific challenges of ASR in the ATC domain. An unsupervised pretraining strategy is first proposed to learn speech representations from unlabeled samples for a certain dataset. Specifically, a masking strategy is applied to improve the diversity of the sample without losing their general patterns. Subsequently, transfer learning is applied to fine-tune a pretrained or other optimized baseline models to finally achieves the supervised ASR task. By virtue of the common terminology used in the ATC domain, the transfer learning task can be regarded as a sub-domain adaption task, in which the transferred model is optimized using a joint corpus consisting of baseline samples and new transcribed samples from the target dataset. This joint corpus construction strategy enriches the size and diversity of the training samples, which is important for addressing the issue of the small transcribed corpus. In addition, speed perturbation is applied to augment the new transcribed samples to further improve the quality of the speech corpus. Three real ATC datasets are used to validate the proposed ASR model and training strategies. The experimental results demonstrate that the ASR performance is significantly improved on all three datasets, with an absolute character error rate only one-third of that achieved through the supervised training. The applicability of the proposed strategies to other ASR approaches is also validated.      
### 46.LEAD: LiDAR Extender for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2102.07989.pdf)
>  3D perception using sensors under vehicle industrial standard is the rigid demand in autonomous driving. MEMS LiDAR emerges with irresistible trend due to its lower cost, more robust, and meeting the mass-production standards. However, it suffers small field of view (FoV), slowing down the step of its population. In this paper, we propose LEAD, i.e., LiDAR Extender for Autonomous Driving, to extend the MEMS LiDAR by coupled image w.r.t both FoV and range. We propose a multi-stage propagation strategy based on depth distributions and uncertainty map, which shows effective propagation ability. Moreover, our depth outpainting/propagation network follows a teacher-student training fashion, which transfers depth estimation ability to depth completion network without any scale error passed. To validate the LiDAR extension quality, we utilize a high-precise laser scanner to generate a ground-truth dataset. Quantitative and qualitative evaluations show that our scheme outperforms SOTAs with a large margin. We believe the proposed LEAD along with the dataset would benefit the community w.r.t depth researches.      
### 47.Voice Gender Scoring and Independent Acoustic Characterization of Perceived Masculinity and Femininity  [ :arrow_down: ](https://arxiv.org/pdf/2102.07982.pdf)
>  Previous research has found that voices can provide reliable information for gender classification with a high level of accuracy. In social psychology, perceived vocal masculinity and femininity has often been considered as an important feature on social behaviours. While previous studies have characterised acoustic features that contributed to perceivers' judgements of speakers' vocal masculinity or femininity, there is limited research on building an objective masculinity/femininity scoring model and characterizing the independent acoustic factors that contribute to the judgements of speakers' vocal masculinity or femininity. In this work, we firstly propose an objective masculinity/femininity scoring system based on the Extreme Random Forest and then characterize the independent and meaningful acoustic factors contributing to perceivers' judgements by using a correlation matrix based hierarchical clustering method. The results show the objective masculinity/femininity ratings strongly correlated with the perceived masculinity/femininity ratings when we used an optimal speech duration of 7 seconds, with a correlation coefficient of up to .63 for females and .77 for males. 9 independent clusters of acoustic measures were generated from our modelling of femininity judgements for female voices and 8 clusters were found for masculinity judgements for male voices. The results revealed that, for both sexes, the F0 mean is the most critical acoustic measure affects the judgement of vocal masculinity and femininity. The F3 mean, F4 mean and VTL estimators are found to be highly inter-correlated and appeared in the same cluster, forming the second significant factor. Next, F1 mean, F2 mean and F0 standard deviation are independent factors that share similar importance. The voice perturbation measures, including HNR, jitter and shimmer, are of lesser importance.      
### 48.Federated Learning over Wireless Networks: A Band-limited Coordinated Descent Approach  [ :arrow_down: ](https://arxiv.org/pdf/2102.07972.pdf)
>  We consider a many-to-one wireless architecture for federated learning at the network edge, where multiple edge devices collaboratively train a model using local data. The unreliable nature of wireless connectivity, together with constraints in computing resources at edge devices, dictates that the local updates at edge devices should be carefully crafted and compressed to match the wireless communication resources available and should work in concert with the receiver. Thus motivated, we propose SGD-based bandlimited coordinate descent algorithms for such settings. Specifically, for the wireless edge employing over-the-air computing, a common subset of k-coordinates of the gradient updates across edge devices are selected by the receiver in each iteration, and then transmitted simultaneously over k sub-carriers, each experiencing time-varying channel conditions. We characterize the impact of communication error and compression, in terms of the resulting gradient bias and mean squared error, on the convergence of the proposed algorithms. We then study learning-driven communication error minimization via joint optimization of power allocation and learning rates. Our findings reveal that optimal power allocation across different sub-carriers should take into account both the gradient values and channel conditions, thus generalizing the widely used water-filling policy. We also develop sub-optimal distributed solutions amenable to implementation.      
### 49.Asynchronous Distributed Optimization via Dual Decomposition and Block Coordinate Subgradient Methods  [ :arrow_down: ](https://arxiv.org/pdf/2102.07953.pdf)
>  We study the problem of minimizing the sum of potentially non-differentiable convex cost functions with partially overlapping dependences in an asynchronous manner, where communication in the network is not coordinated. We study the behavior of an asynchronous algorithm based on dual decomposition and block coordinate subgradient methods under assumptions weaker than those used in the literature. At the same time, we allow different agents to use local stepsizes with no global coordination. Sufficient conditions are provided for almost sure convergence to the solution of the optimization problem. Under additional assumptions, we establish a sublinear convergence rate that in turn can be strengthened to linear convergence rate if the problem is strongly convex and has Lipschitz gradients. We also extend available results in the literature by allowing multiple and potentially overlapping blocks to be updated at the same time with non-uniform and potentially time varying probabilities assigned to different blocks. A numerical example is provided to illustrate the effectiveness of the algorithm.      
### 50.Optimal Distributed Frequency and Voltage Control for Zonal Electricity Markets  [ :arrow_down: ](https://arxiv.org/pdf/2102.07949.pdf)
>  Zonal pricing is a well-suited mechanism to incentivize grid-supporting behavior of profit-maximizing producers and consumers operating on a large-scale power system. In zonal electricity markets, local system operators create individual price zones, which provide appropriate price signals depending on local grid conditions such as an excess or shortage of electrical energy in certain regions. In this paper, a continuous-time zonal pricing controller for AC power networks is presented that ensures frequency and voltage stability as well as Pareto efficiency of the resulting closed-loop equilibria. Based on a dynamic network model taking into account line losses and power exchange with adjacent price zones, distributed control laws are derived which require only neighbor-to-neighbor communication. Case studies on the IEEE-57 bus system with different pricing concepts illustrate how zonal prices enable consideration of regional supply and demand conditions as well as increased robustness compared to an isolated grid operation.      
### 51.Anomalous Sound Detection with Machine Learning: A Systematic Review  [ :arrow_down: ](https://arxiv.org/pdf/2102.07820.pdf)
>  Anomalous sound detection (ASD) is the task of identifying whether the sound emitted from an object is normal or anomalous. In some cases, early detection of this anomaly can prevent several problems. This article presents a Systematic Review (SR) about studies related to Anamolous Sound Detection using Machine Learning (ML) techniques. This SR was conducted through a selection of 31 (accepted studies) studies published in journals and conferences between 2010 and 2020. The state of the art was addressed, collecting data sets, methods for extracting features in audio, ML models, and evaluation methods used for ASD. The results showed that the ToyADMOS, MIMII, and Mivia datasets, the Mel-frequency cepstral coefficients (MFCC) method for extracting features, the Autoencoder (AE) and Convolutional Neural Network (CNN) models of ML, the AUC and F1-score evaluation methods were most cited.      

# ArXiv eess --Mon, 22 Feb 2021
### 1.Going beyond p-convolutions to learn grayscale morphological operators  [ :arrow_down: ](https://arxiv.org/pdf/2102.10038.pdf)
>  Integrating mathematical morphology operations within deep neural networks has been subject to increasing attention lately. However, replacing standard convolution layers with erosions or dilations is particularly challenging because the min and max operations are not differentiable. Relying on the asymptotic behavior of the counter-harmonic mean, p-convolutional layers were proposed as a possible workaround to this issue since they can perform pseudo-dilation or pseudo-erosion operations (depending on the value of their inner parameter p), and very promising results were reported. In this work, we present two new morphological layers based on the same principle as the p-convolutional layer while circumventing its principal drawbacks, and demonstrate their potential interest in further implementations within deep convolutional neural network architectures.      
### 2.Intrapapillary Capillary Loop Classification in Magnification Endoscopy: Open Dataset and Baseline Methodology  [ :arrow_down: ](https://arxiv.org/pdf/2102.09963.pdf)
>  Purpose. Early squamous cell neoplasia (ESCN) in the oesophagus is a highly treatable condition. Lesions confined to the mucosal layer can be curatively treated endoscopically. We build a computer-assisted detection (CADe) system that can classify still images or video frames as normal or abnormal with high diagnostic accuracy. Methods. We present a new benchmark dataset containing 68K binary labeled frames extracted from 114 patient videos whose imaged areas have been resected and correlated to histopathology. Our novel convolutional network (CNN) architecture solves the binary classification task and explains what features of the input domain drive the decision-making process of the network. Results. The proposed method achieved an average accuracy of 91.7 % compared to the 94.7 % achieved by a group of 12 senior clinicians. Our novel network architecture produces deeply supervised activation heatmaps that suggest the network is looking at intrapapillary capillary loop (IPCL) patterns when predicting abnormality. Conclusion. We believe that this dataset and baseline method may serve as a reference for future benchmarks on both video frame classification and explainability in the context of ESCN detection. A future work path of high clinical relevance is the extension of the classification to ESCN types.      
### 3.Artificially Synthesising Data for Audio Classification and Segmentation to Improve Speech and Music Detection in Radio Broadcast  [ :arrow_down: ](https://arxiv.org/pdf/2102.09959.pdf)
>  Segmenting audio into homogeneous sections such as music and speech helps us understand the content of audio. It is useful as a pre-processing step to index, store, and modify audio recordings, radio broadcasts and TV programmes. Deep learning models for segmentation are generally trained on copyrighted material, which cannot be shared. Annotating these datasets is time-consuming and expensive and therefore, it significantly slows down research progress. In this study, we present a novel procedure that artificially synthesises data that resembles radio signals. We replicate the workflow of a radio DJ in mixing audio and investigate parameters like fade curves and audio ducking. We trained a Convolutional Recurrent Neural Network (CRNN) on this synthesised data and outperformed state-of-the-art algorithms for music-speech detection. This paper demonstrates the data synthesis procedure as a highly effective technique to generate large datasets to train deep neural networks for audio segmentation.      
### 4.Joint multi-field T$_1$ quantification for fast field-cycling MRI  [ :arrow_down: ](https://arxiv.org/pdf/2102.09955.pdf)
>  Recent developments in hardware design enable the use of Fast Field-Cycling (FFC) techniques in MRI to exploit the different relaxation rates at very low field strength, achieving novel contrast. The method opens new avenues for in vivo characterisations of pathologies but at the expense of longer acquisition times. To mitigate this we propose a model-based reconstruction method that fully exploits the high information redundancy offered by FFC methods. This is based on joining spatial information from all fields based on TGV regularization. The algorithm was tested on brain stroke images, both simulated and acquired from FFC patients scans using an FFC spin echo sequences. The results are compared to non-linear least squares combined with k-space filtering. The proposed method shows excellent abilities to remove noise while maintaining sharp image features with large SNR gains at low-field images, clearly outperforming the reference approach. Especially patient data shows huge improvements in visual appearance over all fields. The proposed reconstruction technique largely improves FFC image quality, further pushing this new technology towards clinical standards.      
### 5.ABSP System for The Third DIHARD Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2102.09939.pdf)
>  This report describes the speaker diarization system developed by the ABSP Laboratory team for the third DIHARD speech diarization challenge. Our primary contribution is to develop acoustic domain identification (ADI) system for speaker diarization. We investigate speaker embeddings based ADI system. We apply a domain-dependent threshold for agglomerative hierarchical clustering. Besides, we optimize the parameters for PCA-based dimensionality reduction in a domain-dependent way. Our method of integrating domain-based processing schemes in the baseline system of the challenge achieved a relative improvement of $9.63\%$ and $10.64\%$ in DER for core and full conditions, respectively, for Track 1 of the DIHARD III evaluation set.      
### 6.User Subgrouping in Multicast Massive MIMO over Spatially Correlated Rayleigh Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2102.09935.pdf)
>  Massive multiple-input-multiple-output (MaMIMO) multicasting has received significant attention over the last years. MaMIMO is a key enabler of 5G systems to achieve the extremely demanding data rates of upcoming services. Multicast in the physical layer is an efficient way of serving multiple users, simultaneously demanding the same service and sharing radio resources. This work proposes a subgrouping strategy of multicast users based on their spatial channel characteristics to improve the channel estimation and precoding processes. We employ max-min fairness (MMF) power allocation strategy to maximize the minimum spectral efficiency (SE) of the multicast service. Additionally, we explore the combination of spatial multiplexing with orthogonal (time/frequency) multiple access. By varying the number of antennas at the base station (BS) and users' spatial distribution, we also provide the optimal subgroup configuration that maximizes the spectral efficiency per subgroup. Finally, we show that serving the multicast users into two orthogonal time/frequency intervals offers better performance than only relying on spatial multiplexing.      
### 7.Do End-to-End Speech Recognition Models Care About Context?  [ :arrow_down: ](https://arxiv.org/pdf/2102.09928.pdf)
>  The two most common paradigms for end-to-end speech recognition are connectionist temporal classification (CTC) and attention-based encoder-decoder (AED) models. It has been argued that the latter is better suited for learning an implicit language model. We test this hypothesis by measuring temporal context sensitivity and evaluate how the models perform when we constrain the amount of contextual information in the audio input. We find that the AED model is indeed more context sensitive, but that the gap can be closed by adding self-attention to the CTC model. Furthermore, the two models perform similarly when contextual information is constrained. Finally, in contrast to previous research, our results show that the CTC model is highly competitive on WSJ and LibriSpeech without the help of an external language model.      
### 8.End-to-End Neural Systems for Automatic Children Speech Recognition: An Empirical Study  [ :arrow_down: ](https://arxiv.org/pdf/2102.09918.pdf)
>  A key desiderata for inclusive and accessible speech recognition technology is ensuring its robust performance to children's speech. Notably, this includes the rapidly advancing neural network based end-to-end speech recognition systems. Children speech recognition is more challenging due to the larger intra-inter speaker variability in terms of acoustic and linguistic characteristics compared to adult speech. Furthermore, the lack of adequate and appropriate children speech resources adds to the challenge of designing robust end-to-end neural architectures. This study provides a critical assessment of automatic children speech recognition through an empirical study of contemporary state-of-the-art end-to-end speech recognition systems. Insights are provided on the aspects of training data requirements, adaptation on children data, and the effect of children age, utterance lengths, different architectures and loss functions for end-to-end systems and role of language models on the speech recognition performance.      
### 9.Fading Margins for Large-Scale Antenna Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.09903.pdf)
>  Mobile phone operators have begun the roll-out of 5G networks, deploying massive MIMO base stations. Commercial product ranges start with 16 independent radio chains connected to a large-scale antenna system to exploit both channel hardening and favourable propagation in order to obtain increased spectral efficiency. In this work, the cumulative distribution function describing the gain for large-scale antenna systems considering spatial and spectral diversity is evaluated empirically in terms of a fading margin and compared to an analytical maximum diversity reference system. This allows for a simple investigation of the trade-off between deployment size and exploitation of channel hardening. For the considered site-specific measurement data, little additional diversity is harvested with systems larger than 32 antenna elements.      
### 10.Environment-Aware and Training-Free Beam Alignment for mmWave Massive MIMO via Channel Knowledge Map  [ :arrow_down: ](https://arxiv.org/pdf/2102.09871.pdf)
>  Millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) communication system is expected to achieve enormous transmission rate, provided that the transmit and receive beams are properly aligned with the MIMO channel. However, existing beam alignment techniques rely on either channel estimation or beam sweeping, which incur prohibitively high training overhead, especially for future wireless systems with further increased antenna dimensions and more stringent requirement on cost-effective hardware architectures. In this paper, we propose a new beam alignment technique, which is environment-aware and training-free, by utilizing the emerging concept of channel knowledge map (CKM), together with the user location information that is readily available in contemporary wireless systems. CKM is a site-specific database, tagged with the transmitter/receiver locations, which contains useful channel information to facilitate or even obviate real-time channel state information (CSI) acquistion. Two instances of CKM are proposed for beam alignment in mmWave massive MIMO systems, namely channel path map (CPM) and beam index map (BIM). It is shown that compared with existing training-based beam alignment schemes, the proposed CKM-enabled environment-aware beam alignment is able to drastically improve the effective communication rate, even with moderate user location errors, thanks to its significant saving of the prohibitive training overhead.      
### 11.Direction of Arrival Estimation of Noisy Speech Using Convolutional Recurrent Neural Networks with Higher-Order Ambisonics Signals  [ :arrow_down: ](https://arxiv.org/pdf/2102.09853.pdf)
>  Training convolutional recurrent neural networks (CRNNs) on first-order Ambisonics signals is a well-known approach for estimating the direction of speech/sound arrival. In this work, we investigate whether increasing the order of Ambisonics signals up to the fourth order further improves the estimation performance of CRNNs. While our results on data based on simulated spatial room impulse responses (SRIRs) show that the use of higher Ambisonics orders does have the potential to provide better localization results, no further improvement was shown on data based on real SRIRs from order two onwards. Rather, it seems to be crucial to extract meaningful features from the raw data. First order features derived from the acoustic intensity vector were superior to pure higher-order magnitude and phase features in almost all scenarios.      
### 12.A Robust Maximum Likelihood Distortionless Response Beamformer based on a Complex Generalized Gaussian Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2102.09838.pdf)
>  For multichannel speech enhancement, this letter derives a robust maximum likelihood distortionless response beamformer by modeling speech sparse priors with a complex generalized Gaussian distribution, where we refer to as the CGGD-MLDR beamformer. The proposed beamformer can be regarded as a generalization of the minimum power distortionless response beamformer and its improved variations. For narrowband applications, we also reveal that the proposed beamformer reduces to the minimum dispersion distortionless response beamformer, which has been derived with the ${{\ell}_{p}}$-norm minimization. The mechanisms of the proposed beamformer in improving the robustness are clearly pointed out and experimental results show its better performance in PESQ improvement.      
### 13.A systematic review of recent air source heat pump (ASHP) systems assisted by solar thermal, photovoltaic and photovoltaic/thermal sources  [ :arrow_down: ](https://arxiv.org/pdf/2102.09797.pdf)
>  The air source heat pump (ASHP) systems assisted by solar energy have drawn great attentions, owing to their great feasibility in buildings for space heating/cooling and hot water purposes. However, there are a variety of configurations, parameters and performance criteria of solar assisted ASHP systems, leading to a major inconsistency that increase the degree of complexity to compare and implement different systems. A comparative literature review is lacking, with the aim to evaluate the performance of various ASHP systems from three main solar sources, such as solar thermal (ST), photovoltaic (PV) and hybrid photovoltaic/thermal (PV/T). This paper thus conducts a systematic review of the prevailing solar assisted ASHP systems, including their boundary conditions, system configurations, performance indicators, research methodologies and system performance. The comparison result indicates that PV-ASHP system has the best techno-economic performance, which performs best in average with coefficient of performance (COP) of around 3.75, but with moderate cost and payback time. While ST-ASHP and PV/T-ASHP systems have lower performance with mean COP of 2.90 and 3.03, respectively. Moreover, PV/T-ASHP system has the highest cost and longest payback time, while ST-ASHP has the lowest ones. Future research are discussed from aspects of methodologies, system optimization and standard evaluation.      
### 14.A GAN-Based Input-Size Flexibility Model for Single Image Dehazing  [ :arrow_down: ](https://arxiv.org/pdf/2102.09796.pdf)
>  Image-to-image translation based on generative adversarial network (GAN) has achieved state-of-the-art performance in various image restoration applications. Single image dehazing is a typical example, which aims to obtain the haze-free image of a haze one. This paper concentrates on the challenging task of single image dehazing. Based on the atmospheric scattering model, we design a novel model to directly generate the haze-free image. The main challenge of image dehazing is that the atmospheric scattering model has two parameters, i.e., transmission map and atmospheric light. When we estimate them respectively, the errors will be accumulated to compromise dehazing quality. Considering this reason and various image sizes, we propose a novel input-size flexibility conditional generative adversarial network (cGAN) for single image dehazing, which is input-size flexibility at both training and test stages for image-to-image translation with cGAN framework. We propose a simple and effective U-type residual network (UR-Net) to combine the generator and adopt the spatial pyramid pooling (SPP) to design the discriminator. Moreover, the model is trained with multi-loss function, in which the consistency loss is a novel designed loss in this paper. We finally build a multi-scale cGAN fusion model to realize state-of-the-art single image dehazing performance. The proposed models receive a haze image as input and directly output a haze-free one. Experimental results demonstrate the effectiveness and efficiency of the proposed models.      
### 15.A coordinated control to improve performance for a building cluster with energy storage, electric vehicles, and energy sharing considered  [ :arrow_down: ](https://arxiv.org/pdf/2102.09793.pdf)
>  Distributed renewable energy systems are now widely installed in many buildings, transforming the buildings into electricity prosumers. Existing studies have developed some advanced building side controls that enable renewable energy sharing and that aim to optimise building-cluster-level performance via regulating the energy storage charging/ discharging. However, the flexible demand shifting ability of electric vehicles is not considered in these building side controls. For instance, the electric vehicle charging will usually start once they are plugged into charging stations. But, in such charging period the renewable generation may be insufficient to cover the EV charging load, leading to grid electricity imports. Consequently, the building-cluster-level performance is not optimised. Therefore, this study proposes a coordinated control of building prosumers for improving the cluster-level performance, by making use of energy sharing and storage capability of electricity batteries in both buildings and EVs. An EV charging/discharging model is first developed. Then, based on the predicted future 24h electricity demand and renewable generation data, the coordinated control first considers the whole building cluster as one integrated building and optimises its operation as well as the EV charging/discharging using genetic algorithm. Next, the operation of individual buildings in the future 24h is coordinated using nonlinear programming. For validation, the developed control has been tested on a real building cluster in Ludvika, Sweden. The study results show that the developed control can increase the cluster-level daily renewable self-consumption rate by 19% and meanwhile reduce the daily electricity bills by 36% compared with the conventional controls.      
### 16.Deep Learning-based Beam Tracking for Millimeter-wave Communications under Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2102.09785.pdf)
>  In this paper, we propose a deep learning-based beam tracking method for millimeter-wave (mmWave)communications. Beam tracking is employed for transmitting the known symbols using the sounding beams and tracking time-varying channels to maintain a reliable communication link. When the pose of a user equipment (UE) device varies rapidly, the mmWave channels also tend to vary fast, which hinders seamless communication. Thus, models that can capture temporal behavior of mmWave channels caused by the motion of the device are required, to cope with this problem. Accordingly, we employa deep neural network to analyze the temporal structure and patterns underlying in the time-varying channels and the signals acquired by inertial sensors. We propose a model based on long short termmemory (LSTM) that predicts the distribution of the future channel behavior based on a sequence of input signals available at the UE. This channel distribution is used to 1) control the sounding beams adaptively for the future channel state and 2) update the channel estimate through the measurement update step under a sequential Bayesian estimation framework. Our experimental results demonstrate that the proposed method achieves a significant performance gain over the conventional beam tracking methods under various mobility scenarios.      
### 17.Marginal energy intensity of water supply  [ :arrow_down: ](https://arxiv.org/pdf/2102.09753.pdf)
>  Reducing global carbon emissions will require diverse industrial sectors to use energy more efficiently, electrify, and operate intermittently. The water sector is a transformation target, but we lack energy quantification tools to guide operational, infrastructure, and policy interventions in complex water sourcing, treatment, and distribution networks. The marginal energy intensity (MEI) of water supply quantifies the location-specific, instantaneous embedded energy in water delivered to consumers. We describe the first MEI algorithm and elucidate the sensitivity of MEI to generalizable water system features. When incorporated in multi-objective operational and planning models, MEI will dramatically increase the energy co-benefits of water efficiency, conservation, and retrofit programs; maximize energy flexibility services that water systems can deliver to the grid; and facilitate full cost recovery in distribution system operation.      
### 18.Signal Detection in Distributed MIMO Radar with Non-Orthogonal Waveforms and Sync Errors  [ :arrow_down: ](https://arxiv.org/pdf/2102.09719.pdf)
>  Although routinely utilized in literature, orthogonal waveforms may lose orthogonality in distributed multi-input multi-output (MIMO) radar with spatially separated transmit (TX) and receive (RX) antennas, as the waveforms may experience distinct delays and Doppler frequency offsets unique to different TX-RX propagation paths. In such cases, the output of each waveform-specific matched filter (MF), employed to unravel the waveforms at the RXs, contains both an \auto term and multiple cross terms, i.e., the filtered response of the desired and, respectively, undesired waveforms. We consider the impact of non-orthogonal waveforms and their cross terms on target detection with or without timing, frequency, and phase errors. To this end, we present a general signal model for distributed MIMO radar, examine target detection using existing coherent/non-coherent detectors and two new detectors, including a hybrid detector that requires phase coherence locally but not across distributed antennas, and provide a statistical analysis leading to closed-form expressions of false alarm and detection probabilities for all detectors. Our results show that cross terms can behave like foes or allies, respectively, if they and the auto term add destructively or constructively, depending on the propagation delay, frequency, and phase offsets. Regarding sync errors, we show that phase errors affect only coherent detectors, frequency errors degrade all but the non-coherent detector, while all are impacted by timing errors, which result in a loss in the signal-to-noise ratio (SNR).      
### 19.Joint Design of Radar Waveform and Detector via End-to-end Learning with Waveform Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2102.09694.pdf)
>  The problem of data-driven joint design of transmitted waveform and detector in a radar system is addressed in this paper. We propose two novel learning-based approaches to waveform and detector design based on end-to-end training of the radar system. The first approach consists of alternating supervised training of the detector for a fixed waveform and reinforcement learning of the transmitter for a fixed detector. In the second approach, the transmitter and detector are trained simultaneously. Various operational waveform constraints, such as peak-to-average-power ratio (PAR) and spectral compatibility, are incorporated into the design. Unlike traditional radar design methods that rely on rigid mathematical models with limited applicability, it is shown that radar learning can be robustified by training the detector with synthetic data generated from multiple statistical models of the environment. Theoretical considerations and results show that the proposed methods are capable of adapting the transmitted waveform to environmental conditions while satisfying design constraints.      
### 20.Detecting Communities in Gossip Model with Stubborn Agents  [ :arrow_down: ](https://arxiv.org/pdf/2102.09683.pdf)
>  We consider a community detection problem in a gossip model, where agents randomly interact pairwise, with stubborn agents never changing their states. It is assumed that the agents can be divided into two communities based on their interaction probability with others. Such a model can illustrate how disagreement and opinion fluctuation arise in a social network. The considered problem is twofold: to infer which community each agent belongs to, and to estimate interaction probabilities between agents, by only observing their state evolution. First, stability and limit theorems of the model are derived. An integrated detection and estimation algorithm is then proposed to infer the two communities and to estimate the interaction probabilities, based on agent states. It is verified that the community detector of the algorithm converges in finite time, and the interaction estimator converges almost surely. In addition, non-asymptotic property is obtained for the former, and convergence rate is analyzed for the latter. Simulations are presented to illustrate the performance of the proposed algorithm.      
### 21.Dynamic curriculum learning via data parameters for noise robust keyword spotting  [ :arrow_down: ](https://arxiv.org/pdf/2102.09666.pdf)
>  We propose dynamic curriculum learning via data parameters for noise robust keyword spotting. Data parameter learning has recently been introduced for image processing, where weight parameters, so-called data parameters, for target classes and instances are introduced and optimized along with model parameters. The data parameters scale logits and control importance over classes and instances during training, which enables automatic curriculum learning without additional annotations for training data. Similarly, in this paper, we propose using this curriculum learning approach for acoustic modeling, and train an acoustic model on clean and noisy utterances with the data parameters. The proposed approach automatically learns the difficulty of the classes and instances, e.g. due to low speech to noise ratio (SNR), in the gradient descent optimization and performs curriculum learning. This curriculum learning leads to overall improvement of the accuracy of the acoustic model. We evaluate the effectiveness of the proposed approach on a keyword spotting task. Experimental results show 7.7% relative reduction in false reject ratio with the data parameters compared to a baseline model which is simply trained on the multiconditioned dataset.      
### 22.Generative Speech Coding with Predictive Variance Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2102.09660.pdf)
>  The recent emergence of machine-learning based generative models for speech suggests a significant reduction in bit rate for speech codecs is possible. However, the performance of generative models deteriorates significantly with the distortions present in real-world input signals. We argue that this deterioration is due to the sensitivity of the maximum likelihood criterion to outliers and the ineffectiveness of modeling a sum of independent signals with a single autoregressive model. We introduce predictive-variance regularization to reduce the sensitivity to outliers, resulting in a significant increase in performance. We show that noise reduction to remove unwanted signals can significantly increase performance. We provide extensive subjective performance evaluations that show that our system based on generative modeling provides state-of-the-art coding performance at 3 kb/s for real-world speech signals at reasonable computational complexity.      
### 23.Relying on a rate constraint to reduce Motion Estimation complexity  [ :arrow_down: ](https://arxiv.org/pdf/2102.09656.pdf)
>  This paper proposes a rate-based candidate elimination strategy for Motion Estimation, which is considered one of the main sources of encoder complexity. We build from findings of previous works that show that selected motion vectors are generally near the predictor to propose a solution that uses the motion vector bitrate to constrain the candidate search to a subset of the original search window, resulting in less distortion computations. The proposed method is not tied to a particular search pattern, which makes it applicable to several ME strategies. The technique was tested in the VVC reference software implementation and showed complexity reductions of over 80% at the cost of an average 0.74% increase in BD-Rate with respect to the original TZ Search algorithm in the LDP configuration.      
### 24.Identification of Phase-Locked Loop System From Its Experimental Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2102.09638.pdf)
>  Phase-locked loops (PLLs) are now widely used in communication systems and have been a classic system for more than 60 years. Well-known mathematical models of such systems are constructed in a number of approximations, so questions about how they describe the experimental dynamics qualitatively and quantitatively, and how the accuracy of the model description depends on the behavior mode, remain open. One of the most direct approaches to the verification of any model is its reconstruction from the time series obtained in experiment. If it is possible to fit the model to experimental data and the resulting parameter values are close to the expected values (calculated from the first principles), the quantitative correspondence between the model and the physical object is nearly proved. In this paper, for the first time, the equations of the PLL model with a bandpass filter are reconstructed from the experimental signals of the generator in various modes. The reconstruction showed that the model known in the literature generally describes the experimental dynamics in regular and chaotic regimes. The relative error of parameter estimation is between 2% and 50% for different regimes and parameters. The reconstructed nonlinear function of phase is not harmonic and highly asymmetric in contrary to the model one.      
### 25.Noise Entangled GAN For Low-Dose CT Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09615.pdf)
>  We propose a Noise Entangled GAN (NE-GAN) for simulating low-dose computed tomography (CT) images from a higher dose CT image. First, we present two schemes to generate a clean CT image and a noise image from the high-dose CT image. Then, given these generated images, an NE-GAN is proposed to simulate different levels of low-dose CT images, where the level of generated noise can be continuously controlled by a noise factor. NE-GAN consists of a generator and a set of discriminators, and the number of discriminators is determined by the number of noise levels during training. Compared with the traditional methods based on the projection data that are usually unavailable in real applications, NE-GAN can directly learn from the real and/or simulated CT images and may create low-dose CT images quickly without the need of raw data or other proprietary CT scanner information. The experimental results show that the proposed method has the potential to simulate realistic low-dose CT images.      
### 26.Encoding Frequency Constraints in Preventive Unit Commitment Using Deep Learning with Region-of-Interest Active Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2102.09583.pdf)
>  With the increasing penetration of renewable energy, frequency response and its security are of significant concerns for reliable power system operations. Frequency-constrained unit commitment (FCUC) is proposed to address this challenge. Despite existing efforts in modeling frequency characteristics in unit commitment (UC), current strategies can only handle oversimplified low-order frequency response models and do not consider wide-range operating conditions. This paper presents a generic data-driven framework for FCUC under high renewable penetration. Deep neural networks (DNNs) are trained to predict the frequency response using real data or high-fidelity simulation data. Next, the DNN is reformulated as a set of mixed-integer linear constraints to be incorporated into the ordinary UC formulation. In the data generation phase, all possible power injections are considered, and a region-of-interests active sampling is proposed to include power injection samples with frequency nadirs closer to the UFLC threshold, which significantly enhances the accuracy of frequency constraints in FCUC. The proposed FCUC is verified on the the IEEE 39-bus system. Then, a full-order dynamic model simulation using PSS/E verifies the effectiveness of FCUC in frequency-secure generator commitments.      
### 27.Probabilistically Guaranteed Satisfaction of Temporal Logic Constraints During Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.10063.pdf)
>  We present a novel reinforcement learning algorithm for finding optimal policies in Markov Decision Processes while satisfying temporal logic constraints with a desired probability throughout the learning process. An automata-theoretic approach is proposed to ensure probabilistic satisfaction of the constraint in each episode, which is different from penalizing violations to achieve constraint satisfaction after a sufficiently large number of episodes. The proposed approach is based on computing a lower bound on the probability of constraint satisfaction and adjusting the exploration behavior as needed. We present theoretical results on the probabilistic constraint satisfaction achieved by the proposed approach. We also numerically demonstrate the proposed idea in a drone scenario, where the constraint is to perform periodically arriving pick-up and delivery tasks and the objective is to fly over high-reward zones to simultaneously perform aerial monitoring.      
### 28.TransMask: A Compact and Fast Speech Separation Model Based on Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2102.09978.pdf)
>  Speech separation is an important problem in speech processing, which targets to separate and generate clean speech from a mixed audio containing speech from different speakers. Empowered by the deep learning technologies over sequence-to-sequence domain, recent neural speech separation models are now capable of generating highly clean speech audios. To make these models more practical by reducing the model size and inference time while maintaining high separation quality, we propose a new transformer-based speech separation approach, called TransMask. By fully un-leashing the power of self-attention on long-term dependency exception, we demonstrate the size of TransMask is more than 60% smaller and the inference is more than 2 times faster than state-of-the-art solutions. TransMask fully utilizes the parallelism during inference, and achieves nearly linear inference time within reasonable input audio lengths. It also outperforms existing solutions on output speech audio quality, achieving SDR above 16 over Librimix benchmark.      
### 29.Speech enhancement with weakly labelled data from AudioSet  [ :arrow_down: ](https://arxiv.org/pdf/2102.09971.pdf)
>  Speech enhancement is a task to improve the intelligibility and perceptual quality of degraded speech signal. Recently, neural networks based methods have been applied to speech enhancement. However, many neural network based methods require noisy and clean speech pairs for training. We propose a speech enhancement framework that can be trained with large-scale weakly labelled AudioSet dataset. Weakly labelled data only contain audio tags of audio clips, but not the onset or offset times of speech. We first apply pretrained audio neural networks (PANNs) to detect anchor segments that contain speech or sound events in audio clips. Then, we randomly mix two detected anchor segments containing speech and sound events as a mixture, and build a conditional source separation network using PANNs predictions as soft conditions for speech enhancement. In inference, we input a noisy speech signal with the one-hot encoding of "Speech" as a condition to the trained system to predict enhanced speech. Our system achieves a PESQ of 2.28 and an SSNR of 8.75 dB on the VoiceBank-DEMAND dataset, outperforming the previous SEGAN system of 2.16 and 7.73 dB respectively.      
### 30.CatNet: music source separation system with mix-audio augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09966.pdf)
>  Music source separation (MSS) is the task of separating a music piece into individual sources, such as vocals and accompaniment. Recently, neural network based methods have been applied to address the MSS problem, and can be categorized into spectrogram and time-domain based methods. However, there is a lack of research of using complementary information of spectrogram and time-domain inputs for MSS. In this article, we propose a CatNet framework that concatenates a UNet separation branch using spectrogram as input and a WavUNet separation branch using time-domain waveform as input for MSS. We propose an end-to-end and fully differentiable system that incorporate spectrogram calculation into CatNet. In addition, we propose a novel mix-audio data augmentation method that randomly mix audio segments from the same source as augmented audio segments for training. Our proposed CatNet MSS system achieves a state-of-the-art vocals separation source distortion ratio (SDR) of 7.54 dB, outperforming MMDenseNet of 6.57 dB evaluated on the MUSDB18 dataset.      
### 31.Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input  [ :arrow_down: ](https://arxiv.org/pdf/2102.09914.pdf)
>  The prosody of a spoken word is determined by its surrounding context. In incremental text-to-speech synthesis, where the synthesizer produces an output before it has access to the complete input, the full context is often unknown which can result in a loss of naturalness in the synthesized speech. In this paper, we investigate whether the use of predicted future text can attenuate this loss. We compare several test conditions of next future word: (a) unknown (zero-word), (b) language model predicted, (c) randomly predicted and (d) ground-truth. We measure the prosodic features (pitch, energy and duration) and find that predicted text provides significant improvements over a zero-word lookahead, but only slight gains over random-word lookahead. We confirm these results with a perceptive test.      
### 32.Characterising Alzheimer's Disease with EEG-based Energy Landscape Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2102.09882.pdf)
>  Alzheimer's disease (AD) is one of the most common neurodegenerative diseases, with around 50 million patients worldwide. Accessible and non-invasive methods of diagnosing and characterising AD are therefore urgently required. Electroencephalography (EEG) fulfils these criteria and is often used when studying AD. Several features derived from EEG were shown to predict AD with high accuracy, e.g. signal complexity and synchronisation. However, the dynamics of how the brain transitions between stable states have not been properly studied in the case of AD and EEG data. Energy landscape analysis is a method that can be used to quantify these dynamics. This work presents the first application of this method to both AD and EEG. Energy landscape assigns energy value to each possible state, i.e. pattern of activations across brain regions. The energy is inversely proportional to the probability of occurrence. By studying the features of energy landscapes of 20 AD patients and 20 healthy age-matched counterparts, significant differences were found. The dynamics of AD patients' brain networks were shown to be more constrained - with more local minima, less variation in basin size, and smaller basins. We show that energy landscapes can predict AD with high accuracy, performing significantly better than baseline models.      
### 33.ISCL: Interdependent Self-Cooperative Learning for Unpaired Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2102.09858.pdf)
>  With the advent of advances in self-supervised learning, paired clean-noisy data are no longer required in deep learning-based image denoising. However, existing blind denoising methods still require the assumption with regard to noise characteristics, such as zero-mean noise distribution and pixel-wise noise-signal independence; this hinders wide adaptation of the method in the medical domain. On the other hand, unpaired learning can overcome limitations related to the assumption on noise characteristics, which makes it more feasible for collecting the training data in real-world scenarios. In this paper, we propose a novel image denoising scheme, Interdependent Self-Cooperative Learning (ISCL), that leverages unpaired learning by combining cyclic adversarial learning with self-supervised residual learning. Unlike the existing unpaired image denoising methods relying on matching data distributions in different domains, the two architectures in ISCL, designed for different tasks, complement each other and boost the learning process. To assess the performance of the proposed method, we conducted extensive experiments in various biomedical image degradation scenarios, such as noise caused by physical characteristics of electron microscopy (EM) devices (film and charging noise), and structural noise found in low-dose computer tomography (CT). We demonstrate that the image quality of our method is superior to conventional and current state-of-the-art deep learning-based image denoising methods, including supervised learning.      
### 34.AISPEECH-SJTU accent identification system for the Accented English Speech Recognition Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2102.09828.pdf)
>  This paper describes the AISpeech-SJTU system for the accent identification track of the Interspeech-2020 Accented English Speech Recognition Challenge. In this challenge track, only 160-hour accented English data collected from 8 countries and the auxiliary Librispeech dataset are provided for training. To build an accurate and robust accent identification system, we explore the whole system pipeline in detail. First, we introduce the ASR based phone posteriorgram (PPG) feature to accent identification and verify its efficacy. Then, a novel TTS based approach is carefully designed to augment the very limited accent training data for the first time. Finally, we propose the test time augmentation and embedding fusion schemes to further improve the system performance. Our final system is ranked first in the challenge and outperforms all the other participants by a large margin. The submitted system achieves 83.63\% average accuracy on the challenge evaluation data, ahead of the others by more than 10\% in absolute terms.      
### 35.Unit selection synthesis based data augmentation for fixed phrase speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2102.09817.pdf)
>  Data augmentation is commonly used to help build a robust speaker verification system, especially in limited-resource case. However, conventional data augmentation methods usually focus on the diversity of acoustic environment, leaving the lexicon variation neglected. For text dependent speaker verification tasks, it's well-known that preparing training data with the target transcript is the most effectual approach to build a well-performing system, however collecting such data is time-consuming and expensive. In this work, we propose a unit selection synthesis based data augmentation method to leverage the abundant text-independent data resources. In this approach text-independent speeches of each speaker are firstly broke up to speech segments each contains one phone unit. Then segments that contain phonetics in the target transcript are selected to produce a speech with the target transcript by concatenating them in turn. Experiments are carried out on the AISHELL Speaker Verification Challenge 2019 database, the results and analysis shows that our proposed method can boost the system performance significantly.      
### 36.Hierarchical Recurrent Neural Networks for Conditional Melody Generation with Long-term Structure  [ :arrow_down: ](https://arxiv.org/pdf/2102.09794.pdf)
>  The rise of deep learning technologies has quickly advanced many fields, including that of generative music systems. There exist a number of systems that allow for the generation of good sounding short snippets, yet, these generated snippets often lack an overarching, longer-term structure. In this work, we propose CM-HRNN: a conditional melody generation model based on a hierarchical recurrent neural network. This model allows us to generate melodies with long-term structures based on given chord accompaniments. We also propose a novel, concise event-based representation to encode musical lead sheets while retaining the notes' relative position within the bar with respect to the musical meter. With this new data representation, the proposed architecture can simultaneously model the rhythmic, as well as the pitch structures in an effective way. Melodies generated by the proposed model were extensively evaluated in quantitative experiments as well as a user study to ensure the musical quality of the output as well as to evaluate if they contain repeating patterns. We also compared the system with the state-of-the-art AttentionRNN. This comparison shows that melodies generated by CM-HRNN contain more repeated patterns (i.e., higher compression ratio) and a lower tonal tension (i.e., more tonally concise). Results from our listening test indicate that CM-HRNN outperforms AttentionRNN in terms of long-term structure and overall rating.      
### 37.Regularized Recovery by Multi-order Partial Hypergraph Total Variation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09771.pdf)
>  Capturing complex high-order interactions among data is an important task in many scenarios. A common way to model high-order interactions is to use hypergraphs whose topology can be mathematically represented by tensors. Existing methods use a fixed-order tensor to describe the topology of the whole hypergraph, which ignores the divergence of different-order interactions. In this work, we take this divergence into consideration, and propose a multi-order hypergraph Laplacian and the corresponding total variation. Taking this total variation as a regularization term, we can utilize the topology information contained by it to smooth the hypergraph signal. This can help distinguish different-order interactions and represent high-order interactions accurately.      
### 38.Frequency-Temporal Attention Network for Singing Melody Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2102.09763.pdf)
>  Musical audio is generally composed of three physical properties: frequency, time and magnitude. Interestingly, human auditory periphery also provides neural codes for each of these dimensions to perceive music. Inspired by these intrinsic characteristics, a frequency-temporal attention network is proposed to mimic human auditory for singing melody extraction. In particular, the proposed model contains frequency-temporal attention modules and a selective fusion module corresponding to these three physical properties. The frequency attention module is used to select the same activation frequency bands as did in cochlear and the temporal attention module is responsible for analyzing temporal patterns. Finally, the selective fusion module is suggested to recalibrate magnitudes and fuse the raw information for prediction. In addition, we propose to use another branch to simultaneously predict the presence of singing voice melody. The experimental results show that the proposed model outperforms existing state-of-the-art methods.      
### 39.A Sequential Learning Algorithm for Probabilistically Robust Controller Tuning  [ :arrow_down: ](https://arxiv.org/pdf/2102.09738.pdf)
>  In this paper, we introduce a sequential learning algorithm to address a probabilistically robust controller tuning problem. The algorithm leverages ideas from the areas of randomised algorithms and ordinal optimisation, which have both been proposed to find approximate solutions for difficult design problems in control. We formally prove that our algorithm yields a controller which meets a specified probabilisitic performance specification, assuming a Gaussian or near-Gaussian copula model for the controller performances. Additionally, we are able to characterise the computational requirement of the algorithm by using a lower bound on the distribution function of the algorithm's stopping time. To validate our work, the algorithm is then demonstrated for the purpose of tuning model predictive controllers on a diesel engine air-path. It is shown that the algorithm is able to successfully tune a single controller to meet a desired performance threshold, even in the presence of uncertainty in the diesel engine model, that is inherent when a single representation is used across a fleet of vehicles.      
### 40.One Shot Audio to Animated Video Generation  [ :arrow_down: ](https://arxiv.org/pdf/2102.09737.pdf)
>  We consider the challenging problem of audio to animated video generation. We propose a novel method OneShotAu2AV to generate an animated video of arbitrary length using an audio clip and a single unseen image of a person as an input. The proposed method consists of two stages. In the first stage, OneShotAu2AV generates the talking-head video in the human domain given an audio and a person's image. In the second stage, the talking-head video from the human domain is converted to the animated domain. The model architecture of the first stage consists of spatially adaptive normalization based multi-level generator and multiple multilevel discriminators along with multiple adversarial and non-adversarial losses. The second stage leverages attention based normalization driven GAN architecture along with temporal predictor based recycle loss and blink loss coupled with lipsync loss, for unsupervised generation of animated video. In our approach, the input audio clip is not restricted to any specific language, which gives the method multilingual applicability. OneShotAu2AV can generate animated videos that have: (a) lip movements that are in sync with the audio, (b) natural facial expressions such as blinks and eyebrow movements, (c) head movements. Experimental evaluation demonstrates superior performance of OneShotAu2AV as compared to U-GAT-IT and RecycleGan on multiple quantitative metrics including KID(Kernel Inception Distance), Word error rate, blinks/sec      
### 41.Continual Learning for Blind Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2102.09717.pdf)
>  The explosive growth of image data facilitates the fast development of image processing and computer vision methods for emerging visual applications, meanwhile introducing novel distortions to the processed images. This poses a grand challenge to existing blind image quality assessment (BIQA) models, failing to continually adapt to such subpopulation shift. Recent work suggests training BIQA methods on the combination of all available human-rated IQA datasets. However, this type of approach is not scalable to a large number of datasets, and is cumbersome to incorporate a newly created dataset as well. In this paper, we formulate continual learning for BIQA, where a model learns continually from a stream of IQA datasets, building on what was learned from previously seen data. We first identify five desiderata in the new setting with a measure to quantify the plasticity-stability trade-off. We then propose a simple yet effective method for learning BIQA models continually. Specifically, based on a shared backbone network, we add a prediction head for a new dataset, and enforce a regularizer to allow all prediction heads to evolve with new data while being resistant to catastrophic forgetting of old data. We compute the quality score by an adaptive weighted summation of estimates from all prediction heads. Extensive experiments demonstrate the promise of the proposed continual learning method in comparison to standard training techniques for BIQA.      
### 42.Fixing Errors of the Google Voice Recognizer through Phonetic Distance Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2102.09680.pdf)
>  Speech recognition systems for the Spanish language, such as Google's, produce errors quite frequently when used in applications of a specific domain. These errors mostly occur when recognizing words new to the recognizer's language model or ad hoc to the domain. This article presents an algorithm that uses Levenshtein distance on phonemes to reduce the speech recognizer's errors. The preliminary results show that it is possible to correct the recognizer's errors significantly by using this metric and using a dictionary of specific phrases from the domain of the application. Despite being designed for particular domains, the algorithm proposed here is of general application. The phrases that must be recognized can be explicitly defined for each application, without the algorithm having to be modified. It is enough to indicate to the algorithm the set of sentences on which it must work. The algorithm's complexity is $O(tn)$, where $t$ is the number of words in the transcript to be corrected, and $n$ is the number of phrases specific to the domain.      
### 43.Causal Inference Q-Network: Toward Resilient Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.09677.pdf)
>  Deep reinforcement learning (DRL) has demonstrated impressive performance in various gaming simulators and real-world applications. In practice, however, a DRL agent may receive faulty observation by abrupt interferences such as black-out, frozen-screen, and adversarial perturbation. How to design a resilient DRL algorithm against these rare but mission-critical and safety-crucial scenarios is an important yet challenging task. In this paper, we consider a resilient DRL framework with observational interferences. Under this framework, we discuss the importance of the causal relation and propose a causal inference based DRL algorithm called causal inference Q-network (CIQ). We evaluate the performance of CIQ in several benchmark DRL environments with different types of interferences. Our experimental results show that the proposed CIQ method could achieve higher performance and more resilience against observational interferences.      
### 44.Effective Cache Apportioning for Performance Isolation Under Compiler Guidance  [ :arrow_down: ](https://arxiv.org/pdf/2102.09673.pdf)
>  With a growing number of cores per socket in modern data-centers where multi-tenancy of a diverse set of applications must be efficiently supported, effective sharing of the last level cache is a very important problem. This is challenging because modern workloads exhibit \textit{dynamic phase behavior} - their cache requirements \&amp; sensitivity vary across different execution points. To tackle this problem, we propose \textit{Com-CAS}, a compiler-guided cache apportioning system that provides smart cache allocation to co-executing applications in a system. The front-end of \textit{Com-CAS} is primarily a compiler-framework equipped with learning mechanisms to predict cache requirements, while the backend consists of an allocation framework with a pro-active scheduler that apportions cache dynamically to co-executing applications. Our system improved average throughput by 21\%, with a maximum of 54\% while maintaining the worst individual application execution time degradation within 15\% to meet SLA requirements.      
### 45.The Effectiveness of Subsidies and Tolls in Congestion Games  [ :arrow_down: ](https://arxiv.org/pdf/2102.09655.pdf)
>  Are rewards or penalties more effective in influencing user behavior? This work compares the effectiveness of subsidies and tolls in incentivizing user behavior in congestion games. The predominantly studied method of influencing user behavior in network routing problems is to institute taxes which alter users' observed costs in a manner that causes their self-interested choices to more closely align with a system-level objective. Another conceivable method to accomplish the same goal is to subsidize the users' actions that are preferable from a system-level perspective. We show that, when users behave similarly and predictably, subsidies offer superior performance guarantees to tolls under similar budgetary constraints; however, in the presence of unknown player heterogeneity, subsidies fail to offer the same robustness as tolls.      
### 46.Attempted Blind Constrained Descent Experiments  [ :arrow_down: ](https://arxiv.org/pdf/2102.09643.pdf)
>  Blind Descent uses constrained but, guided approach to learn the weights. The probability density function is non-zero in the infinite space of the dimension (case in point: Gaussians and normal probability distribution functions). In Blind Descent paper, some of the implicit ideas involving layer by layer training and filter by filter training (with different batch sizes) were proposed as probable greedy solutions. The results of similar experiments are discussed. Octave (and proposed PyTorch variants) source code of the experiments of this paper can be found at <a class="link-external link-https" href="https://github.com/PrasadNR/Attempted-Blind-Constrained-Descent-Experiments-ABCDE-" rel="external noopener nofollow">this https URL</a> . This is compared against the ABCDE derivatives of the original PyTorch source code of <a class="link-external link-https" href="https://github.com/akshat57/Blind-Descent" rel="external noopener nofollow">this https URL</a> .      
### 47.Deep learning-based COVID-19 pneumonia classification using chest CT images: model generalizability  [ :arrow_down: ](https://arxiv.org/pdf/2102.09616.pdf)
>  Since the outbreak of the COVID-19 pandemic, worldwide research efforts have focused on using artificial intelligence (AI) technologies on various medical data of COVID-19-positive patients in order to identify or classify various aspects of the disease, with promising reported results. However, concerns have been raised over their generalizability, given the heterogeneous factors in training datasets. This study aims to examine the severity of this problem by evaluating deep learning (DL) classification models trained to identify COVID-19-positive patients on 3D computed tomography (CT) datasets from different countries. We collected one dataset at UT Southwestern (UTSW), and three external datasets from different countries: CC-CCII Dataset (China), COVID-CTset (Iran), and MosMedData (Russia). We divided the data into 2 classes: COVID-19-positive and COVID-19-negative patients. We trained nine identical DL-based classification models by using combinations of the datasets with a 72% train, 8% validation, and 20% test data split. The models trained on a single dataset achieved accuracy/area under the receiver operating characteristics curve (AUC) values of 0.87/0.826 (UTSW), 0.97/0.988 (CC-CCCI), and 0.86/0.873 (COVID-CTset) when evaluated on their own dataset. The models trained on multiple datasets and evaluated on a test set from one of the datasets used for training performed better. However, the performance dropped close to an AUC of 0.5 (random guess) for all models when evaluated on a different dataset outside of its training datasets. Including the MosMedData, which only contained positive labels, into the training did not necessarily help the performance on the other datasets. Multiple factors likely contribute to these results, such as patient demographics and differences in image acquisition or reconstruction, causing a data shift among different study cohorts.      
### 48.Modelling Paralinguistic Properties in Conversational Speech to Detect Bipolar Disorder and Borderline Personality Disorder  [ :arrow_down: ](https://arxiv.org/pdf/2102.09607.pdf)
>  Bipolar disorder (BD) and borderline personality disorder (BPD) are two chronic mental health conditions that clinicians find challenging to distinguish based on clinical interviews, due to their overlapping symptoms. In this work, we investigate the automatic detection of these two conditions by modelling both verbal and non-verbal cues in a set of interviews. We propose a new approach of modelling short-term features with visibility-signature transform, and compare it with widely used high-level statistical functions. We demonstrate the superior performance of our proposed signature-based model. Furthermore, we show the role of different sets of features in characterising BD and BPD.      
### 49.Benefits of Linear Conditioning for Segmentation using Metadata  [ :arrow_down: ](https://arxiv.org/pdf/2102.09582.pdf)
>  Medical images are often accompanied by metadata describing the image (vendor, acquisition parameters) and the patient (disease type or severity, demographics, genomics). This metadata is usually disregarded by image segmentation methods. In this work, we adapt a linear conditioning method called FiLM (Feature-wise Linear Modulation) for image segmentation tasks. This FiLM adaptation enables integrating metadata into segmentation models for better performance. We observed an average Dice score increase of 5.1% on spinal cord tumor segmentation when incorporating the tumor type with FiLM. The metadata modulates the segmentation process through low-cost affine transformations applied on feature maps which can be included in any neural network's architecture. Additionally, we assess the relevance of segmentation FiLM layers for tackling common challenges in medical imaging: training with limited or unbalanced number of annotated data, multi-class training with missing segmentations, and model adaptation to multiple tasks. Our results demonstrated the following benefits of FiLM for segmentation: FiLMed U-Net was robust to missing labels and reached higher Dice scores with few labels (up to 16.7%) compared to single-task U-Net. The code is open-source and available at <a class="link-external link-http" href="http://www.ivadomed.org" rel="external noopener nofollow">this http URL</a>.      

# ArXiv eess --Fri, 26 Feb 2021
### 1.Hybrid Systems, Iterative Learning Control, and Non-minimum Phase  [ :arrow_down: ](https://arxiv.org/pdf/2102.13070.pdf)
>  Hybrid systems have steadily grown in popularity over the last few decades because they ease the task of modeling complicated nonlinear systems. Legged locomotion, robotic manipulation, and additive manufacturing are representative examples of systems benefiting from hybrid modeling. They are also prime examples of repetitive processes; gait cycles in walking, product assembly tasks in robotic manipulation, and material deposition in additive manufacturing. Thus, they would also benefit substantially from Iterative Learning Control (ILC), a class of feedforward controllers for repetitive systems that achieve high performance in output reference tracking by learning from the errors of past process cycles. However, the literature is bereft of ILC syntheses from hybrid models. The main thrust of this dissertation is to provide a boradly applicable theory of ILC for deterministic, discrete-time hybrid systems, i.e. piecewise defined (PWD) systems. In summary, the three main gaps addressed by this dissertation are (1) the lack of compatibility between existing hybrid modeling frameworks and ILC synthesis techniques, (2) the failure of ILC based on Newton's method (NILC) for systems with unstable inverses, and (3) the lack of inversion and stable inversion theory for piecewise affine (PWA) systems (a subset of PWD systems). These issues are addressed by (1) developing a closed-form representation for PWD systems, (2) developing a new ILC framework informed by NILC but with the new ability to incorporate stabilizing model inversion techniques, and (3) deriving conventional and stable model inversion theories for PWA systems.      
### 2.On Instabilities of Conventional Multi-Coil MRI Reconstruction to Small Adverserial Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2102.13066.pdf)
>  Although deep learning (DL) has received much attention in accelerated MRI, recent studies suggest small perturbations may lead to instabilities in DL-based reconstructions, leading to concern for their clinical application. However, these works focus on single-coil acquisitions, which is not practical. We investigate instabilities caused by small adversarial attacks for multi-coil acquisitions. Our results suggest that, parallel imaging and multi-coil CS exhibit considerable instabilities against small adversarial perturbations.      
### 3.Application of twin delayed deep deterministic policy gradient learning for the control of transesterification process  [ :arrow_down: ](https://arxiv.org/pdf/2102.13012.pdf)
>  The persistent depletion of fossil fuels has encouraged mankind to look for alternatives fuels that are renewable and environment-friendly. One of the promising and renewable alternatives to fossil fuels is bio-diesel produced by means of the batch transesterification process. Control of the batch transesterification process is difficult due to its complex and non-linear dynamics. It is expected that some of these challenges can be addressed by developing control strategies that directly interact with the process and learning from the experiences. To achieve the same, this study explores the feasibility of reinforcement learning (RL) based control of the batch transesterification process. In particular, the present study exploits the application of twin delayed deep deterministic policy gradient (TD3) based RL for the continuous control of the batch transesterification process. These results showcase that TD3 based controller is able to control batch transesterification process and can be a promising direction towards the goal of artificial intelligence-based control in process industries.      
### 4.Data-Driven Incident Detection in Power Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.12997.pdf)
>  In a power distribution network with energy storage systems (ESS) and advanced controls, traditional monitoring and protection schemes are not well suited for detecting anomalies such as malfunction of controllable devices. In this work, we propose a data-driven technique for the detection of incidents relevant to the operation of ESS in distribution grids. This approach leverages the causal relationship observed among sensor data streams, and does not require prior knowledge of the system model or parameters. Our methodology includes a data augmentation step which allows for the detection of incidents even when sensing is scarce. The effectiveness of our technique is illustrated through case studies which consider active power dispatch and reactive power control of ESS.      
### 5.Event-Driven Receding Horizon Control of Energy-Aware Dynamic Agents For Distributed Persistent Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2102.12963.pdf)
>  This paper addresses the persistent monitoring problem defined on a network where a set of nodes (targets) needs to be monitored by a team of dynamic energy-aware agents. The objective is to control the agents' motion to jointly optimize the overall agent energy consumption and a measure of overall node state uncertainty, evaluated over a finite period of interest. To achieve these objectives, we extend an established event-driven Receding Horizon Control (RHC) solution by adding an optimal controller to account for agent motion dynamics and associated energy consumption. The resulting RHC solution is computationally efficient, distributed and on-line. Finally, numerical results are provided highlighting improvements compared to an existing RHC solution that uses energy-agnostic first-order agents.      
### 6.Deep learning based electrical noise removal enables high spectral optoacoustic contrast in deep tissue  [ :arrow_down: ](https://arxiv.org/pdf/2102.12960.pdf)
>  Image contrast in multispectral optoacoustic tomography (MSOT) can be severely reduced by electrical noise and interference in the acquired optoacoustic signals. Signal processing techniques have proven insufficient to remove the effects of electrical noise because they typically rely on simplified models and fail to capture complex characteristics of signal and noise. Moreover, they often involve time-consuming processing steps that are unsuited for real-time imaging applications. In this work, we develop and demonstrate a discriminative deep learning (DL) approach to separate electrical noise from optoacoustic signals prior to image reconstruction. The proposed DL algorithm is based on two key features. First, it learns spatiotemporal correlations in both noise and signal by using the entire optoacoustic sinogram as input. Second, it employs training based on a large dataset of experimentally acquired pure noise and synthetic optoacoustic signals. We validated the ability of the trained model to accurately remove electrical noise on synthetic data and on optoacoustic images of a phantom and the human breast. We demonstrate significant enhancements of morphological and spectral optoacoustic images reaching 19% higher blood vessel contrast and localized spectral contrast at depths of more than 2 cm for images acquired in vivo. We discuss how the proposed denoising framework is applicable to clinical multispectral optoacoustic tomography and suitable for real-time operation.      
### 7.Adaptive Load Shedding for Grid Emergency Control via Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.12908.pdf)
>  Emergency control, typically such as under-voltage load shedding (UVLS), is broadly used to grapple with low voltage and voltage instability issues in practical power systems under contingencies. However, existing emergency control schemes are rule-based and cannot be adaptively applied to uncertain and floating operating conditions. This paper proposes an adaptive UVLS algorithm for emergency control via deep reinforcement learning (DRL) and expert systems. We first construct dynamic components for picturing the power system operation as the environment. The transient voltage recovery criteria, which poses time-varying requirements to UVLS, is integrated into the states and reward function to advise the learning of deep neural networks. The proposed approach has no tuning issue of coefficients in reward functions, and this issue was regarded as a deficiency in the existing DRL-based algorithms. Extensive case studies illustrate that the proposed method outperforms the traditional UVLS relay in both the timeliness and efficacy for emergency control.      
### 8.ShuffleUNet: Super resolution of diffusion-weighted MRIs using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.12898.pdf)
>  Diffusion-weighted magnetic resonance imaging (DW-MRI) can be used to characterise the microstructure of the nervous tissue, e.g. to delineate brain white matter connections in a non-invasive manner via fibre tracking. Magnetic Resonance Imaging (MRI) in high spatial resolution would play an important role in visualising such fibre tracts in a superior manner. However, obtaining an image of such resolution comes at the expense of longer scan time. Longer scan time can be associated with the increase of motion artefacts, due to the patient's psychological and physical conditions. Single Image Super-Resolution (SISR), a technique aimed to obtain high-resolution (HR) details from one single low-resolution (LR) input image, achieved with Deep Learning, is the focus of this study. Compared to interpolation techniques or sparse-coding algorithms, deep learning extracts prior knowledge from big datasets and produces superior MRI images from the low-resolution counterparts. In this research, a deep learning based super-resolution technique is proposed and has been applied for DW-MRI. Images from the IXI dataset have been used as the ground-truth and were artificially downsampled to simulate the low-resolution images. The proposed method has shown statistically significant improvement over the baselines and achieved an SSIM of $0.913\pm0.045$.      
### 9.On a Network SIS Epidemic Model with Cooperative and Antagonistic Opinion Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2102.12834.pdf)
>  We propose a mathematical model to study coupled epidemic and opinion dynamics in a network of communities. Our model captures SIS epidemic dynamics whose evolution is dependent on the opinions of the communities toward the epidemic, and vice versa. In particular, we allow both cooperative and antagonistic interactions, representing similar and opposing perspectives on the severity of the epidemic, respectively. We propose an Opinion-Dependent Reproduction Number to characterize the mutual influence between epidemic spreading and opinion dissemination over the networks. Through stability analysis of the equilibria, we explore the impact of opinions on both epidemic outbreak and eradication, characterized by bounds on the Opinion-Dependent Reproduction Number. We also show how to eradicate epidemics by reshaping the opinions, offering researchers an approach for designing control strategies to reach target audiences to ensure effective epidemic suppression.      
### 10.Automatic Classification of OSA related Snoring Signals from Nocturnal Audio Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2102.12829.pdf)
>  In this study, the development of an automatic algorithm is presented to classify the nocturnal audio recording of an obstructive sleep apnoea (OSA) patient as OSA related snore, simple snore and other sounds. Recent studies has been shown that knowledge regarding the OSA related snore could assist in identifying the site of airway collapse. Audio signal was recorded simultaneously with full-night polysomnography during sleep with a ceiling microphone. Time and frequency features of the nocturnal audio signal were extracted to classify the audio signal into OSA related snore, simple snore and other sounds. Two algorithms were developed to extract OSA related snore using an linear discriminant analysis (LDA) classifier based on the hypothesis that OSA related snoring can assist in identifying the site-of-upper airway collapse. An unbiased nested leave-one patient-out cross-validation process was used to select a high performing feature set from the full set of features. Results indicated that the algorithm achieved an accuracy of 87% for identifying snore events from the audio recordings and an accuracy of 72% for identifying OSA related snore events from the snore events. The direct method to extract OSA-related snore events using a multi-class LDA classifier achieved an accuracy of 64% using the feature selection algorithm. Our results gives a clear indication that OSA-related snore events can be extracted from nocturnal sound recordings, and therefore could potentially be used as a new tool for identifying the site of airway collapse from the nocturnal audio recordings.      
### 11.Fronthaul Compression and Passive Beamforming Design for Intelligent Reflecting Surface-aided Cloud Radio Access Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.12817.pdf)
>  This letter studies a cloud radio access network (C-RAN) with multiple intelligent reflecting surfaces (IRS) deployed between users and remote radio heads (RRH). Specifically, we consider the uplink transmission where each RRH quantizes the received signals from the users by either point-to-point compression or Wyner-Ziv compression and then transmits the quantization bits to the BBU pool through capacity limited fronthhual links. To maximize the uplink sum rate, we jointly optimize the passive beamformers of IRSs and the quantization noise covariance matrices of fronthoul compression. An joint fronthaul compression and passive beamforming design is proposed by exploiting the Arimoto-Blahut algorithm and semidefinte relaxation (SDR). Numerical results show the performance gain achieved by the proposed algorithm.      
### 12.An Overview of Signal Processing Techniques for Joint Communication and Radar Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2102.12780.pdf)
>  Joint communication and radar sensing (JCR) represents an emerging research field aiming to integrate the above two functionalities into a single system, sharing a majority of hardware and signal processing modules and, in a typical case, sharing a single transmitted signal. It is recognised as a key approach in significantly improving spectrum efficiency, reducing device size, cost and power consumption, and improving performance thanks to potential close cooperation of the two functions. Advanced signal processing techniques are critical for making the integration efficient, from transmission signal design to receiver processing. This paper provides a comprehensive overview of JCR systems from the signal processing perspective, with a focus on state-of-the-art. A balanced coverage on both transmitter and receiver is provided for three types of JCR systems, communication-centric, radar-centric, and joint design and optimization.      
### 13.Reducing Labelled Data Requirement for Pneumonia Segmentation using Image Augmentations  [ :arrow_down: ](https://arxiv.org/pdf/2102.12764.pdf)
>  Deep learning semantic segmentation algorithms can localise abnormalities or opacities from chest radiographs. However, the task of collecting and annotating training data is expensive and requires expertise which remains a bottleneck for algorithm performance. We investigate the effect of image augmentations on reducing the requirement of labelled data in the semantic segmentation of chest X-rays for pneumonia detection. We train fully convolutional network models on subsets of different sizes from the total training data. We apply a different image augmentation while training each model and compare it to the baseline trained on the entire dataset without augmentations. We find that rotate and mixup are the best augmentations amongst rotate, mixup, translate, gamma and horizontal flip, wherein they reduce the labelled data requirement by 70% while performing comparably to the baseline in terms of AUC and mean IoU in our experiments.      
### 14.Binary segmentation of medical images using implicit spline representations and deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.12759.pdf)
>  We propose a novel approach to image segmentation based on combining implicit spline representations with deep convolutional neural networks. This is done by predicting the control points of a bivariate spline function whose zero-set represents the segmentation boundary. We adapt several existing neural network architectures and design novel loss functions that are tailored towards providing implicit spline curve approximations. The method is evaluated on a congenital heart disease computed tomography medical imaging dataset. Experiments are carried out by measuring performance in various standard metrics for different networks and loss functions. We determine that splines of bidegree $(1,1)$ with $128\times128$ coefficient resolution performed optimally for $512\times 512$ resolution CT images. For our best network, we achieve an average volumetric test Dice score of almost 92%, which reaches the state of the art for this congenital heart disease dataset.      
### 15.ConCrete MAP: Learning a Probabilistic Relaxation of Discrete Variables for Soft Estimation with Low Complexity  [ :arrow_down: ](https://arxiv.org/pdf/2102.12756.pdf)
>  Following the great success of Machine Learning (ML), especially Deep Neural Networks (DNNs), in many research domains in 2010s, several learning-based approaches were proposed for detection in large inverse linear problems, e.g., massive MIMO systems. The main motivation behind is that the complexity of Maximum A-Posteriori (MAP) detection grows exponentially with system dimensions. Instead of using DNNs, essentially being a black-box in its most basic form, we take a slightly different approach and introduce a probabilistic Continuous relaxation of disCrete variables to MAP detection. Enabling close approximation and continuous optimization, we derive an iterative detection algorithm: ConCrete MAP Detection (CMD). Furthermore, by extending CMD to the idea of deep unfolding, we allow for (online) optimization of a small number of parameters to different working points while limiting complexity. In contrast to recent DNN-based approaches, we select the optimization criterion and output of CMD based on information theory and are thus able to learn approximate probabilities of the individual optimal detector. This is crucial for soft decoding in today's communication systems. Numerical simulation results in MIMO systems reveal CMD to feature a promising performance complexity trade-off compared to SotA. Notably, we demonstrate CMD's soft outputs to be reliable for decoders.      
### 16.Coarse-to-fine Airway Segmentation Using Multi information Fusion Network and CNN-based Region Growing  [ :arrow_down: ](https://arxiv.org/pdf/2102.12755.pdf)
>  Automatic airway segmentation from chest computed tomography (CT) scans plays an important role in pulmonary disease diagnosis and computer-assisted therapy. However, low contrast at peripheral branches and complex tree-like structures remain as two mainly challenges for airway segmentation. Recent research has illustrated that deep learning methods perform well in segmentation tasks. Motivated by these works, a coarse-to-fine segmentation framework is proposed to obtain a complete airway tree. Our framework segments the overall airway and small branches via the multi-information fusion convolution neural network (Mif-CNN) and the CNN-based region growing, respectively. In Mif-CNN, atrous spatial pyramid pooling (ASPP) is integrated into a u-shaped network, and it can expend the receptive field and capture multi-scale information. Meanwhile, boundary and location information are incorporated into semantic information. These information are fused to help Mif-CNN utilize additional context knowledge and useful features. To improve the performance of the segmentation result, the CNN-based region growing method is designed to focus on obtaining small branches. A voxel classification network (VCN), which can entirely capture the rich information around each voxel, is applied to classify the voxels into airway and non-airway. In addition, a shape reconstruction method is used to refine the airway tree.      
### 17.Synthesis of Hybrid Automata with Affine Dynamics from Time-Series Data  [ :arrow_down: ](https://arxiv.org/pdf/2102.12734.pdf)
>  Formal design of embedded and cyber-physical systems relies on mathematical modeling. In this paper, we consider the model class of hybrid automata whose dynamics are defined by affine differential equations. Given a set of time-series data, we present an algorithmic approach to synthesize a hybrid automaton exhibiting behavior that is close to the data, up to a specified precision, and changes in synchrony with the data. A fundamental problem in our synthesis algorithm is to check membership of a time series in a hybrid automaton. Our solution integrates reachability and optimization techniques for affine dynamical systems to obtain both a sufficient and a necessary condition for membership, combined in a refinement framework. The algorithm processes one time series at a time and hence can be interrupted, provide an intermediate result, and be resumed. We report experimental results demonstrating the applicability of our synthesis approach.      
### 18.Distributional robustness in minimax linear quadratic control with Wasserstein distance  [ :arrow_down: ](https://arxiv.org/pdf/2102.12715.pdf)
>  To address the issue of inaccurate distributions in practical stochastic systems, a minimax linear-quadratic control method is proposed using the Wasserstein metric. Our method aims to construct a control policy that is robust against errors in an empirical distribution of underlying uncertainty, by adopting an adversary that selects the worst-case distribution. The opponent receives a Wasserstein penalty proportional to the amount of deviation from the empirical distribution. A closed-form expression of the finite-horizon optimal policy pair is derived using a Riccati equation. The result is then extended to the infinite-horizon average cost setting by identifying conditions under which the Riccati recursion converges to the unique positive semi-definite solution to an algebraic Riccati equation. Our method is shown to possess several salient features including closed-loop stability, and an out-of-sample performance guarantee. We also discuss how to optimize the penalty parameter for enhancing the distributional robustness of our control policy. Last but not least, a theoretical connection to the classical $H_\infty$-method is identified from the perspective of distributional robustness.      
### 19.Control of Scanning Quantum Dot Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2102.12708.pdf)
>  Scanning quantum dot microscopy is a recently developed high-resolution microscopy technique that is based on atomic force microscopy and is capable of imaging the electrostatic potential of nanostructures like molecules or single atoms. Recently, it could be shown that it not only yields qualitatively but also quantitatively cutting edge images even on an atomic level. In this paper we present how control is a key enabling element to this. The developed control approach consists of a two-degree-of-freedom control framework that comprises a feedforward and a feedback part. For the latter we design two tailored feedback controllers. The feedforward part generates a reference for the current scanned line based on the previously scanned one. We discuss in detail various aspects of the presented control approach and its implications for scanning quantum dot microscopy. We evaluate the influence of the feedforward part and compare the two proposed feedback controllers. The proposed control algorithms speed up scanning quantum dot microscopy by more than a magnitude and enable to scan large sample areas.      
### 20.A flapping feathered wing-powered aerial vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2102.12687.pdf)
>  An aerial vehicle powered by flapping feathered wings was designed, developed and fabricated. Different from legacy flapping-wing aerial vehicles with membrane wings, the new design uses authentic bird feathers to fabricate wings. In field tests, a radio-controlled electric-powered aerial vehicle with flapping feathered wings successfully took off, flew up to 63.88 s and landed safely. It was found that flapping feathered wings can generate sufficient thrust and lift to make a man-made aerial vehicle accomplish takeoff, sustainable flight and a safe landing.      
### 21.Preview Reference Governors  [ :arrow_down: ](https://arxiv.org/pdf/2102.12654.pdf)
>  This paper presents a constraint management strategy based on Scalar Reference Governors (SRG) to enforce output, state, and control constraints while taking into account the preview information of the reference signals. The strategy, referred to as the Preview Reference Governor (PRG), can outperform SRG while maintaining the highly-attractive computational benefits of SRG. However, as it is shown, the performance of PRG may suffer if large preview horizons are used. An extension of PRG, referred to as Multi-horizon PRG, is proposed to remedy this issue. Quantitative comparisons between SRG, PRG, and Multi-horizon PRG on a vehicle rollover example are presented to illustrate their performance and computation time.      
### 22.Optimal steering to invariant distributions for networks flows  [ :arrow_down: ](https://arxiv.org/pdf/2102.12628.pdf)
>  We derive novel results on the ergodic theory of irreducible, aperiodic Markov chains. We show how to optimally steer the network flow to a stationary distribution over a finite or infinite time horizon. Optimality is with respect to an entropic distance between distributions on feasible paths. When the prior is reversible, it shown that solutions to this discrete time and space steering problem are reversible as well. A notion of temperature is defined for Boltzmann distributions on networks, and problems analogous to cooling (in this case, for evolutions in discrete space and time) are discussed.      
### 23.Meta-Learning for improving rare word recognition in end-to-end ASR  [ :arrow_down: ](https://arxiv.org/pdf/2102.12624.pdf)
>  We propose a new method of generating meaningful embeddings for speech, changes to four commonly used meta learning approaches to enable them to perform keyword spotting in continuous signals and an approach of combining their outcomes into an end-to-end automatic speech recognition system to improve rare word recognition. We verify the functionality of each of our three contributions in two experiments exploring their performance for different amounts of classes (N-way) and examples per class (k-shot) in a few-shot setting. We find that the speech embeddings work well and the changes to the meta learning approaches also clearly enable them to perform continuous signal spotting. Despite the interface between keyword spotting and speech recognition being very simple, we are able to consistently improve word error rate by up to 5%.      
### 24.Semantic Communication Systems for Speech Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2102.12605.pdf)
>  Semantic communications could improve the transmission efficiency significantly by exploring the input semantic information. Motivated by the breakthroughs in deep learning (DL), we make an effort to recover the transmitted speech signals in the semantic communication systems, which minimizes the error at the semantic level rather than the bit level or symbol level as in the traditional communication systems. Particularly, we design a DL-enabled semantic communication system for speech signals, named DeepSC-S. Based on an attention mechanism employing squeeze-and-excitation (SE) networks, DeepSC-S is able to identify the essential speech information and assign high values to the weights corresponding to the essential information when training the neural network. Moreover, in order to facilitate the proposed DeepSC-S to cater to dynamic channel environments, we dedicate to find a general model to cope with various channel conditions without retraining. Furthermore, to verify the model adaptation in practice, we investigate DeepSC-S in the telephone systems as well as the multimedia transmission systems, which usually requires higher data rates and lower transmission latency. The simulation results demonstrate that our proposed DeepSC-S achieves higher system performance than the traditional communications in both telephone systems and multimedia transmission systems by comparing the speech signals metrics, signal-to-distortion ration and perceptual evaluation of speech distortion. Besides, DeepSC-S is more robust to channel variations than the traditional approaches, especially in the low signal-to-noise (SNR) regime.      
### 25.A Comprehensive Review on the NILM Algorithms for Energy Disaggregation  [ :arrow_down: ](https://arxiv.org/pdf/2102.12578.pdf)
>  The housing structures have changed with urbanization and the growth due to the construction of high-rise buildings all around the world requires end-use appliance energy conservation and management in real-time. This shift also came along with smart-meters which enabled the estimation of appliance-specific power consumption from the buildings aggregate power consumption reading. Non-intrusive load monitoring (NILM) or energy disaggregation is aimed at separating the household energy measured at the aggregate level into constituent appliances. Over the years, signal processing and machine learning algorithms have been combined to achieve this. Incredible research and publications have been conducted on energy disaggregation, non-intrusive load monitoring, home energy management and appliance classification. There exists an API, NILMTK, a reproducible benchmark algorithm for the same. Many other approaches to perform energy disaggregation has been adapted such as deep neural network architectures and big data approach for household energy disaggregation. This paper provides a survey of the effective NILM system frameworks and reviews the performance of the benchmark algorithms in a comprehensive manner. This paper also summarizes the wide application scope and the effectiveness of the algorithmic performance on three publicly available data sets.      
### 26.An FPGA Implementation of Convolutional Spiking Neural Networks for Radioisotope Identification  [ :arrow_down: ](https://arxiv.org/pdf/2102.12565.pdf)
>  This paper details the FPGA implementation methodology for Convolutional Spiking Neural Networks (CSNN) and applies this methodology to low-power radioisotope identification using high-resolution data. Power consumption of 75 mW has been achieved on an FPGA implementation of a CSNN, with an inference accuracy of 90.62% on a synthetic dataset. The chip validation method is presented. Prototyping was accelerated by evaluating SNN parameters using SpiNNaker neuromorphic platform.      
### 27.Maximum Likelihood Constraint Inference from Stochastic Demonstrations  [ :arrow_down: ](https://arxiv.org/pdf/2102.12554.pdf)
>  When an expert operates a perilous dynamic system, ideal constraint information is tacitly contained in their demonstrated trajectories and controls. The likelihood of these demonstrations can be computed, given the system dynamics and task objective, and the maximum likelihood constraints can be identified. Prior constraint inference work has focused mainly on deterministic models. Stochastic models, however, can capture the uncertainty and risk tolerance that are often present in real systems of interest. <br>This paper extends maximum likelihood constraint inference to stochastic applications by using maximum causal entropy likelihoods. Furthermore, we propose an efficient algorithm that computes constraint likelihood and risk tolerance in a unified Bellman backup, allowing us to generalize to stochastic systems without increasing computational complexity.      
### 28.Estimation and Distributed Eradication of SIR Epidemics on Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.12549.pdf)
>  This work examines the discrete-time networked SIR (susceptible-infected-recovered) epidemic model, where the infection and recovery parameters may be time-varying. We provide a sufficient condition for the SIR model to converge to the set of healthy states exponentially. We propose a stochastic framework to estimate the system states from observed testing data and provide an analytic expression for the error of the estimation algorithm. Employing the estimated and the true system states, we provide two novel eradication strategies that guarantee at least exponential convergence to the set of healthy states. We illustrate the results via simulations over northern Indiana, USA.      
### 29.Prior Image-Constrained Reconstruction using Style-Based Generative Models  [ :arrow_down: ](https://arxiv.org/pdf/2102.12525.pdf)
>  Obtaining an accurate and reliable estimate of an object from highly incomplete imaging measurements remains a holy grail of imaging science. Deep learning methods have shown promise in learning object priors or constraints to improve the conditioning of an ill-posed imaging inverse problem. In this study, a framework for estimating an object of interest that is semantically related to a known prior image, is proposed. An optimization problem is formulated in the disentangled latent space of a style-based generative model, and semantically meaningful constraints are imposed using the disentangled latent representation of the prior image. Stable recovery from incomplete measurements with the help of a prior image is theoretically analyzed. Numerical experiments demonstrating the superior performance of our approach as compared to related methods are presented.      
### 30.Computing the Discrete Fourier Transform of signals with spectral frequency support  [ :arrow_down: ](https://arxiv.org/pdf/2102.12514.pdf)
>  We consider the problem of finding the Discrete Fourier Transform (DFT) of $N-$ length signals with known frequency support of size $k$. When $N$ is a power of 2 and the frequency support is a spectral set, we provide an $O(k \log k)$ algorithm to compute the DFT. Our algorithm uses some recent characterizations of spectral sets and is a generalization of the standard radix-2 algorithm.      
### 31.Download Cost of Private Updating  [ :arrow_down: ](https://arxiv.org/pdf/2102.13094.pdf)
>  We consider the problem of privately updating a message out of $K$ messages from $N$ replicated and non-colluding databases. In this problem, a user has an outdated version of the message $\hat{W}_\theta$ of length $L$ bits that differ from the current version $W_\theta$ in at most $f$ bits. The user needs to retrieve $W_\theta$ correctly using a private information retrieval (PIR) scheme with the least number of downloads without leaking any information about the message index $\theta$ to any individual database. To that end, we propose a novel achievable scheme based on \emph{syndrome decoding}. Specifically, the user downloads the syndrome corresponding to $W_\theta$, according to a linear block code with carefully designed parameters, using the optimal PIR scheme for messages with a length constraint. We derive lower and upper bounds for the optimal download cost that match if the term $\log_2\left(\sum_{i=0}^f \binom{L}{i}\right)$ is an integer. Our results imply that there is a significant reduction in the download cost if $f &lt; \frac{L}{2}$ compared with downloading $W_\theta$ directly using classical PIR approaches without taking the correlation between $W_\theta$ and $\hat{W}_\theta$ into consideration.      
### 32.Social Welfare Maximization and Conformism via Information Design in Linear-Quadratic-Gaussian Games  [ :arrow_down: ](https://arxiv.org/pdf/2102.13047.pdf)
>  We consider linear-quadratic Gaussian (LQG) games in which players have quadratic payoffs that depend on the players' actions and an unknown payoff-relevant state, and signals on the state that follow a Gaussian distribution conditional on the state realization. An information designer decides the fidelity of information revealed to the players in order to maximize the social welfare of the players or reduce the disagreement among players' actions. Leveraging the semi-definiteness of the information design problem, we derive analytical solutions for these objectives under specific LQG games. We show that full information disclosure maximizes social welfare when there is a common payoff-relevant state, when there is strategic substitutability in the actions of players, or when the signals are public. Numerical results show that as strategic substitution increases, the value of the information disclosure increases. When the objective is to induce conformity among players' actions, hiding information is optimal. Lastly, we consider the information design objective that is a weighted combination of social welfare and cohesiveness of players' actions. We obtain an interval for the weights where full information disclosure is optimal under public signals for games with strategic substitutability. Numerical solutions show that the actual interval where full information disclosure is optimal gets close to the analytical interval obtained as substitution increases.      
### 33.Safe CPS from Unsafe Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2102.12981.pdf)
>  In this paper, we explore using runtime verification to design safe cyber-physical systems (CPS). We build upon the Simplex Architecture, where control authority may switch from an unverified and potentially unsafe advanced controller to a backup baseline controller in order to maintain system safety. New to our approach, we remove the requirement that the baseline controller is statically verified. This is important as there are many types of powerful control techniques -- model-predictive control, rapidly-exploring random trees and neural network controllers -- that often work well in practice, but are difficult to statically prove correct, and therefore could not be used before as baseline controllers. We prove that, through more extensive runtime checks, such an approach can still guarantee safety. We call this approach the Black-Box Simplex Architecture, as both high-level controllers are treated as black boxes. We present case studies where model-predictive control provides safety for multi-robot coordination, and neural networks provably prevent collisions for groups of F-16 aircraft, despite occasionally outputting unsafe actions.      
### 34.Fresh, Fair and Energy-Efficient Content Provision in a Private and Cache-Enabled UAV Network  [ :arrow_down: ](https://arxiv.org/pdf/2102.12915.pdf)
>  In this paper, we investigate a private and cache-enabled unmanned aerial vehicle (UAV) network for content provision. Aiming at delivering fresh, fair, and energy-efficient content files to terrestrial users, we formulate a joint UAV caching, UAV trajectory, and UAV transmit power optimization problem. This problem is confirmed to be a sequential decision problem with mixed-integer non-convex constraints, which is intractable directly. To this end, we propose a novel algorithm based on the techniques of subproblem decomposition and convex approximation. Particularly, we first propose to decompose the sequential decision problem into multiple repeated optimization subproblems via a Lyapunov technique. Next, an iterative optimization scheme incorporating a successive convex approximation (SCA) technique is explored to tackle the challenging mixed-integer non-convex subproblems. Besides, we analyze the convergence and computational complexity of the proposed algorithm and derive the theoretical value of the expected peak age of information (PAoI) to estimate the content freshness. Simulation results demonstrate that the proposed algorithm can achieve the expected PAoI close to the theoretical value and is more $22.11$\% and $70.51$\% energy-efficient and fairer than benchmark algorithms.      
### 35.Deep Learning based Channel Extrapolation for Large-Scale Antenna Systems: Opportunities, Challenges and Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2102.12859.pdf)
>  With the depletion of spectrum, wireless communication systems turn to exploit large antenna arrays to achieve the degree of freedom in space domain, such as millimeter wave massive multi-input multioutput (MIMO), reconfigurable intelligent surface assisted communications and cell-free massive MIMO. In these systems, how to acquire accurate channel state information (CSI) is difficult and becomes a bottleneck of the communication links. In this article, we introduce the concept of channel extrapolation that relies on a small portion of channel parameters to infer the remaining channel parameters. Since the substance of channel extrapolation is a mapping from one parameter subspace to another, we can resort to deep learning (DL), a powerful learning architecture, to approximate such mapping function. Specifically, we first analyze the requirements, conditions and challenges for channel extrapolation. Then, we present three typical extrapolations over the antenna dimension, the frequency dimension, and the physical terminal, respectively. We also illustrate their respective principles, design challenges and DL strategies. It will be seen that channel extrapolation could greatly reduce the transmission overhead and subsequently enhance the performance gains compared with the traditional strategies. In the end, we provide several potential research directions on channel extrapolation for future intelligent communications systems.      
### 36.MaskCycleGAN-VC: Learning Non-parallel Voice Conversion with Filling in Frames  [ :arrow_down: ](https://arxiv.org/pdf/2102.12841.pdf)
>  Non-parallel voice conversion (VC) is a technique for training voice converters without a parallel corpus. Cycle-consistent adversarial network-based VCs (CycleGAN-VC and CycleGAN-VC2) are widely accepted as benchmark methods. However, owing to their insufficient ability to grasp time-frequency structures, their application is limited to mel-cepstrum conversion and not mel-spectrogram conversion despite recent advances in mel-spectrogram vocoders. To overcome this, CycleGAN-VC3, an improved variant of CycleGAN-VC2 that incorporates an additional module called time-frequency adaptive normalization (TFAN), has been proposed. However, an increase in the number of learned parameters is imposed. As an alternative, we propose MaskCycleGAN-VC, which is another extension of CycleGAN-VC2 and is trained using a novel auxiliary task called filling in frames (FIF). With FIF, we apply a temporal mask to the input mel-spectrogram and encourage the converter to fill in missing frames based on surrounding frames. This task allows the converter to learn time-frequency structures in a self-supervised manner and eliminates the need for an additional module such as TFAN. A subjective evaluation of the naturalness and speaker similarity showed that MaskCycleGAN-VC outperformed both CycleGAN-VC2 and CycleGAN-VC3 with a model size similar to that of CycleGAN-VC2. Audio samples are available at <a class="link-external link-http" href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/maskcyclegan-vc/index.html" rel="external noopener nofollow">this http URL</a>.      
### 37.A deep perceptual metric for 3D point clouds  [ :arrow_down: ](https://arxiv.org/pdf/2102.12839.pdf)
>  Point clouds are essential for storage and transmission of 3D content. As they can entail significant volumes of data, point cloud compression is crucial for practical usage. Recently, point cloud geometry compression approaches based on deep neural networks have been explored. In this paper, we evaluate the ability to predict perceptual quality of typical voxel-based loss functions employed to train these networks. We find that the commonly used focal loss and weighted binary cross entropy are poorly correlated with human perception. We thus propose a perceptual loss function for 3D point clouds which outperforms existing loss functions on the ICIP2020 subjective dataset. In addition, we propose a novel truncated distance field voxel grid representation and find that it leads to sparser latent spaces and loss functions that are more correlated with perceived visual quality compared to a binary representation. The source code is available at <a class="link-external link-https" href="https://github.com/mauriceqch/2021_pc_perceptual_loss" rel="external noopener nofollow">this https URL</a>.      
### 38.A New Neuromorphic Computing Approach for Epileptic Seizure Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2102.12773.pdf)
>  Several high specificity and sensitivity seizure prediction methods with convolutional neural networks (CNNs) are reported. However, CNNs are computationally expensive and power hungry. These inconveniences make CNN-based methods hard to be implemented on wearable devices. Motivated by the energy-efficient spiking neural networks (SNNs), a neuromorphic computing approach for seizure prediction is proposed in this work. This approach uses a designed gaussian random discrete encoder to generate spike sequences from the EEG samples and make predictions in a spiking convolutional neural network (Spiking-CNN) which combines the advantages of CNNs and SNNs. The experimental results show that the sensitivity, specificity and AUC can remain 95.1%, 99.2% and 0.912 respectively while the computation complexity is reduced by 98.58% compared to CNN, indicating that the proposed Spiking-CNN is hardware friendly and of high precision.      
### 39.Design and Control of a Highly Redundant Rigid-Flexible Coupling Robot to Assist the COVID-19 Oropharyngeal-Swab Sampling  [ :arrow_down: ](https://arxiv.org/pdf/2102.12726.pdf)
>  The outbreak of novel coronavirus pneumonia (COVID-19) has caused mortality and morbidity worldwide. Oropharyngeal-swab (OP-swab) sampling is widely used for the diagnosis of COVID-19 in the world. To avoid the clinical staff from being affected by the virus, we developed a 9-degree-of-freedom (DOF) rigid-flexible coupling (RFC) robot to assist the COVID-19 OP-swab sampling. This robot is composed of a visual system, UR5 robot arm, micro-pneumatic actuator and force-sensing system. The robot is expected to reduce risk and free up the clinical staff from the long-term repetitive sampling work. Compared with a rigid sampling robot, the developed force-sensing RFC robot can facilitate OP-swab sampling procedures in a safer and softer way. In addition, a varying-parameter zeroing neural network-based optimization method is also proposed for motion planning of the 9-DOF redundant manipulator. The developed robot system is validated by OP-swab sampling on both oral cavity phantoms and volunteers.      
### 40.A Simulation-based End-to-End Learning Framework for Evidential Occupancy Grid Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2102.12718.pdf)
>  Evidential occupancy grid maps (OGMs) are a popular representation of the environment of automated vehicles. Inverse sensor models (ISMs) are used to compute OGMs from sensor data such as lidar point clouds. Geometric ISMs show a limited performance when estimating states in unobserved but inferable areas and have difficulties dealing with ambiguous input. Deep learning-based ISMs face the challenge of limited training data and they often cannot handle uncertainty quantification yet. We propose a deep learning-based framework for learning an OGM algorithm which is both capable of quantifying uncertainty and which does not rely on manually labeled data. Results on synthetic and on real-world data show superiority over other approaches.      
### 41.Real-Time Ellipse Detection for Robotics Applications  [ :arrow_down: ](https://arxiv.org/pdf/2102.12670.pdf)
>  We propose a new algorithm for real-time detection and tracking of elliptic patterns suitable for real-world robotics applications. The method fits ellipses to each contour in the image frame and rejects ellipses that do not yield a good fit. It can detect complete, partial, and imperfect ellipses in extreme weather and lighting conditions and is lightweight enough to be used on robots' resource-limited onboard computers. The method is used on an example application of autonomous UAV landing on a fast-moving vehicle to show its performance indoors, outdoors, and in simulation on a real-world robotics task. The comparison with other well-known ellipse detection methods shows that our proposed algorithm outperforms other methods with the F1 score of 0.981 on a dataset with over 1500 frames. The videos of experiments, the source codes, and the collected dataset are provided with the paper.      
### 42.Imitation Learning for Robust and Safe Real-time Motion Planning: A Contraction Theory Approach  [ :arrow_down: ](https://arxiv.org/pdf/2102.12668.pdf)
>  This paper presents Learning-based Autonomous Guidance with Robustness, Optimality, and Safety guarantees (LAG-ROS), a real-time robust motion planning algorithm for safety-critical nonlinear systems perturbed by bounded disturbances. The LAG-ROS method consists of three phases: 1) Control Lyapunov Function (CLF) construction via contraction theory; 2) imitation learning of the CLF-based robust feedback motion planner; and 3) its real-time and decentralized implementation with a learning-based model predictive safety filter. For the CLF, we exploit a neural-network-based method of Neural Contraction Metrics (NCMs), which provides a differential Lyapunov function to minimize an upper bound of the steady-state Euclidean distance between perturbed and unperturbed system trajectories. The NCM ensures the perturbed state to stay in bounded error tubes around given desired trajectories, where we sample training data for imitation learning of the NCM-CLF-based robust centralized motion planner. Using local observations in training also enables its decentralized implementation. Simulation results for perturbed nonlinear systems show that the LAG-ROS achieves higher control performance and task success rate with faster execution speed for real-time computation, when compared with the existing real-time robust MPC and learning-based feedforward motion planners.      
### 43.MixSpeech: Data Augmentation for Low-resource Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.12664.pdf)
>  In this paper, we propose MixSpeech, a simple yet effective data augmentation method based on mixup for automatic speech recognition (ASR). MixSpeech trains an ASR model by taking a weighted combination of two different speech features (e.g., mel-spectrograms or MFCC) as the input, and recognizing both text sequences, where the two recognition losses use the same combination weight. We apply MixSpeech on two popular end-to-end speech recognition models including LAS (Listen, Attend and Spell) and Transformer, and conduct experiments on several low-resource datasets including TIMIT, WSJ, and HKUST. Experimental results show that MixSpeech achieves better accuracy than the baseline models without data augmentation, and outperforms a strong data augmentation method SpecAugment on these recognition tasks. Specifically, MixSpeech outperforms SpecAugment with a relative PER improvement of 10.6$\%$ on TIMIT dataset, and achieves a strong WER of 4.7$\%$ on WSJ dataset.      
### 44.Blended Dynamics Approach to Distributed Optimization: Sum Convexity and Convergence Rate  [ :arrow_down: ](https://arxiv.org/pdf/2102.12647.pdf)
>  This paper studies the application of the blended dynamics approach towards distributed optimization problem where the global cost function is given by a sum of local cost functions. The benefits include (i) individual cost function need not be convex as long as the global cost function is strongly convex and (ii) the convergence rate of the distributed algorithm is arbitrarily close to the convergence rate of the centralized one. Two particular continuous-time algorithms are presented using the proportional-integral-type couplings. One has benefit of `initialization-free,' so that agents can join or leave the network during the operation. The other one has the minimal amount of communication information. After presenting a general theorem that can be used for designing distributed algorithms, we particularly present a distributed heavy-ball method and discuss its strength over other methods.      
### 45.Protograph-Based Design for QC Polar Codes  [ :arrow_down: ](https://arxiv.org/pdf/2102.12629.pdf)
>  We propose a new family of polar coding which realizes high coding gain, low complexity, and high throughput by introducing a protograph-based design. The proposed technique called as quasi-cyclic (QC) polar codes can be highly parallelized without sacrificing decoding complexity. We analyze short cycles in the protograph polar codes and develop a design method to increase the girth. Our approach can resolve the long-standing unsolved problem that belief propagation (BP) decoding does not work well for polar codes due to the inherently short cycles. We demonstrate that a high lifting factor of QC polar codes can improve the performance and that QC polar codes with BP decoding can outperform conventional polar codes with state-of-the-art list decoding. Moreover, we show that a greedy pruning method can improve the performance-complexity trade-off.      
### 46.Disentangling brain heterogeneity via semi-supervised deep-learning and MRI: dimensional representations of Alzheimer's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2102.12582.pdf)
>  Heterogeneity of brain diseases is a challenge for precision diagnosis/prognosis. We describe and validate Smile-GAN (SeMI-supervised cLustEring-Generative Adversarial Network), a novel semi-supervised deep-clustering method, which dissects neuroanatomical heterogeneity, enabling identification of disease subtypes via their imaging signatures relative to controls. When applied to MRIs (2 studies; 2,832 participants; 8,146 scans) including cognitively normal individuals and those with cognitive impairment and dementia, Smile-GAN identified 4 neurodegenerative patterns/axes: P1, normal anatomy and highest cognitive performance; P2, mild/diffuse atrophy and more prominent executive dysfunction; P3, focal medial temporal atrophy and relatively greater memory impairment; P4, advanced neurodegeneration. Further application to longitudinal data revealed two distinct progression pathways: P1$\rightarrow$P2$\rightarrow$P4 and P1$\rightarrow$P3$\rightarrow$P4. Baseline expression of these patterns predicted the pathway and rate of future neurodegeneration. Pattern expression offered better yet complementary performance in predicting clinical progression, compared to amyloid/tau. These deep-learning derived biomarkers offer promise for precision diagnostics and targeted clinical trial recruitment.      
### 47.Triplet loss based embeddings for forensic speaker identification in Spanish  [ :arrow_down: ](https://arxiv.org/pdf/2102.12564.pdf)
>  With the advent of digital technology, it is more common that committed crimes or legal disputes involve some form of speech recording where the identity of a speaker is questioned [1]. In face of this situation, the field of forensic speaker identification has been looking to shed light on the problem by quantifying how much a speech recording belongs to a particular person in relation to a population. In this work, we explore the use of speech embeddings obtained by training a CNN using the triplet loss. In particular, we focus on the Spanish language which has not been extensively studies. We propose extracting the embeddings from speech spectrograms samples, then explore several configurations of such spectrograms, and finally, quantify the embeddings quality. We also show some limitations of our data setting which is predominantly composed by male speakers. At the end, we propose two approaches to calculate the Likelihood Radio given out speech embeddings and we show that triplet loss is a good alternative to create speech embeddings for forensic speaker identification.      

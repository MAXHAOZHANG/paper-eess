# ArXiv eess --Thu, 25 Feb 2021
### 1.Rigid and non-rigid motion compensation in weight-bearing cone-beam CT of the knee using (noisy) inertial measurements  [ :arrow_down: ](https://arxiv.org/pdf/2102.12418.pdf)
>  Involuntary subject motion is the main source of artifacts in weight-bearing cone-beam CT of the knee. To achieve image quality for clinical diagnosis, the motion needs to be compensated. We propose to use inertial measurement units (IMUs) attached to the leg for motion estimation. We perform a simulation study using real motion recorded with an optical tracking system. Three IMU-based correction approaches are evaluated, namely rigid motion correction, non-rigid 2D projection deformation and non-rigid 3D dynamic reconstruction. We present an initialization process based on the system geometry. With an IMU noise simulation, we investigate the applicability of the proposed methods in real applications. All proposed IMU-based approaches correct motion at least as good as a state-of-the-art marker-based approach. The structural similarity index and the root mean squared error between motion-free and motion corrected volumes are improved by 24-35% and 78-85%, respectively, compared with the uncorrected case. The noise analysis shows that the noise levels of commercially available IMUs need to be improved by a factor of $10^5$ which is currently only achieved by specialized hardware not robust enough for the application. The presented study confirms the feasibility of this novel approach and defines improvements necessary for a real application.      
### 2.Thoughts on the potential to compensate a hearing loss in noise  [ :arrow_down: ](https://arxiv.org/pdf/2102.12397.pdf)
>  The effect of hearing impairment on speech perception was described by Plomp (1978) as a sum of a loss of class A, due to signal attenuation, and a loss of class D, due to signal distortion. While a loss of class A can be compensated by linear amplification, a loss of class D, which severely limits the benefit of hearing aids in noisy listening conditions, cannot. Not few users of hearing aids keep complaining about the limited benefit of their devices in noisy environments. Recently, in an approach to model human speech recognition by means of a re-purposed automatic speech recognition system, the loss of class D was explained by introducing a level uncertainty which reduces the individual accuracy of spectro-temporal signal levels. Based on this finding, an implementation of a patented dynamic range manipulation scheme (PLATT) is proposed, which aims to mitigate the effect of increased level uncertainty on speech recognition in noise by expanding spectral modulation patterns in the range of 2 to 4 ERB. An objective evaluation of the benefit in speech recognition thresholds in noise using an ASR-based speech recognition model suggests that more than half of the class D loss due to an increased level uncertainty might be compensable.      
### 3.SEP-28k: A Dataset for Stuttering Event Detection From Podcasts With People Who Stutter  [ :arrow_down: ](https://arxiv.org/pdf/2102.12394.pdf)
>  The ability to automatically detect stuttering events in speech could help speech pathologists track an individual's fluency over time or help improve speech recognition systems for people with atypical speech patterns. Despite increasing interest in this area, existing public datasets are too small to build generalizable dysfluency detection systems and lack sufficient annotations. In this work, we introduce Stuttering Events in Podcasts (SEP-28k), a dataset containing over 28k clips labeled with five event types including blocks, prolongations, sound repetitions, word repetitions, and interjections. Audio comes from public podcasts largely consisting of people who stutter interviewing other people who stutter. We benchmark a set of acoustic models on SEP-28k and the public FluencyBank dataset and highlight how simply increasing the amount of training data improves relative detection performance by 28\% and 24\% F1 on each. Annotations from over 32k clips across both datasets will be publicly released.      
### 4.Frequency Dynamics with Grid Forming Inverters: A New Stability Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2102.12332.pdf)
>  Traditional power system frequency dynamics are driven by Newtonian physics, where a synchronous generator (SG), the historical primary source of power, follows a deceleration frequency trajectory upon power imbalances according to the swing equation. Subsequent to a disturbance, an SG will modify pre-converter, mechanical power as a function of frequency; these are reactive, second order devices. The integration of renewable energies is primarily accomplished with inverters that convert DC power into AC power, and which hitherto have employed grid-following control strategies that require other devices, typically SGs, to establish a voltage waveform and elicit power imbalance frequency dynamics. A 100\% integration of this particular control strategy is untenable and attention has recently shifted to grid-forming (GFM) control, where the inverter directly regulates frequency; direct frequency control implies that a GFM can serve power proactively by simply not changing frequency. With analysis and electromagnetic transient domain simulations, it is shown that GFM pre-converter power has a first order relation to electrical power as compared to SGs. It is shown that the traditional frequency dynamics are dramatically altered with GFM control, and traditional second-order frequency trajectories transition to first-order, with an accompanying decoupling of the nadir and rate of change of frequency.      
### 5.Hyperspectral Denoising Using Unsupervised Disentangled Spatio-Spectral Deep Priors  [ :arrow_down: ](https://arxiv.org/pdf/2102.12310.pdf)
>  Image denoising is often empowered by accurate prior information. In recent years, data-driven neural network priors have shown promising performance for RGB natural image denoising. Compared to classic handcrafted priors (e.g., sparsity and total variation), the "deep priors" are learned using a large number of training samples -- which can accurately model the complex image generating process. However, data-driven priors are hard to acquire for hyperspectral images (HSIs) due to the lack of training data. A remedy is to use the so-called unsupervised deep image prior (DIP). Under the unsupervised DIP framework, it is hypothesized and empirically demonstrated that proper neural network structures are reasonable priors of certain types of images, and the network weights can be learned without training data. Nonetheless, the most effective unsupervised DIP structures were proposed for natural images instead of HSIs. The performance of unsupervised DIP-based HSI denoising is limited by a couple of serious challenges, namely, network structure design and network complexity. This work puts forth an unsupervised DIP framework that is based on the classic spatio-spectral decomposition of HSIs. Utilizing the so-called linear mixture model of HSIs, two types of unsupervised DIPs, i.e., U-Net-like network and fully-connected networks, are employed to model the abundance maps and endmembers contained in the HSIs, respectively. This way, empirically validated unsupervised DIP structures for natural images can be easily incorporated for HSI denoising. Besides, the decomposition also substantially reduces network complexity. An efficient alternating optimization algorithm is proposed to handle the formulated denoising problem. Semi-real and real data experiments are employed to showcase the effectiveness of the proposed approach.      
### 6.Holographic image reconstruction with phase recovery and autofocusing using recurrent neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.12281.pdf)
>  Digital holography is one of the most widely used label-free microscopy techniques in biomedical imaging. Recovery of the missing phase information of a hologram is an important step in holographic image reconstruction. Here we demonstrate a convolutional recurrent neural network (RNN) based phase recovery approach that uses multiple holograms, captured at different sample-to-sensor distances to rapidly reconstruct the phase and amplitude information of a sample, while also performing autofocusing through the same network. We demonstrated the success of this deep learning-enabled holography method by imaging microscopic features of human tissue samples and Papanicolaou (Pap) smears. These results constitute the first demonstration of the use of recurrent neural networks for holographic imaging and phase recovery, and compared with existing methods, the presented approach improves the reconstructed image quality, while also increasing the depth-of-field and inference speed.      
### 7.Topology Learning Aided False Data Injection Attack without Prior Topology Information  [ :arrow_down: ](https://arxiv.org/pdf/2102.12248.pdf)
>  False Data Injection (FDI) attacks against powersystem state estimation are a growing concern for operators.Previously, most works on FDI attacks have been performedunder the assumption of the attacker having full knowledge ofthe underlying system without clear justification. In this paper, wedevelop a topology-learning-aided FDI attack that allows stealthycyber-attacks against AC power system state estimation withoutprior knowledge of system information. The attack combinestopology learning technique, based only on branch and bus powerflows, and attacker-side pseudo-residual assessment to performstealthy FDI attacks with high confidence. This paper, for thefirst time, demonstrates how quickly the attacker can developfull-knowledge of the grid topology and parameters and validatesthe full knowledge assumptions in the previous work.      
### 8.Designing zonal-based flexible bus services under stochatic demand  [ :arrow_down: ](https://arxiv.org/pdf/2102.12209.pdf)
>  In this paper, we develop a zonal-based flexible bus services (ZBFBS) by considering both passenger demands spatial (origin-destination or OD) and volume stochastic variations. Service requests are grouped by zonal OD pairs and number of passengers per request, and aggregated into demand categories which follow certain probability distributions. A two-stage stochastic program is formulated to minimize the expected operating cost of ZBFBS, in which the zonal visit sequences of vehicles are determined in Stage-1, whereas in Stage-2, service requests are assigned to either regular routes determined in Stage-1 or ad hoc services that incur additional costs. Demand volume reliability and detour time reliability are introduced to ensure quality of the services and separate the problem into two phases for efficient solutions. In phase-1, given the reliability requirements, we minimize the cost of operating the regular services. In phase-2, we optimize the passenger assignment to vehicles to minimize the expected ad hoc service cost. The reliabilities are then optimized by a gradient-based approach to minimize the sum of the regular service operating cost and expected ad hoc service cost. We conduct numerical studies on vehicle capacity, detour time limit and demand volume to demonstrate the potential of ZBFBS, and apply the model to Chengdu, China, based on real data to illustrate its applicability.      
### 9.Research on False Data Injection Attacks in VSC-HVDC Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.12208.pdf)
>  The false data injection (FDI) attack is a crucial form of cyber-physical security problems facing cyber-physical power systems. However, there is no research revealing the problem of FDI attacks facing voltage source converter based high voltage direct current transmission (VSC-HVDC) systems. Firstly, the general form of the model of FDI attack strategies is proposed and the essence of the problem of FDI attack strategies is further analyzed. Moreover, the model of FDI attack strategies aiming at disrupting the operation security of converter stations in VSC-HVDC systems is proposed and its solving algorithm is then presented. And finally, the modified IEEE-14 bus system is utilized to reveal the problem of FDI attacks facing VSC-HVDC systems, demonstrating that attackers are capable of disrupting the operation security of converter stations in VSC-HVDC systems by FDI attacks.      
### 10.DeepCervix: A Deep Learning-based Framework for the Classification of Cervical Cells Using Hybrid Deep Feature Fusion Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2102.12191.pdf)
>  Cervical cancer, one of the most common fatal cancers among women, can be prevented by regular screening to detect any precancerous lesions at early stages and treat them. Pap smear test is a widely performed screening technique for early detection of cervical cancer, whereas this manual screening method suffers from high false-positive results because of human errors. To improve the manual screening practice, machine learning (ML) and deep learning (DL) based computer-aided diagnostic (CAD) systems have been investigated widely to classify cervical pap cells. Most of the existing researches require pre-segmented images to obtain good classification results, whereas accurate cervical cell segmentation is challenging because of cell clustering. Some studies rely on handcrafted features, which cannot guarantee the classification stage's optimality. Moreover, DL provides poor performance for a multiclass classification task when there is an uneven distribution of data, which is prevalent in the cervical cell dataset. This investigation has addressed those limitations by proposing DeepCervix, a hybrid deep feature fusion (HDFF) technique based on DL to classify the cervical cells accurately. Our proposed method uses various DL models to capture more potential information to enhance classification performance. Our proposed HDFF method is tested on the publicly available SIPAKMED dataset and compared the performance with base DL models and the LF method. For the SIPAKMED dataset, we have obtained the state-of-the-art classification accuracy of 99.85%, 99.38%, and 99.14% for 2-class, 3-class, and 5-class classification. Moreover, our method is tested on the Herlev dataset and achieves an accuracy of 98.32% for binary class and 90.32% for 7-class classification.      
### 11.Deep learning-based framework for cardiac function assessment in embryonic zebrafish from heart beating videos  [ :arrow_down: ](https://arxiv.org/pdf/2102.12173.pdf)
>  Zebrafish is a powerful and widely-used model system for a host of biological investigations including cardiovascular studies and genetic screening. Zebrafish are readily assessable during developmental stages; however, the current methods for quantification and monitoring of cardiac functions mostly involve tedious manual work and inconsistent estimations. In this paper, we developed and validated a Zebrafish Automatic Cardiovascular Assessment Framework (ZACAF) based on a U-net deep learning model for automated assessment of cardiovascular indices, such as ejection fraction (EF) and fractional shortening (FS) from microscopic videos of wildtype and cardiomyopathy mutant zebrafish embryos. Our approach yielded favorable performance with accuracy above 90% compared with manual processing. We used only black and white regular microscopic recordings with frame rates of 5-20 frames per second (fps); thus, the framework could be widely applicable with any laboratory resources and infrastructure. Most importantly, the automatic feature holds promise to enable efficient, consistent and reliable processing and analysis capacity for large amounts of videos, which can be generated by diverse collaborating teams.      
### 12.Quantitative Evaluation of Crack Depths on Thin Aluminum Plate using Eddy Current Pulse-Compression Thermography  [ :arrow_down: ](https://arxiv.org/pdf/2102.12132.pdf)
>  Eddy current stimulated thermography is an emerging technique for non-destructive testing and evaluation of conductive materials. However, quantitative estimation of the depth of subsurface defects in metallic materials by thermography techniques remains challenging due to significant lateral thermal diffusion. This work presents the application of eddy current pulse compression thermography to detect surface and subsurface defects with various depths in an aluminum sample. Kernel Principal Component analysis and Low Rank Sparse modelling were used to enhance the defective area, and cross point feature was exploited to quantitatively evaluate the defects depth. Based on experimental results, it is shown that the crossing point feature has a monotonic relationship with surface and subsurface defects depth, and it can also indicate whether the defect is within or beyond the eddy current skin depth. In addition, the comparison study between aluminum and composites in terms of impulse response and proposed features are also presented.      
### 13.Speech Enhancement Using Multi-Stage Self-Attentive Temporal Convolutional Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.12078.pdf)
>  Multi-stage learning is an effective technique to invoke multiple deep-learning modules sequentially. This paper applies multi-stage learning to speech enhancement by using a multi-stage structure, where each stage comprises a self-attention (SA) block followed by stacks of temporal convolutional network (TCN) blocks with doubling dilation factors. Each stage generates a prediction that is refined in a subsequent stage. A fusion block is inserted at the input of later stages to re-inject original information. The resulting multi-stage speech enhancement system, in short, multi-stage SA-TCN, is compared with state-of-the-art deep-learning speech enhancement methods using the LibriSpeech and VCTK data sets. The multi-stage SA-TCN system's hyper-parameters are fine-tuned, and the impact of the SA block, the fusion block and the number of stages are determined. The use of a multi-stage SA-TCN system as a front-end for automatic speech recognition systems is investigated as well. It is shown that the multi-stage SA-TCN systems perform well relative to other state-of-the-art systems in terms of speech enhancement and speech recognition scores.      
### 14.An Iterative Approach to Finding Global Solutions of AC Optimal Power Flow Problems  [ :arrow_down: ](https://arxiv.org/pdf/2102.12075.pdf)
>  The existence of multiple solutions to AC optimal power flow (ACOPF) problems has been noted for decades. Existing solvers are generally successful in finding local solutions, which are stationary points but may not be globally optimal. In this paper, we propose a simple iterative approach to find globally optimal solutions to ACOPF problems. First, we call an existing solver for the ACOPF problem. From the solution and the associated dual variables, we form a partial Lagrangian. Then we optimize this partial Lagrangian and use its solution as a warm start to call the solver again for the ACOPF problem. By repeating this process, we can iteratively improve the solution quality, moving from local solutions to global ones. We show the effectiveness our algorithm on standard IEEE networks. The simulation results show that our algorithm can escape from local solutions to achieve global optimums within a few iterations.      
### 15.Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2102.12056.pdf)
>  Liver segmentation from abdominal CT images is an essential step for liver cancer computer-aided diagnosis and surgical planning. However, both the accuracy and robustness of existing liver segmentation methods cannot meet the requirements of clinical applications. In particular, for the common clinical cases where the liver tissue contains major pathology, current segmentation methods show poor performance. In this paper, we propose a novel low-rank tensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that achieves accurate and robust pathological liver segmentation of CT images. Firstly, we propose a multi-slice LRTD scheme to recover the underlying low-rank structure embedded in 3D medical images. It performs the LRTD on small image segments consisting of multiple consecutive image slices. Then, we present an LRTD-based atlas construction method to generate tumor-free liver atlases that mitigates the performance degradation of liver segmentation due to the presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to derive patient-specific liver atlases for each test image, and to achieve accurate pairwise image registration and label propagation. Extensive experiments on three public databases of pathological liver cases validate the effectiveness of the proposed method. Both qualitative and quantitative results demonstrate that, in the presence of major pathology, the proposed method is more accurate and robust than state-of-the-art methods.      
### 16.An Adaptive Video Acquisition Scheme for Object Tracking and its Performance Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2102.12046.pdf)
>  We present a novel adaptive host-chip modular architecture for video acquisition to optimize an overall objective task constrained under a given bit rate. The chip is a high resolution imaging sensor such as gigapixel focal plane array (FPA) with low computational power deployed on the field remotely, while the host is a server with high computational power. The communication channel data bandwidth between the chip and host is constrained to accommodate transfer of all captured data from the chip. The host performs objective task specific computations and also intelligently guides the chip to optimize (compress) the data sent to host. This proposed system is modular and highly versatile in terms of flexibility in re-orienting the objective task. In this work, object tracking is the objective task. While our architecture supports any form of compression/distortion, in this paper we use quadtree (QT)-segmented video frames. We use Viterbi (Dynamic Programming) algorithm to minimize the area normalized weighted rate-distortion allocation of resources. The host receives only these degraded frames for analysis. An object detector is used to detect objects, and a Kalman Filter based tracker is used to track those objects. Evaluation of system performance is done in terms of Multiple Object Tracking Accuracy (MOTA) metric. In this proposed novel architecture, performance gains in MOTA is obtained by twice training the object detector with different system generated distortions as a novel 2-step process. Additionally, object detector is assisted by tracker to upscore the region proposals in the detector to further improve the performance.      
### 17.Contingency Model Predictive Control for Linear Time-Varying Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.12045.pdf)
>  We present Contingency Model Predictive Control (CMPC), a motion planning and control framework that optimizes performance objectives while simultaneously maintaining a contingency plan -- an alternate trajectory that avoids a potential hazard. By preserving the existence of a feasible avoidance trajectory, CMPC anticipates emergency and keeps the controlled system in a safe state that is selectively robust to the identified hazard. We accomplish this by adding an additional prediction horizon in parallel to the typical Model Predictive Control (MPC) horizon. This extra horizon is constrained to guarantee safety from the contingent threat and is coupled to the nominal horizon at its first command. Thus, the two horizons negotiate to compute commands that are both optimized for performance and robust to the contingent event. This article presents a linear formulation for CMPC, illustrates its key features on a toy problem, and then demonstrates its efficacy experimentally on a full-size automated road vehicle that encounters a realistic pop-out obstacle. Contingency MPC approaches potential emergencies with safe, intuitive, and interpretable behavior that balances conservatism with incentive for high performance operation.      
### 18.False Relay Operation Attacks in Power Systems with High Renewables  [ :arrow_down: ](https://arxiv.org/pdf/2102.12041.pdf)
>  Load-generation balance and system inertia are essential for maintaining frequency in power systems. Power grids are equipped with Rate-of-Change-of Frequency (ROCOF) and Load Shedding (LS) relays in order to keep load-generation balance. With the increasing penetration of renewables, the inertia of the power grids is declining, which results in a faster drop in system frequency in case of load-generation imbalance. In this context, we analyze the feasibility of launching False Data Injection (FDI) in order to create False Relay Operations (FRO), which we refer to as FRO attack, in the power systems with high renewables. We model the frequency dynamics of the power systems and corresponding FDI attacks, including the impact of parameters, such as synchronous generators inertia, and governors time constant and droop, on the success of FRO attacks. We formalize the FRO attack as a Constraint Satisfaction Problem (CSP) and solve using Satisfiability Modulo Theories (SMT). Our case studies show that power grids with renewables are more susceptible to FRO attacks and the inertia of synchronous generators plays a critical role in reducing the success of FRO attacks in the power grids.      
### 19.Radar Cross Section Based Statistical Recognition of UAVs at Microwave Frequencies  [ :arrow_down: ](https://arxiv.org/pdf/2102.11954.pdf)
>  This paper presents a radar cross-section (RCS)-based statistical recognition system for identifying/ classifying unmanned aerial vehicles (UAVs) at microwave frequencies. First, the paper presents the results of the vertical (VV) and horizontal (HH) polarization RCS measurement of six commercial UAVs at 15 GHz and 25 GHz in a compact range anechoic chamber. The measurement results show that the average RCS of the UAVs depends on shape, size, material composition of the target UAV as well as the azimuth angle, frequency, and polarization of the illuminating radar. Afterward, radar characterization of the target UAVs is achieved by fitting the RCS measurement data to 11 different statistical models. From the model selection analysis, we observe that the lognormal, generalized extreme value, and gamma distributions are most suitable for modeling the RCS of the commercial UAVs while the Gaussian distribution performed relatively poorly. The best UAV radar statistics forms the class conditional probability densities for the proposed UAV statistical recognition system. The performance of the UAV statistical recognition system is evaluated at different signal noise ratio (SNR) with the aid of Monte Carlo analysis. At an SNR of 10 dB, the average classification accuracy of 97.43% or better is achievable.      
### 20.Multi-Group Multicast Beamforming by Superiorized Projections onto Convex Sets  [ :arrow_down: ](https://arxiv.org/pdf/2102.11947.pdf)
>  In this paper, we propose an iterative algorithm to address the nonconvex multi-group multicast beamforming problem with quality-of-service constraints and per-antenna power constraints. We formulate a convex relaxation of the problem as a semidefinite program in a real Hilbert space, which allows us to approximate a point in the feasible set by iteratively applying a bounded perturbation resilient fixed-point mapping. Inspired by the superiorization methodology, we use this mapping as a basic algorithm, and we add in each iteration a small perturbation with the intent to reduce the objective value and the distance to nonconvex rank-constraint sets. We prove that the sequence of perturbations is bounded, so the algorithm is guaranteed to converge to a feasible point of the relaxed semidefinite program. Simulations show that the proposed approach outperforms existing algorithms in terms of both computation time and approximation gap in many cases.      
### 21.Multi-Feature Multi-Scale CNN-Derived COVID-19 Classification from Lung Ultrasound Data  [ :arrow_down: ](https://arxiv.org/pdf/2102.11942.pdf)
>  The global pandemic of the novel coronavirus disease 2019 (COVID-19) has put tremendous pressure on the medical system. Imaging plays a complementary role in the management of patients with COVID-19. Computed tomography (CT) and chest X-ray (CXR) are the two dominant screening tools. However, difficulty in eliminating the risk of disease transmission, radiation exposure and not being costeffective are some of the challenges for CT and CXR imaging. This fact induces the implementation of lung ultrasound (LUS) for evaluating COVID-19 due to its practical advantages of noninvasiveness, repeatability, and sensitive bedside property. In this paper, we utilize a deep learning model to perform the classification of COVID-19 from LUS data, which could produce objective diagnostic information for clinicians. Specifically, all LUS images are processed to obtain their corresponding local phase filtered images and radial symmetry transformed images before fed into the multi-scale residual convolutional neural network (CNN). Secondly, image combination as the input of the network is used to explore rich and reliable features. Feature fusion strategy at different levels is adopted to investigate the relationship between the depth of feature aggregation and the classification accuracy. Our proposed method is evaluated on the point-of-care US (POCUS) dataset together with the Italian COVID-19 Lung US database (ICLUS-DB) and shows promising performance for COVID-19 prediction.      
### 22.Dynamic Graph Modeling of Simultaneous EEG and Eye-tracking Data for Reading Task Identification  [ :arrow_down: ](https://arxiv.org/pdf/2102.11922.pdf)
>  We present a new approach, that we call AdaGTCN, for identifying human reader intent from Electroencephalogram~(EEG) and Eye movement~(EM) data in order to help differentiate between normal reading and task-oriented reading. Understanding the physiological aspects of the reading process~(the cognitive load and the reading intent) can help improve the quality of crowd-sourced annotated data. Our method, Adaptive Graph Temporal Convolution Network (AdaGTCN), uses an Adaptive Graph Learning Layer and Deep Neighborhood Graph Convolution Layer for identifying the reading activities using time-locked EEG sequences recorded during word-level eye-movement fixations. Adaptive Graph Learning Layer dynamically learns the spatial correlations between the EEG electrode signals while the Deep Neighborhood Graph Convolution Layer exploits temporal features from a dense graph neighborhood to establish the state of the art in reading task identification over other contemporary approaches. We compare our approach with several baselines to report an improvement of 6.29% on the ZuCo 2.0 dataset, along with extensive ablation experiments      
### 23.A predictive safety filter for learning-based racing control  [ :arrow_down: ](https://arxiv.org/pdf/2102.11907.pdf)
>  The growing need for high-performance controllers in safety-critical applications like autonomous driving has been motivating the development of formal safety verification techniques. In this paper, we design and implement a predictive safety filter that is able to maintain vehicle safety with respect to track boundaries when paired alongside any potentially unsafe control signal, such as those found in learning-based methods. A model predictive control (MPC) framework is used to create a minimally invasive algorithm that certifies whether a desired control input is safe and can be applied to the vehicle, or that provides an alternate input to keep the vehicle in bounds. To this end, we provide a principled procedure to compute a safe and invariant set for nonlinear dynamic bicycle models using efficient convex approximation techniques. To fully support an aggressive racing performance without conservative safety interventions, the safe set is extended in real-time through predictive control backup trajectories. Applications for assisted manual driving and deep imitation learning on a miniature remote-controlled vehicle demonstrate the safety filter's ability to ensure vehicle safety during aggressive maneuvers.      
### 24.Handling Background Noise in Neural Speech Generation  [ :arrow_down: ](https://arxiv.org/pdf/2102.11906.pdf)
>  Recent advances in neural-network based generative modeling of speech has shown great potential for speech coding. However, the performance of such models drops when the input is not clean speech, e.g., in the presence of background noise, preventing its use in practical applications. In this paper we examine the reason and discuss methods to overcome this issue. Placing a denoising preprocessing stage when extracting features and target clean speech during training is shown to be the best performing strategy.      
### 25.Targeted False Data Injection Attack against DC State Estimation without Line Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2102.11896.pdf)
>  A novel false data injection attack (FDIA) model against DC state estimation is proposed, which requires no network parameters and exploits only limited phasor measurement unit (PMU) data. The proposed FDIA model can target specific states and launch large deviation attacks using estimated line parameters. Sufficient conditions for the proposed method are also presented. Different attack vectors are studied in the IEEE 39-bus system, showing that the proposed FDIA method can successfully bypass the bad data detection (BDD) with high success rates of up to 95.3%.      
### 26.MGait: Model-Based Gait Analysis Using Wearable Bend and Inertial Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2102.11895.pdf)
>  Movement disorders, such as Parkinson's disease, affect more than 10 million people worldwide. Gait analysis is a critical step in the diagnosis and rehabilitation of these disorders. Specifically, step length provides valuable insights into the gait quality and rehabilitation process. However, traditional approaches for estimating step length are not suitable for continuous daily monitoring since they rely on special mats and clinical environments. To address this limitation, we present a novel and practical step-length estimation technique using low-power wearable bend and inertial sensors. Experimental results show that the proposed model estimates step length with 5.49% mean absolute percentage error and provides accurate real-time feedback to the user.      
### 27.Wavelet Transform Analytics for RF-Based UAV Detection and Identification System Using Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.11894.pdf)
>  In this work, we performed a thorough comparative analysis on a radio frequency (RF) based drone detection and identification system (DDI) under wireless interference, such as WiFi and Bluetooth, by using machine learning algorithms, and a pre-trained convolutional neural network-based algorithm called SqueezeNet, as classifiers. In RF signal fingerprinting research, the transient and steady state of the signals can be used to extract a unique signature from an RF signal. By exploiting the RF control signals from unmanned aerial vehicles (UAVs) for DDI, we considered each state of the signals separately for feature extraction and compared the pros and cons for drone detection and identification. Using various categories of wavelet transforms (discrete wavelet transform, continuous wavelet transform, and wavelet scattering transform) for extracting features from the signals, we built different models using these features. We studied the performance of these models under different signal to noise ratio (SNR) levels. By using the wavelet scattering transform to extract signatures (scattergrams) from the steady state of the RF signals at 30 dB SNR, and using these scattergrams to train SqueezeNet, we achieved an accuracy of 98.9% at 10 dB SNR.      
### 28.Deep Reinforcement Learning for Safe Landing Site Selection with Concurrent Consideration of Divert Maneuvers  [ :arrow_down: ](https://arxiv.org/pdf/2102.12432.pdf)
>  This research proposes a new integrated framework for identifying safe landing locations and planning in-flight divert maneuvers. The state-of-the-art algorithms for landing zone selection utilize local terrain features such as slopes and roughness to judge the safety and priority of the landing point. However, when there are additional chances of observation and diverting in the future, these algorithms are not able to evaluate the safety of the decision itself to target the selected landing point considering the overall descent trajectory. In response to this challenge, we propose a reinforcement learning framework that optimizes a landing site selection strategy concurrently with a guidance and control strategy to the target landing site. The trained agent could evaluate and select landing sites with explicit consideration of the terrain features, quality of future observations, and control to achieve a safe and efficient landing trajectory at a system-level. The proposed framework was able to achieve 94.8 $\%$ of successful landing in highly challenging landing sites where over 80$\%$ of the area around the initial target lading point is hazardous, by effectively updating the target landing site and feedback control gain during descent.      
### 29.Temporal Energy Analysis of Symbol Sequences for Fiber Nonlinear Interference Modelling via Energy Dispersion Index  [ :arrow_down: ](https://arxiv.org/pdf/2102.12411.pdf)
>  The stationary statistical properties of independent, identically distributed (i.i.d.) input symbols provide insights on the induced nonlinear interference (NLI) during fiber transmission. For example, kurtosis is known to predict the modulation format-dependent NLI. These statistical properties can be used in the design of probabilistic amplitude shaping (PAS), which is a popular scheme that relies on an amplitude shaper for increasing spectral efficiencies of fiber-optic systems. One property of certain shapers used in PAS -- including constant-composition distribution matchers -- that is often overlooked is that a time-dependency between amplitudes is introduced. This dependency results in symbols that are non-i.i.d., which have time-varying statistical properties. Somewhat surprisingly, the effective signal-to-noise ratio (SNR) in PAS has been shown to increase when the shaping blocklength decreases. This blocklength dependency of SNR has been attributed to time-varying statistical properties of the symbol sequences, in particular, to variation of the symbol energies. In this paper, we investigate the temporal energy behavior of symbol sequences, and introduce a new metric called energy dispersion index (EDI). EDI captures the time-varying statistical properties of symbol energies. Numerical results show strong correlations between EDI and effective SNR, with absolute correlation coefficients above 99% for different transmission distances.      
### 30.Wirelessly Powered Federated Edge Learning: Optimal Tradeoffs Between Convergence and Power Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2102.12357.pdf)
>  Federated edge learning (FEEL) is a widely adopted framework for training an artificial intelligence (AI) model distributively at edge devices to leverage their data while preserving their data privacy. The execution of a power-hungry learning task at energy-constrained devices is a key challenge confronting the implementation of FEEL. To tackle the challenge, we propose the solution of powering devices using wireless power transfer (WPT). To derive guidelines on deploying the resultant wirelessly powered FEEL (WP-FEEL) system, this work aims at the derivation of the tradeoff between the model convergence and the settings of power sources in two scenarios: 1) the transmission power and density of power-beacons (dedicated charging stations) if they are deployed, or otherwise 2) the transmission power of a server (access-point). The development of the proposed analytical framework relates the accuracy of distributed stochastic gradient estimation to the WPT settings, the randomness in both communication and WPT links, and devices' computation capacities. Furthermore, the local-computation at devices (i.e., mini-batch size and processor clock frequency) is optimized to efficiently use the harvested energy for gradient estimation. The resultant learning-WPT tradeoffs reveal the simple scaling laws of the model-convergence rate with respect to the transferred energy as well as the devices' computational energy efficiencies. The results provide useful guidelines on WPT provisioning to provide a guaranteer on learning performance. They are corroborated by experimental results using a real dataset.      
### 31.Automated Fuzzing of Automotive Control Units  [ :arrow_down: ](https://arxiv.org/pdf/2102.12345.pdf)
>  Modern vehicles are governed by a network of Electronic Control Units (ECUs), which are programmed to sense inputs from the driver and the environment, to process these inputs, and to control actuators that, e.g., regulate the engine or even control the steering system. ECUs within a vehicle communicate via automotive bus systems such as the Controller Area Network (CAN), and beyond the vehicles boundaries through upcoming vehicle-to-vehicle and vehicle-to-infrastructure channels. Approaches to manipulate the communication between ECUs for the purpose of security testing and reverse-engineering of vehicular functions have been presented in the past, all of which struggle with automating the detection of system change in response to message injection. In this paper we present our findings with fuzzing CAN networks, in particular while observing individual ECUs with a sensor harness. The harness detects physical responses, which we then use in a oracle functions to inform the fuzzing process. We systematically define fuzzers, fuzzing configurations and oracle functions for testing ECUs. We evaluate our approach based on case studies of commercial instrument clusters and with an experimental framework for CAN authentication. Our results show that the approach is capable of identifying interesting ECU states with a high level of automation. Our approach is applicable in distributed cyber-physical systems beyond automotive computing.      
### 32.Decentralized conjugate gradients with finite-step convergence  [ :arrow_down: ](https://arxiv.org/pdf/2102.12311.pdf)
>  The decentralized solution of linear systems of equations arises as a subproblem in optimization over networks. Typical examples include the KKT system corresponding to equality constrained quadratic programs in distributed optimization algorithms or in active set methods. This note presents a tailored structure-exploiting decentralized variant of the conjugate gradient method. We show that the decentralized conjugate gradient method exhibits super-linear convergence in a finite number of steps. Finally, we illustrate the algorithm's performance in comparison to the Alternating Direction Method of Multipliers drawing upon examples from sensor fusion.      
### 33.Automatic Feature Extraction for Heartbeat Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2102.12289.pdf)
>  We focus on automatic feature extraction for raw audio heartbeat sounds, aimed at anomaly detection applications in healthcare. We learn features with the help of an autoencoder composed by a 1D non-causal convolutional encoder and a WaveNet decoder trained with a modified objective based on variational inference, employing the Maximum Mean Discrepancy (MMD). Moreover we model the latent distribution using a Gaussian chain graphical model to capture temporal correlations which characterize the encoded signals. After training the autoencoder on the reconstruction task in a unsupervised manner, we test the significance of the learned latent representations by training an SVM to predict anomalies. We evaluate the methods on a problem proposed by the PASCAL Classifying Heart Sounds Challenge and we compare with results in the literature.      
### 34.The non-positive circuit weight problem in parametric graphs: a fast solution based on dioid theory  [ :arrow_down: ](https://arxiv.org/pdf/2102.12264.pdf)
>  Let us consider a parametric weighted directed graph in which every arc $(j,i)$ has weight of the form $w((j,i))=\max(P_{ij}+\lambda,I_{ij}-\lambda,C_{ij})$, where $\lambda$ is a real parameter and $P$, $I$ and $C$ are arbitrary square matrices with elements in $\mathbb{R}\cup\{-\infty\}$. In this paper, we design an algorithm that solves the Non-positive Circuit weight Problem (NCP) on this class of parametric graphs, which consists in finding all values of $\lambda$ such that the graph does not contain circuits with positive weight. This problem, which generalizes other instances of the NCP previously investigated in the literature, has applications in the consistency analysis of a class of discrete-event systems called P-time event graphs. The proposed algorithm is based on max-plus algebra and formal languages and runs faster than other existing approaches, achieving strongly polynomial time complexity $\mathcal{O}(n^4)$ (where $n$ is the number of nodes in the graph).      
### 35.Estimation of Continuous Blood Pressure from PPG via a Federated Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2102.12245.pdf)
>  Ischemic heart disease is the highest cause of mortality globally each year. This not only puts a massive strain on the lives of those affected but also on the public healthcare systems. To understand the dynamics of the healthy and unhealthy heart doctors commonly use electrocardiogram (ECG) and blood pressure (BP) readings. These methods are often quite invasive, in particular when continuous arterial blood pressure (ABP) readings are taken and not to mention very costly. Using machine learning methods we seek to develop a framework that is capable of inferring ABP from a single optical photoplethysmogram (PPG) sensor alone. We train our framework across distributed models and data sources to mimic a large-scale distributed collaborative learning experiment that could be implemented across low-cost wearables. Our time series-to-time series generative adversarial network (T2TGAN) is capable of high-quality continuous ABP generation from a PPG signal with a mean error of 2.54 mmHg and a standard deviation of 23.7 mmHg when estimating mean arterial pressure on a previously unseen, noisy, independent dataset. To our knowledge, this framework is the first example of a GAN capable of continuous ABP generation from an input PPG signal that also uses a federated learning methodology.      
### 36.A Trident Quaternion Framework for Inertial-based Navigation Part II: Error Models and Application to Initial Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2102.12220.pdf)
>  This work deals with error models for trident quaternion framework proposed in the companion paper "A Trident Quaternion Framework for Inertial-based Navigation Part I: Motion Representation and Computation" and further uses them to investigate the static and in-motion alignment for land vehicles. Specifically, the zero-velocity and odometer velocity measurements are applied in the static and in-motion alignment process, respectively. By linearizing the trident quaternion kinematic equation, the right and left trident quaternion error models are obtained. The resultant models are found to be equivalent to those derived from profound group affine. Then the two models are used to design the corresponding extended Kalman filters (EKF), namely, the left-quaternion EKF (LQEKF) and the right-quaternion EKF (RQEKF). Simulations and field tests are conducted to evaluate their actual performances. For the static alignment, owing to their high consistency, the L/RQEKF converge much faster than the EKF even without any heading information. For the in-motion alignment, however, the two filters still need the assistance of the analytical/optimization-based in-motion alignment methods at the very start to avoid extremely large attitude errors, although they possess much larger convergence region than the traditional EKF does.      
### 37.A Trident Quaternion Framework for Inertial-based Navigation Part I: Rigid Motion Representation and Computation  [ :arrow_down: ](https://arxiv.org/pdf/2102.12217.pdf)
>  Strapdown inertial navigation research involves the parameterization and computation of the attitude, velocity and position of a rigid body in a chosen reference frame. The community has long devoted to finding the most concise and efficient representation for the strapdown inertial navigation system (INS). The current work is motivated by simplifying the existing dual quaternion representation of the kinematic model. This paper proposes a compact and elegant representation of the body's attitude, velocity and position, with the aid of a devised trident quaternion tool in which the position is accounted for by adding a second imaginary part to the dual quaternion. Eventually, the kinematics of strapdown INS are cohesively unified in one concise differential equation, which bears the same form as the classical attitude quaternion equation. In addition, the computation of this trident quaternion-based kinematic equation is implemented with the recently proposed functional iterative integration approach. Numerical results verify the analysis and show that incorporating the new representation into the functional iterative integration scheme achieves high inertial navigation computation accuracy as well.      
### 38.Deep Learning Approach for Singer Voice Classification of Vietnamese Popular Music  [ :arrow_down: ](https://arxiv.org/pdf/2102.12111.pdf)
>  Singer voice classification is a meaningful task in the digital era. With a huge number of songs today, identifying a singer is very helpful for music information retrieval, music properties indexing, and so on. In this paper, we propose a new method to identify the singer's name based on analysis of Vietnamese popular music. We employ the use of vocal segment detection and singing voice separation as the pre-processing steps. The purpose of these steps is to extract the singer's voice from the mixture sound. In order to build a singer classifier, we propose a neural network architecture working with Mel Frequency Cepstral Coefficient as extracted input features from said vocal. To verify the accuracy of our methods, we evaluate on a dataset of 300 Vietnamese songs from 18 famous singers. We achieve an accuracy of 92.84% with 5-fold stratified cross-validation, the best result compared to other methods on the same data set.      
### 39.Modern Koopman Theory for Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.12086.pdf)
>  The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to reduce Koopman theory to practice in real-world applications. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of applications. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.      
### 40.Being correct is not enough: efficient verification using robust linear temporal logic  [ :arrow_down: ](https://arxiv.org/pdf/2102.11991.pdf)
>  While most approaches in formal methods address system correctness, ensuring robustness has remained a challenge. In this paper we introduce the logic rLTL which provides a means to formally reason about both correctness and robustness in system design. Furthermore, we identify a large fragment of rLTL for which the verification problem can be efficiently solved, i.e., verification can be done by using an automaton, recognizing the behaviors described by the rLTL formula $\varphi$, of size at most $\mathcal{O} \left( 3^{ |\varphi|} \right)$, where $|\varphi|$ is the length of $\varphi$. This result improves upon the previously known bound of $\mathcal{O}\left(5^{|\varphi|} \right)$ for rLTL verification and is closer to the LTL bound of $\mathcal{O}\left( 2^{|\varphi|} \right)$. The usefulness of this fragment is demonstrated by a number of case studies showing its practical significance in terms of expressiveness, the ability to describe robustness, and the fine-grained information that rLTL brings to the process of system verification. Moreover, these advantages come at a low computational overhead with respect to LTL verification.      
### 41.Learning to Drop Points for LiDAR Scan Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2102.11952.pdf)
>  Generative modeling of 3D scenes is a crucial topic for aiding mobile robots to improve unreliable observations. However, despite the rapid progress in the natural image domain, building generative models is still challenging for 3D data, such as point clouds. Most existing studies on point clouds have focused on small and uniform-density data. In contrast, 3D LiDAR point clouds widely used in mobile robots are non-trivial to be handled because of the large number of points and varying-density. To circumvent this issue, 3D-to-2D projected representation such as a cylindrical depth map has been studied in existing LiDAR processing tasks but susceptible to discrete lossy pixels caused by failures of laser reflection. This paper proposes a novel framework based on generative adversarial networks to synthesize realistic LiDAR data as an improved 2D representation. Our generative architectures are designed to learn a distribution of inverse depth maps and simultaneously simulate the lossy pixels, which enables us to decompose an underlying smooth geometry and the corresponding uncertainty of laser reflection. To simulate the lossy pixels, we propose a differentiable framework to learn to produce sample-dependent binary masks using the Gumbel-Sigmoid reparametrization trick. We demonstrate the effectiveness of our approach in synthesis and reconstruction tasks on two LiDAR datasets. We further showcase potential applications by recovering various corruptions in LiDAR data.      

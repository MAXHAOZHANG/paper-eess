# ArXiv eess --Wed, 24 Feb 2021
### 1.Resource Reservation in Backhaul and Radio Access Network with Uncertain User Demands  [ :arrow_down: ](https://arxiv.org/pdf/2102.11844.pdf)
>  Resource reservation is an essential step to enable wireless data networks to support a wide range of user demands. In this paper, we consider the problem of joint resource reservation in the backhaul and Radio Access Network (RAN) based on the statistics of user demands and channel states, and also network availability. The goal is to maximize the sum of expected traffic flow rates, subject to link and access point budget constraints, while minimizing the expected outage of downlinks. The formulated problem turns out to be non-convex and difficult to solve to global optimality. We propose an efficient Block Coordinate Descent (BCD) algorithm to approximately solve the problem. The proposed BCD algorithm optimizes the link capacity reservation in the backhaul using a novel multipath routing algorithm that decomposes the problem down to link-level and parallelizes the computation across backhaul links, while the reservation of transmission resources in RAN is carried out via a novel scalable and distributed algorithm based on Block Successive Upper-bound Minimization (BSUM). We prove that the proposed BCD algorithm converges to a Karush-Kuhn-Tucker solution. Simulation results verify the efficiency and the efficacy of our BCD approach against two heuristic algorithms.      
### 2.Decentralized Joint Beamforming, User Scheduling and QoS Management in 5G and Beyond Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.11801.pdf)
>  Fifth generation cellular systems support a broad range of services, including mobile broadband, critical and massive Internet of Things and are used in a variety of scenarios. In many of these scenarios, the main challenge is maintaining high throughput and ensuring proper quality of service (QoS) in irregular topologies. In multiple input multiple output systems, this challenge translates to designing linear transmit and receive beamformers that maximize the system throughput and manage QoS constraints. In this paper, we argue that this basic design task in 5G and beyond systems must be extended such that beamforming design and user scheduling are managed jointly. Specifically, we propose a fully decentralized joint beamforming design and user scheduling algorithm that manages QoS. A novel feature of this scheme is its ability to reduce the initial rate requirements in case of infeasibility. By means of simulations that model contemporary 5G scenarios, we show that the proposed decentralized scheme outperforms benchmarking algorithms that do not support minimum rate requirements and previously proposed algorithms that support QoS requirements.      
### 3.Federated Learning for Physical Layer Design  [ :arrow_down: ](https://arxiv.org/pdf/2102.11777.pdf)
>  Model-free techniques, such as machine learning (ML), have recently attracted much interest for physical layer design, e.g., symbol detection, channel estimation and beamforming. Most of these ML techniques employ centralized learning (CL) schemes and assume the availability of datasets at a parameter server (PS), demanding the transmission of data from the edge devices, such as mobile phones, to the PS. Exploiting the data generated at the edge, federated learning (FL) has been proposed recently as a distributed learning scheme, in which each device computes the model parameters and sends them to the PS for model aggregation, while the datasets are kept intact at the edge. Thus, FL is more communication-efficient and privacy-preserving than CL and applicable to the wireless communication scenarios, wherein the data are generated at the edge devices. This article discusses the recent advances in FL-based training for physical layer design problems, and identifies the related design challenges along with possible solutions to improve the performance in terms of communication overhead, model/data/hardware complexity.      
### 4.Recurrent Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2102.11736.pdf)
>  This paper proposes an off-line algorithm, called Recurrent Model Predictive Control (RMPC), to solve general nonlinear finite-horizon optimal control problems. Unlike traditional Model Predictive Control (MPC) algorithms, it can make full use of the current computing resources and adaptively select the longest model prediction horizon. Our algorithm employs a recurrent function to approximate the optimal policy, which maps the system states and reference values directly to the control inputs. The number of prediction steps is equal to the number of recurrent cycles of the learned policy function. With an arbitrary initial policy function, the proposed RMPC algorithm can converge to the optimal policy by directly minimizing the designed loss function. We further prove the convergence and optimality of the RMPC algorithm thorough Bellman optimality principle, and demonstrate its generality and efficiency using two numerical examples.      
### 5.Deep Unrolled Network for Video Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2102.11720.pdf)
>  Video super-resolution (VSR) aims to reconstruct a sequence of high-resolution (HR) images from their corresponding low-resolution (LR) versions. Traditionally, solving a VSR problem has been based on iterative algorithms that can exploit prior knowledge on image formation and assumptions on the motion. However, these classical methods struggle at incorporating complex statistics from natural images. Furthermore, VSR has recently benefited from the improvement brought by deep learning (DL) algorithms. These techniques can efficiently learn spatial patterns from large collections of images. Yet, they fail to incorporate some knowledge about the image formation model, which limits their flexibility. Unrolled optimization algorithms, developed for inverse problems resolution, allow to include prior information into deep learning architectures. They have been used mainly for single image restoration tasks. Adapting an unrolled neural network structure can bring the following benefits. First, this may increase performance of the super-resolution task. Then, this gives neural networks better interpretability. Finally, this allows flexibility in learning a single model to nonblindly deal with multiple degradations. In this paper, we propose a new VSR neural network based on unrolled optimization techniques and discuss its performance.      
### 6.Cell abundance aware deep learning for cell detection on highly imbalanced pathological data  [ :arrow_down: ](https://arxiv.org/pdf/2102.11677.pdf)
>  Automated analysis of tissue sections allows a better understanding of disease biology and may reveal biomarkers that could guide prognosis or treatment selection. In digital pathology, less abundant cell types can be of biological significance, but their scarcity can result in biased and sub-optimal cell detection model. To minimize the effect of cell imbalance on cell detection, we proposed a deep learning pipeline that considers the abundance of cell types during model training. Cell weight images were generated, which assign larger weights to less abundant cells and used the weights to regularize Dice overlap loss function. The model was trained and evaluated on myeloma bone marrow trephine samples. Our model obtained a cell detection F1-score of 0.78, a 2% increase compared to baseline models, and it outperformed baseline models at detecting rare cell types. We found that scaling deep learning loss function by the abundance of cells improves cell detection performance. Our results demonstrate the importance of incorporating domain knowledge on deep learning methods for pathological data with class imbalance.      
### 7.Revisiting the Memristor Concept within Basic Circuit Theory  [ :arrow_down: ](https://arxiv.org/pdf/2102.11669.pdf)
>  In this paper we revisit the memristor concept within circuit theory. We start from the definition of the basic circuit elements, then we introduce the original formulation of the memristor concept and summarize some of the controversies on its nature. We also point out the ambiguities resulting from a non rigorous usage of the flux linkage concept. After concluding that the memristor is not a fourth basic circuit element, prompted by recent claims in the memristor literature, we look into the application of the memristor concept to electrophysiology, realizing that an approach suitable to explain the observed inductive behavior of the giant squid axon had already been developed in the 1960s, with the introduction of "time-variant resistors." We also discuss a recent memristor implementation in which the magnetic flux plays a direct role, concluding that it cannot strictly qualify as a memristor, because its $v-i$ curve cannot exactly pinch at the origin. Finally, we present numerical simulations of a few memristors and memristive systems, focusing on the behavior in the $\varphi-q$ plane. We show that, contrary to what happens for the most basic memristor concept, for general memristive systems the $\varphi-q$ curve is not single-valued or not even closed.      
### 8.Structured LISTA for Multidimensional Harmonic Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2102.11663.pdf)
>  Learned iterative shrinkage thresholding algorithm (LISTA), which adopts deep learning techniques to learn optimal algorithm parameters from labeled training data, can be successfully applied to small-scale multidimensional harmonic retrieval (MHR) problems. However, LISTA computationally demanding for large-scale MHR problems because the matrix size of the learned mutual inhibition matrix exhibits quadratic growth with the signal length. These large matrices consume costly memory/computation resources and require a huge amount of labeled data for training, restricting the applicability of the LISTA method. In this paper, we show that the mutual inhibition matrix of a MHR problem naturally has a Toeplitz structure, which means that the degrees of freedom (DoF) of the matrix can be reduced from a quadratic order to a linear order. By exploiting this characteristic, we propose a structured LISTA-Toeplitz network, which imposes a Toeplitz structure restriction on the mutual inhibition matrices and applies linear convolution instead of the matrix-vector multiplication involved in the traditional LISTA network. Both simulation and field test for air target detection with radar are carried out to validate the performance of the proposed network. For small-scale MHR problems, LISTAToeplitz exhibits close or even better recovery accuracy than traditional LISTA, while the former significantly reduces the network complexity and requires much less training data. For large-scale MHR problems, where LISTA is difficult to implement due to the huge size of the mutual inhibition matrices, our proposed LISTA-Toeplitz still enjoys desirable recovery performance.      
### 9.Unsupervised Brain Anomaly Detection and Segmentation with Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2102.11650.pdf)
>  Pathological brain appearances may be so heterogeneous as to be intelligible only as anomalies, defined by their deviation from normality rather than any specific pathological characteristic. Amongst the hardest tasks in medical imaging, detecting such anomalies requires models of the normal brain that combine compactness with the expressivity of the complex, long-range interactions that characterise its structural organisation. These are requirements transformers have arguably greater potential to satisfy than other current candidate architectures, but their application has been inhibited by their demands on data and computational resource. Here we combine the latent representation of vector quantised variational autoencoders with an ensemble of autoregressive transformers to enable unsupervised anomaly detection and segmentation defined by deviation from healthy brain imaging data, achievable at low computational cost, within relative modest data regimes. We compare our method to current state-of-the-art approaches across a series of experiments involving synthetic and real pathological lesions. On real lesions, we train our models on 15,000 radiologically normal participants from UK Biobank, and evaluate performance on four different brain MR datasets with small vessel disease, demyelinating lesions, and tumours. We demonstrate superior anomaly detection performance both image-wise and pixel-wise, achievable without post-processing. These results draw attention to the potential of transformers in this most challenging of imaging tasks.      
### 10.Dual-Path Modeling for Long Recording Speech Separation in Meetings  [ :arrow_down: ](https://arxiv.org/pdf/2102.11634.pdf)
>  The continuous speech separation (CSS) is a task to separate the speech sources from a long, partially overlapped recording, which involves a varying number of speakers. A straightforward extension of conventional utterance-level speech separation to the CSS task is to segment the long recording with a size-fixed window and process each window separately. Though effective, this extension fails to model the long dependency in speech and thus leads to sub-optimum performance. The recent proposed dual-path modeling could be a remedy to this problem, thanks to its capability in jointly modeling the cross-window dependency and the local-window processing. In this work, we further extend the dual-path modeling framework for CSS task. A transformer-based dual-path system is proposed, which integrates transform layers for global modeling. The proposed models are applied to LibriCSS, a real recorded multi-talk dataset, and consistent WER reduction can be observed in the ASR evaluation for separated speech. Also, a dual-path transformer equipped with convolutional layers is proposed. It significantly reduces the computation amount by 30% with better WER evaluation. Furthermore, the online processing dual-path models are investigated, which shows 10% relative WER reduction compared to the baseline.      
### 11.A low-cost flexible instrument made of off-the-shelf components for pulsed eddy current testing: overview and application to pseudo-noise excitation  [ :arrow_down: ](https://arxiv.org/pdf/2102.11609.pdf)
>  A flexible and low-cost device for eddy current non-destructive testing made of off-the-shelf components is described. The proposed system is compact and easy to operate, and it consists of a dual H-bridge stepper motor driver, a coil winded in-house on an additively manufactured support, a tunnel magnetoresistance sensor, and a data generation/acquisition module. For the latter, two different commercial devices have been used, and both setups have been then tested on a benchmark sample to detect small artificial cracks. The system can flexibly generate the square pulse or square wave with tunable duration and frequency, as well as pseudo-noise binary waveforms that are here used in combination with pulse-compression to increase the inspection sensitivity with respect to standard pulsed eddy current testing. A benchmark sample was analysed, and all the defects were correctly located, demonstrating the good detection capability of the sensor. This was achieved by assembling a very low-cost handy device, which can be further improved in portability and performances with the use of different off-the-shelf components, and that can be easily integrated with single-board PC, paving the way for future developments in this field.      
### 12.Unidirectional Memory-Self-Attention Transducer for Online Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.11594.pdf)
>  Self-attention models have been successfully applied in end-to-end speech recognition systems, which greatly improve the performance of recognition accuracy. However, such attention-based models cannot be used in online speech recognition, because these models usually have to utilize a whole acoustic sequences as inputs. A common method is restricting the field of attention sights by a fixed left and right window, which makes the computation costs manageable yet also introduces performance degradation. In this paper, we propose Memory-Self-Attention (MSA), which adds history information into the Restricted-Self-Attention unit. MSA only needs localtime features as inputs, and efficiently models long temporal contexts by attending memory states. Meanwhile, recurrent neural network transducer (RNN-T) has proved to be a great approach for online ASR tasks, because the alignments of RNN-T are local and monotonic. We propose a novel network structure, called Memory-Self-Attention (MSA) Transducer. Both encoder and decoder of the MSA Transducer contain the proposed MSA unit. The experiments demonstrate that our proposed models improve WER results than Restricted-Self-Attention models by $13.5 on WSJ and $7.1 on SWBD datasets relatively, and without much computation costs increase.      
### 13.Radio-based Sensing and Environment Mapping in Millimeter-Wave 5G and Beyond Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.11593.pdf)
>  Integrating efficient connectivity, positioning and sensing functionalities into 5G New Radio (NR) and beyond mobile cellular systems is one timely research paradigm, especially at mm-wave and sub-THz bands. In this article, we address the radio-based sensing and environment mapping prospect with specific emphasis on the user equipment (UE) side. We first describe an efficient l1-regularized least-squares (LS) approach to obtain sparse range--angle charts at individual measurement or sensing locations. For the subsequent environment mapping, we then describe both grid-based static solution as well as more advanced tracking-based dynamic approaches, where interaction multiple-model extended Kalman filtering and smoothing are utilized. We provide numerical indoor mapping results at 28~GHz band deploying OFDM-based 5G NR uplink waveform with 400~MHz channel bandwidth, covering both accurate ray-tracing based as well as actual RF measurement results. The results illustrate the superiority of the dynamic tracking-based solutions, while overall demonstrate the excellent prospects of radio-based environment sensing and mapping in future mm-wave networks.      
### 14.Matrix-Pencil Approach-Based Interference Mitigation for FMCW Radar Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.11557.pdf)
>  A novel matrix pencil-based interference mitigation approach for FMCW radars is proposed in this paper. The interference-contaminated segment of the beat signal is firstly cut out and then the signal samples in the cut-out region are reconstructed by modeling the beat signal as a sum of complex exponentials and using the matrix pencil method to estimate their parameters. The efficiency of the proposed approach for the interference with different parameters (i.e. interference duration, signal-to-noise ratio (SNR), and different target scenarios) is investigated by means of numerical simulations. The proposed interference mitigation approach is intensively verified on experimental data. Comparisons of the proposed approach with the zeroing and other beat-frequency interpolation techniques are presented. The results indicate the broad applicability and superiority of the proposed approach, especially in low SNR and long interference duration situations.      
### 15.End-to-End Dereverberation, Beamforming, and Speech Recognition with Improved Numerical Stability and Advanced Frontend  [ :arrow_down: ](https://arxiv.org/pdf/2102.11525.pdf)
>  Recently, the end-to-end approach has been successfully applied to multi-speaker speech separation and recognition in both single-channel and multichannel conditions. However, severe performance degradation is still observed in the reverberant and noisy scenarios, and there is still a large performance gap between anechoic and reverberant conditions. In this work, we focus on the multichannel multi-speaker reverberant condition, and propose to extend our previous framework for end-to-end dereverberation, beamforming, and speech recognition with improved numerical stability and advanced frontend subnetworks including voice activity detection like masks. The techniques significantly stabilize the end-to-end training process. The experiments on the spatialized wsj1-2mix corpus show that the proposed system achieves about 35% WER relative reduction compared to our conventional multi-channel E2E ASR system, and also obtains decent speech dereverberation and separation performance (SDR=12.5 dB) in the reverberant multi-speaker condition while trained only with the ASR criterion.      
### 16.Classification of Breast Cancer Lesions in Ultrasound Images by using Attention Layer and loss Ensembles in Deep Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.11519.pdf)
>  Reliable classification of benign and malignant lesions in breast ultrasound images can provide an effective and relatively low cost method for early diagnosis of breast cancer. The accuracy of the diagnosis is however highly dependent on the quality of the ultrasound systems and the experience of the users (radiologists). The leverage in deep convolutional neural network approaches provided solutions in efficient analysis of breast ultrasound images. In this study, we proposed a new framework for classification of breast cancer lesions by use of an attention module in modified VGG16 architecture. We also proposed new ensembled loss function which is the combination of binary cross-entropy and logarithm of the hyperbolic cosine loss to improve the model discrepancy between classified lesions and its labels. Networks trained from pretrained ImageNet weights, and subsequently fine-tuned with ultrasound datasets. The proposed model in this study outperformed other modified VGG16 architectures with the accuracy of 93% and also the results are competitive with other state of the art frameworks for classification of breast cancer lesions. In this study, we employed transfer learning approaches with the pre-trained VGG16 architecture. Different CNN models for classification task were trained to predict benign or malignant lesions in breast ultrasound images. Our Experimental results show that the choice of loss function is highly important in classification task and by adding an attention block we could empower the performance our model.      
### 17.Performance Improvement of LoRa Modulation with Signal Combining  [ :arrow_down: ](https://arxiv.org/pdf/2102.11509.pdf)
>  Low-power long-range (LoRa) modulation has been used to satisfy the low power and large coverage requirements of Internet of Things (IoT) networks. In this paper, we investigate performance improvements of LoRa modulation when a gateway is equipped with multiple antennas. We derive the optimal decision rules for both coherent and non-coherent detections when combining signals received from multiple antennas. We present expressions of the symbol/bit error probabilities of both the coherent and non-coherent detections in AWGN and Rayleigh fading channels, respectively. Moreover, we also propose an iterative semi-coherent detection that does not require any overhead to estimate the channel-state-information (CSI) while its performance can approach that of the coherent detection. Simulation and analytical results show very large power gains provided by the use of multiple antennas for all the detection schemes considered.      
### 18.Evolutionary optimization of contexts for phonetic correction in speech recognition systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.11480.pdf)
>  Automatic Speech Recognition (ASR) is an area of growing academic and commercial interest due to the high demand for applications that use it to provide a natural communication method. It is common for general purpose ASR systems to fail in applications that use a domain-specific language. Various strategies have been used to reduce the error, such as providing a context that modifies the language model and post-processing correction methods. This article explores the use of an evolutionary process to generate an optimized context for a specific application domain, as well as different correction techniques based on phonetic distance metrics. The results show the viability of a genetic algorithm as a tool for context optimization, which, added to a post-processing correction based on phonetic representations, can reduce the errors on the recognized speech.      
### 19.VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels  [ :arrow_down: ](https://arxiv.org/pdf/2102.11467.pdf)
>  Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).      
### 20.Histo-fetch -- On-the-fly processing of gigapixel whole slide images simplifies and speeds neural network training  [ :arrow_down: ](https://arxiv.org/pdf/2102.11433.pdf)
>  We created a custom pipeline (histo-fetch) to efficiently extract random patches and labels from pathology whole slide images (WSIs) for input to a neural network on-the-fly. We prefetch these patches as needed during network training, avoiding the need for WSI preparation such as chopping/tiling. We demonstrate the utility of this pipeline to perform artificial stain transfer and image generation using the popular networks CycleGAN and ProGAN, respectively.      
### 21.The Curious Case of Integrator Reach Sets, Part I: Basic Theory  [ :arrow_down: ](https://arxiv.org/pdf/2102.11423.pdf)
>  This is the first of a two part paper investigating the geometry of the integrator reach sets, and the applications thereof. In this Part I, we establish that this compact convex set is semialgebraic, translated zonoid, and not a spectrahedron. We derive the parametric as well as the implicit representation of the boundary of this reach set. We also deduce the closed form formula for the volume and diameter of this set, and discuss their scaling with state dimension and time. We point out that these results may be utilized in benchmarking the performance of the reach set over-approximation algorithms.      
### 22.Fast Beam Tracking for Reconfigurable Intelligent Surface Assisted Mobile mmWave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.11414.pdf)
>  Millimeter wave (mmWave) communications are vulnerable to blockages and node mobility due to the highly directional signal beams. The emerging Reconfigurable Intelligent Surfaces (RISs) technique can effectively mitigate the blockage problem by exploring the non-line-of-sight (NLOS) path, where the beam switching is realized by digitally configuring the phases of RIS elements. To date, most efforts have been made in the stationary scenario. However, when considering node mobility, beam tracking algorithms designed specifically for RIS are needed in order to maintain the NLOS link. In this paper, a fast RIS-based beam tracking algorithm is developed by partly transforming the large amount of signaling time into the calculation happens at base station in a mmWave system with mobile users. Specifically, the differential form of optimal RIS configuration is exploited as the updating beam tracking parameter to avoid complex channel estimation procedure. The RIS-based beam tracking problem is then transformed into an optimization problem whose solution is found by a calculation-based search. Finally, by training on a small set candidate, RIS-based beam tracking is realized. The effectiveness and efficiency of the proposed RIS-based beam tracking algorithm is evaluated by simulations. It shows that the proposed algorithm has near-optimal performance with dramatic savings in terms of signaling time.      
### 23.Nonsmooth Quasistatic Modeling of Hydraulic Actuators  [ :arrow_down: ](https://arxiv.org/pdf/2102.11381.pdf)
>  This article presents a quasistatic model of a hydraulic actuator driven by a four-valve independent metering circuit. The presented model describes the quasistatic balance between the velocity and force and that between the flowrate and the pressure. In such balanced states, the pressure difference across each valve determines the oil flowrate through the valve, the oil flowrate into the actuator determines the velocity of the actuator, and the pressures in the actuator chambers are algebraically related to the external force acting on the actuator. Based on these relations, we derive a set of quasistatic representations, which analytically relates the control valve openings, the actuator velocity, and the external force. This analytical expression is written with nonsmooth functions, of which the return values are set-valued instead of single-valued. We also show a method of incorporating the obtained nonsmooth quasistatic model into multibody simulators, in which a virtual viscoelastic element is used to mimic transient responses. In addition, the proposed model is extended to include a regeneration pipeline and to deal with a collection of actuators driven by a single pump.      
### 24.Remote Renewable Hubs For Carbon-Neutral Synthetic Fuel Production  [ :arrow_down: ](https://arxiv.org/pdf/2102.11375.pdf)
>  This paper studies the economics of carbon-neutral synthetic fuel production from renewable electricity in remote areas where high-quality renewable resources are abundant. To this end, a graph-based optimisation modelling framework directly applicable to the strategic planning of remote renewable energy supply chains is proposed. More precisely, a graph abstraction of planning problems is introduced, wherein nodes can be viewed as optimisation subproblems with their own parameters, variables, constraints and local objective, and typically represent a subsystem such as a technology, a plant or a process. Edges, on the other hand, express the connectivity between subsystems. The framework is leveraged to study the economics of carbon-neutral synthetic methane production from solar and wind energy in North Africa and its delivery to Northwestern European markets. The full supply chain is modelled in an integrated fashion, which makes it possible to accurately capture the interaction between various technologies on hourly time scales. Results suggest that the cost of synthetic methane production and delivery would be slightly under 200 \euro/MWh and 150 \euro/MWh by 2030 for a system supplying 100 TWh (higher heating value) annually that relies on solar photovoltaic plants alone and a combination of solar photovoltaic and wind power plants, respectively, assuming a uniform weighted average cost of capital of 7\%. The cost difference between these system configurations mostly stems from higher investments in technologies providing flexibility required to balance the system in the solar-driven configuration. Synthetic methane costs would drop to roughly 124 \euro/MWh and 87 \euro/MWh, respectively, if financing costs were zero and only technology costs were taken into account. Prospects for cost reductions are also discussed, and options that would enable such reductions are reviewed.      
### 25.Probabilistic Spatial Analysis in Quantitative Microscopy with Uncertainty-Aware Cell Detection using Deep Bayesian Regression of Density Maps  [ :arrow_down: ](https://arxiv.org/pdf/2102.11865.pdf)
>  3D microscopy is key in the investigation of diverse biological systems, and the ever increasing availability of large datasets demands automatic cell identification methods that not only are accurate, but also can imply the uncertainty in their predictions to inform about potential errors and hence confidence in conclusions using them. While conventional deep learning methods often yield deterministic results, advances in deep Bayesian learning allow for accurate predictions with a probabilistic interpretation in numerous image classification and segmentation tasks. It is however nontrivial to extend such Bayesian methods to cell detection, which requires specialized learning frameworks. In particular, regression of density maps is a popular successful approach for extracting cell coordinates from local peaks in a postprocessing step, which hinders any meaningful probabilistic output. We herein propose a deep learning-based cell detection framework that can operate on large microscopy images and outputs desired probabilistic predictions by (i) integrating Bayesian techniques for the regression of uncertainty-aware density maps, where peak detection can be applied to generate cell proposals, and (ii) learning a mapping from the numerous proposals to a probabilistic space that is calibrated, i.e. accurately represents the chances of a successful prediction. Utilizing such calibrated predictions, we propose a probabilistic spatial analysis with Monte-Carlo sampling. We demonstrate this in revising an existing description of the distribution of a mesenchymal stromal cell type within the bone marrow, where our proposed methods allow us to reveal spatial patterns that are otherwise undetectable. Introducing such probabilistic analysis in quantitative microscopy pipelines will allow for reporting confidence intervals for testing biological hypotheses of spatial distributions.      
### 26.Online Stochastic Gradient Descent Learns Linear Dynamical Systems from A Single Trajectory  [ :arrow_down: ](https://arxiv.org/pdf/2102.11822.pdf)
>  This work investigates the problem of estimating the weight matrices of a stable time-invariant linear dynamical system from a single sequence of noisy measurements. We show that if the unknown weight matrices describing the system are in Brunovsky canonical form, we can efficiently estimate the ground truth unknown matrices of the system from a linear system of equations formulated based on the transfer function of the system, using both online and offline stochastic gradient descent (SGD) methods. Specifically, by deriving concrete complexity bounds, we show that SGD converges linearly in expectation to any arbitrary small Frobenius norm distance from the ground truth weights. To the best of our knowledge, ours is the first work to establish linear convergence characteristics for online and offline gradient-based iterative methods for weight matrix estimation in linear dynamical systems from a single trajectory. Extensive numerical tests verify that the performance of the proposed methods is consistent with our theory, and show their superior performance relative to existing state of the art methods.      
### 27.Improving Deep Learning Sound Events Classifiers using Gram Matrix Feature-wise Correlations  [ :arrow_down: ](https://arxiv.org/pdf/2102.11771.pdf)
>  In this paper, we propose a new Sound Event Classification (SEC) method which is inspired in recent works for out-of-distribution detection. In our method, we analyse all the activations of a generic CNN in order to produce feature representations using Gram Matrices. The similarity metrics are evaluated considering all possible classes, and the final prediction is defined as the class that minimizes the deviation with respect to the features seeing during training. The proposed approach can be applied to any CNN and our experimental evaluation of four different architectures on two datasets demonstrated that our method consistently improves the baseline models.      
### 28.Uncertainty-aware Generalized Adaptive CycleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2102.11747.pdf)
>  Unpaired image-to-image translation refers to learning inter-image-domain mapping in an unsupervised manner. Existing methods often learn deterministic mappings without explicitly modelling the robustness to outliers or predictive uncertainty, leading to performance degradation when encountering unseen out-of-distribution (OOD) patterns at test time. To address this limitation, we propose a novel probabilistic method called Uncertainty-aware Generalized Adaptive Cycle Consistency (UGAC), which models the per-pixel residual by generalized Gaussian distribution, capable of modelling heavy-tailed distributions. We compare our model with a wide variety of state-of-the-art methods on two challenging tasks: unpaired image denoising in the natural image and unpaired modality prorogation in medical image domains. Experimental results demonstrate that our model offers superior image generation quality compared to recent methods in terms of quantitative metrics such as signal-to-noise ratio and structural similarity. Our model also exhibits stronger robustness towards OOD test data.      
### 29.Data Fusion for Audiovisual Speaker Localization: Extending Dynamic Stream Weights to the Spatial Domain  [ :arrow_down: ](https://arxiv.org/pdf/2102.11588.pdf)
>  Estimating the positions of multiple speakers can be helpful for tasks like automatic speech recognition or speaker diarization. Both applications benefit from a known speaker position when, for instance, applying beamforming or assigning unique speaker identities. Recently, several approaches utilizing acoustic signals augmented with visual data have been proposed for this task. However, both the acoustic and the visual modality may be corrupted in specific spatial regions, for instance due to poor lighting conditions or to the presence of background noise. This paper proposes a novel audiovisual data fusion framework for speaker localization by assigning individual dynamic stream weights to specific regions in the localization space. This fusion is achieved via a neural network, which combines the predictions of individual audio and video trackers based on their time- and location-dependent reliability. A performance evaluation using audiovisual recordings yields promising results, with the proposed fusion approach outperforming all baseline models.      
### 30.Memory-efficient Speech Recognition on Smart Devices  [ :arrow_down: ](https://arxiv.org/pdf/2102.11531.pdf)
>  Recurrent transducer models have emerged as a promising solution for speech recognition on the current and next generation smart devices. The transducer models provide competitive accuracy within a reasonable memory footprint alleviating the memory capacity constraints in these devices. However, these models access parameters from off-chip memory for every input time step which adversely effects device battery life and limits their usability on low-power devices. <br>We address transducer model's memory access concerns by optimizing their model architecture and designing novel recurrent cell designs. We demonstrate that i) model's energy cost is dominated by accessing model weights from off-chip memory, ii) transducer model architecture is pivotal in determining the number of accesses to off-chip memory and just model size is not a good proxy, iii) our transducer model optimizations and novel recurrent cell reduces off-chip memory accesses by 4.5x and model size by 2x with minimal accuracy impact.      
### 31.DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.11492.pdf)
>  Thermal power generation plays a dominant role in the world's electricity supply. It consumes large amounts of coal worldwide, and causes serious air pollution. Optimizing the combustion efficiency of a thermal power generating unit (TPGU) is a highly challenging and critical task in the energy industry. We develop a new data-driven AI system, namely DeepThermal, to optimize the combustion control strategy for TPGUs. At its core, is a new model-based offline reinforcement learning (RL) framework, called MORE, which leverages logged historical operational data of a TGPU to solve a highly complex constrained Markov decision process problem via purely offline training. MORE aims at simultaneously improving the long-term reward (increase combustion efficiency and reduce pollutant emission) and controlling operational risks (safety constraints satisfaction). In DeepThermal, we first learn a data-driven combustion process simulator from the offline dataset. The RL agent of MORE is then trained by combining real historical data as well as carefully filtered and processed simulation data through a novel restrictive exploration scheme. DeepThermal has been successfully deployed in four large coal-fired thermal power plants in China. Real-world experiments show that DeepThermal effectively improves the combustion efficiency of a TPGU. We also report and demonstrate the superior performance of MORE by comparing with the state-of-the-art algorithms on the standard offline RL benchmarks. To the best knowledge of the authors, DeepThermal is the first AI application that has been used to solve real-world complex mission-critical control tasks using the offline RL approach.      
### 32.Senone-aware Adversarial Multi-task Training for Unsupervised Child to Adult Speech Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2102.11488.pdf)
>  Acoustic modeling for child speech is challenging due to the high acoustic variability caused by physiological differences in the vocal tract. The dearth of publicly available datasets makes the task more challenging. In this work, we propose a feature adaptation approach by exploiting adversarial multi-task training to minimize acoustic mismatch at the senone (tied triphone states) level between adult and child speech and leverage large amounts of transcribed adult speech. We validate the proposed method on three tasks: child speech recognition, child pronunciation assessment, and child fluency score prediction. Empirical results indicate that our proposed approach consistently outperforms competitive baselines, achieving 7.7% relative error reduction on speech recognition and up to 25.2% relative gains on the evaluation tasks.      
### 33.Text-to-Audio Grounding: Building Correspondence Between Captions and Sound Events  [ :arrow_down: ](https://arxiv.org/pdf/2102.11474.pdf)
>  Automated Audio Captioning is a cross-modal task, generating natural language descriptions to summarize the audio clips' sound events. However, grounding the actual sound events in the given audio based on its corresponding caption has not been investigated. This paper contributes an AudioGrounding dataset, which provides the correspondence between sound events and the captions provided in Audiocaps, along with the location (timestamps) of each present sound event. Based on such, we propose the text-to-audio grounding (TAG) task, which interactively considers the relationship between audio processing and language understanding. A baseline approach is provided, resulting in an event-F1 score of 28.3% and a Polyphonic Sound Detection Score (PSDS) score of 14.7%.      
### 34.An Interaction-aware Evaluation Method for Highly Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2102.11462.pdf)
>  It is important to build a rigorous verification and validation (V&amp;V) process to evaluate the safety of highly automated vehicles (HAVs) before their wide deployment on public roads. In this paper, we propose an interaction-aware framework for HAV safety evaluation which is suitable for some highly-interactive driving scenarios including highway merging, roundabout entering, etc. Contrary to existing approaches where the primary other vehicle (POV) takes predetermined maneuvers, we model the POV as a game-theoretic agent. To capture a wide variety of interactions between the POV and the vehicle under test (VUT), we characterize the interactive behavior using level-k game theory and social value orientation and train a diverse set of POVs using reinforcement learning. Moreover, we propose an adaptive test case sampling scheme based on the Gaussian process regression technique to generate customized and diverse challenging cases. The highway merging is used as the example scenario. We found the proposed method is able to capture a wide range of POV behaviors and achieve better coverage of the failure modes of the VUT compared with other evaluation approaches.      
### 35.Investigating Local and Global Information for Automated Audio Captioning with Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.11457.pdf)
>  Automated audio captioning (AAC) aims at generating summarizing descriptions for audio clips. Multitudinous concepts are described in an audio caption, ranging from local information such as sound events to global information like acoustic scenery. Currently, the mainstream paradigm for AAC is the end-to-end encoder-decoder architecture, expecting the encoder to learn all levels of concepts embedded in the audio automatically. This paper first proposes a topic model for audio descriptions, comprehensively analyzing the hierarchical audio topics that are commonly covered. We then explore a transfer learning scheme to access local and global information. Two source tasks are identified to respectively represent local and global information, being Audio Tagging (AT) and Acoustic Scene Classification (ASC). Experiments are conducted on the AAC benchmark dataset Clotho and Audiocaps, amounting to a vast increase in all eight metrics with topic transfer learning. Further, it is discovered that local information and abstract representation learning are more crucial to AAC than global information and temporal relationship learning.      
### 36.Man-in-The-Middle Attacks and Defense in a Power System Cyber-Physical Testbed  [ :arrow_down: ](https://arxiv.org/pdf/2102.11455.pdf)
>  Man-in-The-Middle (MiTM) attacks present numerous threats to a smart grid. In a MiTM attack, an intruder embeds itself within a conversation between two devices to either eavesdrop or impersonate one of the devices, making it appear to be a normal exchange of information. Thus, the intruder can perform false data injection (FDI) and false command injection (FCI) attacks that can compromise power system operations, such as state estimation, economic dispatch, and automatic generation control (AGC). Very few researchers have focused on MiTM methods that are difficult to detect within a smart grid. To address this, we are designing and implementing multi-stage MiTM intrusions in an emulation-based cyber-physical power system testbed against a large-scale synthetic grid model to demonstrate how such attacks can cause physical contingencies such as misguided operation and false measurements. MiTM intrusions create FCI, FDI, and replay attacks in this synthetic power grid. This work enables stakeholders to defend against these stealthy attacks, and we present detection mechanisms that are developed using multiple alerts from intrusion detection systems and network monitoring tools. Our contribution will enable other smart grid security researchers and industry to develop further detection mechanisms for inconspicuous MiTM attacks.      
### 37.Quasi-Distributed Antenna Selection for Spectral Efficiency Maximization in Subarray Switching XL-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.11438.pdf)
>  In this paper, we consider the downlink (DL) of a zero-forcing (ZF) precoded extra-large scale massive MIMO (XL-MIMO) system. The base-station (BS) operates with limited number of radio-frequency (RF) transceivers due to high cost, power consumption and interconnection bandwidth associated to the fully digital implementation. The BS, which is implemented with a subarray switching architecture, selects groups of active antennas inside each subarray to transmit the DL signal. This work proposes efficient resource allocation (RA) procedures to perform joint antenna selection (AS) and power allocation (PA) to maximize the DL spectral efficiency (SE) of an XL-MIMO system operating under different loading settings. Two metaheuristic RA procedures based on the genetic algorithm (GA) are assessed and compared in terms of performance, coordination data size and computational complexity. One algorithm is based on a quasi-distributed methodology while the other is based on the conventional centralized processing. Numerical results demonstrate that the quasi-distributed GA-based procedure results in a suitable trade-off between performance, complexity and exchanged coordination data. At the same time, it outperforms the centralized procedures with appropriate system operation settings.      
### 38.Smart Navigation for an In-pipe Robot Through Multi-phase Motion Control and Particle Filtering Method  [ :arrow_down: ](https://arxiv.org/pdf/2102.11434.pdf)
>  In-pipe robots are promising solutions for condition assessment, leak detection, water quality monitoring in a variety of other tasks in pipeline networks. Smart navigation is an extremely challenging task for these robots as a result of highly uncertain and disturbing environment for operation. Wireless communication to control these robots during operation is not feasible if the pipe material is metal since the radio signals are destroyed in the pipe environment, and hence, this challenge is still unsolved. In this paper, we introduce a method for smart navigation for our previously designed in-pipe robot [1] based on particle filtering and a two-phase motion controller. The robot is given the map of the operation path with a novel approach and the particle filtering determines the straight and non-straight configurations of the pipeline. In the straight paths, the robot follows a linear quadratic regulator (LQR) and proportional-integral-derivative (PID) based controller that stabilizes the robot and tracks a desired velocity. In non-straight paths, the robot follows the trajectory that a motion trajectory generator block plans for the robot. The proposed method is a promising solution for smart navigation without the need for wireless communication and capable of inspecting long distances in water distribution systems.      
### 39.BMART-Enabled Field-Map Combination of Projection-Reconstruction Phase-Cycled SSFP Cardiac Cine for Banding and Flow-Artifact Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2102.11428.pdf)
>  Purpose: To develop a method for banding-free bSSFP cardiac cine with substantially reduced flow artifacts. <br>Methods: A projection-reconstruction (PR) trajectory is proposed for a frequency-modulated cine sequence, facilitating reconstruction of three phase cycles and a field-map time series from a short, breath-held scan. Data is also acquired during the gradient rewinders to enable generation of field maps using BMART, B$_0$ mapping using rewinding trajectories, where the rewind data forms the second TE image for calculating the field map. A field-map-based combination method is developed which weights the phase-cycle component images to include only passband signal in the final cine images, and exclude stopband and near-band flow artifacts. <br>Results: The weights derived from the BMART-generated field maps mask out banding and near-band flow artifacts in and around the heart. Therefore, the field-map-based phase-cycle combination, which is facilitated by the PR acquisition with BMART, results in more homogeneous blood pools and reduced hyperintense regions than root-sum-of-squares. <br>Conclusion: With the proposed techniques, using a non-Cartesian trajectory for a frequency-modulated cine sequence enables flow-artifact-reduced banding-free cardiac imaging within a short breath-hold.      
### 40.Investigating Deep Neural Structures and their Interpretability in the Domain of Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2102.11420.pdf)
>  Generative Adversarial Networks (GANs) are machine learning networks based around creating synthetic data. Voice Conversion (VC) is a subset of voice translation that involves translating the paralinguistic features of a source speaker to a target speaker while preserving the linguistic information. The aim of non-parallel conditional GANs for VC is to translate an acoustic speech feature sequence from one domain to another without the use of paired data. In the study reported here, we investigated the interpretability of state-of-the-art implementations of non-parallel GANs in the domain of VC. We show that the learned representations in the repeating layers of a particular GAN architecture remain close to their original random initialised parameters, demonstrating that it is the number of repeating layers that is more responsible for the quality of the output. We also analysed the learned representations of a model trained on one particular dataset when used during transfer learning on another dataset. This showed extremely high levels of similarity across the entire network. Together, these results provide new insight into how the learned representations of deep generative networks change during learning and the importance in the number of layers.      
### 41.Procam Calibration from a Single Pose of a Planar Target  [ :arrow_down: ](https://arxiv.org/pdf/2102.11395.pdf)
>  A novel user friendly method is proposed for calibrating a procam system from a single pose of a planar chessboard target. The user simply needs to orient the chessboard in a single appropriate pose. A sequence of Gray Code patterns are projected onto the chessboard, which allows correspondences between the camera, projector and the chessboard to be automatically extracted. These correspondences are fed as input to a nonlinear optimization method that models the projector of the principle points onto the chessboard, and accurately calculates the intrinsic and extrinsic parameters of both the camera and the projector, as well as the camera's distortion coefficients. The method is experimentally validated on the procam system, which is shown to be comparable in accuracy with existing multi-pose approaches. The impact of the orientation of the chessboard with respect to the procam imaging places is also explored through extensive simulation.      
### 42.Explore the Context: Optimal Data Collection for Context-Conditional Dynamics Models  [ :arrow_down: ](https://arxiv.org/pdf/2102.11394.pdf)
>  In this paper, we learn dynamics models for parametrized families of dynamical systems with varying properties. The dynamics models are formulated as stochastic processes conditioned on a latent context variable which is inferred from observed transitions of the respective system. The probabilistic formulation allows us to compute an action sequence which, for a limited number of environment interactions, optimally explores the given system within the parametrized family. This is achieved by steering the system through transitions being most informative for the context variable. We demonstrate the effectiveness of our method for exploration on a non-linear toy-problem and two well-known reinforcement learning environments.      
### 43.No-Reference Quality Assessment for 360-degree Images by Analysis of Multi-frequency Information and Local-global Naturalness  [ :arrow_down: ](https://arxiv.org/pdf/2102.11393.pdf)
>  360-degree/omnidirectional images (OIs) have achieved remarkable attentions due to the increasing applications of virtual reality (VR). Compared to conventional 2D images, OIs can provide more immersive experience to consumers, benefitting from the higher resolution and plentiful field of views (FoVs). Moreover, observing OIs is usually in the head mounted display (HMD) without references. Therefore, an efficient blind quality assessment method, which is specifically designed for 360-degree images, is urgently desired. In this paper, motivated by the characteristics of the human visual system (HVS) and the viewing process of VR visual contents, we propose a novel and effective no-reference omnidirectional image quality assessment (NR OIQA) algorithm by Multi-Frequency Information and Local-Global Naturalness (MFILGN). Specifically, inspired by the frequency-dependent property of visual cortex, we first decompose the projected equirectangular projection (ERP) maps into wavelet subbands. Then, the entropy intensities of low and high frequency subbands are exploited to measure the multi-frequency information of OIs. Besides, except for considering the global naturalness of ERP maps, owing to the browsed FoVs, we extract the natural scene statistics features from each viewport image as the measure of local naturalness. With the proposed multi-frequency information measurement and local-global naturalness measurement, we utilize support vector regression as the final image quality regressor to train the quality evaluation model from visual quality-related features to human ratings. To our knowledge, the proposed model is the first no-reference quality assessment method for 360-degreee images that combines multi-frequency information and image naturalness. Experimental results on two publicly available OIQA databases demonstrate that our proposed MFILGN outperforms state-of-the-art approaches.      
### 44.Reinforcement Learning of Beam Codebooks in Millimeter Wave and Terahertz MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.11392.pdf)
>  Millimeter wave (mmWave) and terahertz MIMO systems rely on pre-defined beamforming codebooks for both initial access and data transmission. Being pre-defined, however, these codebooks are commonly not optimized for specific environments, user distributions, and/or possible hardware impairments. This leads to large codebook sizes with high beam training overhead which increases the initial access/tracking latency and makes it hard for these systems to support highly mobile applications. To overcome these limitations, this paper develops a deep reinforcement learning framework that learns how to iteratively optimize the codebook beam patterns (shapes) relying only on the receive power measurements and without requiring any explicit channel knowledge. The developed model learns how to autonomously adapt the beam patterns to best match the surrounding environment, user distribution, hardware impairments, and array geometry. Further, this approach does not require any knowledge about the channel, array geometry, RF hardware, or user positions. To reduce the learning time, the proposed model designs a novel Wolpertinger-variant architecture that is capable of efficiently searching for an optimal policy in a large discrete action space, which is important for large antenna arrays with quantized phase shifters. This complex-valued neural network architecture design respects the practical RF hardware constraints such as the constant-modulus and quantized phase shifter constraints. Simulation results based on the publicly available DeepMIMO dataset confirm the ability of the developed framework to learn near-optimal beam patterns for both line-of-sight (LOS) and non-LOS scenarios and for arrays with hardware impairments without requiring any channel knowledge.      

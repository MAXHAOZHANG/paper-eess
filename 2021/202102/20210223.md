# ArXiv eess --Tue, 23 Feb 2021
### 1."Am I A Good Therapist?" Automated Evaluation Of Psychotherapy Skills Using Speech And Language Technologies  [ :arrow_down: ](https://arxiv.org/pdf/2102.11265.pdf)
>  With the growing prevalence of psychological interventions, it is vital to have measures which rate the effectiveness of psychological care, in order to assist in training, supervision, and quality assurance of services. Traditionally, quality assessment is addressed by human raters who evaluate recorded sessions along specific dimensions, often codified through constructs relevant to the approach and domain. This is however a cost-prohibitive and time-consuming method which leads to poor feasibility and limited use in real-world settings. To facilitate this process, we have developed an automated competency rating tool able to process the raw recorded audio of a session, analyzing who spoke when, what they said, and how the health professional used language to provide therapy. Focusing on a use case of a specific type of psychotherapy called Motivational Interviewing, our system gives comprehensive feedback to the therapist, including information about the dynamics of the session (e.g., therapist's vs. client's talking time), low-level psychological language descriptors (e.g., type of questions asked), as well as other high-level behavioral constructs (e.g., the extent to which the therapist understands the clients' perspective). We describe our platform and its performance, using a dataset of more than 5,000 recordings drawn from its deployment in a real-world clinical setting used to assist training of new therapists. We are confident that a widespread use of automated psychotherapy rating tools in the near future will augment experts' capabilities by providing an avenue for more effective training and skill improvement and will eventually lead to more positive clinical outcomes.      
### 2.On Stability and Convergence of Distributed Filters  [ :arrow_down: ](https://arxiv.org/pdf/2102.11250.pdf)
>  Recent years have bore witness to the proliferation of distributed filtering techniques, where a collection of agents communicating over an ad-hoc network aim to collaboratively estimate and track the state of a system. These techniques form the enabling technology of modern multi-agent systems and have gained great importance in the engineering community. Although most distributed filtering techniques come with a set of stability and convergence criteria, the conditions imposed are found to be unnecessarily restrictive. The paradigm of stability and convergence in distributed filtering is revised in this manuscript. Accordingly, a general distributed filter is constructed and its estimation error dynamics is formulated. The conducted analysis demonstrates that conditions for achieving stable filtering operations are the same as those required in the centralized filtering setting. Finally, the concepts are demonstrated in a Kalman filtering framework and validated using simulation examples.      
### 3.Mixed-Precision Quantization and Parallel Implementation of Multispectral Riemannian Classification for Brain--Machine Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2102.11221.pdf)
>  With Motor-Imagery (MI) Brain--Machine Interfaces (BMIs) we may control machines by merely thinking of performing a motor action. Practical use cases require a wearable solution where the classification of the brain signals is done locally near the sensor using machine learning models embedded on energy-efficient microcontroller units (MCUs), for assured privacy, user comfort, and long-term usage. In this work, we provide practical insights on the accuracy-cost tradeoff for embedded BMI solutions. Our proposed Multispectral Riemannian Classifier reaches 75.1% accuracy on 4-class MI task. We further scale down the model by quantizing it to mixed-precision representations with a minimal accuracy loss of 1%, which is still 3.2% more accurate than the state-of-the-art embedded convolutional neural network. We implement the model on a low-power MCU with parallel processing units taking only 33.39ms and consuming 1.304mJ per classification.      
### 4.Reinforcement Learning of the Prediction Horizon in Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2102.11122.pdf)
>  Model predictive control (MPC) is a powerful trajectory optimization control technique capable of controlling complex nonlinear systems while respecting system constraints and ensuring safe operation. The MPC's capabilities come at the cost of a high online computational complexity, the requirement of an accurate model of the system dynamics, and the necessity of tuning its parameters to the specific control application. The main tunable parameter affecting the computational complexity is the prediction horizon length, controlling how far into the future the MPC predicts the system response and thus evaluates the optimality of its computed trajectory. A longer horizon generally increases the control performance, but requires an increasingly powerful computing platform, excluding certain control applications.The performance sensitivity to the prediction horizon length varies over the state space, and this motivated the adaptive horizon model predictive control (AHMPC), which adapts the prediction horizon according to some criteria. In this paper we propose to learn the optimal prediction horizon as a function of the state using reinforcement learning (RL). We show how the RL learning problem can be formulated and test our method on two control tasks, showing clear improvements over the fixed horizon MPC scheme, while requiring only minutes of learning.      
### 5.RCoNet: Deformable Mutual Information Maximization and High-order Uncertainty-aware Learning for Robust COVID-19 Detection  [ :arrow_down: ](https://arxiv.org/pdf/2102.11099.pdf)
>  The novel 2019 Coronavirus (COVID-19) infection has spread world widely and is currently a major healthcare challenge around the world. Chest Computed Tomography (CT) and X-ray images have been well recognized to be two effective techniques for clinical COVID-19 disease diagnoses. Due to faster imaging time and considerably lower cost than CT, detecting COVID-19 in chest X-ray (CXR) images is preferred for efficient diagnosis, assessment and treatment. However, considering the similarity between COVID-19 and pneumonia, CXR samples with deep features distributed near category boundaries are easily misclassified by the hyper-planes learned from limited training data. Moreover, most existing approaches for COVID-19 detection focus on the accuracy of prediction and overlook the uncertainty estimation, which is particularly important when dealing with noisy datasets. To alleviate these concerns, we propose a novel deep network named {\em RCoNet$^k_s$} for robust COVID-19 detection which employs {\em Deformable Mutual Information Maximization} (DeIM), {\em Mixed High-order Moment Feature} (MHMF) and {\em Multi-expert Uncertainty-aware Learning} (MUL). With DeIM, the mutual information (MI) between input data and the corresponding latent representations can be well estimated and maximized to capture compact and disentangled representational characteristics. Meanwhile, MHMF can fully explore the benefits of using high-order statistics and extract discriminative features of complex distributions in medical imaging. Finally, MUL creates multiple parallel dropout networks for each CXR image to evaluate uncertainty and thus prevent performance degradation caused by the noise in the data.      
### 6.Comparative Fault Location Estimation by Using Image Processing in Mixed Transmission Lines  [ :arrow_down: ](https://arxiv.org/pdf/2102.11085.pdf)
>  The distance protection relays are used to determine the impedance based fault location according to the current and voltage magnitudes in the transmission lines. However, the fault location cannot be correctly detected in mixed transmission lines due to different characteristic impedance per unit length because the characteristic impedance of high voltage cable line is significantly different from overhead line. Thus, determinations of the fault section and location with the distance protection relays are difficult in the mixed transmission lines. In this study, 154 kV overhead transmission line and underground cable line are examined as the mixed transmission line for the distance protection relays. Phase to ground faults are created in the mixed transmission line. overhead line section and underground cable section are simulated by using PSCAD-EMTDC.The short circuit fault images are generated in the distance protection relay for the overhead transmission line and underground cable transmission line faults. The images include the R-X impedance diagram of the fault, and the R-X impedance diagram have been detected by applying image processing steps. Artificial neural network (ANN) and the regression methods are used for prediction of the fault location, and the results of image processing are used as the input parameters for the training process of ANN and the regression methods. The results of ANN and regression methods are compared to select the most suitable method at the end of this study for forecasting of the fault location in transmission lines.      
### 7.Determination of Fault Location in Transmission Lines with Image Processing and Artificial Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.11073.pdf)
>  In order to transmit electrical energy in a continuous and quality manner, it is necessary to control it from the point of production to the point of consumption. Therefore, protection of transmission and distribution lines is essential at every stage from production to consumption. The main function of the protection relays in electrical installations should be deactivated as soon as possible in the event of short circuits in the system. The most important part of the system is energy transmission lines and distance protection relays that protect these lines. An accurate error location technique is required to make fast and efficient work. Transformer neutral point grounding in transmission lines affects the operation of the zero component current during the single phase to ground short circuit failure of a power system. Considering the relationship between the grounding system and protection systems, an appropriate grounding choice should be made. Artificial neural network (ANN) has been used in order to accurately locate short circuit faults in different grounding systems in transmission lines. Compared with support vector machines (SVM) for testing inside ANN The transmission line model is made in the PSCAD-EMTDC simulation program. Data sets were created by recording the image of the impedance change of the R-X impedance diagram of the distance protection relay in short circuit faults created in different grounding systems. The related focal points in the images are given as an introduction to different ANN models using feature extraction and image processing techniques and the ANN model with the highest fault location estimation accuracy was chosen.      
### 8.Adaptive Video Configuration and Bitrate Allocation for Teleoperated Driving  [ :arrow_down: ](https://arxiv.org/pdf/2102.10898.pdf)
>  Vehicles with autonomous driving capabilities are present on public streets. However, edge cases remain that still require a human in-vehicle driver. Assuming the vehicle manages to come to a safe state in an automated fashion, teleoperated driving technology enables a human to resolve the situation remotely by a control interface connected via a mobile network. While this is a promising solution, it also introduces technical challenges, one of them being the necessity to transmit video data of multiple cameras from the vehicle to the human operator. In this paper, an adaptive video streaming framework specifically designed for teleoperated driving is proposed and demonstrated. The framework enables automatic reconfiguration of the video streams of the multi-camera system at runtime. Predictions of variable transmission service quality are taken into account. With the objective to maximize visual quality, the framework uses so-called rate-quality models to dynamically allocate bitrates and select resolution scaling factors. Results from deploying the proposed framework on an actual teleoperated driving system are presented.      
### 9.Elevated LiDAR based Sensing for 6G -- 3D Maps with cm Level Accuracy  [ :arrow_down: ](https://arxiv.org/pdf/2102.10849.pdf)
>  One key vertical application that will be enabled by 6G is the automation of the processes with the increased use of robots. As a result, sensing and localization of the surrounding environment becomes a crucial factor for these robots to operate. Light detection and ranging (LiDAR) has emerged as an appropriate method of sensing due to its capability of generating detail-rich information with high accuracy. However, LiDARs are power hungry devices that generate a lot of data, and these characteristics limit their use as on-board sensors in robots. In this paper, we present a novel approach on the methodology of generating an enhanced 3D map with improved field-of-view using multiple LiDAR sensors. We utilize an inherent property of LiDAR point clouds; rings and data from the inertial measurement unit (IMU) embedded in the sensor for registration of the point clouds. The generated 3D map has an accuracy of 10 cm when compared to the real-world measurements. We also carry out the practical implementation of the proposed method using two LiDAR sensors. Furthermore, we develop an application to utilize the generated map where a robot navigates through the mapped environment with minimal support from the sensors on-board. The LiDARs are fixed in the infrastructure at elevated positions. Thus this is applicable to vehicular and factory scenarios. Our results further validate the idea of using multiple elevated LiDARs as a part of the infrastructure for various applications.      
### 10.A bi-atrial statistical shape model for large-scale in silico studies of human atria: model development and application to ECG simulations  [ :arrow_down: ](https://arxiv.org/pdf/2102.10838.pdf)
>  Large-scale electrophysiological simulations to obtain electrocardiograms (ECG) carry the potential to produce extensive datasets for training of machine learning classifiers to, e.g., discriminate between different cardiac pathologies. The adoption of simulations for these purposes is limited due to a lack of ready-to-use models covering atrial anatomical variability. We built a bi-atrial statistical shape model (SSM) of the endocardial wall based on 47 segmented human CT and MRI datasets using Gaussian process morphable models. Generalization, specificity, and compactness metrics were evaluated. The SSM was applied to simulate atrial ECGs in 100 random volumetric instances. The first eigenmode of our SSM reflects a change of the total volume of both atria, the second the asymmetry between left vs. right atrial volume, the third a change in the prominence of the atrial appendages. The SSM is capable of generalizing well to unseen geometries and 95% of the total shape variance is covered by its first 23 eigenvectors. The P waves in the 12-lead ECG of 100 random instances showed a duration of 104ms in accordance with large cohort studies. The novel bi-atrial SSM itself as well as 100 exemplary instances with rule-based augmentation of atrial wall thickness, fiber orientation, inter-atrial bridges and tags for anatomical structures have been made publicly available. The novel, openly available bi-atrial SSM can in future be employed to generate large sets of realistic atrial geometries as a basis for in silico big data approaches.      
### 11.LVCNet: Efficient Condition-Dependent Modeling Network for Waveform Generation  [ :arrow_down: ](https://arxiv.org/pdf/2102.10815.pdf)
>  In this paper, we propose a novel conditional convolution network, named location-variable convolution, to model the dependencies of the waveform sequence. Different from the use of unified convolution kernels in WaveNet to capture the dependencies of arbitrary waveform, the location-variable convolution uses convolution kernels with different coefficients to perform convolution operations on different waveform intervals, where the coefficients of kernels is predicted according to conditioning acoustic features, such as Mel-spectrograms. Based on location-variable convolutions, we design LVCNet for waveform generation, and apply it in Parallel WaveGAN to design more efficient vocoder. Experiments on the LJSpeech dataset show that our proposed model achieves a four-fold increase in synthesis speed compared to the original Parallel WaveGAN without any degradation in sound quality, which verifies the effectiveness of location-variable convolutions.      
### 12.Provably Correct Training of Neural Network Controllers Using Reachability Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2102.10806.pdf)
>  In this paper, we consider the problem of training neural network (NN) controllers for cyber-physical systems (CPS) that are guaranteed to satisfy safety and liveness properties. Our approach is to combine model-based design methodologies for dynamical systems with data-driven approaches to achieve this target. Given a mathematical model of the dynamical system, we compute a finite-state abstract model that captures the closed-loop behavior under all possible neural network controllers. Using this finite-state abstract model, our framework identifies the subset of NN weights that are guaranteed to satisfy the safety requirements. During training, we augment the learning algorithm with a NN weight projection operator that enforces the resulting NN to be provably safe. To account for the liveness properties, the proposed framework uses the finite-state abstract model to identify candidate NN weights that may satisfy the liveness properties. Using such candidate NN weights, the proposed framework biases the NN training to achieve the liveness specification. Achieving the guarantees above, can not be ensured without correctness guarantees on the NN architecture, which controls the NN's expressiveness. Therefore, and as a corner step in the proposed framework is the ability to select provably correct NN architectures automatically.      
### 13.Simultaneous Mode, State and Input Set-Valued Observers for Switched Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.10793.pdf)
>  In this paper, we study the problem of designing a simultaneous mode, input, and state set-valued observer for a class of hidden mode switched nonlinear systems with bounded-norm noise and unknown input signals, where the hidden mode and unknown inputs can represent fault or attack models and exogenous fault/disturbance or adversarial signals, respectively. The proposed multiple-model design has three constituents: (i) a bank of mode-matched set-valued observers, (ii) a mode observer, and (iii) a global fusion observer. The mode-matched observers recursively find the sets of compatible states and unknown inputs conditioned on the mode being the true mode, while the mode observer eliminates incompatible modes by leveraging a residual-based criterion. Then, the global fusion observer outputs the estimated sets of states and unknown inputs by taking the union of the mode-matched set-valued estimates over all compatible modes. Moreover, sufficient conditions to guarantee the elimination of all false modes (i.e., mode-detectability) are provided and the effectiveness of our approach is demonstrated and compared with existing approaches using an illustrative example.      
### 14.I-DREM MRAC with Time-Varying Adaptation Rate &amp; No A Priori Knowledge of Control Input Matrix Sign to Relax PE Condition  [ :arrow_down: ](https://arxiv.org/pdf/2102.10785.pdf)
>  The known dynamic regressor extension and mixing method (DREM) is combined with the proposed filter of a new type, which uses the integration operation, and the recursive least-squares method to develop the new I-DREM model reference adaptive control (MRAC) system. It does not require a priori knowledge of the sign or the elements values of the control input matrix of the plant. It also provides the exponential convergence of the adaptation process (with the automatically adjustable adaptation rate) without the regressor persistent excitation. Such control system allows to solve three actual problems of the adaptive control: 1) to provide the exponential convergence of the controller parameter error under the condition of the regressor initial excitation, 2) to make such convergence monotonic, 3) to calculate the adaptation rate online according to the current regressor value. Some numerical experiments are conducted to demonstrate the effectiveness of the proposed method.      
### 15.Model Order Reduction for Water Quality Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2102.10737.pdf)
>  A state-space representation of water quality dynamics describing disinfectant (e.g., chlorine) transport dynamics in drinking water distribution networks has been recently proposed. Such representation is a byproduct of space- and time-discretization of the PDE modeling transport dynamics. This results in a large state-space dimension even for small networks with tens of nodes. Although such a state-space model provides a model-driven approach to predict water quality dynamics, incorporating it into model-based control algorithms or state estimators for large networks is challenging and at times intractable. To that end, this paper investigates model order reduction (MOR) methods for water quality dynamics. The presented investigation focuses on reducing state-dimension by orders of magnitude, the stability of the MOR methods, and the application of these methods to model predictive control.      
### 16.A Data-Driven Energy Storage System-Based Algorithm for Monitoring the Small-Signal Stability of Power Grids with Volatile Wind Power  [ :arrow_down: ](https://arxiv.org/pdf/2102.10716.pdf)
>  In this paper, we propose a data-driven energy storage system (ESS)-based method to enhance the online small-signal stability monitoring of power networks with high penetration of intermittent wind power. To accurately estimate inter-area modes that are closely related to the system's inherent stability characteristics, a novel algorithm that leverages on recent advances in wide-area measurement systems (WAMSs) and ESS technologies is developed. It is shown that the proposed approach can smooth the wind power fluctuations in near real-time using a small additional ESS capacity and thus significantly enhance the monitoring of small-signal stability. Dynamic Monte Carlo simulations on the IEEE 68-bus system are used to illustrate the effectiveness of the proposed algorithm in smoothing wind power and estimating the inter-area mode statistical properties.      
### 17.Optimal Transportation Methods in Nonlinear Filtering: The feedback particle filter  [ :arrow_down: ](https://arxiv.org/pdf/2102.10712.pdf)
>  Feedback particle filter (FPF) is a Monte-Carlo (MC) algorithm to approximate the solution of a stochastic filtering problem. In contrast to conventional particle filters, the Bayesian update step in FPF is implemented via a mean-field type feedback control law. <br>The objective for this paper is to situate the development of FPF and related controlled interacting particle system algorithms within the framework of optimal transportation theory. Starting from the simplest setting of the Bayes' update formula, a coupling viewpoint is introduced to construct particle filters. It is shown that the conventional importance sampling resampling particle filter implements an independent coupling. Design of optimal couplings is introduced first for the simple Gaussian settings and subsequently extended to derive the FPF algorithm. The final half of the paper provides a review of some of the salient aspects of the FPF algorithm including the feedback structure, algorithms for gain function design, and comparison with conventional particle filters. The comparison serves to illustrate the benefit of feedback in particle filtering.      
### 18.Stochastic AC Network-constrained Scheduling of CAES and Wind Power Generation in Joint Energy and reserve market: Toward More Realistic Results  [ :arrow_down: ](https://arxiv.org/pdf/2102.10703.pdf)
>  In this paper, a two-stage stochastic day-ahead (DA) scheduling model is proposed incorporating wind power units and compressed air energy storage (CAES) to clear a co-optimized energy and reserve market. The two-stage stochastic programming method is employed to deal with the wind power generation uncertain nature. A linearized AC optimal power flow (LAC-OPF) approach with consideration of network losses, reactive power, and voltage magnitude constraints is utilized in the proposed two-stage stochastic DA scheduling model. Using an engineering insight, a two-level LAC-OPF (TL-LAC-OPF) approach is proposed to (i) reduce the number of binary variables of the LAC-OPF approach which decreases the computational burden, and (ii) obtain LAC-OPF pre-defined parameters adaptively so that the accuracy of LAC-OPF approach is increased as a result of reducing artificial losses. Furthermore, as the CAES efficiency depends on its thermodynamic and operational conditions, the proposed two-stage stochastic DA scheduling model is developed by considering its thermodynamic characteristics to obtain a more realistic market decision at the first place. The proposed model is applied to IEEE 30-bus and 57-bus test systems using GAMS software, and is compared with three traditional approaches, i.e., AC-OPF, DC-OPF, and LAC-OPF. Simulation results demonstrate effectiveness of the proposed methodology.      
### 19.Electromagnetic Model of Reflective Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2102.10666.pdf)
>  We present an accurate and simple analytical model for the computation of the reflection amplitude and phase of Reflecting Intelligent Surfaces. The model is based on a transmissionline circuit representation of the RIS which takes into account the physics behind the structure including the effect of all relevant geometrical and electrical parameters. The proposed representation of the RIS allows to take into account the effect of incidence angle, the mutual coupling among elements, the effect of the interaction of the periodic surface with the RIS ground plane. It is shown that, by using the proposed approach, it is possible to maximize the power received by a user in a RIS-assisted link without recurring to onerous electromagnetic simulations. The proposed model aims at filling the gap in the design of RIS assisted communications algorithms that are usually disconnected from physical implementation issues and realistic performance of these surfaces.      
### 20.Observer Design for Linear Aperiodic Sampled-Data Systems: A Hybrid Systems Approach  [ :arrow_down: ](https://arxiv.org/pdf/2102.10652.pdf)
>  Observer design for linear systems with aperiodic sampled-data measurements is addressed. To solve this problem, a novel hybrid observer is designed. The main peculiarity of the proposed observer consists of the use two output injection terms, one acting at the sampling instants and one providing an intersample injection. The error dynamics are augmented with a timer variable triggering the arrival of a new measurement and analyzed via hybrid system tools. Using Lyapunov theory, sufficient conditions for the convergence of the observer are provided. Relying on those conditions, an optimal LMI-based design is proposed for the observer gains. The effectiveness of the approach is illustrated in an example.      
### 21.Multi-Agent Consensus Subject to Communication and Privacy Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2102.10642.pdf)
>  We consider a multi-agent consensus problem in the presence of adversarial agents. The adversaries are able to listen to the inter-agent communications and try to estimate the state of the agents. The agents have a limited bit-rate for communication and are required to quantize the transmitted signal in order to meet the bit-rate constraint of the communication channel. We propose a consensus protocol that is protected against the adversaries, i.e., the expected mean-square error of the adversary state estimate is lower bounded. In order to deal with the bit-rate constraint, we propose a dynamic quantization scheme that guarantees protected consensus.      
### 22.Tchebichef Transform Domain-based Deep Learning Architecture for Image Super-resolution  [ :arrow_down: ](https://arxiv.org/pdf/2102.10640.pdf)
>  The recent outbreak of COVID-19 has motivated researchers to contribute in the area of medical imaging using artificial intelligence and deep learning. Super-resolution (SR), in the past few years, has produced remarkable results using deep learning methods. The ability of deep learning methods to learn the non-linear mapping from low-resolution (LR) images to their corresponding high-resolution (HR) images leads to compelling results for SR in diverse areas of research. In this paper, we propose a deep learning based image super-resolution architecture in Tchebichef transform domain. This is achieved by integrating a transform layer into the proposed architecture through a customized Tchebichef convolutional layer ($TCL$). The role of TCL is to convert the LR image from the spatial domain to the orthogonal transform domain using Tchebichef basis functions. The inversion of the aforementioned transformation is achieved using another layer known as the Inverse Tchebichef convolutional Layer (ITCL), which converts back the LR images from the transform domain to the spatial domain. It has been observed that using the Tchebichef transform domain for the task of SR takes the advantage of high and low-frequency representation of images that makes the task of super-resolution simplified. We, further, introduce transfer learning approach to enhance the quality of Covid based medical images. It is shown that our architecture enhances the quality of X-ray and CT images of COVID-19, providing a better image quality that helps in clinical diagnosis. Experimental results obtained using the proposed Tchebichef transform domain super-resolution (TTDSR) architecture provides competitive results when compared with most of the deep learning methods employed using a fewer number of trainable parameters.      
### 23.QoE Optimization for Live Video Streaming in UAV-to-UAV Communications via Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.10637.pdf)
>  A challenge for rescue teams when fighting against wildfire in remote areas is the lack of information, such as the size and images of fire areas. As such, live streaming from Unmanned Aerial Vehicles (UAVs), capturing videos of dynamic fire areas, is crucial for firefighter commanders in any location to monitor the fire situation with quick response. The 5G network is a promising wireless technology to support such scenarios. In this paper, we consider a UAV-to-UAV (U2U) communication scenario, where a UAV at a high altitude acts as a mobile base station (UAV-BS) to stream videos from other flying UAV-users (UAV-UEs) through the uplink. Due to the mobility of the UAV-BS and UAV-UEs, it is important to determine the optimal movements and transmission powers for UAV-BSs and UAV-UEs in real-time, so as to maximize the data rate of video transmission with smoothness and low latency, while mitigating the interference according to the dynamics in fire areas and wireless channel conditions. In this paper, we co-design the video resolution, the movement, and the power control of UAV-BS and UAV-UEs to maximize the Quality of Experience (QoE) of real-time video streaming. To learn the Deep Q-Network (DQN) and Actor-Critic (AC) to maximize the QoE of video transmission from all UAV-UEs to a single UAVBS. Simulation results show the effectiveness of our proposed algorithm in terms of the QoE, delay and video smoothness as compared to the Greedy algorithm.      
### 24.Classification of COVID-19 via Homology of CT-SCAN  [ :arrow_down: ](https://arxiv.org/pdf/2102.10593.pdf)
>  In this worldwide spread of SARS-CoV-2 (COVID-19) infection, it is of utmost importance to detect the disease at an early stage especially in the hot spots of this epidemic. There are more than 110 Million infected cases on the globe, sofar. Due to its promptness and effective results computed tomography (CT)-scan image is preferred to the reverse-transcription polymerase chain reaction (RT-PCR). Early detection and isolation of the patient is the only possible way of controlling the spread of the disease. Automated analysis of CT-Scans can provide enormous support in this process. In this article, We propose a novel approach to detect SARS-CoV-2 using CT-scan images. Our method is based on a very intuitive and natural idea of analyzing shapes, an attempt to mimic a professional medic. We mainly trace SARS-CoV-2 features by quantifying their topological properties. We primarily use a tool called persistent homology, from Topological Data Analysis (TDA), to compute these topological properties. We train and test our model on the "SARS-CoV-2 CT-scan dataset" \citep{soares2020sars}, an open-source dataset, containing 2,481 CT-scans of normal and COVID-19 patients. Our model yielded an overall benchmark F1 score of $99.42\% $, accuracy $99.416\%$, precision $99.41\%$, and recall $99.42\%$. The TDA techniques have great potential that can be utilized for efficient and prompt detection of COVID-19. The immense potential of TDA may be exploited in clinics for rapid and safe detection of COVID-19 globally, in particular in the low and middle-income countries where RT-PCR labs and/or kits are in a serious crisis.      
### 25.False Data Injection Attack Against Power System Small-Signal Stability  [ :arrow_down: ](https://arxiv.org/pdf/2102.10587.pdf)
>  Small-Signal Stability (SSS) is crucial for the control of power grids. However, False Data Injection (FDI) attacks against SSS can impact the grid stability, hence, the security of SSS needs to be studied. This paper proposes a formal method of synthesizing FDI attack vectors (i.e., a set of measurements to be altered) that can destabilize power systems. We formulate an FDI attack as an optimization problem using AC power flow, SSS model, and stability constraints. The attacker capability is modeled as the accessibility to a limited set of measurements. The solution of the proposed FDI attack model provides a destabilizing attack vector if exists. We implement the proposed mechanism and evaluate its performance by conducting several case studies using the WSCC 3-machine 9-bus system. The case study results showed that the possibility of random FDIs (i.e., with no knowledge of the power system) in launching a destabilizing attack is too low to be successful. However, an intelligent attacker can leverage the grid knowledge to make the system unstable, even with limited access to the measurements.      
### 26.Detection of Winding Axial Deformation in Power Transformers by UWB Radar Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2102.10561.pdf)
>  In this paper, a novel method for detecting transformer winding axial displacement has been presented. In this method, which is based on UWB radar imaging, a UWB pulse is transmitted to the transformer winding and the reflection from it is received and recorded. By changing the antenna position this process is repeated on several points along the axis of the winding. The measured signals are mapped to a 2-D image of the winding. By analyzing this image, the axial displacement of the winding can detected and the magnitude of it is determined with an acceptable precision. Simulation results are provided to verify the proposed method.      
### 27.Detection of Transformer Winding Axial Displacement by Kirchhoff and Delay and sum Radar Imaging Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2102.10519.pdf)
>  In this paper, a novel method for in detail detection of the winding axial displacement in power transformers based on UWB imaging is presented. In this method, the radar imaging process is implemented on the power transformer by using an ultra-wide band (UWB) transceiver. The result is a 2-D image of the transformer winding, which is analyzed to determine the occurrence as well as the magnitude of the winding axial displacement. The method is implemented on a transformer model. The experimental results illustrate the effectiveness of the proposed method.      
### 28.Practical graph signal sampling with log-linear size scaling  [ :arrow_down: ](https://arxiv.org/pdf/2102.10506.pdf)
>  Graph signal sampling is the problem of selecting a subset of representative graph vertices whose values can be used to interpolate missing values on the remaining graph vertices. Optimizing the choice of sampling set can help minimize the effect of noise in the input signal. While many existing sampling set selection methods are computationally intensive because they require an eigendecomposition, existing eigendecompostion-free methods are still much slower than random sampling algorithms for large graphs. In this paper, we propose a sampling algorithm that can achieve speeds similar to random sampling, while reaching accuracy similar to existing eigendecomposition-free methods for a broad range of graph types.      
### 29.WARP-Q: Quality Prediction For Generative Neural Speech Codecs  [ :arrow_down: ](https://arxiv.org/pdf/2102.10449.pdf)
>  Good speech quality has been achieved using waveform matching and parametric reconstruction coders. Recently developed very low bit rate generative codecs can reconstruct high quality wideband speech with bit streams less than 3 kb/s. These codecs use a DNN with parametric input to synthesise high quality speech outputs. Existing objective speech quality models (e.g., POLQA, ViSQOL) do not accurately predict the quality of coded speech from these generative models underestimating quality due to signal differences not highlighted in subjective listening tests. We present WARP-Q, a full-reference objective speech quality metric that uses dynamic time warping cost for MFCC speech representations. It is robust to small perceptual signal changes. Evaluation using waveform matching, parametric and generative neural vocoder based codecs as well as channel and environmental noise shows that WARP-Q has better correlation and codec quality ranking for novel codecs compared to traditional metrics in addition to versatility for general quality assessment scenarios.      
### 30.Dynamic Selective Positioning for High-Precision Accuracy in 5G NR V2X Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.10426.pdf)
>  The capability to achieve high-precision positioning accuracy has been considered as one of the most critical requirements for vehicle-to-everything (V2X) services in the fifth-generation (5G) cellular networks. The non-line-of-sight (NLOS) connectivity, coverage, reliability requirements, the minimum number of available anchors, and bandwidth limitations are among the main challenges to achieve high accuracy in V2X services. This work provides an overview of the potential solutions to provide the new radio (NR) V2X users (UEs) with high positioning accuracy in the future 3GPP releases. In particular, we propose a novel selective positioning solution to dynamically switch between different positioning technologies to improve the overall positioning accuracy in NR V2X services, taking into account the locations of V2X UEs and the accuracy of the collected measurements. Furthermore, we use high-fidelity system-level simulations to evaluate the performance gains of fusing the positioning measurements from different technologies in NR V2X services. Our numerical results show that the proposed hybridized schemes achieve a positioning error $\boldsymbol{\leq}$ 3 m with $\boldsymbol{\approx}$ 76\% availability compared to $\boldsymbol{\approx}$ 55\% availability when traditional positioning methods are used. The numerical results also reveal a potential gain of $\boldsymbol{\approx}$ 56\% after leveraging the road-side units (RSUs) to improve the tail of the UE's positioning error distribution, i.e., worst-case scenarios, in NR V2X services.      
### 31.Analyzing Novel Grant-Based and Grant-Free Access Schemes for Small Data Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2102.10405.pdf)
>  The Fifth Generation (5G) New Radio (NR) does not support data transmission during the random access (RA) procedures, which results in unnecessary control signalling overhead and power consumption, especially for small data transmission. Motivated by this, we propose two new RA schemes based on the existing grant-based (4-step) and grant-free (2-step B) RA schemes, which are NR Early Data Transmission (NR EDT) and 2-step A RA schemes, with the aim to enable data transmission during RA procedures in Radio Resource Control (RRC) Inactive state. To compare our proposed schemes with the benchmark schemes, we provide a spatio-temporal analytical framework to evaluate the RA schemes, which jointly models the preamble detection, Physical Uplink Shared Channel (PUSCH) decoding, and data transmission procedures. Based on this analytical model, we derive the analytical expressions for the overall packet transmission success probability of four RA schemes in each time slot. We also derive the throughput and the average energy consumption for a successful packet transmission of each scheme. Our results show that the 2-step A and 2-step B RA schemes provide the highest overall packet transmission success probability, the 2-step A RA scheme provides the lowest average energy consumption in low device intensity scenario, and 2-step B RA provides the lowest average energy consumption in high device intensity scenario.      
### 32.The Incubator Case Study for Digital Twin Engineering  [ :arrow_down: ](https://arxiv.org/pdf/2102.10390.pdf)
>  To demystify the Digital Twin concept, we built a simple yet representative thermal incubator system. The incubator is an insulated box fitted with a heatbed, and complete with a software system for communication, a controller, and simulation models. We developed two simulation models to predict the temperature inside the incubator, one with two free parameters and one with four free parameters. Our experiments showed that the latter model was better at predicting the thermal inertia of the heatbed itself, which makes it more appropriate for further development of the digital twin. The hardware and software used in this case study are available open source, providing an accessible platform for those who want to develop and verify their own techniques for digital twins.      
### 33.Regulating Mobility-on-Demand Services: Tri-level Model and Bayesian Optimization Solution Approach  [ :arrow_down: ](https://arxiv.org/pdf/2102.10382.pdf)
>  The goal of this paper is to develop a modeling framework that captures the inter-decision dynamics between mobility service providers (MSPs) and travelers that can be used to optimize and analyze policies/regulations related to MSPs. To meet this goal, the paper proposes a tri-level mathematical programming model with a public-sector decision maker (regulator) at the highest level, the MSP in the middle level, and travelers at the lowest level. The regulator aims to maximize social welfare via implementing regulations, policies, plans, transit service designs, etc. The MSP aims to maximize profit by adjusting its service designs. Travelers aim to maximize utility by changing their modes and routes. The travelers' decisions depend on the regulator and MSP's decisions while the MSP decisions themselves depend on the regulator's decisions. To solve the tri-level mathematical program, the study employs Bayesian optimization (BO) within a simulation-optimization solution approach. At the lowest level, the solution approach includes an agent-based transportation system simulation model to capture travelers' behavior subject to specific decisions made by the regulator and MSP. The agent-based transportation simulation model includes a mode choice model, a road network, a transit network, and an MSP providing automated mobility-on-demand (AMOD) service with shared rides. The modeling and solution approaches are applied to Munich, Germany in order to validate the model. The case study investigates the tolls and parking costs the city administration should set, as well as changes in the public transport budget and a limitation of the AMOD fleet size. Best policy settings are derived for two social welfare definitions, in both of which the AMOD fleet size is not regulated as the shared-ride AMOD service provides significant value to travelers in Munich.      
### 34.The Use of Voice Source Features for Sung Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2102.10376.pdf)
>  In this paper, we ask whether vocal source features (pitch, shimmer, jitter, etc) can improve the performance of automatic sung speech recognition, arguing that conclusions previously drawn from spoken speech studies may not be valid in the sung speech domain. We first use a parallel singing/speaking corpus (NUS-48E) to illustrate differences in sung vs spoken voicing characteristics including pitch range, syllables duration, vibrato, jitter and shimmer. We then use this analysis to inform speech recognition experiments on the sung speech DSing corpus, using a state of the art acoustic model and augmenting conventional features with various voice source parameters. Experiments are run with three standard (increasingly large) training sets, DSing1 (15.1 hours), DSing3 (44.7 hours) and DSing30 (149.1 hours). Pitch combined with degree of voicing produces a significant decrease in WER from 38.1% to 36.7% when training with DSing1 however smaller decreases in WER observed when training with the larger more varied DSing3 and DSing30 sets were not seen to be statistically significant. Voicing quality characteristics did not improve recognition performance although analysis suggests that they do contribute to an improved discrimination between voiced/unvoiced phoneme pairs.      
### 35.Denoising Higher-order Moments for Blind Digital Modulation Identification in Multiple-antenna Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.10371.pdf)
>  The paper proposes a new technique that substantially improves blind digital modulation identification (DMI) algorithms that are based on higher-order statistics (HOS). The proposed technique takes advantage of noise power estimation to make an offset on higher-order moments (HOM), thus getting an estimate of noise-free HOM. When tested for multiple-antenna systems, the proposed method outperforms other DMI algorithms, in terms of identification accuracy, that are based only on cumulants or do not consider HOM denoising, even for a receiver with impairments. The improvement is achieved with the same order of complexity of the common HOS-based DMI algorithms in the same context.      
### 36.Deep Learning-based Power Control for Cell-Free Massive MIMO Networks  [ :arrow_down: ](https://arxiv.org/pdf/2102.10366.pdf)
>  A deep learning (DL)-based power control algorithm that solves the max-min user fairness problem in a cell-free massive multiple-input multiple-output (MIMO) system is proposed. Max-min rate optimization problem in a cell-free massive MIMO uplink setup is formulated, where user power allocations are optimized in order to maximize the minimum user rate. Instead of modeling the problem using mathematical optimization theory, and solving it with iterative algorithms, our proposed solution approach is using DL. Specifically, we model a deep neural network (DNN) and train it in an unsupervised manner to learn the optimum user power allocations which maximize the minimum user rate. This novel unsupervised learning-based approach does not require optimal power allocations to be known during model training as in previously used supervised learning techniques, hence it has a simpler and flexible model training stage. Numerical results show that the proposed DNN achieves a performance-complexity trade-off with around 400 times faster implementation and comparable performance to the optimization-based algorithm. An online learning stage is also introduced, which results in near-optimal performance with 4-6 times faster processing.      
### 37.Regression Filtration with Resetting to Provide Exponential Convergence of MRAC for Plants with Jump Change of Unknown Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2102.10359.pdf)
>  This paper proposes a new method to provide the exponential convergence of both the parameter and tracking errors of the composite adaptive control system without the requirement of the regressor persistent excitation (PE). Instead, the composite adaptation law obtained in this paper requires the regressor to be finitely exciting (FE) to guarantee the above-mentioned properties. Unlike known solutions, not only does it relax the PE requirement, but also it functions effectively under the condition of a jump change of the plant uncertainty parameters. To derive such an adaptation law, an integral filter of regressor with damping and resetting is proposed. It provides the required properties of the control system, and its output signal is bounded even when its input is subjected to noise and disturbances. A rigorous analytical proof of all mentioned properties of the developed adaptation law is presented. Such law is compared with the known composite ones relaxing the PE requirement. The wing-rock problem is used for the modeling of the developed composite MRAC system. The obtained results fully support the theoretical analysis and demonstrate the advantages of the proposed method.      
### 38.FlexClock: Generic Clock Reconfiguration for Low-end IoT Devices  [ :arrow_down: ](https://arxiv.org/pdf/2102.10353.pdf)
>  Clock configuration within constrained general-purpose microcontrollers takes a key role in tuning performance, power consumption, and timing accuracy of applications in the Internet of Things (IoT). Subsystems governing the underlying clock tree must nonetheless cope with a huge parameter space, complex dependencies, and dynamic constraints. Manufacturers expose the underlying functions in very diverse ways, which leads to specialized implementations of low portability. In this paper, we propose FlexClock, an approach for generic online clock reconfiguration on constrained IoT devices. We argue that (costly) generic clock configuration of general purpose computers and powerful mobile devices need to slim down to the lower end of the device spectrum. In search of a generalized solution, we identify recurring patterns and building blocks, which we use to decompose clock trees into independent, reusable components. With this segmentation we derive an abstract representation of vendor-specific clock trees, which then can be dynamically reconfigured at runtime. We evaluate our implementation on common hardware. Our measurements demonstrate how FlexClock significantly improves peak power consumption and energy efficiency by enabling dynamic voltage and frequency scaling (DVFS) in a platform-agnostic way.      
### 39.Model architectures to extrapolate emotional expressions in DNN-based text-to-speech  [ :arrow_down: ](https://arxiv.org/pdf/2102.10345.pdf)
>  This paper proposes architectures that facilitate the extrapolation of emotional expressions in deep neural network (DNN)-based text-to-speech (TTS). In this study, the meaning of "extrapolate emotional expressions" is to borrow emotional expressions from others, and the collection of emotional speech uttered by target speakers is unnecessary. Although a DNN has potential power to construct DNN-based TTS with emotional expressions and some DNN-based TTS systems have demonstrated satisfactory performances in the expression of the diversity of human speech, it is necessary and troublesome to collect emotional speech uttered by target speakers. To solve this issue, we propose architectures to separately train the speaker feature and the emotional feature and to synthesize speech with any combined quality of speakers and emotions. The architectures are parallel model (PM), serial model (SM), auxiliary input model (AIM), and hybrid models (PM&amp;AIM and SM&amp;AIM). These models are trained through emotional speech uttered by few speakers and neutral speech uttered by many speakers. Objective evaluations demonstrate that the performances in the open-emotion test provide insufficient information. They make a comparison with those in the closed-emotion test, but each speaker has their own manner of expressing emotion. However, subjective evaluation results indicate that the proposed models could convey emotional information to some extent. Notably, the PM can correctly convey sad and joyful emotions at a rate of &gt;60%.      
### 40.Versatile and Robust Transient Stability Assessment via Instance Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.10296.pdf)
>  To support N-1 pre-fault transient stability assessment, this paper introduces a new data collection method in a data-driven algorithm incorporating the knowledge of power system dynamics. The domain knowledge on how the disturbance effect will propagate from the fault location to the rest of the network is leveraged to recognise the dominant conditions that determine the stability of a system. Accordingly, we introduce a new concept called Fault-Affected Area, which provides crucial information regarding the unstable region of operation. This information is embedded in an augmented dataset to train an ensemble model using an instance transfer learning framework. The test results on the IEEE 39-bus system verify that this model can accurately predict the stability of previously unseen operational scenarios while reducing the risk of false prediction of unstable instances compared to standard approaches.      
### 41.Recurrent Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2102.10289.pdf)
>  This paper proposes an off-line algorithm, called Recurrent Model Predictive Control (RMPC), to solve general nonlinear finite-horizon optimal control problems. Unlike traditional Model Predictive Control (MPC) algorithms, it can make full use of the current computing resources and adaptively select the longest model prediction horizon. Our algorithm employs a recurrent function to approximate the optimal policy, which maps the system states and reference values directly to the control inputs. The number of prediction steps is equal to the number of recurrent cycles of the learned policy function. With an arbitrary initial policy function, the proposed RMPC algorithm can converge to the optimal policy by directly minimizing the designed loss function. We further prove the convergence and optimality of the RMPC algorithm thorough Bellman optimality principle, and demonstrate its generality and efficiency using two numerical examples.      
### 42.Wireless sensor network for in situ soil moisture monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2102.10260.pdf)
>  We discuss the history and lessons learned from a series of deployments of environmental sensors measuring soil parameters and CO2 fluxes over the last fifteen years, in an outdoor environment. We present the hardware and software architecture of our current Gen-3 system, and then discuss how we are simplifying the user facing part of the software, to make it easier and friendlier for the environmental scientist to be in full control of the system. Finally, we describe the current effort to build a large-scale Gen-4 sensing platform consisting of hundreds of nodes to track the environmental parameters for urban green spaces in Baltimore, Maryland.      
### 43.Safety Embedded Control of Nonlinear Systems via Barrier States  [ :arrow_down: ](https://arxiv.org/pdf/2102.10253.pdf)
>  Many of today's rapidly growing engineering technologies are accompanied with highly challenging problems, and safety is, undeniably, a crucial one of them. In many safety critical control systems, possibly opposing safety restrictions and control performance objectives arise. To confront such a conflict, this paper proposes a safety integrating methodology that embeds safety into stability of control systems. The development enforces safety by means of barrier functions used in optimization which are used to construct \textit{barrier states} (BaS's) that are \textit{embedded} in the control system's model. As a result, as long as the equilibrium point of interest of the closed loop system is asymptotically stable, the generated trajectories are guaranteed to be safe. Consequently, the conflict between control objectives and safety constraints is substantially avoided. To show the efficacy of the proposed technique, we employ the simple pole placement method on a linear control system to generate a safely stabilizing controller. Optimal control is subsequently employed to fulfill safety, stability and performance objectives by solving the associated Hamilton-Jacobi-Bellman (HJB) which minimizes a cost functional that can involve the barrier states. Following this further, we exploit optimal control on a second dimensional pendulum on a cart model that is desired to avoid low velocities regions where the system may exhibit some controllability loss and on two simple mobile robots that are sent to opposite targets with an obstacle on the way which may potentially result in a collision.      
### 44.Sparse Array Transceiver Design for Enhanced Adaptive Beamforming in MIMO Radar  [ :arrow_down: ](https://arxiv.org/pdf/2102.10238.pdf)
>  Sparse array design aided by emerging fast sensor switching technologies can lower the overall system overhead by reducing the number of expensive transceiver chains. In this paper, we examine the active sparse array design enabling the maximum signal to interference plus noise ratio (MaxSINR) beamforming at the MIMO radar receiver. The proposed approach entails an entwined design, i.e., jointly selecting the optimum transmit and receive sensor locations for accomplishing MaxSINR receive beamforming. Specifically, we consider a co-located multiple-input multiple-output (MIMO) radar platform with orthogonal transmitted waveforms, and examine antenna selections at the transmit and receive arrays. The optimum active sparse array transceiver design problem is formulated as successive convex approximation (SCA) alongside the two-dimensional group sparsity promoting regularization. Several examples are provided to demonstrate the effectiveness of the proposed approach in utilizing the given transmit/receive array aperture and degrees of freedom for achieving MaxSINR beamforming.      
### 45.CKNet: A Convolutional Neural Network Based on Koopman Operator for Modeling Latent Dynamics from Pixels  [ :arrow_down: ](https://arxiv.org/pdf/2102.10205.pdf)
>  For systems with only known pixels, it is difficult to identify its dynamics, especially with a linear operator. In this work, we present a convolutional neural network (CNN) based on the Koopman operator (CKNet) to identify the latent dynamics from raw pixels. CKNet learned an encoder and decoder to play the role of the Koopman eigenfunctions and modes, respectively. The Koopman eigenvalues can be approximated by the eigenvalues of the learned system matrix. We present the deterministic and variational approaches to realize the encoder separately. Because CKNet is trained under the constraints of the Koopman theory, the identified dynamics is linear, controllable and physically-interpretable. Besides, the system matrix and control matrix are trained as trainable tensors. To improve the performance, we propose the auxiliary weight term for multi-step linearity and prediction losses. Experiments select two classic forced dynamical systems with continuous action space, and the results show that identified dynamics with 32-dim can predict validly 120 steps and generate clear images.      
### 46.DeepScaleTool : A Tool for the Accurate Estimation of Technology Scaling in the Deep-Submicron Era  [ :arrow_down: ](https://arxiv.org/pdf/2102.10195.pdf)
>  The estimation of classical CMOS "constant-field" or "Dennard" scaling methods that define scaling factors for various dimensional and electrical parameters have become less accurate in the deep-submicron regime, which drives the need for better estimation approaches especially in the educational and research domains. We present DeepScaleTool, a tool for the accurate estimation of deep-submicron technology scaling by modeling and curve fitting published data by a leading commercial fabrication company for silicon fabrication technology generations from 130~nm to 7~nm for the key parameters of area, delay, and energy. Compared to 10~nm--7~nm scaling data published by a leading foundry, the DeepScaleTool achieves an error of 1.7% in area, 2.5% in delay, and 5% in power. This compares favorably with another leading academic estimation method that achieves an error of 24% in area, 9.1% in delay, and 24.9% in power.      
### 47.Spatial-temporal switching estimators for imaging locally concentrated dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2102.10167.pdf)
>  The evolution of images with physics-based dynamics is often spatially localized and nonlinear. A switching linear dynamic system (SLDS) is a natural model under which to pose such problems when the system's evolution randomly switches over the observation interval. Because of the high parameter space dimensionality, efficient and accurate recovery of the underlying state is challenging. The work presented in this paper focuses on the common cases where the dynamic evolution may be adequately modeled as a collection of decoupled, locally concentrated dynamic operators. Patch-based hybrid estimators are proposed for real-time reconstruction of images from noisy measurements given perfect or partial information about the underlying system dynamics. Numerical results demonstrate the effectiveness of the proposed approach for denoising in a realistic data-driven simulation of remotely sensed cloud dynamics.      
### 48.Unsupervised Segmentation Algorithms for Infrared Cloud Images  [ :arrow_down: ](https://arxiv.org/pdf/2102.10151.pdf)
>  The increasing number of Photovoltaic (PV) systems connected to the power grids makes them vulnerable to the projection of shadows from moving clouds. Solar Global Irradiance (GSI) forecasting allows smart grids to optimize energy dispatch preventing cloud coverage shortages. This investigation compares the performances of unsupervised learning algorithms (not requiring labelled images for training) for real-time segmentation of clouds in a ground-base infrared sky-imaging system, which is commonly used to extract cloud features using only the pixels where clouds are detected.      
### 49.Coherent Integration for Targets with Constant Cartesian Velocities Based on Accurate Range Model  [ :arrow_down: ](https://arxiv.org/pdf/2102.10129.pdf)
>  Long-time coherent integration (LTCI) is one of the most important techniques to improve radar detection performance of weak targets. However, for the targets moving with constant Cartesian velocities (CCV), the existing LTCI methods based on polynomial motion models suffer from limited integration time and coverage of target speed due to model mismatch. Here, a novel generalized Radon Fourier transform method for CCV targets is presented, based on the accurate range evolving model, which is a square root of a polynomial with terms up to the second order with target speed as the factor. The accurate model instead of approximate polynomial models used in the proposed method enables effective energy integration on characteristic invariant with feasible computational complexity. The target samplings are collected and the phase fluctuation among pulses is compensated according to the accurate range model. The high order range migration and complex Doppler frequency migration caused by the highly nonlinear signal are eliminated simultaneously. Integration results demonstrate that the proposed method can not only achieve effective coherent integration of CCV targets regardless of target speed and coherent processing interval, but also provide additional observation and resolution in speed domain.      
### 50.Softmax Policy Gradient Methods Can Take Exponential Time to Converge  [ :arrow_down: ](https://arxiv.org/pdf/2102.11270.pdf)
>  The softmax policy gradient (PG) method, which performs gradient ascent under softmax policy parameterization, is arguably one of the de facto implementations of policy optimization in modern reinforcement learning. For $\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs), remarkable progress has recently been achieved towards establishing global convergence of softmax PG methods in finding a near-optimal policy. However, prior results fall short of delineating clear dependencies of convergence rates on salient parameters such as the cardinality of the state space $\mathcal{S}$ and the effective horizon $\frac{1}{1-\gamma}$, both of which could be excessively large. In this paper, we deliver a pessimistic message regarding the iteration complexity of softmax PG methods, despite assuming access to exact gradient computation. Specifically, we demonstrate that softmax PG methods can take exponential time -- in terms of $|\mathcal{S}|$ and $\frac{1}{1-\gamma}$ -- to converge, even in the presence of a benign policy initialization and an initial state distribution amenable to exploration. This is accomplished by characterizing the algorithmic dynamics over a carefully-constructed MDP containing only three actions. Our exponential lower bound hints at the necessity of carefully adjusting update rules or enforcing proper regularization in accelerating PG methods.      
### 51.Experimental Study on Probabilistic ToA and AoA Joint Localization in Real Indoor Environments  [ :arrow_down: ](https://arxiv.org/pdf/2102.11233.pdf)
>  In this paper, we study probabilistic time-of-arrival (ToA) and angle-of-arrival (AoA) joint localization in real indoor environments. To mitigate the effects of multipath propagation, the joint localization algorithm incorporates into the likelihood function Gaussian mixture models (GMM) and the Von Mises-Fisher distribution to model time bias errors and angular uncertainty, respectively. We evaluate the algorithm performance using a proprietary prototype deployed in an indoor factory environment with infrastructure receivers in each of the four corners at the ceiling of a 10 meter by 20 meter section. The field test results show that our joint probabilistic localization algorithm significantly outperforms baselines using only ToA or AoA measurements and achieves 2-D sub-meter accuracy at the 90%-ile. We also numerically demonstrate that the joint localization algorithm is more robust to synchronization errors than the baseline using ToA measurements only.      
### 52.Subspace-Based Feature Fusion From Hyperspectral And Multispectral Image For Land Cover Classification  [ :arrow_down: ](https://arxiv.org/pdf/2102.11228.pdf)
>  In remote sensing, hyperspectral (HS) and multispectral (MS) image fusion have emerged as a synthesis tool to improve the data set resolution. However, conventional image fusion methods typically degrade the performance of the land cover classification. In this paper, a feature fusion method from HS and MS images for pixel-based classification is proposed. More precisely, the proposed method first extracts spatial features from the MS image using morphological profiles. Then, the feature fusion model assumes that both the extracted morphological profiles and the HS image can be described as a feature matrix lying in different subspaces. An algorithm based on combining alternating optimization (AO) and the alternating direction method of multipliers (ADMM) is developed to solve efficiently the feature fusion problem. Finally, extensive simulations were run to evaluate the performance of the proposed feature fusion approach for two data sets. In general, the proposed approach exhibits a competitive performance compared to other feature extraction methods.      
### 53.Generating Human Readable Transcript for Automatic Speech Recognition with Pre-trained Language Model  [ :arrow_down: ](https://arxiv.org/pdf/2102.11114.pdf)
>  Modern Automatic Speech Recognition (ASR) systems can achieve high performance in terms of recognition accuracy. However, a perfectly accurate transcript still can be challenging to read due to disfluency, filter words, and other errata common in spoken communication. Many downstream tasks and human readers rely on the output of the ASR system; therefore, errors introduced by the speaker and ASR system alike will be propagated to the next task in the pipeline. In this work, we propose an ASR post-processing model that aims to transform the incorrect and noisy ASR output into a readable text for humans and downstream tasks. We leverage the Metadata Extraction (MDE) corpus to construct a task-specific dataset for our study. Since the dataset is small, we propose a novel data augmentation method and use a two-stage training strategy to fine-tune the RoBERTa pre-trained model. On the constructed test set, our model outperforms a production two-step pipeline-based post-processing method by a large margin of 13.26 on readability-aware WER (RA-WER) and 17.53 on BLEU metrics. Human evaluation also demonstrates that our method can generate more human-readable transcripts than the baseline method.      
### 54.Anyone GAN Sing  [ :arrow_down: ](https://arxiv.org/pdf/2102.11058.pdf)
>  The problem of audio synthesis has been increasingly solved using deep neural networks. With the introduction of Generative Adversarial Networks (GAN), another efficient and adjective path has opened up to solve this problem. In this paper, we present a method to synthesize the singing voice of a person using a Convolutional Long Short-term Memory (ConvLSTM) based GAN optimized using the Wasserstein loss function. Our work is inspired by WGANSing by Chandna et al. Our model inputs consecutive frame-wise linguistic and frequency features, along with singer identity and outputs vocoder features. We train the model on a dataset of 48 English songs sung and spoken by 12 non-professional singers. For inference, sequential blocks are concatenated using an overlap-add procedure. We test the model using the Mel-Cepstral Distance metric and a subjective listening test with 18 participants.      
### 55.Coherence of Working Memory Study Between Deep Neural Network and Neurophysiology  [ :arrow_down: ](https://arxiv.org/pdf/2102.10994.pdf)
>  The auto feature extraction capability of deep neural networks (DNN) endows them the potentiality for analysing complicated electroencephalogram (EEG) data captured from brain functionality research. This work investigates the potential coherent correspondence between the region-of-interest (ROI) for DNN to explore, and ROI for conventional neurophysiological oriented methods to work with, exemplified in the case of working memory study. The attention mechanism induced by global average pooling (GAP) is applied to a public EEG dataset of working memory, to unveil these coherent ROIs via a classification problem. The result shows the alignment of ROIs from different research disciplines. This work asserts the confidence and promise of utilizing DNN for EEG data analysis, albeit in lack of the interpretation to network operations.      
### 56.Joint Intent Detection And Slot Filling Based on Continual Learning Model  [ :arrow_down: ](https://arxiv.org/pdf/2102.10905.pdf)
>  Slot filling and intent detection have become a significant theme in the field of natural language understanding. Even though slot filling is intensively associated with intent detection, the characteristics of the information required for both tasks are different while most of those approaches may not fully aware of this problem. In addition, balancing the accuracy of two tasks effectively is an inevitable problem for the joint learning model. In this paper, a Continual Learning Interrelated Model (CLIM) is proposed to consider semantic information with different characteristics and balance the accuracy between intent detection and slot filling effectively. The experimental results show that CLIM achieves state-of-the-art performace on slot filling and intent detection on ATIS and Snips.      
### 57.Average Elliptic Billiard Invariants with Spatial Integrals  [ :arrow_down: ](https://arxiv.org/pdf/2102.10899.pdf)
>  We compare invariants of N-periodic trajectories in the elliptic billiard, classic and new, to their aperiodic counterparts via a spatial integrals evaluated over the boundary of the elliptic billiard. The integrand is weighed by a universal measure equal to the density of rays hitting a given boundary point. We find that aperiodic averages are smooth and monotonic on caustic eccentricity, and perfectly match N-periodic average invariants at the discrete caustic parameters which admit a given N-periodic family.      
### 58.Anchor-Assisted Channel Estimation for Intelligent Reflecting Surface Aided Multiuser Communication  [ :arrow_down: ](https://arxiv.org/pdf/2102.10886.pdf)
>  Channel estimation is a practical challenge for intelligent reflecting surface (IRS) aided wireless communication. As the number of IRS reflecting elements or IRS-aided users increases, the channel training overhead becomes excessively high, which results in long delay and low throughput in data transmission. To tackle this challenge, we propose in this paper a new anchor-assisted channel estimation approach, where two anchor nodes, namely A1 and A2, are deployed near the IRS for facilitating its aided base station (BS) in acquiring the cascaded BS-IRS-user channels required for data transmission. Specifically, in the first scheme, the partial channel state information (CSI) on the element-wise channel gain square of the common BS-IRS link for all users is first obtained at the BS via the anchor-assisted training and feedback. Then, by leveraging such partial CSI, the cascaded BS-IRS-user channels are efficiently resolved at the BS with additional training by the users. While in the second scheme, the BS-IRS-A1 and A1-IRS-A2 channels are first estimated via the training by A1. Then, with additional training by A2, all users estimate their individual cascaded A2-IRS-user channels simultaneously. Based on the CSI fed back from A2 and all users, the BS resolves the cascaded BS-IRS-user channels efficiently. In both schemes, the quasi-static channels among the fixed BS, IRS, and two anchors are estimated off-line only, which greatly reduces the real-time training overhead. Simulation results demonstrate that our proposed anchor-assisted channel estimation schemes achieve superior performance as compared to existing IRS channel estimation schemes, under various practical setups. In addition, the first proposed scheme outperforms the second one when the number of antennas at the BS is sufficiently large, and vice versa.      
### 59.Expanding boundaries of Gap Safe screening  [ :arrow_down: ](https://arxiv.org/pdf/2102.10846.pdf)
>  Sparse optimization problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution, which can then be eliminated to reduce the problem's size and accelerate convergence. In this work, we extend the existing Gap Safe screening framework by relaxing the global strong-concavity assumption on the dual cost function. Instead, we exploit local regularity properties, that is, strong concavity on well-chosen subsets of the domain. The non-negativity constraint is also integrated to the existing framework. Besides making safe screening possible to a broader class of functions that includes beta-divergences (e.g., the Kullback-Leibler divergence), the proposed approach also improves upon the existing Gap Safe screening rules on previously applicable cases (e.g., logistic regression). The proposed general framework is exemplified by some notable particular cases: logistic function, beta = 1.5 and Kullback-Leibler divergences. Finally, we showcase the effectiveness of the proposed screening rules with different solvers (coordinate descent, multiplicative-update and proximal gradient algorithms) and different data sets (binary classification, hyperspectral and count data).      
### 60.Characterization of Minimum Time-Fuel Optimal Control for LTI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.10831.pdf)
>  A problem of computing time-fuel optimal control for state transfer of a single input linear time invariant (LTI) system to the origin is considered. The input is assumed to be bounded. Since, the optimal control is bang-off-bang in nature, it is characterized by sequences of +1 , 0 and -1 and the corresponding switching time instants. All (candidate) sequences satisfying the Pontryagin's maximum principle (PMP) necessary conditions are characterized. The number of candidate sequences is obtained as a function of the order of system and a method to list all candidate sequences is derived. Corresponding to each candidate sequence, switching time instants are computed by solving a static optimization problem. Since the candidate control input is a piece-wise constant function, the time-fuel cost functional is converted to a linear function in switching time instants. By using a simple substitution of variables, reachability constraints are converted to polynomial equations and inequalities. Such a static optimization problem can be solved separately for each candidate sequence. Finally, the optimal control input is obtained from candidate sequences which gives the least cost. For each sequence, optimization problem can be solved by converting it to a generalized moment problem (GMP) and then solving a hierachical sequence of semidefinite relaxations to approximate the minima and minimizer [1]. Lastly, a numerical example is presented for demonstration of method.      
### 61.Energy-Efficient Precoding for Multi-User Visible Light Communication with Confidential Messages  [ :arrow_down: ](https://arxiv.org/pdf/2102.10822.pdf)
>  In this paper, an energy-efficient precoding scheme is designed for multi-user visible light communication (VLC) systems in the context of physical layer security, where users' messages are kept mutually confidential. The design problem is shown to be non-convex fractional programming, therefore Dinkelbach algorithm and convex-concave procedure (CCCP) based on the first-order Taylor approximation are utilized to tackle the problem. Numerical results are performed to show the convergence behaviors and the performance of the proposed solution for different parameter settings.      
### 62.Residual-Aided End-to-End Learning of Communication System without Known Channel  [ :arrow_down: ](https://arxiv.org/pdf/2102.10786.pdf)
>  Leveraging powerful deep learning techniques, the end-to-end (E2E) learning of communication system is able to outperform the classical communication system. Unfortunately, this communication system cannot be trained by deep learning without known channel. To deal with this problem, a generative adversarial network (GAN) based training scheme has been recently proposed to imitate the real channel. However, the gradient vanishing and overfitting problems of GAN will result in the serious performance degradation of E2E learning of communication system. To mitigate these two problems, we propose a residual aided GAN (RA-GAN) based training scheme in this paper. Particularly, inspired by the idea of residual learning, we propose a residual generator to mitigate the gradient vanishing problem by realizing a more robust gradient backpropagation. Moreover, to cope with the overfitting problem, we reconstruct the loss function for training by adding a regularizer, which limits the representation ability of RA-GAN. Simulation results show that the trained residual generator has better generation performance than the conventional generator, and the proposed RA-GAN based training scheme can achieve the near-optimal block error rate (BLER) performance with a negligible computational complexity increase in both the theoretical channel model and the ray-tracing based channel dataset.      
### 63.CSIT-Free Federated Edge Learning via Reconfigurable Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2102.10749.pdf)
>  We study over-the-air model aggregation in federated edge learning (FEEL) systems, where channel state information at the transmitters (CSIT) is assumed to be unavailable. We leverage the reconfigurable intelligent surface (RIS) technology to align the cascaded channel coefficients for CSIT-free model aggregation. To this end, we jointly optimize the RIS and the receiver by minimizing the aggregation error under the channel alignment constraint. We then develop a difference-of-convex algorithm for the resulting non-convex optimization. Numerical experiments on image classification show that the proposed method is able to achieve a similar learning accuracy as the state-of-the-art CSIT-based solution, demonstrating the efficiency of our approach in combating the lack of CSIT.      
### 64.Joint Estimation of Multipath Angles and Delays for Millimeter-Wave Cylindrical Arrays with Hybrid Front-ends  [ :arrow_down: ](https://arxiv.org/pdf/2102.10746.pdf)
>  Accurate channel parameter estimation is challenging for wideband millimeter-wave (mmWave) large-scale hybrid arrays, due to beam squint and much fewer radio frequency (RF) chains than antennas. This paper presents a novel joint delay and angle estimation approach for wideband mmWave fully-connected hybrid uniform cylindrical arrays. We first design a new hybrid beamformer to reduce the dimension of received signals on the horizontal plane by exploiting the convergence of the Bessel function, and to reduce the active beams in the vertical direction through preselection. The important recurrence relationship of the received signals needed for subspace-based angle and delay estimation is preserved, even with substantially fewer RF chains than antennas. Then, linear interpolation is generalized to reconstruct the received signals of the hybrid beamformer, so that the signals can be coherently combined across the whole band to suppress the beam squint. As a result, efficient subspace-based algorithm algorithms can be developed to estimate the angles and delays of multipath components. The estimated delays and angles are further matched and correctly associated with different paths in the presence of non-negligible noises, by putting forth perturbation operations. Simulations show that the proposed approach can approach the Cramér-Rao lower bound (CRLB) of the estimation with a significantly lower computational complexity than existing techniques.      
### 65.Design, Integration and Sea Trials of 3D Printed Unmanned Aerial Vehicle and Unmanned Surface Vehicle for Cooperative Missions  [ :arrow_down: ](https://arxiv.org/pdf/2102.10709.pdf)
>  In recent years, Unmanned Surface Vehicles (USV) have been extensively deployed for maritime applications. However, USV has a limited detection range with sensor installed at the same elevation with the targets. In this research, we propose a cooperative Unmanned Aerial Vehicle - Unmanned Surface Vehicle (UAV-USV) platform to improve the detection range of USV. A floatable and waterproof UAV is designed and 3D printed, which allows it to land on the sea. A catamaran USV and landing platform are also developed. To land UAV on the USV precisely in various lighting conditions, IR beacon detector and IR beacon are implemented on the UAV and USV, respectively. Finally, a two-phase UAV precise landing method, USV control algorithm and USV path following algorithm are proposed and tested.      
### 66.Representing and computing the B-derivative of an $EC^r$ vector field's $PC^r$ flow  [ :arrow_down: ](https://arxiv.org/pdf/2102.10702.pdf)
>  This paper concerns the first-order approximation of the piecewise-differentiable flow generated by a class of nonsmooth vector fields. Specifically, we represent and compute the Bouligand (or B-)derivative of the piecewise-$C^r$ flow generated by an event-selected $C^r$ vector field. Our results are remarkably efficient: although there are factorially many "pieces" of the desired derivative, we provide an algorithm that evaluates its action on a given tangent vector using polynomial time and space, and verify the algorithm's correctness by deriving a representation for the B-derivative that requires "only" exponential time and space to construct. We apply our methods in two classes of illustrative examples: piecewise-constant vector fields and mechanical systems subject to unilateral constraints.      
### 67.Transferable Visual Words: Exploiting the Semantics of Anatomical Patterns for Self-supervised Learning  [ :arrow_down: ](https://arxiv.org/pdf/2102.10680.pdf)
>  This paper introduces a new concept called "transferable visual words" (TransVW), aiming to achieve annotation efficiency for deep learning in medical image analysis. Medical imaging--focusing on particular parts of the body for defined clinical purposes--generates images of great similarity in anatomy across patients and yields sophisticated anatomical patterns across images, which are associated with rich semantics about human anatomy and which are natural visual words. We show that these visual words can be automatically harvested according to anatomical consistency via self-discovery, and that the self-discovered visual words can serve as strong yet free supervision signals for deep models to learn semantics-enriched generic image representation via self-supervision (self-classification and self-restoration). Our extensive experiments demonstrate the annotation efficiency of TransVW by offering higher performance and faster convergence with reduced annotation cost in several applications. Our TransVW has several important advantages, including (1) TransVW is a fully autodidactic scheme, which exploits the semantics of visual words for self-supervised learning, requiring no expert annotation; (2) visual word learning is an add-on strategy, which complements existing self-supervised methods, boosting their performance; and (3) the learned image representation is semantics-enriched models, which have proven to be more robust and generalizable, saving annotation efforts for a variety of applications through transfer learning. Our code, pre-trained models, and curated visual words are available at <a class="link-external link-https" href="https://github.com/JLiangLab/TransVW" rel="external noopener nofollow">this https URL</a>.      
### 68.MedAug: Contrastive learning leveraging patient metadata improves representations for chest X-ray interpretation  [ :arrow_down: ](https://arxiv.org/pdf/2102.10663.pdf)
>  Self-supervised contrastive learning between pairs of multiple views of the same image has been shown to successfully leverage unlabeled data to produce meaningful visual representations for both natural and medical images. However, there has been limited work on determining how to select pairs for medical images, where availability of patient metadata can be leveraged to improve representations. In this work, we develop a method to select positive pairs coming from views of possibly different images through the use of patient metadata. We compare strategies for selecting positive pairs for chest X-ray interpretation including requiring them to be from the same patient, imaging study or laterality. We evaluate downstream task performance by fine-tuning the linear layer on 1% of the labeled dataset for pleural effusion classification. Our best performing positive pair selection strategy, which involves using images from the same patient from the same study across all lateralities, achieves a performance increase of 3.4% and 14.4% in mean AUC from both a previous contrastive method and ImageNet pretrained baseline respectively. Our controlled experiments show that the keys to improving downstream performance on disease classification are (1) using patient metadata to appropriately create positive pairs from different images with the same underlying pathologies, and (2) maximizing the number of different images used in query pairing. In addition, we explore leveraging patient metadata to select hard negative pairs for contrastive learning, but do not find improvement over baselines that do not use metadata. Our method is broadly applicable to medical image interpretation and allows flexibility for incorporating medical insights in choosing pairs for contrastive learning.      
### 69.Safe Reinforcement Learning Using Robust Action Governor  [ :arrow_down: ](https://arxiv.org/pdf/2102.10643.pdf)
>  Reinforcement Learning (RL) is essentially a trial-and-error learning procedure which may cause unsafe behavior during the exploration-and-exploitation process. This hinders the applications of RL to real-world control problems, especially to those for safety-critical systems. In this paper, we introduce a framework for safe RL that is based on integration of an RL algorithm with an add-on safety supervision module, called the Robust Action Governor (RAG), which exploits set-theoretic techniques and online optimization to manage safety-related requirements during learning. We illustrate this proposed safe RL framework through an application to automotive adaptive cruise control.      
### 70.Privacy-Preserving Wireless Federated Learning Exploiting Inherent Hardware Impairments  [ :arrow_down: ](https://arxiv.org/pdf/2102.10639.pdf)
>  We consider a wireless federated learning system where multiple data holder edge devices collaborate to train a global model via sharing their parameter updates with an honest-but-curious parameter server. We demonstrate that the inherent hardware-induced distortion perturbing the model updates of the edge devices can be exploited as a privacy-preserving mechanism. In particular, we model the distortion as power-dependent additive Gaussian noise and present a power allocation strategy that provides privacy guarantees within the framework of differential privacy. We conduct numerical experiments to evaluate the performance of the proposed power allocation scheme under different levels of hardware impairments.      
### 71.Model Checking for Decision Making System of Long Endurance Unmanned Surface Vehicle  [ :arrow_down: ](https://arxiv.org/pdf/2102.10604.pdf)
>  This work aims to develop a model checking method to verify the decision making system of Unmanned Surface Vehicle (USV) in a long range surveillance mission. The scenario in this work was captured from a long endurance USV surveillance mission using C-Enduro, an USV manufactured by ASV Ltd. The C-Enduro USV may encounter multiple non-deterministic and concurrent problems including lost communication signals, collision risk and malfunction. The vehicle is designed to utilise multiple energy sources from solar panel, wind turbine and diesel generator. The energy state can be affected by the solar irradiance condition, wind condition, states of the diesel generator, sea current condition and states of the USV. In this research, the states and the interactive relations between environmental uncertainties, sensors, USV energy system, USV and Ground Control Station (GCS) decision making systems are abstracted and modelled successfully using Kripke models. The desirable properties to be verified are expressed using temporal logic statement and finally the safety properties and the long endurance properties are verified using the model checker MCMAS, a model checker for multi-agent systems. The verification results are analyzed and show the feasibility of applying model checking method to retrospect the desirable property of the USV decision making system. This method could assist researcher to identify potential design error of decision making system in advance.      
### 72.Mapping Surgeon's Hand/Finger Motion During Conventional Microsurgery to Enhance Intuitive Surgical Robot Teleoperation  [ :arrow_down: ](https://arxiv.org/pdf/2102.10585.pdf)
>  Purpose: Recent developments in robotics and artificial intelligence (AI) have led to significant advances in healthcare technologies enhancing robot-assisted minimally invasive surgery (RAMIS) in some surgical specialties. However, current human-robot interfaces lack intuitive teleoperation and cannot mimic surgeon's hand/finger sensing and fine motion. These limitations make tele-operated robotic surgery not suitable for micro-surgery and difficult to learn for established surgeons. We report a pilot study showing an intuitive way of recording and mapping surgeon's gross hand motion and the fine synergic motion during cardiac micro-surgery as a way to enhance future intuitive teleoperation. Methods: We set to develop a prototype system able to train a Deep Neural Net-work (DNN) by mapping wrist, hand and surgical tool real-time data acquisition(RTDA) inputs during mock-up heart micro-surgery procedures. The trained network was used to estimate the tools poses from refined hand joint angles. Results: Based on surgeon's feedback during mock micro-surgery, the developed wearable system with light-weight sensors for motion tracking did not interfere with the surgery and instrument handling. The wearable motion tracking system used 15 finger-thumb-wrist joint angle sensors to generate meaningful data-sets representing inputs of the DNN network with new hand joint angles added as necessary based on comparing the estimated tool poses against measured tool pose. The DNN architecture was optimized for the highest estimation accuracy and the ability to determine the tool pose with the least mean squared error. This novel approach showed that the surgical instrument's pose, an essential requirement for teleoperation, can be accurately estimated from recorded surgeon's hand/finger movements with a mean squared error (MSE) less than 0.3%      
### 73.A Deep Decomposition Network for Image Processing: A Case Study for Visible and Infrared Image Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2102.10526.pdf)
>  Image decomposition is a crucial subject in the field of image processing. It can extract salient features from the source image. We propose a new image decomposition method based on convolutional neural network. This method can be applied to many image processing tasks. In this paper, we apply the image decomposition network to the image fusion task. We input infrared image and visible light image and decompose them into three high-frequency feature images and a low-frequency feature image respectively. The two sets of feature images are fused using a specific fusion strategy to obtain fusion feature images. Finally, the feature images are reconstructed to obtain the fused image. Compared with the state-of-the-art fusion methods, this method has achieved better performance in both subjective and objective evaluation.      
### 74.Anomaly Detection in Audio with Concept Drift using Adaptive Huffman Coding  [ :arrow_down: ](https://arxiv.org/pdf/2102.10515.pdf)
>  In this work, we propose a framework to apply Huffman coding for anomaly detection in audio. There are a number of advantages of using the Huffman coding technique for anomaly detection, such as less dependence on the a-priory information about clusters (e.g., number, size, density) and variable event length. The coding cost can be calculated for any duration of the audio. Huffman codes are mostly used to compress non-time series data or data without concept drift. However, the normal class distribution of audio data varies greatly with time due to environmental noise. In this work, we explore how to adapt the Huffman tree to incorporate this concept drift. We found that, instead of creating new nodes, merging existing nodes gives a more effective performance. Note that with node merging, you never actually forget the history, at least theoretically. To the best of our knowledge, this is the first work on applying Huffman coding techniques for anomaly detection in temporal data. Experiments show that this scheme improves the result without much computational overhead. The approach is time-efficient and can be easily extended to other types of time series data (e.g., video).      
### 75.CheckSoft : A Scalable Event-Driven Software Architecture for Keeping Track of People and Things in People-Centric Spaces  [ :arrow_down: ](https://arxiv.org/pdf/2102.10513.pdf)
>  We present CheckSoft, a scalable event-driven software architecture for keeping track of people-object interactions in people-centric applications such as airport checkpoint security areas, automated retail stores, smart libraries, and so on. The architecture works off the video data generated in real time by a network of surveillance cameras. Although there are many different aspects to automating these applications, the most difficult part of the overall problem is keeping track of the interactions between the people and the objects. CheckSoft uses finite-state-machine (FSM) based logic for keeping track of such interactions which allows the system to quickly reject any false detections of the interactions by the video cameras. CheckSoft is easily scalable since the architecture is based on multi-processing in which a separate process is assigned to each human and to each "storage container" for the objects. A storage container may be a shelf on which the objects are displayed or a bin in which the objects are stored, depending on the specific application in which CheckSoft is deployed.      
### 76.Information Decoding and SDR Implementation of DFRC Systems Without Training Signals  [ :arrow_down: ](https://arxiv.org/pdf/2102.10488.pdf)
>  Recent performance analysis of dual-function radar communications (DFRC) systems, which embed information using phase shift keying (PSK) into multiple-input multiple-output (MIMO) frequency hopping (FH) radar pulses, shows promising results for addressing spectrum sharing issues between radar and communications. However, the problem of decoding information at the communication receiver remains challenging, since the DFRC transmitter is typically assumed to transmit only information embedded radar waveforms and not the training sequence. We propose a novel method for decoding information at the communication receiver without using training data, which is implemented using a software-defined radio (SDR). The performance of the SDR implementation is examined in terms of bit error rate (BER) as a function of signal-to-noise ratio (SNR) for differential binary and quadrature phase shift keying modulation schemes and compared with the BER versus SNR obtained with numerical simulations.      
### 77.Multi-Phase Locking Value: A Generalized Method for Determining Instantaneous Multi-frequency Phase Coupling  [ :arrow_down: ](https://arxiv.org/pdf/2102.10471.pdf)
>  Many physical, biological and neural systems behave as coupled oscillators, with characteristic phase coupling across different frequencies. Methods such as $n:m$ phase locking value and bi-phase locking value have previously been proposed to quantify phase coupling between two resonant frequencies (e.g. $f$, $2f/3$) and across three frequencies (e.g. $f_1$, $f_2$, $f_1+f_2$), respectively. However, the existing phase coupling metrics have their limitations and limited applications. They cannot be used to detect or quantify phase coupling across multiple frequencies (e.g. $f_1$, $f_2$, $f_3$, $f_4$, $f_1+f_2+f_3-f_4$), or coupling that involves non-integer multiples of the frequencies (e.g. $f_1$, $f_2$, $2f_1/3+f_2/3$). To address the gap, this paper proposes a generalized approach, named multi-phase locking value (M-PLV), for the quantification of various types of instantaneous multi-frequency phase coupling. Different from most instantaneous phase coupling metrics that measure the simultaneous phase coupling, the proposed M-PLV method also allows the detection of delayed phase coupling and the associated time lag between coupled oscillators. The M-PLV has been tested on cases where synthetic coupled signals are generated using white Gaussian signals, and a system comprised of multiple coupled Rössler oscillators. Results indicate that the M-PLV can provide a reliable estimation of the time window and frequency combination where the phase coupling is significant, as well as a precise determination of time lag in the case of delayed coupling. This method has the potential to become a powerful new tool for exploring phase coupling in complex nonlinear dynamic systems.      
### 78.Trumpets: Injective Flows for Inference and Inverse Problems  [ :arrow_down: ](https://arxiv.org/pdf/2102.10461.pdf)
>  We propose injective generative models called Trumpets that generalize invertible normalizing flows. The proposed generators progressively increase dimension from a low-dimensional latent space. We demonstrate that Trumpets can be trained orders of magnitudes faster than standard flows while yielding samples of comparable or better quality. They retain many of the advantages of the standard flows such as training based on maximum likelihood and a fast, exact inverse of the generator. Since Trumpets are injective and have fast inverses, they can be effectively used for downstream Bayesian inference. To wit, we use Trumpet priors for maximum a posteriori estimation in the context of image reconstruction from compressive measurements, outperforming competitive baselines in terms of reconstruction quality and speed. We then propose an efficient method for posterior characterization and uncertainty quantification with Trumpets by taking advantage of the low-dimensional latent space.      
### 79.Development of the first Portuguese radar tracking sensor for Space Debris  [ :arrow_down: ](https://arxiv.org/pdf/2102.10457.pdf)
>  Currently, space debris represents a threat for satellites and space-based operations, both in-orbit and during the launching process. The yearly increase in space debris represents a serious concern to major space agencies leading to the development of dedicated space programs to deal with this issue. Ground-based radars can detect Earth orbiting debris down to a few square centimeters and therefore constitute a major building block of a space debris monitoring system. New radar sensors are required in Europe to enhance capabilities and availability of its small radar network capable of tracking and surveying space objects and to respond to the debris increase expected from the New Space economy activities. This article presents ATLAS, a new tracking radar system for debris detection located in Portugal. It starts by an extensive technical description of all the system components followed by a study that estimates its future performance. A section dedicated to waveform design is also presented, since the system allows the usage of several types of pulse modulation schemes such as LFM and phase coded modulations while enabling the development and testing of more advanced ones. By presenting an architecture that is highly modular with fully digital signal processing, ATLAS establishes a platform for fast and easy development, research and innovation. The system follows the use of Commercial-Off-The-Shelf technologies and Open Systems which is unique among current radar systems.      
### 80.Efficient Numerical Methods for Secrecy Capacity of Gaussian MIMO Wiretap Channel  [ :arrow_down: ](https://arxiv.org/pdf/2102.10396.pdf)
>  This paper presents two different low-complexity methods for obtaining the secrecy capacity of multiple-input multiple-output (MIMO) wiretap channel subject to a sum power constraint (SPC). The challenges in deriving computationally efficient solutions to the secrecy capacity problem are due to the fact that the secrecy rate is a difference of convex functions (DC) of the transmit covariance matrix, for which its convexity is only known for \emph{the degraded case}. In the first method, we capitalize on the accelerated DC algorithm, which requires solving a sequence of convex subproblems. In particular, we show that each subproblem indeed admits a water-filling solution. In the second method, based on the equivalent convex-concave reformulation of the secrecy capacity problem, we develop a so-called partial best response algorithm (PBRA). Each iteration of the PBRA is also done in closed form. Simulation results are provided to demonstrate the superior performance of the proposed methods.      
### 81.Impacts of Heat Decarbonisation on System Adequacy considering Increased Meteorological Sensitivity  [ :arrow_down: ](https://arxiv.org/pdf/2102.10391.pdf)
>  This paper explores the impacts of decarbonisation of heat on demand and subsequently on the generation capacity required to secure against system adequacy standards. Gas demand is explored as a proxy variable for modelling the electrification of heating demand in existing housing stock, with a focus on impacts on timescales of capacity markets (up to four years ahead). The work considers the systemic changes that electrification of heating could introduce, including biases that could be introduced if legacy modelling approaches continue to prevail. Covariates from gas and electrical regression models are combined to form a novel, time-collapsed system model, with demand-weather sensitivities determined using lasso-regularized linear regression. It is shown, using a GB case study with one million domestic heat pump installations per year, that the sensitivity of electrical system demand to temperature (and subsequently sensitivities to cold/warm winter seasons) could increase by 50% following four years of heat demand electrification. A central estimate of 1.75 kW additional peak demand per heat pump is estimated, with variability across three published heat demand profiles leading to a range of more than 14 GW in the most extreme cases. It is shown that the legacy approach of scaling historic demand, as compared to the explicit modelling of heat, could lead to over-procurement of 0.79 GW due to bias in estimates of additional capacity to secure. Failure to address this issue could lead to £100m overspend on capacity over ten years.      
### 82.A Python Framework for Fast Modelling and Simulation of Cellular Nonlinear Networks and other Finite-difference Time-domain Systems  [ :arrow_down: ](https://arxiv.org/pdf/2102.10340.pdf)
>  This paper introduces and evaluates a freely available cellular nonlinear network simulator optimized for the effective use of GPUs, to achieve fast modelling and simulations. Its relevance is demonstrated for several applications in nonlinear complex dynamical systems, such as slow-growth phenomena as well as for various image processing applications such as edge detection. The simulator is designed as a Jupyter notebook written in Python and functionally tested and optimized to run on the freely available cloud platform Google Collaboratory. Although the simulator, in its actual form, is designed to model the FitzHugh Nagumo Reaction-Diffusion cellular nonlinear network, it can be easily adapted for any other type of finite-difference time-domain model. Four implementation versions are considered, namely using the PyCUDA, NUMBA respectively CUPY libraries (all three supporting GPU computations) as well as a NUMPY-based implementation to be used when GPU is not available. The specificities and performances for each of the four implementations are analyzed concluding that the PyCUDA implementation ensures a very good performance being capable to run up to 14000 Mega cells per seconds (each cell referring to the basic nonlinear dynamic system composing the cellular nonlinear network).      
### 83.Separating Stimulus-Induced and Background Components of Dynamic Functional Connectivity in Naturalistic fMRI  [ :arrow_down: ](https://arxiv.org/pdf/2102.10331.pdf)
>  We consider the challenges in extracting stimulus-related neural dynamics from other intrinsic processes and noise in naturalistic functional magnetic resonance imaging (fMRI). Most studies rely on inter-subject correlations (ISC) of low-level regional activity and neglect varying responses in individuals. We propose a novel, data-driven approach based on low-rank plus sparse (L+S) decomposition to isolate stimulus-driven dynamic changes in brain functional connectivity (FC) from the background noise, by exploiting shared network structure among subjects receiving the same naturalistic stimuli. The time-resolved multi-subject FC matrices are modeled as a sum of a low-rank component of correlated FC patterns across subjects, and a sparse component of subject-specific, idiosyncratic background activities. To recover the shared low-rank subspace, we introduce a fused version of principal component pursuit (PCP) by adding a fusion-type penalty on the differences between the rows of the low-rank matrix. The method improves the detection of stimulus-induced group-level homogeneity in the FC profile while capturing inter-subject variability. We develop an efficient algorithm via a linearized alternating direction method of multipliers to solve the fused-PCP. Simulations show accurate recovery by the fused-PCP even when a large fraction of FC edges are severely corrupted. When applied to natural fMRI data, our method reveals FC changes that were time-locked to auditory processing during movie watching, with dynamic engagement of sensorimotor systems for speech-in-noise. It also provides a better mapping to auditory content in the movie than ISC.      
### 84.Learnable MFCCs for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2102.10322.pdf)
>  We propose a learnable mel-frequency cepstral coefficient (MFCC) frontend architecture for deep neural network (DNN) based automatic speaker verification. Our architecture retains the simplicity and interpretability of MFCC-based features while allowing the model to be adapted to data flexibly. In practice, we formulate data-driven versions of the four linear transforms of a standard MFCC extractor -- windowing, discrete Fourier transform (DFT), mel filterbank and discrete cosine transform (DCT). Results reported reach up to 6.7\% (VoxCeleb1) and 9.7\% (SITW) relative improvement in term of equal error rate (EER) from static MFCCs, without additional tuning effort.      
### 85.Stability and Resilience of Distributed Information Spreading in Aggregate Computing  [ :arrow_down: ](https://arxiv.org/pdf/2102.10319.pdf)
>  Spreading information through a network of devices is a core activity for most distributed systems. As such, self-stabilizing algorithms implementing information spreading are one of the key building blocks enabling aggregate computing to provide resilient coordination in open complex distributed systems. This paper improves a general spreading block in the aggregate computing literature by making it resilient to network perturbations, establishes its global uniform asymptotic stability and proves that it is ultimately bounded under persistent disturbances. The ultimate bounds depend only on the magnitude of the largest perturbation and the network diameter, and three design parameters trade off competing aspects of performance. For example, as in many dynamical systems, values leading to greater resilience to network perturbations slow convergence and vice versa.      
### 86.Imitation Learning for Variable Speed Object Manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2102.10283.pdf)
>  To operate in a real-world environment, robots have several requirements including environmental adaptability. Moreover, the desired success rate for the completion of tasks must be achieved. In this regard, end-to-end learning for autonomous operation is currently being investigated. However, the issue of operating speed has not been investigated in detail. Therefore, in this paper, we propose a method for generating variable operating speeds while adapting to perturbations in the environment. When the work speed changes, there is a nonlinear relationship between the operating speed and force (e.g., inertial and frictional forces). However, the proposed method can be adapted to nonlinearities by utilizing minimal motion data. We experimentally evaluated the proposed method for erasing a line using an eraser fixed to the tip of a robot. Furthermore, the proposed method enables a robot to perform a task faster than a human operator.      
### 87.Singer Identification Using Deep Timbre Feature Learning with KNN-Net  [ :arrow_down: ](https://arxiv.org/pdf/2102.10236.pdf)
>  In this paper, we study the issue of automatic singer identification (SID) in popular music recordings, which aims to recognize who sang a given piece of song. The main challenge for this investigation lies in the fact that a singer's singing voice changes and intertwines with the signal of background accompaniment in time domain. To handle this challenge, we propose the KNN-Net for SID, which is a deep neural network model with the goal of learning local timbre feature representation from the mixture of singer voice and background music. Unlike other deep neural networks using the softmax layer as the output layer, we instead utilize the KNN as a more interpretable layer to output target singer labels. Moreover, attention mechanism is first introduced to highlight crucial timbre features for SID. Experiments on the existing artist20 dataset show that the proposed approach outperforms the state-of-the-art method by 4%. We also create singer32 and singer60 datasets consisting of Chinese pop music to evaluate the reliability of the proposed method. The more extensive experiments additionally indicate that our proposed model achieves a significant performance improvement compared to the state-of-the-art methods.      
### 88.The Accented English Speech Recognition Challenge 2020: Open Datasets, Tracks, Baselines, Results and Methods  [ :arrow_down: ](https://arxiv.org/pdf/2102.10233.pdf)
>  The variety of accents has posed a big challenge to speech recognition. The Accented English Speech Recognition Challenge (AESRC2020) is designed for providing a common testbed and promoting accent-related research. Two tracks are set in the challenge -- English accent recognition (track 1) and accented English speech recognition (track 2). A set of 160 hours of accented English speech collected from 8 countries is released with labels as the training set. Another 20 hours of speech without labels is later released as the test set, including two unseen accents from another two countries used to test the model generalization ability in track 2. We also provide baseline systems for the participants. This paper first reviews the released dataset, track setups, baselines and then summarizes the challenge results and major techniques used in the submissions.      
### 89.Single Acquisition Label-free Histology-like Imaging with Dual Contrast Photoacoustic Remote Sensing Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2102.10225.pdf)
>  Significance: Histopathological analysis of tissues is an essential tool for grading, staging, diagnosing and resecting cancers and other malignancies. Current histopathological techniques require substantial sample processing prior to staining with hematoxylin and eosin (H&amp;E) dyes, to highlight nuclear and cellular morphology. Sample preparation and staining is resource-intensive and introduces potential for variability during sample preparation. <br>Aim: We present a novel method for direct label-free histopathological assessment of formalin fixed paraffin embedded tissue blocks and thin tissue sections using a dual contrast photoacoustic remote sensing (PARS) microscopy system. <br>Approach: To emulate the nuclear and cellular contrast of H&amp;E staining, we leverage unique properties of the PARS system. Here the ultraviolet excitation of the PAARS microscope takes advantage of DNA's unique optical absorption to provide nuclear contrast analogous to hematoxylin staining of cell nucelli. Concurrently, the optical scattering contrast of the PARS detection system is leveraged to provide bulk tissue contrast analogous to eosin staining of cell membranes. <br>Results: We demonstrate the efficacy of this technique by imaging human breast tissue and human skin tissues in formalin fixed paraffin embedded tissue blocks and frozen sections respectively. Salient nuclear and extra-nuclear features such as cancerous cells, glands and ducts, adipocytes, and stromal structures such as collagen. <br>Conclusions. The presented dual contrast PARS microscope enables label-free visualizations of tissue with contrast and quality analogous to the current gold standard for histopathological analysis. Thus, the proposed system is well positioned to augment existing histopathological workflows, providing histological imaging directly on unstained tissue blocks and sections.      
### 90.Channel Estimation and Data Decoding Analysis of Massive MIMO with 1-Bit ADCs  [ :arrow_down: ](https://arxiv.org/pdf/2102.10172.pdf)
>  We present an analytical framework for the channel estimation and the data decoding in massive multiple-input multiple-output uplink systems with 1-bit analog-to-digital converters (ADCs). First, we provide a closed-form expression of the mean squared error of the channel estimation for a general class of linear estimators. In addition, we propose a novel linear estimator with significantly enhanced performance compared with existing estimators with the same structure. For the data decoding, we provide closed-form expressions of the expected value and the variance of the estimated symbols when maximum ratio combining is adopted, which can be exploited to efficiently implement maximum likelihood decoding and, potentially, to design the set of transmit symbols. Comprehensive numerical results are presented to study the performance of the channel estimation and the data decoding with 1-bit ADCs with respect to the signal-to-noise ratio (SNR), the number of user equipments, and the pilot length. The proposed analysis highlights a fundamental SNR trade-off, according to which operating at the right noise level significantly enhances the system performance.      

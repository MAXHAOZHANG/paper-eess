# ArXiv eess --Mon, 17 May 2021
### 1.A Hypothesis Testing Approach to Nonstationary Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2105.06958.pdf)
>  The extraction of nonstationary signals from blind and semi-blind multivariate observations is a recurrent problem. Numerous algorithms have been developed for this problem, which are based on the exact or approximate joint diagonalization of second or higher order cumulant matrices/tensors of multichannel data. While a great body of research has been dedicated to joint diagonalization algorithms, the selection of the diagonalized matrix/tensor set remains highly problem-specific. Herein, various methods for nonstationarity identification are reviewed and a new general framework based on hypothesis testing is proposed, which results in a classification/clustering perspective to semi-blind source separation of nonstationary components. The proposed method is applied to noninvasive fetal ECG extraction, as case study.      
### 2.Surface Detection for Sketched Single Photon Lidar  [ :arrow_down: ](https://arxiv.org/pdf/2105.06920.pdf)
>  Single-photon lidar devices are able to collect an ever-increasing amount of time-stamped photons in small time periods due to increasingly larger arrays, generating a memory and computational bottleneck on the data processing side. Recently, a sketching technique was introduced to overcome this bottleneck which compresses the amount of information to be stored and processed. The size of the sketch scales with the number of underlying parameters of the time delay distribution and not, fundamentally, with either the number of detected photons or the time-stamp resolution. In this paper, we propose a detection algorithm based solely on a small sketch that determines if there are surfaces or objects in the scene or not. If a surface is detected, the depth and intensity of a single object can be computed in closed-form directly from the sketch. The computational load of the proposed detection algorithm depends solely on the size of the sketch, in contrast to previous algorithms that depend at least linearly in the number of collected photons or histogram bins, paving the way for fast, accurate and memory efficient lidar estimation. Our experiments demonstrate the memory and statistical efficiency of the proposed algorithm both on synthetic and real lidar datasets.      
### 3.Sound Pressure Minimization at the Ear Drum for In-ear ANC Headphones using a Fixed Feedforward Remote Microphone Technique  [ :arrow_down: ](https://arxiv.org/pdf/2105.06894.pdf)
>  In this paper we consider an in-ear headphone equipped with an external microphone and aim to minimize the sound pressure at the ear drum by means of a fixed feedforward ANC controller. Based on measured acoustic paths to predict the sound pressure generated by external sources and the headphone at the ear drum, the FIR filter coefficients of the ANC controller are optimized for different sound fields. Due to the acoustic feedback path between the loudspeaker and the microphone, a stability constraint based on the Nyquist stability criterion is introduced. Performance degradations due to reinsertions of the headphone and intra-subject variations are addressed by simultaneously optimizing the controller for several measurement repetitions of the acoustic paths. Simulations show that the controller optimized for an ipsilateral excitation produces an attenuation of at least -10 dB that extends approximately to +45째 and -65째 from the ipsilateral DoA. The controller optimized for a diffuse-field excitation achieves an attenuation of at least -10 dB over a wider range of DoAs on the ipsilateral side, namely +90째 to -90째. Optimizing the controller for several measurement repetitions is shown to be effective against performance degradations due to reinsertions and intra-subject variations.      
### 4.A Frequency Domain Constraint for Synthetic X-ray Image Super Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2105.06887.pdf)
>  Synthetic X-ray images can be helpful for image guiding systems and VR simulations. However, it is difficult to produce high-quality arbitrary view synthetic X-ray images in real-time due to limited CT scanning resolution, high computation resource demand or algorithm complexity. Our goal is to generate high-resolution synthetic X-ray images in real-time by upsampling low-resolution im-ages. Reference-based Super Resolution (RefSR) has been well studied in recent years and has been proven to be more powerful than traditional Single Image Su-per-Resolution (SISR). RefSR can produce fine details by utilizing the reference image but it still inevitably generates some artifacts and noise. In this paper, we propose texture transformer super-resolution with frequency domain (TTSR-FD). We introduce frequency domain loss as a constraint to further improve the quality of the RefSR results with fine details and without obvious artifacts. This makes a real-time synthetic X-ray image-guided procedure VR simulation system possible. To the best of our knowledge, this is the first paper utilizing the frequency domain as part of the loss functions in the field of super-resolution. We evaluated TTSR-FD on our synthetic X-ray image dataset and achieved state-of-the-art results.      
### 5.Enhancing sparse representation of color images by cross channel transformation  [ :arrow_down: ](https://arxiv.org/pdf/2105.06883.pdf)
>  Transformations for enhancing sparsity in the approximation of color images by 2D atomic decomposition are discussed. The sparsity is firstly considered with respect to the most significant coefficients in the wavelet decomposition of the color image. The discrete cosine transform is singled out as an effective transformation for this purpose. The enhanced feature is further exploited by approximating the transformed arrays using an effective greedy strategy with a separable highly redundant dictionary. The relevance of the achieved sparsity is illustrated by a simple encoding procedure. On a set of typical test images the compression at high quality recovery is shown to significantly improve upon JPEG and WebP formats. The results are competitive with those produced by the JPEG2000 standard.      
### 6.Deep Learning Based RIS Channel Extrapolation with Element-grouping  [ :arrow_down: ](https://arxiv.org/pdf/2105.06850.pdf)
>  Reconfigurable intelligent surface (RIS) is considered as a revolutionary technology for future wireless communication networks. In this letter, we consider the acquisition of the cascaded channels, which is a challenging task due to the massive number of passive RIS elements. To reduce the pilot overhead, we adopt the element-grouping strategy, where each element in one group shares the same reflection coefficient and is assumed to have the same channel condition. We analyze the channel interference caused by the element-grouping strategy and further design two deep learning based networks. The first one aims to refine the partial channels by eliminating the interference, while the second one tries to extrapolate the full channels from the refined partial channels. We cascade the two networks and jointly train them. Simulation results show that the proposed scheme provides significant gain compared to the conventional element-grouping method without interference elimination.      
### 7.Predicting speech intelligibility from EEG using a dilated convolutional network  [ :arrow_down: ](https://arxiv.org/pdf/2105.06844.pdf)
>  Objective: Currently, only behavioral speech understanding tests are available, which require active participation of the person. As this is infeasible for certain populations, an objective measure of speech intelligibility is required. Recently, brain imaging data has been used to establish a relationship between stimulus and brain response. Linear models have been successfully linked to speech intelligibility but require per-subject training. We present a deep-learning-based model incorporating dilated convolutions that can be used to predict speech intelligibility without subject-specific (re)training. Methods: We evaluated the performance of the model as a function of input segment length, EEG frequency band and receptive field size while comparing it to a baseline model. Next, we evaluated performance on held-out data and finetuning. Finally, we established a link between the accuracy of our model and the state-of-the-art behavioral MATRIX test. Results: The model significantly outperformed the baseline for every input segment length (p$\leq10^{-9}$), for all EEG frequency bands except the theta band (p$\leq0.001$) and for receptive field sizes larger than 125~ms (p$\leq0.05$). Additionally, finetuning significantly increased the accuracy (p$\leq0.05$) on a held-out dataset. Finally, a significant correlation (r=0.59, p=0.0154) was found between the speech reception threshold estimated using the behavioral MATRIX test and our objective method. Conclusion: Our proposed dilated convolutional model can be used as a proxy for speech intelligibility. Significance: Our method is the first to predict the speech reception threshold from EEG for unseen subjects, contributing to objective measures of speech intelligibility.      
### 8.Exploiting Aliasing for Manga Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2105.06830.pdf)
>  As a popular entertainment art form, manga enriches the line drawings details with bitonal screentones. However, manga resources over the Internet usually show screentone artifacts because of inappropriate scanning/rescaling resolution. In this paper, we propose an innovative two-stage method to restore quality bitonal manga from degraded ones. Our key observation is that the aliasing induced by downsampling bitonal screentones can be utilized as informative clues to infer the original resolution and screentones. First, we predict the target resolution from the degraded manga via the Scale Estimation Network (SE-Net) with spatial voting scheme. Then, at the target resolution, we restore the region-wise bitonal screentones via the Manga Restoration Network (MR-Net) discriminatively, depending on the degradation degree. Specifically, the original screentones are directly restored in pattern-identifiable regions, and visually plausible screentones are synthesized in pattern-agnostic regions. Quantitative evaluation on synthetic data and visual assessment on real-world cases illustrate the effectiveness of our method.      
### 9.Dual-Attention Residual Network for Automatic Diagnosis of COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2105.06779.pdf)
>  The ongoing global pandemic of Coronavirus Disease 2019 (COVID-19) has posed serious threat to public health and the economy. Rapid and accurate diagnosis of COVID-19 is crucial to prevent the further spread of the disease and reduce its mortality. Chest computed tomography (CT) is an effective tool for the early diagnosis of lung diseases including pneumonia. However, detecting COVID-19 from CT is demanding and prone to human errors as some early-stage patients may have negative findings on images. In this study, we propose a novel residual network to automatically identify COVID-19 from other common pneumonia and normal people using CT images. Specifically, we employ the modified 3D ResNet18 as the backbone network, which is equipped with both channel-wise attention (CA) and depth-wise attention (DA) modules to further improve the diagnostic performance. Experimental results on the large open-source dataset show that our method can differentiate COVID-19 from the other two classes with 94.7% accuracy, 93.73% sensitivity, 98.28% specificity, 95.26% F1-score, and an area under the receiver operating characteristic curve (AUC) of 0.99, outperforming baseline methods. These results demonstrate that the proposed method could potentially assist the clinicians in performing a quick diagnosis to fight COVID-19.      
### 10.Two-dimensional multi-target detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.06765.pdf)
>  We consider the two-dimensional multi-target detection problem of recovering a target image from a noisy measurement that contains multiple copies of the image, each randomly rotated and translated. Motivated by the structure reconstruction problem in single-particle cryo-electron microscopy, we focus on the high noise regime, where the noise hampers accurate detection of the image occurrences. We develop an autocorrelation analysis framework to estimate the image directly from a measurement with an arbitrary spacing distribution of image occurrences, bypassing the estimation of individual locations and rotations. We conduct extensive numerical experiments, and demonstrate image recovery in highly noisy environments. The code to reproduce all numerical experiments is publicly available at <a class="link-external link-https" href="https://github.com/krshay/MTD-2D" rel="external noopener nofollow">this https URL</a>.      
### 11.A Primer on Techtile: An R&amp;D Testbed for Distributed Communication, Sensing and Positioning  [ :arrow_down: ](https://arxiv.org/pdf/2105.06740.pdf)
>  The Techtile measurement infrastructure is a multi-functional, versatile testbed for new communication and sensing technologies relying on fine-grained distributed resources. The facility enables experimental research on hyper-connected interactive environments and validation of new wireless connectivity, sensing and positioning solutions. It consists of a data acquisition and processing equipment backbone and a fabric of dispersed edge computing devices, Software-Defined Radios, sensors, and LED sources. These bring intelligence close to the applications and can also collectively function as a massive, distributed resource. Furthermore, the infrastructure allows exploring more degrees and new types of diversity, i.e., scaling up the number of elements, introducing `3D directional diversity' by deploying the distributed elements with different orientations, and `interface diversity' by exploiting multiple technologies and hybrid signals (RF, acoustic, and visible light).      
### 12.Nonuniform Sampling Rate Conversion: An Efficient Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.06700.pdf)
>  We present a discrete-time algorithm for nonuniform sampling rate conversion that presents low computational complexity and memory requirements. It generalizes arbitrary sampling rate conversion by accommodating time-varying conversion ratios, i.e., it can efficiently adapt to instantaneous changes of the input and output sampling rates. This approach is based on appropriately factorizing the time-varying discrete-time filter used for the conversion. Common filters that satisfy this factorization property are those where the underlying continuous-time filter consists of linear combinations of exponentials, e.g., those described by linear constant-coefficient differential equations. This factorization separates the computation into two parts: one consisting of a factor solely depending on the output sampling instants and the other consists of a summation -- that can be computed recursively -- whose terms depend solely on the input sampling instants and its number of terms is given by a relationship between input and output sampling instants. Thus, nonuniform sampling rates can be accommodated by updating the factors involved and adjusting the number of terms added. When the impulse response consists of exponentials, computing the factors can be done recursively in an efficient manner.      
### 13.One Network to Solve Them All: A Sequential Multi-Task Joint Learning Network Framework for MR Imaging Pipeline  [ :arrow_down: ](https://arxiv.org/pdf/2105.06653.pdf)
>  Magnetic resonance imaging (MRI) acquisition, reconstruction, and segmentation are usually processed independently in the conventional practice of MRI workflow. It is easy to notice that there are significant relevances among these tasks and this procedure artificially cuts off these potential connections, which may lead to losing clinically important information for the final diagnosis. To involve these potential relations for further performance improvement, a sequential multi-task joint learning network model is proposed to train a combined end-to-end pipeline in a differentiable way, aiming at exploring the mutual influence among those tasks simultaneously. Our design consists of three cascaded modules: 1) deep sampling pattern learning module optimizes the $k$-space sampling pattern with predetermined sampling rate; 2) deep reconstruction module is dedicated to reconstructing MR images from the undersampled data using the learned sampling pattern; 3) deep segmentation module encodes MR images reconstructed from the previous module to segment the interested tissues. The proposed model retrieves the latently interactive and cyclic relations among those tasks, from which each task will be mutually beneficial. The proposed framework is verified on MRB dataset, which achieves superior performance on other SOTA methods in terms of both reconstruction and segmentation.      
### 14.CN-LBP: Complex Networks-based Local Binary Patterns for Texture Classification  [ :arrow_down: ](https://arxiv.org/pdf/2105.06652.pdf)
>  To effectively overcome the limitations of local binary patterns (LBP), this letter proposes a new texture descriptor aided by complex networks (CN) and uniform LBP (ULBP), namely, CN-LBP. Specifically, we first abstract a gray-scale image (GSI) as an undirected graph with the help of pixel distance and intensity, and gradient of image (GoI). Second, three variants of CN-based feature measurements (clustering coefficient, degree centrality, and eigenvector centrality) are proposed to decipher the image spatial-relationship, energy, and entropy, respectively, thus generating three feature maps, which can retain the image information as much as possible. Third, given the generated feature maps, we apply ULBP on feature maps, GSI, and GoI, and obtain the discriminative representation of the texture image. Finally, CN-LBP is obtained by jointly calculating and concatenating the spatial histograms. In contrast to original LBP, the proposed texture descriptor contains more detailed image information and shows certain resistance to noise. Experiment results show that the proposed approach significantly improves the texture classification accuracy compared with state-of-the-art LBP-based variants and deep learning-based approaches.      
### 15.COVID-Net CXR-2: An Enhanced Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.06640.pdf)
>  As the COVID-19 pandemic continues to devastate globally, the use of chest X-ray (CXR) imaging as a complimentary screening strategy to RT-PCR testing continues to grow given its routine clinical use for respiratory complaint. As part of the COVID-Net open source initiative, we introduce COVID-Net CXR-2, an enhanced deep convolutional neural network design for COVID-19 detection from CXR images built using a greater quantity and diversity of patients than the original COVID-Net. To facilitate this, we also introduce a new benchmark dataset composed of 19,203 CXR images from a multinational cohort of 16,656 patients from at least 51 countries, making it the largest, most diverse COVID-19 CXR dataset in open access form. The COVID-Net CXR-2 network achieves sensitivity and positive predictive value of 95.5%/97.0%, respectively, and was audited in a transparent and responsible manner. Explainability-driven performance validation was used during auditing to gain deeper insights in its decision-making behaviour and to ensure clinically relevant factors are leveraged for improving trust in its usage. Radiologist validation was also conducted, where select cases were reviewed and reported on by two board-certified radiologists with over 10 and 19 years of experience, respectively, and showed that the critical factors leveraged by COVID-Net CXR-2 are consistent with radiologist interpretations. While not a production-ready solution, we hope the open-source, open-access release of COVID-Net CXR-2 and the respective CXR benchmark dataset will encourage researchers, clinical scientists, and citizen scientists to accelerate advancements and innovations in the fight against the pandemic.      
### 16.Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation  [ :arrow_down: ](https://arxiv.org/pdf/2105.06598.pdf)
>  We present a unified and hardware efficient architecture for two stage voice trigger detection (VTD) and false trigger mitigation (FTM) tasks. Two stage VTD systems of voice assistants can get falsely activated to audio segments acoustically similar to the trigger phrase of interest. FTM systems cancel such activations by using post trigger audio context. Traditional FTM systems rely on automatic speech recognition lattices which are computationally expensive to obtain on device. We propose a streaming transformer (TF) encoder architecture, which progressively processes incoming audio chunks and maintains audio context to perform both VTD and FTM tasks using only acoustic features. The proposed joint model yields an average 18% relative reduction in false reject rate (FRR) for the VTD task at a given false alarm rate. Moreover, our model suppresses 95% of the false triggers with an additional one second of post-trigger audio. Finally, on-device measurements show 32% reduction in runtime memory and 56% reduction in inference time compared to non-streaming version of the model.      
### 17.Mapping of Dynamics between Mechanical and Electrical Ports in SG-IBR Composite Grids  [ :arrow_down: ](https://arxiv.org/pdf/2105.06583.pdf)
>  Power grids are traditionally dominated by synchronous generators (SGs) but are currently undergoing a major transformation through the increasing integration of inverter-based resources (IBRs). The SG-dominated grid is traditionally analyzed in a mechanical-centric view which ignores fast electrical dynamics and focuses on the torque-speed dynamics. By contrast, analysis of the emergent IBR-dominated grid usually takes the electrical-centric view which focuses on the voltage-current interaction. In this article, a port-mapping method is proposed to fill the gap between these approaches and combine them in a unified model. Specifically, the mechanical dynamics are mapped to the electrical impedance seen at the electrical port; and the electrical dynamics are also mapped to the torque coefficient seen at the mechanical port. The bidirectional mapping gives additional flexibility and insights to analyze the sub-system interactions in whole-system dynamics and guide the tuning of parameter. Application of the proposed method is illustrated in three cases with increasing scales, namely a single-SG-infinite-bus system, a single-IBR-weak-grid system, and a modified IEEE 14-bus SG-IBR composite system.      
### 18.Stroke Lesion Segmentation with Visual Cortex Anatomy Alike Neural Nets  [ :arrow_down: ](https://arxiv.org/pdf/2105.06544.pdf)
>  Cerebrovascular accident or stroke, is an acute disease with extreme impact on patients and healthcare systems and is the second largest cause of death worldwide. Fast and precise stroke lesion detection and location is an extreme important process with regards to stroke diagnosis, treatment, and prognosis. Except from the manual segmentation and traditional segmentation approach, machine learning based segmentation methods are the most promising ones when considering efficiency and accuracy, and convolutional neural network based models are the first of its kind. However, most of these neural network models do not really align with the brain anatomical structures. Intuitively, this work presents a more brain alike model which mimics the anatomical structure of the human visual cortex. Through the preliminary experiments on stroke lesion segmentation task, the proposed model is found to be able to perform equally well to some of the state-of-the-art models.      
### 19.Multi-Resolution Data Fusion for SuperResolution Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2105.06533.pdf)
>  Applications in materials and biological imaging are limited by the ability to collect high-resolution data over large areas in practical amounts of time. <br>One possible solution to this problem is to collect low-resolution data and interpolate to produce a high-resolution image. However, state-of-the-art super-resolution algorithms are typically designed for natural images, require aligned pairing of high and low-resolution training data for optimal performance, and do not directly incorporate a model of the imaging sensor. <br>In this paper, we present a Multi-Resolution Data Fusion (MDF) algorithm for accurate interpolation of low-resolution SEM and TEM data by factors of 4x and 8x. This MDF interpolation algorithm uses small quantities of unpaired high-resolution data to learn an accurate prior model denoiser and balances this with a forward model agent based on a mismatched back-projector that maintains fidelity to measured data. <br>Our method is based on Multi-Agent Consensus Equilibrium, a generalization of the Plug-and-Play method, and allows for interpolation at arbitrary resolutions without retraining. <br>We present electron microscopy results at 4x and 8x interpolation factors that exhibit reduced artifacts relative to existing methods while maintaining fidelity to acquired data and accurately resolving sub-pixel-scale features.      
### 20.Safety-Constrained Learning and Control using Scarce Data and Reciprocal Barriers  [ :arrow_down: ](https://arxiv.org/pdf/2105.06526.pdf)
>  We develop a control algorithm that ensures the safety, in terms of confinement in a set, of a system with unknown, 2nd-order nonlinear dynamics. The algorithm establishes novel connections between data-driven and robust, nonlinear control. It is based on data obtained online from the current trajectory and the concept of reciprocal barriers. More specifically, it first uses the obtained data to calculate set-valued functions that over-approximate the unknown dynamic terms. For the second step of the algorithm, we design a robust control scheme that uses these functions as well as reciprocal barriers to render the system forward invariant with respect to the safe set. In addition, we provide an extension of the algorithm that tackles issues of controllability loss incurred by the nullspace of the control-direction matrix. The algorithm removes a series of standard, limiting assumptions considered in the related literature since it does not require global boundedness, growth conditions, or a priori approximations of the unknown dynamics' terms.      
### 21.Deep learned SVT: Unrolling singular value thresholding to obtain better MSE  [ :arrow_down: ](https://arxiv.org/pdf/2105.06934.pdf)
>  Affine rank minimization problem is the generalized version of low rank matrix completion problem where linear combinations of the entries of a low rank matrix are observed and the matrix is estimated from these measurements. We propose a trainable deep neural network by unrolling a popular iterative algorithm called the singular value thresholding (SVT) algorithm to perform this generalized matrix completion which we call Learned SVT (LSVT). We show that our proposed LSVT with fixed layers (say T) reconstructs the matrix with lesser mean squared error (MSE) compared with that incurred by SVT with fixed (same T) number of iterations and our method is much more robust to the parameters which need to be carefully chosen in SVT algorithm.      
### 22.Adding Indoor Capacity Without Fiber Backhaul: A mmWave Bridge Prototype  [ :arrow_down: ](https://arxiv.org/pdf/2105.06911.pdf)
>  Today, a large portion of the mobile data traffic is consumed behind the shielding walls of buildings or in the Faraday cage of trains. This renders cellular network coverage from outdoor cell sites difficult. Indoor small cells and distributed antennas along train tracks are often considered as a solution, but the cost and the need for optical fiber backhaul are often prohibitive. To alleviate this issue, we describe an out-of-band repeater that converts a sub-6 GHz cell signal from a small cell installed at a cell tower to a mmWave frequency for the fronthaul to buildings or distributed antenna sites, where the signal is downconverted to the original frequency and emitted for example inside a building. This concept does not require fiber deployment, provides backward compatibility to equipment already in use, and additional indoor capacity is gained while outdoor networks are offloaded. The architecture and hardware prototype implementation are described, and measurements are reported to demonstrate the functionality and compatibility with commercial infrastructure and mobile terminals.      
### 23.Delivering Gigabit Capacities to Passenger Trains Tales from an Operator on the Road to 5G  [ :arrow_down: ](https://arxiv.org/pdf/2105.06898.pdf)
>  Delivering reliable and high-capacity Internet connectivity to high-speed train users is a challenge. Modern railway cars act as Faraday cages and a typical train consist comprises several hundreds of users moving at high velocity. Furthermore, with the global availability of fourth generation (4G) Long Term Evolution (LTE), user expectations have dramatically increased: it is expected to be online anytime and anywhere. Demand for mobile high-capacity is being driven by video and music streaming services, for lower latency and higher availability by gaming, and for more reliability and even uplink capacity by mission critical applications. Finally, the life-cycle of the railway industry is much longer than for telecommunications, which makes supporting 5G challenging. In this paper, we survey the challenges associated with delivering high-capacity connectivity to train users, describe potential options, and highlight how a leading western European operator is tackling these challenges and preparing for 5G and beyond.      
### 24.A Tutorial to Sparse Code Multiple Access  [ :arrow_down: ](https://arxiv.org/pdf/2105.06860.pdf)
>  Sparse Code Multiple Access (SCMA) is an enabling code-domain non-orthogonal multiple access (NOMA)scheme for massive connectivity and ultra low-latency in future machine-type communication networks. As an evolved variant of code division multiple access (CDMA), multiple users in SCMA are separated by assigning distinctive codebooks which display certain sparsity. At an SCMA receiver, efficient multiuser detection is carried out by employing the message passing algorithm (MPA) which exploits the sparsity of codebooks to achieve error rate performance approaching to that of the maximum likelihood receiver. Despite numerous research efforts on SCMA in recent years, a comprehensive and in-depth tutorial to SCMA is missing, to the best of our knowledge. To fill this gap and to stimulate more forthcoming research, we introduce the principles of SCMA encoding, codebook design, and MPA based decoding in a self-contained manner for layman researchers and engineers.      
### 25.3.5 GHz Coverage Assessment with a 5G Testbed  [ :arrow_down: ](https://arxiv.org/pdf/2105.06812.pdf)
>  Today, cellular networks have saturated frequencies below 3\,GHz. Because of increasing capacity requirements, 5th generation (5G) mobile networks target the 3.5\,GHz band (3.4 to 3.8\,GHz). Despite its expected wide usage, there is little empirical path loss data and mobile radio network planning experience for the 3.5\,GHz band available. This paper presents the results of rural, suburban, and urban measurement campaigns using a pre-standard 5G prototype testbed operating at 3.5\,GHz, with outdoor as well as outdoor-to-indoor scenarios. Based on the measurement results, path loss models are evaluated, which are essential for network planning.      
### 26.Waste detection in Pomerania: non-profit project for detecting waste in environment  [ :arrow_down: ](https://arxiv.org/pdf/2105.06808.pdf)
>  Waste pollution is one of the most significant environmental issues in the modern world. The importance of recycling is well known, either for economic or ecological reasons, and the industry demands high efficiency. Our team conducted comprehensive research on Artificial Intelligence usage in waste detection and classification to fight the world's waste pollution problem. As a result an open-source framework that enables the detection and classification of litter was developed. The final pipeline consists of two neural networks: one that detects litter and a second responsible for litter classification. Waste is classified into seven categories: bio, glass, metal and plastic, non-recyclable, other, paper and unknown. Our approach achieves up to 70% of average precision in waste detection and around 75% of classification accuracy on the test dataset. The code used in the studies is publicly available online.      
### 27.Exploring the Intrinsic Probability Distribution for Hyperspectral Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.06775.pdf)
>  In recent years, neural network-based anomaly detection methods have attracted considerable attention in the hyperspectral remote sensing domain due to the powerful reconstruction ability compared with traditional methods. However, actual probability distribution statistics hidden in the latent space are not discovered by exploiting the reconstruction error because the probability distribution of anomalies is not explicitly modeled. To address the issue, we propose a novel probability distribution representation detector (PDRD) that explores the intrinsic distribution of both the background and the anomalies in original data for hyperspectral anomaly detection in this paper. First, we represent the hyperspectral data with multivariate Gaussian distributions from a probabilistic perspective. Then, we combine the local statistics with the obtained distributions to leverage the spatial information. Finally, the difference between the corresponding distributions of the test pixel and the average expectation of the pixels in the Chebyshev neighborhood is measured by computing the modified Wasserstein distance to acquire the detection map. We conduct the experiments on four real data sets to evaluate the performance of our proposed method. Experimental results demonstrate the accuracy and efficiency of our proposed method compared to the state-of-the-art detection methods.      
### 28.Innovation Compression for Communication-efficient Distributed Optimization with Linear Convergence  [ :arrow_down: ](https://arxiv.org/pdf/2105.06697.pdf)
>  Information compression is essential to reduce communication cost in distributed optimization over peer-to-peer networks. This paper proposes a communication-efficient linearly convergent distributed (COLD) algorithm to solve strongly convex optimization problems. By compressing innovation vectors, which are the differences between decision vectors and their estimates, COLD is able to achieve linear convergence for a class of $\delta$-contracted compressors. We explicitly quantify how the compression affects the convergence rate and show that COLD matches the same rate of its uncompressed version. To accommodate a wider class of compressors that includes the binary quantizer, we further design a novel dynamical scaling mechanism and obtain the linearly convergent Dyna-COLD. Importantly, our results strictly improve existing results for the quantized consensus problem. Numerical experiments demonstrate the advantages of both algorithms under different compressors.      
### 29.Fusion of Heterogeneous Friction Estimates for Traction Adaptive Motion Planning and Control  [ :arrow_down: ](https://arxiv.org/pdf/2105.06692.pdf)
>  Traction adaptive motion planning and control has potential to improve an an automated vehicle's ability to avoid accident in a critical situation. However, such functionality require an accurate friction estimate for the road ahead of the vehicle that is updated in real time. Current state of the art friction estimation techniques include high accuracy local friction estimation in the presence of tire slip, as well as rough classification of the road surface ahead of the vehicle, based on forward looking camera. In this paper we show that neither of these techniques in isolation yield satisfactory behavior when deployed with traction adaptive motion planning and control functionality. However, fusion of the two provides sufficient accuracy, availability and foresight to yield near optimal behavior. To this end, we propose a fusion method based on heteroscedastic gaussian process regression, and present initial simulation based results.      
### 30.Hybrid Device-to-Device and Device-to-Vehicle Networks for Energy-Efficient Emergency Communication  [ :arrow_down: ](https://arxiv.org/pdf/2105.06658.pdf)
>  Considering the energy-efficient emergency response, subject to a given set of constraints on emergency communication networks (ECN), this article proposes a hybrid device-to-device (D2D) and device-to-vehicle (D2V) network for collecting and transmitting emergency information. First, we establish the D2D network from the perspective of complex networks by jointly determining the optimal network partition (ONP) and the temporary data caching centers (TDCC), and thus emergency data can be forwarded and cached in TDCCs. Second, based on the distribution of TDCCs, the D2V network is established by unmanned aerial vehicles (UAV)-based waypoint and motion planning, which saves the time for wireless transmission and aerial moving. Finally, the amount of time for emergency response and the total energy consumption are simultaneously minimized by a multiobjective evolutionary algorithm based on decomposition (MOEA/D), subject to a given set of minimum signal-to-interference- plus-noise ratio (SINR), number of UAVs, transmit power, and energy constraints. Simulation results show that the proposed method significantly improves response efficiency and reasonably controls the energy, thus overcoming limitations of existing ECNs. Therefore, this network effectively solves the key problem in the rescue system and makes great contributions to post-disaster decision-making.      
### 31.Fast Ambiguous DOA Elimination Method of DOA Measurement for Hybrid Massive MIMO Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2105.06634.pdf)
>  DOA estimation for massive multiple-input multiple-output (MIMO) system can provide ultra-high-resolution angle estimation. However, due to the high computational complexity and cost of all digital MIMO systems, a hybrid analog digital (HAD) structure MIMO was proposed. In this paper, a fast ambiguous phase elimination method is proposed to solve the problem of direction-finding ambiguity caused by the HAD MIMO. Only two-data-blocks are used to realize DOA estimation. Simulation results show that the proposed method can greatly reduce the estimation delay with a slight performance loss.      
### 32.On Development of Efficient Data Acquisition Systems and Parameter Extraction Technique for DFB Lasers  [ :arrow_down: ](https://arxiv.org/pdf/2105.06556.pdf)
>  Distributed Feedback Laser plays a key role as a light source component in optical fiber communication systems ranging from metro, long-haul to submarine one thanks to its competitive features of superior narrow spectral width and wavelength cohesion. Characterizing such lasers via obtaining their electrical and spectral data and extracting their internal parameters therefore remains a critical task in designing and troubleshooting optical fiber systems. This paper presents first an agile framework for a rapid collection of laser data via automatic measurement and second an efficient approach for extracting laser internal parameters.      
### 33.Kinematic control design for wheeled mobile robots with longitudinal and lateral slip  [ :arrow_down: ](https://arxiv.org/pdf/2105.06501.pdf)
>  The motion control of wheeled mobile robots at high speeds under adverse ground conditions is a difficult task, since the robots' wheels may be subject to different kinds of slip. This work introduces an adaptive kinematic controller that is capable of solving the trajectory tracking problem of a nonholonomic mobile robot under longitudinal and lateral slip. While the controller can effectively compensate for the longitudinal slip, the lateral slip is a more involved problem to deal with, since nonholonomic robots cannot directly produce movement in the lateral direction. To show that the proposed controller is still able to make the mobile robot follow a reference trajectory under lateral and longitudinal time-varying slip, the solutions of the robot's position and orientation error dynamics are shown to be uniformly ultimately bounded. Numerical simulations are presented to illustrate the robot's performance using the proposed adaptive control law.      

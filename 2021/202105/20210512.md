# ArXiv eess --Wed, 12 May 2021
### 1.ReflectNet -- A Generative Adversarial Method for Single Image Reflection Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2105.05216.pdf)
>  Taking pictures through glass windows almost always produces undesired reflections that degrade the quality of the photo. The ill-posed nature of the reflection removal problem reached the attention of many researchers for more than decades. The main challenge of this problem is the lack of real training data and the necessity of generating realistic synthetic data. In this paper, we proposed a single image reflection removal method based on context understanding modules and adversarial training to efficiently restore the transmission layer without reflection. We also propose a complex data generation model in order to create a large training set with various type of reflections. Our proposed reflection removal method outperforms state-of-the-art methods in terms of PSNR and SSIM on the SIR benchmark dataset.      
### 2.Development of a Multi-Task Learning V-Net for Pulmonary Lobar Segmentation on Computed Tomography and Application to Diseased Lungs  [ :arrow_down: ](https://arxiv.org/pdf/2105.05204.pdf)
>  Automated lobar segmentation allows regional evaluation of lung disease and is important for diagnosis and therapy planning. Advanced statistical workflows permitting such evaluation is a needed area within respiratory medicine; their adoption remains slow, with poor workflow accuracy. Diseased lung regions often produce high-density zones on CT images, limiting an algorithm's execution to specify damaged lobes due to oblique or lacking fissures. This impact motivated developing an improved machine learning method to segment lung lobes that utilises tracheobronchial tree information to enhance segmentation accuracy through the algorithm's spatial familiarity to define lobar extent more accurately. The method undertakes parallel segmentation of lobes and auxiliary tissues simultaneously by employing multi-task learning (MTL) in conjunction with V-Net-attention, a popular convolutional neural network in the imaging realm. In keeping with the model's adeptness for better generalisation, high performance was retained in an external dataset of patients with four distinct diseases: severe lung cancer, COVID-19 pneumonitis, collapsed lungs and Chronic Obstructive Pulmonary Disease (COPD), even though the training data included none of these cases. The benefit of our external validation test is specifically relevant since our choice includes those patients who have diagnosed lung disease with associated radiological abnormalities. To ensure equal rank is given to all segmentations in the main task we report the following performance (Dice score) on a per-segment basis: normal lungs 0.97, COPD 0.94, lung cancer 0.94, COVID-19 pneumonitis 0.94 and collapsed lung 0.92, all at p&lt;0.05. Even segmenting lobes with large deformations on CT images, the model maintained high accuracy. The approach can be readily adopted in the clinical setting as a robust tool for radiologists.      
### 3.On Plug-and-Play Regularization using Linear Denoisers  [ :arrow_down: ](https://arxiv.org/pdf/2105.05177.pdf)
>  In plug-and-play (PnP) regularization, the knowledge of the forward model is combined with a powerful denoiser to obtain state-of-the-art image reconstructions. This is typically done by taking a proximal algorithm such as FISTA or ADMM, and formally replacing the proximal map associated with a regularizer by nonlocal means, BM3D or a CNN denoiser. Each iterate of the resulting PnP algorithm involves some kind of inversion of the forward model followed by denoiser-induced regularization. A natural question in this regard is that of optimality, namely, do the PnP iterations minimize some f+g, where f is a loss function associated with the forward model and g is a regularizer? This has a straightforward solution if the denoiser can be expressed as a proximal map, as was shown to be the case for a class of linear symmetric denoisers. However, this result excludes kernel denoisers such as nonlocal means that are inherently non-symmetric. In this paper, we prove that a broader class of linear denoisers (including symmetric denoisers and kernel denoisers) can be expressed as a proximal map of some convex regularizer g. An algorithmic implication of this result for non-symmetric denoisers is that it necessitates appropriate modifications in the PnP updates to ensure convergence to a minimum of f+g. Apart from the convergence guarantee, the modified PnP algorithms are shown to produce good restorations.      
### 4.Mitigating Smart Meter Asynchrony Error Via Multi-Objective Low Rank Matrix Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2105.05175.pdf)
>  Smart meters (SMs) are being widely deployed by distribution utilities across the U.S. Despite their benefits in real-time monitoring. SMs suffer from certain data quality issues; specifically, unlike phasor measurement units (PMUs) that use GPS for data synchronization, SMs are not perfectly synchronized. The asynchrony error can degrade the monitoring accuracy in distribution networks. To address this challenge, we propose a principal component pursuit (PCP)-based data recovery strategy. Since asynchrony results in a loss of temporal correlation among SMs, the key idea in our solution is to leverage a PCP-based low rank matrix recovery technique to maximize the temporal correlation between multiple data streams obtained from SMs. Further, our approach has a novel multi-objective structure, which allows utilities to precisely refine and recover all SM-measured variables, including voltage and power measurements, while incorporating their inherent dependencies through power flow equations. We have performed numerical experiments using real SM data to demonstrate the effectiveness of the proposed strategy in mitigating the impact of SM asynchrony on distribution grid monitoring.      
### 5.Segmentation of Anatomical Layers and Artifacts in Intravascular Polarization Sensitive Optical Coherence Tomography Using Attending Physician and Boundary Cardinality Lost Terms  [ :arrow_down: ](https://arxiv.org/pdf/2105.05137.pdf)
>  Cardiovascular diseases are the leading cause of death and require a spectrum of diagnostic procedures as well as invasive interventions. Medical imaging is a vital part of the healthcare system, facilitating both diagnosis and guidance for intervention. Intravascular ultrasound and optical coherence tomography are widely available for characterizing coronary stenoses and provide critical vessel parameters to optimize percutaneous intervention. Intravascular polarization-sensitive optical coherence tomography (PS-OCT) can simultaneously provide high-resolution cross-sectional images of vascular structures while also revealing preponderant tissue components such as collagen and smooth muscle and thereby enhance plaque characterization. Automated interpretation of these features would facilitate the objective clinical investigation of the natural history and significance of coronary atheromas. Here, we propose a convolutional neural network model and optimize its performance using a new multi-term loss function to classify the lumen, intima, and media layers in addition to the guidewire and plaque artifacts. Our multi-class classification model outperforms the state-of-the-art methods in detecting the anatomical layers based on accuracy, Dice coefficient, and average boundary error. Furthermore, the proposed model segments two classes of major artifacts and detects the anatomical layers within the thickened vessel wall regions, which were excluded from analysis by other studies. The source code and the trained model are publicly available at <a class="link-external link-https" href="https://github.com/mhaft/OCTseg" rel="external noopener nofollow">this https URL</a> .      
### 6.Energy-optimal Design and Control of Electric Vehicles' Transmissions  [ :arrow_down: ](https://arxiv.org/pdf/2105.05119.pdf)
>  This paper presents models and optimization algorithms to jointly optimize the design and control of the transmission of electric vehicles equipped with one central electric motor (EM). First, considering the required traction power to be given, we identify a convex speed-dependent loss model for the EM. Second, we leverage such a model to devise computationally-efficient algorithms to determine the energy-optimal design and control strategies for the transmission. In particular, with the objective of minimizing the EM energy consumption on a given drive cycle, we analytically compute the optimal gear-ratio trajectory for a continuously variable transmission (CVT) and the optimal gear-ratio design for a fixed-gear transmission (FGT) in closed form, whilst efficiently solving the combinatorial joint gear-ratio design and control problem for a multiple-gear transmission (MGT), combining convex analysis and dynamic programming in an iterative fashion. Third, we validate our models with nonlinear simulations, and benchmark the optimality of our methods with mixed-integer quadratic programming. Finally, we showcase our framework in a case-study for a family vehicle, whereby we leverage the computational efficiency of our methods to jointly optimize the EM size via exhaustive search. Our numerical results show that by using a 2-speed MGT, the energy consumption of an electric vehicle can be reduced by 3% and 2.5% compared to an FGT and a CVT, respectively, whilst further increasing the number of gears may even be detrimental due to the additional weight      
### 7.Over-the-Air Computation via Reconfigurable Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2105.05113.pdf)
>  Over-the-air computation (AirComp) is a disruptive technique for fast wireless data aggregation in Internet of Things (IoT) networks via exploiting the waveform superposition property of multiple-access channels. However, the performance of AirComp is bottlenecked by the worst channel condition among all links between the IoT devices and the access point. In this paper, a reconfigurable intelligent surface (RIS) assisted AirComp system is proposed to boost the received signal power and thus mitigate the performance bottleneck by reconfiguring the propagation channels. With an objective to minimize the AirComp distortion, we propose a joint design of AirComp transceivers and RIS phase-shifts, which however turns out to be a highly intractable non-convex programming problem. To this end, we develop a novel alternating minimization framework in conjunction with the successive convex approximation technique, which is proved to converge monotonically. To reduce the computational complexity, we transform the subproblem in each alternation as a smooth convex-concave saddle point problem, which is then tackled by proposing a Mirror-Prox method that only involves a sequence of closed-form updates. Simulations show that the computation time of the proposed algorithm can be two orders of magnitude smaller than that of the state-of-the-art algorithms, while achieving a similar distortion performance.      
### 8.Understanding Deep MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.05044.pdf)
>  Incorporating deep learning (DL) into multiple-input multiple-output (MIMO) detection has been deemed as a promising technique for future wireless communications. However, most DL-based detection algorithms are lack of theoretical interpretation on internal mechanisms and could not provide general guidance on network design. In this paper, we analyze the performance of DL-based MIMO detection to better understand its strengths and weaknesses. We investigate two different architectures: a data-driven DL detector with a neural network activated by rectifier linear unit (ReLU) function and a model-driven DL detector from unfolding a traditional iterative detection algorithm. We demonstrate that data-driven DL detector asymptotically approaches to the maximum a posterior (MAP) detector in various scenarios but requires enough training samples to converge in time-varying channels. On the other hand, the model-driven DL detector utilizes model expert knowledge to alleviate the impact of channels and establish a relatively reliable detection method with a small set of training data. Due to its model specific property, the performance of model-driven DL detector is largely determined by the underlying iterative detection algorithm, which is usually suboptimal compared to the MAP detector. Simulation results confirm our analytical results and demonstrate the effectiveness of DL-based MIMO detection for both linear and nonlinear signal systems.      
### 9.English Accent Accuracy Analysis in a State-of-the-Art Automatic Speech Recognition System  [ :arrow_down: ](https://arxiv.org/pdf/2105.05041.pdf)
>  Nowadays, research in speech technologies has gotten a lot out thanks to recently created public domain corpora that contain thousands of recording hours. These large amounts of data are very helpful for training the new complex models based on deep learning technologies. However, the lack of dialectal diversity in a corpus is known to cause performance biases in speech systems, mainly for underrepresented dialects. In this work, we propose to evaluate a state-of-the-art automatic speech recognition (ASR) deep learning-based model, using unseen data from a corpus with a wide variety of labeled English accents from different countries around the world. The model has been trained with 44.5K hours of English speech from an open access corpus called Multilingual LibriSpeech, showing remarkable results in popular benchmarks. We test the accuracy of such ASR against samples extracted from another public corpus that is continuously growing, the Common Voice dataset. Then, we present graphically the accuracy in terms of Word Error Rate of each of the different English included accents, showing that there is indeed an accuracy bias in terms of accentual variety, favoring the accents most prevalent in the training corpus.      
### 10.Optimal Receive Beamforming for Over-the-Air Computation  [ :arrow_down: ](https://arxiv.org/pdf/2105.05024.pdf)
>  In this paper, we consider fast wireless data aggregation via over-the-air computation (AirComp) in Internet of Things (IoT) networks, where an access point (AP) with multiple antennas aim to recover the arithmetic mean of sensory data from multiple IoT devices. To minimize the estimation distortion, we formulate a mean-squared-error (MSE) minimization problem that involves the joint optimization of the transmit scalars at the IoT devices as well as the denoising factor and the receive beamforming vector at the AP. To this end, we derive the transmit scalars and the denoising factor in closed-form, resulting in a non-convex quadratic constrained quadratic programming (QCQP) problem concerning the receive beamforming vector.Different from the existing studies that only obtain sub-optimal beamformers, we propose a branch and bound (BnB) algorithm to design the globally optimal receive beamformer.Extensive simulations demonstrate the superior performance of the proposed algorithm in terms of MSE. Moreover, the proposed BnB algorithm can serve as a benchmark to evaluate the performance of the existing sub-optimal algorithms.      
### 11.Reducing Streaming ASR Model Delay with Self Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2105.05005.pdf)
>  Reducing prediction delay for streaming end-to-end ASR models with minimal performance regression is a challenging problem. Constrained alignment is a well-known existing approach that penalizes predicted word boundaries using external low-latency acoustic models. On the contrary, recently proposed FastEmit is a sequence-level delay regularization scheme encouraging vocabulary tokens over blanks without any reference alignments. Although all these schemes are successful in reducing delay, ASR word error rate (WER) often severely degrades after applying these delay constraining schemes. In this paper, we propose a novel delay constraining method, named self alignment. Self alignment does not require external alignment models. Instead, it utilizes Viterbi forced-alignments from the trained model to find the lower latency alignment direction. From LibriSpeech evaluation, self alignment outperformed existing schemes: 25% and 56% less delay compared to FastEmit and constrained alignment at the similar word error rate. For Voice Search evaluation,12% and 25% delay reductions were achieved compared to FastEmit and constrained alignment with more than 2% WER improvements.      
### 12.Weighted Hierarchical Sparse Representation for Hyperspectral Target Detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.04990.pdf)
>  Hyperspectral target detection has been widely studied in the field of remote sensing. However, background dictionary building issue and the correlation analysis of target and background dictionary issue have not been well studied. To tackle these issues, a \emph{Weighted Hierarchical Sparse Representation} for hyperspectral target detection is proposed. The main contributions of this work are listed as follows. 1) Considering the insufficient representation of the traditional background dictionary building by dual concentric window structure, a hierarchical background dictionary is built considering the local and global spectral information simultaneously. 2) To reduce the impureness impact of background dictionary, target scores from target dictionary and background dictionary are weighted considered according to the dictionary quality. Three hyperspectral target detection data sets are utilized to verify the effectiveness of the proposed method. And the experimental results show a better performance when compared with the state-of-the-arts.      
### 13.Task-related self-supervised learning for remote sensing image change detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.04951.pdf)
>  Change detection for remote sensing images is widely applied for urban change detection, disaster assessment and other fields. However, most of the existing CNN-based change detection methods still suffer from the problem of inadequate pseudo-changes suppression and insufficient feature representation. In this work, an unsupervised change detection method based on Task-related Self-supervised Learning Change Detection network with smooth mechanism(TSLCD) is proposed to eliminate it. The main contributions include: (1) the task-related self-supervised learning module is introduced to extract spatial features more effectively. (2) a hard-sample-mining loss function is applied to pay more attention to the hard-to-classify samples. (3) a smooth mechanism is utilized to remove some of pseudo-changes and noise. Experiments on four remote sensing change detection datasets reveal that the proposed TSLCD method achieves the state-of-the-art for change detection task.      
### 14.Applications of Deep Learning Techniques for Automated Multiple Sclerosis Detection Using Magnetic Resonance Imaging: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2105.04881.pdf)
>  Multiple Sclerosis (MS) is a type of brain disease which causes visual, sensory, and motor problems for people with a detrimental effect on the functioning of the nervous system. In order to diagnose MS, multiple screening methods have been proposed so far; among them, magnetic resonance imaging (MRI) has received considerable attention among physicians. MRI modalities provide physicians with fundamental information about the structure and function of the brain, which is crucial for the rapid diagnosis of MS lesions. Diagnosing MS using MRI is time-consuming, tedious, and prone to manual errors. Hence, computer aided diagnosis systems (CADS) based on artificial intelligence (AI) methods have been proposed in recent years for accurate diagnosis of MS using MRI neuroimaging modalities. In the AI field, automated MS diagnosis is being conducted using (i) conventional machine learning and (ii) deep learning (DL) techniques. The conventional machine learning approach is based on feature extraction and selection by trial and error. In DL, these steps are performed by the DL model itself. In this paper, a complete review of automated MS diagnosis methods performed using DL techniques with MRI neuroimaging modalities are discussed. Also, each work is thoroughly reviewed and discussed. Finally, the most important challenges and future directions in the automated MS diagnosis using DL techniques coupled with MRI modalities are presented in detail.      
### 15.Asymptotically Optimal Procedures for Sequential Joint Detection and Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2105.04828.pdf)
>  We investigate the problem of jointly testing multiple hypotheses and estimating a random parameter of the underlying distribution in a sequential setup. The aim is to jointly infer the true hypothesis and the true parameter while using on average as few samples as possible and keeping the detection and estimation errors below predefined levels. Based on mild assumptions on the underlying model, we propose an asymptotically optimal procedure, i.e., a procedure that becomes optimal when the tolerated detection and estimation error levels tend to zero. The implementation of the resulting asymptotically optimal stopping rule is computationally cheap and, hence, applicable for high-dimensional data. We further propose a projected quasi-Newton method to optimally chose the coefficients that parameterize the instantaneous cost function such that the constraints are fulfilled with equality. The proposed theory is validated by numerical examples.      
### 16.Deep scattering network for speech emotion recognition  [ :arrow_down: ](https://arxiv.org/pdf/2105.04806.pdf)
>  This paper introduces scattering transform for speech emotion recognition (SER). Scattering transform generates feature representations which remain stable to deformations and shifting in time and frequency without much loss of information. In speech, the emotion cues are spread across time and localised in frequency. The time and frequency invariance characteristic of scattering coefficients provides a representation robust against emotion irrelevant variations e.g., different speakers, language, gender etc. while preserving the variations caused by emotion cues. Hence, such a representation captures the emotion information more efficiently from speech. We perform experiments to compare scattering coefficients with standard mel-frequency cepstral coefficients (MFCCs) over different databases. It is observed that frequency scattering performs better than time-domain scattering and MFCCs. We also investigate layer-wise scattering coefficients to analyse the importance of time shift and deformation stable scalogram and modulation spectrum coefficients for SER. We observe that layer-wise coefficients taken independently also perform better than MFCCs.      
### 17.Equivariant Systems Theory and Observer Design for Second Order Kinematic Systems on Matrix Lie Groups  [ :arrow_down: ](https://arxiv.org/pdf/2105.04797.pdf)
>  This paper presents the equivariant systems theory and observer design for second order kinematic systems on matrix Lie groups. The state of a second order kinematic system on a matrix Lie group is naturally posed on the tangent bundle of the group with the inputs lying in the tangent of the tangent bundle known as the double tangent bundle. We provide a simple parameterization of both the tangent bundle state space and the input space (the fiber space of the double tangent bundle) and then introduce a semi-direct product group and group actions onto both the state and input spaces. We show that with the proposed group actions the second order kinematics are equivariant. An equivariant lift of the kinematics onto the symmetry group is defined and used to design a nonlinear observer on the lifted state space using nonlinear constructive design techniques. A simple hovercraft simulation verifies the performance of our observer.      
### 18.A Simple Bound for Resilient Submodular Maximization with Curvature  [ :arrow_down: ](https://arxiv.org/pdf/2105.04793.pdf)
>  Resilient submodular maximization refers to the combinatorial problems studied by Nemhauser and Fisher and asks how to maximize an objective given a number of adversarial removals. For example, one application of this problem is multi-robot sensor planning with adversarial attacks. However, more general applications of submodular maximization are also relevant. Tzoumas et al. obtain near-optimal solutions to this problem by taking advantage of a property called curvature to produce a mechanism which makes certain bait elements interchangeable with other elements of the solution that are produced via typical greedy means. This document demonstrates that -- at least in theory -- applying the method for selection of bait elements to the entire solution can improve that guarantee on solution quality.      
### 19.HAPS-ITS: Enabling Future ITS Services in Trans-Continental Highways  [ :arrow_down: ](https://arxiv.org/pdf/2105.04756.pdf)
>  As the world we live in becomes smaller and more interconnected, with people and goods traveling for thousands of kilometers to reach their destinations, the reliability and efficiency of transportation systems have become critical. Indeed, trans-continental highways need particular attention due to their important role in sustaining globalization. In this context, intelligent transportation systems (ITS) can actively enhance the safety, mobility, productivity, and comfort of trans-continental highways. However, ITS efficiency depends greatly on the roads where they are deployed, on the availability of power and connectivity, and on the integration of future connected and autonomous vehicles. To this end, high altitude platform station (HAPS) systems, due to their mobility, sustainability, payload capacity, and communication/caching/computing capabilities, are seen as a key enabler of future ITS services for trans-continental highways; this paradigm is referred to as HAPS-ITS. The latter is envisioned as an active component of ITS systems to support a plethora of transportation applications, such as traffic monitoring, accident reporting, and platooning. This paper discusses how HAPS systems can enable advanced ITS services for trans-continental highways, presenting the main requirements of HAPS-ITS and a detailed case study of the Trans-Sahara highway.      
### 20.Differentiable Signal Processing With Black-Box Audio Effects  [ :arrow_down: ](https://arxiv.org/pdf/2105.04752.pdf)
>  We present a data-driven approach to automate audio signal processing by incorporating stateful third-party, audio effects as layers within a deep neural network. We then train a deep encoder to analyze input audio and control effect parameters to perform the desired signal manipulation, requiring only input-target paired audio data as supervision. To train our network with non-differentiable black-box effects layers, we use a fast, parallel stochastic gradient approximation scheme within a standard auto differentiation graph, yielding efficient end-to-end backpropagation. We demonstrate the power of our approach with three separate automatic audio production applications: tube amplifier emulation, automatic removal of breaths and pops from voice recordings, and automatic music mastering. We validate our results with a subjective listening test, showing our approach not only can enable new automatic audio effects tasks, but can yield results comparable to a specialized, state-of-the-art commercial solution for music mastering.      
### 21.Parameter Estimation in Epidemic Spread Networks Using Limited Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2105.04750.pdf)
>  We study the problem of estimating the parameters (i.e., infection rate and recovery rate) governing the spread of epidemics in networks. Such parameters are typically estimated by measuring various characteristics (such as the number of infected and recovered individuals) of the infected populations over time. However, these measurements also incur certain costs, depending on the population being tested and the times at which the tests are administered. We thus formulate the epidemic parameter estimation problem as an optimization problem, where the goal is to either minimize the total cost spent on collecting measurements, or to optimize the parameter estimates while remaining within a measurement budget. We show that these problems are NP-hard to solve in general, and then propose approximation algorithms with performance guarantees. We validate our algorithms using numerical examples.      
### 22.Optimal Online Algorithms for Peak-Demand Reduction Maximization with Energy Storage  [ :arrow_down: ](https://arxiv.org/pdf/2105.04728.pdf)
>  The high proportions of demand charges in electric bills motivate large-power customers to leverage energy storage for reducing the peak procurement from the outer grid. Given limited energy storage, we expect to maximize the peak-demand reduction in an online fashion, challenged by the highly uncertain demands and renewable injections, the non-cumulative nature of peak consumption, and the coupling of online decisions. In this paper, we propose an optimal online algorithm that achieves the best competitive ratio, following the idea of maintaining a constant ratio between the online and the optimal offline peak-reduction performance. We further show that the optimal competitive ratio can be computed by solving a linear number of linear-fractional programs. Moreover, we extend the algorithm to adaptively maintain the best competitive ratio given the revealed inputs and actions at each decision-making round. The adaptive algorithm retains the optimal worst-case guarantee and attains improved average-case performance. We evaluate our proposed algorithms using real-world traces and show that they obtain up to 81% peak reduction of the optimal offline benchmark. Additionally, the adaptive algorithm achieves at least 20% more peak reduction against baseline alternatives.      
### 23.Automated quantitative analysis of first-pass myocardial perfusion magnetic resonance imaging data  [ :arrow_down: ](https://arxiv.org/pdf/2105.04690.pdf)
>  Coronary artery disease (CAD) remains the world's leading cause of mortality and the disease burden is continually expanding as the population ages. Recently, the MR-INFORM randomised trial has demonstrated that the management of patients with stable CAD can be guided by stress perfusion cardiovascular magnetic resonance (CMR) imaging and it is non-inferior to the using the invasive reference standard of fractional flow reserve. The benefits of using stress perfusion CMR include that it is non-invasive and significantly reduces the number of unnecessary coronary revascularisations. As compared to other ischaemia tests, it boasts a high spatial resolution and does not expose the patient to ionising radiation. However, the main limitation of stress perfusion CMR is that the diagnostic accuracy is highly dependent on the level of training of the operator, resulting in the test only being performed routinely in experienced tertiary centres. The clinical translation of stress perfusion CMR would be greatly aided by a fully automated, user-independent, quantitative evaluation of myocardial blood flow. This thesis presents major steps towards this goal: robust motion correction, automated image processing, reliable quantitative modelling, and thorough validation. The motion correction scheme makes use of data decomposition techniques, such as robust principal component analysis, to mitigate the difficulties in image registration caused by the dynamic contrast enhancement. The motion corrected image series are input to a processing pipeline which leverages the recent advances in image processing facilitated by deep learning. The pipeline utilises convolutional neural networks to perform a series of computer vision tasks including myocardial segmentation and right ventricular insertion point detection...      
### 24.Different Environment Feedback in Fast-slow Eco-evolutionary Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2105.04659.pdf)
>  The fast-slow dynamics of an eco-evolutionary system are studied, where we consider the feedback actions of environmental resources that are classified into those that are self-renewing and those externally supplied. We show although these two types of resources are drastically different, the resulting closed-loop systems bear close resemblances, which include the same equilibria and their stability conditions on the boundary of the phase space, and the similar appearances of equilibria in the interior. After closer examination of specific choices of parameter values, we disclose that the global dynamical behaviors of the two types of closed-loop systems can be fundamentally different in terms of limit cycles: the system with self-renewing resources undergoes a generalized Hopf bifurcation such that one stable limit cycle and one unstable limit cycle can coexist; the system with externally supplied resources can only have the stable limit cycle induced by a supercritical Hopf bifurcation. Finally, the explorative analysis is carried out to show the discovered dynamic behaviors are robust in even larger parameter space.      
### 25.Cross-Corpora Language Recognition: A Preliminary Investigation with Indian Languages  [ :arrow_down: ](https://arxiv.org/pdf/2105.04639.pdf)
>  In this paper, we conduct one of the very first studies for cross-corpora performance evaluation in the spoken language identification (LID) problem. Cross-corpora evaluation was not explored much in LID research, especially for the Indian languages. We have selected three Indian spoken language corpora: IIITH-ILSC, LDC South Asian, and IITKGP-MLILSC. For each of the corpus, LID systems are trained on the state-of-the-art time-delay neural network (TDNN) based architecture with MFCC features. We observe that the LID performance degrades drastically for cross-corpora evaluation. For example, the system trained on the IIITH-ILSC corpus shows an average EER of 11.80 % and 43.34 % when evaluated with the same corpora and LDC South Asian corpora, respectively. Our preliminary analysis shows the significant differences among these corpora in terms of mismatch in the long-term average spectrum (LTAS) and signal-to-noise ratio (SNR). Subsequently, we apply different feature level compensation methods to reduce the cross-corpora acoustic mismatch. Our results indicate that these feature normalization schemes can help to achieve promising LID performance on cross-corpora experiments.      
### 26.Freshness Based Cache Updating in Parallel Relay Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.05237.pdf)
>  We consider a system consisting of a server, which receives updates for $N$ files according to independent Poisson processes. The goal of the server is to deliver the latest version of the files to the user through a parallel network of $K$ caches. We consider an update received by the user successful, if the user receives the same file version that is currently prevailing at the server. We derive an analytical expression for information freshness at the user. We observe that freshness for a file increases with increase in consolidation of rates across caches. To solve the multi-cache problem, we first solve the auxiliary problem of a single-cache system. We then rework this auxiliary solution to our parallel-cache network by consolidating rates to single routes as much as possible. This yields an approximate (sub-optimal) solution for the original problem. We provide an upper bound on the gap between the sub-optimal solution and the optimal solution. Numerical results show that the sub-optimal policy closely approximates the optimal policy.      
### 27.Stochastic Formulation of Causal Digital Twin: Kalman Filter Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2105.05236.pdf)
>  We provide some basic and sensible definitions of different types of digital twins and recommendations on when and how to use them. Following up on our recent publication of the Learning Causal Digital Twin, this article reports on a stochastic formulation and solution of the problem. Structural Vector Autoregressive Model (SVAR) for Causal estimation is recast as a state-space model. Kalman filter (and smoother) is then employed to estimate causal factors in a system of connected machine bearings. The previous neural network algorithm and Kalman Smoother produced very similar results; however, Kalman Filter/Smoother may show better performance for noisy data from industrial IoT sources.      
### 28.A Spectral Representation of Power Systems with Applications to Adaptive Grid Partitioning and Cascading Failure Localization  [ :arrow_down: ](https://arxiv.org/pdf/2105.05234.pdf)
>  Transmission line failures in power systems propagate and cascade non-locally. This well-known yet counter-intuitive feature makes it even more challenging to optimally and reliably operate these complex networks. In this work we present a comprehensive framework based on spectral graph theory that fully and rigorously captures how multiple simultaneous line failures propagate, distinguishing between non-cut and cut set outages. Using this spectral representation of power systems, we identify the crucial graph sub-structure that ensures line failure localization -- the network bridge-block decomposition. Leveraging this theory, we propose an adaptive network topology reconfiguration paradigm that uses a two-stage algorithm where the first stage aims to identify optimal clusters using the notion of network modularity and the second stage refines the clusters by means of optimal line switching actions. Our proposed methodology is illustrated using extensive numerical examples on standard IEEE networks and we discussed several extensions and variants of the proposed algorithm.      
### 29.Source-Level Bitwise Branching for Temporal Verification of Lifted Binaries  [ :arrow_down: ](https://arxiv.org/pdf/2105.05159.pdf)
>  There is increasing interest in applying verification tools to programs that have bitvector operations (eg., binaries). SMT solvers, which serve as a foundation for these tools, have thus increased support for bitvector reasoning through bit-blasting and linear arithmetic approximations. In this paper we show that similar linear arithmetic approximation of bitvector operations can be done at the source level through transformations. Specifically, we introduce new paths that over-approximate bitvector operations with linear conditions/constraints, increasing branching but allowing us to better exploit the well-developed integer reasoning and interpolation of verification tools. We show that, for reachability of bitvector programs, increased branching incurs negligible overhead yet, when combined with integer interpolation optimizations, enables more programs to be verified. We further show this exploitation of integer interpolation in the common case also enables competitive termination verification of bitvector programs and leads to the first effective technique for LTL verification of bitvector programs. Finally, we provide an in-depth case study of decompiled ("lifted") binary programs, which emulate X86 execution through frequent use of bitvector operations. We present a new tool DarkSea, the first tool capable of verifying reachability, termination, and LTL of such lifted binaries.      
### 30.Continuous User Authentication using IoT Wearable Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2105.05126.pdf)
>  Over the past several years, the electrocardiogram (ECG) has been investigated for its uniqueness and potential to discriminate between individuals. This paper discusses how this discriminatory information can help in continuous user authentication by a wearable chest strap which uses dry electrodes to obtain a single lead ECG signal. To the best of the authors' knowledge, this is the first such work which deals with continuous authentication using a genuine wearable device as most prior works have either used medical equipment employing gel electrodes to obtain an ECG signal or have obtained an ECG signal through electrode positions that would not be feasible using a wearable device. Prior works have also mainly dealt with using the ECG signal for identification rather than verification, or dealt with using the ECG signal for discrete authentication. This paper presents a novel algorithm which uses QRS detection, weighted averaging, Discrete Cosine Transform (DCT), and a Support Vector Machine (SVM) classifier to determine whether the wearer of the device should be positively verified or not. Zero intrusion attempts were successful when tested on a database consisting of 33 subjects.      
### 31.Sparse Linear Precoders for Mitigating Nonlinearities in Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2105.05086.pdf)
>  Dealing with nonlinear effects of the radio-frequency(RF) chain is a key issue in the realization of very large-scale multi-antenna (MIMO) systems. Achieving the remarkable gains possible with massive MIMO requires that the signal processing algorithms systematically take into account these effects. Here, we present a computationally efficient linear precoding method satisfying the requirements for low peak-to-average power ratio (PAPR) and low-resolution D/A-converters (DACs). The method is based on a sparse regularization of the precoding matrix and offers advantages in terms of precoded signal PAPR as well as processing complexity. Through simulation, we find that the method substantially improves conventional linear precoders.      
### 32.What Will the Future of UAV Cellular Communications Be? A Flight from 5G to 6G  [ :arrow_down: ](https://arxiv.org/pdf/2105.04842.pdf)
>  What will the future of UAV cellular communications be? In this tutorial article, we address such a compelling yet difficult question by embarking on a journey from 5G to 6G and sharing a large number of realistic case studies supported by original results. We start by overviewing the status quo on UAV communications from an industrial standpoint, providing fresh updates from the 3GPP and detailing new 5G NR features in support of aerial devices. We then show the potential and the limitations of such features. In particular, we demonstrate how sub-6 GHz massive MIMO can successfully tackle cell selection and interference challenges, we showcase encouraging mmWave coverage evaluations in both urban and suburban/rural settings, and we examine the peculiarities of direct device-to-device communications in the sky. Moving on, we sneak a peek at next-generation UAV communications, listing some of the use cases envisioned for the 2030s. We identify the most promising 6G enablers for UAV communication, those expected to take the performance and reliability to the next level. For each of these disruptive new paradigms (non-terrestrial networks, cell-free architectures, artificial intelligence, reconfigurable intelligent surfaces, and THz communications), we gauge the prospective benefits for UAVs and discuss the main technological hurdles that stand in the way. All along, we distil our numerous findings into essential takeaways, and we identify key open problems worthy of further study.      
### 33.Exact Recovery in the General Hypergraph Stochastic Block Model  [ :arrow_down: ](https://arxiv.org/pdf/2105.04770.pdf)
>  This paper investigates fundamental limits of exact recovery in the general d-uniform hypergraph stochastic block model (d-HSBM), wherein n nodes are partitioned into k disjoint communities with relative sizes (p1,..., pk). Each subset of nodes with cardinality d is generated independently as an order-d hyperedge with a certain probability that depends on the ground-truth communities that the d nodes belong to. The goal is to exactly recover the k hidden communities based on the observed hypergraph. We show that there exists a sharp threshold such that exact recovery is achievable above the threshold and impossible below the threshold (apart from a small regime of parameters that will be specified precisely). This threshold is represented in terms of a quantity which we term as the generalized Chernoff-Hellinger divergence between communities. Our result for this general model recovers prior results for the standard SBM and d-HSBM with two symmetric communities as special cases. En route to proving our achievability results, we develop a polynomial-time two-stage algorithm that meets the threshold. The first stage adopts a certain hypergraph spectral clustering method to obtain a coarse estimate of communities, and the second stage refines each node individually via local refinement steps to ensure exact recovery.      
### 34.Autonomous Situational Awareness for Robotic Swarms in High-Risk Environments  [ :arrow_down: ](https://arxiv.org/pdf/2105.04764.pdf)
>  This paper describes a technique for the autonomous mission planning of robotic swarms in high risk environments where agent disablement is likely. Given a swarm operating in a known area, a central command system generates measurements from the swarm. If those measurements indicate changes to the mission situation such as target movement or agent loss, the swarm planning is updated to reflect the new situation and guidance updates are broadcast to the swarm. The primary algorithms featured in this work are A* pathfinding and the Generalized Labeled Multi-Bernoulli multi-object tracking method.      
### 35.Separate but Together: Unsupervised Federated Learning for Speech Enhancement from Non-IID Data  [ :arrow_down: ](https://arxiv.org/pdf/2105.04727.pdf)
>  We propose FEDENHANCE, an unsupervised federated learning (FL) approach for speech enhancement and separation with non-IID distributed data across multiple clients. We simulate a real-world scenario where each client only has access to a few noisy recordings from a limited and disjoint number of speakers (hence non-IID). Each client trains their model in isolation using mixture invariant training while periodically providing updates to a central server. Our experiments show that our approach achieves competitive enhancement performance compared to IID training on a single device and that we can further facilitate the convergence speed and the overall performance using transfer learning on the server-side. Moreover, we show that we can effectively combine updates from clients trained locally with supervised and unsupervised losses. We also release a new dataset LibriFSD50K and its creation recipe in order to facilitate FL research for source separation problems.      
### 36.Speech2Slot: An End-to-End Knowledge-based Slot Filling from Speech  [ :arrow_down: ](https://arxiv.org/pdf/2105.04719.pdf)
>  In contrast to conventional pipeline Spoken Language Understanding (SLU) which consists of automatic speech recognition (ASR) and natural language understanding (NLU), end-to-end SLU infers the semantic meaning directly from speech and overcomes the error propagation caused by ASR. End-to-end slot filling (SF) from speech is an essential component of end-to-end SLU, and is usually regarded as a sequence-to-sequence generation problem, heavily relied on the performance of language model of ASR. However, it is hard to generate a correct slot when the slot is out-of-vovabulary (OOV) in training data, especially when a slot is an anti-linguistic entity without grammatical rule. Inspired by object detection in computer vision that is to detect the object from an image, we consider SF as the task of slot detection from speech. In this paper, we formulate the SF task as a matching task and propose an end-to-end knowledge-based SF model, named Speech-to-Slot (Speech2Slot), to leverage knowledge to detect the boundary of a slot from the speech. We also release a large-scale dataset of Chinese speech for slot filling, containing more than 830,000 samples. The experiments show that our approach is markedly superior to the conventional pipeline SLU approach, and outperforms the state-of-the-art end-to-end SF approach with 12.51% accuracy improvement.      
### 37.Personalized Popular Music Generation Using Imitation and Structure  [ :arrow_down: ](https://arxiv.org/pdf/2105.04709.pdf)
>  Many practices have been presented in music generation recently. While stylistic music generation using deep learning techniques has became the main stream, these models still struggle to generate music with high musicality, different levels of music structure, and controllability. In addition, more application scenarios such as music therapy require imitating more specific musical styles from a few given music examples, rather than capturing the overall genre style of a large data corpus. To address requirements that challenge current deep learning methods, we propose a statistical machine learning model that is able to capture and imitate the structure, melody, chord, and bass style from a given example seed song. An evaluation using 10 pop songs shows that our new representations and methods are able to create high-quality stylistic music that is similar to a given input song. We also discuss potential uses of our approach in music evaluation and music therapy.      
### 38.Value Iteration in Continuous Actions, States and Time  [ :arrow_down: ](https://arxiv.org/pdf/2105.04682.pdf)
>  Classical value iteration approaches are not applicable to environments with continuous states and actions. For such environments, the states and actions are usually discretized, which leads to an exponential increase in computational complexity. In this paper, we propose continuous fitted value iteration (cFVI). This algorithm enables dynamic programming for continuous states and actions with a known dynamics model. Leveraging the continuous-time formulation, the optimal policy can be derived for non-linear control-affine dynamics. This closed-form solution enables the efficient extension of value iteration to continuous environments. We show in non-linear control experiments that the dynamic programming solution obtains the same quantitative performance as deep reinforcement learning methods in simulation but excels when transferred to the physical system. The policy obtained by cFVI is more robust to changes in the dynamics despite using only a deterministic model and without explicitly incorporating robustness in the optimization. Videos of the physical system are available at \url{<a class="link-external link-https" href="https://sites.google.com/view/value-iteration" rel="external noopener nofollow">this https URL</a>}.      
### 39.What shall we do with an hour of data? Speech recognition for the un- and under-served languages of Common Voice  [ :arrow_down: ](https://arxiv.org/pdf/2105.04674.pdf)
>  This technical report describes the methods and results of a three-week sprint to produce deployable speech recognition models for 31 under-served languages of the Common Voice project. We outline the preprocessing steps, hyperparameter selection, and resulting accuracy on official testing sets. In addition to this we evaluate the models on multiple tasks: closed-vocabulary speech recognition, pre-transcription, forced alignment, and key-word spotting. The following experiments use Coqui STT, a toolkit for training and deployment of neural Speech-to-Text models.      
### 40.Stabilizability of Vector Systems with UniformActuation Unpredictability  [ :arrow_down: ](https://arxiv.org/pdf/2105.04652.pdf)
>  This paper explores the fundamental limits of a simple system, inspired by the intermittent Kalman filtering model, where the actuation direction is drawn uniformly from the unit hypersphere. The model allows us to focus on a fundamental tension in the control of underactuated vector systems -- the need to balance the growth of the system in different dimensions. <br>We characterize the stabilizability of $d$-dimensional systems with symmetric gain matrices by providing tight necessary and sufficient conditions that depend on the eigenvalues of the system. The proof technique is slightly different from the standard dynamic programming approach and relies on the fact that the second moment stability of the system can also be understood by examining any arbitrary weighted two-norm of the state.      

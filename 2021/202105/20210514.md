# ArXiv eess --Fri, 14 May 2021
### 1.End-to-End Sequential Sampling and Reconstruction for MR Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2105.06460.pdf)
>  Accelerated MRI shortens acquisition time by subsampling in the measurement k-space. Recovering a high-fidelity anatomical image from subsampled measurements requires close cooperation between two components: (1) a sampler that chooses the subsampling pattern and (2) a reconstructor that recovers images from incomplete measurements. In this paper, we leverage the sequential nature of MRI measurements, and propose a fully differentiable framework that jointly learns a sequential sampling policy simultaneously with a reconstruction strategy. This co-designed framework is able to adapt during acquisition in order to capture the most informative measurements for a particular target (Figure 1). Experimental results on the fastMRI knee dataset demonstrate that the proposed approach successfully utilizes intermediate information during the sampling process to boost reconstruction performance. In particular, our proposed method outperforms the current state-of-the-art learned k-space sampling baseline on up to 96.96% of test samples. We also investigate the individual and collective benefits of the sequential sampling and co-design strategies. Code and more visualizations are available at <a class="link-external link-http" href="http://imaging.cms.caltech.edu/seq-mri" rel="external noopener nofollow">this http URL</a>      
### 2.Manipulation Detection in Satellite Images Using Vision Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2105.06373.pdf)
>  A growing number of commercial satellite companies provide easily accessible satellite imagery. Overhead imagery is used by numerous industries including agriculture, forestry, natural disaster analysis, and meteorology. Satellite images, just as any other images, can be tampered with image manipulation tools. Manipulation detection methods created for images captured by "consumer cameras" tend to fail when used on satellite images due to the differences in image sensors, image acquisition, and processing. In this paper we propose an unsupervised technique that uses a Vision Transformer to detect spliced areas within satellite images. We introduce a new dataset which includes manipulated satellite images that contain spliced objects. We show that our proposed approach performs better than existing unsupervised splicing detection techniques.      
### 3.Gait Characterization in Duchenne Muscular Dystrophy (DMD) Using a Single-Sensor Accelerometer: Classical Machine Learning and Deep Learning Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2105.06295.pdf)
>  Differences in gait patterns of children with Duchenne muscular dystrophy (DMD) and typically developing (TD) peers are visible to the eye, but quantification of those differences outside of the gait laboratory has been elusive. We measured vertical, mediolateral, and anteroposterior acceleration using a waist-worn iPhone accelerometer during ambulation across a typical range of velocities. Six TD and six DMD children from 3-15 years of age underwent seven walking/running tasks, including five 25m walk/run tests at a slow walk to running speeds, a 6-minute walk test (6MWT), and a 100-meter-run/walk (100MRW). We extracted temporospatial clinical gait features (CFs) and applied multiple Artificial Intelligence (AI) tools to differentiate between DMD and TD control children using extracted features and raw data. Extracted CFs showed reduced step length and a greater mediolateral component of total power (TP) consistent with shorter strides and Trendelenberg-like gait commonly observed in DMD. AI methods using CFs and raw data varied ineffectiveness at differentiating between DMD and TD controls at different speeds, with an accuracy of some methods exceeding 91%. We demonstrate that by using AI tools with accelerometer data from a consumer-level smartphone, we can identify DMD gait disturbance in toddlers to early teens.      
### 4.Electrocardio Panorama: Synthesizing New ECG Views with Self-supervision  [ :arrow_down: ](https://arxiv.org/pdf/2105.06293.pdf)
>  Multi-lead electrocardiogram (ECG) provides clinical information of heartbeats from several fixed viewpoints determined by the lead positioning. However, it is often not satisfactory to visualize ECG signals in these fixed and limited views, as some clinically useful information is represented only from a few specific ECG viewpoints. For the first time, we propose a new concept, Electrocardio Panorama, which allows visualizing ECG signals from any queried viewpoints. To build Electrocardio Panorama, we assume that an underlying electrocardio field exists, representing locations, magnitudes, and directions of ECG signals. We present a Neural electrocardio field Network (Nef-Net), which first predicts the electrocardio field representation by using a sparse set of one or few input ECG views and then synthesizes Electrocardio Panorama based on the predicted representations. Specially, to better disentangle electrocardio field information from viewpoint biases, a new Angular Encoding is proposed to process viewpoint angles. Also, we propose a self-supervised learning approach called Standin Learning, which helps model the electrocardio field without direct supervision. Further, with very few modifications, Nef-Net can also synthesize ECG signals from scratch. Experiments verify that our Nef-Net performs well on Electrocardio Panorama synthesis, and outperforms the previous work on the auxiliary tasks (ECG view transformation and ECG synthesis from scratch). The codes and the division labels of cardiac cycles and ECG deflections on Tianchi ECG and PTB datasets are available at <a class="link-external link-https" href="https://github.com/WhatAShot/Electrocardio-Panorama" rel="external noopener nofollow">this https URL</a>.      
### 5.Outage Constrained Robust Secure Beamforming in Cognitive Satellite-Aerial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.06272.pdf)
>  This paper proposes a robust beamforming scheme to enhance the physical layer security (PLS) of multicast transmission in a cognitive satellite and aerial network (CSAN) operating in the millimeter wave frequency band. Based on imperfect channel state information (CSI) of both eavesdroppers (Eves) and primary users (PUs), we maximize the minimum achievable secrecy rate (ASR) of the secondary users (SUs) in the aerial network under the constraints of the interference to the PUs in the satellite network, the quality of service (QoS) requirements of the SUs and per-antenna power budget of the aerial platform. To tackle this mathematically intractable problem, we first introduce an auxiliary variable and outage constraints to simplify the complex objective function. We then convert the non-convex outage constraints into deterministic forms and adopt penalty function approach to obtain a semi-definite problem such that it can be solved in an iterative fashion. Finally, simulation results show that with the transmit power increase, the minimal ASR of SUs obtained from the proposed BF scheme well approximate the optimal value.      
### 6.Multi-scale Regional Attention Deeplab3+: Multiple Myeloma Plasma Cells Segmentation in Microscopic Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.06238.pdf)
>  Multiple myeloma cancer is a type of blood cancer that happens when the growth of abnormal plasma cells becomes out of control in the bone marrow. There are various ways to diagnose multiple myeloma in bone marrow such as complete blood count test (CBC) or counting myeloma plasma cell in aspirate slide images using manual visualization or through image processing technique. In this work, an automatic deep learning method for the detection and segmentation of multiple myeloma plasma cell have been explored. To this end, a two-stage deep learning method is designed. In the first stage, the nucleus detection network is utilized to extract each instance of a cell of interest. The extracted instance is then fed to the multi-scale function to generate a multi-scale representation. The objective of the multi-scale function is to capture the shape variation and reduce the effect of object scale on the cytoplasm segmentation network. The generated scales are then fed into a pyramid of cytoplasm networks to learn the segmentation map in various scales. On top of the cytoplasm segmentation network, we included a scale aggregation function to refine and generate a final prediction. The proposed approach has been evaluated on the SegPC2021 grand-challenge and ranked second on the final test phase among all teams.      
### 7.Multi-Signal Approaches for Repeated Sampling Schemes in Inertial Sensor Calibration  [ :arrow_down: ](https://arxiv.org/pdf/2105.06217.pdf)
>  The task of inertial sensor calibration has become increasingly important due to the growing use of low-cost inertial measurement units which are however characterized by measurement errors. Being widely employed in a variety of mass-market applications, there is considerable focus on compensating for these errors by taking into account the deterministic and stochastic factors that characterize them. In this paper, we focus on the stochastic part of the error signal where it is customary to record the latter and use the observed error signal to identify and estimate the stochastic models, often complex in nature, that underlie this process. However, it is often the case that these error signals are observed through a series of replicates for the same inertial sensor and equally often that these replicates have the same model structure but their parameters appear different between replicates. This phenomenon has not been taken into account by current stochastic calibration procedures which therefore can be conditioned by flawed parameter estimation. For this reason, this paper aims at studying different approaches for this problem and studying their properties to take into account parameter variation between replicates thereby improving measurement precision and navigation uncertainty quantification in the long run.      
### 8.A Service-oriented Metro Traffic Regulation Method for Improving Operation Performance  [ :arrow_down: ](https://arxiv.org/pdf/2105.06149.pdf)
>  For high-density metro traffic, nowadays the time-variant passenger flow is the main cause of train delays and stranded passengers. Typically, the main objective of automatic metro traffic regulation methods is to minimize the delay time of trains while passengers' satisfaction is not considered. Instead, in this work, a novel framework that integrates a passenger flow module (PFM) and a train operation module (TOM) is proposed with the aim of simultaneously minimizing traffic delays and passengers' discomfort. In particular, the PFM is devoted to the optimization of the headway time in case of platform overcrowding, so as to reduce the passengers waiting time at platforms and increase the load rate of trains; while the TOM is devoted to the minimization of trains' delays. The two modules interact with each other so that the headway time is automatically adjusted when a platform is overcrowded, and the train traffic is immediately regulated according to the new headway time. As a result, the number of passengers on the platform and their total waiting time can be significantly reduced. Numerical results are provided to show the effectiveness of the proposed method in improving the operation performance while minimizing the passengers' discomfort.      
### 9.Decision tree aided planning and energy balancing of planned community microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2105.06096.pdf)
>  Planned Communities (PCs) present a unique opportunity for deployment of intelligent control of demand-side distributed energy resources (DER) and storage, which may be organized in Microgrids (MGs). MGs require balancing for maintaining safe and resilient operation. This paper discusses the implications of using MG concepts for planning and control of energy systems within PCs. A novel tool is presented, based on decision trees (DT), with two potential applications: (i) planning of energy storage systems within such MGs and (ii) controlling energy resources for energy balancing within a PC MG. The energy storage planning and energy balancing methodology is validated through sensitivity case studies, demonstrating its effectiveness. A test implementation is presented, utilizing distributed controller hardware to execute the energy balancing algorithm in real-time.      
### 10.Voltage Regulation Support Along a Distribution Line by a Virtual Power Plant Based on a Center of Mass Load Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2105.06092.pdf)
>  A voltage regulation method for slow voltage variations at distribution level is proposed, based on a view of the loads, generators and storage along a distribution line as point weights. The "centers of mass" of the absorbed and injected currents (loads &amp; generation, respectively) are compensated by minimizing the distance between them, through proper re-dispatching of the power of the available units and interruptible loads. The technique is recursively applied to lesser parts of the distribution line to address local phenomena and is assumed to be offered as ancillary service to the system operator by a Virtual Power Plant. The favorable results of the methodology are assessed on a distribution line of the island of Rhodes (Greece) under critical loading for numerous scenarios. Unlike previous approaches, the technique focuses specifically in the restoration of bus voltages within standard limits and may reduce the activation of on-line tap changing transformers control.      
### 11.HINet: Half Instance Normalization Network for Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2105.06086.pdf)
>  In this paper, we explore the role of Instance Normalization in low-level vision tasks. Specifically, we present a novel block: Half Instance Normalization Block (HIN Block), to boost the performance of image restoration networks. Based on HIN Block, we design a simple and powerful multi-stage network named HINet, which consists of two subnetworks. With the help of HIN Block, HINet surpasses the state-of-the-art (SOTA) on various image restoration tasks. For image denoising, we exceed it 0.11dB and 0.28 dB in PSNR on SIDD dataset, with only 7.5% and 30% of its multiplier-accumulator operations (MACs), 6.8 times and 2.9 times speedup respectively. For image deblurring, we get comparable performance with 22.5% of its MACs and 3.3 times speedup on REDS and GoPro datasets. For image deraining, we exceed it by 0.3 dB in PSNR on the average result of multiple datasets with 1.4 times speedup. With HINet, we won 1st place on the NTIRE 2021 Image Deblurring Challenge - Track2. JPEG Artifacts, with a PSNR of 29.70. The code is available at <a class="link-external link-https" href="https://github.com/megvii-model/HINet" rel="external noopener nofollow">this https URL</a>.      
### 12.Low Complexity Secure State Estimation Design for Linear System with Non-derogatory $A$  [ :arrow_down: ](https://arxiv.org/pdf/2105.06064.pdf)
>  We consider the problem of estimating the state of a time-invariant linear Gaussian system in the presence of integrity attacks. The attacker can compromise $p$ out of $m$ sensors, the set of which is fixed and unknown to the system operator, and manipulate the measurements arbitrarily. Under the assumption that all the eigenvalues of system matrix $A$ have geometric multiplicity 1 ($A$ is non-derogatory), we propose a secure estimation scheme that is resilient to integrity attack as long as the system is $2p$-sparse observable. In the absence of attack, the proposed estimation coincides with Kalman estimation with a certain probability that can be adjusted. Furthermore, our proposed estimator is computational efficient during the security condition checking in the designing phase and during the estimation computing in the online operating phase. A numerical example is provided to corroborate the results and illustrate the performance of the proposed estimator.      
### 13.Edge Augmentation with Controllability Constraints in Directed Laplacian Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.06011.pdf)
>  In this paper, we study the maximum edge augmentation problem in directed Laplacian networks to improve their robustness while preserving lower bounds on their strong structural controllability (SSC). Since adding edges could adversely impact network controllability, the main objective is to maximally densify a given network by selectively adding missing edges while ensuring that SSC of the network does not deteriorate beyond certain levels specified by the SSC bounds. We consider two widely used bounds: first is based on the notion of zero forcing (ZF), and the second relies on the distances between nodes in a graph. We provide an edge augmentation algorithm that adds the maximum number of edges in a graph while preserving the ZF-based SSC bound, and also derive a closed-form expression for the exact number of edges added to the graph. Then, we examine the edge augmentation problem while preserving the distance-based bound and present a randomized algorithm that guarantees an approximate solution with high probability. Finally, we numerically evaluate and compare these edge augmentation solutions.      
### 14.Data-Driven Strategies for Hierarchical Predictive Control in Unknown Environments  [ :arrow_down: ](https://arxiv.org/pdf/2105.06005.pdf)
>  This article proposes a hierarchical learning architecture for safe data-driven control in unknown environments. We consider a constrained nonlinear dynamical system and assume the availability of state-input trajectories solving control tasks in different environments. In addition to task-invariant system state and input constraints, a parameterized environment model generates task-specific state constraints, which are satisfied by the stored trajectories. Our goal is to use these trajectories to find a safe and high-performing policy for a new task in a new, unknown environment. We propose using the stored data to learn generalizable control strategies. At each time step, based on a local forecast of the new task environment, the learned strategy consists of a target region in the state space and input constraints to guide the system evolution to the target region. These target regions are used as terminal sets by a low-level model predictive controller. We show how to i) design the target sets from past data and then ii) incorporate them into a model predictive control scheme with shifting horizon that ensures safety of the closed-loop system when performing the new task. We prove the feasibility of the resulting control policy, and apply the proposed method to robotic path planning, racing, and computer game applications.      
### 15.DONet: Dual-Octave Network for Fast MR Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.05980.pdf)
>  Magnetic resonance (MR) image acquisition is an inherently prolonged process, whose acceleration has long been the subject of research. This is commonly achieved by obtaining multiple undersampled images, simultaneously, through parallel imaging. In this paper, we propose the Dual-Octave Network (DONet), which is capable of learning multi-scale spatial-frequency features from both the real and imaginary components of MR data, for fast parallel MR image reconstruction. More specifically, our DONet consists of a series of Dual-Octave convolutions (Dual-OctConv), which are connected in a dense manner for better reuse of features. In each Dual-OctConv, the input feature maps and convolutional kernels are first split into two components (ie, real and imaginary), and then divided into four groups according to their spatial frequencies. Then, our Dual-OctConv conducts intra-group information updating and inter-group information exchange to aggregate the contextual information across different groups. Our framework provides three appealing benefits: (i) It encourages information interaction and fusion between the real and imaginary components at various spatial frequencies to achieve richer representational capacity. (ii) The dense connections between the real and imaginary groups in each Dual-OctConv make the propagation of features more efficient by feature reuse. (iii) DONet enlarges the receptive field by learning multiple spatial-frequency features of both the real and imaginary components. Extensive experiments on two popular datasets (ie, clinical knee and fastMRI), under different undersampling patterns and acceleration factors, demonstrate the superiority of our model in accelerated parallel MR image reconstruction.      
### 16.Sensor Placement with Optimal Precision for Temperature Estimation of Battery Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.05976.pdf)
>  The temperature distribution in the battery significantly impacts the short-term and long-term performance of battery systems. Therefore, efficient, safe, and reliable battery system operation requires an accurate estimation of the temperature field. The current industry standard for sensors to battery cell ratio is quite frugal. Thus, the problem of sensor placement for accurate temperature estimation becomes non-trivial, especially for large-scale systems. In this paper, we explore a greedy approach for sensor placement suitable for large-scale battery systems. An observer to estimate the thermal field is designed in an $\mathcal{H}_{\infty}$ framework while simultaneously minimizing the sensor precisions, thus lowering the overall thermal management system's economic cost.      
### 17.Removing Blocking Artifacts in Video Streams Using Event Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2105.05973.pdf)
>  In this paper, we propose EveRestNet, a convolutional neural network designed to remove blocking artifacts in videostreams using events from neuromorphic sensors. We first degrade the video frame using a quadtree structure to produce the blocking artifacts to simulate transmitting a video under a heavily constrained bandwidth. Events from the neuromorphic sensor are also simulated, but are transmitted in full. Using the distorted frames and the event stream, EveRestNet is able to improve the image quality.      
### 18.Tencent Video Dataset (TVD): A Video Dataset for Learning-based Visual Data Compression and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2105.05961.pdf)
>  Learning-based visual data compression and analysis have attracted great interest from both academia and industry recently. More training as well as testing datasets, especially good quality video datasets are highly desirable for related research and standardization activities. Tencent Video Dataset (TVD) is established to serve various purposes such as training neural network-based coding tools and testing machine vision tasks including object detection and tracking. TVD contains 86 video sequences with a variety of content coverage. Each video sequence consists of 65 frames at 4K (3840x2160) spatial resolution. In this paper, the details of this dataset, as well as its performance when compressed by VVC and HEVC video codecs, are introduced.      
### 19.Attention-based Neural Beamforming Layers for Multi-channel Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2105.05920.pdf)
>  Attention-based beamformers have recently been shown to be effective for multi-channel speech recognition. However, they are less capable at capturing local information. In this work, we propose a 2D Conv-Attention module which combines convolution neural networks with attention for beamforming. We apply self- and cross-attention to explicitly model the correlations within and between the input channels. The end-to-end 2D Conv-Attention model is compared with a multi-head self-attention and superdirective-based neural beamformers. We train and evaluate on an in-house multi-channel dataset. The results show a relative improvement of 3.8% in WER by the proposed model over the baseline neural beamformer.      
### 20.Finite-time Koopman Identifier: A Unified Batch-online Learning Framework for Joint Learning of Koopman Structure and Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2105.05903.pdf)
>  In this paper, a unified batch-online learning approach is introduced to learn a linear representation of nonlinear system dynamics using the Koopman operator. The presented system modeling approach leverages a novel incremental Koopman-based update law that retrieves a mini-batch of samples stored in a memory to not only minimizes the instantaneous Koopman operator's identification errors but also the identification errors for the batch of retrieved samples. Discontinuous modifications of gradient flows are presented for the online update law to assure finite-time convergence under easy-to-verify conditions defined on the batch of data. Therefore, this unified online-batch framework allows performing joint sample- and time-domain analysis for converging the Koopman operator's parameters. More specifically, it is shown that if the collected mini-batch of samples guarantees a rank condition, then finite-time guarantee in the time domain can be certified and the settling time depends on the quality of collected samples being reused in the update law. Moreover, the efficiency of the proposed Koopman-based update law is further analyzed by showing that the identification regret in continuous time grows sub-linearly with time. Furthermore, to avoid learning corrupted dynamics due to the selection of an inappropriate set of Koopman observables, a higher-layer meta learner employs a discrete Bayesian optimization algorithm to obtain the best library of observable functions for the operator. Since finite-time convergence of the Koopman model for each set of observable is guaranteed under a rank condition on stored data, the fitness of each set of observables can be obtained based on the identification error on the stored samples in the proposed framework and even without implementing any controller based on the learned system.      
### 21.The Federated Tumor Segmentation (FeTS) Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2105.05874.pdf)
>  This manuscript describes the first challenge on Federated Learning, namely the Federated Tumor Segmentation (FeTS) challenge 2021. International challenges have become the standard for validation of biomedical image analysis methods. However, the actual performance of participating (even the winning) algorithms on "real-world" clinical data often remains unclear, as the data included in challenges are usually acquired in very controlled settings at few institutions. The seemingly obvious solution of just collecting increasingly more data from more institutions in such challenges does not scale well due to privacy and ownership hurdles. Towards alleviating these concerns, we are proposing the FeTS challenge 2021 to cater towards both the development and the evaluation of models for the segmentation of intrinsically heterogeneous (in appearance, shape, and histology) brain tumors, namely gliomas. Specifically, the FeTS 2021 challenge uses clinically acquired, multi-institutional magnetic resonance imaging (MRI) scans from the BraTS 2020 challenge, as well as from various remote independent institutions included in the collaborative network of a real-world federation (<a class="link-external link-https" href="https://www.fets.ai/" rel="external noopener nofollow">this https URL</a>). The goals of the FeTS challenge are directly represented by the two included tasks: 1) the identification of the optimal weight aggregation approach towards the training of a consensus model that has gained knowledge via federated learning from multiple geographically distinct institutions, while their data are always retained within each institution, and 2) the federated evaluation of the generalizability of brain tumor segmentation models "in the wild", i.e. on data from institutional distributions that were not part of the training datasets.      
### 22.Audio Captioning with Composition of Acoustic and Semantic Information  [ :arrow_down: ](https://arxiv.org/pdf/2105.06355.pdf)
>  Generating audio captions is a new research area that combines audio and natural language processing to create meaningful textual descriptions for audio clips. To address this problem, previous studies mostly use the encoder-decoder based models without considering semantic information. To fill this gap, we present a novel encoder-decoder architecture using bi-directional Gated Recurrent Units (BiGRU) with audio and semantic embeddings. We extract semantic embedding by obtaining subjects and verbs from the audio clip captions and combine these embedding with audio embedding to feed the BiGRU-based encoder-decoder model. To enable semantic embeddings for the test audios, we introduce a Multilayer Perceptron classifier to predict the semantic embeddings of those clips. We also present exhaustive experiments to show the efficiency of different features and datasets for our proposed model the audio captioning task. To extract audio features, we use the log Mel energy features, VGGish embeddings, and a pretrained audio neural network (PANN) embeddings. Extensive experiments on two audio captioning datasets Clotho and AudioCaps show that our proposed model outperforms state-of-the-art audio captioning models across different evaluation metrics and using the semantic information improves the captioning performance. Keywords: Audio captioning; PANNs; VGGish; GRU; BiGRU.      
### 23.A Scalable Algorithm for Anomaly Detection via Learning-Based Controlled Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2105.06289.pdf)
>  We address the problem of sequentially selecting and observing processes from a given set to find the anomalies among them. The decision-maker observes one process at a time and obtains a noisy binary indicator of whether or not the corresponding process is anomalous. In this setting, we develop an anomaly detection algorithm that chooses the process to be observed at a given time instant, decides when to stop taking observations, and makes a decision regarding the anomalous processes. The objective of the detection algorithm is to arrive at a decision with an accuracy exceeding a desired value while minimizing the delay in decision making. Our algorithm relies on a Markov decision process defined using the marginal probability of each process being normal or anomalous, conditioned on the observations. We implement the detection algorithm using the deep actor-critic reinforcement learning framework. Unlike prior work on this topic that has exponential complexity in the number of processes, our algorithm has computational and memory requirements that are both polynomial in the number of processes. We demonstrate the efficacy of our algorithm using numerical experiments by comparing it with the state-of-the-art methods.      
### 24.Anomaly Detection via Controlled Sensing and Deep Active Inference  [ :arrow_down: ](https://arxiv.org/pdf/2105.06288.pdf)
>  In this paper, we address the anomaly detection problem where the objective is to find the anomalous processes among a given set of processes. To this end, the decision-making agent probes a subset of processes at every time instant and obtains a potentially erroneous estimate of the binary variable which indicates whether or not the corresponding process is anomalous. The agent continues to probe the processes until it obtains a sufficient number of measurements to reliably identify the anomalous processes. In this context, we develop a sequential selection algorithm that decides which processes to be probed at every instant to detect the anomalies with an accuracy exceeding a desired value while minimizing the delay in making the decision and the total number of measurements taken. Our algorithm is based on active inference which is a general framework to make sequential decisions in order to maximize the notion of free energy. We define the free energy using the objectives of the selection policy and implement the active inference framework using a deep neural network approximation. Using numerical experiments, we compare our algorithm with the state-of-the-art method based on deep actor-critic reinforcement learning and demonstrate the superior performance of our algorithm.      
### 25.Ergodic Capacity of High Throughput Satellite Systems With Mixed FSO-RF Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2105.06284.pdf)
>  We study a high throughput satellite system, where the feeder link uses free-space optical (FSO) and the user link uses radio frequency (RF) communication. In particular, we first propose a transmit diversity using Alamouti space time block coding to mitigate the atmospheric turbulence in the feeder link. Then, based on the concept of average virtual signal-to-interference-plus-noise ratio and one-bit feedback, we propose a beamforming algorithm for the user link to maximize the ergodic capacity (EC). Moreover, by assuming that the FSO links follow the Malaga distribution whereas RF links undergo the shadowed-Rician fading, we derive a closed-form EC expression of the considered system. Finally, numerical simulations validate the accuracy of our theoretical analysis, and show that the proposed schemes can achieve higher capacity compared with the reference schemes.      
### 26.Group Feature Learning and Domain Adversarial Neural Network for aMCI Diagnosis System Based on EEG  [ :arrow_down: ](https://arxiv.org/pdf/2105.06270.pdf)
>  Medical diagnostic robot systems have been paid more and more attention due to its objectivity and accuracy. The diagnosis of mild cognitive impairment (MCI) is considered an effective means to prevent Alzheimer's disease (AD). Doctors diagnose MCI based on various clinical examinations, which are expensive and the diagnosis results rely on the knowledge of doctors. Therefore, it is necessary to develop a robot diagnostic system to eliminate the influence of human factors and obtain a higher accuracy rate. In this paper, we propose a novel Group Feature Domain Adversarial Neural Network (GF-DANN) for amnestic MCI (aMCI) diagnosis, which involves two important modules. A Group Feature Extraction (GFE) module is proposed to reduce individual differences by learning group-level features through adversarial learning. A Dual Branch Domain Adaptation (DBDA) module is carefully designed to reduce the distribution difference between the source and target domain in a domain adaption way. On three types of data set, GF-DANN achieves the best accuracy compared with classic machine learning and deep learning methods. On the DMS data set, GF-DANN has obtained an accuracy rate of 89.47%, and the sensitivity and specificity are 90% and 89%. In addition, by comparing three EEG data collection paradigms, our results demonstrate that the DMS paradigm has the potential to build an aMCI diagnose robot system.      
### 27.Robust Beamforming Design and Time Allocation for IRS-assisted Wireless Powered Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.06226.pdf)
>  In this paper, a novel intelligent reflecting surface (IRS)-assisted wireless powered communication network (WPCN) architecture is proposed for low-power Internet-of-Things (IoT) devices, where the IRS is exploited to improve the performance of WPCN under imperfect channel state information (CSI). We formulate a hybrid access point (HAP) transmission energy minimization problem by a joint design of time allocation, HAP energy beamforming, receiving beamforming, user transmit power allocation, IRS energy reflection coefficient and information reflection coefficient under the imperfect CSI and non-linear energy harvesting model. Due to the high coupling of optimization variables, this problem is a non-convex optimization problem, which is difficult to solve directly. In order to solve the above-mentioned challenging problems, the alternating optimization (AO) is applied to decouple the optimization variables to solve the problem. Specifically, through AO, time allocation, HAP energy beamforming, receiving beamforming, user transmit power allocation, IRS energy reflection coefficient and information reflection coefficient are divided into three sub-problems to be solved alternately. The difference-of-convex (DC) programming is applied to solve the non-convex rank-one constraint in solving the IRS energy reflection coefficient and information reflection coefficient. Numerical simulations verify the effectiveness of our proposed algorithm in reducing HAP transmission energy compared to other benchmarks.      
### 28.Adaptive Test-Time Augmentation for Low-Power CPU  [ :arrow_down: ](https://arxiv.org/pdf/2105.06183.pdf)
>  Convolutional Neural Networks (ConvNets) are trained offline using the few available data and may therefore suffer from substantial accuracy loss when ported on the field, where unseen input patterns received under unpredictable external conditions can mislead the model. Test-Time Augmentation (TTA) techniques aim to alleviate such common side effect at inference-time, first running multiple feed-forward passes on a set of altered versions of the same input sample, and then computing the main outcome through a consensus of the aggregated predictions. Unfortunately, the implementation of TTA on embedded CPUs introduces latency penalties that limit its adoption on edge applications. To tackle this issue, we propose AdapTTA, an adaptive implementation of TTA that controls the number of feed-forward passes dynamically, depending on the complexity of the input. Experimental results on state-of-the-art ConvNets for image classification deployed on a commercial ARM Cortex-A CPU demonstrate AdapTTA reaches remarkable latency savings, from 1.49X to 2.21X, and hence a higher frame rate compared to static TTA, still preserving the same accuracy gain.      
### 29.A hybrid machine learning/deep learning COVID-19 severity predictive model from CT images and clinical data  [ :arrow_down: ](https://arxiv.org/pdf/2105.06141.pdf)
>  COVID-19 clinical presentation and prognosis are highly variable, ranging from asymptomatic and paucisymptomatic cases to acute respiratory distress syndrome and multi-organ involvement. We developed a hybrid machine learning/deep learning model to classify patients in two outcome categories, non-ICU and ICU (intensive care admission or death), using 558 patients admitted in a northern Italy hospital in February/May of 2020. A fully 3D patient-level CNN classifier on baseline CT images is used as feature extractor. Features extracted, alongside with laboratory and clinical data, are fed for selection in a Boruta algorithm with SHAP game theoretical values. A classifier is built on the reduced feature space using CatBoost gradient boosting algorithm and reaching a probabilistic AUC of 0.949 on holdout test set. The model aims to provide clinical decision support to medical doctors, with the probability score of belonging to an outcome class and with case-based SHAP interpretation of features importance.      
### 30.Multi-target DoA Estimation with an Audio-visual Fusion Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2105.06107.pdf)
>  Most of the prior studies in the spatial \ac{DoA} domain focus on a single modality. However, humans use auditory and visual senses to detect the presence of sound sources. With this motivation, we propose to use neural networks with audio and visual signals for multi-speaker localization. The use of heterogeneous sensors can provide complementary information to overcome uni-modal challenges, such as noise, reverberation, illumination variations, and occlusions. We attempt to address these issues by introducing an adaptive weighting mechanism for audio-visual fusion. We also propose a novel video simulation method that generates visual features from noisy target 3D annotations that are synchronized with acoustic features. Experimental results confirm that audio-visual fusion consistently improves the performance of speaker DoA estimation, while the adaptive weighting mechanism shows clear benefits.      
### 31.A Low-Complexity Multi-Survivor Dynamic Programming for Constrained Discrete Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2105.06085.pdf)
>  Constrained discrete optimization problems are encountered in many areas of communication and machine learning. We consider the case where the objective function satisfies Bellman's optimality principle without the constraints on which we place no conditions. We first show that these problems are a generalization of optimization in constrained Markov decision processes with finite horizon used in reinforcement learning and are NP-Hard. We then present a novel multi-survivor dynamic programming (msDP) algorithm that guarantees optimality at significant computational savings. We demonstrate this by solving 5G quantizer bit allocation and DNA fragment assembly problems. The results are very promising and suggest that msDP can be used for many applications.      
### 32.A Received Power Model for Reconfigurable Intelligent Surface and Measurement-based Validations  [ :arrow_down: ](https://arxiv.org/pdf/2105.06082.pdf)
>  The idea of using a Reconfigurable Intelligent Surface (RIS) consisting of a large array of passive scattering elements to assist wireless communication systems has recently attracted much attention from academia and industry. A central issue with RIS is how much power they can effectively convey to the target radio nodes. Regarding this question, several power level models exist in the literature but few have been validated through experiments. In this paper, we propose a radar cross section-based received power model for an RIS-aided wireless communication system that is rooted in the physical properties of RIS. Our proposed model follows the intuition that the received power is related to the distances from the transmitter/receiver to the RIS, the angles in the TX-RIS-RX triangle, the effective area of each element, and the reflection coefficient of each element. To the best of our knowledge, this paper is the first to model the angle-dependent phase shift of the reflection coefficient, which is typically ignored in existing literature. We further measure the received power with our experimental platform in different scenarios to validate our model. The measurement results show that our model is appropriate both in near field and far field and can characterize the impact of angles well.      
### 33.A Hybrid Wired/Wireless Deterministic Network for Smart Grid  [ :arrow_down: ](https://arxiv.org/pdf/2105.06053.pdf)
>  With the rapid growth of time-critical applications in smart grid, robotics, autonomous vehicles, and industrial automation, demand for high reliability, low latency and strictly bounded jitter is sharply increasing. High-precision time synchronization communications, such as Time Triggered Ethernet (TTE), have been successfully developed for wired networks. However, the high cost of deploying additional equipment and extra wiring limits the scalability of these networks. Therefore, in this paper, a hybrid wired/wireless high-precision time synchronization network based on a combination of high-speed TTE and 5G Ultra-Reliable and Low-Latency Communications (URLLC) is proposed. The main motivation is to comply with the low latency, low jitter, and high reliability requirements of time critical applications, such as smart grid synchrophasor communications. Therefore, in the proposed hybrid network architecture, a high-speed TTE is considered as the main bus (i.e., backbone network), whereas a Precision Time Protocol (PTP) aided 5G-URLLC-based wireless access is used as a sub-network. The main challenge is to achieve interoperability between the PTP aided URLLC and the TTE, while ensuring high precision timing and synchronization. The simulation results demonstrate the impact of the PTP-aided URLLC in maintaining network reliability, latency, and jitter in full coordination with the TTE-network.      
### 34.TopoTxR: A Topological Biomarker for Predicting Treatment Response in Breast Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2105.06049.pdf)
>  Characterization of breast parenchyma on dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is a challenging task owing to the complexity of underlying tissue structures. Current quantitative approaches, including radiomics and deep learning models, do not explicitly capture the complex and subtle parenchymal structures, such as fibroglandular tissue. In this paper, we propose a novel method to direct a neural network's attention to a dedicated set of voxels surrounding biologically relevant tissue structures. By extracting multi-dimensional topological structures with high saliency, we build a topology-derived biomarker, TopoTxR. We demonstrate the efficacy of TopoTxR in predicting response to neoadjuvant chemotherapy in breast cancer. Our qualitative and quantitative results suggest differential topological behavior of breast tissue on treatment-naïve imaging, in patients who respond favorably to therapy versus those who do not.      
### 35.Imaging through random media using coherent averaging  [ :arrow_down: ](https://arxiv.org/pdf/2105.06045.pdf)
>  We propose and demonstrate a new phase retrieval method for imaging through random media. Although methods to recover the Fourier amplitude through random distortions are well established, recovery of the Fourier phase has been a more difficult problem and is still a very active research area. Here, we show that by simply ensemble averaging shift-corrected images, the Fourier phase of an object obscured by random distortions can be accurately retrieved up to the diffraction limit. The method is simple, fast, does not have any optimization parameters, and does not require prior knowledge or assumptions about the sample. We demonstrate the feasibility and robustness of our method by realizing all computational diffraction-limited imaging through atmospheric turbulence as well as imaging through multiple scattering media.      
### 36.Robust Beamforming for Enhancing Security in Multibeam Satellite Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.06023.pdf)
>  This paper proposes a robust beamforming (BF) scheme to enhance physical layer security (PLS) of the downlink of a multibeam satellite system in the presence of either uncoordinated or coordinated eavesdroppers (Eves). Specifically, with knowing only the approximate locations of the Eves, we aim at maximizing the worst-case achievable secrecy rate (ASR) of the legitimate user (LU), subject to the constraints of per-antenna transmit power and quality of service (QoS) requirement of the LU. Since the optimization problem is non-convex, we first adopt the discretization method to deal with the unknown regions of the Eves and then exploit the log-sum-exp function to approximate the objective function. Afterwards, a BF method joint alternating direction method of multipliers (ADMM) with Dinkelbach iteration is presented to solve this non-convex problem. Finally, simulation results verify that our robust BF algorithm can effectively improve the security of multibeam satellite systems.      
### 37.Lightweight compression of neural network feature tensors for collaborative intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2105.06002.pdf)
>  In collaborative intelligence applications, part of a deep neural network (DNN) is deployed on a relatively low-complexity device such as a mobile phone or edge device, and the remainder of the DNN is processed where more computing resources are available, such as in the cloud. This paper presents a novel lightweight compression technique designed specifically to code the activations of a split DNN layer, while having a low complexity suitable for edge devices and not requiring any retraining. We also present a modified entropy-constrained quantizer design algorithm optimized for clipped activations. When applied to popular object-detection and classification DNNs, we were able to compress the 32-bit floating point activations down to 0.6 to 0.8 bits, while keeping the loss in accuracy to less than 1%. When compared to HEVC, we found that the lightweight codec consistently provided better inference accuracy, by up to 1.3%. The performance and simplicity of this lightweight compression technique makes it an attractive option for coding a layer's activations in split neural networks for edge/cloud applications.      
### 38.Mobility-enhanced MPC for Legged Locomotion on Rough Terrain  [ :arrow_down: ](https://arxiv.org/pdf/2105.05998.pdf)
>  Re-planning in legged locomotion is crucial to track a given set-point while adapting to the terrain and rejecting external disturbances. In this work, we propose a real-time Nonlinear Model Predictive Control (NMPC) tailored to a legged robot for achieving dynamic locomotion on a wide variety of terrains. We introduce a mobility-based criterion to define an NMPC cost that enhances the locomotion of quadruped robots while maximizing leg mobility and staying far from kinematic limits. Our NMPC is based on the real-time iteration scheme that allows us to re-plan online at $25 \, \mathrm{Hz}$ with a time horizon of $2$ seconds. We use the single rigid body dynamic model defined in the center of mass frame that allows to increase the computational efficiency. In simulations, the NMPC is tested to traverse a set of pallets of different sizes, to walk into a V-shaped chimney, and to locomote over rough terrain. We demonstrate the effectiveness of our NMPC with the mobility feature that allowed IIT's $87.4 \,\mathrm{kg}$ quadruped robot HyQ to achieve an omni-directional walk on flat terrain, to traverse a static pallet, and to adapt to a repositioned pallet during a walk in real experiments.      
### 39.The impact of the additional features on the performance of regression analysis: a case study on regression analysis of music signal  [ :arrow_down: ](https://arxiv.org/pdf/2105.05938.pdf)
>  Machine learning techniques nowadays play a vital role in many burning issues of real-world problems when it involves data. In addition, when the task is complex, people are in dilemma in choosing deep learning techniques or going without them. This paper is about whether we should always rely on deep learning techniques or it is really possible to overcome the performance of deep learning algorithms by simple statistical machine learning algorithms by understanding the application and processing the data so that it can help in increasing the performance of the algorithm by a notable amount. The paper mentions the importance of data preprocessing than that of the selection of the algorithm. It discusses the functions involving trigonometric, logarithmic, and exponential terms and also talks about functions that are purely trigonometric. Finally, we discuss regression analysis on music signals to justify our claim.      
### 40.Silicon Photonics in Optical Access Networks for 5G Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.05924.pdf)
>  Only radio access networks can provide connectivity across multiple antenna sites to achieve the great leap forward in capacity targeted by 5G. Optical fronthaul remains a sticking point in that connectivity, and we make the case for analog radio over fiber signals and an optical access network smartedge to achieve the potential of radio access networks. The edge of the network would house the intelligence that coordinates wireless transmissions to minimize interference and maximize throughput. As silicon photonics provides a hardware platform well adapted to support optical fronthaul, it is poised to drive smart edge adoption. We draw out the issues in adopting oursolution, propose a strategy for network densification, and cite recent demonstrations to support our approach.      

# ArXiv eess --Wed, 26 May 2021
### 1.Self-Organized Variational Autoencoders (Self-VAE) for Learned Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2105.12107.pdf)
>  In end-to-end optimized learned image compression, it is standard practice to use a convolutional variational autoencoder with generalized divisive normalization (GDN) to transform images into a latent space. Recently, Operational Neural Networks (ONNs) that learn the best non-linearity from a set of alternatives, and their self-organized variants, Self-ONNs, that approximate any non-linearity via Taylor series have been proposed to address the limitations of convolutional layers and a fixed nonlinear activation. In this paper, we propose to replace the convolutional and GDN layers in the variational autoencoder with self-organized operational layers, and propose a novel self-organized variational autoencoder (Self-VAE) architecture that benefits from stronger non-linearity. The experimental results demonstrate that the proposed Self-VAE yields improvements in both rate-distortion performance and perceptual image quality.      
### 2.Adversarial Attack Driven Data Augmentation for Accurate And Robust Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.12106.pdf)
>  Segmentation is considered to be a very crucial task in medical image analysis. This task has been easier since deep learning models have taken over with its high performing behavior. However, deep learning models dependency on large data proves it to be an obstacle in medical image analysis because of insufficient data samples. Several data augmentation techniques have been used to mitigate this problem. We propose a new augmentation method by introducing adversarial learning attack techniques, specifically Fast Gradient Sign Method (FGSM). Furthermore, We have also introduced the concept of Inverse FGSM (InvFGSM), which works in the opposite manner of FGSM for the data augmentation. This two approaches worked together to improve the segmentation accuracy, as well as helped the model to gain robustness against adversarial attacks. The overall analysis of experiments indicates a novel use of adversarial machine learning along with robustness enhancement.      
### 3.Generalized Hessian-Schatten Norm Regularization for Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.12099.pdf)
>  Regularization plays a crucial role in reliably utilizing imaging systems for scientific and medical investigations. It helps to stabilize the process of computationally undoing any degradation caused by physical limitations of the imaging process. In the past decades, total variation regularization, especially second-order total variation (TV-2) regularization played a dominant role in the literature. Two forms of generalizations, namely Hessian-Schatten norm (HSN) regularization, and total generalized variation (TGV) regularization, have been recently proposed and have become significant developments in the area of regularization for imaging inverse problems owing to their performance. Here, we develop a novel regularization for image recovery that combines the strengths of these well-known forms. We achieve this by restricting the maximization space in the dual form of HSN in the same way that TGV is obtained from TV-2. We name the new regularization as the generalized Hessian-Schatten norm regularization (GHSN), and we develop a novel optimization method for image reconstruction using the new form of regularization based on the well-known framework called alternating direction method of multipliers (ADMM). We demonstrate the strength of the GHSN using some reconstruction examples.      
### 4.Rate Splitting in VCSEL-based Optical Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.12084.pdf)
>  Optical wireless communication is an effective potential solution for enabling high speed next generation cellular networks. In this paper, laser sources, in particular, vertical-cavity surface-emitting (VCSEL) lasers are used for data transmission due to their high modulation speed compared with light emitting diode (LED) sources. To manage multi-user interference, rate splitting (RS) is implemented where the message of a user is split into common and private parts. However, the performance of RS is limited in high density networks. Therefore, hierarchical rate splitting (HRS) particularly suited in high density networks is considered. The results demonstrate the high data rate achieved by using VCSELs. Moreover, HRS is more suitable for achieving high performance in optical networks compared with RS.      
### 5.Analytical Aircraft State and IMU Signal Generator from Smoothed Reference Trajectory  [ :arrow_down: ](https://arxiv.org/pdf/2105.12001.pdf)
>  This work presents a method for generating position, attitude, and velocity states for an aircraft following a smoothed reference trajectory. The method also generates accelerometer and gyro measurements consistent with the aircraft states. This work describes three corner smoothing algorithms for generating a smoothed reference trajectory from a series waypoints that accounts for limitations in the physical system. The smoothed reference trajectory, and curvilinear motion theory are used to generate the lower-order states. A coordinated turn maneuver is then applied to generate accelerometer and gyro measurement estimates.      
### 6.Model Mismatch Trade-offs in LMMSE Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2105.11964.pdf)
>  We consider a linear minimum mean squared error (LMMSE) estimation framework with model mismatch where the assumed model order is smaller than that of the underlying linear system which generates the data used in the estimation process. By modelling the regressors of the underlying system as random variables, we analyze the average behaviour of the mean squared error (MSE). Our results quantify how the MSE depends on the interplay between the number of samples and the number of parameters in the underlying system and in the assumed model. In particular, if the number of samples is not sufficiently large, neither increasing the number of samples nor the assumed model complexity is sufficient to guarantee a performance improvement.      
### 7.On the Use of the Smith-McMillan Form in Decoupling System Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2105.11885.pdf)
>  In this paper, the use of the Smith-McMillan form in decoupling multiple-input multiple-output system dynamics is analyzed. In short, from a transfer matrix plant model one can obtain a decoupling compensator which leads to a decoupled plant that contains the same transmission poles and zeros of the transfer matrix of the original system. As a result, full decoupling of the plant transfer matrix is obtained for all frequencies, which can be individually addressed by single-input single-output control. The aim of this paper is to present conditions for the decoupled system that guarantee internal stability and performance requirements for the overall control system. Performance specifications are defined in terms of magnitude limits for the maximum singular value of the closed-loop transfer matrices. The potential of the decoupling procedure is shown in a simulation study of a mechanical system.      
### 8.Detection and blind channel estimation for UAV-aided wireless sensor networks in smart cities under mobile jamming attack  [ :arrow_down: ](https://arxiv.org/pdf/2105.11868.pdf)
>  There exist several ways of integrating unmanned aerial vehicles (UAVs) into wireless sensor networks (WSNs) for smart city applications. Among the others, a UAV can be employed as a relay in a "store-carry and forward" fashion by uploading data from ground sensors and meters and, then, downloading it to a central unit. However, both the uploading and downloading phases can be prone to potential threats and attacks. As a legacy from traditional wireless networks, the jamming attack is still one of the major and serious threats to UAV-aided communications, especially when the jammer is mobile, too, e.g., it is mounted on an UAV or inside a terrestrial vehicle. In this paper, we investigate anti-jamming communications in UAV-aided WSNs operating over doubly-selective channels. In such a scenario, the signals transmitted by the legitimate transmitters (sensors and meters in the uploading phase or the UAV in the downloading phase) and the malicious mobile jammer undergo both time dispersion due to multipath propagation effects and frequency dispersion caused by Doppler shifts. To suppress the jamming signal, we propose a blind physical-layer technique that jointly exploits amplitudes, phases, time delays, and Doppler shifts differences between the two superimposed signals. Such parameters are estimated from data through the use of algorithms exploiting the almost-cyclostationarity properties of the received signal. Simulation results corroborate the antijamming capabilities of the proposed method, for different mobility scenario of the jammer.      
### 9.CoRSAI: A System for Robust Interpretation of CT Scans of COVID-19 Patients Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.11863.pdf)
>  Analysis of chest CT scans can be used in detecting parts of lungs that are affected by infectious diseases such as COVID-19.Determining the volume of lungs affected by lesions is essential for formulating treatment recommendations and prioritizingpatients by severity of the disease. In this paper we adopted an approach based on using an ensemble of deep convolutionalneural networks for segmentation of slices of lung CT scans. Using our models we are able to segment the lesions, evaluatepatients dynamics, estimate relative volume of lungs affected by lesions and evaluate the lung damage stage. Our modelswere trained on data from different medical centers. We compared predictions of our models with those of six experiencedradiologists and our segmentation model outperformed most of them. On the task of classification of disease severity, ourmodel outperformed all the radiologists.      
### 10.A Prototype of Reconfigurable Intelligent Surface with Continuous Control of the Reflection Phase  [ :arrow_down: ](https://arxiv.org/pdf/2105.11862.pdf)
>  With the development of the next generation of mobile networks, new research challenges have emerged, and new technologies have been proposed to face them. On the one hand, the reconfigurable intelligent surface (RIS) technology is being investigated for partially controlling the wireless channels. The RIS is a promising technology for improving the signal quality by controlling the scattering of the electromagnetic waves in a nearly passive manner. On the other hand, ambient backscatter communications (AmBC) is another promising technology that is tailored for addressing the energy efficiency requirements for the Internet of Things (IoT). This technique enables low-power communications by backscattering ambient signals and, thus, reusing existing electromagnetic waves for communications. RIS technology can be utilized in the context of AmBC for improving the system performance. In this paper, we report a prototype of an RIS that offers the capability of controlling the phase shift of the reflected waves in a continuous manner, and we characterize its characteristics by using full-wave simulations and through experimental measurements. Specifically, we introduce a phase shift model for predicting the signal reflected by the RIS prototype. We apply the proposed model for optimizing an RISassisted AmBC system and we demonstrate that the use of an RIS can significantly improve the system performance.      
### 11.Model-Free Adaptive Control Compensated with Disturbance  [ :arrow_down: ](https://arxiv.org/pdf/2105.11820.pdf)
>  In this paper, we restudy how to modify the model-free adaptive control (MFAC) to reject the disturbance both in single-input single-output (SISO) systems and multiple-input multiple-output (MIMO) systems, with the aim to pave the way for the development of this interesting controller in the future. First of all, in order to accurately describe the nonlinear system model at each time, we compensate the equivalent dynamic linearization model (EDLM) with disturbance and prove it through the definition of differentiability and the Taylor series. Then based on modified EDLM, we redesign MFAC compensated with disturbance and firstly reanalyze the discrete-time nonlinear system through the closed-loop system equation at each time. This is all possible because some nonlinear system functions can be accurately described by the EDLM compensated with disturbance according to Taylor series. At last, several examples are given to verify the theorem.      
### 12.Distortions Characterization for Dynamic Carrier Allocation in Ultra High-Throughput Satellites  [ :arrow_down: ](https://arxiv.org/pdf/2105.11803.pdf)
>  A novel analytical formula for the characterization of linear and nonlinear distortions in future ultra high-throughput communication payloads is proposed in this work. In this context, the carrier-to-interference ratio related to single-carrier and multicarrier signals is derived. Through the analysis of its behavior valuable insights are created, especially regarding the interaction between linear and nonlinear intersymbol interference. Furthermore, the principle of dynamic carrier allocation optimization is highlighted in a realistic scenario. Within the presented framework, it is proven that a significant gain can be achieved even with a limited number of carriers. Finally, a complexity and accuracy analysis emphasizes the practicality of the proposed approach.      
### 13.Automatic Dynamic Parallelotope Bundles for Reachability Analysis of Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.11796.pdf)
>  Reachable set computation is an important technique for the verification of safety properties of dynamical systems. In this paper, we investigate parallelotope bundle based reachable set computation for discrete nonlinear systems. The algorithm relies on computing an upper bound on the supremum of a nonlinear function over a rectangular domain, traditionally done using Bernstein polynomials. We strive to remove the manual step of parallelotope template selection to make the method fully automatic. Further, we show that changing templates dynamically during computations can improve accuracy. We investigate two techniques for generating the template directions. The first technique approximates the dynamics as a linear transformation and generates templates using this linear transformation. The second technique uses Principle Component Analysis (PCA) of sample trajectories for generating templates. We have implemented our approach in a Python based tool called Kaa and improve its performance by two main enhancements. The tool is modular and use two types of global optimization solvers, the first using Bernstein polynomials and the second using NASA's Kodiak nonlinear optimization library. Second, we leverage the natural parallelism of the reachability algorithm and parallelize the Kaa implementation. We demonstrate the improved accuracy of our approach on several standard nonlinear benchmark systems.      
### 14.Deep learning-based bias transfer for overcoming laboratory differences of microscopic images  [ :arrow_down: ](https://arxiv.org/pdf/2105.11765.pdf)
>  The automated analysis of medical images is currently limited by technical and biological noise and bias. The same source tissue can be represented by vastly different images if the image acquisition or processing protocols vary. For an image analysis pipeline, it is crucial to compensate such biases to avoid misinterpretations. Here, we evaluate, compare, and improve existing generative model architectures to overcome domain shifts for immunofluorescence (IF) and Hematoxylin and Eosin (H&amp;E) stained microscopy images. To determine the performance of the generative models, the original and transformed images were segmented or classified by deep neural networks that were trained only on images of the target bias. In the scope of our analysis, U-Net cycleGANs trained with an additional identity and an MS-SSIM-based loss and Fixed-Point GANs trained with an additional structure loss led to the best results for the IF and H&amp;E stained samples, respectively. Adapting the bias of the samples significantly improved the pixel-level segmentation for human kidney glomeruli and podocytes and improved the classification accuracy for human prostate biopsies by up to 14%.      
### 15.Dense Regression Activation Maps For Lesion Segmentation in CT scans of COVID-19 patients  [ :arrow_down: ](https://arxiv.org/pdf/2105.11748.pdf)
>  Automatic lesion segmentation on thoracic CT enables rapid quantitative analysis of lung involvement in COVID- 19 infections. Obtaining voxel-level annotations for training segmentation networks is prohibitively expensive. Therefore we propose a weakly-supervised segmentation method based on dense regression activation maps (dRAM). Most advanced weakly supervised segmentation approaches exploit class activation maps (CAMs) to localize objects generated from high-level semantic features at a coarse resolution. As a result, CAMs provide coarse outlines that do not align precisely with the object segmentations. Instead, we exploit dense features from a segmentation network to compute dense regression activation maps (dRAMs) for preserving local details. During training, dRAMs are pooled lobe-wise to regress the per-lobe lesion percentage. In such a way, the network achieves additional information regarding the lesion quantification in comparison with the classification approach. Furthermore, we refine dRAMs based on an attention module and dense conditional random field trained together with the main regression task. The refined dRAMs are served as the pseudo labels for training a final segmentation network. When evaluated on 69 CT scans, our method substantially improves the intersection over union from 0.335 in the CAM-based weakly supervised segmentation method to 0.495.      
### 16.The perturbed prox-preconditioned spider algorithm: non-asymptotic convergence bounds  [ :arrow_down: ](https://arxiv.org/pdf/2105.11733.pdf)
>  A novel algorithm named Perturbed Prox-Preconditioned SPIDER (3P-SPIDER) is introduced. It is a stochastic variancereduced proximal-gradient type algorithm built on Stochastic Path Integral Differential EstimatoR (SPIDER), an algorithm known to achieve near-optimal first-order oracle inequality for nonconvex and nonsmooth optimization. Compared to the vanilla prox-SPIDER, 3P-SPIDER uses preconditioned gradient estimators. Preconditioning can either be applied "explicitly" to a gradient estimator or be introduced "implicitly" as in applications to the EM algorithm. 3P-SPIDER also assumes that the preconditioned gradients may (possibly) be not known in closed analytical form and therefore must be approximated which adds an additional degree of perturbation. Studying the convergence in expectation, we show that 3P-SPIDER achieves a near-optimal oracle inequality O(n^(1/2) /epsilon) where n is the number of observations and epsilon the target precision even when the gradient is estimated by Monte Carlo methods. We illustrate the algorithm on an application to the minimization of a penalized empirical loss.      
### 17.A Fast MR Fingerprinting Simulator for Direct Error Estimation and Sequence Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2105.11594.pdf)
>  MR Fingerprinting is a novel quantitative MR technique that could simultaneously provide multiple tissue property maps. When optimizing MRF scans, modeling undersampling errors and field imperfections in cost functions will make the optimization results more practical and robust. However, this process is computationally expensive and impractical for sequence optimization algorithms when MRF signal evolutions need to be generated for each optimization iteration. Here, we introduce a fast MRF simulator to simulate aliased images from actual scan scenarios including undersampling and system imperfections, which substantially reduces computational time and allows for direct error estimation and efficient sequence optimization. By constraining the total number of tissues present in a brain phantom, MRF signals from highly undersampled scans can be simulated as the product of the spatial response functions based on sampling patterns and sequence-dependent temporal functions. During optimization, the spatial response function is independent of sequence design and does not need to be recalculated. We evaluate the performance and computational speed of the proposed approach by simulations and in vivo experiments. We also demonstrate the power of applying the simulator in MRF sequence optimization. The simulation results from the proposed method closely approximate the signals and MRF maps from in vivo scans, with 158 times shorter processing time than the conventional simulation method using Non-uniform Fourier transform. Incorporating the proposed simulator in the MRF optimization framework makes direct estimation of undersampling errors during the optimization process feasible, and provide optimized MRF sequences that are robust against undersampling factors and system inhomogeneity.      
### 18.Online learning of data-driven controllers for unknown switched linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.11523.pdf)
>  Motivated by the goal of learning controllers for complex systems whose dynamics change over time, we consider the problem of designing control laws for systems that switch among a finite set of unknown discrete-time linear subsystems under unknown switching signals. To this end, we propose a method that uses data to directly design a control mechanism without any explicit identification step. Our approach is online, meaning that the data are collected over time while the system is evolving in closed-loop, and are directly used to iteratively update the controller. A major benefit of the proposed online implementation is therefore the ability of the controller to automatically adjust to changes in the operating mode of the system. We show that the proposed control mechanism guarantees stability of the closed-loop switched linear system provided that the switching is slow enough. Effectiveness of the proposed design technique is illustrated for two aerospace applications.      
### 19.Matched Illumination Waveforms using Multi-Tone Sinusoidal Frequency Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2105.11517.pdf)
>  This paper explores the design of constant modulus Matched-Illumination (MI) waveforms using the Multi-Tone Sinusoidal Frequency Modulation (MTSFM) waveform model. MI waveforms are optimized for detecting targets in known noise and clutter Power Spectral Densities (PSDs). There exist well-defined information theoretic methods that describe the design of MI waveforms for a myriad of target/noise/clutter models. However, these methods generally only produce the magnitude square of the MI waveform's spectrum. Additionally, the waveform's time-series is not guaranteed to be constant modulus. The MTSFM is a constant modulus waveform model with a discrete set of design coefficients. The coefficients are adjusted to synthesize constant modulus waveforms that approximate the ideal MI waveform's spectrum. Simulations demonstrate that the MTSFM's detection performance closely approximates an ideal MI waveform spectrum and generally outperforms flat spectrum waveforms across a range of transmit energies when the noise and clutter PSDs vary greatly across the operational band.      
### 20.Towards Low-Photon Nanoscale Imaging: Holographic Phase Retrieval via Maximum Likelihood Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2105.11512.pdf)
>  A new algorithmic framework is presented for holographic phase retrieval via maximum likelihood optimization, which allows for practical and robust image reconstruction. This framework is especially well-suited for holographic coherent diffraction imaging in the \textit{low-photon regime}, where data is highly corrupted by Poisson shot noise. Thus, this methodology provides a viable solution towards the advent of \textit{low-photon nanoscale imaging}, which is a fundamental challenge facing the current state of imaging technologies. Practical optimization algorithms are derived and implemented, and extensive numerical simulations demonstrate significantly improved image reconstruction versus the leading algorithms currently in use. Further experiments compare the performance of popular holographic reference geometries to determine the optimal combined physical setup and algorithm pipeline for practical implementation. Additional features of these methods are also demonstrated, which allow for fewer experimental constraints.      
### 21.Experimenting with Knowledge Distillation techniques for performing Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.11486.pdf)
>  Multi-modal magnetic resonance imaging (MRI) is a crucial method for analyzing the human brain. It is usually used for diagnosing diseases and for making valuable decisions regarding the treatments - for instance, checking for gliomas in the human brain. With varying degrees of severity and detection, properly diagnosing gliomas is one of the most daunting and significant analysis tasks in modern-day medicine. Our primary focus is on working with different approaches to perform the segmentation of brain tumors in multimodal MRI scans. Now, the quantity, variability of the data used for training has always been considered to be crucial for developing excellent models. Hence, we also want to experiment with Knowledge Distillation techniques.      
### 22.Managing HILP Consequences Using Dynamic Distribution System Asset Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2105.11455.pdf)
>  In order to increase the resilience of distribution systems against high-impact low-probability (HILP) events, it is important to prioritize assets damaged by these events so that the lost loads, especially sensitive and important loads, can be recovered faster. For this reason, this paper discusses the prioritization of electricity supply lines for scheduling and prioritizing repair actions. To this end, the economic value of distribution system lines has been considered as a criterion representing the sensitivity of the network to hurricanes. The modeling is based on value, in which the load value, lifetime-based failure probability of the poles, fragility curve, duration of line repair by the maintenance team, and the topology factor have been considered. This is so that the significance of the demand side, the failure extent and accessibility of the lines, the importance of time, and the network configuration are considered. The results provide an order of line priority for fault resolution, in which the topology factor has a larger effect. This modeling has been tested on an IEEE 33-bus network.      
### 23.Neural Network Based Sleep Phases Classification for Resource Constraint Environments  [ :arrow_down: ](https://arxiv.org/pdf/2105.11452.pdf)
>  Sleep is restoration process of the body. The efficiency of this restoration process is directly correlated to the amount of time spent at each sleep phase. Hence, automatic tracking of sleep via wearable devices has attracted both the researchers and industry. Current state-of-the-art sleep tracking solutions are memory and processing greedy and they require cloud or mobile phone connectivity. We propose a memory efficient sleep tracking architecture which can work in the embedded environment without needing any cloud or mobile phone connection. In this study, a novel architecture is proposed that consists of a feature extraction and Artificial Neural Networks based stacking classifier. Besides, we discussed how to tackle with sequential nature of the sleep staging for the memory constraint environments through the proposed framework. To verify the system, a dataset is collected from 24 different subjects for 31 nights with a wrist worn device having 3-axis accelerometer (ACC) and photoplethysmogram (PPG) sensors. Over the collected dataset, the proposed classification architecture achieves 20\% and 14\% better F1 scores than its competitors. Apart from the superior performance, proposed architecture is a promising solution for resource constraint embedded systems by allocating only 4.2 kilobytes of memory (RAM).      
### 24.Tight Inner Approximations of the Positive-Semidefinite Cone viaGrassmannian Packing  [ :arrow_down: ](https://arxiv.org/pdf/2105.12021.pdf)
>  We investigate the problem of finding tight innerapproximations of large dimensional positive semidefinite (PSD)cones. To solve this problem, we develop a novel decompositionframework of the PSD cone by means of conical combinationsof smaller dimensional sub-cones. We show that many innerapproximation techniques could be summarized within thisframework, including the set of (scaled) diagonally dominantmatrices, Factor-widthkmatrices, and Chordal Sparse ma-trices. Furthermore, we provide a more flexible family ofinner approximations of the PSD cone, where we aim toarrange the sub-cones so that they are maximally separatedfrom each other. In doing so, these approximations tend tooccupy large fractions of the volume of the PSD cone. Theproposed approach is connected to a classical packing problemin Riemannian Geometry. Precisely, we show that the problemof finding maximally distant sub-cones in an ambient PSD coneis equivalent to the problem of packing sub-spaces in a Grass-mannian Manifold. We further leverage existing computationalmethod for constructing packings in Grassmannian manifoldsto build tighter approximations of the PSD cone. Numericalexperiments show how the proposed framework can balancebetween accuracy and computational complexity, to efficientlysolve positive-semidefinite programs.      
### 25.Throughput-Fairness Tradeoffs in Mobility Platforms  [ :arrow_down: ](https://arxiv.org/pdf/2105.11999.pdf)
>  This paper studies the problem of allocating tasks from different customers to vehicles in mobility platforms, which are used for applications like food and package delivery, ridesharing, and mobile sensing. A mobility platform should allocate tasks to vehicles and schedule them in order to optimize both throughput and fairness across customers. However, existing approaches to scheduling tasks in mobility platforms ignore fairness. <br>We introduce Mobius, a system that uses guided optimization to achieve both high throughput and fairness across customers. Mobius supports spatiotemporally diverse and dynamic customer demands. It provides a principled method to navigate inherent tradeoffs between fairness and throughput caused by shared mobility. Our evaluation demonstrates these properties, along with the versatility and scalability of Mobius, using traces gathered from ridesharing and aerial sensing applications. Our ridesharing case study shows that Mobius can schedule more than 16,000 tasks across 40 customers and 200 vehicles in an online manner.      
### 26.A Closed-Loop Linear Covariance Framework for Vehicle Path Planning in an Uncertain Obstacle Field  [ :arrow_down: ](https://arxiv.org/pdf/2105.11998.pdf)
>  Path planning in uncertain environments is a key enabler of true vehicle autonomy. Over the past two decades, numerous approaches have been developed to account for errors in the vehicle path while navigating complex and often uncertain environments. An important capability of such planning is the prediction of vehicle dispersion covariances about candidate paths. This work develops a new closed-loop linear covariance (CL-LinCov) framework applicable to wide range of autonomous system architectures. Extensions to current CL-LinCov frameworks are made to accommodate 1) the cascaded architecture typical of autonomous vehicles and 2) the dual-use of continuous sensor information for both navigation and control. The closed-loop nature of the framework preserves the important coupling between the system dynamics, exogenous disturbances, and the guidance, navigation, and control algorithms. The developed framework is applied to a simplified model of an unmanned aerial vehicle and validated by comparison via Monte Carlo analysis. The utility of the CL-LinCov information is illustrated by its application to path planning in an uncertain obstacle field via a modified version of the rapidly exploring random tree algorithm.      
### 27.Reservoir Computing based on Mutually Injected Phase Modulated Semiconductor Lasers as a monolithic integrated hardware accelerator  [ :arrow_down: ](https://arxiv.org/pdf/2105.11972.pdf)
>  In this paper we propose and numerically study a neuromorphic computing scheme that applies delay-based reservoir computing in a laser system consisting of two mutually coupled phase modulated lasers. The scheme can be monolithic integrated in a straightforward manner and alleviates the need for external optical injection, as the data can be directly applied on the on-chip phase modulator placed between the two lasers. The scheme also offers the benefit of increasing the nodes compared to a reservoir computing system using either one laser under feedback or laser under feedback and optical injection. Numerical simulations assess the performance of the integrated reservoir computing system in dispersion compensation tasks in short-reach optical communication systems. We numerically demonstrate that the proposed platform can recover severely distorted 25 Gbaud PAM-4 signals for transmission distances exceeding 50km and outperform other competing delay-based reservoir computing systems relying on optical feedback. The proposed scheme, thanks to its compactness and simplicity, can play the role of a monolithic integrated hardware accelerator in a wide range of application requiring high speed real time processing.      
### 28.Hyperspectral Image Denoising with Log-Based Robust PCA  [ :arrow_down: ](https://arxiv.org/pdf/2105.11927.pdf)
>  It is a challenging task to remove heavy and mixed types of noise from Hyperspectral images (HSIs). In this paper, we propose a novel nonconvex approach to RPCA for HSI denoising, which adopts the log-determinant rank approximation and a novel $\ell_{2,\log}$ norm, to restrict the low-rank or column-wise sparse properties for the component matrices, respectively.For the $\ell_{2,\log}$-regularized shrinkage problem, we develop an efficient, closed-form solution, which is named $\ell_{2,\log}$-shrinkage operator, which can be generally used in other problems. Extensive experiments on both simulated and real HSIs demonstrate the effectiveness of the proposed method in denoising HSIs.      
### 29.Theory of Geometric Super-resolution for Haptic Sensor Design  [ :arrow_down: ](https://arxiv.org/pdf/2105.11914.pdf)
>  Haptic feedback is important to make robots more dexterous and effective. High-resolution haptic sensors are still not widely available, and their application is often bound by robustness issues. A route towards high-resolution and robust sensors is to embed a few sensor units (taxels) into a flexible surface material and use signal processing to achieve sensing with super-resolution accuracy. We propose a theory for geometric super-resolution to guide the development of haptic sensors of this kind. This theory is based on sensor isolines and allows us to predict force sensitivity and accuracy in force magnitude and contact position as a spatial quantity. We evaluate the influence of different factors, such as the elastic properties of the material, using finite element simulations. We compare three representative real sensor unit types, empirically determine their isolines, and validate the theory in a custom-built sensor. Using machine learning techniques, we obtain an average super-resolution factor of 300. As we illustrate, our theory can guide future haptic sensor designs and inform various design choices.      
### 30.Exploiting Adapters for Cross-lingual Low-resource Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2105.11905.pdf)
>  Cross-lingual speech adaptation aims to solve the problem of leveraging multiple rich-resource languages to build models for a low-resource target language. Since the low-resource language has limited training data, speech recognition models can easily overfit. In this paper, we propose to use adapters to investigate the performance of multiple adapters for parameter-efficient cross-lingual speech adaptation. Based on our previous MetaAdapter that implicitly leverages adapters, we propose a novel algorithms called SimAdapter for explicitly learning knowledge from adapters. Our algorithm leverages adapters which can be easily integrated into the Transformer structure.MetaAdapter leverages meta-learning to transfer the general knowledge from training data to the test language. SimAdapter aims to learn the similarities between the source and target languages during fine-tuning using the adapters. We conduct extensive experiments on five-low-resource languages in Common Voice dataset. Results demonstrate that our MetaAdapter and SimAdapter methods can reduce WER by 2.98% and 2.55% with only 2.5% and 15.5% of trainable parameters compared to the strong full-model fine-tuning baseline. Moreover, we also show that these two novel algorithms can be integrated for better performance with up to 3.55% relative WER reduction.      
### 31.Spectrum Correction: Acoustic Scene Classification with Mismatched Recording Devices  [ :arrow_down: ](https://arxiv.org/pdf/2105.11856.pdf)
>  Machine learning algorithms, when trained on audio recordings from a limited set of devices, may not generalize well to samples recorded using other devices with different frequency responses. In this work, a relatively straightforward method is introduced to address this problem. Two variants of the approach are presented. First requires aligned examples from multiple devices, the second approach alleviates this requirement. This method works for both time and frequency domain representations of audio recordings. Further, a relation to standardization and Cepstral Mean Subtraction is analysed. The proposed approach becomes effective even when very few examples are provided. This method was developed during the Detection and Classification of Acoustic Scenes and Events (DCASE) 2019 challenge and won the 1st place in the scenario with mis-matched recording devices with the accuracy of 75%. Source code for the experiments can be found online.      
### 32.A Modulation Front-End for Music Audio Tagging  [ :arrow_down: ](https://arxiv.org/pdf/2105.11836.pdf)
>  Convolutional Neural Networks have been extensively explored in the task of automatic music tagging. The problem can be approached by using either engineered time-frequency features or raw audio as input. Modulation filter bank representations that have been actively researched as a basis for timbre perception have the potential to facilitate the extraction of perceptually salient features. We explore end-to-end learned front-ends for audio representation learning, ModNet and SincModNet, that incorporate a temporal modulation processing block. The structure is effectively analogous to a modulation filter bank, where the FIR filter center frequencies are learned in a data-driven manner. The expectation is that a perceptually motivated filter bank can provide a useful representation for identifying music features. Our experimental results provide a fully visualisable and interpretable front-end temporal modulation decomposition of raw audio. We evaluate the performance of our model against the state-of-the-art of music tagging on the MagnaTagATune dataset. We analyse the impact on performance for particular tags when time-frequency bands are subsampled by the modulation filters at a progressively reduced rate. We demonstrate that modulation filtering provides promising results for music tagging and feature representation, without using extensive musical domain knowledge in the design of this front-end.      
### 33.Improving THz Coverage for 6G URLLC Services via Exploiting Mobile Computing  [ :arrow_down: ](https://arxiv.org/pdf/2105.11834.pdf)
>  Terahertz (THz) communication (0.1-10 THz) is regarded as a promising technology, which provides rich available bandwidth and high data rate of terahertz bit per second (Tbps). However, THz signals suffer from high path loss, which profoundly decreases the transmission distance. To improve THz coverage, we consider the aid of mobile computing. Specifically, job offloading decision in mobile computing and frequency allocation in communication are co-designed to maximize distance and concurrently support ultra-reliable low-latency communications (URLLC) services for the sixth-generation (6G) mobile communication. Further, the above optimization problem is non-convex, then an effective and low-complexity method is proposed via exploiting the special structure of this problem. Finally, numerical results verify the effectiveness of our work.      
### 34.RNNoise-Ex: Hybrid Speech Enhancement System based on RNN and Spectral Features  [ :arrow_down: ](https://arxiv.org/pdf/2105.11813.pdf)
>  Recent interest in exploiting Deep Learning techniques for Noise Suppression, has led to the creation of Hybrid Denoising Systems that combine classic Signal Processing with Deep Learning. In this paper, we concentrated our efforts on extending the RNNoise denoising system (<a class="link-https" data-arxiv-id="1709.08243" href="https://arxiv.org/abs/1709.08243">arXiv:1709.08243</a>) with the inclusion of complementary features during the training phase. We present a comprehensive explanation of the set-up process of a modified system and present the comparative results derived from a performance evaluation analysis, using a reference version of RNNoise as control.      
### 35.The Perturbed Prox-Preconditioned SPIDER algorithm for EM-based large scale learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.11732.pdf)
>  Incremental Expectation Maximization (EM) algorithms were introduced to design EM for the large scale learning framework by avoiding the full data set to be processed at each iteration. Nevertheless, these algorithms all assume that the conditional expectations of the sufficient statistics are explicit. In this paper, we propose a novel algorithm named Perturbed Prox-Preconditioned SPIDER (3P-SPIDER), which builds on the Stochastic Path Integral Differential EstimatoR EM (SPIDER-EM) algorithm. The 3P-SPIDER algorithm addresses many intractabilities of the E-step of EM; it also deals with non-smooth regularization and convex constraint set. Numerical experiments show that 3P-SPIDER outperforms other incremental EM methods and discuss the role of some design parameters.      
### 36.Utterance partitioning for speaker recognition: an experimental review and analysis with new findings under GMM-SVM framework  [ :arrow_down: ](https://arxiv.org/pdf/2105.11728.pdf)
>  The performance of speaker recognition system is highly dependent on the amount of speech used in enrollment and test. This work presents a detailed experimental review and analysis of the GMM-SVM based speaker recognition system in presence of duration variability. This article also reports a comparison of the performance of GMM-SVM classifier with its precursor technique Gaussian mixture model-universal background model (GMM-UBM) classifier in presence of duration variability. The goal of this research work is not to propose a new algorithm for improving speaker recognition performance in presence of duration variability. However, the main focus of this work is on utterance partitioning (UP), a commonly used strategy to compensate the duration variability issue. We have analysed in detailed the impact of training utterance partitioning in speaker recognition performance under GMM-SVM framework. We further investigate the reason why the utterance partitioning is important for boosting speaker recognition performance. We have also shown in which case the utterance partitioning could be useful and where not. Our study has revealed that utterance partitioning does not reduce the data imbalance problem of the GMM-SVM classifier as claimed in earlier study. Apart from these, we also discuss issues related to the impact of parameters such as number of Gaussians, supervector length, amount of splitting required for obtaining better performance in short and long duration test conditions from speech duration perspective. We have performed the experiments with telephone speech from POLYCOST corpus consisting of 130 speakers.      
### 37.There is no data like more data -- current status of machine learning datasets in remote sensing  [ :arrow_down: ](https://arxiv.org/pdf/2105.11726.pdf)
>  Annotated datasets have become one of the most crucial preconditions for the development and evaluation of machine learning-based methods designed for the automated interpretation of remote sensing data. In this paper, we review the historic development of such datasets, discuss their features based on a few selected examples, and address open issues for future developments.      
### 38.High-Frequency aware Perceptual Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2105.11711.pdf)
>  In this paper, we introduce a novel deep neural network suitable for multi-scale analysis and propose efficient model-agnostic methods that help the network extract information from high-frequency domains to reconstruct clearer images. Our model can be applied to multi-scale image enhancement problems including denoising, deblurring and single image super-resolution. Experiments on SIDD, Flickr2K, DIV2K, and REDS datasets show that our method achieves state-of-the-art performance on each task. Furthermore, we show that our model can overcome the over-smoothing problem commonly observed in existing PSNR-oriented methods and generate more natural high-resolution images by applying adversarial training.      
### 39.A Geometry-Informed Deep Learning Framework for Ultra-Sparse 3D Tomographic Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.11692.pdf)
>  Deep learning affords enormous opportunities to augment the armamentarium of biomedical imaging, albeit its design and implementation have potential flaws. Fundamentally, most deep learning models are driven entirely by data without consideration of any prior knowledge, which dramatically increases the complexity of neural networks and limits the application scope and model generalizability. Here we establish a geometry-informed deep learning framework for ultra-sparse 3D tomographic image reconstruction. We introduce a novel mechanism for integrating geometric priors of the imaging system. We demonstrate that the seamless inclusion of known priors is essential to enhance the performance of 3D volumetric computed tomography imaging with ultra-sparse sampling. The study opens new avenues for data-driven biomedical imaging and promises to provide substantially improved imaging tools for various clinical imaging and image-guided interventions.      
### 40.Self-Supervised Graph Representation Learning via Topology Transformations  [ :arrow_down: ](https://arxiv.org/pdf/2105.11689.pdf)
>  We present the Topology Transformation Equivariant Representation learning, a general paradigm of self-supervised learning for node representations of graph data to enable the wide applicability of Graph Convolutional Neural Networks (GCNNs). We formalize the proposed model from an information-theoretic perspective, by maximizing the mutual information between topology transformations and node representations before and after the transformations. We derive that maximizing such mutual information can be relaxed to minimizing the cross entropy between the applied topology transformation and its estimation from node representations. In particular, we seek to sample a subset of node pairs from the original graph and flip the edge connectivity between each pair to transform the graph topology. Then, we self-train a representation encoder to learn node representations by reconstructing the topology transformations from the feature representations of the original and transformed graphs. In experiments, we apply the proposed model to the downstream node and graph classification tasks, and results show that the proposed method outperforms the state-of-the-art unsupervised approaches.      
### 41.Deep Neural Networks and End-to-End Learning for Audio Compression  [ :arrow_down: ](https://arxiv.org/pdf/2105.11681.pdf)
>  Recent achievements in end-to-end deep learning have encouraged the exploration of tasks dealing with highly structured data with unified deep network models. Having such models for compressing audio signals has been challenging since it requires discrete representations that are not easy to train with end-to-end backpropagation. In this paper, we present an end-to-end deep learning approach that combines recurrent neural networks (RNNs) within the training strategy of variational autoencoders (VAEs) with a binary representation of the latent space. We apply a reparametrization trick for the Bernoulli distribution for the discrete representations, which allows smooth backpropagation. In addition, our approach allows the separation of the encoder and decoder, which is necessary for compression tasks. To our best knowledge, this is the first end-to-end learning for a single audio compression model with RNNs, and our model achieves a Signal to Distortion Ratio (SDR) of 20.54.      
### 42.Safe Model-based Off-policy Reinforcement Learning for Eco-Driving in Connected and Automated Hybrid Electric Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2105.11640.pdf)
>  Connected and Automated Hybrid Electric Vehicles have the potential to reduce fuel consumption and travel time in real-world driving conditions. The eco-driving problem seeks to design optimal speed and power usage profiles based upon look-ahead information from connectivity and advanced mapping features. Recently, Deep Reinforcement Learning (DRL) has been applied to the eco-driving problem. While the previous studies synthesize simulators and model-free DRL to reduce online computation, this work proposes a Safe Off-policy Model-Based Reinforcement Learning algorithm for the eco-driving problem. The advantages over the existing literature are three-fold. First, the combination of off-policy learning and the use of a physics-based model improves the sample efficiency. Second, the training does not require any extrinsic rewarding mechanism for constraint satisfaction. Third, the feasibility of trajectory is guaranteed by using a safe set approximated by deep generative models. <br>The performance of the proposed method is benchmarked against a baseline controller representing human drivers, a previously designed model-free DRL strategy, and the wait-and-see optimal solution. In simulation, the proposed algorithm leads to a policy with a higher average speed and a better fuel economy compared to the model-free agent. Compared to the baseline controller, the learned strategy reduces the fuel consumption by more than 21\% while keeping the average speed comparable.      
### 43.Robust Principal Component Analysis Using a Novel Kernel Related with the L1-Norm  [ :arrow_down: ](https://arxiv.org/pdf/2105.11634.pdf)
>  We consider a family of vector dot products that can be implemented using sign changes and addition operations only. The dot products are energy-efficient as they avoid the multiplication operation entirely. Moreover, the dot products induce the $\ell_1$-norm, thus providing robustness to impulsive noise. First, we analytically prove that the dot products yield symmetric, positive semi-definite generalized covariance matrices, thus enabling principal component analysis (PCA). Moreover, the generalized covariance matrices can be constructed in an Energy Efficient (EEF) manner due to the multiplication-free property of the underlying vector products. We present image reconstruction examples in which our EEF PCA method result in the highest peak signal-to-noise ratios compared to the ordinary $\ell_2$-PCA and the recursive $\ell_1$-PCA.      
### 44.Resource Allocation for Massive MIMO HetNets with Quantize-Forward Relaying  [ :arrow_down: ](https://arxiv.org/pdf/2105.11581.pdf)
>  We investigate how massive MIMO impacts the uplink transmission design in a heterogeneous network (HetNet) where multiple users communicate with a macro-cell base station (MCBS) with the help of a small-cell BS (SCBS) with zero-forcing (ZF) detection at each BS. We first analyze the quantize-forward (QF) relaying scheme with joint decoding (JD) at the MCBS. To maximize the rate region, we optimize the quantization of all user data streams at the SCBS by developing a novel water-filling algorithm that is based on the Descartes' rule of signs. Our result shows that as a user link to the SCBS becomes stronger than that to the MCBS, the SCBS deploys finer quantization to that user data stream. We further propose a new simplified scheme through Wyner-Ziv (WZ) binning and time-division (TD) transmission at the SCBS, which allows not only sequential but also separate decoding of each user message at the MCBS. For this new QF-WZTD scheme, the optimal quantization parameters are identical to that of the QF-JD scheme while the phase durations are conveniently optimized as functions of the quantization parameters. Despite its simplicity, the QF-WZTD scheme achieves the same rate performance of the QF-JD scheme, making it an attractive option for future HetNets.      
### 45.Pan-sharpening via High-pass Modification Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2105.11576.pdf)
>  Most existing deep learning-based pan-sharpening methods have several widely recognized issues, such as spectral distortion and insufficient spatial texture enhancement, we propose a novel pan-sharpening convolutional neural network based on a high-pass modification block. Different from existing methods, the proposed block is designed to learn the high-pass information, leading to enhance spatial information in each band of the multi-spectral-resolution images. To facilitate the generation of visually appealing pan-sharpened images, we propose a perceptual loss function and further optimize the model based on high-level features in the near-infrared space. Experiments demonstrate the superior performance of the proposed method compared to the state-of-the-art pan-sharpening methods, both quantitatively and qualitatively. The proposed model is open-sourced at <a class="link-external link-https" href="https://github.com/jiaming-wang/HMB" rel="external noopener nofollow">this https URL</a>.      
### 46.Model-Dependent Prosthesis Control with Real-Time Force Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2105.11561.pdf)
>  Lower-limb prosthesis wearers are more prone to fall than non-amputees. Powered prosthesis can reduce this instability of passive prostheses. While shown to be more stable in practice, powered prostheses generally use model-independent control methods that lack formal guarantees of stability and rely on heuristic tuning. Recent work overcame one of the limitations of model-based prosthesis control by developing a class of stable prosthesis subsystem controllers independent of the human model, except for its interaction forces with the prosthesis. Force sensors to measure these socket interaction forces as well as the ground reaction forces (GRFs) could introduce noise into the control loop making hardware implementation infeasible. This paper addresses part of this limitation by obtaining some of the GRFs through an insole pressure sensor. This paper achieves the first model-dependent prosthesis controller that uses in-the-loop on-board real-time force sensing, resulting in stable human-prosthesis walking and increasing the validity of our formal guarantees of stability.      
### 47.Discrete MMSE Precoding for Multiuser MIMO Systems with PSK Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2105.11555.pdf)
>  We propose an optimal MMSE precoding technique using quantized signals with constant envelope. Unlike the existing MMSE design that relies on 1-bit resolution, the proposed approach employs uniform phase quantization and the bounding step in the branch-and-bound method is different in terms of considering the most restrictive relaxation of the nonconvex problem, which is then utilized for a suboptimal design also. Moreover, unlike prior studies, we propose three different soft detection methods and an iterative detection and decoding scheme that allow the utilization of channel coding in conjunction with low-resolution precoding. Besides an exact approach for computing the extrinsic information, we propose two approximations with reduced computational complexity. Numerical simulations show that utilizing the MMSE criterion instead of the established maximum-minimum distance to the decision threshold yields a lower bit-error-rate in many scenarios. Furthermore, when using the MMSE criterion, a smaller number of bound evaluations in the branch-and-bound method is required for low and medium SNR. Finally, results based on an LDPC block code indicate that the receive processing schemes yield a lower bit-error-rate compared to the conventional design.      
### 48.A Formal Approach to Physics-Based Attacks in Cyber-Physical Systems (Extended Version)  [ :arrow_down: ](https://arxiv.org/pdf/1902.04572.pdf)
>  We apply formal methods to lay and streamline theoretical foundations to reason about Cyber-Physical Systems (CPSs) and physics-based attacks, i.e., attacks targeting physical devices. We focus on a formal treatment of both integrity and denial of service attacks to sensors and actuators of CPSs, and on the timing aspects of these attacks. Our contributions are fourfold. (1)~We define a hybrid process calculus to model both CPSs and physics-based attacks. (2)~We formalise a threat model that specifies MITM attacks that can manipulate sensor readings or control commands in order to drive a CPS into an undesired state, and we provide the means to assess attack tolerance/vulnerability with respect to a given attack. (3)~We formalise how to estimate the impact of a successful attack on a CPS and investigate possible quantifications of the success chances of an attack. (4)~We illustrate our definitions and results by formalising a non-trivial running example in Uppaal SMC, the statistical extension of the Uppaal model checker; we use Uppaal SMC as an automatic tool for carrying out a static security analysis of our running example in isolation and when exposed to three different physics-based attacks with different impacts.      

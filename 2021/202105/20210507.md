# ArXiv eess --Fri, 7 May 2021
### 1.Deep Learning based Multi-modal Computing with Feature Disentanglement for MRI Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2105.02835.pdf)
>  Purpose: Different Magnetic resonance imaging (MRI) modalities of the same anatomical structure are required to present different pathological information from the physical level for diagnostic needs. However, it is often difficult to obtain full-sequence MRI images of patients owing to limitations such as time consumption and high cost. The purpose of this work is to develop an algorithm for target MRI sequences prediction with high accuracy, and provide more information for clinical diagnosis. Methods: We propose a deep learning based multi-modal computing model for MRI synthesis with feature disentanglement strategy. To take full advantage of the complementary information provided by different modalities, multi-modal MRI sequences are utilized as input. Notably, the proposed approach decomposes each input modality into modality-invariant space with shared information and modality-specific space with specific information, so that features are extracted separately to effectively process the input data. Subsequently, both of them are fused through the adaptive instance normalization (AdaIN) layer in the decoder. In addition, to address the lack of specific information of the target modality in the test phase, a local adaptive fusion (LAF) module is adopted to generate a modality-like pseudo-target with specific information similar to the ground truth. Results: To evaluate the synthesis performance, we verify our method on the BRATS2015 dataset of 164 subjects. The experimental results demonstrate our approach significantly outperforms the benchmark method and other state-of-the-art medical image synthesis methods in both quantitative and qualitative measures. Compared with the pix2pixGANs method, the PSNR improves from 23.68 to 24.8. Conclusion: The proposed method could be effective in prediction of target MRI sequences, and useful for clinical diagnosis and treatment.      
### 2.Design of Non-Coherent and Coherent Receivers for Chirp Spread Spectrum Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.02833.pdf)
>  LoRaWAN is a prominent communication standard to enable reliable low-power, long-range communications for the Internet of Things (IoT). The modulation technique used in LoRaWAN, commonly known as LoRa modulation, is based on the principle of chirp spread spectrum (CSS). While extensive research has been conducted on improving various aspects of LoRa transmitter, the design of LoRa receivers that can operate under practical conditions of timing and frequency offsets is missing. To fill this gap, this paper develops and presents detailed designs of timing, frequency and phase synchronization circuits for both non-coherent and coherent detection of CSS signals. More importantly, the proposed receiver can be used to detect the recently proposed CSS-based modulation that embeds extra information bits in the starting phases of conventional CSS symbols. Such a transmission scheme, referred to as phase-shift keying CSS (PSK-CSS) helps to improve the transmission rates of the conventional CSS system. In particular, it is shown that the bit error rate performance of the PSK-CSS scheme achieved with the proposed practical coherent receiver has only 0.25 dB gaps as compared to the ideal co-coherent receiver.      
### 3.Pathloss modeling for in-body optical wireless communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.02829.pdf)
>  Optical wireless communications (OWCs) have been recognized as a candidate enabler of next generation in-body nano-scale networks and implants. The development of an accurate channel model capable of accommodating the particularities of different type of tissues is expected to boost the design of optimized communication protocols for such applications. Motivated by this, this paper focuses on presenting a general pathloss model for in-body OWCs. In particular, we use experimental measurements in order to extract analytical expressions for the absorption coefficients of the five main tissues' constitutions, namely oxygenated and de-oxygenated blood, water, fat, and melanin. Building upon these expressions, we derive a general formula for the absorption coefficient evaluation of any biological tissue. To verify the validity of this formula, we compute the absorption coefficient of complex tissues and compare them against respective experimental results reported by independent research works. Interestingly, we observe that the analytical formula has high accuracy and is capable of modeling the pathloss and, therefore, the penetration depth in complex tissues.      
### 4.Activity-Aware Deep Cognitive Fatigue Assessment using Wearables  [ :arrow_down: ](https://arxiv.org/pdf/2105.02824.pdf)
>  Cognitive fatigue has been a common problem among workers which has become an increasing global problem since the emergence of COVID-19 as a global pandemic. While existing multi-modal wearable sensors-aided automatic cognitive fatigue monitoring tools have focused on physical and physiological sensors (ECG, PPG, Actigraphy) analytic on specific group of people (say gamers, athletes, construction workers), activity-awareness is utmost importance due to its different responses on physiology in different person. In this paper, we propose a novel framework, Activity-Aware Recurrent Neural Network (\emph{AcRoNN}), that can generalize individual activity recognition and improve cognitive fatigue estimation significantly. We evaluate and compare our proposed method with state-of-art methods using one real-time collected dataset from 5 individuals and another publicly available dataset from 27 individuals achieving max. 19% improvement.      
### 5.A High-Performance, Reconfigurable, Fully Integrated Time-Domain Reflectometry Architecture Using Digital I/Os  [ :arrow_down: ](https://arxiv.org/pdf/2105.02822.pdf)
>  Time-domain reflectometry (TDR) is an established means of measuring impedance inhomogeneity of a variety of waveguides, providing critical data necessary to characterize and optimize the performance of high-bandwidth computational and communication systems. However, TDR systems with both the high spatial resolution (sub-cm) and voltage resolution (sub-$\muV$) required to evaluate high-performance waveguides are physically large and often cost-prohibitive, severely limiting their utility as testing platforms and greatly limiting their use in characterizing and trouble-shooting fielded hardware. <br>Consequently, there exists a growing technical need for an electronically simple, portable, and low-cost TDR technology. The receiver of a TDR system plays a key role in recording reflection waveforms; thus, such a receiver must have high analog bandwidth, high sampling rate, and high-voltage resolution. However, these requirements are difficult to meet using low-cost analog-to-digital converters (ADCs). This article describes a new TDR architecture, namely, jitter-based APC (JAPC), which obviates the need for external components based on an alternative concept, analog-to-probability conversion (APC) that was recently proposed. These results demonstrate that a fully reconfigurable and highly integrated TDR (iTDR) can be implemented on a field-programmable gate array (FPGA) chip without using any external circuit components. Empirical evaluation of the system was conducted using an HDMI cable as the device under test (DUT), and the resulting impedance inhomogeneity pattern (IIP) of the DUT was extracted with spatial and voltage resolutions of 5 cm and 80 $\muV$, respectively. These results demonstrate the feasibility of using the prototypical JAPC-based iTDR for real-world waveguide characterization applications      
### 6.Simulating the DFT Algorithm for Audio Processing  [ :arrow_down: ](https://arxiv.org/pdf/2105.02820.pdf)
>  Since the evolution of digital computers, the storage of data has always been in terms of discrete bits that can store values of either 1 or 0. Hence, all computer programs (such as MATLAB), convert any input continuous signal into a discrete dataset. Applying this to oscillating signals, such as audio, opens a domain for processing as well as editing. The Fourier transform, which is an integral over infinite limits, for the use of signal processing is discrete. The essential feature of the Fourier transform is to decompose any signal into a combination of multiple sinusoidal waves that are easy to deal with. The discrete Fourier transform (DFT) can be represented as a matrix, with each data point acting as an orthogonal point, allowing one to perform complicated transformations on individual frequencies. Due to this formulation, all the concepts of linear algebra and linear transforms prove to be extremely useful here. In this paper, we first explain the theoretical basis of audio processing using linear algebra, and then focus on a simulation coded in MATLAB, to process and edit various audio samples. The code is open ended and easily expandable by just defining newer matrices which can transform over the original audio signal. Finally, this paper attempts to highlight and briefly explain the results that emerge from the simulation      
### 7.Evaluating Sensor Data Quality in Internet ofThings Smart Agriculture Applications  [ :arrow_down: ](https://arxiv.org/pdf/2105.02819.pdf)
>  The unprecedented growth of Internet of Things (IoT) and its applications in areas such as Smart Agriculture compels the need to devise newer ways for evaluating the quality of such applications. While existing models for application quality focus on the quality experienced by the end-user (captured using likert scale), IoT applications have minimal human involvement and rely on machine to machine communication and analytics to drive decision via actuations. In this paper, we first present a conceptual framework for the evaluation of IoT application quality. Subsequently, we propose, develop and validate via empirical evaluations a novel model for evaluating sensor data quality that is a key component in assessing IoT application quality. We present an implementation of the sensor data quality model and demonstrate how the IoT sensor data quality can be integrated with a Smart Agriculture application. Results of experimental evaluations conducted using data from a real-world testbed concludes the paper.      
### 8.Holographic Transmitarray Antenna with linear Polarization in X band  [ :arrow_down: ](https://arxiv.org/pdf/2105.02817.pdf)
>  In this paper, we present the design and demonstration of transmitarray antennas (TAs) based on the holographic technique for the first time. According to the holographic theory, the amplitudes and phases of electromagnetic waves can be recorded on a surface, and then they can be reconstructed independently. This concept is used to design single-beam and multi-beam linearly polarized holographic TAs without using any iterative optimization algorithms. Initially, a transmission impedance surface is analyzed and compared with the reflection one. Then, interferograms associated with the scalar admittance distribution are defined according to the number and direction of the radiation beams. After that, a transmission metasurface of dimensions equal to 0:26l0 is hired to design holographic TAs at 12 GHz. Several examples are provided to support the method. In the end, a linearly polarized circular aperture wideband holographic transmitarray antenna with a radius of 13.3 cm has been manufactured and tested. The antenna achieves 12.5% (11.4-12.9 GHz) 1-dB gain bandwidth and 23.8 dB maximum gain, leading to 21.46% aperture efficiency.      
### 9.End-to-end deep meta modelling to calibrate and optimize energy consumption and comfort  [ :arrow_down: ](https://arxiv.org/pdf/2105.02814.pdf)
>  In this paper, we propose a new end-to-end methodology to optimize the energy performance as well as comfort and air quality in large buildings without any renovation work. We introduce a metamodel based on recurrent neural networks and trained to predict the behavior of a general class of buildings using a database sampled from a simulation program. This metamodel is then deployed in different frameworks and its parameters are calibrated using the specific data of two real buildings. Parameters are estimated by comparing the predictions of the metamodel with real data obtained from sensors using the CMA-ES algorithm, a derivative free optimization procedure. Then, energy consumptions are optimized while maintaining a target thermal comfort and air quality, using the NSGA-II multi-objective optimization procedure. The numerical experiments illustrate how this metamodel ensures a significant gain in energy efficiency, up to almost 10%, while being computationally much more appealing than numerical models and flexible enough to be adapted to several types of buildings.      
### 10.Prediction of Ultrasonic Guided Wave Propagation in Solid-fluid and their Interface under Uncertainty using Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.02813.pdf)
>  Structural health monitoring (SHM) systems use the non-destructive testing principle for damage identification. As part of SHM, the propagation of ultrasonic guided waves (UGWs) is tracked and analyzed for the changes in the associated wave pattern. These changes help identify the location of a structural damage, if any. We advance existing research by accounting for uncertainty in the material and geometric properties of a structure. The physics model used in this study comprises of a monolithically coupled system of acoustic and elastic wave equations, known as the wave propagation in fluid-solid and their interface (WpFSI) problem. As the UGWs propagate in the solid, fluid, and their interface, the wave signal displacement measurements are contrasted against the benchmark pattern. For the numerical solution, we develop an efficient algorithm that successfully addresses the inherent complexity of solving the multiphysics problem under uncertainty. We present a procedure that uses Gaussian process regression and convolutional neural network for predicting the UGW propagation in a solid-fluid and their interface under uncertainty. First, a set of training images for different realizations of the uncertain parameters of the inclusion inside the structure is generated using a monolithically-coupled system of acoustic and elastic wave equations. Next, Gaussian processes trained with these images are used for predicting the propagated wave with convolutional neural networks for further enhancement to produce high-quality images of the wave patterns for new realizations of the uncertainty. The results indicate that the proposed approach provides an accurate prediction for the WpFSI problem in the presence of uncertainty.      
### 11.Wearable and Continuous Prediction of Passage of Time Perception for Monitoring Mental Health  [ :arrow_down: ](https://arxiv.org/pdf/2105.02808.pdf)
>  A person's passage of time perception (POTP) is strongly linked to their mental state and stress response, and can therefore provide an easily quantifiable means of continuous mental health monitoring. In this work, we develop a custom experiment and Machine Learning (ML) models for predicting POTP from biomarkers acquired from wearable biosensors. We first confirm that individuals experience time passing slower than usual during fear or sadness (p = 0.046) and faster than usual during cognitive tasks (p = 2 x 10^-5). Then, we group together the experimental segments associated with fast, slow, and normal POTP, and train a ML model to classify between these states based on a person's biomarkers. The classifier had a weighted average F-1 score of 79%, with the fast-passing time class having the highest F-1 score of 93%. Next, we classify each individual's POTP regardless of the task at hand, achieving an F-1 score of 77.1% when distinguishing time passing faster rather than slower than usual. In the two classifiers, biomarkers derived from the respiration, electrocardiogram, skin conductance, and skin temperature signals contributed most to the classifier output, thus enabling real-time POTP monitoring using noninvasive, wearable biosensors.      
### 12.Saliency-Guided Deep Learning Network for Automatic Tumor Bed Volume Delineation in Post-operative Breast Irradiation  [ :arrow_down: ](https://arxiv.org/pdf/2105.02771.pdf)
>  Efficient, reliable and reproducible target volume delineation is a key step in the effective planning of breast radiotherapy. However, post-operative breast target delineation is challenging as the contrast between the tumor bed volume (TBV) and normal breast tissue is relatively low in CT images. In this study, we propose to mimic the marker-guidance procedure in manual target delineation. We developed a saliency-based deep learning segmentation (SDL-Seg) algorithm for accurate TBV segmentation in post-operative breast irradiation. The SDL-Seg algorithm incorporates saliency information in the form of markers' location cues into a U-Net model. The design forces the model to encode the location-related features, which underscores regions with high saliency levels and suppresses low saliency regions. The saliency maps were generated by identifying markers on CT images. Markers' locations were then converted to probability maps using a distance-transformation coupled with a Gaussian filter. Subsequently, the CT images and the corresponding saliency maps formed a multi-channel input for the SDL-Seg network. Our in-house dataset was comprised of 145 prone CT images from 29 post-operative breast cancer patients, who received 5-fraction partial breast irradiation (PBI) regimen on GammaPod. The performance of the proposed method was compared against basic U-Net. Our model achieved mean (standard deviation) of 76.4 %, 6.76 mm, and 1.9 mm for DSC, HD95, and ASD respectively on the test set with computation time of below 11 seconds per one CT volume. SDL-Seg showed superior performance relative to basic U-Net for all the evaluation metrics while preserving low computation cost. The findings demonstrate that SDL-Seg is a promising approach for improving the efficiency and accuracy of the on-line treatment planning procedure of PBI, such as GammaPod based PBI.      
### 13.Nonlinear Full Information and Moving Horizon Estimation: Robust Global Asymptotic Stability  [ :arrow_down: ](https://arxiv.org/pdf/2105.02764.pdf)
>  In this paper, we propose time-discounted schemes for full information estimation (FIE) and moving horizon estimation (MHE) that are robustly globally asymptotically stable (RGAS). We consider general nonlinear system dynamics with nonlinear process and output disturbances that are a priori unknown. For FIE being RGAS, our only assumption is that the system is time-discounted incrementally input-output-to-state-stable (i-IOSS). Hence, we show that this condition is sufficient for the existence of RGAS observers. Based on the stability result for FIE, we provide sufficient conditions such that the induced MHE scheme is RGAS as well for sufficiently large horizons. For both schemes, we can guarantee convergence of the estimation error in case the disturbances converge to zero without incorporating a priori knowledge. Finally, we present explicit converge rates and show how to verify that the MHE results approach the FIE results for increasing horizons.      
### 14.Deep Neural Network Feature Designs for RF Data-Driven Wireless Device Classification  [ :arrow_down: ](https://arxiv.org/pdf/2105.02755.pdf)
>  Most prior works on deep learning-based wireless device classification using radio frequency (RF) data apply off-the-shelf deep neural network (DNN) models, which were matured mainly for domains like vision and language. However, wireless RF data possesses unique characteristics that differentiate it from these other domains. For instance, RF data encompasses intermingled time and frequency features that are dictated by the underlying hardware and protocol configurations. In addition, wireless RF communication signals exhibit cyclostationarity due to repeated patterns (PHY pilots, frame prefixes, etc.) that these signals inherently contain. In this paper, we begin by explaining and showing the unsuitability as well as limitations of existing DNN feature design approaches currently proposed to be used for wireless device classification. We then present novel feature design approaches that exploit the distinct structures of the RF communication signals and the spectrum emissions caused by transmitter hardware impairments to custom-make DNN models suitable for classifying wireless devices using RF signal data. Our proposed DNN feature designs substantially improve classification robustness in terms of scalability, accuracy, signature anti-cloning, and insensitivity to environment perturbations. We end the paper by presenting other feature design strategies that have great potentials for providing further performance improvements of the DNN-based wireless device classification, and discuss the open research challenges related to these proposed strategies.      
### 15.Non-Semantic Evaluation of Image Forensics Tools: Methodology and Database  [ :arrow_down: ](https://arxiv.org/pdf/2105.02700.pdf)
>  With the aim of evaluating image forensics tools, we propose a methodology to create forgeries traces, leaving intact the semantics of the image. Thus, the only forgery cues left are the specific alterations of one or several aspects of the image formation pipeline. This methodology creates automatically forged images that are challenging to detect for forensic tools and overcomes the problem of creating convincing semantic forgeries. Based on this methodology, we create the Trace database and conduct an evaluation of the main state-of-the-art image forensics tools.      
### 16.SS-CADA: A Semi-Supervised Cross-Anatomy Domain Adaptation for Coronary Artery Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.02674.pdf)
>  The segmentation of coronary arteries by convolutional neural network is promising yet requires a large amount of labor-intensive manual annotations. Transferring knowledge from retinal vessels in widely-available public labeled fundus images (FIs) has a potential to reduce the annotation requirement for coronary artery segmentation in X-ray angiograms (XAs) due to their common tubular structures. However, it is challenged by the cross-anatomy domain shift due to the intrinsically different vesselness characteristics in different anatomical regions under even different imaging protocols. To solve this problem, we propose a Semi-Supervised Cross-Anatomy Domain Adaptation (SS-CADA) which requires only limited annotations for coronary arteries in XAs. With the supervision from a small number of labeled XAs and publicly available labeled FIs, we propose a vesselness-specific batch normalization (VSBN) to individually normalize feature maps for them considering their different cross-anatomic vesselness characteristics. In addition, to further facilitate the annotation efficiency, we employ a self-ensembling mean-teacher (SEMT) to exploit abundant unlabeled XAs by imposing a prediction consistency constraint. Extensive experiments show that our SS-CADA is able to solve the challenging cross-anatomy domain shift, achieving accurate segmentation for coronary arteries given only a small number of labeled XAs.      
### 17.Ordinal UNLOC: Target Localization with Noisy and Incomplete Distance Measures  [ :arrow_down: ](https://arxiv.org/pdf/2105.02671.pdf)
>  A main challenge in target localization arises from the lack of reliable distance measures. This issue is especially pronounced in indoor settings due to the presence of walls, floors, furniture, and other dynamically changing conditions such as the movement of people and goods, varying temperature, and airflows. Here, we develop a new computational framework to estimate the location of a target without the need for reliable distance measures. The method, which we term Ordinal UNLOC, uses only ordinal data obtained from comparing the signal strength from anchor pairs at known locations to the target. Our estimation technique utilizes rank aggregation, function learning as well as proximity-based unfolding optimization. As a result, it yields accurate target localization for common transmission models with unknown parameters and noisy observations that are reminiscent of practical settings. Our results are validated by both numerical simulations and hardware experiments.      
### 18.A Reinforcement Learning-based Economic Model Predictive Control Framework for Autonomous Operation of Chemical Reactors  [ :arrow_down: ](https://arxiv.org/pdf/2105.02656.pdf)
>  Economic model predictive control (EMPC) is a promising methodology for optimal operation of dynamical processes that has been shown to improve process economics considerably. However, EMPC performance relies heavily on the accuracy of the process model used. As an alternative to model-based control strategies, reinforcement learning (RL) has been investigated as a model-free control methodology, but issues regarding its safety and stability remain an open research challenge. This work presents a novel framework for integrating EMPC and RL for online model parameter estimation of a class of nonlinear systems. In this framework, EMPC optimally operates the closed loop system while maintaining closed loop stability and recursive feasibility. At the same time, to optimize the process, the RL agent continuously compares the measured state of the process with the model's predictions (nominal states), and modifies model parameters accordingly. The major advantage of this framework is its simplicity; state-of-the-art RL algorithms and EMPC schemes can be employed with minimal modifications. The performance of the proposed framework is illustrated on a network of reactions with challenging dynamics and practical significance. This framework allows control, optimization, and model correction to be performed online and continuously, making autonomous reactor operation more attainable.      
### 19.Security Protection in Cooperative Control of Multi-agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.02618.pdf)
>  Due to the wide application of average consensus algorithm, its security and privacy problems have attracted great attention. In this paper, we consider the system threatened by a set of unknown agents that are both "malicious" and "curious", who add additional input signals to the system in order to perturb the final consensus value or prevent consensus, and try to infer the initial state of other agents. At the same time, we design a privacy-preserving average consensus algorithm equipped with an attack detector with a time-varying exponentially decreasing threshold for every benign agent, which can guarantee the initial state privacy of every benign agent, under mild conditions. The attack detector will trigger an alarm if it detects the presence of malicious attackers. An upper bound of false alarm rate in the absence of malicious attackers and the necessary and sufficient condition for there is no undetectable input by the attack detector in the system are given. Specifically, we show that under this condition, the system can achieve asymptotic consensus almost surely when no alarm is triggered from beginning to end, and an upper bound of convergence rate and some quantitative estimates about the error of final consensus value are given. Finally, numerical case is used to illustrate the effectiveness of some theoretical results.      
### 20.A Binarizing NUV Prior and its Use for M-Level Control and Digital-to-Analog Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2105.02599.pdf)
>  Priors with a NUV representation (normal with unknown variance) have mostly been used for sparsity. In this paper, a novel NUV prior is proposed that effectively binarizes. While such a prior may have many uses, in this paper, we explore its use for discrete-level control (with M $\geq$ 2 levels) including, in particular, a practical scheme for digital-to-analog conversion. The resulting computations, for each planning period, amount to iterating forward-backward Gaussian message passing recursions (similar to Kalman smoothing), with a complexity (per iteration) that is linear in the planning horizon. In consequence, the proposed method is not limited to a short planning horizon and can therefore outperform "optimal" methods. A preference for sparse level switches can easily be incorporated.      
### 21.USM-SED - A Dataset for Polyphonic Sound Event Detection in Urban Sound Monitoring Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2105.02592.pdf)
>  This paper introduces a novel dataset for polyphonic sound event detection in urban sound monitoring use-cases. Based on isolated sounds taken from the FSD50k dataset, 20,000 polyphonic soundscapes are synthesized with sounds being randomly positioned in the stereo panorama using different loudness levels. The paper gives a detailed discussion of possible application scenarios, explains the dataset generation process in detail, and discusses current limitations of the proposed USM-SED dataset.      
### 22.Quantification of pulmonary involvement in COVID-19 pneumonia by means of a cascade oftwo U-nets: training and assessment on multipledatasets using different annotation criteria  [ :arrow_down: ](https://arxiv.org/pdf/2105.02566.pdf)
>  The automatic assignment of a severity score to the CT scans of patients affected by COVID-19 pneumonia could reduce the workload in radiology departments. This study aims at exploiting Artificial intelligence (AI) for the identification, segmentation and quantification of COVID-19 pulmonary lesions. We investigated the effects of using multiple datasets, heterogeneously populated and annotated according to different criteria. We developed an automated analysis pipeline, the LungQuant system, based on a cascade of two U-nets. The first one (U-net_1) is devoted to the identification of the lung parenchyma, the second one (U-net_2) acts on a bounding box enclosing the segmented lungs to identify the areas affected by COVID-19 lesions. Different public datasets were used to train the U-nets and to evaluate their segmentation performances, which have been quantified in terms of the Dice index. The accuracy in predicting the CT-Severity Score (CT-SS) of the LungQuant system has been also evaluated. Both Dice and accuracy showed a dependency on the quality of annotations of the available data samples. On an independent and publicly available benchmark dataset, the Dice values measured between the masks predicted by LungQuant system and the reference ones were 0.95$\pm$0.01 and 0.66$\pm$0.13 for the segmentation of lungs and COVID-19 lesions, respectively. The accuracy of 90% in the identification of the CT-SS on this benchmark dataset was achieved. We analysed the impact of using data samples with different annotation criteria in training an AI-based quantification system for pulmonary involvement in COVID-19 pneumonia. In terms of the Dice index, the U-net segmentation quality strongly depends on the quality of the lesion annotations. Nevertheless, the CT-SS can be accurately predicted on independent validation sets, demonstrating the satisfactory generalization ability of the LungQuant.      
### 23.Differential Transmission Schemes for Generalized Spatial Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2105.02478.pdf)
>  Differential modulation schemes are very relevant in receivers having power and processing limitations, as these schemes dispense with the need for knowledge of channel coefficients for symbol detection. Spatial modulation (SM) is a scheme used in multi-antenna transmission scenarios where the data is transmitted in the amplitude, phase and spatial domains through selected antennas. Differential schemes for SM such as generalized differential scheme for spatial modulation (GD-SM) employ a similar method like conventional SM where it uses only one transmit antenna at a time to convey the information. In the coherent domain, multiple antennas were activated in combination during every time slot to enhance the spectral efficiency (SE). In this paper, we propose two differential schemes which activate two or more antennas at a time to transmit the modulated symbol. These schemes achieve higher SE using a lesser number of antennas transmitting lower order modulation schemes instead of the higher number of antennas required for SM and conventional GD-SM. Simulation studies reveal that the optimal detector for these schemes has better bit error rate performance than GD-SM. We also derive the analytical union bound for the proposed schemes and is satisfied from medium to high SNR ranges.      
### 24.Estimation and inference of signals via the stochastic geometry of spectrogram level sets  [ :arrow_down: ](https://arxiv.org/pdf/2105.02471.pdf)
>  Spectrograms are fundamental tools in the detection, estimation and analysis of signals in the time-frequency analysis paradigm. Signal analysis via spectrograms have traditionally explored their peaks, i.e. their maxima, complemented by a recent interest in their zeros or minima. In particular, recent investigations have demonstrated connections between Gabor spectrograms of Gaussian white noise and Gaussian analytic functions (abbrv. GAFs) in different geometries. However, the zero sets (or the maxima or minima) of GAFs have a complicated stochastic structure, which makes a direct theoretical analysis of usual spectrogram based techniques via GAFs a difficult proposition. These techniques, in turn, largely rely on statistical observables from the analysis of spatial data, whose distributional properties for spectrogram extrema are mostly understood empirically. <br>In this work, we investigate spectrogram analysis via an examination of the stochastic, geometric and analytical properties of their level sets. This includes a comparative analysis of relevant spectrogram structures, with vs without the presence of signals coupled with Gaussian white noise. We obtain theorems demonstrating the efficacy of a spectrogram level sets based approach to the detection and estimation of signals, framed in a concrete inferential set-up. Exploiting these ideas as theoretical underpinnings, we propose a level sets based algorithm for signal analysis that is intrinsic to given spectrogram data. We substantiate the effectiveness of the algorithm by extensive empirical studies, and provide additional theoretical analysis to elucidate some of its key features. Our results also have theoretical implications for spectrogram zero based approaches to signal analysis.      
### 25.Point Cloud Audio Processing  [ :arrow_down: ](https://arxiv.org/pdf/2105.02469.pdf)
>  Most audio processing pipelines involve transformations that act on fixed-dimensional input representations of audio. For example, when using the Short Time Fourier Transform (STFT) the DFT size specifies a fixed dimension for the input representation. As a consequence, most audio machine learning models are designed to process fixed-size vector inputs which often prohibits the repurposing of learned models on audio with different sampling rates or alternative representations. We note, however, that the intrinsic spectral information in the audio signal is invariant to the choice of the input representation or the sampling rate. Motivated by this, we introduce a novel way of processing audio signals by treating them as a collection of points in feature space, and we use point cloud machine learning models that give us invariance to the choice of representation parameters, such as DFT size or the sampling rate. Additionally, we observe that these methods result in smaller models, and allow us to significantly subsample the input representation with minimal effects to a trained model performance.      
### 26.Subjective Opinions Matter: Controllable Image Quality Assessment Using Pseudo Reference Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.02464.pdf)
>  Recently, image quality assessment (IQA) has achieved remarkable progress with the success of deep learning. However, existing IQA methods are practically troublesome. With the strict pre-condition of full-reference (FR) methods limiting its application in real scenarios, the no-reference (NR) scheme is also inconvenient due to its unsatisfying performance and the lack of flexibility or controllability. In this paper, we aim to bridge the gap between FR and NR-IQA and introduce a brand new scheme, namely pseudo-reference image quality assessment (PR-IQA), by introducing pseudo reference images. As the first implementation of PR-IQA, we propose a novel baseline, i.e., Unpaired-IQA, from the perspective of subjective opinion-aware IQA. A self-adaptive feature fusion (SAFF) module is well-designed for the unpaired features in PR-IQA, with which the model can extract quality-discriminative features from distorted images and content variability-robust features from pseudo reference ones, respectively. Extensive experiments demonstrate that the proposed model outperforms the state-of-the-art NR-IQA methods, verifying the effectiveness of PR-IQA and demonstrating that a user-friendly, controllable IQA is feasible and successfully realized.      
### 27.Sensor-less Angle and Stiffness Control of Antagonistic PAM Actuator Using Reference Set  [ :arrow_down: ](https://arxiv.org/pdf/2105.02462.pdf)
>  This paper proposes a simultaneous control method for the angle and stiffness of the joint in an antagonistic pneumatic artificial muscle (PAM) actuator system using only pressure measurements, and clarifies the allowable references for the PAM actuator system. To achieve a sensor-less control, the proposed method estimates the joint angle and contraction forces using an unscented Kalman filter that employs a detailed model of the actuator system. Unlike previous control methods, the proposed method does not require any encoder and force sensor to achieve angle and stiffness control of the PAM actuator system. Experimental validations using three control scenarios confirm that the proposed method can control the joint angle and stiffness simultaneously and independently. Moreover, it is shown that a reference admissible set can be used as an indicator to establish reference values by demonstrating that the reference set covers the experimentally obtained trajectories of the angle and stiffness.      
### 28.DiffSinger: Diffusion Acoustic Model for Singing Voice Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2105.02446.pdf)
>  Singing voice synthesis (SVS) system is built to synthesize high-quality and expressive singing voice, in which the acoustic model generates the acoustic features (e.g., mel-spectrogram) given a music score. Previous singing acoustic models adopt simple loss (e.g., L1 and L2) or generative adversarial network (GAN) to reconstruct the acoustic features, while they suffer from over-smoothing and unstable training issues respectively, which hinder the naturalness of synthesized singing. In this work, we propose DiffSinger, an acoustic model for SVS based on the diffusion probabilistic model. DiffSinger is a parameterized Markov chain which iteratively converts the noise into mel-spectrogram conditioned on the music score. By implicitly optimizing variational bound, DiffSinger can be stably trained and generates realistic outputs. To further improve the voice quality, we introduce a \textbf{shallow diffusion mechanism} to make better use of the prior knowledge learned by the simple loss. Specifically, DiffSinger starts generation at a shallow step smaller than the total number of diffusion steps, according to the intersection of the diffusion trajectories of the ground-truth mel-spectrogram and the one predicted by a simple mel-spectrogram decoder. Besides, we train a boundary prediction network to locate the intersection and determine the shallow step adaptively. The evaluations conducted on the Chinese singing dataset demonstrate that DiffSinger outperforms state-of-the-art SVS work with a notable margin (0.11 MOS gains). Our extensional experiments also prove the generalization of DiffSinger on text-to-speech task.      
### 29.Resilient Time-Varying Output Formation Tracking of Linear Multi-Agent Systems Against Unbounded FDI Sensor Attacks and Unreliable Digraphs  [ :arrow_down: ](https://arxiv.org/pdf/2105.02427.pdf)
>  One salient feature of cooperative formation tracking is its distributed nature that relies on localized control and information sharing over a sparse communication network. That is, a distributed control manner could be prone to malicious attacks and unreliable communication that deteriorate the formation tracking performance or even destabilize the whole multi-agent system. This paper studies a safe and reliable time-varying output formation tracking problem of linear multi-agent systems, where an attacker adversely injects any unbounded time-varying signals (false data injection (FDI) attacks), while an interruption of communication channels between the agents is caused by an unreliable network. Both characteristics improve the practical relevance of the problem to be addressed, which poses some technical challenges to the distributed algorithm design and stability analysis. To mitigate the adverse effect, a novel resilient distributed control architecture is established to guarantee time-varying output formation tracking exponentially. The key features of the proposed framework are threefold: 1) an observer-based identifier is integrated to compensate for adverse effects; 2) a reliable distributed algorithm is proposed to deal with time-varying topologies caused by unreliable communication; and 3) in contrast to the existing remedies that deal with attacks as bounded disturbances/faults with known knowledge, we propose resilience strategies to handle unknown and unbounded attacks for exponential convergence of dynamic formation tracking errors, whereas most of existing results achieve uniformly ultimately boundedness (UUB) results. Numerical simulations are given to show the effectiveness of the proposed design.      
### 30.Weighted Sum-Rate Maximization for Multi-Hop RIS-Aided Multi-User Communications:A Minorization-Maximization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.02395.pdf)
>  The reconfigurable intelligent surface (RIS) has aroused much research attention recently due to its potential benefits in 5G and beyond wireless networks. This paper considers a general multi-hop RIS-aided multi-user communication system and the weighted sum-rate maximization problem is studied by jointly designing the active beamforming matrix at the base station and multiple phase-shift matrices at the RISs (considering both continuous and discrete phase constraints). To tackle the resulting highly nonconvex optimization problem, a problem-tailored low-complexity and globally convergent algorithm based on block minorization-maximization (BMM) is proposed. The effectiveness of the proposed BMM approach and the performance improvement gained with multi-hop RISs are both demonstrated through numerical simulations. The merits of the proposed algorithms are further illustrated by indicating their adaptivity in solving many other RIS-related system designs.      
### 31.A Small-Gain Theorem for Discrete-Time Convergent Systems and Its Applications  [ :arrow_down: ](https://arxiv.org/pdf/2105.02376.pdf)
>  Convergent, contractive or incremental stability properties of nonlinear systems have attracted interest for control tasks such as observer design, output regulation and synchronization. The convergence property plays a central role in the neuromorphic (brain-inspired) computing of reservoir computing, which seeks to harness the information processing capability of nonlinear systems. This paper presents a small-gain theorem for discrete-time output-feedback interconnected systems to be uniformly input-to-output convergent (UIOC) with outputs converging to a bounded reference output uniquely determined by the input. A small-gain theorem for interconnected time-varying discrete-time uniform input-to-output stable systems that could be of separate interest is also presented as an intermediate result. Applications of the UIOC small-gain theorem are illustrated in the design of observer-based controllers and interconnected nonlinear classical and quantum dynamical systems (as reservoir computers) for black-box system identification.      
### 32.Primary and Secondary Social Media Source Identification  [ :arrow_down: ](https://arxiv.org/pdf/2105.02306.pdf)
>  Social networks like Facebook and WhatsApp have enabled users to share images with other users around the world. Along with this has come the rapid spread of misinformation. One step towards verifying the authenticity of an image is understanding its origin, including it distribution history through social media. In this paper, we present a method for tracing the posting history of an image across different social networks. To do this, we propose a two-stage deep-learning-based approach, which takes advantage of cascaded fingerprints in images left by social networks during uploading. Our proposed system is not reliant upon metadata or similar easily falsifiable information. Through a series of experiments, we show that we are able to outperform existing social media source identification algorithms. and identify chains of social networks up to length two with over over 84% accuracy.      
### 33.Control Design for Inverters: Beyond Steady-State Droop Laws  [ :arrow_down: ](https://arxiv.org/pdf/2105.02292.pdf)
>  This paper presents a novel control structure and control synthesis method for regulating the output voltage/frequency and power injection of DC-AC inverters. The traditional droop method offers attractive solution to achieve compromise between clashing power and voltage/frequency regulation objectives. However, it relies on use of nonlinear power variables through slow outer control loop. In this paper we formulate the traditional droop method as a feedback control problem based on static power-flow equations and show how neglecting the dynamics of inverter and transmission line restricts the attainable closed-loop bandwidth and stability and robustness margin. Then we introduce a mapping between power variables and current in $dq$ frame under given PLL condition, allowing for replacing the fast acting current variables as a proxy for power. Consequently, we present a novel control structure and control synthesis method based on disturbance rejection framework, and demonstrate inherent droop like characteristics in underlying dynamics for special cases of resistive and inductive line. Moreover, we generalize the proposed control synthesis procedure to include a generalized complex line dynamical model and introduce concept of hybrid-sourced-intverter. Finally, we validate higher bandwidth and better transient performance of our proposed design through experimental validation.      
### 34.R2U3D: Recurrent Residual 3D U-Net for Lung Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.02290.pdf)
>  3D lung segmentation is essential since it processes the volumetric information of the lungs, removes the unnecessary areas of the scan, and segments the actual area of the lungs in a 3D volume. Recently, the deep learning model, such as U-Net outperforms other network architectures for biomedical image segmentation. In this paper, we propose a novel model, namely, Recurrent Residual 3D U-Net (R2U3D), for the 3D lung segmentation task. In particular, the proposed model integrates 3D convolution into the Recurrent Residual Neural Network based on U-Net. It helps learn spatial dependencies in 3D and increases the propagation of 3D volumetric information. The proposed R2U3D network is trained on the publicly available dataset LUNA16 and it achieves state-of-the-art performance on both LUNA16 (testing set) and VESSEL12 dataset. In addition, we show that training the R2U3D model with a smaller number of CT scans, i.e., 100 scans, without applying data augmentation achieves an outstanding result in terms of Soft Dice Similarity Coefficient (Soft-DSC) of 0.9920.      
### 35.Model reduction in acoustic inversion by artificial neural network  [ :arrow_down: ](https://arxiv.org/pdf/2105.02225.pdf)
>  In ultrasound tomography, the speed of sound inside an object is estimated based on acoustic measurements carried out by sensors surrounding the object. An accurate forward model is a prominent factor for high-quality image reconstruction, but it can make computations far too time-consuming in many applications. Using approximate forward models, it is possible to speed up the computations, but the quality of the reconstruction may have to be compromised. In this paper, a neural network -based approach is proposed, that can compensate for modeling errors caused by the approximate forward models. The approach is tested with various different imaging scenarios in a simulated two-dimensional domain. The results show that with fairly small training data sets, the proposed approach can be utilized to approximate the modelling errors, and to significantly improve the image reconstruction quality in ultrasound tomography, compared to commonly used inversion algorithms.      
### 36.A Metamodel Structure For Regression Analysis: Application To Prediction Of Autism Spectrum Disorder Severity  [ :arrow_down: ](https://arxiv.org/pdf/2105.02874.pdf)
>  Traditional regression models do not generalize well when learning from small and noisy datasets. Here we propose a novel metamodel structure to improve the regression result. The metamodel is composed of multiple classification base models and a regression model built upon the base models. We test this structure on the prediction of autism spectrum disorder (ASD) severity as measured by the ADOS communication (ADOS COMM) score from resting-state fMRI data, using a variety of base models. The metamodel outperforms traditional regression models as measured by the Pearson correlation coefficient between true and predicted scores and stability. In addition, we found that the metamodel is more flexible and more generalizable.      
### 37.Estimating Reproducible Functional Networks Associated with Task Dynamics using Unsupervised LSTMs  [ :arrow_down: ](https://arxiv.org/pdf/2105.02869.pdf)
>  We propose a method for estimating more reproducible functional networks that are more strongly associated with dynamic task activity by using recurrent neural networks with long short term memory (LSTMs). The LSTM model is trained in an unsupervised manner to learn to generate the functional magnetic resonance imaging (fMRI) time-series data in regions of interest. The learned functional networks can then be used for further analysis, e.g., correlation analysis to determine functional networks that are strongly associated with an fMRI task paradigm. We test our approach and compare to other methods for decomposing functional networks from fMRI activity on 2 related but separate datasets that employ a biological motion perception task. We demonstrate that the functional networks learned by the LSTM model are more strongly associated with the task activity and dynamics compared to other approaches. Furthermore, the patterns of network association are more closely replicated across subjects within the same dataset as well as across datasets. More reproducible functional networks are essential for better characterizing the neural correlates of a target task.      
### 38.Age of Gossip in Networks with Community Structure  [ :arrow_down: ](https://arxiv.org/pdf/2105.02867.pdf)
>  We consider a network consisting of a single source and $n$ receiver nodes that are grouped into $m$ equal size communities, i.e., clusters, where each cluster includes $k$ nodes and is served by a dedicated cluster head. The source node keeps versions of an observed process and updates each cluster through the associated cluster head. Nodes within each cluster are connected to each other according to a given network topology. Based on this topology, each node relays its current update to its neighboring nodes by $local$ $gossiping$. We use the $version$ $age$ metric to quantify information timeliness at the receiver nodes. We consider disconnected, ring, and fully connected network topologies for each cluster. For each of these network topologies, we characterize the average version age at each node and find the version age scaling as a function of the network size $n$. Our results indicate that per node version age scalings of $O(\sqrt{n})$, $O(n^{\frac{1}{3}})$, and $O(\log n)$ are achievable in disconnected, ring, and fully connected networks, respectively. Finally, through numerical evaluations, we determine the version age-optimum $(m,k)$ pairs as a function of the source, cluster head, and node update rates.      
### 39.Membership Inference Attacks on Deep Regression Models for Neuroimaging  [ :arrow_down: ](https://arxiv.org/pdf/2105.02866.pdf)
>  Ensuring the privacy of research participants is vital, even more so in healthcare environments. Deep learning approaches to neuroimaging require large datasets, and this often necessitates sharing data between multiple sites, which is antithetical to the privacy objectives. Federated learning is a commonly proposed solution to this problem. It circumvents the need for data sharing by sharing parameters during the training process. However, we demonstrate that allowing access to parameters may leak private information even if data is never directly shared. In particular, we show that it is possible to infer if a sample was used to train the model given only access to the model prediction (black-box) or access to the model itself (white-box) and some leaked samples from the training data distribution. Such attacks are commonly referred to as Membership Inference attacks. We show realistic Membership Inference attacks on deep learning models trained for 3D neuroimaging tasks in a centralized as well as decentralized setup. We demonstrate feasible attacks on brain age prediction models (deep learning models that predict a person's age from their brain MRI scan). We correctly identified whether an MRI scan was used in model training with a 60% to over 80% success rate depending on model complexity and security assumptions.      
### 40.Online Preconditioning of Experimental Inkjet Hardware by Bayesian Optimization in Loop  [ :arrow_down: ](https://arxiv.org/pdf/2105.02858.pdf)
>  High-performance semiconductor optoelectronics such as perovskites have high-dimensional and vast composition spaces that govern the performance properties of the material. To cost-effectively search these composition spaces, we utilize a high-throughput experimentation method of rapidly printing discrete droplets via inkjet deposition, in which each droplet is comprised of a unique permutation of semiconductor materials. However, inkjet printer systems are not optimized to run high-throughput experimentation on semiconductor materials. Thus, in this work, we develop a computer vision-driven Bayesian optimization framework for optimizing the deposited droplet structures from an inkjet printer such that it is tuned to perform high-throughput experimentation on semiconductor materials. The goal of this framework is to tune to the hardware conditions of the inkjet printer in the shortest amount of time using the fewest number of droplet samples such that we minimize the time and resources spent on setting the system up for material discovery applications. We demonstrate convergence on optimum inkjet hardware conditions in 10 minutes using Bayesian optimization of computer vision-scored droplet structures. We compare our Bayesian optimization results with stochastic gradient descent.      
### 41.A Novel Multi-scale Dilated 3D CNN for Epileptic Seizure Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2105.02823.pdf)
>  Accurate prediction of epileptic seizures allows patients to take preventive measures in advance to avoid possible injuries. In this work, a novel convolutional neural network (CNN) is proposed to analyze time, frequency, and channel information of electroencephalography (EEG) signals. The model uses three-dimensional (3D) kernels to facilitate the feature extraction over the three dimensions. The application of multiscale dilated convolution enables the 3D kernel to have more flexible receptive fields. The proposed CNN model is evaluated with the CHB-MIT EEG database, the experimental results indicate that our model outperforms the existing state-of-the-art, achieves 80.5% accuracy, 85.8% sensitivity and 75.1% specificity.      
### 42.Practical and Rigorous Uncertainty Bounds for Gaussian Process Regression  [ :arrow_down: ](https://arxiv.org/pdf/2105.02796.pdf)
>  Gaussian Process Regression is a popular nonparametric regression method based on Bayesian principles that provides uncertainty estimates for its predictions. However, these estimates are of a Bayesian nature, whereas for some important applications, like learning-based control with safety guarantees, frequentist uncertainty bounds are required. Although such rigorous bounds are available for Gaussian Processes, they are too conservative to be useful in applications. This often leads practitioners to replacing these bounds by heuristics, thus breaking all theoretical guarantees. To address this problem, we introduce new uncertainty bounds that are rigorous, yet practically useful at the same time. In particular, the bounds can be explicitly evaluated and are much less conservative than state of the art results. Furthermore, we show that certain model misspecifications lead to only graceful degradation. We demonstrate these advantages and the usefulness of our results for learning-based control with numerical examples.      
### 43.LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface  [ :arrow_down: ](https://arxiv.org/pdf/2105.02786.pdf)
>  In this paper, we propose LGG, a neurologically inspired graph neural network, to learn local-global-graph representations from Electroencephalography (EEG) for a Brain-Computer Interface (BCI). A temporal convolutional layer with multi-scale 1D convolutional kernels and kernel-level attention fusion is proposed to learn the temporal dynamics of EEG. Inspired by neurological knowledge of cognitive processes in the brain, we propose local and global graph-filtering layers to learn the brain activities within and between different functional areas of the brain to model the complex relations among them during the cognitive processes. Under the robust nested cross-validation settings, the proposed method is evaluated on the publicly available dataset DEAP, and the classification performance is compared with state-of-the-art methods, such as FBFgMDM, FBTSC, Unsupervised learning, DeepConvNet, ShallowConvNet, EEGNet, and TSception. The results show that the proposed method outperforms all these state-of-the-art methods, and the improvements are statistically significant (p&lt;0.05) in most cases. The source code can be found at: <a class="link-external link-https" href="https://github.com/yi-ding-cs/LGG" rel="external noopener nofollow">this https URL</a>      
### 44.Mobile Robot Localization Using Fuzzy Neural Network Based Extended Kalman Filter  [ :arrow_down: ](https://arxiv.org/pdf/2105.02706.pdf)
>  This paper proposes a novel approach to improve the performance of the extended Kalman filter (EKF) for the problem of mobile robot localization. A fuzzy logic system is employed to continuous-ly adjust the noise covariance matrices of the filter. A neural network is implemented to regulate the membership functions of the antecedent and consequent parts of the fuzzy rules. The aim is to gain the accuracy and avoid the divergence of the EKF when the noise covariance matrices are fixed or wrongly determined. Simulations and experiments have been conducted. The results show that the proposed filter is better than the EKF in localizing the mobile robot.      
### 45.MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection with Domain Shifts due to Changes in Operational and Environmental Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2105.02702.pdf)
>  In this paper, we introduce a new dataset for malfunctioning industrial machine investigation and inspection with domain shifts due to changes in operational and environmental conditions (MIMII DUE). Conventional methods for anomalous sound detection face challenges in practice because the distribution of features changes between the training and operational phases (called domain shift) due to some real-world factors. To check the robustness against domain shifts, we need a dataset with domain shifts, but such a dataset does not exist so far. The new dataset consists of normal and abnormal operating sounds of industrial machines of five different types under two different operational/environmental conditions (source domain and target domain) independent of normal/abnormal, with domain shifts occurring between the two domains. Experimental results show significant performance differences between the source and target domains, and the dataset contains the domain shifts. These results indicate that the dataset will be helpful to check the robustness against domain shifts. The dataset is a subset of the dataset for DCASE 2021 Challenge Task 2 and freely available for download at <a class="link-external link-https" href="https://zenodo.org/record/4740355" rel="external noopener nofollow">this https URL</a>      
### 46.(ASNA) An Attention-based Siamese-Difference Neural Network with Surrogate Ranking Loss function for Perceptual Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2105.02531.pdf)
>  Recently, deep convolutional neural networks (DCNN) that leverage the adversarial training framework for image restoration and enhancement have significantly improved the processed images' sharpness. Surprisingly, although these DCNNs produced crispier images than other methods visually, they may get a lower quality score when popular measures are employed for evaluating them. Therefore it is necessary to develop a quantitative metric to reflect their performances, which is well-aligned with the perceived quality of an image. Famous quantitative metrics such as Peak signal-to-noise ratio (PSNR), The structural similarity index measure (SSIM), and Perceptual Index (PI) are not well-correlated with the mean opinion score (MOS) for an image, especially for the neural networks trained with adversarial loss functions. <br>This paper has proposed a convolutional neural network using an extension architecture of the traditional Siamese network so-called Siamese-Difference neural network. We have equipped this architecture with the spatial and channel-wise attention mechanism to increase our method's performance. <br>Finally, we employed an auxiliary loss function to train our model. The suggested additional cost function surrogates ranking loss to increase Spearman's rank correlation coefficient while it is differentiable concerning the neural network parameters. Our method achieved superior performance in \textbf{\textit{NTIRE 2021 Perceptual Image Quality Assessment}} Challenge. The implementations of our proposed method are publicly available.      
### 47.Optical OFDM Waveform Construction by Combining Real and Imaginary Parts of IDFT  [ :arrow_down: ](https://arxiv.org/pdf/2105.02517.pdf)
>  In optical communication systems, orthogonal frequency division multiplexing (OFDM) is widely used to combat inter-symbol interference (ISI) caused by multipath propagation. Optical systems which use intensity modulation and direct detection (IM/DD) can only transmit real valued symbols, but the inverse discrete Fourier transform (IDFT) or its computationally efficient form inverse-fast Fourier transform (IFFT) required for the OFDM waveform construction produces complex values. Hermitian symmetry is often used to obtain real valued symbols. For this purpose, some trigonometric transformations such as discrete cosine transform (DCT) are also used, however these transformations can eliminate the ISI only under certain conditions. In this paper, we propose a completely different method for the construction of OFDM waveform with IFFT to obtain real valued symbols by combining the real and imaginary parts (CRIP) of IFFT output electrically (E-CRIP) or optically (O-CRIP). Analytical analysis and simulation works are presented to show that compared to the Hermitian symmetric system, the proposed method slightly increases the spectral efficiency, eliminates ISI, significantly reduces the amount of needed calculation and does not effect the error performance. In addition, the O-CRIP method is less affected by clipping noise that may occur due to the imperfections of the transmitter front-ends.      
### 48.Data-driven distributionally robust control of partially observable jump linear systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.02511.pdf)
>  We study safe, data-driven control of (Markov) jump linear systems with unknown transition probabilities, where both the discrete mode and the continuous state are to be inferred from output measurements. To this end, we develop a receding horizon estimator which uniquely identifies a sub-sequence of past mode transitions and the corresponding continuous state, allowing for arbitrary switching behavior. Unlike traditional approaches to mode estimation, we do not require an offline exhaustive search over mode sequences to determine the size of the observation window, but rather select it online. If the system is weakly mode observable, the window size will be upper bounded, leading to a finite-memory observer. We integrate the estimation procedure with a simple distributionally robust controller, which hedges against misestimations of the transition probabilities due to finite sample sizes. As additional mode transitions are observed, the used ambiguity sets are updated, resulting in continual improvements of the control performance. The practical applicability of the approach is illustrated on small numerical examples.      
### 49.Speech Enhancement using Separable Polling Attention and Global Layer Normalization followed with PReLU  [ :arrow_down: ](https://arxiv.org/pdf/2105.02509.pdf)
>  Single channel speech enhancement is a challenging task in speech community. Recently, various neural networks based methods have been applied to speech enhancement. Among these models, PHASEN and T-GSA achieve state-of-the-art performances on the publicly opened VoiceBank+DEMAND corpus. Both of the models reach the COVL score of 3.62. PHASEN achieves the highest CSIG score of 4.21 while T-GSA gets the highest PESQ score of 3.06. However, both of these two models are very large. The contradiction between the model performance and the model size is hard to reconcile. In this paper, we introduce three kinds of techniques to shrink the PHASEN model and improve the performance. Firstly, seperable polling attention is proposed to replace the frequency transformation blocks in PHASEN. Secondly, global layer normalization followed with PReLU is used to replace batch normalization followed with ReLU. Finally, BLSTM in PHASEN is replaced with Conv2d operation and the phase stream is simplified. With all these modifications, the size of the PHASEN model is shrunk from 33M parameters to 5M parameters, while the performance on VoiceBank+DEMAND is improved to the CSIG score of 4.30, the PESQ score of 3.07 and the COVL score of 3.73.      
### 50.Deficient Basis Estimation of Noise Spatial Covariance Matrix for Rank-Constrained Spatial Covariance Matrix Estimation Method in Blind Speech Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2105.02491.pdf)
>  Rank-constrained spatial covariance matrix estimation (RCSCME) is a state-of-the-art blind speech extraction method applied to cases where one directional target speech and diffuse noise are mixed. In this paper, we proposed a new algorithmic extension of RCSCME. RCSCME complements a deficient one rank of the diffuse noise spatial covariance matrix, which cannot be estimated via preprocessing such as independent low-rank matrix analysis, and estimates the source model parameters simultaneously. In the conventional RCSCME, a direction of the deficient basis is fixed in advance and only the scale is estimated; however, the candidate of this deficient basis is not unique in general. In the proposed RCSCME model, the deficient basis itself can be accurately estimated as a vector variable by solving a vector optimization problem. Also, we derive new update rules based on the EM algorithm. We confirm that the proposed method outperforms conventional methods under several noise conditions.      
### 51.Single-pixel diffuser camera  [ :arrow_down: ](https://arxiv.org/pdf/2105.02459.pdf)
>  We present a compact, diffuser-assisted, single-pixel computational camera. A rotating ground glass diffuser is adopted, in preference to a commonly used digital micro-mirror device (DMD), to encode a two-dimensional (2D) image into single-pixel signals. We retrieve images with an 8.8% sampling ratio after the calibration of the pseudo-random pattern of the diffuser under incoherent illumination. Furthermore, we demonstrate hyperspectral imaging with line array detection by adding a diffraction grating. The implementation results in a cost-effective single-pixel camera for high-dimensional imaging, with potential for imaging in non-visible wavebands.      
### 52.DBNet: A Dual-branch Network Architecture Processing on Spectrum and Waveform for Single-channel Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2105.02436.pdf)
>  In real acoustic environment, speech enhancement is an arduous task to improve the quality and intelligibility of speech interfered by background noise and reverberation. Over the past years, deep learning has shown great potential on speech enhancement. In this paper, we propose a novel real-time framework called DBNet which is a dual-branch structure with alternate interconnection. Each branch incorporates an encoder-decoder architecture with skip connections. The two branches are responsible for spectrum and waveform modeling, respectively. A bridge layer is adopted to exchange information between the two branches. Systematic evaluation and comparison show that the proposed system substantially outperforms related algorithms under very challenging environments. And in INTERSPEECH 2021 Deep Noise Suppression (DNS) challenge, the proposed system ranks the top 8 in real-time track 1 in terms of the Mean Opinion Score (MOS) of the ITU-T P.835 framework.      
### 53.Attack-Resilient Distributed Convex Optimization of Linear Multi-Agent Systems Against Malicious Cyber-Attacks over Random Digraphs  [ :arrow_down: ](https://arxiv.org/pdf/2105.02423.pdf)
>  This paper addresses a resilient exponential distributed convex optimization problem for a heterogeneous linear multi-agent system under Denial-of-Service (DoS) attacks over random digraphs. The random digraphs are caused by unreliable networks and the DoS attacks, allowed to occur aperiodically, refer to an interruption of the communication channels carried out by the intelligent adversaries. In contrast to many existing distributed convex optimization works over a prefect communication network, the global optimal solution might not be sought under the adverse influences that result in performance degradations or even failures of optimization algorithms. The aforementioned setting poses certain technical challenges to optimization algorithm design and exponential convergence analysis. In this work, several resilient algorithms are presented such that a team of agents minimizes a sum of local non-quadratic cost functions in a safe and reliable manner with global exponential convergence. Inspired by the preliminary works in [15]-[18], an explicit analysis of frequency and duration of attacks is investigated to guarantee exponential optimal solutions. Numerical simulation results are presented to demonstrate the effectiveness of the proposed design.      
### 54.In the Danger Zone: U-Net Driven Quantile Regression can Predict High-risk SARS-CoV-2 Regions via Pollutant Particulate Matter and Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2105.02406.pdf)
>  Since the outbreak of COVID-19 policy makers have been relying upon non-pharmacological interventions to control the outbreak. With air pollution as a potential transmission vector there is need to include it in intervention strategies. We propose a U-net driven quantile regression model to predict $PM_{2.5}$ air pollution based on easily obtainable satellite imagery. We demonstrate that our approach can reconstruct $PM_{2.5}$ concentrations on ground-truth data and predict reasonable $PM_{2.5}$ values with their spatial distribution, even for locations where pollution data is unavailable. Such predictions of $PM_{2.5}$ characteristics could crucially advise public policy strategies geared to reduce the transmission of and lethality of COVID-19.      
### 55.SIPSA-Net: Shift-Invariant Pan Sharpening with Moving Object Alignment for Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2105.02400.pdf)
>  Pan-sharpening is a process of merging a high-resolution (HR) panchromatic (PAN) image and its corresponding low-resolution (LR) multi-spectral (MS) image to create an HR-MS and pan-sharpened image. However, due to the different sensors' locations, characteristics and acquisition time, PAN and MS image pairs often tend to have various amounts of misalignment. Conventional deep-learning-based methods that were trained with such misaligned PAN-MS image pairs suffer from diverse artifacts such as double-edge and blur artifacts in the resultant PAN-sharpened images. In this paper, we propose a novel framework called shift-invariant pan-sharpening with moving object alignment (SIPSA-Net) which is the first method to take into account such large misalignment of moving object regions for PAN sharpening. The SISPA-Net has a feature alignment module (FAM) that can adjust one feature to be aligned to another feature, even between the two different PAN and MS domains. For better alignment in pan-sharpened images, a shift-invariant spectral loss is newly designed, which ignores the inherent misalignment in the original MS input, thereby having the same effect as optimizing the spectral loss with a well-aligned MS image. Extensive experimental results show that our SIPSA-Net can generate pan-sharpened images with remarkable improvements in terms of visual quality and alignment, compared to the state-of-the-art methods.      
### 56.How do Voices from Past Speech Synthesis Challenges Compare Today?  [ :arrow_down: ](https://arxiv.org/pdf/2105.02373.pdf)
>  Shared challenges provide a venue for comparing systems trained on common data using a standardized evaluation, and they also provide an invaluable resource for researchers when the data and evaluation results are publicly released. The Blizzard Challenge and Voice Conversion Challenge are two such challenges for text-to-speech synthesis and for speaker conversion, respectively, and their publicly-available system samples and listening test results comprise a historical record of state-of-the-art synthesis methods over the years. In this paper, we revisit these past challenges and conduct a large-scale listening test with samples from many challenges combined. Our aims are to analyze and compare opinions of a large number of systems together, to determine whether and how opinions change over time, and to collect a large-scale dataset of a diverse variety of synthetic samples and their ratings for further research. We found strong correlations challenge by challenge at the system level between the original results and our new listening test. We also observed the importance of the choice of speaker on synthesis quality.      

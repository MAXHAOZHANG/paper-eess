# ArXiv eess --Thu, 6 May 2021
### 1.Cooperative Output Regulation with Mixed Time- and Event-triggered Observers  [ :arrow_down: ](https://arxiv.org/pdf/2105.02200.pdf)
>  Mixed time- and event-triggered cooperative output regulation for heterogeneous distributed systems is investigated in this paper. A distributed observer with time-triggered observations is proposed to estimate the state of the leader, and an auxiliary observer with event-triggered communication is designed to reduce the information exchange among followers. A necessary and sufficient condition for the existence of desirable time-triggered observers is established, and delicate relationships among sampling periods, topologies, and reference signals are revealed. An event-triggering mechanism based on local sampled data is proposed to regulate the communication among agents; and the convergence of the estimation errors under the mechanism holds for a class of positive and convergent triggering functions, which include the commonly used exponential function as a special case. The mixed time- and event-triggered system naturally excludes the existence of Zeno behavior as the system updates at discrete instants. When the triggering function is bounded by exponential functions, analytical characterization of the relationship among sampling, event triggering, and inter-event behaviour is established. Finally, several examples are provided to illustrate the effectiveness and merits of the theoretical results.      
### 2.Rethinking Ultrasound Augmentation: A Physics-Inspired Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.02188.pdf)
>  Medical Ultrasound (US), despite its wide use, is characterized by artifacts and operator dependency. Those attributes hinder the gathering and utilization of US datasets for the training of Deep Neural Networks used for Computer-Assisted Intervention Systems. Data augmentation is commonly used to enhance model generalization and performance. However, common data augmentation techniques, such as affine transformations do not align with the physics of US and, when used carelessly can lead to unrealistic US images. To this end, we propose a set of physics-inspired transformations, including deformation, reverb and Signal-to-Noise Ratio, that we apply on US B-mode images for data augmentation. We evaluate our method on a new spine US dataset for the tasks of bone segmentation and classification.      
### 3.Cylindrical Battery Fault Detection under Extreme Fast Charging: A Physics-based Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.02169.pdf)
>  High power operation in extreme fast charging significantly increases the risk of internal faults in Electric Vehicle batteries which can lead to accelerated battery failure. Early detection of these faults is crucial for battery safety and widespread deployment of fast charging. In this setting, we propose a real-time {detection} framework for battery voltage and thermal faults. A major challenge in battery fault detection arises from the effect of uncertainties originating from sensor inaccuracies, nominal aging, or unmodelled dynamics. Inspired by physics-based learning, we explore a detection paradigm that combines physics-based models, model-based detection observers, and data-driven learning techniques to address this challenge. Specifically, we construct the {detection} observers based on an experimentally identified electrochemical-thermal model, and subsequently design the observer tuning parameters following Lyapunov's stability theory. Furthermore, we utilize Gaussian Process Regression technique to learn the model and measurement uncertainties which in turn aid the {detection} observers in distinguishing faults and uncertainties. Such uncertainty learning essentially helps suppressing their effects, potentially enabling early detection of faults. We perform simulation and experimental case studies on the proposed fault {detection} scheme verifying the potential of physics-based learning in early detection of battery faults.      
### 4.H-TD2: Hybrid Temporal Difference Learning for Adaptive Urban Taxi Dispatch  [ :arrow_down: ](https://arxiv.org/pdf/2105.02138.pdf)
>  We present H-TD2: Hybrid Temporal Difference Learning for Taxi Dispatch, a model-free, adaptive decision-making algorithm to coordinate a large fleet of automated taxis in a dynamic urban environment to minimize expected customer waiting times. Our scalable algorithm exploits the natural transportation network company topology by switching between two behaviors: distributed temporal-difference learning computed locally at each taxi and infrequent centralized Bellman updates computed at the dispatch center. We derive a regret bound and design the trigger condition between the two behaviors to explicitly control the trade-off between computational complexity and the individual taxi policy's bounded sub-optimality; this advances the state of the art by enabling distributed operation with bounded-suboptimality. Additionally, unlike recent reinforcement learning dispatch methods, this policy estimation is adaptive and robust to out-of-training domain events. This result is enabled by a two-step modelling approach: the policy is learned on an agent-agnostic, cell-based Markov Decision Process and individual taxis are coordinated using the learned policy in a distributed game-theoretic task assignment. We validate our algorithm against a receding horizon control baseline in a Gridworld environment with a simulated customer dataset, where the proposed solution decreases average customer waiting time by 50% over a wide range of parameters. We also validate in a Chicago city environment with real customer requests from the Chicago taxi public dataset where the proposed solution decreases average customer waiting time by 26% over irregular customer distributions during a 2016 Major League Baseball World Series game.      
### 5.Optimal Phasor Measurement Unit Placement Using a Honey Bee Mating Optimization (HBMO) Technique Considering Measurement Loss and Line Outages  [ :arrow_down: ](https://arxiv.org/pdf/2105.02102.pdf)
>  Phasor measurement units (PMUs) are important devices for protection, monitoring, and control of modern power systems. Unlike the supervisory control and data acquisition (SCADA) system which only measure the magnitude, PMUs can provide a set of synchronized phasor measurements with high sampling rate with the accuracy of less than one second, for better system monitoring especially during the outages. Since the PMUs are costly devices, system operator is not able to install a PMU at each bus to maximize the observability of system. To this end, determination of the number of PMUs in the system for having a 100% observability is pivotal. In this paper, honey bee mating optimization (HBMO) approach is utilized to allocate PMUs in modern power systems. Moreover, the impact of line outages, as well as measurement loses, are considered. The simulation results show the effectiveness of the proposed method on solving the PMU placement problem.      
### 6.Phase-Space Function Recovery for Moving Target Imaging in SAR by Convex Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2105.02081.pdf)
>  In this paper, we present an approach for ground moving target imaging (GMTI) and velocity recovery using synthetic aperture radar. We formulate the GMTI problem as the recovery of a phase-space reflectivity (PSR) function which represents the strengths and velocities of the scatterers in a scene of interest. We show that the discretized PSR matrix can be decomposed into a rank-one, and a highly sparse component corresponding to the stationary and moving scatterers, respectively. We then recover the two distinct components by solving a constrained optimization problem that admits computationally efficient convex solvers within the proximal gradient descent and alternating direction method of multipliers frameworks. Using the structural properties of the PSR matrix, we alleviate the computationally expensive steps associated with rank-constraints, such as singular value thresholding. Our optimization-based approach has several advantages over state-of-the-art GMTI methods, including computational efficiency, applicability to dense target environments, and arbitrary imaging configurations. We present extensive simulations to assess the robustness of our approach to both additive noise and clutter, with increasing number of moving targets. We show that both solvers perform well in dense moving target environments, and low-signal-to-clutter ratios without the need for additional clutter suppression techniques.      
### 7.Numerical Gaussian process Kalman filtering for spatiotemporal systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.02079.pdf)
>  We present a novel Kalman filter for spatiotemporal systems called the numerical Gaussian process Kalman filter (GPKF). Numerical Gaussian processes have recently been introduced as a physics informed machine learning method for simulating time-dependent partial differential equations without the need for spatial discretization. We bring numerical GPs into probabilistic state space form. This model is linear and its states are Gaussian distributed. These properties enable us to embed the numerical GP state space model into the recursive Kalman filter algorithm. We showcase the method using two case studies.      
### 8.Towards Interpretable and Transferable Speech Emotion Recognition: Latent Representation Based Analysis of Features, Methods and Corpora  [ :arrow_down: ](https://arxiv.org/pdf/2105.02055.pdf)
>  In recent years, speech emotion recognition (SER) has been used in wide ranging applications, from healthcare to the commercial sector. In addition to signal processing approaches, methods for SER now also use deep learning techniques. However, generalizing over languages, corpora and recording conditions is still an open challenge in the field. Furthermore, due to the black-box nature of deep learning algorithms, a newer challenge is the lack of interpretation and transparency in the models and the decision making process. This is critical when the SER systems are deployed in applications that influence human lives. In this work we address this gap by providing an in-depth analysis of the decision making process of the proposed SER system. Towards that end, we present low-complexity SER based on undercomplete- and denoising- autoencoders that achieve an average classification accuracy of over 55\% for four-class emotion classification. Following this, we investigate the clustering of emotions in the latent space to understand the influence of the corpora on the model behavior and to obtain a physical interpretation of the latent embedding. Lastly, we explore the role of each input feature towards the performance of the SER.      
### 9.Joint Communication and Radar Sensing with Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2105.01966.pdf)
>  In this paper, we use a reconfigurable intelligent surface (RIS) to enhance the radar sensing and communication capabilities of a mmWave dual function radar communication system. To simultaneously localize the target and to serve the user, we propose to adaptively partition the RIS by reserving separate RIS elements for sensing and communication. We design a multi-stage hierarchical codebook to localize the target while ensuring a strong communication link to the user. We also present a method to choose the number of times to transmit the same beam in each stage to achieve a desired target localization probability of error. The proposed algorithm typically requires fewer transmissions than an exhaustive search scheme to achieve a desired target localization probability of error. Furthermore, the average spectral efficiency of the user with the proposed algorithm is found to be comparable to that of a RIS-assisted MIMO communication system without sensing capabilities and is much better than that of traditional MIMO systems without RIS.      
### 10.An Ensemble Forecasting Technique for Photovoltaic Power Generation  [ :arrow_down: ](https://arxiv.org/pdf/2105.01950.pdf)
>  To cater the rapidly growing demand for electricity leading to the integration of renewable energy sources in power system. Due to intermittent nature of renewables, it also brings challenges for research community during the planning and operation stage in power system. Therefore it is primary necessity of the community to develop an accurate forecasting technique to solve the intermittency problem. In this report, A forecasting technique is proposed based on ensemble of state of the art forecasting techniques. For performance comparison among the techniques, GEFCom2014 meteorological data are used to predict the photovoltaic power, and the obtained results are included in this report.      
### 11.Accent Recognition with Hybrid Phonetic Features  [ :arrow_down: ](https://arxiv.org/pdf/2105.01920.pdf)
>  The performance of voice-controlled systems is usually influenced by accented speech. To make these systems more robust, the frontend accent recognition (AR) technologies have received increased attention in recent years. As accent is a high-level abstract feature that has a profound relationship with the language knowledge, AR is more challenging than other language-agnostic audio classification tasks. In this paper, we use an auxiliary automatic speech recognition (ASR) task to extract language-related phonetic features. Furthermore, we propose a hybrid structure that incorporates the embeddings of both a fixed acoustic model and a trainable acoustic model, making the language-related acoustic feature more robust. We conduct several experiments on the Accented English Speech Recognition Challenge (AESRC) 2020 dataset. The results demonstrate that our approach can obtain a 6.57% relative improvement on the validation set. We also get a 7.28% relative improvement on the final test set for this competition, showing the merits of the proposed method.      
### 12.Improved current reference calculation for MMCs interal energy balancing control  [ :arrow_down: ](https://arxiv.org/pdf/2105.01908.pdf)
>  The paper addresses an improved inner current reference calculation to be employed in the control of modular multilevel converters operating during either balanced or unbalanced conditions. The suggested reference calculation is derived based on the AC and DC additive and differential voltage components applied to the upper and lower arms of the converter. In addition, the impacts caused not only by the AC network's impedances but also by the MMC's arm impedances are also considered during the derivation of the AC additive current reference expressions. Another issue discussed in this article regards that singular voltage conditions, where the positive-sequence component is equal to the negative one, may occur not only in the AC network but also internally (within the converter's applied voltages). Several different inner current reference calculation methods are compared and their applicability during the former fault conditions is analyzed. The paper presents a detailed formulation of the inner current reference calculation and applies it to different unbalanced AC grid faults where it is shown that the presented approach can be potentially used to maintain the internal energy of the converter balanced during normal and fault conditions.      
### 13.Using Synthetic Data to Enhance the Accuracy of Fingerprint-Based Localization: A Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.01903.pdf)
>  Human-centered data collection is typically costly and implicates issues of privacy. Various solutions have been proposed in the literature to reduce this cost, such as crowdsourced data collection, or the use of semi-supervised algorithms. However, semi-supervised algorithms require a source of unlabeled data, and crowd-sourcing methods require numbers of active participants. An alternative passive data collection modality is fingerprint-based localization. Such methods use received signal strength (RSS) or channel state information (CSI) in wireless sensor networks to localize users in indoor/outdoor environments. In this paper, we introduce a novel approach to reduce training data collection costs in fingerprint-based localization by using synthetic data. Generative adversarial networks (GANs) are used to learn the distribution of a limited sample of collected data and, following this, to produce synthetic data that can be used to augment the real collected data in order to increase overall positioning accuracy. Experimental results on a benchmark dataset show that by applying the proposed method and using a combination of 10% collected data and 90% synthetic data, we can obtain essentially similar positioning accuracy to that which would be obtained by using the full set of collected data. This means that by employing GAN-generated synthetic data, we can use 90% less real data, thereby reduce data-collection costs while achieving acceptable accuracy.      
### 14.Deep Learning for Needle Detection in a Cannulation Simulator  [ :arrow_down: ](https://arxiv.org/pdf/2105.01852.pdf)
>  Cannulation for hemodialysis is the act of inserting a needle into a surgically created vascular access (e.g., an arteriovenous fistula) for the purpose of dialysis. The main risk associated with cannulation is infiltration, the puncture of the wall of the vascular access after entry, which can cause medical complications. Simulator-based training allows clinicians to gain cannulation experience without putting patients at risk. In this paper, we propose to use deep-learning-based techniques for detecting, based on video, whether the needle tip is in or has infiltrated the simulated fistula. Three categories of deep neural networks are investigated in this work: modified pre-trained models based on VGG-16 and ResNet-50, light convolutional neural networks (light CNNs), and convolutional recurrent neural networks (CRNNs). CRNNs consist of convolutional layers and a long short-term memory (LSTM) layer. A data set of cannulation experiments was collected and analyzed. The results show that both the light CNN and the CRNN achieve better performance than the pre-trained baseline models. The CRNN was implemented in real time on commodity hardware for use in the cannulation simulator, and the performance was verified. Deep-learning video analysis is a viable method for detecting needle state in a low cost cannulation simulator. Our data sets and code are released at <a class="link-external link-https" href="https://github.com/axin233/DL_for_Needle_Detection_Cannulation" rel="external noopener nofollow">this https URL</a>      
### 15.Joint Registration and Segmentation via Multi-Task Learning for Adaptive Radiotherapy of Prostate Cancer  [ :arrow_down: ](https://arxiv.org/pdf/2105.01844.pdf)
>  Medical image registration and segmentation are two of the most frequent tasks in medical image analysis. As these tasks are complementary and correlated, it would be beneficial to apply them simultaneously in a joint manner. In this paper, we formulate registration and segmentation as a joint problem via a Multi-Task Learning (MTL) setting, allowing these tasks to leverage their strengths and mitigate their weaknesses through the sharing of beneficial information. We propose to merge these tasks not only on the loss level, but on the architectural level as well. We studied this approach in the context of adaptive image-guided radiotherapy for prostate cancer, where planning and follow-up CT images as well as their corresponding contours are available for training. The study involves two datasets from different manufacturers and institutes. The first dataset was divided into training (12 patients) and validation (6 patients), and was used to optimize and validate the methodology, while the second dataset (14 patients) was used as an independent test set. We carried out an extensive quantitative comparison between the quality of the automatically generated contours from different network architectures as well as loss weighting methods. Moreover, we evaluated the quality of the generated deformation vector field (DVF). We show that MTL algorithms outperform their Single-Task Learning (STL) counterparts and achieve better generalization on the independent test set. The best algorithm achieved a mean surface distance of $1.06 \pm 0.3$ mm, $1.27 \pm 0.4$ mm, $0.91 \pm 0.4$ mm, and $1.76 \pm 0.8$ mm on the validation set for the prostate, seminal vesicles, bladder, and rectum, respectively. The high accuracy of the proposed method combined with the fast inference speed, makes it a promising method for automatic re-contouring of follow-up scans for adaptive radiotherapy.      
### 16.CUAB: Convolutional Uncertainty Attention Block Enhanced the Chest X-ray Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2105.01840.pdf)
>  In recent years, convolutional neural networks (CNNs) have been successfully implemented to various image recognition applications, such as medical image analysis, object detection, and image segmentation. Many studies and applications have been working on improving the performance of CNN algorithms and models. The strategies that aim to improve the performance of CNNs can be grouped into three major approaches: (1) deeper and wider network architecture, (2) automatic architecture search, and (3) convolutional attention block. Unlike approaches (1) and (2), the convolutional attention block approach is more flexible with lower cost. It enhances the CNN performance by extracting more efficient features. However, the existing attention blocks focus on enhancing the significant features, which lose some potential features in the uncertainty information. Inspired by the test time augmentation and test-time dropout approaches, we developed a novel convolutional uncertainty attention block (CUAB) that can leverage the uncertainty information to improve CNN-based models. The proposed module discovers potential information from the uncertain regions on feature maps in computer vision tasks. It is a flexible functional attention block that can be applied to any position in the convolutional block in CNN models. We evaluated the CUAB with notable backbone models, ResNet and ResNeXt, on a medical image segmentation task. The CUAB achieved a dice score of 73% and 84% in pneumonia and pneumothorax segmentation, respectively, thereby outperforming the original model and other notable attention approaches. The results demonstrated that the CUAB can efficiently utilize the uncertainty information to improve the model performance.      
### 17.Lesion Segmentation and RECIST Diameter Prediction via Click-driven Attention and Dual-path Connection  [ :arrow_down: ](https://arxiv.org/pdf/2105.01828.pdf)
>  Measuring lesion size is an important step to assess tumor growth and monitor disease progression and therapy response in oncology image analysis. Although it is tedious and highly time-consuming, radiologists have to work on this task by using RECIST criteria (Response Evaluation Criteria In Solid Tumors) routinely and manually. Even though lesion segmentation may be the more accurate and clinically more valuable means, physicians can not manually segment lesions as now since much more heavy laboring will be required. In this paper, we present a prior-guided dual-path network (PDNet) to segment common types of lesions throughout the whole body and predict their RECIST diameters accurately and automatically. Similar to [1], a click guidance from radiologists is the only requirement. There are two key characteristics in PDNet: 1) Learning lesion-specific attention matrices in parallel from the click prior information by the proposed prior encoder, named click-driven attention; 2) Aggregating the extracted multi-scale features comprehensively by introducing top-down and bottom-up connections in the proposed decoder, named dual-path connection. Experiments show the superiority of our proposed PDNet in lesion segmentation and RECIST diameter prediction using the DeepLesion dataset and an external test set. PDNet learns comprehensive and representative deep image features for our tasks and produces more accurate results on both lesion segmentation and RECIST diameter prediction.      
### 18.Generative Adversarial Networks (GAN) Powered Fast Magnetic Resonance Imaging -- Mini Review, Comparison and Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2105.01800.pdf)
>  Magnetic Resonance Imaging (MRI) is a vital component of medical imaging. When compared to other image modalities, it has advantages such as the absence of radiation, superior soft tissue contrast, and complementary multiple sequence information. However, one drawback of MRI is its comparatively slow scanning and reconstruction compared to other image modalities, limiting its usage in some clinical applications when imaging time is critical. Traditional compressive sensing based MRI (CS-MRI) reconstruction can speed up MRI acquisition, but suffers from a long iterative process and noise-induced artefacts. Recently, Deep Neural Networks (DNNs) have been used in sparse MRI reconstruction models to recreate relatively high-quality images from heavily undersampled k-space data, allowing for much faster MRI scanning. However, there are still some hurdles to tackle. For example, directly training DNNs based on L1/L2 distance to the target fully sampled images could result in blurry reconstruction because L1/L2 loss can only enforce overall image or patch similarity and does not take into account local information such as anatomical sharpness. It is also hard to preserve fine image details while maintaining a natural appearance. More recently, Generative Adversarial Networks (GAN) based methods are proposed to solve fast MRI with enhanced image perceptual quality. The encoder obtains a latent space for the undersampling image, and the image is reconstructed by the decoder using the GAN loss. In this chapter, we review the GAN powered fast MRI methods with a comparative study on various anatomical datasets to demonstrate the generalisability and robustness of this kind of fast MRI while providing future perspectives.      
### 19.Fast Spline Trajectory Planning: Minimum Snap and Beyond  [ :arrow_down: ](https://arxiv.org/pdf/2105.01788.pdf)
>  In this paper, we study spline trajectory generation via the solution of two optimisation problems: (i) a quadratic program (QP) with linear equality constraints and (ii) a nonlinear and nonconvex optimisation program. We propose an efficient algorithm to solve (i), which we then leverage to use in an iterative algorithm to solve (ii). Both the first algorithm and each iteration of the second algorithm have linear computational complexity in the number of spline segments. The scaling of each algorithm is such that we are able to solve the two problems faster than state-of-the-art methods and in times amenable to real-time trajectory generation requirements. The trajectories we generate are applicable to differentially flat systems, a broad class of mechanical systems, which we demonstrate by planning trajectories for a quadrotor.      
### 20.Voice Conversion Based Speaker Normalization for Acoustic Unit Discovery  [ :arrow_down: ](https://arxiv.org/pdf/2105.01786.pdf)
>  Discovering speaker independent acoustic units purely from spoken input is known to be a hard problem. In this work we propose an unsupervised speaker normalization technique prior to unit discovery. It is based on separating speaker related from content induced variations in a speech signal with an adversarial contrastive predictive coding approach. This technique does neither require transcribed speech nor speaker labels, and, furthermore, can be trained in a multilingual fashion, thus achieving speaker normalization even if only few unlabeled data is available from the target language. The speaker normalization is done by mapping all utterances to a medoid style which is representative for the whole database. We demonstrate the effectiveness of the approach by conducting acoustic unit discovery with a hidden Markov model variational autoencoder noting, however, that the proposed speaker normalization can serve as a front end to any unit discovery system. Experiments on English, Yoruba and Mboshi show improvements compared to using non-normalized input.      
### 21.Optimal Real-time Coordination of Distributed Energy Resources in Low-voltage Grids  [ :arrow_down: ](https://arxiv.org/pdf/2105.01750.pdf)
>  This study proposes a real-time distributed energy resource (DER) coordination model that can exploit flexibility from the DERs to solve voltage and overloading issues using both active and reactive power. The model considers time-coupling devices including electric vehicles and heat pumps by deviating as little as possible from their original schedules while prioritizing DERs with the most urgent demand using dynamic cost terms. The model does not require a multi-period setting or a multi-period-ahead forecast, which enables the model to alleviate the computational difficulty and enhance its applicability for DSOs to manage the grids in real time. A case study using a Dutch low-voltage grid assuming a 100% penetration scenario of electric vehicles, heat pumps, and photovoltaics (PVs) in the households validates that the proposed model can resolve the network issues while not affecting user comfort.      
### 22.COVID-19 Detection from Chest X-ray Images using Imprinted Weights Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.01710.pdf)
>  The COVID-19 pandemic has had devastating effects on the well-being of the global population. The pandemic has been so prominent partly due to the high infection rate of the virus and its variants. In response, one of the most effective ways to stop infection is rapid diagnosis. The main-stream screening method, reverse transcription-polymerase chain reaction (RT-PCR), is time-consuming, laborious and in short supply. Chest radiography is an alternative screening method for the COVID-19 and computer-aided diagnosis (CAD) has proven to be a viable solution at low cost and with fast speed; however, one of the challenges in training the CAD models is the limited number of training data, especially at the onset of the pandemic. This becomes outstanding precisely when the quick and cheap type of diagnosis is critically needed for flattening the infection curve. To address this challenge, we propose the use of a low-shot learning approach named imprinted weights, taking advantage of the abundance of samples from known illnesses such as pneumonia to improve the detection performance on COVID-19.      
### 23.Attention-based Stylisation for Exemplar Image Colourisation  [ :arrow_down: ](https://arxiv.org/pdf/2105.01705.pdf)
>  Exemplar-based colourisation aims to add plausible colours to a grayscale image using the guidance of a colour reference image. Most of the existing methods tackle the task as a style transfer problem, using a convolutional neural network (CNN) to obtain deep representations of the content of both inputs. Stylised outputs are then obtained by computing similarities between both feature representations in order to transfer the style of the reference to the content of the target input. However, in order to gain robustness towards dissimilar references, the stylised outputs need to be refined with a second colourisation network, which significantly increases the overall system complexity. This work reformulates the existing methodology introducing a novel end-to-end colourisation network that unifies the feature matching with the colourisation process. The proposed architecture integrates attention modules at different resolutions that learn how to perform the style transfer task in an unsupervised way towards decoding realistic colour predictions. Moreover, axial attention is proposed to simplify the attention operations and to obtain a fast but robust cost-effective architecture. Experimental validations demonstrate efficiency of the proposed methodology which generates high quality and visual appealing colourisation. Furthermore, the complexity of the proposed methodology is reduced compared to the state-of-the-art methods.      
### 24.Model-Free Incremental Adaptive Dynamic Programming Based Approximate Robust Optimal Regulation  [ :arrow_down: ](https://arxiv.org/pdf/2105.01698.pdf)
>  This paper presents a new formulation for model-free robust optimal regulation of continuous-time nonlinear systems. The proposed reinforcement learning based approach, referred to as incremental adaptive dynamic programming (IADP), exploits measured data to allow the design of the approximate optimal incremental control strategy, which stabilizes the controlled system incrementally under model uncertainties, environmental disturbances, and input saturation. By leveraging the time delay estimation (TDE) technique, we first exploit sensory data to reduce the requirement of a complete dynamics, where measured data are adopted to construct an incremental dynamics that reflects the system evolution in an incremental form. Then, the resulting incremental dynamics serves to design the approximate optimal incremental control strategy based on adaptive dynamic programming, which is implemented as a simplified single critic structure to get the approximate solution to the value function of the Hamilton-Jacobi-Bellman equation. Furthermore, for the critic artificial neural network, experience data are used to design an off-policy weight update law with guaranteed weight convergence. Rather importantly, to address the unintentionally introduced TDE error, we incorporate a TDE error bound related term into the cost function, whereby the TDE error is attenuated during the optimization process. The system stability proof and the weight convergence proof are provided. Numerical simulations are conducted to validate the effectiveness and superiority of our proposed IADP, especially regarding the reduced control energy expenditure and the enhanced robustness.      
### 25.Learning to Continuously Optimize Wireless Resource in a Dynamic Environment: A Bilevel Optimization Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2105.01696.pdf)
>  There has been a growing interest in developing data-driven, and in particular deep neural network (DNN) based methods for modern communication tasks. For a few popular tasks such as power control, beamforming, and MIMO detection, these methods achieve state-of-the-art performance while requiring less computational efforts, less resources for acquiring channel state information (CSI), etc. However, it is often challenging for these approaches to learn in a dynamic environment. <br>This work develops a new approach that enables data-driven methods to continuously learn and optimize resource allocation strategies in a dynamic environment. Specifically, we consider an ``episodically dynamic" setting where the environment statistics change in ``episodes", and in each episode the environment is stationary. We propose to build the notion of continual learning (CL) into wireless system design, so that the learning model can incrementally adapt to the new episodes, {\it without forgetting} knowledge learned from the previous episodes. Our design is based on a novel bilevel optimization formulation which ensures certain ``fairness" across different data samples. We demonstrate the effectiveness of the CL approach by integrating it with two popular DNN based models for power control and beamforming, respectively, and testing using both synthetic and ray-tracing based data sets. These numerical results show that the proposed CL approach is not only able to adapt to the new scenarios quickly and seamlessly, but importantly, it also maintains high performance over the previously encountered scenarios as well.      
### 26.On Moment Matching for Stochastic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.01680.pdf)
>  In this paper we study the problem of model reduction by moment matching for stochastic systems. We characterize the mathematical object which generalizes the notion of moment to stochastic differential equations and we find a class of models which achieve moment matching. However, differently from the deterministic case, these reduced-order models cannot be considered "simpler" because of the high computational cost paid to determine the moment. To overcome this difficulty, we relax the moment matching problem in two different ways and we present two classes of reduced-order models which, approximately matching the stochastic moment, are computationally tractable.      
### 27.Impact of individual rater style on deep learning uncertainty in medical imaging segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.02197.pdf)
>  While multiple studies have explored the relation between inter-rater variability and deep learning model uncertainty in medical segmentation tasks, little is known about the impact of individual rater style. This study quantifies rater style in the form of bias and consistency and explores their impacts when used to train deep learning models. Two multi-rater public datasets were used, consisting of brain multiple sclerosis lesion and spinal cord grey matter segmentation. On both datasets, results show a correlation ($R^2 = 0.60$ and $0.93$) between rater bias and deep learning uncertainty. The impact of label fusion between raters' annotations on this relationship is also explored, and we show that multi-center consensuses are more effective than single-center consensuses to reduce uncertainty, since rater style is mostly center-specific.      
### 28.Audio Retrieval with Natural Language Queries  [ :arrow_down: ](https://arxiv.org/pdf/2105.02192.pdf)
>  We consider the task of retrieving audio using free-form natural language queries. To study this problem, which has received limited attention in the existing literature, we introduce challenging new benchmarks for text-based audio retrieval using text annotations sourced from the Audiocaps and Clotho datasets. We then employ these benchmarks to establish baselines for cross-modal audio retrieval, where we demonstrate the benefits of pre-training on diverse audio tasks. We hope that our benchmarks will inspire further research into cross-modal text-based audio retrieval with free-form text queries.      
### 29.VoxelContext-Net: An Octree based Framework for Point Cloud Compression  [ :arrow_down: ](https://arxiv.org/pdf/2105.02158.pdf)
>  In this paper, we propose a two-stage deep learning framework called VoxelContext-Net for both static and dynamic point cloud compression. Taking advantages of both octree based methods and voxel based schemes, our approach employs the voxel context to compress the octree structured data. Specifically, we first extract the local voxel representation that encodes the spatial neighbouring context information for each node in the constructed octree. Then, in the entropy coding stage, we propose a voxel context based deep entropy model to compress the symbols of non-leaf nodes in a lossless way. Furthermore, for dynamic point cloud compression, we additionally introduce the local voxel representations from the temporal neighbouring point clouds to exploit temporal dependency. More importantly, to alleviate the distortion from the octree construction procedure, we propose a voxel context based 3D coordinate refinement method to produce more accurate reconstructed point cloud at the decoder side, which is applicable to both static and dynamic point cloud compression. The comprehensive experiments on both static and dynamic point cloud benchmark datasets(e.g., ScanNet and Semantic KITTI) clearly demonstrate the effectiveness of our newly proposed method VoxelContext-Net for 3D point cloud geometry compression.      
### 30.Graph structure based Heuristics for Optimal Targeting in Social Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.02133.pdf)
>  We consider a dynamic model for competition in a social network, where two strategic agents have fixed beliefs and the non-strategic/regular agents adjust their states according to a distributed consensus protocol. We suppose that one strategic agent must identify k+ target agents in the network in order to maximally spread its own opinion and alter the average opinion that eventually emerges. In the literature, this problem is cast as the maximization of a set function and, leveraging on the submodular property, is solved in a greedy manner by solving k+ separate single targeting problems. Our main contribution is to exploit the underlying graph structure to build more refined heuristics. As a first instance, we provide the analytical solution for the optimal targeting problem over complete graphs. This result provides a rule to understand whether it is convenient or not to block the opponent's influence by targeting the same nodes. The argument is then extended to generic graphs leading to more accurate solutions compared to a simple greedy approach. As a second instance, by electrical analogy we provide the analytical solution of the single targeting problem for the line graph and derive some useful properties of the objective function for trees. Inspired by these findings, we define a new algorithm which selects the optimal solution on trees in a much faster way with respect to a brute-force approach and works well also over tree-like/sparse graphs. The proposed heuristics are then compared to zero-cost heuristics on different random generated graphs and real social networks. Summarizing, our results suggest a scheme that tells which algorithm is more suitable in terms of accuracy and computational complexity, based on the density of the graphs and its degree distribution.      
### 31.Self-Supervised Learning from Automatically Separated Sound Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2105.02132.pdf)
>  Real-world sound scenes consist of time-varying collections of sound sources, each generating characteristic sound events that are mixed together in audio recordings. The association of these constituent sound events with their mixture and each other is semantically constrained: the sound scene contains the union of source classes and not all classes naturally co-occur. With this motivation, this paper explores the use of unsupervised automatic sound separation to decompose unlabeled sound scenes into multiple semantically-linked views for use in self-supervised contrastive learning. We find that learning to associate input mixtures with their automatically separated outputs yields stronger representations than past approaches that use the mixtures alone. Further, we discover that optimal source separation is not required for successful contrastive learning by demonstrating that a range of separation system convergence states all lead to useful and often complementary example transformations. Our best system incorporates these unsupervised separation models into a single augmentation front-end and jointly optimizes similarity maximization and coincidence prediction objectives across the views. The result is an unsupervised audio representation that rivals state-of-the-art alternatives on the established shallow AudioSet classification benchmark.      
### 32.Generalized Selection in Wireless Powered Networks with Non-Linear Energy Harvesting  [ :arrow_down: ](https://arxiv.org/pdf/2105.02100.pdf)
>  The rapid growth of the so-called Internet of Things is expected to significantly expand and support the deployment of resource-limited devices. Therefore, intelligent scheduling protocols and technologies such as wireless power transfer, are important for the efficient implementation of these massive low-powered networks. This paper studies the performance of a wireless powered communication network, where multiple batteryless devices harvest radio-frequency from a dedicated transmitter in order to communicate with a common information receiver (IR). We investigate several novel selection schemes, corresponding to different channel state information requirements and implementation complexities. In particular, each scheme schedules the $k$-th best device based on: a) the end-to-end (e2e) signal-to-noise ratio (SNR), b) the energy harvested at the devices, c) the uplink transmission to the IR, and d) the conventional/legacy max-min selection policy. We consider a non-linear energy harvesting (EH) model and derive analytical expressions for the outage probability of each selection scheme by using tools from high order statistics. %Our results show that, the performance of all the proposed schemes converges to an error floor due to the saturation effects of the considered EH model. Moreover, an asymptotic scenario in terms of the number of devices is considered and, by applying extreme value theory, the system's performance is evaluated. We derive a complete analytical framework that provides useful insights for the design and realization of such networks.      
### 33.Efficient Strategy Synthesis for MDPs with Resource Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2105.02099.pdf)
>  We consider qualitative strategy synthesis for the formalism called consumption Markov decision processes. This formalism can model dynamics of an agents that operates under resource constraints in a stochastic environment. The presented algorithms work in time polynomial with respect to the representation of the model and they synthesize strategies ensuring that a given set of goal states will be reached (once or infinitely many times) with probability 1 without resource exhaustion. In particular, when the amount of resource becomes too low to safely continue in the mission, the strategy changes course of the agent towards one of a designated set of reload states where the agent replenishes the resource to full capacity; with sufficient amount of resource, the agent attempts to fulfill the mission again. <br>We also present two heuristics that attempt to reduce expected time that the agent needs to fulfill the given mission, a parameter important in practical planning. The presented algorithms were implemented and numerical examples demonstrate (i) the effectiveness (in terms of computation time) of the planning approach based on consumption Markov decision processes and (ii) the positive impact of the two heuristics on planning in a realistic example.      
### 34.End-to-End Diarization for Variable Number of Speakers with Local-Global Networks and Discriminative Speaker Embeddings  [ :arrow_down: ](https://arxiv.org/pdf/2105.02096.pdf)
>  We present an end-to-end deep network model that performs meeting diarization from single-channel audio recordings. End-to-end diarization models have the advantage of handling speaker overlap and enabling straightforward handling of discriminative training, unlike traditional clustering-based diarization methods. The proposed system is designed to handle meetings with unknown numbers of speakers, using variable-number permutation-invariant cross-entropy based loss functions. We introduce several components that appear to help with diarization performance, including a local convolutional network followed by a global self-attention module, multi-task transfer learning using a speaker identification component, and a sequential approach where the model is refined with a second stage. These are trained and validated on simulated meeting data based on LibriSpeech and LibriTTS datasets; final evaluations are done using LibriCSS, which consists of simulated meetings recorded using real acoustics via loudspeaker playback. The proposed model performs better than previously proposed end-to-end diarization models on these data.      
### 35.Leveraging Machine Learning for Industrial Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.02051.pdf)
>  Two main trends characterize today's communication landscape and are finding their way into industrial facilities: the rollout of 5G with its distinct support for vertical industries and the increasing success of machine learning (ML). The combination of those two technologies open the doors to many exciting industrial applications and its impact is expected to rapidly increase in the coming years, given the abundant data growth and the availability of powerful edge computers in production facilities. Unlike most previous work that has considered the application of 5G and ML in industrial environment separately, this paper highlights the potential and synergies that result from combining them. The overall vision presented here generates from the KICK project, a collaboration of several partners from the manufacturing and communication industry as well as research institutes. This unprecedented blend of 5G and ML expertise creates a unique perspective on ML-supported industrial communications and their role in facilitating industrial automation. The paper identifies key open industrial challenges that are grouped into four use cases: wireless connectivity and edge-cloud integration, flexibility in network reconfiguration, dynamicity of heterogeneous network services, and mobility of robots and vehicles. Moreover, the paper provides insights into the advantages of ML-based industrial communications and discusses current challenges of data acquisition in real systems.      
### 36.Non-Autoregressive vs Autoregressive Neural Networks for System Identification  [ :arrow_down: ](https://arxiv.org/pdf/2105.02027.pdf)
>  The application of neural networks to non-linear dynamic system identification tasks has a long history, which consists mostly of autoregressive approaches. Autoregression, the usage of the model outputs of previous time steps, is a method of transferring a system state between time steps, which is not necessary for modeling dynamic systems with modern neural network structures, such as gated recurrent units (GRUs) and Temporal Convolutional Networks (TCNs). We compare the accuracy and execution performance of autoregressive and non-autoregressive implementations of a GRU and TCN on the simulation task of three publicly available system identification benchmarks. Our results show, that the non-autoregressive neural networks are significantly faster and at least as accurate as their autoregressive counterparts. Comparisons with other state-of-the-art black-box system identification methods show, that our implementation of the non-autoregressive GRU is the best performing neural network-based system identification method, and in the benchmarks without extrapolation, the best performing black-box method.      
### 37.Improved feature extraction for CRNN-based multiple sound source localization  [ :arrow_down: ](https://arxiv.org/pdf/2105.01897.pdf)
>  In this work, we propose to extend a state-of-the-art multi-source localization system based on a convolutional recurrent neural network and Ambisonics signals. We significantly improve the performance of the baseline network by changing the layout between convolutional and pooling layers. We propose several configurations with more convolutional layers and smaller pooling sizes in-between, so that less information is lost across the layers, leading to a better feature extraction. In parallel, we test the system's ability to localize up to 3 sources, in which case the improved feature extraction provides the most significant boost in accuracy. We evaluate and compare these improved configurations on synthetic and real-world data. The obtained results show a quite substantial improvement of the multiple sound source localization performance over the baseline network.      
### 38.Parameterizing the Angular Distribution of Emission: A model for TOF-PET low counts reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.01854.pdf)
>  Low counts reconstruction remains a challenge for Positron Emission Tomography (PET) even with the recent progresses in time-of-flight (TOF) resolution. In that setting, the bias between the acquired histogram, composed of low values or zeros, and the expected histogram, obtained from the forward projector, is propagated to the image, resulting in a biased reconstruction. This could be exacerbated with finer resolution of the TOF information, which further sparsify the acquired histogram. We propose a new approach to circumvent this limitation of the classical reconstruction model. It consists of extending the parametrization of the reconstruction scheme to also explicitly include the projection domain. This parametrization has greater degrees of freedom than the log-likelihood model, which can not be harnessed in classical circumstances. We hypothesize that with ultra-fast TOF this new approach would not only be viable for low counts reconstruction but also more adequate than the classical reconstruction model. An implementation of this approach is compared to the log-likelihood model by using two-dimensional simulations of a hot spots phantom. The proposed model achieves similar contrast recovery coefficients as MLEM except for the smallest structures where the low counts nature of the simulations makes it difficult to draw conclusions. Also, this new model seems to converge toward a less noisy solution than the MLEM. These results suggest that this new approach has potential for low counts reconstruction with ultra-fast TOF.      
### 39.Acoustic Scene Classification Using Multichannel Observation with Partially Missing Channels  [ :arrow_down: ](https://arxiv.org/pdf/2105.01836.pdf)
>  Sounds recorded with smartphones or IoT devices often have partially unreliable observations caused by clipping, wind noise, and completely missing parts due to microphone failure and packet loss in data transmission over the network. In this paper, we investigate the impact of the partially missing channels on the performance of acoustic scene classification using multichannel audio recordings, especially for a distributed microphone array. Missing observations cause not only losses of time-frequency and spatial information on sound sources but also a mismatch between a trained model and evaluation data. We thus investigate how a missing channel affects the performance of acoustic scene classification in detail. We also propose simple data augmentation methods for scene classification using multichannel observations with partially missing channels and evaluate the scene classification performance using the data augmentation methods.      
### 40.Curvatures of Stiefel manifolds with deformation metrics  [ :arrow_down: ](https://arxiv.org/pdf/2105.01834.pdf)
>  We compute curvatures of a family of tractable metrics on Stiefel manifolds, introduced recently by H{ü}per, Markina and Silva Leite, which includes the well-known embedded and canonical metrics on Stiefel manifolds as special cases. The metrics could be identified with the Cheeger deformation metrics. We identify parameter values in the family to make a Stiefel manifold an Einstein manifold and show Stiefel manifolds always carry an Einstein metric. We analyze the sectional curvature range and identify the parameter range where the manifold has non-negative sectional curvature. We provide the exact sectional curvature range when the number of columns in a Stiefel matrix is $2$, and a conjectural range for other cases. We derive the formulas from two approaches, one from a global curvature formula derived in our recent work, another using curvature formulas for left-invariant metrics. The second approach leads to curvature formulas for Cheeger deformation metrics on normal homogeneous spaces.      
### 41.Real-time Face Mask Detection in Video Data  [ :arrow_down: ](https://arxiv.org/pdf/2105.01816.pdf)
>  In response to the ongoing COVID-19 pandemic, we present a robust deep learning pipeline that is capable of identifying correct and incorrect mask-wearing from real-time video streams. To accomplish this goal, we devised two separate approaches and evaluated their performance and run-time efficiency. The first approach leverages a pre-trained face detector in combination with a mask-wearing image classifier trained on a large-scale synthetic dataset. The second approach utilizes a state-of-the-art object detection network to perform localization and classification of faces in one shot, fine-tuned on a small set of labeled real-world images. The first pipeline achieved a test accuracy of 99.97% on the synthetic dataset and maintained 6 FPS running on video data. The second pipeline achieved a mAP(0.5) of 89% on real-world images while sustaining 52 FPS on video data. We have concluded that if a larger dataset with bounding-box labels can be curated, this task is best suited using object detection architectures such as YOLO and SSD due to their superior inference speed and satisfactory performance on key evaluation metrics.      
### 42.Intensity Harmonization for Airborne LiDAR  [ :arrow_down: ](https://arxiv.org/pdf/2105.01793.pdf)
>  Constructing a point cloud for a large geographic region, such as a state or country, can require multiple years of effort. Often several vendors will be used to acquire LiDAR data, and a single region may be captured by multiple LiDAR scans. A key challenge is maintaining consistency between these scans, which includes point density, number of returns, and intensity. Intensity in particular can be very different between scans, even in areas that are overlapping. Harmonizing the intensity between scans to remove these discrepancies is expensive and time consuming. In this paper, we propose a novel method for point cloud harmonization based on deep neural networks. We evaluate our method quantitatively and qualitatively using a high quality real world LiDAR dataset. We compare our method to several baselines, including standard interpolation methods as well as histogram matching. We show that our method performs as well as the best baseline in areas with similar intensity distributions, and outperforms all baselines in areas with different intensity distributions. Source code is available at <a class="link-external link-https" href="https://github.com/mvrl/lidar-harmonization" rel="external noopener nofollow">this https URL</a> .      
### 43.Aggregate Cyber-Risk Management in the IoT Age: Cautionary Statistics for (Re)Insurers and Likes  [ :arrow_down: ](https://arxiv.org/pdf/2105.01792.pdf)
>  In this paper, we provide (i) a rigorous general theory to elicit conditions on (tail-dependent) heavy-tailed cyber-risk distributions under which a risk management firm might find it (non)sustainable to provide aggregate cyber-risk coverage services for smart societies, and (ii)a real-data driven numerical study to validate claims made in theory assuming boundedly rational cyber-risk managers, alongside providing ideas to boost markets that aggregate dependent cyber-risks with <a class="link-external link-http" href="http://heavy-tails.To" rel="external noopener nofollow">this http URL</a> the best of our knowledge, this is the only complete general theory till date on the feasibility of aggregate cyber-risk management.      
### 44.Robust Reconfigurable Intelligent Surfaces via Invariant Risk and Causal Representations  [ :arrow_down: ](https://arxiv.org/pdf/2105.01771.pdf)
>  In this paper, the problem of robust reconfigurable intelligent surface (RIS) system design under changes in data distributions is investigated. Using the notion of invariant risk minimization (IRM), an invariant causal representation across multiple environments is used such that the predictor is simultaneously optimal for each environment. A neural network-based solution is adopted to seek the predictor and its performance is validated via simulations against an empirical risk minimization-based design. Results show that leveraging invariance yields more robustness against unseen and out-of-distribution testing environments.      
### 45.WaveGlove: Transformer-based hand gesture recognition using multiple inertial sensors  [ :arrow_down: ](https://arxiv.org/pdf/2105.01753.pdf)
>  Hand Gesture Recognition (HGR) based on inertial data has grown considerably in recent years, with the state-of-the-art approaches utilizing a single handheld sensor and a vocabulary comprised of simple gestures. <br>In this work we explore the benefits of using multiple inertial sensors. Using WaveGlove, a custom hardware prototype in the form of a glove with five inertial sensors, we acquire two datasets consisting of over $11000$ samples. <br>To make them comparable with prior work, they are normalized along with $9$ other publicly available datasets, and subsequently used to evaluate a range of Machine Learning approaches for gesture recognition, including a newly proposed Transformer-based architecture. Our results show that even complex gestures involving different fingers can be recognized with high accuracy. <br>An ablation study performed on the acquired datasets demonstrates the importance of multiple sensors, with an increase in performance when using up to three sensors and no significant improvements beyond that.      
### 46.Motion Artifact Reduction in Quantitative Susceptibility Mapping using Deep Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2105.01746.pdf)
>  An approach to reduce motion artifacts in Quantitative Susceptibility Mapping using deep learning is proposed. We use an affine motion model with randomly created motion profiles to simulate motion-corrupted QSM images. The simulated QSM image is paired with its motion-free reference to train a neural network using supervised learning. The trained network is tested on unseen simulated motion-corrupted QSM images, in healthy volunteers and in Parkinson's disease patients. The results show that motion artifacts, such as ringing and ghosting, were successfully suppressed.      

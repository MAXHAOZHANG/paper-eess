# ArXiv eess --Tue, 4 May 2021
### 1.Multi-agent consensus with heterogeneous time-varying input and communication delays in digraphs  [ :arrow_down: ](https://arxiv.org/pdf/2105.01053.pdf)
>  This paper investigates the distributed consensus tracking control problem for general linear multi-agent systems (MASs) with external disturbances and heterogeneous time-varying input and communication delays under a directed communication graph topology, containing a spanning tree. First, for all agents whose state matrix has no eigenvalues with positive real parts, a communication-delay-related observer, which is used to construct the controller, is designed for followers to estimate the leader's state information. Second, by means of the output regulation theory, the results are relaxed to the case that only the leader's state matrix eigenvalues have non-positive real parts and, under these relaxed conditions, the controller is redesigned. Both cases lead to a closed-loop error system of which the stability is guaranteed via a Lyapunov-Krasovskii functional with sufficient conditions in terms of input-delay-dependent linear matrix inequalities (LMIs). An extended LMI is proposed which, in conjunction with the rest of LMIs, results in a solution with a larger upper bound on delays than what would be feasible without it. It is highlighted that the integration of communication-delay-related observer and input-delay-related LMI to construct a fully distributed controller (which requires no global information) is scalable to arbitrarily large networks. The efficacy of the proposed scheme is demonstrated via illustrative numerical examples.      
### 2.On the Sum of Random Samples with Bounded Pareto Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2105.01032.pdf)
>  Heavy-tailed random samples, as well as their sum or average, are encountered in a number of signal processing applications in radar, communications, finance, and natural sciences. Modeling such data through the Pareto distribution is particularly attractive due to its simple analytical form, but may lead to infinite variance and/or mean, which is not physically plausible: in fact, samples are always bounded in practice, namely because of clipping during the signal acquisition or deliberate censoring or trimming (truncation) at the processing stage. Based on this motivation, the paper derives and analyzes the distribution of the sum of right-censored Pareto Type-II variables, which generalizes the conventional Pareto (Type-I) and Lomax distributions. The distribution of the sum of truncated Pareto is also obtained, and an analytical connection is drawn with the unbounded case. A numerical analysis illustrates the findings, providing insights on several aspects including the intimate mixture structure of the obtained expressions.      
### 3.Enhanced U-Net: A Feature Enhancement Network for Polyp Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00999.pdf)
>  Colonoscopy is a procedure to detect colorectal polyps which are the primary cause for developing colorectal cancer. However, polyp segmentation is a challenging task due to the diverse shape, size, color, and texture of polyps, shuttle difference between polyp and its background, as well as low contrast of the colonoscopic images. To address these challenges, we propose a feature enhancement network for accurate polyp segmentation in colonoscopy images. Specifically, the proposed network enhances the semantic information using the novel Semantic Feature Enhance Module (SFEM). Furthermore, instead of directly adding encoder features to the respective decoder layer, we introduce an Adaptive Global Context Module (AGCM), which focuses only on the encoder's significant and hard fine-grained features. The integration of these two modules improves the quality of features layer by layer, which in turn enhances the final feature representation. The proposed approach is evaluated on five colonoscopy datasets and demonstrates superior performance compared to other state-of-the-art models.      
### 4.Fleet management for ride-pooling with meeting points at scale: a case study in the five boroughs of New York City  [ :arrow_down: ](https://arxiv.org/pdf/2105.00994.pdf)
>  Introducing meeting points to ride-pooling (RP) services has been shown to increase the satisfaction level of both riders and service providers. Passengers may choose to walk to a meeting point for a cost reduction. Drivers may also get matched with more riders without making additional stops. There are economic benefits of using ride-pooling with meeting points (RPMP) compared to the traditional RP services. Many RPMP models have been proposed to better understand their benefits. However, most prior works study RPMP either with a restricted set of parameters or at a small scale due to the expensive computation involved. In this paper, we propose STaRS+, a scalable RPMP framework that is based on a comprehensive integer linear programming model. The high scalability of STaRS+ is achieved by utilizing a heuristic optimization strategy along with a novel shortest-path caching scheme. We applied our model to the NYC metro area to evaluate the scalability of the framework and demonstrate the importance of city-scale simulations. Our results show that city-scale simulations can reveal valuable insights for city planners that are not always visible at smaller scales. To the best of our knowledge, STaRS+ is the first study on the RPMP that can solve large-scale instances on the order of the entire NYC metro area.      
### 5.A lightweight deep learning based cloud detection method for Sentinel-2A imagery fusing multi-scale spectral and spatial features  [ :arrow_down: ](https://arxiv.org/pdf/2105.00967.pdf)
>  Clouds are a very important factor in the availability of optical remote sensing images. Recently, deep learning-based cloud detection methods have surpassed classical methods based on rules and physical models of clouds. However, most of these deep models are very large which limits their applicability and explainability, while other models do not make use of the full spectral information in multi-spectral images such as Sentinel-2. In this paper, we propose a lightweight network for cloud detection, fusing multi-scale spectral and spatial features (CDFM3SF) and tailored for processing all spectral bands in Sentinel- 2A images. The proposed method consists of an encoder and a decoder. In the encoder, three input branches are designed to handle spectral bands at their native resolution and extract multiscale spectral features. Three novel components are designed: a mixed depth-wise separable convolution (MDSC) and a shared and dilated residual block (SDRB) to extract multi-scale spatial features, and a concatenation and sum (CS) operation to fuse multi-scale spectral and spatial features with little calculation and no additional parameters. The decoder of CD-FM3SF outputs three cloud masks at the same resolution as input bands to enhance the supervision information of small, middle and large clouds. To validate the performance of the proposed method, we manually labeled 36 Sentinel-2A scenes evenly distributed over mainland China. The experiment results demonstrate that CD-FM3SF outperforms traditional cloud detection methods and state-of-theart deep learning-based methods in both accuracy and speed.      
### 6.Systematic Assessment of Hyperdimensional Computing for Epileptic Seizure Detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.00934.pdf)
>  Hyperdimensional computing is a promising novel paradigm for low-power embedded machine learning. It has been applied on different biomedical applications, and particularly on epileptic seizure detection. Unfortunately, due to differences in data preparation, segmentation, encoding strategies, and performance metrics, results are hard to compare, which makes building upon that knowledge difficult. Thus, the main goal of this work is to perform a systematic assessment of the HD computing framework for the detection of epileptic seizures, comparing different feature approaches mapped to HD vectors. More precisely, we test two previously implemented features as well as several novel approaches with HD computing on epileptic seizure detection. We evaluate them in a comparable way, i.e., with the same preprocessing setup, and with the identical performance measures. We use two different datasets in order to assess the generalizability of our conclusions. The systematic assessment involved three primary aspects relevant for potential wearable implementations: 1) detection performance, 2) memory requirements, and 3) computational complexity. Our analysis shows a significant difference in detection performance between approaches, but also that the ones with the highest performance might not be ideal for wearable applications due to their high memory or computational requirements. Furthermore, we evaluate a post-processing strategy to adjust the predictions to the dynamics of epileptic seizures, showing that performance is significantly improved in all the approaches and also that after post-processing, differences in performance are much smaller between approaches.      
### 7.Complex-valued Convolutional Neural Networks for Enhanced Radar Signal Denoising and Interference Mitigation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00929.pdf)
>  Autonomous driving highly depends on capable sensors to perceive the environment and to deliver reliable information to the vehicles' control systems. To increase its robustness, a diversified set of sensors is used, including radar sensors. Radar is a vital contribution of sensory information, providing high resolution range as well as velocity measurements. The increased use of radar sensors in road traffic introduces new challenges. As the so far unregulated frequency band becomes increasingly crowded, radar sensors suffer from mutual interference between multiple radar sensors. This interference must be mitigated in order to ensure a high and consistent detection sensitivity. In this paper, we propose the use of Complex-Valued Convolutional Neural Networks (CVCNNs) to address the issue of mutual interference between radar sensors. We extend previously developed methods to the complex domain in order to process radar data according to its physical characteristics. This not only increases data efficiency, but also improves the conservation of phase information during filtering, which is crucial for further processing, such as angle estimation. Our experiments show, that the use of CVCNNs increases data efficiency, speeds up network training and substantially improves the conservation of phase information during interference removal.      
### 8.Reachability of Black-Box Nonlinear Systems after Koopman Operator Linearization  [ :arrow_down: ](https://arxiv.org/pdf/2105.00886.pdf)
>  Reachability analysis of nonlinear dynamical systems is a challenging and computationally expensive task. Computing the reachable states for linear systems, in contrast, can often be done efficiently in high dimensions. In this paper, we explore verification methods that leverage a connection between these two classes of systems based on the concept of the Koopman operator. The Koopman operator links the behaviors of a nonlinear system to a linear system embedded in a higher dimensional space, with an additional set of so-called observable variables. Although, the new dynamical system has linear differential equations, the set of initial states is defined with nonlinear constraints. For this reason, existing approaches for linear systems reachability cannot be used directly. In this paper, we propose the first reachability algorithm that deals with this unexplored type of reachability problem. Our evaluation examines several optimizations, and shows the proposed workflow is a promising avenue for verifying behaviors of nonlinear systems.      
### 9.A Sensorless Control System for an Implantable Heart Pump using a Real-time Deep Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2105.00875.pdf)
>  Left ventricular assist devices (LVADs) are mechanical pumps, which can be used to support heart failure (HF) patients as bridge to transplant and destination therapy. To automatically adjust the LVAD speed, a physiological control system needs to be designed to respond to variations of patient hemodynamics across a variety of clinical scenarios. These control systems require pressure feedback signals from the cardiovascular system. However, there are no suitable long-term implantable sensors available. In this study, a novel real-time deep convolutional neural network (CNN) for estimation of preload based on the LVAD flow was proposed. A new sensorless adaptive physiological control system for an LVAD pump was developed using the full dynamic form of model free adaptive control (FFDL-MFAC) and the proposed preload estimator to maintain the patient conditions in safe physiological ranges. The CNN model for preload estimation was trained and evaluated through 10-fold cross validation on 100 different patient conditions and the proposed sensorless control system was assessed on a new testing set of 30 different patient conditions across six different patient scenarios. The proposed preload estimator was extremely accurate with a correlation coefficient of 0.97, root mean squared error of 0.84 mmHg, reproducibility coefficient of 1.56 mmHg, coefficient of variation of 14.44 %, and bias of 0.29 mmHg for the testing dataset. The results also indicate that the proposed sensorless physiological controller works similarly to the preload-based physiological control system for LVAD using measured preload to prevent ventricular suction and pulmonary congestion. This study shows that the LVADs can respond appropriately to changing patient states and physiological demands without the need for additional pressure or flow measurements.      
### 10.On Addressing Practical Challenges for RNN-Transducer  [ :arrow_down: ](https://arxiv.org/pdf/2105.00858.pdf)
>  In this paper, several works are proposed to address practical challenges for deploying RNN Transducer (RNN-T) based speech recognition system. These challenges are adapting a well-trained RNN-T model to a new domain without collecting the audio data, obtaining time stamps and confidence scores at word level. The first challenge is solved with a splicing data method which concatenates the speech segments extracted from the source domain data. To get the time stamp, a phone prediction branch is added to the RNN-T model by sharing the encoder for the purpose of force alignment. Finally, we obtain word-level confidence scores by utilizing several types of features calculated during decoding and from confusion network. Evaluated with Microsoft production data, the splicing data adaptation method improves the baseline and adaption with the text to speech method by 58.03% and 15.25% relative word error rate reduction, respectively. The proposed time stamping method can get less than 50ms word timing difference on average while maintaining the recognition accuracy of the RNN-T model. We also obtain high confidence annotation performance with limited computation cost.      
### 11.Robust 3D Cell Segmentation: Extending the View of Cellpose  [ :arrow_down: ](https://arxiv.org/pdf/2105.00794.pdf)
>  Increasing data set sizes of digital microscopy imaging experiments demand for an automation of segmentation processes to be able to extract meaningful biomedical information. Due to the shortage of annotated 3D image data that can be used for machine learning-based approaches, 3D segmentation approaches are required to be robust and to generalize well to unseen data. Reformulating the problem of instance segmentation as a collection of diffusion gradient maps, proved to be such a generalist approach for cell segmentation tasks. In this paper, we extend the Cellpose approach to improve segmentation accuracy on 3D image data and we further show how the formulation of the gradient maps can be simplified while still being robust and reaching similar segmentation accuracy. We quantitatively compared different experimental setups and validated on two different data sets of 3D confocal microscopy images of A. thaliana.      
### 12.Full-Reference Speech Quality Estimation with Attentional Siamese Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00783.pdf)
>  In this paper, we present a full-reference speech quality prediction model with a deep learning approach. The model determines a feature representation of the reference and the degraded signal through a siamese recurrent convolutional network that shares the weights for both signals as input. The resulting features are then used to align the signals with an attention mechanism and are finally combined to estimate the overall speech quality. The proposed network architecture represents a simple solution for the time-alignment problem that occurs for speech signals transmitted through Voice-Over-IP networks and shows how the clean reference signal can be incorporated into speech quality models that are based on end-to-end trained neural networks.      
### 13.Robust Observer Based Methodology for Frequency and Rate of Change of Frequency Estimation in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.00758.pdf)
>  An observer based adaptive detection methodology (ADM) is proposed for estimating frequency and its rate of change (RoCoF) of the voltage and/or current measurements acquired from an instrument transformer. With guaranteed convergence and stability, the proposed methodology effectively neutralizes the effect of the measurement distortions like harmonics, decaying DC components and outliers by adding its counter negative. It is robust to noise statistics, performs well while encountering step changes in amplitude/phase and is demonstrably superior to its precursors as established by test results. A benchmark IEEE NETS/NYPS 16 machine 68 bus power system has been used for performance evaluation of robust ADM against its precursors and scaled laboratory setup based on OP5600 multiprocessors was used for establishing its real-time applicability.      
### 14.Performance analysis of frequency regulation services provided by aggregates of domestic thermostatically controlled loads  [ :arrow_down: ](https://arxiv.org/pdf/2105.00729.pdf)
>  This paper proposes a control method for allowing aggregates of thermostatically controlled loads to provide synthetic inertia and primary frequency regulation services to the grid. The proposed control framework is fully distributed and basically consists in the modification of the thermostat logic as a function of the grid frequency. Three strategies are considered: in the first one, the load aggregate provides synthetic inertia by varying its active power demand proportionally to the frequency rate of change; in the second one, the load aggregate provides primary frequency regulation by varying its power demand proportionally to frequency; in the third one, the two services are combined. The performances of the proposed control solutions are analyzed in the forecasted scenario of the electric power system of Sardinia in 2030, characterized by a huge installation of wind and photovoltaic generation and no coil and combustible oil power plants. The considered load aggregate is composed by domestic refrigerators and water heaters. Results prove the effectiveness of the proposed approach and show that, in the particular case of refrigerators and water heaters, the contribution to the frequency regulation is more significant in the case of positive frequency variations. Finally, the correlation between the regulation performances and the level of penetration of the load aggregate with respect to the system total load is evaluated.      
### 15.Higher-order tensor independent component analysis to realize MIMO remote sensing of respiration and heartbeat signals  [ :arrow_down: ](https://arxiv.org/pdf/2105.00723.pdf)
>  This paper proposes a novel method of independent component analysis (ICA), which we name higher-order tensor ICA (HOT-ICA). HOT-ICA is a tensor ICA that makes effective use of the signal categories represented by the axes of a separating tensor. Conventional tensor ICAs, such as multilinear ICA (MICA) based on Tucker decomposition, do not fully utilize the high dimensionality of tensors because the matricization in MICA nullifies the tensor axial categorization. In this paper, we deal with multiple-target signal separation in a multiple-input multiple-output (MIMO) radar system to detect respiration and heartbeat. HOT-ICA realizes high robustness in learning by incorporating path information, i.e., the physical-measurement categories on which transmitting/receiving antennas were used. In numerical-physical experiments, our HOT-ICA system effectively separate the bio-signals successfully even in an obstacle-affecting environment, which is usually a difficult task. The results demonstrate the significance of the HOT-ICA, which keeps the tensor categorization unchanged for full utilization of the high-dimensionality of the separation tensor.      
### 16.Autonomous parafoil precision landing using convex real-time optimized guidance and control  [ :arrow_down: ](https://arxiv.org/pdf/2105.00715.pdf)
>  To overcome the limitations of current parafoil precision landing capabilities, an efficient real-time convex optimized guidance and control strategy is presented. Successive convexification of the parafoil guidance problem guarantees local optimality with polynomial convergence rate for efficient real-time implementation, where each iteration is dynamically feasible. Our approach shows reliable and fast numerical convergence through in-flight recalculation of time of flight and a new optimal trajectory to cope with time-varying dynamics. The efficiency of our strategy is demonstrated via a comparative analysis of the existing X-38 in-flight demonstrated guidance and control system. Exhaustive Monte-Carlo simulations show performance improvements of about one order of magnitude. The concept proposed is simple, yet general, as it scales to any atmospheric parafoil landing system and allows efficient implementation relying only on the turn rate information.      
### 17.Robust Control for Lane Keeping System Using Linear Parameter Varying Approach with Scheduling Variables Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2105.00712.pdf)
>  This paper presents a robust controller using a Linear Parameter Varying (LPV) model of the lane-keeping system with parameter reduction. Both varying vehicle speed and roll motion on a curved road influence the lateral vehicle model parameters, such as tire cornering stiffness. Thus, we use the LPV technique to take the parameter variations into account in vehicle dynamics. However, multiple varying parameters lead to a high number of scheduling variables and cause massive computational complexity. In this paper, to reduce the computational complexity, Principal Component Analysis (PCA)-based parameter reduction is performed to obtain a reduced model with a tighter convex set. We designed the LPV robust feedback controller using the reduced model solving a set of Linear Matrix Inequality (LMI). The effectiveness of the proposed system is validated with full vehicle dynamics from CarSim on an interchange road. From the simulation, we confirmed that the proposed method largely reduces the lateral offset error, compared with other controllers based on Linear Time-Invariant (LTI) system.      
### 18.Heart-Darts: Classification of Heartbeats Using Differentiable Architecture Search  [ :arrow_down: ](https://arxiv.org/pdf/2105.00693.pdf)
>  Arrhythmia is a cardiovascular disease that manifests irregular heartbeats. In arrhythmia detection, the electrocardiogram (ECG) signal is an important diagnostic technique. However, manually evaluating ECG signals is a complicated and time-consuming task. With the application of convolutional neural networks (CNNs), the evaluation process has been accelerated and the performance is improved. It is noteworthy that the performance of CNNs heavily depends on their architecture design, which is a complex process grounded on expert experience and trial-and-error. In this paper, we propose a novel approach, Heart-Darts, to efficiently classify the ECG signals by automatically designing the CNN model with the differentiable architecture search (i.e., Darts, a cell-based neural architecture search method). Specifically, we initially search a cell architecture by Darts and then customize a novel CNN model for ECG classification based on the obtained cells. To investigate the efficiency of the proposed method, we evaluate the constructed model on the MIT-BIH arrhythmia database. Additionally, the extensibility of the proposed CNN model is validated on two other new databases. Extensive experimental results demonstrate that the proposed method outperforms several state-of-the-art CNN models in ECG classification in terms of both performance and generalization capability.      
### 19.Present and Future of Reconfigurable Intelligent Surface-Empowered Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.00671.pdf)
>  Signal processing and communication communities have witnessed the rise of many exciting communication technologies in recent years. Notable examples include alternative waveforms, massive multiple-input multiple-output (MIMO) signaling, non-orthogonal multiple access (NOMA), joint communications and sensing, sparse vector coding, index modulation, and so on. It is inevitable that 6G wireless networks will require a rethinking of wireless communication systems and technologies, particularly at the physical layer (PHY), considering the fact that the cellular industry reached another important milestone with the development of 5G wireless networks with diverse applications. Within this perspective, this article aims to shed light on the rising concept of reconfigurable intelligent surface (RIS)-empowered communications towards 6G wireless networks. We discuss the recent developments in the field and put forward promising candidates for future research and development. Specifically, we put our emphasis on active, transmitter-type, transmissive-reflective, and standalone RISs, by discussing their advantages and disadvantages compared to reflective RIS designs. Finally, we also envision an ultimate RIS architecture, which is able to adjust its operation modes dynamically, and introduce the new concept of PHY slicing over RISs towards 6G wireless networks.      
### 20.Feasibility Study on Intra-Grid Location Estimation Using Power ENF Signals  [ :arrow_down: ](https://arxiv.org/pdf/2105.00668.pdf)
>  The Electric Network Frequency (ENF) is a signature of power distribution networks that can be captured by multimedia recordings made in areas where there is electrical activity. This has led to an emergence of several forensic applications based on the use of the ENF signature. Examples of such applications include estimating or verifying the time-of-recording of a media signal and inferring the power grid associated with the location in which the media signal was recorded. In this paper, we carry out a feasibility study to examine the possibility of using embedded ENF traces to pinpoint the location-of-recording of a signal within a power grid. In this study, we demonstrate that it is possible to pinpoint the location-of-recording to a certain geographical resolution using power signal recordings containing strong ENF traces. To this purpose, a high-passed version of an ENF signal is extracted and it is demonstrated that the correlation between two such signals, extracted from recordings made in different geographical locations within the same grid, decreases as the distance between the recording locations increases. We harness this property of correlation in the ENF signals to propose trilateration based localization methods, which pinpoint the unknown location of a recording while using some known recording locations as anchor locations. We also discuss the challenges that need to be overcome in order to extend this work to using ENF traces in noisier audio/video recordings for such fine localization purposes.      
### 21.A Rate-Splitting Strategy to Enable Joint Radar Sensing and Communication with Partial CSIT  [ :arrow_down: ](https://arxiv.org/pdf/2105.00633.pdf)
>  In order to manage the increasing interference between radar and communication systems, joint radar and communication (RadCom) systems have attracted increased attention in recent years, with the studies so far considering the assumption of perfect Channel State Information at the Transmitter (CSIT). However, such an assumption is unrealistic and neglects the inevitable CSIT errors that need to be considered to fully exploit the multi-antenna processing and interference management capabilities of a joint RadCom system. In this work, a joint RadCom system is designed which marries the capabilities of a Multiple-Input Multiple-Output (MIMO) radar with Rate-Splitting Multiple Access (RSMA), a powerful downlink communications scheme based on linearly precoded Rate-Splitting (RS) to partially decode multi-user interference (MUI) and partially treat it as noise. In this way, the RadCom precoders are optimized in the presence of partial CSIT to simultaneously maximize the Average Weighted Sum-Rate (AWSR) under QoS rate constraints and minimize the RadCom Beampattern Squared Error (BSE) against an ideal MIMO radar beampattern. Simulation results demonstrate that RSMA provides the RadCom with more robustness, flexibility and user rate fairness compared to the baseline joint RadCom system based on Space Division Multiple Access (SDMA).      
### 22.A guide to design disturbance observer based motion control systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.00615.pdf)
>  This paper proposes new practical design tools for the robust motion control systems based on disturbance observer (DOB). Although DOB has long been used in several motion control applications, it has insufficient analysis and design tools. The paper proposes a new practical robustness constraint, which improve the robustness at high frequencies, on the bandwidth of a DOB and nominal inertia. Although increasing the bandwidth of a DOB and nominal inertia improves the performance and stability, they are limited by the robustness constraint. Besides, a novel stability analysis method is proposed for reaction force observer (RFOB) based robust force control systems. It is shown that not only the performance, but also the stability changes significantly by the imperfect identification of inertia and torque coefficient. The robustness and stability of a DOB based motion control system are improved by proposing new design tools. The validity of the proposals are verified by experimental results.      
### 23.Efficiency Assessment of a Residential DC Nanogrid with Low and High Distribution Voltages Using Realistic Data  [ :arrow_down: ](https://arxiv.org/pdf/2105.00595.pdf)
>  Direct Current (DC) power distribution has gained attention in the Residential Nanogrids (RNGs) due to the substantial increase in the number of roof-top Photovoltaic (PV) systems and internally DC appliances used in buildings. Using DC distribution improves the efficiency of the RNGs compared to AC distribution. This paper investigated the efficiency of a DC RNG for low and high distribution voltage levels by exploring reasons for power losses. The studied DC RNG consisted of various types of local loads, on-site PV generation, and battery storage systems. The realistic load, PV profiles, and converter efficiency curves were used to make the analysis more accurate. In addition, three load profiles with low, medium, and high power consumptions were considered to study the load impacts on the overall system efficiency.      
### 24.Noisy Student learning for cross-institution brain hemorrhage detection  [ :arrow_down: ](https://arxiv.org/pdf/2105.00582.pdf)
>  Computed tomography (CT) is the imaging modality used in the diagnosis of neurological emergencies, including acute stroke and traumatic brain injury. Advances in deep learning have led to models that can detect and segment hemorrhage on head CT. PatchFCN, one such supervised fully convolutional network (FCN), recently demonstrated expert-level detection of intracranial hemorrhage on in-sample data. However, its potential for similar accuracy outside the training domain is hindered by its need for pixel-labeled data from outside institutions. Also recently, a semi-supervised technique, Noisy Student (NS) learning, demonstrated state-of-the-art performance on ImageNet by moving from a fully-supervised to a semi-supervised learning paradigm. We combine the PatchFCN and Noisy Student approaches, extending semi-supervised learning to an intracranial hemorrhage segmentation task. Surprisingly, the NS model performance surpasses that of a fully-supervised oracle model trained with image-level labels on the same data. It also performs comparably to another recently reported supervised model trained on a labeled dataset 600x larger than that used to train the NS model. To our knowledge, we are the first to demonstrate the effectiveness of semi-supervised learning on a head CT detection and segmentation task.      
### 25.Unsupervised Anomaly Detection in MR Images using Multi-Contrast Information  [ :arrow_down: ](https://arxiv.org/pdf/2105.00463.pdf)
>  Anomaly detection in medical imaging is to distinguish the relevant biomarkers of diseases from those of normal tissues. Deep supervised learning methods have shown potentials in various detection tasks, but its performances would be limited in medical imaging fields where collecting annotated anomaly data is limited and labor-intensive. Therefore, unsupervised anomaly detection can be an effective tool for clinical practices, which uses only unlabeled normal images as training data. In this paper, we developed an unsupervised learning framework for pixel-wise anomaly detection in multi-contrast magnetic resonance imaging (MRI). The framework has two steps of feature generation and density estimation with Gaussian mixture model (GMM). A feature is derived through the learning of contrast-to-contrast translation that effectively captures the normal tissue characteristics in multi-contrast MRI. The feature is collaboratively used with another feature that is the low-dimensional representation of multi-contrast images. In density estimation using GMM, a simple but efficient way is introduced to handle the singularity problem which interrupts the joint learning process. The proposed method outperforms previous anomaly detection approaches. Quantitative and qualitative analyses demonstrate the effectiveness of the proposed method in anomaly detection for multi-contrast MRI.      
### 26.Brain Graph Super-Resolution Using Adversarial Graph Neural Network with Application to Functional Brain Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2105.00425.pdf)
>  Brain image analysis has advanced substantially in recent years with the proliferation of neuroimaging datasets acquired at different resolutions. While research on brain image super-resolution has undergone a rapid development in the recent years, brain graph super-resolution is still poorly investigated because of the complex nature of non-Euclidean graph data. In this paper, we propose the first-ever deep graph super-resolution (GSR) framework that attempts to automatically generate high-resolution (HR) brain graphs with N' nodes (i.e., anatomical regions of interest (ROIs)) from low-resolution (LR) graphs with N nodes where N &lt; N'. First, we formalize our GSR problem as a node feature embedding learning task. Once the HR nodes' embeddings are learned, the pairwise connectivity strength between brain ROIs can be derived through an aggregation rule based on a novel Graph U-Net architecture. While typically the Graph U-Net is a node-focused architecture where graph embedding depends mainly on node attributes, we propose a graph-focused architecture where the node feature embedding is based on the graph topology. Second, inspired by graph spectral theory, we break the symmetry of the U-Net architecture by super-resolving the low-resolution brain graph structure and node content with a GSR layer and two graph convolutional network layers to further learn the node embeddings in the HR graph. Third, to handle the domain shift between the ground-truth and the predicted HR brain graphs, we incorporate adversarial regularization to align their respective distributions. Our proposed AGSR-Net framework outperformed its variants for predicting high-resolution functional brain graphs from low-resolution ones. Our AGSR-Net code is available on GitHub at <a class="link-external link-https" href="https://github.com/basiralab/AGSR-Net" rel="external noopener nofollow">this https URL</a>.      
### 27.AG-CUResNeSt: A Novel Method for Colon Polyp Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00402.pdf)
>  Colorectal cancer is among the most common malignancies and can develop from high-risk colon polyps. Colonoscopy is an effective screening tool to detect and remove polyps, especially in the case of precancerous lesions. However, the missing rate in clinical practice is relatively high due to many factors. The procedure could benefit greatly from automatic polyp segmentation models, which provide valuable insights for colon polyp detection improvement. However, precise segmentation is still challenging due to the variation of polyps in size, shape, texture, and color. This paper proposes a novel neural network architecture called AG-CUResNeSt, which enhances Coupled UNets using the robust ResNeSt backbone and attention gates. The network is capable of effectively combining multi-level features to yield accurate polyp segmentation. Experimental results on five popular benchmark datasets show that our proposed method achieves state-of-the-art accuracy compared to existing methods.      
### 28.Simulations for Stochastic Geometry on the Performance of V2X Communications in Rural Macrocell Environment  [ :arrow_down: ](https://arxiv.org/pdf/2105.00366.pdf)
>  Vehicle-to-everything (V2X) communications is a concept that has been around for the past decade. It involves communication between vehicles and other types of infrastructure. This application is exceptionally useful for emergency services such as ambulances, fire trucks etc. This is because an emergency vehicle can communicate with the traffic light infrastructure and make it give the green signal thereby allowing vehicle to pass quickly. This is useful because it alerts other cars and pedestrians on the road when an emergency vehicle is present. In this paper, a V2X communications system in an urban setting will be simulated using MATLAB and the Automated Driving Toolbox. The purpose of simulation in MATLAB is to test if vehicle to vehicle communication is affected by buildings and other infrastructure. The first Simulation is constructed using the Automated driving simulator. In this simulation clover highway is constructed and cars are added to mimic a busy highway. The second simulation involves several nodes being programmed in MATLAB and intersecting at various points to simulate an overpass highway. The end goal of this project to successfully simulate a V2X communications system with additional components added within the program to represent additional cars and infrastructure.      
### 29.Load Oscillating Attacks of Smart Grids: Demand Strategies and Vulnerability Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2105.00350.pdf)
>  We investigate the vulnerability of a power transmission grid to load oscillation attacks. We demonstrate that an adversary with a relatively small amount of resources can launch a successful load oscillation attack to destabilize the grid. The adversary is assumed to be able to compromise smart meters at a subset of load buses and control their switches. In the studied attack scenarios the adversary estimates the line flow sensitivity factors (LFSFs) associated with the monitored tie lines by perturbing a small amount of load at compromised buses and observing the monitored lines flow changes. The learned LFSF values are used for selecting a target line and optimizing the oscillation attack to cause the target line to trip while minimizing the magnitude of load oscillation. We evaluated the attack impact using the COSMIC time-domain simulator with two test cases, the IEEE RTS 96 and Polish 2383-Bus Systems. The proposed attack strategy succeeded in causing 33% of load to be shed while oscillating only 7% of load in the IEEE RTS 96 test system, and full blackout after oscillating only 3% of the load in the Polish test system, which is much smaller than oscillation magnitudes used by other benchmarks.      
### 30.Machine Learning-based Reconfigurable Intelligent Surface-aided MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.00347.pdf)
>  Reconfigurable intelligent surface (RIS) technology has recently emerged as a spectral- and cost-efficient approach for wireless communications systems. However, existing hand-engineered schemes for passive beamforming design and optimization of RIS, such as the alternating optimization (AO) approaches, require a high computational complexity, especially for multiple-input-multiple-output (MIMO) systems. To overcome this challenge, we propose a low-complexity unsupervised learning scheme, referred to as learning-phase-shift neural network (LPSNet), to efficiently find the solution to the spectral efficiency maximization problem in RIS-aided MIMO systems. In particular, the proposed LPSNet has an optimized input structure and requires a small number of layers and nodes to produce efficient phase shifts for the RIS. Simulation results for a 16x2 MIMO system assisted by an RIS with 40 elements show that the LPSNet achieves 97.25% of the SE provided by the AO counterpart with more than a 95% reduction in complexity.      
### 31.Spectral Efficiency Optimization for Hybrid Relay-Reflecting Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2105.00345.pdf)
>  We propose a novel concept of hybrid relay-reflecting intelligent surface (HR-RIS), in which a single or few elements are deployed with power amplifiers (PAs) to serve as active relays, while the remaining elements only reflect the incident signals. The design and optimization of the HR-RIS is formulated in a spectral efficiency (SE) maximization problem, which is efficiently solved by the alternating optimization (AO) method. The simulation results show that a significant improvement in the SE can be attained by the proposed HR-RIS, even with a limited power budget, with respect to the conventional reconfigurable intelligent surface (RIS). In particular, the favorable design and deployment of the HR-RIS are analytically derived and numerically justified.      
### 32.Backhaul-Aware Intelligent Positioning of UAVs and Association of Terrestrial Base Stations for Fronthaul Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2105.00286.pdf)
>  The mushroom growth of cellular users requires novel advancements in the existing cellular infrastructure. One way to handle such a tremendous increase is to densely deploy terrestrial small-cell base stations (TSBSs) with careful management of smart backhaul/fronthaul networks. Nevertheless, terrestrial backhaul hubs significantly suffer from the dense fading environment and are difficult to install in a typical urban environment. Therefore, this paper considers the idea of replacing terrestrial backhaul network with an aerial network consisting of unmanned aerial vehicles (UAVs) to provide the fronthaul connectivity between the TSBSs and the ground core-network (GCN). To this end, we focus on the joint positioning of UAVs and the association of TSBSs such that the sum-rate of the overall system is maximized. In particular, the association problem of TSBSs with UAVs is formulated under communication-related constraints, i.e., bandwidth, number of connections to a UAV, power limit, interference threshold, UAV heights, and backhaul data rate. To meet this joint objective, we take advantage of the genetic algorithm (GA) due to the offline nature of our optimization problem. The performance of the proposed approach is evaluated using the unsupervised learning-based k-means clustering algorithm. We observe that the proposed approach is highly effective to satisfy the requirements of smart fronthaul networks.      
### 33.Systematic Categorization of Influencing Factors on Radar-Based Perception to Facilitate Complex Real-World Data Evaluation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00279.pdf)
>  For the assessment of machine perception for automated driving it is important to understand the influence of certain environment factors on the sensors used. Especially when investigating large amounts of real-world data to find and understand perception uncertainties, a smart concept is needed to structure and categorize such complex data depending on the level of detail desired for the investigation. Information on performance limitation causes can support realistic sensor modeling, help determining scenarios containing shortcomings of sensors and above all is essential to reach perception safety. The paper at hand looks into influencing factors on radar sensors. It utilizes the fact that radar sensors have been used in vehicles for several decades already. Therefore, previous findings on influencing factors can be used as a starting point when assessing radar-based perception for driver assistance systems and automated driving functions. On top of the literature review on environment factors influencing radar sensors, the paper introduces a modular structuring concept for such that can facilitate real-world data analysis by categorizing the factors possibly leading to performance limitations into different independent clusters in order to reduce the level of detail in complex real-world environments.      
### 34.Blind microscopy image denoising with a deep residual and multiscale encoder/decoder network  [ :arrow_down: ](https://arxiv.org/pdf/2105.00273.pdf)
>  In computer-aided diagnosis (CAD) focused on microscopy, denoising improves the quality of image analysis. In general, the accuracy of this process may depend both on the experience of the microscopist and on the equipment sensitivity and specificity. A medical image could be corrupted by both intrinsic noise, due to the device limitations, and, by extrinsic signal perturbations during image acquisition. Nowadays, CAD deep learning applications pre-process images with image denoising models to reinforce learning and prediction. In this work, an innovative and lightweight deep multiscale convolutional encoder-decoder neural network is proposed. Specifically, the encoder uses deterministic mapping to map features into a hidden representation. Then, the latent representation is rebuilt to generate the reconstructed denoised image. Residual learning strategies are used to improve and accelerate the training process using skip connections in bridging across convolutional and deconvolutional layers. The proposed model reaches on average 38.38 of PSNR and 0.98 of SSIM on a test set of 57458 images overcoming state-of-the-art models in the same application domain      
### 35.COVID-Net CXR-S: Deep Convolutional Neural Network for Severity Assessment of COVID-19 Cases from Chest X-ray Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.00256.pdf)
>  The world is still struggling in controlling and containing the spread of the COVID-19 pandemic caused by the SARS-CoV-2 virus. The medical conditions associated with SARS-CoV-2 infections have resulted in a surge in the number of patients at clinics and hospitals, leading to a significantly increased strain on healthcare resources. As such, an important part of managing and handling patients with SARS-CoV-2 infections within the clinical workflow is severity assessment, which is often conducted with the use of chest x-ray (CXR) images. In this work, we introduce COVID-Net CXR-S, a convolutional neural network for predicting the airspace severity of a SARS-CoV-2 positive patient based on a CXR image of the patient's chest. More specifically, we leveraged transfer learning to transfer representational knowledge gained from over 16,000 CXR images from a multinational cohort of over 15,000 patient cases into a custom network architecture for severity assessment. Experimental results with a multi-national patient cohort curated by the Radiological Society of North America (RSNA) RICORD initiative showed that the proposed COVID-Net CXR-S has potential to be a powerful tool for computer-aided severity assessment of CXR images of COVID-19 positive patients. Furthermore, radiologist validation on select cases by two board-certified radiologists with over 10 and 19 years of experience, respectively, showed consistency between radiologist interpretation and critical factors leveraged by COVID-Net CXR-S for severity assessment. While not a production-ready solution, the ultimate goal for the open source release of COVID-Net CXR-S is to act as a catalyst for clinical scientists, machine learning researchers, as well as citizen scientists to develop innovative new clinical decision support solutions for helping clinicians around the world manage the continuing pandemic.      
### 36.Online and Adaptive Parking Availability Mapping: An Uncertainty-Aware Active Sensing Approach for Connected Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2105.00246.pdf)
>  Research on connected vehicles represents a continuously evolving technological domain, fostered by the emerging Internet of Things (IoT) paradigm and the recent advances in intelligent transportation systems. Nowadays, vehicles are platforms capable of generating, receiving and automatically act based on large amount of data. In the context of assisted driving, connected vehicle technology provides real-time information about the surrounding traffic conditions. Such information is expected to improve drivers' quality of life, for example, by adopting decision making strategies according to the current parking availability status. In this context, we propose an online and adaptive scheme for parking availability mapping. Specifically, we adopt an information-seeking active sensing approach to select the incoming data, thus preserving the onboard storage and processing resources; then, we estimate the parking availability through Gaussian Process Regression. We compare the proposed algorithm with several baselines, which attain inferior performance in terms of mapping convergence speed and adaptivity capabilities; moreover, the proposed approach comes at the cost of a very small computational demand.      
### 37.Simultaneous super-resolution and motion artifact removal in diffusion-weighted MRI using unsupervised deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.00240.pdf)
>  Diffusion-weighted MRI is nowadays performed routinely due to its prognostic ability, yet the quality of the scans are often unsatisfactory which can subsequently hamper the clinical utility. To overcome the limitations, here we propose a fully unsupervised quality enhancement scheme, which boosts the resolution and removes the motion artifact simultaneously. This process is done by first training the network using optimal transport driven cycleGAN with stochastic degradation block which learns to remove aliasing artifacts and enhance the resolution, then using the trained network in the test stage by utilizing bootstrap subsampling and aggregation for motion artifact suppression. We further show that we can control the trade-off between the amount of artifact correction and resolution by controlling the bootstrap subsampling ratio at the inference stage. To the best of our knowledge, the proposed method is the first to tackle super-resolution and motion artifact correction simultaneously in the context of MRI using unsupervised learning. We demonstrate the efficiency of our method by applying it to both quantitative evaluation using simulation study, and to in vivo diffusion-weighted MR scans, which shows that our method is superior to the current state-of-the-art methods. The proposed method is flexible in that it can be applied to various quality enhancement schemes in other types of MR scans, and also directly to the quality enhancement of apparent diffusion coefficient maps.      
### 38.Inversion-free feedforward hysteresis control using Preisach operator  [ :arrow_down: ](https://arxiv.org/pdf/2105.00236.pdf)
>  We introduce a new type of inversion-free feedforward hysteresis control with the Preisach operator. The feedforward control has a high-gain integral loop structure with the Preisach operator in negative feedback. This allows obtaining a dynamic quantity which corresponds to the inverse hysteresis output, since the loop error tends towards zero for a sufficiently high feedback gain. By analyzing the loop sensitivity function with hysteresis, which acts as a non-constant phase lag, we show the achievable bandwidth and accuracy of the proposed control. Remarkable fact is that the control bandwidth is theoretically infinite, provided the integral feedback loop with Preisach operator can be implemented with a smooth hysteresis output. Numerical control examples with the Preisach hysteresis model in differential form are shown and discussed in detail.      
### 39.JAS-GAN: Generative Adversarial Network Based Joint Atrium and Scar Segmentations on Unbalanced Atrial Targets  [ :arrow_down: ](https://arxiv.org/pdf/2105.00234.pdf)
>  Automated and accurate segmentations of left atrium (LA) and atrial scars from late gadolinium-enhanced cardiac magnetic resonance (LGE CMR) images are in high demand for quantifying atrial scars. The previous quantification of atrial scars relies on a two-phase segmentation for LA and atrial scars due to their large volume difference (unbalanced atrial targets). In this paper, we propose an inter-cascade generative adversarial network, namely JAS-GAN, to segment the unbalanced atrial targets from LGE CMR images automatically and accurately in an end-to-end way. Firstly, JAS-GAN investigates an adaptive attention cascade to automatically correlate the segmentation tasks of the unbalanced atrial targets. The adaptive attention cascade mainly models the inclusion relationship of the two unbalanced atrial targets, where the estimated LA acts as the attention map to adaptively focus on the small atrial scars roughly. Then, an adversarial regularization is applied to the segmentation tasks of the unbalanced atrial targets for making a consistent optimization. It mainly forces the estimated joint distribution of LA and atrial scars to match the real ones. We evaluated the performance of our JAS-GAN on a 3D LGE CMR dataset with 192 scans. Compared with the state-of-the-art methods, our proposed approach yielded better segmentation performance (Average Dice Similarity Coefficient (DSC) values of 0.946 and 0.821 for LA and atrial scars, respectively), which indicated the effectiveness of our proposed approach for segmenting unbalanced atrial targets.      
### 40.Application of Deep Convolutional Neural Networks for automated and rapid identification and characterization of thin cracks in SHCCs  [ :arrow_down: ](https://arxiv.org/pdf/2105.00230.pdf)
>  Previous research has showcased that the characterization of surface cracks is one of the key steps towards understanding the durability of strain hardening cementitious composites (SHCCs). Under laboratory conditions, surface crack statistics can be obtained from images of specimen surfaces through manual inspection or image processing techniques. Since these techniques require optimal lighting conditions, proper surface treatment, and prior (manual) selection of the correct region for proper inference, they are strenuous and time-consuming. Through this work, we explored and tailored deep convolutional networks (DCCNs) for the rapid characterization of cracks in SHCC from various kinds of photographs. The results from the controlled study suggest that the inference ability of the tailored DCCN (TDCNN) is quite good, resilient against epistemic uncertainty, and tunable for completely independent but adverse observations. From the crack pattern computed using TDCCN, average crack width (ACW) and crack density (CD) can be calculated to facilitate durability design and conditional assessment in a practical environment.      
### 41.Deep Spectrum Cartography: Completing Radio Map Tensors Using Learned Neural Models  [ :arrow_down: ](https://arxiv.org/pdf/2105.00177.pdf)
>  The spectrum cartography (SC) technique constructs multi-domain (e.g., frequency, space, and time) radio frequency (RF) maps from limited measurements, which can be viewed as an ill-posed tensor completion problem. Model-based cartography techniques often rely on handcrafted priors (e.g., sparsity, smoothness and low-rank structures) for the completion task. Such priors may be inadequate to capture the essence of complex wireless environments -- especially when severe shadowing happens. To circumvent such challenges, offline-trained deep neural models of radio maps were considered for SC, as deep neural networks (DNNs) are able to "learn" intricate underlying structures from data. However, such deep learning (DL)-based SC approaches encounter serious challenges in both off-line model learning (training) and completion (generalization), possibly because the latent state space for generating the radio maps is prohibitively large. In this work, an emitter radio map disaggregation-based approach is proposed, under which only individual emitters' radio maps are modeled by DNNs. This way, the learning and generalization challenges can both be substantially alleviated. Using the learned DNNs, a fast nonnegative matrix factorization-based two-stage SC method and a performance-enhanced iterative optimization algorithm are proposed. Theoretical aspects -- such as recoverability of the radio tensor, sample complexity, and noise robustness -- under the proposed framework are characterized, and such theoretical properties have been elusive in the context of DL-based radio tensor completion. Experiments using synthetic and real-data from indoor and heavily shadowed environments are employed to showcase the effectiveness of the proposed methods.      
### 42.Distributed Energy Trading Management for Renewable Prosumers with HVAC and Energy Storage  [ :arrow_down: ](https://arxiv.org/pdf/2105.00175.pdf)
>  Heating, ventilating, and air-conditioning (HVAC) systems consume a large amount of energy in residential houses and buildings. Effective energy management of HVAC is a cost-effective way to improve energy efficiency and reduce the energy cost of residential users. This work develops a novel distributed method for the residential transactive energy system that enables multiple users to interactively optimize their energy management of HVAC systems and behind-the-meter batteries. Specifically, this method effectively reduces the cost of smart homes by employing energy trading among users to leverage their power usage flexibility without compromising the users' privacy. To achieve this goal, we design a distributed optimization algorithm based on the alternating direction method of multipliers (ADMM) to automatically operate the HVAC system and batteries, which minimizes the energy costs of users. Specifically, we decouple the optimization problem into a primal subproblem and a dual subproblem. The primal subproblem is solved by the users, and the dual subproblem is solved by the grid operator. Unlike the existing centralized method, our approach only uses the users' private information locally for solving the primal subproblem hence preserves the users' privacy. Using real-world data, we validate our proposed algorithm through extensive simulations in Matlab. The results demonstrate that our method effectively incentivizes the energy trading among the users to reduce users' peak load and reduce the overall energy cost of the system by 23% on average.      
### 43.Blockchain-Based Decentralized Energy Management Platform for Residential Distributed Energy Resources in A Virtual Power Plant  [ :arrow_down: ](https://arxiv.org/pdf/2105.00174.pdf)
>  The advent of distributed energy resources (DERs), such as distributed renewables, energy storage, electric vehicles, and controllable loads, \rv{brings} a significantly disruptive and transformational impact on the centralized power system. It is widely accepted that a paradigm shift to a decentralized power system with bidirectional power flow is necessary to the integration of DERs. The virtual power plant (VPP) emerges as a promising paradigm for managing DERs to participate in the power system. In this paper, we develop a blockchain-based VPP energy management platform to facilitate a rich set of transactive energy activities among residential users with renewables, energy storage, and flexible loads in a VPP. Specifically, users can interact with each other to trade energy for mutual benefits and provide network services, such as feed-in energy, reserve, and demand response, through the VPP. To respect the users' independence and preserve their privacy, we design a decentralized optimization algorithm to optimize the users' energy scheduling, energy trading, and network services. Then we develop a prototype blockchain network for VPP energy management and implement the proposed algorithm on the blockchain network. By experiments using real-world data-trace, we validated the feasibility and effectiveness of our algorithm and the blockchain system. The simulation results demonstrate that our blockchain-based VPP energy management platform reduces the users' cost by up to 38.6% and reduces the overall system cost by 11.2%.      
### 44.PER Measurement of BLE in RF Interference and Harsh Electromagnetic Environment  [ :arrow_down: ](https://arxiv.org/pdf/2105.00141.pdf)
>  Bluetooth Low Energy (BLE) is a short-range data transmission technology that is used for multimedia file sharing, home automation, and internet-of-things application. In this work, we perform packet error rate (PER) measurement and RF testing of BLE receiver in the harsh electromagnetic environment and in presence of RF interference. We check the PER performance in the line-of-sight (LOS) and non-line-of-sight (NLOS) scenario in absence of any interfering signal and in presence of wideband WLAN interference. The BLE PER measurements are conducted in a large reverberation chamber which is a rich scattering environment. Software-defined-radio has been used to create BLE communication link for PER measurement in LOS and NLOS configuration. The BLE PER is measured both in the presence and in absence of WLAN interference. Our measurement results show a higher PER for uncoded BLE PHY modes in NLOS channel condition and in presence of wideband interference. Whereas coded BLE PHY modes i.e. LE500K and LE125K are robust to interference with lower PER measurements.      
### 45.On the Efficient Implementation of an Implicit Discrete-Time Differentiator  [ :arrow_down: ](https://arxiv.org/pdf/2105.00126.pdf)
>  New methodologies are designed to reduce the time complexity of an implicit discrete-time differentiator and the simulation time to implement it. They rely on Horner's method and the Shaw-Traub algorithm. The algorithms are compared for differentiators of orders 3, 7, and 10. The Half-Horner and Full-Horner methods showed the best performance and time complexity.      
### 46.SUPERB: Speech processing Universal PERformance Benchmark  [ :arrow_down: ](https://arxiv.org/pdf/2105.01051.pdf)
>  Self-supervised learning (SSL) has proven vital for advancing research in natural language processing (NLP) and computer vision (CV). The paradigm pretrains a shared model on large volumes of unlabeled data and achieves state-of-the-art (SOTA) for various tasks with minimal adaptation. However, the speech processing community lacks a similar setup to systematically explore the paradigm. To bridge this gap, we introduce Speech processing Universal PERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the performance of a shared model across a wide range of speech processing tasks with minimal architecture changes and labeled data. Among multiple usages of the shared model, we especially focus on extracting the representation learned from SSL due to its preferable re-usability. We present a simple framework to solve SUPERB tasks by learning task-specialized lightweight prediction heads on top of the frozen shared model. Our results demonstrate that the framework is promising as SSL representations show competitive generalizability and accessibility across SUPERB tasks. We release SUPERB as a challenge with a leaderboard and a benchmark toolkit to fuel the research in representation learning and general speech processing.      
### 47.On the Stability of Multilinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.01041.pdf)
>  In this letter, we investigate the stability properties of a discrete-time multilinear system. We establish theoretical results on the criteria for determining the internal stability of multilinear systems via tensor spectral theory. In particular, we show that the Z-eigenvalues of the dynamic tensor play a significant role in the stability analysis. We also explore the Lyapunov stability of multilinear systems. Finally, we demonstrate our results with numerical examples.      
### 48.Robust Learning of Recurrent Neural Networks in Presence of Exogenous Noise  [ :arrow_down: ](https://arxiv.org/pdf/2105.00996.pdf)
>  Recurrent Neural networks (RNN) have shown promising potential for learning dynamics of sequential data. However, artificial neural networks are known to exhibit poor robustness in presence of input noise, where the sequential architecture of RNNs exacerbates the problem. In this paper, we will use ideas from control and estimation theories to propose a tractable robustness analysis for RNN models that are subject to input noise. The variance of the output of the noisy system is adopted as a robustness measure to quantify the impact of noise on learning. It is shown that the robustness measure can be estimated efficiently using linearization techniques. Using these results, we proposed a learning method to enhance robustness of a RNN with respect to exogenous Gaussian noise with known statistics. Our extensive simulations on benchmark problems reveal that our proposed methodology significantly improves robustness of recurrent neural networks.      
### 49.Reachability Map for Diverse Balancing Strategies and Energy Efficient Stepping of Humanoids  [ :arrow_down: ](https://arxiv.org/pdf/2105.00995.pdf)
>  In legged locomotion, the relationship between different gait behaviors and energy consumption must consider the full-body dynamics and the robot control as a whole, which cannot be captured by simple models. This work studies the robot dynamics and whole-body optimal control as a coupled system to investigate energy consumption during balance recovery. We developed a 2-phase nonlinear optimization pipeline for dynamic stepping, which generates reachability maps showing complex energy-stepping relations. We optimize gait parameters to search all reachable locations and quantify the energy cost during dynamic transitions, which allows studying the relationship between energy consumption and stepping locations given different initial conditions. We found that to achieve efficient actuation, the stepping location and timing can have simple approximations close to the underlying optimality. Despite the complexity of this nonlinear process, we show that near-minimal effort stepping locations fall within a region of attractions, rather than a narrow solution space suggested by a simple model. This provides new insights into the non-uniqueness of near-optimal solutions in robot motion planning and control, and the diversity of stepping behavior in humans.      
### 50.On the limit of English conversational speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2105.00982.pdf)
>  In our previous work we demonstrated that a single headed attention encoder-decoder model is able to reach state-of-the-art results in conversational speech recognition. In this paper, we further improve the results for both Switchboard 300 and 2000. Through use of an improved optimizer, speaker vector embeddings, and alternative speech representations we reduce the recognition errors of our LSTM system on Switchboard-300 by 4% relative. Compensation of the decoder model with the probability ratio approach allows more efficient integration of an external language model, and we report 5.9% and 11.5% WER on the SWB and CHM parts of Hub5'00 with very simple LSTM models. Our study also considers the recently proposed conformer, and more advanced self-attention based language models. Overall, the conformer shows similar performance to the LSTM; nevertheless, their combination and decoding with an improved LM reaches a new record on Switchboard-300, 5.0% and 10.0% WER on SWB and CHM. Our findings are also confirmed on Switchboard-2000, and a new state of the art is reported, practically reaching the limit of the benchmark.      
### 51.3-D Deployment of UAV Swarm for Massive MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.00950.pdf)
>  We consider the uplink transmission between a multi-antenna ground station and an unmanned aerial vehicle (UAV) swarm. The UAVs are assumed as intelligent agents, which can explore their optimal three dimensional (3-D) deployment to maximize the channel capacity of the multiple input multiple output (MIMO) system. Specifically, considering the limitations of each UAV in accessing the global information of the network, we focus on a decentralized control strategy by noting that each UAV in the swarm can only utilize the local information to achieve the optimal 3-D deployment. In this case, the optimization problem can be divided into several optimization sub-problems with respect to the rank function. Due to the non-convex nature of the rank function and the fact that the optimization sub-problems are coupled, the original problem is NP-hard and, thus, cannot be solved with standard convex optimization solvers. Interestingly, we can relax the constraint condition of each sub-problem and solve the optimization problem by a formulated UAVs channel capacity maximization game. We analyze such game according to the designed reward function and the potential function. Then, we discuss the existence of the pure Nash equilibrium in the game. To achieve the best Nash equilibrium of the MIMO system, we develop a decentralized learning algorithm, namely decentralized UAVs channel capacity learning. The details of the algorithm are provided, and then, the convergence, the effectiveness and the computational complexity are analyzed, respectively. Moreover, we give some insightful remarks based on the proofs and the theoretical analysis. Also, extensive simulations illustrate that the developed learning algorithm can achieve a high MIMO channel capacity by optimizing the 3-D UAV swarm deployment with the local information.      
### 52.Deep Neural Network for Musical Instrument Recognition using MFCCs  [ :arrow_down: ](https://arxiv.org/pdf/2105.00933.pdf)
>  The task of efficient automatic music classification is of vital importance and forms the basis for various advanced applications of AI in the musical domain. Musical instrument recognition is the task of instrument identification by virtue of its audio. This audio, also termed as the sound vibrations are leveraged by the model to match with the instrument classes. In this paper, we use an artificial neural network (ANN) model that was trained to perform classification on twenty different classes of musical instruments. Here we use use only the mel-frequency cepstral coefficients (MFCCs) of the audio data. Our proposed model trains on the full London philharmonic orchestra dataset which contains twenty classes of instruments belonging to the four families viz. woodwinds, brass, percussion, and strings. Based on experimental results our model achieves state-of-the-art accuracy on the same.      
### 53.Fully Learnable Deep Wavelet Transform for Unsupervised Monitoring of High-Frequency Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2105.00899.pdf)
>  High-Frequency (HF) signal are ubiquitous in the industrial world and are of great use for the monitoring of industrial assets. Most deep learning tools are designed for inputs of fixed and/or very limited size and many successful applications of deep learning to the industrial context use as inputs extracted features, which is a manually and often arduously obtained compact representation of the original signal. In this paper, we propose a fully unsupervised deep learning framework that is able to extract meaningful and sparse representation of raw HF signals. We embed in our architecture important properties of the fast discrete wavelet transformation (FDWT) such as (1) the cascade algorithm, (2) the quadrature mirror filter property that relates together the wavelet, the scaling and transposed filter functions, and (3) the coefficient denoising. Using deep learning, we make this architecture fully learnable: both the wavelet bases and the wavelet coefficient denoising are learnable. To achieve this objective, we introduce a new activation function that performs a learnable hard-thresholding of the wavelet coefficients. With our framework, the denoising FDWT becomes a fully learnable unsupervised tool that does neither require any type of pre- nor post-processing, nor any prior knowledge on wavelet transform. We demonstrate the benefit of embedding all these properties on three machine-learning tasks performed on open source sound datasets. We achieve results well above baseline and we perform an ablation study of the impact of each property on the performance of the architecture.      
### 54.Optimal heating of an indoor swimming pool  [ :arrow_down: ](https://arxiv.org/pdf/2105.00849.pdf)
>  This work presents the derivation of a model for the heating process of the air of a glass dome, where an indoor swimming pool is located in the bottom of the dome. The problem can be reduced from a three dimensional to a two dimensional one. The main goal is the formulation of a proper optimization problem for computing the optimal heating of the air after a given time. For that, the model of the heating process as a partial differential equation is formulated as well as the optimization problem subject to the time-dependent partial differential equation. This yields the optimal heating of the air under the glass dome such that the desired temperature distribution is attained after a given time. The discrete formulation of the optimization problem and a proper numerical method for it, the projected gradient method, are discussed. Finally, numerical experiments are presented which show the practical performance of the optimal control problem and its numerical solution method discussed.      
### 55.Layer Reduction: Accelerating Conformer-Based Self-Supervised Model via Layer Consistency  [ :arrow_down: ](https://arxiv.org/pdf/2105.00812.pdf)
>  Transformer-based self-supervised models are trained as feature extractors and have empowered many downstream speech tasks to achieve state-of-the-art performance. However, both the training and inference process of these models may encounter prohibitively high computational cost and large parameter budget. Although Parameter Sharing Strategy (PSS) proposed in ALBERT paves the way for parameter reduction, the computation required remains the same. Interestingly, we found in experiments that distributions of feature embeddings from different Transformer layers are similar when PSS is integrated: a property termed as Layer Consistency (LC) in this paper. Given this similarity of feature distributions, we assume that feature embeddings from different layers would have similar representing power. In this work, Layer Consistency enables us to adopt Transformer-based models in a more efficient manner: the number of Conformer layers in each training iteration could be uniformly sampled and Shallow Layer Inference (SLI) could be applied to reduce the number of layers in inference stage. In experiments, our models are trained with LibriSpeech dataset and then evaluated on both phone classification and Speech Recognition tasks. We experimentally achieve 7.8X parameter reduction, 41.9% training speedup and 37.7% inference speedup while maintaining comparable performance with conventional BERT-like self-supervised methods.      
### 56.Exploiting Audio-Visual Consistency with Partial Supervision for Spatial Audio Generation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00708.pdf)
>  Human perceives rich auditory experience with distinct sound heard by ears. Videos recorded with binaural audio particular simulate how human receives ambient sound. However, a large number of videos are with monaural audio only, which would degrade the user experience due to the lack of ambient information. To address this issue, we propose an audio spatialization framework to convert a monaural video into a binaural one exploiting the relationship across audio and visual components. By preserving the left-right consistency in both audio and visual modalities, our learning strategy can be viewed as a self-supervised learning technique, and alleviates the dependency on a large amount of video data with ground truth binaural audio data during training. Experiments on benchmark datasets confirm the effectiveness of our proposed framework in both semi-supervised and fully supervised scenarios, with ablation studies and visualization further support the use of our model for audio spatialization.      
### 57.Generalized Spatially Coupled Parallel Concatenated Convolutional Codes With Partial Repetition  [ :arrow_down: ](https://arxiv.org/pdf/2105.00698.pdf)
>  We introduce generalized spatially coupled parallel concatenated codes (GSC-PCCs), a class of spatially coupled turbo-like codes obtained by coupling parallel concatenated codes (PCCs) with a fraction of information bits repeated before the PCC encoding. GSC-PCCs can be seen as a generalization of the original spatially coupled parallel concatenated convolutional codes (SC-PCCs) proposed by Moloudi et al. [1]. To characterize the asymptotic performance of GSC-PCCs, we derive the corresponding density evolution equations and compute their decoding thresholds. We show that the proposed codes have some nice properties such as threshold saturation and that their decoding thresholds improve with the repetition factor $q$. Most notably, our analysis suggests that the proposed codes asymptotically approach the capacity as $q$ tends to infinity with any given constituent convolutional code.      
### 58.Distributionally robust risk map for learning-based motion planning and control: A semidefinite programming approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.00657.pdf)
>  This paper proposes a novel safety specification tool, called the distributionally robust risk map (DR-risk map), for a mobile robot operating in a learning-enabled environment. Given the robot's position, the map aims to reliably assess the conditional value-at-risk (CVaR) of collision with obstacles whose movements are inferred by Gaussian process regression (GPR). Unfortunately, the inferred distribution is subject to errors, making it difficult to accurately evaluate the CVaR of collision. To overcome this challenge, this tool measures the risk under the worst-case distribution in a so-called ambiguity set that characterizes allowable distribution errors. To resolve the infinite-dimensionality issue inherent in the construction of the DR-risk map, we derive a tractable semidefinite programming formulation that provides an upper bound of the risk, exploiting techniques from modern distributionally robust optimization. As a concrete application for motion planning, a distributionally robust RRT* algorithm is considered using the risk map that addresses distribution errors caused by GPR. Furthermore, a motion control method is devised using the DR-risk map in a learning-based model predictive control (MPC) formulation. In particular, a neural network approximation of the risk map is proposed to reduce the computational cost in solving the MPC problem. The performance and utility of the proposed risk map are demonstrated through simulation studies that show its ability to ensure the safety of mobile robots despite learning errors.      
### 59.Naturalistic audio-visual volumetric sequences dataset of sounding actions for six degree-of-freedom interaction  [ :arrow_down: ](https://arxiv.org/pdf/2105.00641.pdf)
>  As audio-visual systems increasingly bring immersive and interactive capabilities into our work and leisure activities, so the need for naturalistic test material grows. New volumetric datasets have captured high-quality 3D video, but accompanying audio is often neglected, making it hard to test an integrated bimodal experience. Designed to cover diverse sound types and features, the presented volumetric dataset was constructed from audio and video studio recordings of scenes to yield forty short action sequences. Potential uses in technical and scientific tests are discussed.      
### 60.AvaTr: One-Shot Speaker Extraction with Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2105.00609.pdf)
>  To extract the voice of a target speaker when mixed with a variety of other sounds, such as white and ambient noises or the voices of interfering speakers, we extend the Transformer network to attend the most relevant information with respect to the target speaker given the characteristics of his or her voices as a form of contextual information. The idea has a natural interpretation in terms of the selective attention theory. Specifically, we propose two models to incorporate the voice characteristics in Transformer based on different insights of where the feature selection should take place. Both models yield excellent performance, on par or better than published state-of-the-art models on the speaker extraction task, including separating speech of novel speakers not seen during training.      
### 61.An End-to-End and Accurate PPG-based Respiratory Rate Estimation Approach Using Cycle Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00594.pdf)
>  Respiratory rate (RR) is a clinical sign representing ventilation. An abnormal change in RR is often the first sign of health deterioration as the body attempts to maintain oxygen delivery to its tissues. There has been a growing interest in remotely monitoring of RR in everyday settings which has made photoplethysmography (PPG) monitoring wearable devices an attractive choice. PPG signals are useful sources for RR extraction due to the presence of respiration-induced modulations in them. The existing PPG-based RR estimation methods mainly rely on hand-crafted rules and manual parameters tuning. An end-to-end deep learning approach was recently proposed, however, despite its automatic nature, the performance of this method is not ideal using the real world data. In this paper, we present an end-to-end and accurate pipeline for RR estimation using Cycle Generative Adversarial Networks (CycleGAN) to reconstruct respiratory signals from raw PPG signals. Our results demonstrate a higher RR estimation accuracy of up to 2$\times$ (mean absolute error of 1.9$\pm$0.3 using five fold cross validation) compared to the state-of-th-art using a identical publicly available dataset. Our results suggest that CycleGAN can be a valuable method for RR estimation from raw PPG signals.      
### 62.Learning Visually Guided Latent Actions for Assistive Teleoperation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00580.pdf)
>  It is challenging for humans -- particularly those living with physical disabilities -- to control high-dimensional, dexterous robots. Prior work explores learning embedding functions that map a human's low-dimensional inputs (e.g., via a joystick) to complex, high-dimensional robot actions for assistive teleoperation; however, a central problem is that there are many more high-dimensional actions than available low-dimensional inputs. To extract the correct action and maximally assist their human controller, robots must reason over their context: for example, pressing a joystick down when interacting with a coffee cup indicates a different action than when interacting with knife. In this work, we develop assistive robots that condition their latent embeddings on visual inputs. We explore a spectrum of visual encoders and show that incorporating object detectors pretrained on small amounts of cheap, easy-to-collect structured data enables i) accurately and robustly recognizing the current context and ii) generalizing control embeddings to new objects and tasks. In user studies with a high-dimensional physical robot arm, participants leverage this approach to perform new tasks with unseen objects. Our results indicate that structured visual representations improve few-shot performance and are subjectively preferred by users.      
### 63.Searchable Hidden Intermediates for End-to-End Models of Decomposable Sequence Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00573.pdf)
>  End-to-end approaches for sequence tasks are becoming increasingly popular. Yet for complex sequence tasks, like speech translation, systems that cascade several models trained on sub-tasks have shown to be superior, suggesting that the compositionality of cascaded systems simplifies learning and enables sophisticated search capabilities. In this work, we present an end-to-end framework that exploits compositionality to learn searchable hidden representations at intermediate stages of a sequence model using decomposed sub-tasks. These hidden intermediates can be improved using beam search to enhance the overall performance and can also incorporate external models at intermediate stages of the network to re-score or adapt towards out-of-domain data. One instance of the proposed framework is a Multi-Decoder model for speech translation that extracts the searchable hidden intermediates from a speech recognition sub-task. The model demonstrates the aforementioned benefits and outperforms the previous state-of-the-art by around +6 and +3 BLEU on the two test sets of Fisher-CallHome and by around +3 and +4 BLEU on the English-German and English-French test sets of MuST-C.      
### 64.MagSurface: Wireless 2D Finger Tracking Leveraging Magnetic Fields  [ :arrow_down: ](https://arxiv.org/pdf/2105.00543.pdf)
>  With the ubiquity of touchscreens, touch input modality has become a popular way of interaction. However, current touchscreen technology is limiting in its design as it restricts touch interactions to specially instrumented touch surfaces. Surface contaminants like water can also hinder proper interactions. In this paper, we propose the use of magnetic field sensing to enable finger tracking on a surface with minimal instrumentation. Our system, MagSurface, turns everyday surfaces into a touch medium, thus allowing more flexibility in the types of touch surfaces. The evaluation of our system consists of quantifying the accuracy of the system in locating an object on 2D flat surfaces. We test our system on three different surface materials to validate its usage scenarios. A qualitative user experience study was also conducted to get feedback on the ease of use and comfort of the system. Localization error as low as a few millimeters was achieved      
### 65.A 1D-CNN Based Deep Learning Technique for Sleep Apnea Detection in IoT Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2105.00528.pdf)
>  Internet of Things (IoT) enabled wearable sensors for health monitoring are widely used to reduce the cost of personal healthcare and improve quality of life. The sleep apnea-hypopnea syndrome, characterized by the abnormal reduction or pause in breathing, greatly affects the quality of sleep of an individual. This paper introduces a novel method for apnea detection (pause in breathing) from electrocardiogram (ECG) signals obtained from wearable devices. The novelty stems from the high resolution of apnea detection on a second-by-second basis, and this is achieved using a 1-dimensional convolutional neural network for feature extraction and detection of sleep apnea events. The proposed method exhibits an accuracy of 99.56% and a sensitivity of 96.05%. This model outperforms several lower resolution state-of-the-art apnea detection methods. The complexity of the proposed model is analyzed. We also analyze the feasibility of model pruning and binarization to reduce the resource requirements on a wearable IoT device. The pruned model with 80\% sparsity exhibited an accuracy of 97.34% and a sensitivity of 86.48%. The binarized model exhibited an accuracy of 75.59% and sensitivity of 63.23%. The performance of low complexity patient-specific models derived from the generic model is also studied to analyze the feasibility of retraining existing models to fit patient-specific requirements. The patient-specific models on average exhibited an accuracy of 97.79% and sensitivity of 92.23%. The source code for this work is made publicly available.      
### 66.Multi-Level Over-the-Air Aggregation of Mobile Edge Computing over D2D Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00471.pdf)
>  In this paper, we consider a wireless multihop device-to-device (D2D) based mobile edge computing (MEC) system, where the destination wireless device (WD) is scheduled to compute nomographic functions. Under the MapReduce framework and motivated by reducing communication resource overhead, we propose a new multi-level over-the-air (OTA) aggregation scheme for the destination WD to collect the individual partially aggregated intermediate values (IVAs) for reduction from multiple source WDs in the data shuffling phase. For OTA aggregation per level, the source WDs employ a channel inverse structure multiplied by their individual transmit coefficients in transmission over the same time frequency resource blocks, and the destination WD finally uses a receive filtering factor to construct the aggregated IVA. Under this setup, we develop a unified transceiver design framework that minimizes the mean squared error (MSE) of the aggregated IVA at the destination WD subject to the source WDs' individual power constraints, by jointly optimizing the source WDs' individual transmit coefficients and the destination WD's receive filtering factor. First, based on the primal decomposition method, we derive the closed-form solution under the special case of a common transmit coefficient. It shows that all the source WDs' common transmit is determined by the minimal transmit power budget among the source WDs. Next, for the general case, we transform the original problem into a quadratic fractional programming problem, and then develop a low-complexity algorithm to obtain the (near-) optimal solution by leveraging Dinkelbach's algorithm along with the Gaussian randomization method.      
### 67.Fast Power Control Adaptation via Meta-Learning for Random Edge Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00459.pdf)
>  Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.      
### 68.Dynamic Routing for Traffic Flow through Multi-agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.00434.pdf)
>  Routing strategies for traffics and vehicles have been historically studied. However, in the absence of considering drivers' preferences, current route planning algorithms are developed under ideal situations where all drivers are expected to behave rationally and properly. Especially, for jumbled urban road networks, drivers' actual routing strategies deteriorated to a series of empirical and selfish decisions that result in congestion. Self-evidently, if minimum mobility can be kept, traffic congestion is avoidable by traffic load dispersing. In this paper, we establish a novel dynamic routing method catering drivers' preferences and retaining maximum traffic mobility simultaneously through multi-agent systems (MAS). Modeling human-drivers' behavior through agents' dynamics, MAS can analyze the global behavior of the entire traffic flow. Therefore, regarding agents as particles in smoothed particles hydrodynamics (SPH), we can enforce the traffic flow to behave like a real flow. Thereby, with the characteristic of distributing itself uniformly in road networks, our dynamic routing method realizes traffic load balancing without violating the individual time-saving motivation. Moreover, as a discrete control mechanism, our method is robust to chaos meaning driver's disobedience can be tolerated. As controlled by SPH based density, the only intelligent transportation system (ITS) we require is the location-based service (LBS). A mathematical proof is accomplished to scrutinize the stability of the proposed control law. Also, multiple testing cases are built to verify the effectiveness of the proposed dynamic routing algorithm.      
### 69.Learning data association without data association: An EM approach to neural assignment prediction  [ :arrow_down: ](https://arxiv.org/pdf/2105.00369.pdf)
>  Data association is a fundamental component of effective multi-object tracking. Current approaches to data-association tend to frame this as an assignment problem relying on gating and distance-based cost matrices, or offset the challenge of data association to a problem of tracking by detection. The latter is typically formulated as a supervised learning problem, and requires labelling information about tracked object identities to train a model for object recognition. This paper introduces an expectation maximisation approach to train neural models for data association, which does not require labelling information. Here, a Sinkhorn network is trained to predict assignment matrices that maximise the marginal likelihood of trajectory observations. Importantly, networks trained using the proposed approach can be re-used in downstream tracking applications.      
### 70.RADDet: Range-Azimuth-Doppler based Radar Object Detection for Dynamic Road Users  [ :arrow_down: ](https://arxiv.org/pdf/2105.00363.pdf)
>  Object detection using automotive radars has not been explored with deep learning models in comparison to the camera based approaches. This can be attributed to the lack of public radar datasets. In this paper, we collect a novel radar dataset that contains radar data in the form of Range-Azimuth-Doppler tensors along with the bounding boxes on the tensor for dynamic road users, category labels, and 2D bounding boxes on the Cartesian Bird-Eye-View range map. To build the dataset, we propose an instance-wise auto-annotation method. Furthermore, a novel Range-Azimuth-Doppler based multi-class object detection deep learning model is proposed. The algorithm is a one-stage anchor-based detector that generates both 3D bounding boxes and 2D bounding boxes on Range-Azimuth-Doppler and Cartesian domains, respectively. Our proposed algorithm achieves 56.3% AP with IOU of 0.3 on 3D bounding box predictions, and 51.6% with IOU of 0.5 on 2D bounding box prediction. Our dataset and the code can be found at <a class="link-external link-https" href="https://github.com/ZhangAoCanada/RADDet.git" rel="external noopener nofollow">this https URL</a>.      
### 71.Binarized Aggregated Network with Quantization: Flexible Deep Learning Deployment for CSI Feedback in Massive MIMO System  [ :arrow_down: ](https://arxiv.org/pdf/2105.00354.pdf)
>  Massive multiple-input multiple-output (MIMO) is one of the key techniques to achieve better spectrum and energy efficiency in 5G system. The channel state information (CSI) needs to be fed back from the user equipment to the base station in frequency division duplexing (FDD) mode. However, the overhead of the direct feedback is unacceptable due to the large antenna array in massive MIMO system. Recently, deep learning is widely adopted to the compressed CSI feedback task and proved to be effective. In this paper, a novel network named aggregated channel reconstruction network (ACRNet) is designed to boost the feedback performance with network aggregation and parametric rectified linear unit (PReLU) activation. The practical deployment of the feedback network in the communication system is also considered. Specifically, the elastic feedback scheme is proposed to flexibly adapt the network to meet different resource limitations. Besides, the network binarization technique is combined with the feature quantization for lightweight and practical deployment. Experiments show that the proposed ACRNet outperforms loads of previous state-of-the-art networks, providing a neat feedback solution with high performance, low cost and impressive flexibility.      
### 72.Estimating the electrical power output of industrial devices with end-to-end time-series classification in the presence of label noise  [ :arrow_down: ](https://arxiv.org/pdf/2105.00349.pdf)
>  In complex industrial settings, it is common practice to monitor the operation of machines in order to detect undesired states, adjust maintenance schedules, optimize system performance or collect usage statistics of individual machines. In this work, we focus on estimating the power output of a Combined Heat and Power (CHP) machine of a medium-sized company facility by analyzing the total facility power consumption. We formulate the problem as a time-series classification problem where the class label represents the CHP power output. As the facility is fully instrumented and sensor measurements from the CHP are available, we generate the training labels in an automated fashion from the CHP sensor readings. However, sensor failures result in mislabeled training data samples which are hard to detect and remove from the dataset. Therefore, we propose a novel multi-task deep learning approach that jointly trains a classifier and an autoencoder with a shared embedding representation. The proposed approach targets to gradually correct the mislabelled data samples during training in a self-supervised fashion, without any prior assumption on the amount of label noise. We benchmark our approach on several time-series classification datasets and find it to be comparable and sometimes better than state-of-the-art methods. On the real-world use-case of predicting the CHP power output, we thoroughly evaluate the architectural design choices and show that the final architecture considerably increases the robustness of the learning process and consistently beats other recent state-of-the-art algorithms in the presence of unstructured as well as structured label noise.      
### 73.Audio Transformers:Transformer Architectures For Large Scale Audio Understanding. Adieu Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2105.00335.pdf)
>  Over the past two decades, CNN architectures have produced compelling models of sound perception and cognition, learning hierarchical organizations of features. Analogous to successes in computer vision, audio feature classification can be optimized for a particular task of interest, over a wide variety of datasets and labels. In fact similar architectures designed for image understanding have proven effective for acoustic scene analysis. Here we propose applying Transformer based architectures without convolutional layers to raw audio signals. On a standard dataset of Free Sound 50K,comprising of 200 categories, our model outperforms convolutional models to produce state of the art results. This is significant as unlike in natural language processing and computer vision, we do not perform unsupervised pre-training for outperforming convolutional architectures. On the same training set, with respect mean aver-age precision benchmarks, we show a significant improvement. We further improve the performance of Transformer architectures by using techniques such as pooling inspired from convolutional net-work designed in the past few years. In addition, we also show how multi-rate signal processing ideas inspired from wavelets, can be applied to the Transformer embeddings to improve the results. We also show how our models learns a non-linear non constant band-width filter-bank, which shows an adaptable time frequency front end representation for the task of audio understanding, different from other tasks e.g. pitch estimation.      
### 74.A Single-Layer Asymmetric RNN: Potential Low Hardware Complexity Linear Equation Solver  [ :arrow_down: ](https://arxiv.org/pdf/2105.00293.pdf)
>  A single layer neural network for the solution of linear equations is presented. The proposed circuit is based on the standard Hopfield model albeit with the added flexibility that the interconnection weight matrix need not be symmetric. This results in an asymmetric Hopfield neural network capable of solving linear equations. PSPICE simulation results are given which verify the theoretical predictions. Experimental results for circuits set up to solve small problems further confirm the operation of the proposed circuit.      
### 75.A Perceptual Distortion Reduction Framework for Adversarial Perturbation Generation  [ :arrow_down: ](https://arxiv.org/pdf/2105.00278.pdf)
>  Most of the adversarial attack methods suffer from large perceptual distortions such as visible artifacts, when the attack strength is relatively high. These perceptual distortions contain a certain portion which contributes less to the attack success rate. This portion of distortions, which is induced by unnecessary modifications and lack of proper perceptual distortion constraint, is the target of the proposed framework. In this paper, we propose a perceptual distortion reduction framework to tackle this problem from two perspectives. We guide the perturbation addition process to reduce unnecessary modifications by proposing an activated region transfer attention mask, which intends to transfer the activated regions of the target model from the correct prediction to incorrect ones. Note that an ensemble model is adopted to predict the activated regions of the unseen models in the black-box setting of our framework. Besides, we propose a perceptual distortion constraint and add it into the objective function of adversarial attack to jointly optimize the perceptual distortions and attack success rate. Extensive experiments have verified the effectiveness of our framework on several baseline methods.      
### 76.Normalization of regressor excitation as a part of dynamic regressor extension and mixing procedure  [ :arrow_down: ](https://arxiv.org/pdf/2105.00231.pdf)
>  The method of excitation normalization of the regressor, which is used in the estimation loop to solve the plant identification problem, is proposed. It is based on the dynamic regressor extension and mixing procedure. Its application allows to obtain the same upper bound of the parameter identification error for the scalar regressors with different excitation level, using a constant value of the adaptation rate for all of them. This fact is a significant advantage from the practical point of view. Comparison of the developed method with the known one of the regressor amplitude normalization is conducted. It is shown that the classical approach does not have the above-stated property. To validate the theoretical conclusions made, the results of the comparative mathematical modeling of three loops are presented: 1) the classical gradient one, 2) the one with the normalization of the regressor amplitude, 3) the proposed one with the normalization of the regressor excitation.      
### 77.Phase and amplitude synchronisation in power-grid frequency fluctuations in the Nordic Grid  [ :arrow_down: ](https://arxiv.org/pdf/2105.00228.pdf)
>  Monitoring and modelling the power grid frequency is key to ensuring stability in the electrical power system. Many tools exist to investigate the detailed deterministic dynamics and especially the bulk behaviour of the frequency. However, far less attention has been paid to its stochastic properties, and there is a need for a cohesive framework that couples both short-time scale fluctuations and bulk behaviour. Moreover, commonly assumed uncorrelated stochastic noise is predominantly employed in modelling in energy systems. In this publication, we examine the stochastic properties of six synchronous power-grid frequency recording with high-temporal resolution of the Nordic Grid from September 2013, focusing on the increments of the frequency recordings. We show that these increments follow non-Gaussian statistics and display spatial and temporal correlations. Furthermore, we report two different physical synchronisation phenomena: a very short timescale phase synchronisation ($&lt;2\,$s) followed by a slightly larger timescale amplitude synchronisation ($2\,$s-$5\,$s). Overall, these results provide guidance on how to model fluctuations in power systems.      
### 78.One-shot learning for acoustic identification of bird species in non-stationary environments  [ :arrow_down: ](https://arxiv.org/pdf/2105.00202.pdf)
>  This work introduces the one-shot learning paradigm in the computational bioacoustics domain. Even though, most of the related literature assumes availability of data characterizing the entire class dictionary of the problem at hand, that is rarely true as a habitat's species composition is only known up to a certain extent. Thus, the problem needs to be addressed by methodologies able to cope with non-stationarity. To this end, we propose a framework able to detect changes in the class dictionary and incorporate new classes on the fly. We design an one-shot learning architecture composed of a Siamese Neural Network operating in the logMel spectrogram space. We extensively examine the proposed approach on two datasets of various bird species using suitable figures of merit. Interestingly, such a learning scheme exhibits state of the art performance, while taking into account extreme non-stationarity cases.      
### 79.Feature Disentanglement in generating three-dimensional structure from two-dimensional slice with sliceGAN  [ :arrow_down: ](https://arxiv.org/pdf/2105.00194.pdf)
>  Deep generative models are known to be able to model arbitrary probability distributions. Among these, a recent deep generative model, dubbed sliceGAN, proposed a new way of using the generative adversarial network (GAN) to capture the micro-structural characteristics of a two-dimensional (2D) slice and generate three-dimensional (3D) volumes with similar properties. While 3D micrographs are largely beneficial in simulating diverse material behavior, they are often much harder to obtain than their 2D counterparts. Hence, sliceGAN opens up many interesting directions of research by learning the representative distribution from 2D slices, and transferring the learned knowledge to generate arbitrary 3D volumes. However, one limitation of sliceGAN is that latent space steering is not possible. Hence, we combine sliceGAN with AdaIN to endow the model with the ability to disentangle the features and control the synthesis.      
### 80.Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis Tool for Singers  [ :arrow_down: ](https://arxiv.org/pdf/2105.00173.pdf)
>  Current computational-emotion research has focused on applying acoustic properties to analyze how emotions are perceived mathematically or used in natural language processing machine learning models. With most recent interest being in analyzing emotions from the spoken voice, little experimentation has been performed to discover how emotions are recognized in the singing voice -- both in noiseless and noisy data (i.e., data that is either inaccurate, difficult to interpret, has corrupted/distorted/nonsense information like actual noise sounds in this case, or has a low ratio of usable/unusable information). Not only does this ignore the challenges of training machine learning models on more subjective data and testing them with much noisier data, but there is also a clear disconnect in progress between advancing the development of convolutional neural networks and the goal of emotionally cognizant artificial intelligence. By training a new model to include this type of information with a rich comprehension of psycho-acoustic properties, not only can models be trained to recognize information within extremely noisy data, but advancement can be made toward more complex biofeedback applications -- including creating a model which could recognize emotions given any human information (language, breath, voice, body, posture) and be used in any performance medium (music, speech, acting) or psychological assistance for patients with disorders such as BPD, alexithymia, autism, among others. This paper seeks to reflect and expand upon the findings of related research and present a stepping-stone toward this end goal.      
### 81.Data-driven Full-waveform Inversion Surrogate using Conditional Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.00100.pdf)
>  In the Oil and Gas industry, estimating a subsurface velocity field is an essential step in seismic processing, reservoir characterization, and hydrocarbon volume calculation. Full-waveform inversion (FWI) velocity modeling is an iterative advanced technique that provides an accurate and detailed velocity field model, although at a very high computational cost due to the physics-based numerical simulations required at each FWI iteration. In this study, we propose a method of generating velocity field models, as detailed as those obtained through FWI, using a conditional generative adversarial network (cGAN) with multiple inputs. The primary motivation of this approach is to circumvent the extremely high cost of full-waveform inversion velocity modeling. Real-world data were used to train and test the proposed network architecture, and three evaluation metrics (percent error, structural similarity index measure, and visual analysis) were adopted as quality criteria. Based on these metrics, the results evaluated upon the test set suggest that the GAN was able to accurately match real FWI generated outputs, enabling it to extract from input data the main geological structures and lateral velocity variations. Experimental results indicate that the proposed method, when deployed, has the potential to increase the speed of geophysical reservoir characterization processes, saving on time and computational resources.      
### 82.Energy Efficient Reconfigurable Intelligent Surface Enabled Mobile Edge Computing Networks with NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2105.00093.pdf)
>  Reconfigurable intelligent surface (RIS) has emerged as a promising technology for achieving high spectrum and energy efficiency in future wireless communication networks. In this paper, we investigate an RIS-aided single-cell multi-user mobile edge computing (MEC) system where an RIS is deployed to support the communication between a base station (BS) equipped with MEC servers and multiple single-antenna users. To utilize the scarce frequency resource efficiently, we assume that users communicate with BS based on a non-orthogonal multiple access (NOMA) protocol. Each user has a computation task which can be computed locally or partially/fully offloaded to the BS. We aim to minimize the sum energy consumption of all users by jointly optimizing the passive phase shifters, the size of transmission data, transmission rate, power control, transmission time and the decoding order. Since the resulting problem is non-convex, we use the block coordinate descent method to alternately optimize two separated subproblems. More specifically, we use the dual method to tackle a subproblem with given phase shift and obtain the closed-form solution; and then we utilize penalty method to solve another subproblem for given power control. Moreover, in order to demonstrate the effectiveness of our proposed algorithm, we propose three benchmark schemes: the time-division multiple access (TDMA)-MEC scheme, the full local computing scheme and the full offloading scheme. We use an alternating 1-D search method and the dual method that can solve the TDMA-based transmission problem well. Numerical results demonstrate that the proposed scheme can increase the energy efficiency and achieve significant performance gains over the three benchmark schemes.      
### 83.Real-Time Detection and Classification of Astronomical Transient Events: The State-of-the-Art  [ :arrow_down: ](https://arxiv.org/pdf/2105.00089.pdf)
>  In the last years, the need for automated real-time detection and classification of astronomical transients began to be more impelling. Better technologies involve a higher number of detected candidates and an automated classification will allow dealing with this amount of data, every night. The desired state-of-the-art in detection and classification will be presented in its key features and different practical approaches will be introduced, as well. Several ongoing and future surveys will be presented, showing the current situation of Time-Domain Astronomy, and eventually compared with the desired state-of-the-art. The final purpose of this paper is to highlight the general technology readiness level with respect to the level yet to be achieved.      
### 84.Cybersecurity in Power Grids: Challenges and Opportunities  [ :arrow_down: ](https://arxiv.org/pdf/2105.00013.pdf)
>  Increasing volatilities within power transmission and distribution force power grid operators to amplify their use of communication infrastructure to monitor and control their grid. The resulting increase in communication creates a larger attack surface for malicious actors. Indeed, cyber attacks on power grids have already succeeded in causing temporary, large-scale blackouts in the recent past. In this paper, we analyze the communication infrastructure of power grids to derive resulting fundamental challenges of power grids with respect to cybersecurity. Based on these challenges, we identify a broad set of resulting attack vectors and attack scenarios that threaten the security of power grids. To address these challenges, we propose to rely on a defense-in-depth strategy, which encompasses measures for (i) device and application security, (ii) network security, (iii) physical security, as well as (iv) policies, procedures, and awareness. For each of these categories, we distill and discuss a comprehensive set of state-of-the art approaches, and identify further opportunities to strengthen cybersecurity in interconnected power grids.      
### 85.NuSPAN: A Proximal Average Network for Nonuniform Sparse Model -- Application to Seismic Reflectivity Inversion  [ :arrow_down: ](https://arxiv.org/pdf/2105.00003.pdf)
>  We solve the problem of sparse signal deconvolution in the context of seismic reflectivity inversion, which pertains to high-resolution recovery of the subsurface reflection coefficients. Our formulation employs a nonuniform, non-convex synthesis sparse model comprising a combination of convex and non-convex regularizers, which results in accurate approximations of the l0 pseudo-norm. The resulting iterative algorithm requires the proximal average strategy. When unfolded, the iterations give rise to a learnable proximal average network architecture that can be optimized in a data-driven fashion. We demonstrate the efficacy of the proposed approach through numerical experiments on synthetic 1-D seismic traces and 2-D wedge models in comparison with the benchmark techniques. We also present validations considering the simulated Marmousi2 model as well as real 3-D seismic volume data acquired from the Penobscot 3D survey off the coast of Nova Scotia, Canada.      

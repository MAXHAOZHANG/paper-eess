# ArXiv eess --Tue, 25 May 2021
### 1.Counter-Epidemiological Projections of e-Coaching  [ :arrow_down: ](https://arxiv.org/pdf/2105.11437.pdf)
>  This paper considers e-coaching at times of pandemic. It utilizes the Emergency Management Cycle (EMC), a core doctrine for managing disasters. The EMC dimensions provide a useful taxonomical view for the development and application of e-coaching systems, emphasizing technological and societal issues. Typical pandemic symptoms such as anxiety, panic, avoidance, and stress, if properly detected, can be mitigated using the e-coaching tactic and strategy. In this work, we focus on a stress monitoring assistant developed upon machine learning techniques. We provide the results of an experimental study of a prototype of such an assistant. Our study leads to the conclusion that stress monitoring shall become a valuable component of e-coaching at all EMC phases.      
### 2.Design to automate the detection and counting of Tuberculosis(TB) bacilli  [ :arrow_down: ](https://arxiv.org/pdf/2105.11432.pdf)
>  Tuberculosis is a contagious disease which is one of the leading causes of death, globally. The general diagnosis methods for tuberculosis include microscopic examination, tuberculin skin test, culture method, enzyme linked immunosorbent assay (ELISA) and electronic nose system. World Health Organization (WHO) recommends standard microscopic examination for early diagnosis of tuberculosis. In microscopy, the technician examines field of views (FOVs) in sputum smear for presence of any TB bacilli and counts the number of TB bacilli per FOV to report the level of severity. This process is time consuming with an increased concentration for an experienced staff to examine a single sputum smear. The examination demands for skilled technicians in high-prevalence countries which may lead to overload, fatigue and diminishes the quality of microscopy. Thus, a computer assisted system is proposed and designed for the detection of tuberculosis bacilli to assist pathologists with increased sensitivity and specificity. The manual efforts in detecting and counting the number of TB bacilli is greatly minimized. The system obtains Ziehl-Neelsen stained microscopic images from conventional microscope at 100x magnification and passes the data to the detection system. Initially the segmentation of TB bacilli was done using RGB thresholding and Sauvola's adaptive thresholding algorithm. To eliminate the non-TB bacilli from coarse level segmentation, shape descriptors like area, perimeter, convex hull, major axis length and eccentricity are used to extract only the TB bacilli features. Finally, the TB bacilli are counted using the generated bounding boxes to report the level of severity.      
### 3.An Electricity Market Clearing Formulation for Harnessing Space-Time, Load-Shifting Flexibility from Data Centers  [ :arrow_down: ](https://arxiv.org/pdf/2105.11416.pdf)
>  In this work, we provide a theoretical analysis of an electricity market clearing formulation that seeks to harness spatio-temporal, load-shifting flexibility from data centers (DaCes). Central to our study is the concept of virtual links, which provide non-physical pathways that can be used by DaCes to shift power loads (by shifting computing loads) across space and time. We use virtual links to show that the clearing formulation treats DaCes as prosumers that simultaneously request load and provide a load-shifting flexibility service. Our analysis also reveals that DaCes are remunerated for the provision of load shifting flexibility based on nodal price differences (across space and time). We also show that DaCe flexibility helps relieve space-time price volatility and show that the clearing formulation satisfies fundamental economic properties that are expected from coordinated markets (e.g., provides a competitive equilibrium and achieves revenue adequacy and cost recovery). Case studies are presented to demonstrate these properties.      
### 4.Real-time People Tracking and Identification from Sparse mm-Wave Radar Point-clouds  [ :arrow_down: ](https://arxiv.org/pdf/2105.11368.pdf)
>  Mm-wave radars have recently gathered significant attention as a means to track human movement and identify subjects from their gait characteristics. A widely adopted method to perform the identification is the extraction of the micro-Doppler signature of the targets, which is computationally demanding in case of co-existing multiple targets within the monitored physical space. Such computational complexity is the main problem of state-of-the-art approaches, and makes them inapt for real-time use. In this work, we present an end-to-end, low-complexity but highly accurate method to track and identify multiple subjects in real-time using the sparse point-cloud sequences obtained from a low-cost mm-wave radar. Our proposed system features an extended object tracking Kalman filter, used to estimate the position, shape and extension of the subjects, which is integrated with a novel deep learning classifier, specifically tailored for effective feature extraction and fast inference on radar point-clouds. The proposed method is thoroughly evaluated on an edge-computing platform from NVIDIA (Jetson series), obtaining greatly reduced execution times (reduced complexity) against the best approaches from the literature. Specifically, it achieves accuracies as high as 91.62%, operating at 15 frames per seconds, in identifying three subjects that concurrently and freely move in an unseen indoor environment, among a group of eight.      
### 5.DDR-Net: Dividing and Downsampling Mixed Network for Diffeomorphic Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2105.11361.pdf)
>  Deep diffeomorphic registration faces significant challenges for high-dimensional images, especially in terms of memory limits. Existing approaches either downsample original images, or approximate underlying transformations, or reduce model size. The information loss during the approximation or insufficient model capacity is a hindrance to the registration accuracy for high-dimensional images, e.g., 3D medical volumes. In this paper, we propose a Dividing and Downsampling mixed Registration network (DDR-Net), a general architecture that preserves most of the image information at multiple scales. DDR-Net leverages the global context via downsampling the input and utilizes the local details from divided chunks of the input images. This design reduces the network input size and its memory cost; meanwhile, by fusing global and local information, DDR-Net obtains both coarse-level and fine-level alignments in the final deformation fields. We evaluate DDR-Net on three public datasets, i.e., OASIS, IBSR18, and 3DIRCADB-01, and the experimental results demonstrate our approach outperforms existing approaches.      
### 6.Brain tumour segmentation using a triplanar ensemble of U-Nets  [ :arrow_down: ](https://arxiv.org/pdf/2105.11356.pdf)
>  Gliomas appear with wide variation in their characteristics both in terms of their appearance and location on brain MR images, which makes robust tumour segmentation highly challenging, and leads to high inter-rater variability even in manual segmentations. In this work, we propose a triplanar ensemble network, with an independent tumour core prediction module, for accurate segmentation of these tumours and their sub-regions. On evaluating our method on the MICCAI Brain Tumor Segmentation (BraTS) challenge validation dataset, for tumour sub-regions, we achieved a Dice similarity coefficient of 0.77 for both enhancing tumour (ET) and tumour core (TC). In the case of the whole tumour (WT) region, we achieved a Dice value of 0.89, which is on par with the top-ranking methods from BraTS'17-19. Our method achieved an evaluation score that was the equal 5th highest value (with our method ranking in 10th place) in the BraTS'20 challenge, with mean Dice values of 0.81, 0.89 and 0.84 on ET, WT and TC regions respectively on the BraTS'20 unseen test dataset.      
### 7.Verification of Dissipativity and Evaluation of Storage Function in Economic Nonlinear MPC using Q-Learning  [ :arrow_down: ](https://arxiv.org/pdf/2105.11313.pdf)
>  In the Economic Nonlinear Model Predictive (ENMPC) context, closed-loop stability relates to the existence of a storage function satisfying a dissipation inequality. Finding the storage function is in general -- for nonlinear dynamics and cost -- challenging, and has attracted attentions recently. Q-Learning is a well-known Reinforcement Learning (RL) techniques that attempts to capture action-value functions based on the state-input transitions and stage cost of the system. In this paper, we present the use of the Q-Learning approach to obtain the storage function and verify the dissipativity for discrete-time systems subject to state-input constraints. We show that undiscounted Q-learning is able to capture the storage function for dissipative problems when the parameterization is rich enough. The efficiency of the proposed method will be illustrated in the different case studies.      
### 8.Generation of COVID-19 Chest CT Scan Images using Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.11241.pdf)
>  SARS-CoV-2, also known as COVID-19 or Coronavirus, is a viral contagious disease that is infected by a novel coronavirus, and has been rapidly spreading across the globe. It is very important to test and isolate people to reduce spread, and from here comes the need to do this quickly and efficiently. According to some studies, Chest-CT outperforms RT-PCR lab testing, which is the current standard, when diagnosing COVID-19 patients. Due to this, computer vision researchers have developed various deep learning systems that can predict COVID-19 using a Chest-CT scan correctly to a certain degree. The accuracy of these systems is limited since deep learning neural networks such as CNNs (Convolutional Neural Networks) need a significantly large quantity of data for training in order to produce good quality results. Since the disease is relatively recent and more focus has been on CXR (Chest XRay) images, the available chest CT Scan image dataset is much less. We propose a method, by utilizing GANs, to generate synthetic chest CT images of both positive and negative COVID-19 patients. Using a pre-built predictive model, we concluded that around 40% of the generated images are correctly predicted as COVID-19 positive. The dataset thus generated can be used to train a CNN-based classifier which can help determine COVID-19 in a patient with greater accuracy.      
### 9.A self-supervised learning strategy for postoperative brain cavity segmentation simulating resections  [ :arrow_down: ](https://arxiv.org/pdf/2105.11239.pdf)
>  Accurate segmentation of brain resection cavities (RCs) aids in postoperative analysis and determining follow-up treatment. Convolutional neural networks (CNNs) are the state-of-the-art image segmentation technique, but require large annotated datasets for training. Annotation of 3D medical images is time-consuming, requires highly-trained raters, and may suffer from high inter-rater variability. Self-supervised learning strategies can leverage unlabeled data for training. <br>We developed an algorithm to simulate resections from preoperative magnetic resonance images (MRIs). We performed self-supervised training of a 3D CNN for RC segmentation using our simulation method. We curated EPISURG, a dataset comprising 430 postoperative and 268 preoperative MRIs from 430 refractory epilepsy patients who underwent resective neurosurgery. We fine-tuned our model on three small annotated datasets from different institutions and on the annotated images in EPISURG, comprising 20, 33, 19 and 133 subjects. <br>The model trained on data with simulated resections obtained median (interquartile range) Dice score coefficients (DSCs) of 81.7 (16.4), 82.4 (36.4), 74.9 (24.2) and 80.5 (18.7) for each of the four datasets. After fine-tuning, DSCs were 89.2 (13.3), 84.1 (19.8), 80.2 (20.1) and 85.2 (10.8). For comparison, inter-rater agreement between human annotators from our previous study was 84.0 (9.9). <br>We present a self-supervised learning strategy for 3D CNNs using simulated RCs to accurately segment real RCs on postoperative MRI. Our method generalizes well to data from different institutions, pathologies and modalities. Source code, segmentation models and the EPISURG dataset are available at <a class="link-external link-https" href="https://github.com/fepegar/ressegijcars" rel="external noopener nofollow">this https URL</a> .      
### 10.Aluminum Nitride Two-Dimensional-Resonant-Rods  [ :arrow_down: ](https://arxiv.org/pdf/2105.11232.pdf)
>  In the last decades, Bulk-Acoustic-Wave (BAW) filters have been essential components of 1G-to-4G radios. These devices rely on the high electromechanical coupling coefficient (kt2~7%), attained by Aluminum Nitride (AlN) Film-Bulk-Acoustic-Resonators (FBARs), to achieve a wideband and low-loss frequency response. As the resonance frequency of FBARs is set by their thickness, the integration of multiple FBARs, to form filters, can only be attained through the adoption of frequency tuning fabrication steps, such as mass loading or trimming. However, as the ability to reliably control these steps significantly decays for thinner FBARs, manufacturing FBARs-based filters, addressing the needs of emerging IoT and 5G high-frequency applications, is becoming more and more challenging. Consequently, there is a quest for new acoustic resonant components, simultaneously exhibiting high kt2 and a lithographic frequency tunability. In this work, a novel class of AlN resonators is presented. These radio-frequency devices, labelled as Two-Dimensional-Resonant-Rods (2DRRs), exploit, for the first time, the unconventional acoustic behavior exhibited by a forest of locally resonant rods, built in the body of a profiled AlN layer that is sandwiched between a bottom un-patterned metal plate and a top metallic grating. 2DRRs exhibit unexplored modal features that make them able to achieve high kt2, a significant lithographic frequency tunability and a relaxed lithographic resolution, while relying on an optimal AlN crystalline orientation. The operation of 2DRRs is discussed, in this work, by means of analytical and finite-element (FE) investigations. The measured performance of the first fabricated 2DRR, showing a kt2 in excess of 7.4%, are also reported.      
### 11.Pulmonary embolism identification in computerized tomography pulmonary angiography scans with deep learning technologies in COVID-19 patients  [ :arrow_down: ](https://arxiv.org/pdf/2105.11187.pdf)
>  The main objective of this work is to utilize state-of-the-art deep learning approaches for the identification of pulmonary embolism in CTPA-Scans for COVID-19 patients, provide an initial assessment of their performance and, ultimately, provide a fast-track prototype solution (system). We adopted and assessed some of the most popular convolutional neural network architectures through transfer learning approaches, to strive to combine good model accuracy with fast training. Additionally, we exploited one of the most popular one-stage object detection models for the localization (through object detection) of the pulmonary embolism regions-of-interests. The models of both approaches are trained on an original CTPA-Scan dataset, where we annotated of 673 CTPA-Scan images with 1,465 bounding boxes in total, highlighting pulmonary embolism regions-of-interests. We provide a brief assessment of some state-of-the-art image classification models by achieving validation accuracies of 91% in pulmonary embolism classification. Additionally, we achieved a precision of about 68% on average in the object detection model for the pulmonary embolism localization under 50% IoU threshold. For both approaches, we provide the entire training pipelines for future studies (step by step processes through source code). In this study, we present some of the most accurate and fast deep learning models for pulmonary embolism identification in CTPA-Scans images, through classification and localization (object detection) approaches for patients infected by COVID-19. We provide a fast-track solution (system) for the research community of the area, which combines both classification and object detection models for improving the precision of identifying pulmonary embolisms.      
### 12.Smart mobile microscopy: towards fully-automated digitization  [ :arrow_down: ](https://arxiv.org/pdf/2105.11179.pdf)
>  Mobile microscopy is a newly formed field that emerged from a combination of optical microscopy capabilities and spread, functionality, and ever-increasing computing resources of mobile devices. Despite the idea of creating a system that would successfully merge a microscope, numerous computer vision methods, and a mobile device is regularly examined, the resulting implementations still require the presence of a qualified operator to control specimen digitization. In this paper, we address the task of surpassing this constraint and present a ``smart'' mobile microscope concept aimed at automatic digitization of the most valuable visual information about the specimen. We perform this through combining automated microscope setup control and classic techniques such as auto-focusing, in-focus filtering, and focus-stacking -- adapted and optimized as parts of a mobile cross-platform library.      
### 13.Phase Noise and Frequency Accuracy in Crystal-less Wireless Edge Nodes  [ :arrow_down: ](https://arxiv.org/pdf/2105.10992.pdf)
>  This paper presents a fundamental analysis connecting phase noise and long-term frequency accuracy of oscillators and explores the possibilities and limitations in crystal-less frequency calibration for wireless edge nodes from a noise-impact perspective. N-period-average jitter (NPAJ) is introduced as a link between the spectral characterization of phase noise and long-term frequency accuracy. It is found that flicker noise or other colored noise profiles coming from the reference in a frequency synthesizer is the dominant noise source affecting long-term frequency accuracy. An average processing unit embedded in an ADPLL is proposed based on the N-period-average jitter concept to enhance frequency accuracy in a Calibrate and Open-loop scenario commonly used in low power radios. With this low-cost block, the frequency calibration accuracy can be directly associated with the reference noise performance. Thus, the feasibility of XO-less design with certain communication standards can be easily evaluated with the proposed theory.      
### 14.FBI-Denoiser: Fast Blind Image Denoiser for Poisson-Gaussian Noise  [ :arrow_down: ](https://arxiv.org/pdf/2105.10967.pdf)
>  We consider the challenging blind denoising problem for Poisson-Gaussian noise, in which no additional information about clean images or noise level parameters is available. Particularly, when only "single" noisy images are available for training a denoiser, the denoising performance of existing methods was not satisfactory. Recently, the blind pixelwise affine image denoiser (BP-AIDE) was proposed and significantly improved the performance in the above setting, to the extent that it is competitive with denoisers which utilized additional information. However, BP-AIDE seriously suffered from slow inference time due to the inefficiency of noise level estimation procedure and that of the blind-spot network (BSN) architecture it used. To that end, we propose Fast Blind Image Denoiser (FBI-Denoiser) for Poisson-Gaussian noise, which consists of two neural network models; 1) PGE-Net that estimates Poisson-Gaussian noise parameters 2000 times faster than the conventional methods and 2) FBI-Net that realizes a much more efficient BSN for pixelwise affine denoiser in terms of the number of parameters and inference speed. Consequently, we show that our FBI-Denoiser blindly trained solely based on single noisy images can achieve the state-of-the-art performance on several real-world noisy image benchmark datasets with much faster inference time (x 10), compared to BP-AIDE. The official code of our method is available at <a class="link-external link-https" href="https://github.com/csm9493/FBI-Denoiser" rel="external noopener nofollow">this https URL</a>.      
### 15.Large-Signal Grid-Synchronization Stability Analysis of PLL-based VSCs Using Lyapunov's Direct Method  [ :arrow_down: ](https://arxiv.org/pdf/2105.10957.pdf)
>  Grid-synchronization stability (GSS) is an emerging stability issue of grid-tied voltage source converters (VSCs), which can be provoked by severe grid voltage sags. Although a qualitative understanding of the mechanism behind the loss of synchronization has been acquired in recent studies, an analytical method for quantitative assessment of GSS of grid-tied VSCs is still missing. To bridge this gap, a dedicated Lyapunov function is analytically proposed, and its corresponding stability criterion for GSS analysis of grid-tied VSCs is rigorously constructed. Both theoretical analysis and simulation result demonstrate that the proposed method can provide a credible GSS evaluation compared to the previous EAC/EF-based method. Therefore, it can be applied for fast GSS evaluation of the grid-tied VSCs as is exemplified in this paper, as well as an analytical tool for some GSS-related issues, e.g., GSS-oriented parameter design and stabilization control.      
### 16.SSCAN: A Spatial-spectral Cross Attention Network for Hyperspectral Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2105.10949.pdf)
>  Hyperspectral images (HSIs) have been widely used in a variety of applications thanks to the rich spectral information they are able to provide. Among all HSI processing tasks, HSI denoising is a crucial step. Recently, deep learning-based image denoising methods have made great progress and achieved great performance. However, existing methods tend to ignore the correlations between adjacent spectral bands, leading to problems such as spectral distortion and blurred edges in denoised results. In this study, we propose a novel HSI denoising network, termed SSCAN, that combines group convolutions and attention modules. Specifically, we use a group convolution with a spatial attention module to facilitate feature extraction by directing models' attention to band-wise important features. We propose a spectral-spatial attention block (SSAB) to exploit the spatial and spectral information in hyperspectral images in an effective manner. In addition, we adopt residual learning operations with skip connections to ensure training stability. The experimental results indicate that the proposed SSCAN outperforms several state-of-the-art HSI denoising algorithms.      
### 17.Principled information fusion for multi-view multi-agent surveillance systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.10935.pdf)
>  A key objective of multi-agent surveillance systems is to monitor a much larger region than the limited field-of-view (FoV) of any individual agent by successfully exploiting cooperation among multi-view agents. Whenever either a centralized or a distributed approach is pursued, this goal cannot be achieved unless an appropriately designed fusion strategy is adopted. This paper presents a novel principled information fusion approach for dealing with multi-view multi-agent case, on the basis of Generalized Covariance Intersection (GCI). The proposed method can be used to perform multi-object tracking on both a centralized and a distributed peer-to-peer sensor network. Simulation experiments on realistic multi-object tracking scenarios demonstrate effectiveness of the proposed solution.      
### 18.A frequency domain approach for local module identification in dynamic networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.10901.pdf)
>  In classical approaches of dynamic network identification, in order to identify a system (module) embedded in a dynamic network, one has to formulate a Multi-input-Single-output (MISO) identification problem that requires identification of a parametric model for all the modules constituting the MISO setup including (possibly) the noise model, and determine their model order. This requirement leads to model order selection steps for modules that are of no interest to the experimenter which increases the computational complexity for large-sized networks. Also, identification using a parametric noise model (like BJ method) can suffer from local minima, however neglecting the noise model has its impact on the variance of the estimates. In this paper, we provide a two-step identification approach to avoid these problems. The first step involves performing a non-parametric indirect approach for a MISO identification problem to get the non-parametric frequency response function (FRF) estimates and its variance as a function of frequency. In the second step, the estimated non-parametric FRF of the target module is smoothed using a parametric frequency domain estimator with the estimated variance from the previous step as the non-parametric noise model. The developed approach is practical with weak assumptions on noise, uses the available toolbox, requires a parametric model only for the target module of interest, and uses a non-parametric noise model to reduce the variance of the estimates. Numerical simulations illustrate the potentials of the introduced method in comparison with the classical identification methods.      
### 19.Simulation-Based Impact of Connected Vehicles in Platooning Mode on Travel Time, Emissions and Fuel Consumption  [ :arrow_down: ](https://arxiv.org/pdf/2105.10894.pdf)
>  Several approaches have been presented during the last decades to reduce carbon pollution from transportation. One example is the use of platooning mode. This paper considers data obtained from daily trips to investigate the impact of platooning on travel time, emissions of CO2, CO, NO2 and HC and fuel consumption on a road network in Upper Austria. For this purpose, we studied fuel combustion-based engines relying on the extension of the 3DCoAutoSim simulation platform. The obtained results showed that the platooning mode not only increased driving efficiency but also decreased the total emissions by reducing fuel consumption.      
### 20.Fast Crack Detection Using Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2105.10892.pdf)
>  To improve the efficiency and reduce the labour cost of the renovation process, this study presents a lightweight Convolutional Neural Network (CNN)-based architecture to extract crack-like features, such as cracks and joints. Moreover, Transfer Learning (TF) method was used to save training time while offering comparable prediction results. For three different objectives: 1) Detection of the concrete cracks; 2) Detection of natural stone cracks; 3) Differentiation between joints and cracks in natural stone; We built a natural stone dataset with joints and cracks information as complementary for the concrete benchmark dataset. As the results show, our model is demonstrated as an effective tool for industry use.      
### 21.Analysis and Calibration of SAR ADC  [ :arrow_down: ](https://arxiv.org/pdf/2105.10836.pdf)
>  This paper presents the effect of capacitor mismatch on the weights of binary and split SAR ADC. It proposes a matrix formulation to calculate the nodal voltages for N-section split SAR ADC. The second part of the paper proposes a new weight estimation methodology.      
### 22.Dynamic Evaluation of Power Distribution Lines for Determining the Number of Repair Teams and Prioritizing the Resolution of Faults Caused by High-Impact Low-Probability Events  [ :arrow_down: ](https://arxiv.org/pdf/2105.10834.pdf)
>  In order to increase the resilience of distribution systems against high-impact low-probability (HILP) events, it is important to prioritize the damaged assets so that the lost loads, especially critical and important loads, can be restored faster. In addition, correctly predicting the number of repair teams during critical times contributes to restoring the network to the initial resilience level. For this reason, this paper discusses the prioritization of electricity supply lines for evaluating the number of required repair teams. To this end, the economic value of distribution system lines has been considered as a criterion representing the sensitivity of the network to hurricanes. The modeling is based on value, in which the load value, failure probability of the poles, fragility curve, duration of line repair by the maintenance team, and the topology factor have been considered. This is so that the significance of the demand side, the failure extent and accessibility of the lines, the importance of time, and the network configuration are considered. The results provide a list of line priority for fault resolution, in which the topology factor has a larger effect. The number of repair teams required to restore critical and important loads is determined from this model. This modeling has been tested on an IEEE 33-bus network. Keywords: Resilience, distribution systems, asset evaluation, restoration prioritization, repair team      
### 23.Orthogonal Ensemble Networks for Biomedical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.10827.pdf)
>  Despite the astonishing performance of deep-learning based approaches for visual tasks such as semantic segmentation, they are known to produce miscalibrated predictions, which could be harmful for critical decision-making processes. Ensemble learning has shown to not only boost the performance of individual models but also reduce their miscalibration by averaging independent predictions. In this scenario, model diversity has become a key factor, which facilitates individual models converging to different functional solutions. In this work, we introduce Orthogonal Ensemble Networks (OEN), a novel framework to explicitly enforce model diversity by means of orthogonal constraints. The proposed method is based on the hypothesis that inducing orthogonality among the constituents of the ensemble will increase the overall model diversity. We resort to a new pairwise orthogonality constraint which can be used to regularize a sequential ensemble training process, resulting on improved predictive performance and better calibrated model outputs. We benchmark the proposed framework in two challenging brain lesion segmentation tasks --brain tumor and white matter hyper-intensity segmentation in MR images. The experimental results show that our approach produces more robust and well-calibrated ensemble models and can deal with challenging tasks in the context of biomedical image segmentation.      
### 24.High Dimensional Robust Consensus over Networks with Limited Capacity  [ :arrow_down: ](https://arxiv.org/pdf/2105.10823.pdf)
>  We investigate robust linear consensus over networks under capacity-constrained communication. The capacity of each edge is encoded as an upper bound on the number of state variables that can be communicated instantaneously. When the edge capacities are small compared to the dimensionality of the state vectors, it is not possible to instantaneously communicate full state information over every edge. We investigate how robust consensus (small steady state variance of the states) can be achieved within a linear time-invariant setting by optimally assigning edges to state-dimensions. We show that if a finite steady state variance of the states can be achieved, then both the minimum cut capacity and the total capacity of the network should be sufficiently large. Optimal and approximate solutions are provided for some special classes of graphs. We also consider the related problem of optimally allocating additional capacity on a feasible initial solution. We show that this problem corresponds to the maximization of a submodular function subject to a matroid constraint, which can be approximated via a greedy algorithm.      
### 25.Reconfigurable Surface Wave Platform Using Fluidic Conductive Structures  [ :arrow_down: ](https://arxiv.org/pdf/2105.10810.pdf)
>  Surface wave inherently has less propagation loss as it adheres to the surface and minimizes unwanted dissipation in space. Recently, they find applications in network-on-chip (NoC) communications and intelligent surface aided mobile networked communications. This paper puts forward a reconfigurable surface wave platform (RSWP) that utilizes liquid metal to produce highly energy-efficient and adaptive pathways for surface wave transmission. Our simulation results illustrate that the proposed RSWP using Galinstan can obtain a $25{\rm dB}$ gain in the electric field for a propagation distance of $35\lambda$ at $30{\rm GHz}$ where $\lambda$ denotes the wavelength. Moreover, less than $1{\rm dB}$ loss is observed even at a distance of $50\lambda$, and a pathway with right-angled turns can also be created with only a $3.5{\rm dB}$ loss at the turn.      
### 26.Multi-Feature Fusion-based Scene Classification Framework for HSR Images  [ :arrow_down: ](https://arxiv.org/pdf/2105.10758.pdf)
>  To realize high-accuracy classification of high spatial resolution (HSR) images, this letter proposes a new multi-feature fusion-based scene classification framework (MF2SCF) by fusing local, global, and color features of HSR images. Specifically, we first extract the local features with the help of image slicing and densely connected convolutional networks (DenseNet), where the outputs of dense blocks in the fine-tuned DenseNet-121 model are jointly averaged and concatenated to describe local features. Second, from the perspective of complex networks (CN), we model a HSR image as an undirected graph based on pixel distance, intensity, and gradient, and obtain a gray-scale image (GSI), a gradient of image (GoI), and three CN-based feature images to delineate global features. To make the global feature descriptor resist to the impact of rotation and illumination, we apply uniform local binary patterns (LBP) on GSI, GoI, and feature images, respectively, and generate the final global feature representation by concatenating spatial histograms. Third, the color features are determined based on the normalized HSV histogram, where HSV stands for hue, saturation, and value, respectively. Finally, three feature vectors are jointly concatenated for scene classification. Experiment results show that MF2SCF significantly improves the classification accuracy compared with state-of-the-art LBP-based methods and deep learning-based methods.      
### 27.Tuning of Drone PD Controller Parameters for Medical Supplies Delivery  [ :arrow_down: ](https://arxiv.org/pdf/2105.10741.pdf)
>  During the COVID-19 pandemic and similar outbreaks in the future, drones can be set up to reduce human interaction for medical supplies delivery, which is crucial in times of pandemic. In this short paper, we introduce the use of two evolutionary algorithms for multi-objective optimization (MOO) and tuning the parameters of the PD controller of a drone to follow the 3D desired path.      
### 28.MIASSR: An Approach for Medical Image Arbitrary Scale Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2105.10738.pdf)
>  Single image super-resolution (SISR) aims to obtain a high-resolution output from one low-resolution image. Currently, deep learning-based SISR approaches have been widely discussed in medical image processing, because of their potential to achieve high-quality, high spatial resolution images without the cost of additional scans. However, most existing methods are designed for scale-specific SR tasks and are unable to generalise over magnification scales. In this paper, we propose an approach for medical image arbitrary-scale super-resolution (MIASSR), in which we couple meta-learning with generative adversarial networks (GANs) to super-resolve medical images at any scale of magnification in (1, 4]. Compared to state-of-the-art SISR algorithms on single-modal magnetic resonance (MR) brain images (OASIS-brains) and multi-modal MR brain images (BraTS), MIASSR achieves comparable fidelity performance and the best perceptual quality with the smallest model size. We also employ transfer learning to enable MIASSR to tackle SR tasks of new medical modalities, such as cardiac MR images (ACDC) and chest computed tomography images (COVID-CT). The source code of our work is also public. Thus, MIASSR has the potential to become a new foundational pre-/post-processing step in clinical image analysis tasks such as reconstruction, image quality enhancement, and segmentation.      
### 29.Reduction in Circulating Current with Improved Secondary Side Modulation in Isolated Current-Fed Half Bridge AC-DC Converter  [ :arrow_down: ](https://arxiv.org/pdf/2105.10727.pdf)
>  Current-fed half bridge converter with bidirectional switches on ac side and a full bridge converter on dc side of a high frequency transformer is an optimal topology for single stage galvanically isolated ac-dc converter for onboard vehicle charging application. AC side switches are actively commutated to achieve zero current switching (ZCS) using single phase shift modulation (SPSM) and discontinuous current phase shift modulation (DCPSM). Furthermore, zero voltage turn-on (ZVS) is achieved for dc side switches. Compared to SPSM, DCPSM maintains a constant peak current in the converter throughout the grid cycle of ac mains voltage. However, constant peak current contributes to a high circulating current near the zero crossings of ac mains voltage and also at light load conditions. This paper proposes an improved discontinuous current phase shift modulation (IDCPSM) to increase the efficiency of the converter across different loading conditions. A dual control variable is adopted to actively reduce the circulating current while maintaining soft switching of both ac and dc side switches across the grid cycle of ac mains voltage. A 1.5 kW laboratory prototype has been developed to experimentally validate the analysis, design and improvement in performance for different loading conditions.      
### 30.V2V Spatiotemporal Interactive Pattern Recognition and Risk Analysis in Lane Changes  [ :arrow_down: ](https://arxiv.org/pdf/2105.10688.pdf)
>  In complex lane change (LC) scenarios, semantic interpretation and safety analysis of dynamic interactive pattern are necessary for autonomous vehicles to make appropriate decisions. This study proposes an unsupervised learning framework that combines primitive-based interactive pattern recognition methods and risk analysis methods. The Hidden Markov Model with the Gaussian mixture model (GMM-HMM) approach is developed to decompose the LC scenarios into primitives. Then the Dynamic Time Warping (DTW) distance based K-means clustering is applied to gather the primitives to 13 types of interactive patterns. Finally, this study considers two types of time-to-collision (TTC) involved in the LC process as indicators to analyze the risk of the interactive patterns and extract high-risk LC interactive patterns. The results obtained from The Highway Drone Dataset (highD) demonstrate that the identified LC interactive patterns contain interpretable semantic information. This study explores the spatiotemporal evolution law and risk formation mechanism of the LC interactive patterns and the findings are useful for comprehensively understanding the latent interactive patterns, improving the rationality and safety of autonomous vehicle's decision-making.      
### 31.A Model Randomization Approach to Statistical Parameter Privacy  [ :arrow_down: ](https://arxiv.org/pdf/2105.10664.pdf)
>  In this paper, we study a privacy filter design problem for a sequence of sensor measurements whose joint probability density function (p.d.f.) depends on a private parameter. To ensure parameter privacy, we propose a filter design framework which consists of two components: a randomizer and a nonlinear transformation. The randomizer takes the private parameter as input and randomly generates a pseudo parameter. The nonlinear mapping transforms the measurements such that the joint p.d.f. of the filter's output depends on the pseudo parameter rather than the private parameter. It also ensures that the joint p.d.f. of the filter's output belongs to the same family of distributions as that of the measurements. The nonlinear transformation has a feedforward-feedback structure that allows real-time and causal generation of the disguised measurements with low complexity using a recursive structure. The design of the randomizer is formulated as an optimization problem subject to a privacy constraint, in terms of mutual information, and it is shown that the optimal randomizer is the solution of a convex optimization problem. Using information-theoretic inequalities, we show that the performance of any estimator of the private parameter, based on the output of the privacy filter, is limited by the privacy constraint. The structure of the nonlinear transformation is studied in the special cases of independent and identically distributed, Markovian, and Gauss-Markov measurements. Our results show that the privacy filter in the Gauss-Markov case can be implemented as two one-step ahead Kalman predictors and a set of minimum mean square error predictors. The Kalman predictors significantly reduce the complexity of computing the disguised measurements. A numerical example on occupancy privacy in a building automation system illustrates the approach.      
### 32.An Efficient Network Solver for Dynamic Simulation of Power Systems Based on Hierarchical Inverse Computation and Modification  [ :arrow_down: ](https://arxiv.org/pdf/2105.10661.pdf)
>  In power system dynamic simulation, up to 90% of the computational time is devoted to solve the network equations, i.e., a set of linear equations. Traditional approaches are based on sparse LU factorization, which is inherently sequential. In this paper, an inverse-based network solution is proposed by a hierarchical method for computing and store the approximate inverse of the conductance matrix in electromagnetic transient (EMT) simulations. The proposed method can also efficiently update the inverse by modifying only local sub-matrices to reflect changes in the network, e.g., loss of a line. Experiments on a series of simplified 179-bus Western Interconnection demonstrate the advantages of the proposed methods.      
### 33.Analysis of Contractions in System Graphs: Application to State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2105.10641.pdf)
>  Observability and estimation are closely tied to the system structure, which can be visualized as a system graph--a graph that captures the inter-dependencies within the state variables. For example, in social system graphs such inter-dependencies represent the social interactions of different individuals. It was recently shown that contractions, a key concept from graph theory, in the system graph are critical to system observability, as (at least) one state measurement in every contraction is necessary for observability. Thus, the size and number of contractions are critical in recovering for loss of observability. In this paper, the correlation between the average-size/number of contractions and the global clustering coefficient (GCC) of the system graph is studied. Our empirical results show that estimating systems with high GCC requires fewer measurements, and in case of measurement failure, there are fewer possible options to find substitute measurement that recovers the system's observability. This is significant as by tuning the GCC, we can improve the observability properties of large-scale engineered networks, such as social networks and smart grid.      
### 34.Simultaneous Distributed Estimation and Attack Detection/Isolation in Social Networks: Structural Observability, Kronecker-Product Network, and Chi-Square Detector  [ :arrow_down: ](https://arxiv.org/pdf/2105.10639.pdf)
>  This paper considers distributed estimation of linear systems when the state observations are corrupted with Gaussian noise of unbounded support and under possible random adversarial attacks. We consider sensors equipped with single time-scale estimators and local chi-square ($\chi^2$) detectors to simultaneously opserve the states, share information, fuse the noise/attack-corrupted data locally, and detect possible anomalies in their own observations. While this scheme is applicable to a wide variety of systems associated with full-rank (invertible) matrices, we discuss it within the context of distributed inference in social networks. The proposed technique outperforms existing results in the sense that: (i) we consider Gaussian noise with no simplifying upper-bound assumption on the support; (ii) all existing $\chi^2$-based techniques are centralized while our proposed technique is distributed, where the sensors \textit{locally} detect attacks, with no central coordinator, using specific probabilistic thresholds; and (iii) no local-observability assumption at a sensor is made, which makes our method feasible for large-scale social networks. Moreover, we consider a Linear Matrix Inequalities (LMI) approach to design block-diagonal gain (estimator) matrices under appropriate constraints for isolating the attacks.      
### 35.Decentralized Baseband Processing with Gaussian Message Passing Detection for Uplink Massive MU-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.10636.pdf)
>  Decentralized baseband processing (DBP) architecture, which partitions the base station antennas into multiple antenna clusters, has been recently proposed to alleviate the excessively high interconnect bandwidth, chip input/output data rates, and detection complexity for massive multi-user multiple-input multiple-output (MU-MIMO) systems. In this paper, we develop a novel decentralized Gaussian message passing (GMP) detection for the DBP architecture. By projecting the discrete probability distribution into a complex Gaussian function, the local means and variances iteratively calculated in each antenna cluster are fused to generate the global symbol beliefs based on the proposed message fusion rule in the centralized processing unit. We present the framework and analysis of the convergence of the decentralized GMP detection based on state evolution under the assumptions of large-system limit and Gaussian sources. Analytical results corroborated by simulations demonstrate that nonuniform antenna cluster partition scheme exhibits higher convergence rate than the uniform counterpart. Simulation results illustrate that the proposed decentralized GMP detection outperforms the recently proposed decentralized algorithms.      
### 36.Automatic calibration of time of flight based non-line-of-sight reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2105.10603.pdf)
>  Time of flight based Non-line-of-sight (NLOS) imaging approaches require precise calibration of illumination and detector positions on the visible scene to produce reasonable results. If this calibration error is sufficiently high, reconstruction can fail entirely without any indication to the user. In this work, we highlight the necessity of building autocalibration into NLOS reconstruction in order to handle mis-calibration. We propose a forward model of NLOS measurements that is differentiable with respect to both, the hidden scene albedo, and virtual illumination and detector positions. With only a mean squared error loss and no regularization, our model enables joint reconstruction and recovery of calibration parameters by minimizing the measurement residual using gradient descent. We demonstrate our method is able to produce robust reconstructions using simulated and real data where the calibration error applied causes other state of the art algorithms to fail.      
### 37.Enhancing Feasibility and Safety of Nonlinear Model Predictive Control with Discrete-Time Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2105.10596.pdf)
>  Safety is one of the fundamental problems in robotics. Recently, one-step or multi-step optimal control problems for discrete-time nonlinear dynamical system are formulated to offer tracking stability using control Lyapunov functions (CLFs) while subject to input constraints as well as safety-critical constraints using control barrier functions (CBFs). The limitations of these existing approaches are mainly about feasibility and safety. In the existing approaches, the optimization feasibility and the system safety cannot be enhanced at the same time theoretically. In this paper, we propose two formulations that unifies CLFs and CBFs under the framework of nonlinear model predictive control (NMPC). In the proposed formulations, safety criteria is commonly formulated as CBF constraints and stability performance is ensured with either a terminal cost function or CLF constraints. Relaxing variables are introduced on the CBF constraints to resolve the tradeoff between feasibility and safety so that they can be enhanced at the same. The advantages about feasibility and safety of proposed formulations compared with existing methods are analyzed theoretically and validated with numerical results.      
### 38.Hyper-Convolution Networks for Biomedical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2105.10559.pdf)
>  The convolution operation is a central building block of neural network architectures widely used in computer vision. The size of the convolution kernels determines both the expressiveness of convolutional neural networks (CNN), as well as the number of learnable parameters. Increasing the network capacity to capture rich pixel relationships requires increasing the number of learnable parameters, often leading to overfitting and/or lack of robustness. In this paper, we propose a powerful novel building block, the hyper-convolution, which implicitly represents the convolution kernel as a function of kernel coordinates. Hyper-convolutions enable decoupling the kernel size, and hence its receptive field, from the number of learnable parameters. In our experiments, focused on challenging biomedical image segmentation tasks, we demonstrate that replacing regular convolutions with hyper-convolutions leads to more efficient architectures that achieve improved accuracy. Our analysis also shows that learned hyper-convolutions are naturally regularized, which can offer better generalization performance. We believe that hyper-convolutions can be a powerful building block in future neural network architectures solving computer vision tasks.      
### 39.Prostate Gland Segmentation in Histology Images via Residual and Multi-Resolution U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2105.10556.pdf)
>  Prostate cancer is one of the most prevalent cancers worldwide. One of the key factors in reducing its mortality is based on early detection. The computer-aided diagnosis systems for this task are based on the glandular structural analysis in histology images. Hence, accurate gland detection and segmentation is crucial for a successful prediction. The methodological basis of this work is a prostate gland segmentation based on U-Net convolutional neural network architectures modified with residual and multi-resolution blocks, trained using data augmentation techniques. The residual configuration outperforms in the test subset the previous state-of-the-art approaches in an image-level comparison, reaching an average Dice Index of 0.77.      
### 40.On the Optimality of the Stationary Solution of Secrecy Rate Maximization for MIMO Wiretap Channel  [ :arrow_down: ](https://arxiv.org/pdf/2105.11415.pdf)
>  To achieve perfect secrecy in a multiple-input multiple-output (MIMO) Gaussian wiretap channel (WTC), we need to find its secrecy capacity and optimal signaling, which involves solving a difference of convex functions program known to be non-convex for the non-degraded case. To deal with this, a class of existing solutions have been developed but only local optimality is guaranteed by standard convergence analysis. Interestingly, our extensive numerical experiments have shown that these local optimization methods indeed achieve global optimality. In this paper, we provide an analytical proof for this observation. To achieve this, we show that the Karush-Kuhn-Tucker (KKT) conditions of the secrecy rate maximization problem admit a unique solution for both degraded and non-degraded cases. Motivated by this, we also propose a low-complexity algorithm to find a stationary point. Numerical results are presented to verify the theoretical analysis.      
### 41.The role of frustration in collective decision-making dynamical processes on multiagent signed networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.11396.pdf)
>  In this work we consider a collective decision-making process in a network of agents described by a nonlinear interconnected dynamical model with sigmoidal nonlinearities and signed interaction graph. The decisions are encoded in the equilibria of the system. The aim is to investigate this multiagent system when the signed graph representing the community is not structurally balanced and in particular as we vary its frustration, i.e., its distance to structural balance. The model exhibits bifurcations, and a ``social effort'' parameter, added to the model to represent the strength of the interactions between the agents, plays the role of bifurcation parameter in our analysis. We show that, as the social effort increases, the decision-making dynamics exhibits a pitchfork bifurcation behavior where, from a deadlock situation of ``no decision'' (i.e., the origin is the only globally stable equilibrium point), two possible (alternative) decision states for the community are achieved (corresponding to two nonzero locally stable equilibria). The value of social effort for which the bifurcation is crossed (and a decision is reached) increases with the frustration of the signed network.      
### 42.Dynamic region proposal networks for semantic segmentation in automated glaucoma screening  [ :arrow_down: ](https://arxiv.org/pdf/2105.11364.pdf)
>  Screening for the diagnosis of glaucoma through a fundus image can be determined by the optic cup to disc diameter ratio (CDR), which requires the segmentation of the cup and disc regions. In this paper, we propose two novel approaches, namely Parameter-Shared Branched Network (PSBN) andWeak Region of Interest Model-based segmentation (WRoIM) to identify disc and cup boundaries. Unlike the previous approaches, the proposed methods are trained end-to-end through a single neural network architecture and use dynamic cropping instead of manual or traditional computer vision-based cropping. We are able to achieve similar performance as that of state-of-the-art approaches with less number of network parameters. Our experiments include comparison with different best known methods on publicly available Drishti-GS1 and RIM-ONE v3 datasets. With $7.8 \times 10^6$ parameters our approach achieves a Dice score of 0.96/0.89 for disc/cup segmentation on Drishti-GS1 data whereas the existing state-of-the-art approach uses $19.8\times 10^6$ parameters to achieve a dice score of 0.97/0.89.      
### 43.Change Point Detection in Nonstationary Sub-Hourly Wind Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2105.11353.pdf)
>  In this paper, we present a change point detection method for detecting change points in multivariate nonstationary wind speed time series. The change point method identifies changes in the covariance structure and decomposes the nonstationary multivariate time series into stationary segments. We also present parametric and nonparametric simulation techniques to simulate new wind time series within each stationary segment. The proposed simulation methods retain statistical properties of the original time series and therefore, can be employed for simulation-based analysis of power systems planning and operations problems. We demonstrate the capabilities of the change point detection method through computational experiments conducted on wind speed time series at five-minute resolution. We also conduct experiments on the economic dispatch problem to illustrate the impact of nonstationarity in wind generation on conventional generation and location marginal prices.      
### 44.Low-Rank Hankel Tensor Completion for Traffic Speed Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2105.11335.pdf)
>  This paper studies the traffic state estimation (TSE) problem using sparse observations from mobile sensors. TSE can be considered a spatiotemporal interpolation problem in which the evolution of traffic variables (e.g., speed/density) is governed by traffic flow dynamics (e.g., partial differential equations). Most existing TSE methods either rely on well-defined physical traffic flow models or require large amounts of simulation data as input to train machine learning models. Different from previous studies, in this paper we propose a purely data-driven and model-free solution. We consider TSE as a spatiotemporal matrix completion/interpolation problem, and apply spatiotemporal Hankel delay embedding to transforms the original incomplete matrix to a fourth-order tensor. By imposing a low-rank assumption on this tensor structure, we can approximate and characterize both global patterns and the unknown and complex local spatiotemporal dynamics in a data-driven manner. We use the truncated nuclear norm of the spatiotemporal unfolding (i.e., square norm) to approximate the tensor rank and develop an efficient solution algorithm based on the Alternating Direction Method of Multipliers (ADMM). The proposed framework only involves two hyperparameters -- spatial and temporal window lengths, which are easy to set given the degree of data sparsity. We conduct numerical experiments on both synthetic simulation data and real-world high-resolution trajectory data, and our results demonstrate the effectiveness and superiority of the proposed model in some challenging scenarios.      
### 45.Physical Layer Security for UAV Communications in 5G and Beyond Networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.11332.pdf)
>  Due to its high mobility and flexible deployment, unmanned aerial vehicle (UAV) is drawing unprecedented interest in both military and civil applications to enable agile wireless communications and provide ubiquitous connectivity. Mainly operating in an open environment, UAV communications can benefit from dominant line-of-sight links; however, it on the other hand renders the UAVs more vulnerable to malicious eavesdropping or jamming attacks. Recently, physical layer security (PLS), which exploits the inherent randomness of the wireless channels for secure communications, has been introduced to UAV systems as an important complement to the conventional cryptography-based approaches. In this paper, a comprehensive survey on the current achievements of the UAV-aided wireless communications is conducted from the PLS perspective. We first introduce the basic concepts of UAV communications including the typical static/mobile deployment scenarios, the unique characteristics of air-to-ground channels, as well as various roles that a UAV may act when PLS is concerned. Then, we introduce the widely used secrecy performance metrics and start by reviewing the secrecy performance analysis and enhancing techniques for statically deployed UAV systems, and extend the discussion to a more general scenario where the UAVs' mobility is further exploited. For both cases, respectively, we summarize the commonly adopted methodologies in the corresponding analysis and design, then describe important works in the literature in detail. Finally, potential research directions and challenges are discussed to provide an outlook for future works in the area of UAV-PLS in 5G and beyond networks.      
### 46.Fixed-Dimensional and Permutation Invariant State Representation of Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2105.11299.pdf)
>  In this paper, we propose a new state representation method, called encoding sum and concatenation (ESC), for the state representation of decision-making in autonomous driving. Unlike existing state representation methods, ESC is applicable to a variable number of surrounding vehicles and eliminates the need for manually pre-designed sorting rules, leading to higher representation ability and generality. The proposed ESC method introduces a representation neural network (NN) to encode each surrounding vehicle into an encoding vector, and then adds these vectors to obtain the representation vector of the set of surrounding vehicles. By concatenating the set representation with other variables, such as indicators of the ego vehicle and road, we realize the fixed-dimensional and permutation invariant state representation. This paper has further proved that the proposed ESC method can realize the injective representation if the output dimension of the representation NN is greater than the number of variables of all surrounding vehicles. This means that by taking the ESC representation as policy inputs, we can find the nearly optimal representation NN and policy NN by simultaneously optimizing them using gradient-based updating. Experiments demonstrate that compared with the fixed-permutation representation method, the proposed method improves the representation ability of the surrounding vehicles, and the corresponding approximation error is reduced by 62.2%.      
### 47.What is the State of the Art of Computer Vision-Assisted Cytology? A Systematic Literature Review  [ :arrow_down: ](https://arxiv.org/pdf/2105.11277.pdf)
>  Cytology is a low-cost and non-invasive diagnostic procedure employed to support the diagnosis of a broad range of pathologies. Computer Vision technologies, by automatically generating quantitative and objective descriptions of examinations' contents, can help minimize the chances of misdiagnoses and shorten the time required for analysis. To identify the state-of-art of computer vision techniques currently applied to cytology, we conducted a Systematic Literature Review. We analyzed papers published in the last 5 years. The initial search was executed in September 2020 and resulted in 431 articles. After applying the inclusion/exclusion criteria, 157 papers remained, which we analyzed to build a picture of the tendencies and problems present in this research area, highlighting the computer vision methods, staining techniques, evaluation metrics, and the availability of the used datasets and computer code. As a result, we identified that the most used methods in the analyzed works are deep learning-based (70 papers), while fewer works employ classic computer vision only (101 papers). The most recurrent metric used for classification and object detection was the accuracy (33 papers and 5 papers), while for segmentation it was the Dice Similarity Coefficient (38 papers). Regarding staining techniques, Papanicolaou was the most employed one (130 papers), followed by H&amp;E (20 papers) and Feulgen (5 papers). Twelve of the datasets used in the papers are publicly available, with the DTU/Herlev dataset being the most used one. We conclude that there still is a lack of high-quality datasets for many types of stains and most of the works are not mature enough to be applied in a daily clinical diagnostic routine. We also identified a growing tendency towards adopting deep learning-based approaches as the methods of choice.      
### 48.Application of Opportunistic Bit to Multilevel Codes  [ :arrow_down: ](https://arxiv.org/pdf/2105.11273.pdf)
>  In this paper, we propose a new signal organization method to work in the structure of the multi level coding (MLC). The transmit bits are divided into opportunistic bit (OB) and conventional bit (CB), which are mapped to the lower level- and higher level signal in parallel to the MLC, respectively. Because the OB's mapping does not require signal power explicitly, the energy of the CB modulated symbol can be doubled. As the result, the overall mutual information of the proposed method is found higher than that of the conventional BPSK in one dimensional case. Moreover, the extension of the method to the two-complex-dimension shows the better performance over the QPSK. The numerical results confirm this approach.      
### 49.A Practical Consideration on Convex Mutual Information  [ :arrow_down: ](https://arxiv.org/pdf/2105.11272.pdf)
>  In this paper, we focus on the convex mutual information, which was found at the lowest level split in multilevel coding schemes with communications over the additive white Gaussian noise (AWGN) channel. Theoretical analysis shows that communication achievable rates (ARs) do not necessarily below mutual information in the convex region. In addition, simulation results are provided as an evidence.      
### 50.On Incremental Structure-from-Motion using Lines  [ :arrow_down: ](https://arxiv.org/pdf/2105.11196.pdf)
>  Humans tend to build environments with structure, which consists of mainly planar surfaces. From the intersection of planar surfaces arise straight lines. Lines have more degrees-of-freedom than points. Thus, line-based Structure-from-Motion (SfM) provides more information about the environment. In this paper, we present solutions for SfM using lines, namely, incremental SfM. These approaches consist of designing state observers for a camera's dynamical visual system looking at a 3D line. We start by presenting a model that uses spherical coordinates for representing the line's moment vector. We show that this parameterization has singularities, and therefore we introduce a more suitable model that considers the line's moment and shortest viewing ray. Concerning the observers, we present two different methodologies. The first uses a memory-less state-of-the-art framework for dynamic visual systems. Since the previous states of the robotic agent are accessible -- while performing the 3D mapping of the environment -- the second approach aims at exploiting the use of memory to improve the estimation accuracy and convergence speed. The two models and the two observers are evaluated in simulation and real data, where mobile and manipulator robots are used.      
### 51.Interplay Between NOMA and GSSK: Detection Strategies and Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2105.11186.pdf)
>  Non-orthogonal multiple access (NOMA) is a technology enabler for the fifth generation and beyond networks, which has shown a great flexibility such that it can be readily integrated with other wireless technologies. In this paper, we investigate the interplay between NOMA and generalized space shift keying (GSSK) in a hybrid NOMA-GSSK (N-GSSK) network. Specifically, we provide a comprehensive analytical framework and propose a novel suboptimal energy-based maximum likelihood (ML) detector for the N-GSSK scheme. The proposed ML decoder exploits the energy of the received signals in order to estimate the active antenna indices. Its performance is investigated in terms of pairwise error probability, bit error rate union bound, and achievable rate. Finally, we establish the validity of our analysis through Monte-Carlo simulations and demonstrate that N-GSSK outperforms conventional NOMA and GSSK, particularly in terms of spectral efficiency.      
### 52.Frequency Permutations for Joint Radar and Communications  [ :arrow_down: ](https://arxiv.org/pdf/2105.11106.pdf)
>  This paper presents a new joint radar and communication technique based on the classical stepped frequency radar waveform. The randomization in the waveform, which is achieved by using permutations of the sequence of frequency tones, is utilized for data transmission. A new signaling scheme is proposed in which the mapping between incoming data and waveforms is performed based on an efficient combinatorial transform called the Lehmer code. Considering the optimum maximum likelihood (ML) detection, the union bound and the nearest neighbour approximation on the communication block error probability is derived for communication in an additive white Gaussian noise (AWGN) channel. The results are further extended to incorporate the Rician fading channel model, of which the Rayleigh fading channel model is presented as a special case. Furthermore, an efficient communication receiver implementation is discussed based on the Hungarian algorithm which achieves optimum performance with much less operational complexity when compared to an exhaustive search. From the radar perspective, two key analytical tools, namely, the ambiguity function (AF) and the Fisher information matrix are derived. Furthermore, accurate approximations to the Cramer-Rao lower bounds (CRLBs) on the delay and Doppler estimation errors are derived based on which the range and velocity estimation accuracy of the waveform is analysed. Numerical examples are used to highlight the accuracy of the analysis and to illustrate the performance of the proposed waveform.      
### 53.Criticality and Utility-aware Fog Computing System for Remote Health Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2105.11097.pdf)
>  Growing remote health monitoring system allows constant monitoring of the patient's condition and performance of preventive and control check-ups outside medical facilities. However, the real-time smart-healthcare application poses a delay constraint that has to be solved efficiently. Fog computing is emerging as an efficient solution for such real-time applications. Moreover, different medical centers are getting attracted to the growing IoT-based remote healthcare system in order to make a profit by hiring Fog computing resources. However, there is a need for an efficient algorithmic model for allocation of limited fog computing resources in the criticality-aware smart-healthcare system considering the profit of medical centers. Thus, the objective of this work is to maximize the system utility calculated as a linear combination of the profit of the medical center and the loss of patients. To measure profit, we propose a flat-pricing-based model. Further, we propose a swapping-based heuristic to maximize the system utility. The proposed heuristic is tested on various parameters and shown to perform close to the optimal with criticality-awareness in its core. Through extensive simulations, we show that the proposed heuristic achieves an average utility of $96\%$ of the optimal, in polynomial time complexity.      
### 54.Belief Space Planning: A Covariance Steering Approach  [ :arrow_down: ](https://arxiv.org/pdf/2105.11092.pdf)
>  A new belief space planning algorithm, called covariance steering Belief RoadMap (CS-BRM), is introduced, which is a multi-query algorithm for motion planning of dynamical systems under simultaneous motion and observation uncertainties. CS-BRM extends the probabilistic roadmap (PRM) approach to belief spaces and is based on the recently developed theory of covariance steering (CS) that enables guaranteed satisfaction of terminal belief constraints in finite-time. The nodes in the CS-BRM are sampled in belief space and represent distributions of the system states. A covariance steering controller steers the system from one BRM node to another, thus acting as an edge controller of the corresponding belief graph that ensures belief constraint satisfaction. After the edge controller is computed, a specific edge cost is assigned to that edge. The CS-BRM algorithm allows the sampling of non-stationary belief nodes, and thus is able to explore the velocity space and find efficient motion plans. The performance of CS-BRM is evaluated and compared to a previous belief space planning method, demonstrating the benefits of the proposed approach.      
### 55.Unsupervised Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2105.11084.pdf)
>  Despite rapid progress in the recent past, current speech recognition systems still require labeled training data which limits this technology to a small fraction of the languages spoken around the globe. This paper describes wav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition models without any labeled data. We leverage self-supervised speech representations to segment unlabeled audio and learn a mapping from these representations to phonemes via adversarial training. The right representations are key to the success of our method. Compared to the best previous unsupervised work, wav2vec-U reduces the phoneme error rate on the TIMIT benchmark from 26.1 to 11.3. On the larger English Librispeech benchmark, wav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the best published systems trained on 960 hours of labeled data from only two years ago. We also experiment on nine other languages, including low-resource languages such as Kyrgyz, Swahili and Tatar.      
### 56.SleepTransformer: Automatic Sleep Staging with Interpretability and Uncertainty Quantification  [ :arrow_down: ](https://arxiv.org/pdf/2105.11043.pdf)
>  Black-box skepticism is one of the main hindrances impeding deep-learning-based automatic sleep scoring from being used in clinical environments. Towards interpretability, this work proposes a sequence-to-sequence sleep-staging model, namely SleepTransformer. It is based on the transformer backbone whose self-attention scores offer interpretability of the model's decisions at both the epoch and sequence level. At the epoch level, the attention scores can be encoded as a heat map to highlight sleep-relevant features captured from the input EEG signal. At the sequence level, the attention scores are visualized as the influence of different neighboring epochs in an input sequence (i.e. the context) to recognition of a target epoch, mimicking the way manual scoring is done by human experts. We further propose a simple yet efficient method to quantify uncertainty in the model's decisions. The method, which is based on entropy, can serve as a metric for deferring low-confidence epochs to a human expert for further inspection. Additionally, we demonstrate that the proposed SleepTransformer outperforms existing methods at a lower computational cost and achieves state-of-the-art performance on two experimental databases of different sizes.      
### 57.Digital-Twin-Based Improvements to Diagnosis, Prognosis, Strategy Assessment, and Discrepancy Checking in a Nearly Autonomous Management and Control System  [ :arrow_down: ](https://arxiv.org/pdf/2105.11039.pdf)
>  The Nearly Autonomous Management and Control System (NAMAC) is a comprehensive control system that assists plant operations by furnishing control recommendations to operators in a broad class of situations. This study refines a NAMAC system for making reasonable recommendations during complex loss-of-flow scenarios with a validated Experimental Breeder Reactor II simulator, digital twins improved by machine-learning algorithms, a multi-attribute decision-making scheme, and a discrepancy checker for identifying unexpected recommendation effects. We assessed the performance of each NAMAC component, while we demonstrated and evaluated the capability of NAMAC in a class of loss-of-flow scenarios.      
### 58.Distributed CNN Inference on Resource-Constrained UAVs for Surveillance Systems: Design and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2105.11013.pdf)
>  Unmanned Aerial Vehicles (UAVs) have attracted great interest in the last few years owing to their ability to cover large areas and access difficult and hazardous target zones, which is not the case of traditional systems relying on direct observations obtained from fixed cameras and sensors. Furthermore, thanks to the advancements in computer vision and machine learning, UAVs are being adopted for a broad range of solutions and applications. However, Deep Neural Networks (DNNs) are progressing toward deeper and complex models that prevent them from being executed on-board. In this paper, we propose a DNN distribution methodology within UAVs to enable data classification in resource-constrained devices and avoid extra delays introduced by the server-based solutions due to data communication over air-to-ground links. The proposed method is formulated as an optimization problem that aims to minimize the latency between data collection and decision-making while considering the mobility model and the resource constraints of the UAVs as part of the air-to-air communication. We also introduce the mobility prediction to adapt our system to the dynamics of UAVs and the network variation. The simulation conducted to evaluate the performance and benchmark the proposed methods, namely Optimal UAV-based Layer Distribution (OULD) and OULD with Mobility Prediction (OULD-MP), were run in an HPC cluster. The obtained results show that our optimization solution outperforms the existing and heuristic-based approaches.      
### 59.Graph-based Detection of Multiuser Impulse Radio Systems  [ :arrow_down: ](https://arxiv.org/pdf/2105.10913.pdf)
>  Impulse-Radio (IR) is a wideband modulation technique that can support multiple users by employing random Time-Hopping (TH) combined with repeated transmissions. The latter is aimed at alleviating the impact of collisions. This work employs a graphical model for describing the multiuser system which, in turn, facilitates the inclusion of general coding schemes. Based on factor graph representation of the system, several iterative multiuser detectors are presented. These detectors are applicable for any binary linear coding scheme. The performance of the proposed multiuser detectors is evaluated via simulations revealing large gains with low complexity.      
### 60.Synchronous Pre-biasing of Triboelectric Nanogenerator for Enhanced Energy Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2105.10856.pdf)
>  Triboelectric Nanogenerator (TENG) is a class of ambient mechanical energy harvesters used to augment the battery life of electronic devices such as sensors in implantables, wearables, and Internet of Things (IoT) applications. In this work, the fundamentals of pre-biasing (pre-charging) the TENG at the start of the operation cycle to enhance the per-cycle extracted energy is presented. The energy gain is mathematically formulated, and the optimum pre-biasing voltage (equivalently charge) is derived by analyzing the energy exchange between the mechanical and the electrical domain over a periodic cycle. Further, a novel Energy Extraction Circuit (EEC) termed as "Pre-biased Synchronous Charge Extraction (pSCE)" is introduced to 1) Realize synchronous pre-biasing of TENG using the load battery itself and 2) Achieve enhanced energy extraction from TENG. Energy output per-cycle is derived analytically for the pSCE circuit and compared to the state of the art Synchronous Charge Extraction (SCE) circuit. The experimental implementation is performed for the proposed pSCE circuit that shows a 6.65 fold gain over the Full Wave Rectifier (standard EEC) and 1.45 over the SCE circuit for a 5V battery load.      
### 61.Quanta in sound, the sound of quanta: a voice-informed quantum theoretical perspective on sound  [ :arrow_down: ](https://arxiv.org/pdf/2105.10781.pdf)
>  Humans have a privileged, embodied way to explore the world of sounds, through vocal imitation. The Quantum Vocal Theory of Sounds (QVTS) starts from the assumption that any sound can be expressed and described as the evolution of a superposition of vocal states, i.e., phonation, turbulence, and supraglottal myoelastic vibrations. The postulates of quantum mechanics, with the notions of observable, measurement, and time evolution of state, provide a model that can be used for sound processing, in both directions of analysis and synthesis. QVTS can give a quantum-theoretic explanation to some auditory streaming phenomena, eventually leading to practical solutions of relevant sound-processing problems, or it can be creatively exploited to manipulate superpositions of sonic elements. Perhaps more importantly, QVTS may be a fertile ground to host a dialogue between physicists, computer scientists, musicians, and sound designers, possibly giving us unheard manifestations of human creativity.      
### 62.Finite Blocklength Secrecy Analysis of Polar and Reed-Muller Codes in BEC Semi-Deterministic Wiretap Channels  [ :arrow_down: ](https://arxiv.org/pdf/2105.10747.pdf)
>  In this paper, we consider a semi-deterministic wiretap channel where the main channel is noiseless and the eavesdropper's channel is a binary erasure channel (BEC). We provide a lower bound for the achievable secrecy rates of polar and Reed Muller codes and compare it to the second order coding rate for the semi-deterministic wiretap channel. To the best of our knowledge, this is the first work which demonstrates the secrecy performance of polar and Reed-Muller codes in short blocklengths. The results show that under a total variation secrecy metric, Reed Muller codes can achieve secrecy rates very close to the second order approximation rate. On the other hand, we observe a significant gap between the lower bound for the achievable rates of polar codes and the the second order approximation rate for short blocklengths.      
### 63.Centralized Learning of the Distributed Downlink Channel Estimators in FDD Systems using Uplink Data  [ :arrow_down: ](https://arxiv.org/pdf/2105.10746.pdf)
>  In this work, we propose a convolutional neural network (CNN) based low-complexity approach for downlink (DL) channel estimation (CE) in frequency division duplex (FDD) systems. In contrast to existing work, we use training data which solely stems from the uplink (UL) domain. This allows us to learn the CNN centralized at the base station (BS). After training, the network parameters are offloaded to mobile terminals (MTs) within the coverage area of the BS. The MTs can then obtain channel state information (CSI) of the MIMO channels with the low-complexity CNN estimator. This circumvents the necessity of an infeasible amount of feedback, the acquisition of training data at the user, and the offline training phase at each MT. Numerical results show that the CNN which is trained solely on UL data performs equally well as the network trained on DL data. Furthermore, the approach is able to outperform state-of-the-art CE algorithms.      
### 64.Q-learning algorithm for resource allocation in WDMA-based optical wireless communication networks  [ :arrow_down: ](https://arxiv.org/pdf/2105.10729.pdf)
>  Visible Light Communication (VLC) has been widely investigated during the last decade due to its ability to provide high data rates with low power consumption. In general, resource management is an important issue in cellular networks that can highly effect their performance. In this paper, an optimisation problem is formulated to assign each user to an optimal access point and a wavelength at a given time. This problem can be solved using mixed integer linear programming (MILP). However, using MILP is not considered a practical solution due to its complexity and memory requirements. In addition, accurate information must be provided to perform the resource allocation. Therefore, the optimisation problem is reformulated using reinforcement learning (RL), which has recently received tremendous interest due to its ability to interact with any environment without prior knowledge. In this paper, we investigate solving the resource allocation optimisation problem in VLC systems using the basic Q-learning algorithm. Two scenarios are simulated to compare the results with the previously proposed MILP model. The results demonstrate the ability of the Q-learning algorithm to provide optimal solutions close to the MILP model without prior knowledge of the system.      
### 65.Trade-off Energy and Spectral Efficiency in 5G Massive MIMO System  [ :arrow_down: ](https://arxiv.org/pdf/2105.10722.pdf)
>  A massive multiple input multiple-output system is very important to optimize the trade-off energy efficiency and spectral efficiency in fifth-generation cellular networks. The challenges for the next generation depend on increasing the high data traffic in the wireless communication system for both EE and SE. In this paper, the trade off energy efficiency and spectral efficiency based on the first derivative of transmit antennas and transmit power in a downlink massive MIMO system has been investigated. The trade off EE-SE by using a multiobjective optimization problem to decrease transmit power has been analyzed. The EE and SE based on constraint maximum transmit power allocation and a number of antennas by computing the first derivative of transmit power to maximize the trade-off energy efficiency and spectral efficiency has been improved. From the simulation results, the optimum trade-off between EE and SE can be obtained based on the first derivative by selecting the optimal antennas with a low cost of transmit power. Therefore, based on an optimal optimization problem is flexible to make trade-offs between EE-SE for distinct preferences      
### 66.Denoising Noisy Neural Networks: A Bayesian Approach with Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2105.10699.pdf)
>  Noisy neural networks (NoisyNNs) refer to the inference and training of NNs in the presence of noise. Noise is inherent in most communication and storage systems; hence, NoisyNNs emerge in many new applications, including federated edge learning, where wireless devices collaboratively train a NN over a noisy wireless channel, or when NNs are implemented/stored in an analog storage medium. This paper studies a fundamental problem of NoisyNNs: how to estimate the uncontaminated NN weights from their noisy observations or manifestations. Whereas all prior works relied on the maximum likelihood (ML) estimation to maximize the likelihood function of the estimated NN weights, this paper demonstrates that the ML estimator is in general suboptimal. To overcome the suboptimality of the conventional ML estimator, we put forth an $\text{MMSE}_{pb}$ estimator to minimize a compensated mean squared error (MSE) with a population compensator and a bias compensator. Our approach works well for NoisyNNs arising in both 1) noisy inference, where noise is introduced only in the inference phase on the already-trained NN weights; and 2) noisy training, where noise is introduced over the course of training. Extensive experiments on the CIFAR-10 and SST-2 datasets with different NN architectures verify the significant performance gains of the $\text{MMSE}_{pb}$ estimator over the ML estimator when used to denoise the NoisyNN. For noisy inference, the average gains are up to $156\%$ for a noisy ResNet34 model and $14.7\%$ for a noisy BERT model; for noisy training, the average gains are up to $18.1$ dB for a noisy ResNet18 model.      
### 67.Estimation of lunar surface dielectric constant using MiniRF SAR data  [ :arrow_down: ](https://arxiv.org/pdf/2105.10670.pdf)
>  A new model has been developed to estimate the dielectric constant of the lunar surface using Synthetic Aperture Radar (SAR) data. Continuous investigation on the dielectric constant of the lunar surface is a high priority task due to future lunar mission's goals and possible exploration of human outposts. For this purpose, derived anisotropy and backscattering coefficients of SAR images are used. The SAR images are obtained from Miniature Radio Frequency (MiniRF) radar onboard Lunar Reconnaissance Orbiter (LRO). These images are available in the form of Stokes parameters, which are used to derive the coherency matrix. The derived coherency matrix is further represented in terms of particle anisotropy. This coherency matrix's elements compared with Cloud's coherency matrix, which results in the new relationship between particle anisotropy and coherency matrix elements (backscattering coefficients). Following this, estimated anisotropy is used to determine the dielectric constant. Our model estimates the dielectric constant of the lunar surface without parallax error. The produce results are also comparable with the earlier estimate. As an advantageous, our method estimates the dielectric constant without any apriori information about the density or composition of lunar surface materials. The proposed approach can also be useful for determining the dielectric properties of Mars and other celestial bodies.      
### 68.Runtime Enforcement of Programmable Logic Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2105.10668.pdf)
>  With the advent of Industry 4.0, industrial facilities and critical infrastructures are transforming into an ecosystem of heterogeneous physical and cyber components, such as programmable logic controllers, increasingly interconnected and therefore exposed to cyber-physical attacks, i.e., security breaches in cyberspace that may adversely affect the physical processes underlying industrial control systems. In this paper, we propose a formal approach} based on runtime enforcement to ensure specification compliance in networks of controllers, possibly compromised by colluding malware that may tamper with actuator commands, sensor readings, and inter-controller communications. Our approach relies on an ad-hoc sub-class of Ligatti et al.'s edit automata to enforce controllers represented in Hennessy and Regan's Timed Process Language. We define a synthesis algorithm that, given an alphabet $P$ of observable actions and a regular timed correctness property $e$, returns a monitor that enforces the property $e$ during the execution of any (potentially corrupted) controller with alphabet $P$, and complying with the property $e$. Our monitors correct and suppress incorrect actions coming from corrupted controllers and emit actions in full autonomy when the controller under scrutiny is not able to do so in a correct manner. Besides classical requirements, such as transparency and soundness, the proposed enforcement enjoys deadlock- and diverge-freedom of monitored controllers, together with scalability when dealing with networks of controllers. Finally, we test the proposed enforcement mechanism on a non-trivial case study, taken from the context of industrial water treatment systems, in which the controllers are injected with different malware with different malicious goals.      
### 69.Post-Radiotherapy PET Image Outcome Prediction by Deep Learning under Biological Model Guidance: A Feasibility Study of Oropharyngeal Cancer Application  [ :arrow_down: ](https://arxiv.org/pdf/2105.10650.pdf)
>  This paper develops a method of biologically guided deep learning for post-radiation FDG-PET image outcome prediction based on pre-radiation images and radiotherapy dose information. Based on the classic reaction-diffusion mechanism, a novel biological model was proposed using a partial differential equation that incorporates spatial radiation dose distribution as a patient-specific treatment information variable. A 7-layer encoder-decoder-based convolutional neural network (CNN) was designed and trained to learn the proposed biological model. As such, the model could generate post-radiation FDG-PET image outcome predictions with possible time-series transition from pre-radiotherapy image states to post-radiotherapy states. The proposed method was developed using 64 oropharyngeal patients with paired FDG-PET studies before and after 20Gy delivery (2Gy/daily fraction) by IMRT. In a two-branch deep learning execution, the proposed CNN learns specific terms in the biological model from paired FDG-PET images and spatial dose distribution as in one branch, and the biological model generates post-20Gy FDG-PET image prediction in the other branch. The proposed method successfully generated post-20Gy FDG-PET image outcome prediction with breakdown illustrations of biological model components. Time-series FDG-PET image predictions were generated to demonstrate the feasibility of disease response rendering. The developed biologically guided deep learning method achieved post-20Gy FDG-PET image outcome predictions in good agreement with ground-truth results. With break-down biological modeling components, the outcome image predictions could be used in adaptive radiotherapy decision-making to optimize personalized plans for the best outcome in the future.      
### 70.Searching Collaborative Agents for Multi-plane Localization in 3D Ultrasound  [ :arrow_down: ](https://arxiv.org/pdf/2105.10626.pdf)
>  3D ultrasound (US) has become prevalent due to its rich spatial and diagnostic information not contained in 2D US. Moreover, 3D US can contain multiple standard planes (SPs) in one shot. Thus, automatically localizing SPs in 3D US has the potential to improve user-independence and scanning-efficiency. However, manual SP localization in 3D US is challenging because of the low image quality, huge search space and large anatomical variability. In this work, we propose a novel multi-agent reinforcement learning (MARL) framework to simultaneously localize multiple SPs in 3D US. Our contribution is four-fold. First, our proposed method is general and it can accurately localize multiple SPs in different challenging US datasets. Second, we equip the MARL system with a recurrent neural network (RNN) based collaborative module, which can strengthen the communication among agents and learn the spatial relationship among planes effectively. Third, we explore to adopt the neural architecture search (NAS) to automatically design the network architecture of both the agents and the collaborative module. Last, we believe we are the first to realize automatic SP localization in pelvic US volumes, and note that our approach can handle both normal and abnormal uterus cases. Extensively validated on two challenging datasets of the uterus and fetal brain, our proposed method achieves the average localization accuracy of 7.03 degrees/1.59mm and 9.75 degrees/1.19mm. Experimental results show that our light-weight MARL model has higher accuracy than state-of-the-art methods.      
### 71.COVID-19 Detection Using Recorded Coughs in the 2021 DiCOVA Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2105.10619.pdf)
>  COVID-19 has resulted in over 100 million infections and caused worldwide lock downs due to its high transmission rate and limited testing options. Current diagnostic tests can be expensive, limited in availability, time-intensive and require risky in-person appointments. It has been established that symptomatic COVID-19 seriously impairs normal functioning of the respiratory system, thus affecting the coughing acoustics. The 2021 DiCOVA Challenge @ INTERSPEECH was designed to find scientific and engineering insights to the question by enabling participants to analyze an acoustic dataset gathered from COVID-19 positive and non-COVID-19 individuals. In this report we describe our participation in the Challenge (Track 1). We achieved 82.37% AUC ROC on the blind test outperforming the Challenge's baseline of 69.85%.      
### 72.Soft robotic suits: State of the art, core technologies and open challenges  [ :arrow_down: ](https://arxiv.org/pdf/2105.10588.pdf)
>  Wearable robots are undergoing a disruptive transition, from the rigid machines that populated the science-fiction world in the early eighties to lightweight robotic apparel, hardly distinguishable from our daily clothes. In less than a decade of development, soft robotic suits have achieved important results in human motor assistance and augmentation. In this paper, we start by giving a definition of soft robotic suits and proposing a taxonomy to classify existing systems. We then critically review the modes of actuation, the physical human-robot interface and the intention-detection strategies of state of the art soft robotic suits, highlighting the advantages and limitations of different approaches. Finally, we discuss the impact of this new technology on human movements, for both augmenting human function and supporting motor impairments, and identify areas that are in need of further development.      
### 73.A model-based technique to identify lubrication condition of hydrodynamic bearings using the rotor vibrational response  [ :arrow_down: ](https://arxiv.org/pdf/2105.10573.pdf)
>  Faults related to hydrodynamic bearing can imply in high maintenance costs when late-detected and even to the total shutdown of the system. Thus, techniques of early fault diagnosis have high relevance to the reliability of rotating machinery. However, a common fault caused by inadequate bearing oil supply has not yet received appropriate attention. This paper presents a new approach to model and identify starved or excessive oil supply in hydrodynamic bearings. The developed identification technique is a model-based process that uses the rotor vibration signal to access the bearing lubrication. Numerical identification tests were performed and the results showed that the proposed method can satisfactorily estimate the oil flow rate in bearings under starved and flooded lubrication conditions, thus representing a useful and promising tool for condition monitoring and fault diagnosis applied to rotating machinery.      
### 74.Semi-Supervised Audio Representation Learning for Modeling Beehive Strengths  [ :arrow_down: ](https://arxiv.org/pdf/2105.10536.pdf)
>  Honey bees are critical to our ecosystem and food security as a pollinator, contributing 35% of our global agriculture yield. In spite of their importance, beekeeping is exclusively dependent on human labor and experience-derived heuristics, while requiring frequent human checkups to ensure the colony is healthy, which can disrupt the colony. Increasingly, pollinator populations are declining due to threats from climate change, pests, environmental toxicity, making their management even more critical than ever before in order to ensure sustained global food security. To start addressing this pressing challenge, we developed an integrated hardware sensing system for beehive monitoring through audio and environment measurements, and a hierarchical semi-supervised deep learning model, composed of an audio modeling module and a predictor, to model the strength of beehives. The model is trained jointly on audio reconstruction and prediction losses based on human inspections, in order to model both low-level audio features and circadian temporal dynamics. We show that this model performs well despite limited labels, and can learn an audio embedding that is useful for characterizing different sound profiles of beehives. This is the first instance to our knowledge of applying audio-based deep learning to model beehives and population size in an observational setting across a large number of hives.      
### 75.Towards a formal notion of impact metric for cyber-physical attacks (full version)  [ :arrow_down: ](https://arxiv.org/pdf/1806.10463.pdf)
>  Industrial facilities and critical infrastructures are transforming into "smart" environments that dynamically adapt to external events. The result is an ecosystem of heterogeneous physical and cyber components integrated in cyber-physical systems which are more and more exposed to cyber-physical attacks, i.e., security breaches in cyberspace that adversely affect the physical processes at the core of the systems. <br>We provide a formal compositional metric to estimate the impact of cyber-physical attacks targeting sensor devices of IoT systems formalised in a simple extension of Hennessy and Regan's Timed Process Language. Our impact metric relies on a discrete-time generalisation of Desharnais et al.'s weak bisimulation metric for concurrent systems. We show the adequacy of our definition on two different attacks on a simple surveillance system.      
### 76.A Probabilistic Calculus of Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/1707.02279.pdf)
>  We propose a hybrid probabilistic process calculus for modelling and reasoning on cyber-physical systems (CPSs). The dynamics of the calculus is expressed in terms of a probabilistic labelled transition system in the SOS style of Plotkin. This is used to define a bisimulation-based probabilistic behavioural semantics which supports compositional reasonings. For a more careful comparison between CPSs, we provide two compositional probabilistic metrics to formalise the notion of behavioural distance between systems, also in the case of bounded computations. Finally, we provide a non-trivial case study, taken from an engineering application, and use it to illustrate our definitions and our compositional behavioural theory for CPSs.      

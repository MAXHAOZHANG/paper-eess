# ArXiv eess --Thu, 1 Apr 2021
### 1.State-Dependent Processing in Payment Channel Networks for Throughput Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.17207.pdf)
>  Payment channel networks (PCNs) have emerged as a scalability solution for blockchains built on the concept of a payment channel: a setting that allows two nodes to safely transact between themselves in high frequencies based on pre-committed peer-to-peer balances. Transaction requests in these networks may be declined because of unavailability of funds due to temporary uneven distribution of the channel balances. In this paper, we investigate how to alleviate unnecessary payment blockage via proper prioritization of the transaction execution order. Specifically, we consider the scheduling problem in PCNs: as transactions continuously arrive on both sides of a channel, nodes need to decide which ones to process and when in order to maximize their objective, which in our case is the channel throughput. We introduce a stochastic model to capture the dynamics of a payment channel under random arrivals, and propose that channels can hold incoming transactions in buffers up to some deadline in order to enable more elaborate processing decisions. We describe a policy that maximizes the channel success rate/throughput for uniform transaction requests of fixed amounts, both in the presence and absence of buffering capabilities, and formally prove its optimality. We also develop a discrete event simulator of a payment channel, and evaluate different heuristic scheduling policies in the more general heterogeneous amounts case, with the results showing superiority of the heuristic extension of our policy in this case as well. Our work opens the way for more formal research on improving PCN performance via joint consideration of routing and scheduling decisions.      
### 2.Y$^2$-Net FCRN for Acoustic Echo and Noise Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2103.17189.pdf)
>  In recent years, deep neural networks (DNNs) were studied as an alternative to traditional acoustic echo cancellation (AEC) algorithms. The proposed models achieved remarkable performance for the separate tasks of AEC and residual echo suppression (RES). A promising network topology is a fully convolutional recurrent network (FCRN) structure, which has already proven its performance on both noise suppression and AEC tasks, individually. However, the combination of AEC, postfiltering, and noise suppression to a single network typically leads to a noticeable decline in the quality of the near-end speech component due to the lack of a separate loss for echo estimation. In this paper, we propose a two-stage model (Y$^2$-Net) which consists of two FCRNs, each with two inputs and one output (Y-Net). The first stage (AEC) yields an echo estimate, which - as a novelty for a DNN AEC model - is further used by the second stage to perform RES and noise suppression. While the subjective listening test of the Interspeech 2021 AEC Challenge mostly yielded results close to the baseline, the proposed method scored an average improvement of 0.46 points over the baseline on the blind testset in double-talk on the instrumental metric DECMOS, provided by the challenge organizers.      
### 3.Classification of Hematoma: Joint Learning of Semantic Segmentation and Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.17172.pdf)
>  Cerebral hematoma grows rapidly in 6-24 hours and misprediction of the growth can be fatal if it is not operated by a brain surgeon. There are two types of cerebral hematomas: one that grows rapidly and the other that does not grow rapidly. We are developing the technique of artificial intelligence to determine whether the CT image includes the cerebral hematoma which leads to the rapid growth. This problem has various difficulties: the few positive cases in this classification problem of cerebral hematoma and the targeted hematoma has deformable object. Other difficulties include the imbalance classification, the covariate shift, the small data, and the spurious correlation problems. It is difficult with the plain CNN classification such as VGG. This paper proposes the joint learning of semantic segmentation and classification and evaluate the performance of this.      
### 4.Training robust deep learning models for medical imaging tasks with spectral decoupling  [ :arrow_down: ](https://arxiv.org/pdf/2103.17171.pdf)
>  Deep neural networks show impressive performance in medical imaging tasks. However, many current networks generalise poorly to data unseen during training, for example data generated by different centres. Such behaviour can be caused by networks overfitting easy-to-learn, or statistically dominant, features while disregarding other potentially informative features. Moreover, dominant features can lead to learning spurious correlations. For instance, indistinguishable differences in the sharpness of the images from two different scanners can degrade the performance of the network significantly. <br>To address these challenges, we evaluate the utility of spectral decoupling in the context of medical image analysis. Spectral decoupling encourages the neural network to learn more features by simply regularising the networks' unnormalized prediction scores with an L2 penalty. <br>Simulation experiments show that spectral decoupling allows training neural networks on datasets with strong spurious correlations. Networks trained without spectral decoupling do not learn the original task and appear to make false predictions based on the spurious correlations. Spectral decoupling also significantly increases networks' robustness for data distribution shifts. To validate our findings, we train networks with and without spectral decoupling to detect prostate cancer on haematoxylin and eosin stained whole slide images. The networks are then evaluated with data scanned in the same centre with two different scanners, and data from a different centre. Networks trained with spectral decoupling increase the accuracy by 10 percentage points over weight decay on the dataset from a different centre. <br>Our results show that spectral decoupling allows training generalisable and robust neural networks to be used across multiple centres, and recommend its use in future medical imaging tasks.      
### 5.RIS-Assisted UAV for Timely Data Collection in IoT Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.17162.pdf)
>  Smart city services are thriving thanks to a wide range of technological advances, namely 5G communications, Internet of Things (IoT), and artificial intelligence. Central to this is the wide deployment of smart sensing devices and accordingly the large amount of harvested information to be processed for timely decision making. Robust network access is, hence, essential for offloading the collected data before a set deadline, beyond which the data loses its value. In environments where direct communication can be impaired by blockages, unmanned aerial vehicles (UAVs) can be considered as an alternative for enhancing connectivity, particularly when IoT devices (IoTDs) are constrained with their resources. Moreover, to conserve energy, IoTDs are assumed to alternate between their active and passive modes. This paper, therefore, considers a time-constrained data gathering problem from a network of sensing devices and with assistance from a UAV. A reconfigurable intelligent surface (RIS) is deployed to further improve the connectivity to the UAV, particularly when the multiple devices are served concurrently and experience different channel impairments. This integrated problem brings challenges related to the configuration of the phase shift elements of the RIS, the scheduling of IoTDs transmissions, and the trajectory of the UAV. First, the problem is formulated with the objective of maximizing the total number of served IoTDs each during its activation period. Owing to its complexity and the incomplete knowledge about the environment, we leverage deep reinforcement learning in our solution; the UAV trajectory planning is modeled as a Markov Decision Process, and Proximal Policy Optimization is invoked to solve it. Next, the RIS configuration is then handled via Block Coordinate Descent. Finally, extensive simulations are conducted to demonstrate the efficiency of our solution approach.      
### 6.Generalized State-Feedback Controller Synthesis for Underactuated Systems through Bayesian Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.17158.pdf)
>  Underactuated systems pose the challenge of being able to control a plant whose degrees of freedom are not necessarily directly linked to an actuator or where such a relationship is not straightforward. Rotary inverted pendulum is an example of such systems, which on its simplest representation consists of a pendulum whose vertical angle should be taken up to the upward unstable position based on the impulse given from another bar and an appropriate control strategy, bar that is controlled by an electrical motor. This problem is often tackled by linear control theory with state-feedback controllers that is frequently obtained by means of designing a feedback gain meeting some constraints. This article reports a Bayesian Optimization approach for designing a generalized state-feedback controller, that involves more parameters than a simple state-feedback control law, but with the benefit of achieving lower control effort in terms of the signal amplitude. The source code is made publicly available to facilitate further research.      
### 7.Federated Learning: A Signal Processing Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2103.17150.pdf)
>  The dramatic success of deep learning is largely due to the availability of data. Data samples are often acquired on edge devices, such as smart phones, vehicles and sensors, and in some cases cannot be shared due to privacy considerations. Federated learning is an emerging machine learning paradigm for training models across multiple edge devices holding local datasets, without explicitly exchanging the data. Learning in a federated manner differs from conventional centralized machine learning, and poses several core unique challenges and requirements, which are closely related to classical problems studied in the areas of signal processing and communications. Consequently, dedicated schemes derived from these areas are expected to play an important role in the success of federated learning and the transition of deep learning from the domain of centralized servers to mobile edge devices. In this article, we provide a unified systematic framework for federated learning in a manner that encapsulates and highlights the main challenges that are natural to treat using signal processing tools. We present a formulation for the federated learning paradigm from a signal processing perspective, and survey a set of candidate approaches for tackling its unique challenges. We further provide guidelines for the design and adaptation of signal processing and communication methods to facilitate federated learning at large scale.      
### 8.Lightweight UAV-based Measurement System for Air-to-Ground Channels at 28 GHz  [ :arrow_down: ](https://arxiv.org/pdf/2103.17149.pdf)
>  Wireless communication at millimeter wave frequencies has attracted considerable attention for the delivery of high-bit-rate connectivity to unmanned aerial vehicles (UAVs). However, conducting the channel measurements necessary to assess communication at these frequencies has been challenging due to the severe payload and power restrictions in commercial UAVs. This work presents a novel lightweight (approximately 1.3 kg) channel measurement system at 28 GHz installed on a commercially available UAV. A ground transmitter equipped with a horn antenna conveys sounding signals to a UAV equipped with a lightweight spectrum analyzer. We demonstrate that the measurements can be highly influenced by the antenna pattern as shaped by the UAV's frame. A calibration procedure is presented to correct for the resulting angular variations in antenna gain. The measurement setup is then validated on real flights from an airstrip at distances in excess of 300 m.      
### 9.Adversarial Attacks and Defenses for Speech Recognition Systems  [ :arrow_down: ](https://arxiv.org/pdf/2103.17122.pdf)
>  The ubiquitous presence of machine learning systems in our lives necessitates research into their vulnerabilities and appropriate countermeasures. In particular, we investigate the effectiveness of adversarial attacks and defenses against automatic speech recognition (ASR) systems. We select two ASR models - a thoroughly studied DeepSpeech model and a more recent Espresso framework Transformer encoder-decoder model. We investigate two threat models: a denial-of-service scenario where fast gradient-sign method (FGSM) or weak projected gradient descent (PGD) attacks are used to degrade the model's word error rate (WER); and a targeted scenario where a more potent imperceptible attack forces the system to recognize a specific phrase. We find that the attack transferability across the investigated ASR systems is limited. To defend the model, we use two preprocessing defenses: randomized smoothing and WaveGAN-based vocoder, and find that they significantly improve the model's adversarial robustness. We show that a WaveGAN vocoder can be a useful countermeasure to adversarial attacks on ASR systems - even when it is jointly attacked with the ASR, the target phrases' word error rate is high.      
### 10.Differentiable Deconvolution for Improved Stroke Perfusion Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.17111.pdf)
>  Perfusion imaging is the current gold standard for acute ischemic stroke analysis. It allows quantification of the salvageable and non-salvageable tissue regions (penumbra and core areas respectively). In clinical settings, the singular value decomposition (SVD) deconvolution is one of the most accepted and used approaches for generating interpretable and physically meaningful maps. Though this method has been widely validated in experimental and clinical settings, it might produce suboptimal results because the chosen inputs to the model cannot guarantee optimal performance. For the most critical input, the arterial input function (AIF), it is still controversial how and where it should be chosen even though the method is very sensitive to this input. In this work we propose an AIF selection approach that is optimized for maximal core lesion segmentation performance. The AIF is regressed by a neural network optimized through a differentiable SVD deconvolution, aiming to maximize core lesion segmentation agreement with ground truth data. To our knowledge, this is the first work exploiting a differentiable deconvolution model with neural networks. We show that our approach is able to generate AIFs without any manual annotation, and hence avoiding manual rater's influences. The method achieves manual expert performance in the ISLES18 dataset. We conclude that the methodology opens new possibilities for improving perfusion imaging quantification with deep neural networks.      
### 11.Linear systems with neural network nonlinearities: Improved stability analysis via acausal Zames-Falb multipliers  [ :arrow_down: ](https://arxiv.org/pdf/2103.17106.pdf)
>  In this paper, we analyze the stability of feedback interconnections of a linear time-invariant system with a neural network nonlinearity in discrete time. Our analysis is based on abstracting neural networks using integral quadratic constraints (IQCs), exploiting the sector-bounded and slope-restricted structure of the underlying activation functions. In contrast to existing approaches, we leverage the full potential of dynamic IQCs to describe the nonlinear activation functions in a less conservative fashion. To be precise, we consider multipliers based on the full-block Yakubovich / circle criterion in combination with acausal Zames-Falb multipliers, leading to linear matrix inequality based stability certificates. Our approach provides a flexible and versatile framework for stability analysis of feedback interconnections with neural network nonlinearities, allowing to trade off computational efficiency and conservatism. Finally, we provide numerical examples that demonstrate the applicability of the proposed framework and the achievable improvements over previous approaches.      
### 12.Low-dimensional Denoising Embedding Transformer for ECG Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.17099.pdf)
>  The transformer based model (e.g., FusingTF) has been employed recently for Electrocardiogram (ECG) signal classification. However, the high-dimensional embedding obtained via 1-D convolution and positional encoding can lead to the loss of the signal's own temporal information and a large amount of training parameters. In this paper, we propose a new method for ECG classification, called low-dimensional denoising embedding transformer (LDTF), which contains two components, i.e., low-dimensional denoising embedding (LDE) and transformer learning. In the LDE component, a low-dimensional representation of the signal is obtained in the time-frequency domain while preserving its own temporal information. And with the low dimensional embedding, the transformer learning is then used to obtain a deeper and narrower structure with fewer training parameters than that of the FusingTF. Experiments conducted on the MIT-BIH dataset demonstrates the effectiveness and the superior performance of our proposed method, as compared with state-of-the-art methods.      
### 13.Transactive Resilience in Renewable Microgrids: A Contract-Theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2103.17089.pdf)
>  Renewable energy-based microgrids play a critical role in future smart grids. Due to the uncertainties of renewable generations, the microgrids face potential risk of load shedding during operation. To address this problem, we propose a contract-based approach to enhance the resilience of microgrids. Specifically, in the framework, the microgrids who may not be self-efficient to meet their local demands can purchase the needed power from their connected microgrids by signing a contract that specifies the power price in advance. We leverage a principal-agent model to capture the energy trading relationships between the microgrids through a resilience as a service (RaaS) paradigm. By focusing on the incentive compatible and individual rational constraints of the service requester, the service provider designs the optimal contracts for the transactive resilience that yields the largest payoff despite the incomplete information. We characterize analytical solutions of the optimal contracts for several scenarios where the service requester has various options on its hidden actions. Numerical simulations are used to illustrate and corroborate the obtained results.      
### 14.Deep Noise Suppression With Non-Intrusive PESQNet Supervision Enabling the Use of Real Training Data  [ :arrow_down: ](https://arxiv.org/pdf/2103.17088.pdf)
>  Data-driven speech enhancement employing deep neural networks (DNNs) can provide state-of-the-art performance even in the presence of non-stationary noise. During the training process, most of the speech enhancement neural networks are trained in a fully supervised way with losses requiring noisy speech to be synthesized by clean speech and additive noise. However, in a real implementation, only the noisy speech mixture is available, which leads to the question, how such data could be advantageously employed in training. In this work, we propose an end-to-end non-intrusive PESQNet DNN which estimates perceptual evaluation of speech quality (PESQ) scores, allowing a reference-free loss for real data. As a further novelty, we combine the PESQNet loss with denoising and dereverberation loss terms, and train a complex mask-based fully convolutional recurrent neural network (FCRN) in a "weakly" supervised way, each training cycle employing some synthetic data, some real data, and again synthetic data to keep the PESQNet up-to-date. In a subjective listening test, our proposed framework outperforms the Interspeech 2021 Deep Noise Suppression (DNS) Challenge baseline overall by 0.09 MOS points and in particular by 0.45 background noise MOS points.      
### 15.Static extraction of memory access profiles for multi-core interference analysis of real-time tasks  [ :arrow_down: ](https://arxiv.org/pdf/2103.17082.pdf)
>  We present a static analysis framework for real-time task systems running on multi-core processors. Our method analyzes tasks in isolation at the binary level and generates worst-case timing and memory access profiles. These profiles can then be combined to perform an interference analysis at the task system level, as part of a multi-core Worst-Case Response Time (WCRT) analysis. In this paper we introduce a formal description of the models and algorithmic building blocks composing our framework. We also discuss how the memory access profiles generated by our method could be used to feed existing state-of-the-art WCRT frameworks. To the best of our knowledge, it is the first time that a method is documented on how to produce sound, safe and precise inputs for interference analysis methods.      
### 16.Green IoT using UAVs in B5G Networks: A Review of Applications and Strategies  [ :arrow_down: ](https://arxiv.org/pdf/2103.17043.pdf)
>  Unmanned Aerial Vehicles (UAVs) present a promising advanced technology that can enhance people life quality and smartness of cities dramatically and increase overall economic efficiency. UAVs have attained a significant interest in supporting many applications such as surveillance, agriculture, communication, transportation, pollution monitoring, disaster management, public safety, healthcare, and environmental preservation. Industry 4.0 applications are conceived of intelligent things that can automatically and collaboratively improve beyond 5G (B5G). Therefore, the Internet of Things (IoT) is required to ensure collaboration between the vast multitude of things efficiently anywhere in real-world applications that are monitored in real-time. However, many IoT devices consume a significant amount of energy when transmitting the collected data from surrounding environments. Due to a drone's capability to fly closer to IoT, UAV technology plays a vital role in greening IoT by transmitting collected data to achieve a sustainable, reliable, eco-friendly Industry 4.0. This survey presents an overview of the techniques and strategies proposed recently to achieve green IoT using UAVs infrastructure for a reliable and sustainable smart world. This survey is different from other attempts in terms of concept, focus, and discussion. Finally, various use cases, challenges, and opportunities regarding green IoT using UAVs are presented.      
### 17.Weighted SPICE Algorithms for Range-Doppler Imaging Using One-Bit Automotive Radar  [ :arrow_down: ](https://arxiv.org/pdf/2103.17032.pdf)
>  We consider the problem of range-Doppler imaging using one-bit automotive LFMCW1 or PMCW radar that utilizes one-bit ADC sampling with time-varying thresholds at the receiver. The one-bit sampling technique can significantly reduce the cost as well as the power consumption of automotive radar systems. We formulate the one-bit LFMCW/PMCW radar rangeDoppler imaging problem as one-bit sparse parameter estimation. The recently proposed hyperparameter-free (and hence user friendly) weighted SPICE algorithms, including SPICE, LIKES, SLIM and IAA, achieve excellent parameter estimation performance for data sampled with high precision. However, these algorithms cannot be used directly for one-bit data. In this paper we first present a regularized minimization algorithm, referred to as 1bSLIM, for accurate range-Doppler imaging using onebit radar systems. Then, we describe how to extend the SPICE, LIKES and IAA algorithms to the one-bit data case, and refer to these extensions as 1bSPICE, 1bLIKES and 1bIAA. These onebit hyperparameter-free algorithms are unified within the one-bit weighted SPICE framework. Moreover, efficient implementations of the aforementioned algorithms are investigated that rely heavily on the use of FFTs. Finally, both simulated and experimental examples are provided to demonstrate the effectiveness of the proposed algorithms for range-Doppler imaging using one-bit automotive radar systems.      
### 18.Learning Scalable $\ell_\infty$-constrained Near-lossless Image Compression via Joint Lossy Image and Residual Compression  [ :arrow_down: ](https://arxiv.org/pdf/2103.17015.pdf)
>  We propose a novel joint lossy image and residual compression framework for learning $\ell_\infty$-constrained near-lossless image compression. Specifically, we obtain a lossy reconstruction of the raw image through lossy image compression and uniformly quantize the corresponding residual to satisfy a given tight $\ell_\infty$ error bound. Suppose that the error bound is zero, i.e., lossless image compression, we formulate the joint optimization problem of compressing both the lossy image and the original residual in terms of variational auto-encoders and solve it with end-to-end training. To achieve scalable compression with the error bound larger than zero, we derive the probability model of the quantized residual by quantizing the learned probability model of the original residual, instead of training multiple networks. We further correct the bias of the derived probability model caused by the context mismatch between training and inference. Finally, the quantized residual is encoded according to the bias-corrected probability model and is concatenated with the bitstream of the compressed lossy image. Experimental results demonstrate that our near-lossless codec achieves the state-of-the-art performance for lossless and near-lossless image compression, and achieves competitive PSNR while much smaller $\ell_\infty$ error compared with lossy image codecs at high bit rates.      
### 19.Capturing Power System Dynamics by Physics-Informed Neural Networks and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2103.17004.pdf)
>  This paper proposes a tractable framework to determine key characteristics of non-linear dynamic systems by converting physics-informed neural networks to a mixed integer linear program. Our focus is on power system applications. Traditional methods in power systems require the use of a large number of simulations and other heuristics to determine parameters such as the critical clearing time, i.e. the maximum allowable time within which a disturbance must be cleared before the system moves to instability. The work proposed in this paper uses physics-informed neural networks to capture the power system dynamic behavior and, through an exact transformation, converts them to a tractable optimization problem which can be used to determine critical system indices. By converting neural networks to mixed integer linear programs, our framework also allows to adjust the conservativeness of the neural network output with respect to the existing stability boundaries. We demonstrate the performance of our methods on the non-linear dynamics of converter-based generation in response to voltage disturbances.      
### 20.Delay Analysis of Wireless Federated Learning Based on Saddle Point Approximation and Large Deviation Theory  [ :arrow_down: ](https://arxiv.org/pdf/2103.16994.pdf)
>  Federated learning (FL) is a collaborative machine learning paradigm, which enables deep learning model training over a large volume of decentralized data residing in mobile devices without accessing clients' private data. Driven by the ever increasing demand for model training of mobile applications or devices, a vast majority of FL tasks are implemented over wireless fading channels. Due to the time-varying nature of wireless channels, however, random delay occurs in both the uplink and downlink transmissions of FL. How to analyze the overall time consumption of a wireless FL task, or more specifically, a FL's delay distribution, becomes a challenging but important open problem, especially for delay-sensitive model training. In this paper, we present a unified framework to calculate the approximate delay distributions of FL over arbitrary fading channels. Specifically, saddle point approximation, extreme value theory (EVT), and large deviation theory (LDT) are jointly exploited to find the approximate delay distribution along with its tail distribution, which characterizes the quality-of-service of a wireless FL system. Simulation results will demonstrate that our approximation method achieves a small approximation error, which vanishes with the increase of training accuracy.      
### 21.Multicriteria design and experimental verification of hybrid renewable energy systems. Application to electric vehicle charging stations  [ :arrow_down: ](https://arxiv.org/pdf/2103.16976.pdf)
>  The installation of electric vehicle charging stations (EVCS) will be essential to promote the acceptance by the users of electric vehicles (EVs). However, if EVCS are exclusively supplied by the grid, negative impacts on its stability together with possible CO2 emission increases could be produced. Introduction of hybrid renewable energy systems (HRES) for EVCS can cope with both drawbacks by reducing the load on the grid and generating clean electricity. This paper develops a methodology based on a weighted multicriteria process to design the most suitable configuration for HRES in EVCS. This methodology determines the local renewable resources and the EVCS electricity demand. Then, taking into account environmental, economic and technical aspects, it deduces the most adequate HRES design for the EVCS. Besides, an experimental stage to validate the design deduced from the multicriteria process is included. Therefore, the final design for the HRES in EVCS is supported not only by a complete numerical evaluation, but also by an experimental verification of the demand being fully covered. Methodology application to Valencia (Spain) proves that an off-grid HRES with solar PV, wind resources and batteries support would be the most suitable configuration for the system. This solution was also experimentally verified.      
### 22.A Transactive Energy Market Framework Considering Network Constraints and Fairness  [ :arrow_down: ](https://arxiv.org/pdf/2103.16971.pdf)
>  The continuous penetration of distributed energy resources (DER) in the electric power grid is driving a new paradigm shift towards transactive energy system (TES), an active and more sustainable system characterized by distributed generation and energy exchanges among consumers and producers in the network. This transition, however, comes with challenges such as dealing with the nonlinear and non-convex power flows of the system, determining an optimal transaction price to maximize overall system welfare, and ensuring fairness for all participants. In this paper, we propose a three-stage transactive energy framework that aims to address these challenges. In the first stage, the cost without trading is calculated which will serve as the reference in the profit maximization problem in the next stage. DER dispatch, power flows and initial transaction payments/incentives of the participants will then be determined in the second stage. A benefit allocation algorithm is applied in the third control stage to determine the optimal transaction price and final payments/incentives that will ensure fairness for trading participants. The proposed framework was tested in an IEEE 33-bus system and results show that fair benefits are given for all participants during trading and the system operates within the network and economic constraints.      
### 23.UAV-enabled optimal position selection for secure and precise wireless transmission  [ :arrow_down: ](https://arxiv.org/pdf/2103.16903.pdf)
>  In this letter, two unmanned-aerial-vehicle (UAV) optimal position selection schemes are proposed. Based on the proposed schemes, the optimal UAV transmission positions for secure precise wireless transmission (SPWT) are given, where the maximum secrecy rate (SR) can be achieved without artificial noise (AN). In conventional SPWT schemes, the transmission location is not considered which impacts the SR a lot. The proposed schemes find the optimal transmission positions based on putting the eavesdropper at the null point. Thus, the received confidential message energy at the eavesdropper is zero, and the maximum SR achieves. Simulation results show that proposed schemes have improved the SR performance significantly.      
### 24.SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.16858.pdf)
>  In this paper, we present SpecAugment++, a novel data augmentation method for deep neural networks based acoustic scene classification (ASC). Different from other popular data augmentation methods such as SpecAugment and mixup that only work on the input space, SpecAugment++ is applied to both the input space and the hidden space of the deep neural networks to enhance the input and the intermediate feature representations. For an intermediate hidden state, the augmentation techniques consist of masking blocks of frequency channels and masking blocks of time frames, which improve generalization by enabling a model to attend not only to the most discriminative parts of the feature, but also the entire parts. Apart from using zeros for masking, we also examine two approaches for masking based on the use of other samples within the minibatch, which helps introduce noises to the networks to make them more discriminative for classification. The experimental results on the DCASE 2018 Task1 dataset and DCASE 2019 Task1 dataset show that our proposed method can obtain 3.6% and 4.7% accuracy gains over a strong baseline without augmentation (i.e. CP-ResNet) respectively, and outperforms other previous data augmentation methods.      
### 25.TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation  [ :arrow_down: ](https://arxiv.org/pdf/2103.16849.pdf)
>  In this paper, we exploit the effective way to leverage contextual information to improve the speech dereverberation performance in real-world reverberant environments. We propose a temporal-contextual attention approach on the deep neural network (DNN) for environment-aware speech dereverberation, which can adaptively attend to the contextual information. More specifically, a FullBand based Temporal Attention approach (FTA) is proposed, which models the correlations between the fullband information of the context frames. In addition, considering the difference between the attenuation of high frequency bands and low frequency bands (high frequency bands attenuate faster than low frequency bands) in the room impulse response (RIR), we also propose a SubBand based Temporal Attention approach (STA). In order to guide the network to be more aware of the reverberant environments, we jointly optimize the dereverberation network and the reverberation time (RT60) estimator in a multi-task manner. Our experimental results indicate that the proposed method outperforms our previously proposed reverberation-time-aware DNN and the learned attention weights are fully physical consistent. We also report a preliminary yet promising dereverberation and recognition experiment on real test data.      
### 26.A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for Real-time Surgical Video Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.16847.pdf)
>  Seven million people suffer complications after surgery each year. With sufficient surgical training and feedback, half of these complications could be prevented. Automatic surgical video analysis, especially for minimally invasive surgery, plays a key role in training and review, with increasing interests from recent studies on tool and workflow detection. In this research, a novel machine learning architecture, RPM-CNN, is created to perform real-time surgical video analysis. This architecture, for the first time, integrates visual simultaneous localization and mapping (vSLAM) into Mask R-CNN. Spatio-temporal information, in addition to the visual features, is utilized to increase the accuracy to 96.8 mAP for tool detection and 97.5 mean Jaccard for workflow detection, surpassing all previous works via the same benchmark dataset. As a real-time prediction, the RPM-CNN model reaches a 50 FPS runtime performance speed, 10x faster than region based CNN, by modeling the spatio-temporal information directly from surgical videos during the vSLAM 3D mapping. Additionally, this novel Region Proposal Module (RPM) replaces the region proposal network (RPN) in Mask R-CNN, accurately placing bounding-boxes and lessening the annotation requirement. In principle, this architecture integrates the best of both worlds, inclusive of 1) vSLAM on object detection, through focusing on geometric information for region proposals and 2) CNN on object recognition, through focusing on semantic information for image classification; the integration of these two technologies into one joint training process opens a new door in computer vision. Furthermore, to apply RPM-CNN's real-time top performance to the real world, a Microsoft HoloLens 2 application is developed to provide an augmented reality (AR) based solution for both surgical training and assistance.      
### 27.Large-Scale Pre-Training of End-to-End Multi-Talker ASR for Meeting Transcription with Single Distant Microphone  [ :arrow_down: ](https://arxiv.org/pdf/2103.16776.pdf)
>  Transcribing meetings containing overlapped speech with only a single distant microphone (SDM) has been one of the most challenging problems for automatic speech recognition (ASR). While various approaches have been proposed, all previous studies on the monaural overlapped speech recognition problem were based on either simulation data or small-scale real data. In this paper, we extensively investigate a two-step approach where we first pre-train a serialized output training (SOT)-based multi-talker ASR by using large-scale simulation data and then fine-tune the model with a small amount of real meeting data. Experiments are conducted by utilizing 75 thousand (K) hours of our internal single-talker recording to simulate a total of 900K hours of multi-talker audio segments for supervised pre-training. With fine-tuning on the 70 hours of the AMI-SDM training data, our SOT ASR model achieves a word error rate (WER) of 21.2% for the AMI-SDM evaluation set while automatically counting speakers in each test segment. This result is not only significantly better than the previous state-of-the-art WER of 36.4% with oracle utterance boundary information but also better than a result by a similarly fine-tuned single-talker ASR model applied to beamformed audio.      
### 28.Space-Time Video Regularity and Visual Fidelity: Compression, Resolution and Frame Rate Adaptation  [ :arrow_down: ](https://arxiv.org/pdf/2103.16771.pdf)
>  In order to be able to deliver today's voluminous amount of video contents through limited bandwidth channels in a perceptually optimal way, it is important to consider perceptual trade-offs of compression and space-time downsampling protocols. In this direction, we have studied and developed new models of natural video statistics (NVS), which are useful because high-quality videos contain statistical regularities that are disturbed by distortions. Specifically, we model the statistics of divisively normalized difference between neighboring frames that are relatively displaced. In an extensive empirical study, we found that those paths of space-time displaced frame differences that provide maximal regularity against our NVS model generally align best with motion trajectories. Motivated by this, we build a new video quality prediction engine that extracts NVS features from displaced frame differences, and combines them in a learned regressor that can accurately predict perceptual quality. As a stringent test of the new model, we apply it to the difficult problem of predicting the quality of videos subjected not only to compression, but also to downsampling in space and/or time. We show that the new quality model achieves state-of-the-art (SOTA) prediction performance compared on the new ETRI-LIVE Space-Time Subsampled Video Quality (STSVQ) database, which is dedicated to this problem. Downsampling protocols are of high interest to the streaming video industry, given rapid increases in frame resolutions and frame rates.      
### 29.Joint Channel Estimation and Synchronization Techniques for Time Interleaved Block Windowed Burst OFDM  [ :arrow_down: ](https://arxiv.org/pdf/2103.16719.pdf)
>  From a conceptual perspective, 5G technology promises to deliver low latency, high data rate and more reliable connections for the next generations of communication systems. To face these demands, modulation schemes based on Orthogonal Frequency Domain Multiplexing (OFDM) can accommodate these requirements for wireless systems. On the other hand, several hybrid OFDM-based systems such as the Time-Interleaved Block Windowed Burst Orthogonal Frequency Division Multiplexing (TIBWB-OFDM) are capable of achieving even better spectral confinement and power efficiency. This paper addresses to the implementation of the TIBWB-OFDM system in a more realistic and practical wireless link scenarios by addressing the challenges of proper and reliable channel estimation and frame synchronization. We propose to incorporate a preamble formed by optimum correlation training sequences, such as the Zadoff-Chu (ZC) sequences. The added ZC preamble sequence is used to jointly estimate the frame beginning, through signal correlation strategies and a threshold decision device, and acquire the channel state information (CSI), by employing estimators based on the preamble sequence and the transmitted data. The employed receiver estimators show that it is possible to detect the TIBWB-OFDM frame beginning and provide a close BER performance comparatively to the one where the perfect channel is known.      
### 30.Islanded Microgrid Restoration Studies with Graph-Based Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2103.16709.pdf)
>  Power outages are bound to occur. The question is not usually if they will occur but how the frequency of occurrence can be minimized and how we can quickly get the grid up and running after its occurrence. One promising approach to power restoration is the use of locally available energy resources to restore the system to form isolated microgrids. In this paper, we present a black start restoration method that forms islanded microgrids after a black out. The master DGs in the formed microgrid were coordinated to work together through droop control. Several constraints, including incentive-based demand response (DR) with direct load control (DLC) and distributed generator (DG) operation constraints, were formulated and linearized to realize a mixed-integer linear programming (MILP) restoration model. To improve compactness and to ensure that the model is neither under-sized nor over-sized, a pre-processing graph analysis approach was introduced which helps to characterize the least number of restoration steps needed to optimally restore the microgrid. Studies were performed on a modified IEEE 123 node test feeder to evaluate the effects of demand response, non-dispatchable DGs, and choice of restoration steps on the quality of the restoration solution.      
### 31.CNN-based Cardiac Motion Extraction to Generate Deformable Geometric Left Ventricle Myocardial Models from Cine MRI  [ :arrow_down: ](https://arxiv.org/pdf/2103.16695.pdf)
>  Patient-specific left ventricle (LV) myocardial models have the potential to be used in a variety of clinical scenarios for improved diagnosis and treatment plans. Cine cardiac magnetic resonance (MR) imaging provides high resolution images to reconstruct patient-specific geometric models of the LV myocardium. With the advent of deep learning, accurate segmentation of cardiac chambers from cine cardiac MR images and unsupervised learning for image registration for cardiac motion estimation on a large number of image datasets is attainable. Here, we propose a deep leaning-based framework for the development of patient-specific geometric models of LV myocardium from cine cardiac MR images, using the Automated Cardiac Diagnosis Challenge (ACDC) dataset. We use the deformation field estimated from the VoxelMorph-based convolutional neural network (CNN) to propagate the isosurface mesh and volume mesh of the end-diastole (ED) frame to the subsequent frames of the cardiac cycle. We assess the CNN-based propagated models against segmented models at each cardiac phase, as well as models propagated using another traditional nonrigid image registration technique.      
### 32.Mask-ToF: Learning Microlens Masks for Flying Pixel Correction in Time-of-Flight Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2103.16693.pdf)
>  We introduce Mask-ToF, a method to reduce flying pixels (FP) in time-of-flight (ToF) depth captures. FPs are pervasive artifacts which occur around depth edges, where light paths from both an object and its background are integrated over the aperture. This light mixes at a sensor pixel to produce erroneous depth estimates, which can adversely affect downstream 3D vision tasks. Mask-ToF starts at the source of these FPs, learning a microlens-level occlusion mask which effectively creates a custom-shaped sub-aperture for each sensor pixel. This modulates the selection of foreground and background light mixtures on a per-pixel basis and thereby encodes scene geometric information directly into the ToF measurements. We develop a differentiable ToF simulator to jointly train a convolutional neural network to decode this information and produce high-fidelity, low-FP depth reconstructions. We test the effectiveness of Mask-ToF on a simulated light field dataset and validate the method with an experimental prototype. To this end, we manufacture the learned amplitude mask and design an optical relay system to virtually place it on a high-resolution ToF sensor. We find that Mask-ToF generalizes well to real data without retraining, cutting FP counts in half.      
### 33.The Division of Assets in Multiagent Systems: A Case Study in Team Blotto Games  [ :arrow_down: ](https://arxiv.org/pdf/2103.16688.pdf)
>  Multi-agent systems are designed to concurrently accomplish a diverse set of tasks at unprecedented scale. Here, the central problems faced by a system operator are to decide (i) how to divide available resources amongst the agents assigned to tasks and (ii) how to coordinate the behavior of the agents to optimize the efficiency of the resulting collective behavior. The focus of this paper is on problem (i), where we seek to characterize the impact of the division of resources on the best-case efficiency of the resulting collective behavior. Specifically, we focus on a team Colonel Blotto game where there are two sub-colonels competing against a common adversary in a two battlefield environment. Here, each sub-colonel is assigned a given resource budget and is required to allocate these resources independent of the other sub-colonel. However, their success is dependent on the allocation strategy of both sub-colonels. The central focus of this manuscript is on how to divide a common pool of resources among the two sub-colonels to optimize the resulting best-case efficiency guarantees. Intuitively, one would imagine that the more balanced the division of resources, the worse the performance, as such divisions restrict the sub-colonels' ability to employ joint randomized strategies that tend to be necessary for optimizing performance guarantees. However, the main result of this paper demonstrates that this intuition is actually incorrect. A more balanced division of resources can offer better performance guarantees than a more centralized division. Hence, this paper demonstrates that the resource division problem is highly non-trivial in such enmeshed environments and worthy of significant future research efforts.      
### 34.Pre-training for low resource speech-to-intent applications  [ :arrow_down: ](https://arxiv.org/pdf/2103.16674.pdf)
>  Designing a speech-to-intent (S2I) agent which maps the users' spoken commands to the agents' desired task actions can be challenging due to the diverse grammatical and lexical preference of different users. As a remedy, we discuss a user-taught S2I system in this paper. The user-taught system learns from scratch from the users' spoken input with action demonstration, which ensure it is fully matched to the users' way of formulating intents and their articulation habits. The main issue is the scarce training data due to the user effort involved. Existing state-of-art approaches in this setting are based on non-negative matrix factorization (NMF) and capsule networks. In this paper we combine the encoder of an end-to-end ASR system with the prior NMF/capsule network-based user-taught decoder, and investigate whether pre-training methodology can reduce training data requirements for the NMF and capsule network. Experimental results show the pre-trained ASR-NMF framework significantly outperforms other models, and also, we discuss limitations of pre-training with different types of command-and-control(C&amp;C) applications.      
### 35.HAD-Net: A Hierarchical Adversarial Knowledge Distillation Network for Improved Enhanced Tumour Segmentation Without Post-Contrast Images  [ :arrow_down: ](https://arxiv.org/pdf/2103.16617.pdf)
>  Segmentation of enhancing tumours or lesions from MRI is important for detecting new disease activity in many clinical contexts. However, accurate segmentation requires the inclusion of medical images (e.g., T1 post contrast MRI) acquired after injecting patients with a contrast agent (e.g., Gadolinium), a process no longer thought to be safe. Although a number of modality-agnostic segmentation networks have been developed over the past few years, they have been met with limited success in the context of enhancing pathology segmentation. In this work, we present HAD-Net, a novel offline adversarial knowledge distillation (KD) technique, whereby a pre-trained teacher segmentation network, with access to all MRI sequences, teaches a student network, via hierarchical adversarial training, to better overcome the large domain shift presented when crucial images are absent during inference. In particular, we apply HAD-Net to the challenging task of enhancing tumour segmentation when access to post-contrast imaging is not available. The proposed network is trained and tested on the BraTS 2019 brain tumour segmentation challenge dataset, where it achieves performance improvements in the ranges of 16% - 26% over (a) recent modality-agnostic segmentation methods (U-HeMIS, U-HVED), (b) KD-Net adapted to this problem, (c) the pre-trained student network and (d) a non-hierarchical version of the network (AD-Net), in terms of Dice scores for enhancing tumour (ET). The network also shows improvements in tumour core (TC) Dice scores. Finally, the network outperforms both the baseline student network and AD-Net in terms of uncertainty quantification for enhancing tumour segmentation based on the BraTs 2019 uncertainty challenge metrics. Our code is publicly available at: <a class="link-external link-https" href="https://github.com/SaverioVad/HAD_Net" rel="external noopener nofollow">this https URL</a>      
### 36.The nature of synchronization in power systems: a revelation from communication theory  [ :arrow_down: ](https://arxiv.org/pdf/2103.16608.pdf)
>  The large-scale integration of converter-interfaced resources in electrical power systems raises new stability threats which call for a new theoretic framework for modelling and analysis. Here we present the theory of power-communication isomorphism to solve this grand challenge. It is revealed that an intrinsic communication mechanism governs the synchronisation of all apparatus in power systems based on which a unified representation for heterogeneous apparatus and behaviours is established. We develop the mathematics to model the dynamic interaction within a power-communication isomorphic system which yield a simple stability criterion for complex systems that can be intuitively interpreted and thus conveniently applied in practice.      
### 37.Enhancing human bodies with extra robotic arms and fingers: The Neural Resource Allocation Problem  [ :arrow_down: ](https://arxiv.org/pdf/2103.17252.pdf)
>  The emergence of robot-based body augmentation promises exciting innovations that will inform robotics, human-machine interaction, and wearable electronics. Even though augmentative devices like extra robotic arms and fingers in many ways build on restorative technologies, they introduce unique challenges for bidirectional human-machine collaboration. Can humans adapt and learn to operate a new limb collaboratively with their biological limbs without sacrificing their physical abilities? To successfully achieve robotic body augmentation, we need to ensure that by giving a person an additional (artificial) limb, we are not in fact trading off an existing (biological) one. In this manuscript, we introduce the "Neural Resource Allocation" problem, which distinguishes body augmentation from existing robotics paradigms such as teleoperation and prosthetics. We discuss how to allow the effective and effortless voluntary control of augmentative devices without compromising the voluntary control of the biological body. In reviewing the relevant literature on extra robotic fingers and limbs we critically assess the range of potential solutions available for the "Neural Resource Allocation" problem. For this purpose, we combine multiple perspectives from engineering and neuroscience with considerations from human-machine interaction, sensory-motor integration, ethics and law. Altogether we aim to define common foundations and operating principles for the successful implementation of motor augmentation.      
### 38.FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.17235.pdf)
>  With the increase in available large clinical and experimental datasets, there has been substantial amount of work being done on addressing the challenges in the area of biomedical image analysis. Image segmentation, which is crucial for any quantitative analysis, has especially attracted attention. Recent hardware advancement has led to the success of deep learning approaches. However, although deep learning models are being trained on large datasets, existing methods do not use the information from different learning epochs effectively. In this work, we leverage the information of each training epoch to prune the prediction maps of the subsequent epochs. We propose a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch. The previous epoch mask is then used to provide a hard attention to the learnt feature maps at different convolutional layers. The network also allows to rectify the predictions in an iterative fashion during the test time. We show that our proposed feedback attention model provides a substantial improvement on most segmentation metrics tested on seven publicly available biomedical imaging datasets demonstrating the effectiveness of the proposed FANet.      
### 39.A Closer Look at Fourier Spectrum Discrepancies for CNN-generated Images Detection  [ :arrow_down: ](https://arxiv.org/pdf/2103.17195.pdf)
>  CNN-based generative modelling has evolved to produce synthetic images indistinguishable from real images in the RGB pixel space. Recent works have observed that CNN-generated images share a systematic shortcoming in replicating high frequency Fourier spectrum decay attributes. Furthermore, these works have successfully exploited this systematic shortcoming to detect CNN-generated images reporting up to 99% accuracy across multiple state-of-the-art GAN models. <br>In this work, we investigate the validity of assertions claiming that CNN-generated images are unable to achieve high frequency spectral decay consistency. We meticulously construct a counterexample space of high frequency spectral decay consistent CNN-generated images emerging from our handcrafted experiments using DCGAN, LSGAN, WGAN-GP and StarGAN, where we empirically show that this frequency discrepancy can be avoided by a minor architecture change in the last upsampling operation. We subsequently use images from this counterexample space to successfully bypass the recently proposed forensics detector which leverages on high frequency Fourier spectrum decay attributes for CNN-generated image detection. <br>Through this study, we show that high frequency Fourier spectrum decay discrepancies are not inherent characteristics for existing CNN-based generative models--contrary to the belief of some existing work--, and such features are not robust to perform synthetic image detection. Our results prompt re-thinking of using high frequency Fourier spectrum decay attributes for CNN-generated image detection. Code and models are available at <a class="link-external link-https" href="https://keshik6.github.io/Fourier-Discrepancies-CNN-Detection/" rel="external noopener nofollow">this https URL</a>      
### 40.Compressing 1D Time-Channel Separable Convolutions using Sparse Random Ternary Matrices  [ :arrow_down: ](https://arxiv.org/pdf/2103.17142.pdf)
>  We demonstrate that 1x1-convolutions in 1D time-channel separable convolutions may be replaced by constant, sparse random ternary matrices with weights in $\{-1,0,+1\}$. Such layers do not perform any multiplications and do not require training. Moreover, the matrices may be generated on the chip during computation and therefore do not require any memory access. With the same parameter budget, we can afford deeper and more expressive models, improving the Pareto frontiers of existing models on several tasks. For command recognition on Google Speech Commands v1, we improve the state-of-the-art accuracy from 97.21\% to 97.41\% at the same network size. Alternatively, we can lower the cost of existing models. For speech recognition on Librispeech, we half the number of weights to be trained while only sacrificing about $1\%$ of the floating-point baseline's word error rate.      
### 41.Unpaired Single-Image Depth Synthesis with cycle-consistent Wasserstein GANs  [ :arrow_down: ](https://arxiv.org/pdf/2103.16938.pdf)
>  Real-time estimation of actual environment depth is an essential module for various autonomous system tasks such as localization, obstacle detection and pose estimation. During the last decade of machine learning, extensive deployment of deep learning methods to computer vision tasks yielded successful approaches for realistic depth synthesis out of a simple RGB modality. While most of these models rest on paired depth data or availability of video sequences and stereo images, there is a lack of methods facing single-image depth synthesis in an unsupervised manner. Therefore, in this study, latest advancements in the field of generative neural networks are leveraged to fully unsupervised single-image depth synthesis. To be more exact, two cycle-consistent generators for RGB-to-depth and depth-to-RGB transfer are implemented and simultaneously optimized using the Wasserstein-1 distance. To ensure plausibility of the proposed method, we apply the models to a self acquised industrial data set as well as to the renown NYU Depth v2 data set, which allows comparison with existing approaches. The observed success in this study suggests high potential for unpaired single-image depth estimation in real world applications.      
### 42.Near field Acoustic Holography on arbitrary shapes using Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2103.16935.pdf)
>  Near-field Acoustic Holography (NAH) is a well-known problem aimed at estimating the vibrational velocity field of a structure by means of acoustic measurements. In this paper, we propose a NAH technique based on Convolutional Neural Network (CNN). The devised CNN predicts the vibrational field on the surface of arbitrary shaped plates (violin plates) with orthotropic material properties from a limited number of measurements. In particular, the architecture, named super resolution CNN (SRCNN), is able to estimate the vibrational field with a higher spatial resolution compared to the input pressure. The pressure and velocity datasets have been generated through Finite Element Method simulations. We validate the proposed method by comparing the estimates with the synthesized ground truth and with a state-of-the-art technique. Moreover, we evaluate the robustness of the devised network against noisy input data.      
### 43.Seeing through a Black Box: Toward High-Quality Terahertz TomographicImaging via Multi-Scale Spatio-Spectral Image Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2103.16932.pdf)
>  Terahertz tomographic imaging has recently arisen significant attention due to its non-invasive, non-destructive, non-ionizing, material-classification, and ultrafast-frame-rate nature for object exploration and inspection. However, its strong water absorption nature and low noise tolerance lead to undesired blurring and distortion of reconstructed terahertz images. Research groups aim to deal with this issue through the use of synthetic data in the training phase, but still, their performances are highly constrained by the diffraction-limited terahertz signals. In this paper, we propose a novel multi-scale spatio-spectral fusion Unet (MS3-Unet) that extracts multi-scale features from the different spectral of terahertz image data for restoration. MS3-Unet utilizes multi-scale branches to extract spatio-spectral features which are then processed by element-wise adaptive filters, and then fused to achieve high-quality terahertz image restoration. Here, we experimentally construct ultra-high-speed terahertz time-domain spectroscopy system covering a broad frequency range from 0.1 THz to 4 THz for building up temporal/spectral/spatial/phase/material terahertz database of hidden 3-D objects. Complementary to a quantitative evaluation, we demonstrate the effectiveness of the proposed MS3-Unet image restoration approach on 3-D terahertz tomographic reconstruction applications.      
### 44.Generating Multi-scale Maps from Remote Sensing Images via Series Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2103.16909.pdf)
>  Considering the success of generative adversarial networks (GANs) for image-to-image translation, researchers have attempted to translate remote sensing images (RSIs) to maps (rs2map) through GAN for cartography. However, these studies involved limited scales, which hinders multi-scale map creation. By extending their method, multi-scale RSIs can be trivially translated to multi-scale maps (multi-scale rs2map translation) through scale-wise rs2map models trained for certain scales (parallel strategy). However, this strategy has two theoretical limitations. First, inconsistency between various spatial resolutions of multi-scale RSIs and object generalization on multi-scale maps (RS-m inconsistency) increasingly complicate the extraction of geographical information from RSIs for rs2map models with decreasing scale. Second, as rs2map translation is cross-domain, generators incur high computation costs to transform the RSI pixel distribution to that on maps. Thus, we designed a series strategy of generators for multi-scale rs2map translation to address these limitations. In this strategy, high-resolution RSIs are inputted to an rs2map model to output large-scale maps, which are translated to multi-scale maps through series multi-scale map translation models. The series strategy avoids RS-m inconsistency as inputs are high-resolution large-scale RSIs, and reduces the distribution gap in multi-scale map generation through similar pixel distributions among multi-scale maps. Our experimental results showed better quality multi-scale map generation with the series strategy, as shown by average increases of 11.69%, 53.78%, 55.42%, and 72.34% in the structural similarity index, edge structural similarity index, intersection over union (road), and intersection over union (water) for data from Mexico City and Tokyo at zoom level 17-13.      
### 45.ArtFlow: Unbiased Image Style Transfer via Reversible Neural Flows  [ :arrow_down: ](https://arxiv.org/pdf/2103.16877.pdf)
>  Universal style transfer retains styles from reference images in content images. While existing methods have achieved state-of-the-art style transfer performance, they are not aware of the content leak phenomenon that the image content may corrupt after several rounds of stylization process. In this paper, we propose ArtFlow to prevent content leak during universal style transfer. ArtFlow consists of reversible neural flows and an unbiased feature transfer module. It supports both forward and backward inferences and operates in a projection-transfer-reversion scheme. The forward inference projects input images into deep features, while the backward inference remaps deep features back to input images in a lossless and unbiased way. Extensive experiments demonstrate that ArtFlow achieves comparable performance to state-of-the-art style transfer methods while avoiding content leak.      
### 46.Channel-Based Attention for LCC Using Sentinel-2 Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2103.16836.pdf)
>  Deep Neural Networks (DNNs) are getting increasing attention to deal with Land Cover Classification (LCC) relying on Satellite Image Time Series (SITS). Though high performances can be achieved, the rationale of a prediction yielded by a DNN often remains unclear. An architecture expressing predictions with respect to input channels is thus proposed in this paper. It relies on convolutional layers and an attention mechanism weighting the importance of each channel in the final classification decision. The correlation between channels is taken into account to set up shared kernels and lower model complexity. Experiments based on a Sentinel-2 SITS show promising results.      
### 47.Q-ASR: Integer-only Zero-shot Quantization for Efficient Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2103.16827.pdf)
>  End-to-end neural network models achieve improved performance on various automatic speech recognition (ASR) tasks. However, these models perform poorly on edge hardware due to large memory and computation requirements. While quantizing model weights and/or activations to low-precision can be a promising solution, previous research on quantizing ASR models is limited. Most quantization approaches use floating-point arithmetic during inference; and thus they cannot fully exploit integer processing units, which use less power than their floating-point counterparts. Moreover, they require training/validation data during quantization for finetuning or calibration; however, this data may not be available due to security/privacy concerns. To address these limitations, we propose Q-ASR, an integer-only, zero-shot quantization scheme for ASR models. In particular, we generate synthetic data whose runtime statistics resemble the real data, and we use it to calibrate models during quantization. We then apply Q-ASR to quantize QuartzNet-15x5 and JasperDR-10x5 without any training data, and we show negligible WER change as compared to the full-precision baseline models. For INT8-only quantization, we observe a very modest WER degradation of up to 0.29%, while we achieve up to 2.44x speedup on a T4 GPU. Furthermore, Q-ASR exhibits a large compression rate of more than 4x with small WER degradation.      
### 48.Novel Outage-Aware NOMA Protocol for Secrecy Fairness Maximization Among Untrusted Users  [ :arrow_down: ](https://arxiv.org/pdf/2103.16814.pdf)
>  Observing the significance of spectrally-efficient secure non-orthogonal multiple access (NOMA), this paper proposes a novel quality of service (QoS) aware secure NOMA protocol that maximizes secrecy fairness among untrusted users. Considering a base station (BS) and two users, a novel decoding order is designed that provides security to both users. With the objective of ensuring secrecy fairness between users, while satisfying their QoS requirements under BS transmit power budget constraint, we explore the problem of minimizing the maximum secrecy outage probability (SOP). Closed-form expression of pair outage probability (POP) and optimal power allocation (PA) minimizing POP are obtained. To analyze secrecy performance, analytical expressions of SOP for both users are derived, and individual SOP minimization problems are solved using concept of generalized-convexity. High signal-to-noise ratio approximation of SOP and asymptotically optimized solution minimizing this approximation is also found. Furthermore, a global-optimal solution from secrecy fairness standpoint is obtained at low computational complexity, and tight approximation is derived to get analytical insights. Numerical results present useful insights on globally optimized PA which ensure secrecy fairness and provide performance gain of about 55.12%, 69.30%, and 19.11%, respectively, compared to fixed PA and individual users' optimal PAs. Finally, a tradeoff between secrecy fairness performance and QoS demands is presented.      
### 49.Descending Predictive Feedback: From Optimal Control to the Sensorimotor System  [ :arrow_down: ](https://arxiv.org/pdf/2103.16812.pdf)
>  Descending predictive feedback (DPF) is an ubiquitous yet unexplained phenomenon in the central nervous system. Motivated by recent observations on motor-related signals in the visual system, we approach this problem from a sensorimotor standpoint and make use of optimal controllers to explain DPF. We define and analyze DPF in the optimal control context, revisiting several control problems (state feedback, full control, and output feedback) to explore conditions that necessitate DPF. We find that even small deviations from the unconstrained state feedback problem (e.g. incomplete sensing, communication delay) necessitate DPF in the optimal controller. We also discuss parallels between controller structure and observations from neuroscience. In particular, the system level (SLS) controller displays DPF patterns compatible with predictive coding theory and easily accommodates signaling restrictions (e.g. delay) typical to neurons, making it a candidate for use in sensorimotor modeling.      
### 50.Self-Regression Learning for Blind Hyperspectral Image Fusion Without Label  [ :arrow_down: ](https://arxiv.org/pdf/2103.16806.pdf)
>  Hyperspectral image fusion (HIF) is critical to a wide range of applications in remote sensing and many computer vision applications. Most traditional HIF methods assume that the observation model is predefined or known. However, in real applications, the observation model involved are often complicated and unknown, which leads to the serious performance drop of many advanced HIF methods. Also, deep learning methods can achieve outstanding performance, but they generally require a large number of image pairs for model training, which are difficult to obtain in realistic scenarios. Towards these issues, we proposed a self-regression learning method that alternatively reconstructs hyperspectral image (HSI) and estimate the observation model. In particular, we adopt an invertible neural network (INN) for restoring the HSI, and two fully-connected network (FCN) for estimating the observation model. Moreover, \emph{SoftMax} nonlinearity is applied to the FCN for satisfying the non-negative, sparsity and equality constraints. Besides, we proposed a local consistency loss function to constrain the observation model by exploring domain specific knowledge. Finally, we proposed an angular loss function to improve spectral reconstruction accuracy. Extensive experiments on both synthetic and real-world dataset show that our model can outperform the state-of-the-art methods      
### 51.TS-RIR: Translated synthetic room impulse responses for speech augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2103.16804.pdf)
>  We propose a method for improving the quality of synthetic room impulse responses generated using acoustic simulators for far-field speech recognition tasks. We bridge the gap between the synthetic room impulse responses and the real room impulse responses using our novel, one-dimensional CycleGAN architecture. We pass a synthetic room impulse response in the form of raw-waveform audio to our one-dimensional CycleGAN and translate it into a real room impulse response. We also perform sub-band room equalization to the translated room impulse response to further improve the quality of the room impulse response. We artificially create far-field speech by convolving the LibriSpeech clean speech dataset [1] with room impulse response and adding background noise. We show that far-field speech simulated with the improved room impulse response using our approach reduces the word error rate by up to 19.9% compared to the unmodified room impulse response in Kaldi LibriSpeech far-field automatic speech recognition benchmark [2].      
### 52.Robust Trajectory Tracking Error Model-Based Predictive Control for Unmanned Ground Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2103.16782.pdf)
>  This paper proposes a new robust trajectory tracking error-based control approach for unmanned ground vehicles. A trajectory tracking error-based model is used to design a linear model predictive controller and its control action is combined with feedforward and robust control actions. The experimental results show that the proposed control structure is capable to let a tractor-trailer system track both linear and curvilinear target trajectories with low tracking error.      
### 53.Deep Simultaneous Optimisation of Sampling and Reconstruction for Multi-contrast MRI  [ :arrow_down: ](https://arxiv.org/pdf/2103.16744.pdf)
>  MRI images of the same subject in different contrasts contain shared information, such as the anatomical structure. Utilizing the redundant information amongst the contrasts to sub-sample and faithfully reconstruct multi-contrast images could greatly accelerate the imaging speed, improve image quality and shorten scanning protocols. We propose an algorithm that generates the optimised sampling pattern and reconstruction scheme of one contrast (e.g. T2-weighted image) when images with different contrast (e.g. T1-weighted image) have been acquired. The proposed algorithm achieves increased PSNR and SSIM with the resulting optimal sampling pattern compared to other acquisition patterns and single contrast methods.      
### 54.Deep Learning in current Neuroimaging: a multivariate approach with power and type I error control but arguable generalization ability  [ :arrow_down: ](https://arxiv.org/pdf/2103.16685.pdf)
>  Discriminative analysis in neuroimaging by means of deep/machine learning techniques is usually tested with validation techniques, whereas the associated statistical significance remains largely under-developed due to their computational complexity. In this work, a non-parametric framework is proposed that estimates the statistical significance of classifications using deep learning architectures. In particular, a combination of autoencoders (AE) and support vector machines (SVM) is applied to: (i) a one-condition, within-group designs often of normal controls (NC) and; (ii) a two-condition, between-group designs which contrast, for example, Alzheimer's disease (AD) patients with NC (the extension to multi-class analyses is also included). A random-effects inference based on a label permutation test is proposed in both studies using cross-validation (CV) and resubstitution with upper bound correction (RUB) as validation methods. This allows both false positives and classifier overfitting to be detected as well as estimating the statistical power of the test. Several experiments were carried out using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, the Dominantly Inherited Alzheimer Network (DIAN) dataset, and a MCI prediction dataset. We found in the permutation test that CV and RUB methods offer a false positive rate close to the significance level and an acceptable statistical power (although lower using cross-validation). A large separation between training and test accuracies using CV was observed, especially in one-condition designs. This implies a low generalization ability as the model fitted in training is not informative with respect to the test set. We propose as solution by applying RUB, whereby similar results are obtained to those of the CV test set, but considering the whole set and with a lower computational cost per iteration.      
### 55.Contrastive Learning of Single-Cell Phenotypic Representations for Treatment Classification  [ :arrow_down: ](https://arxiv.org/pdf/2103.16670.pdf)
>  Learning robust representations to discriminate cell phenotypes based on microscopy images is important for drug discovery. Drug development efforts typically analyse thousands of cell images to screen for potential treatments. Early works focus on creating hand-engineered features from these images or learn such features with deep neural networks in a fully or weakly-supervised framework. Both require prior knowledge or labelled datasets. Therefore, subsequent works propose unsupervised approaches based on generative models to learn these representations. Recently, representations learned with self-supervised contrastive loss-based methods have yielded state-of-the-art results on various imaging tasks compared to earlier unsupervised approaches. In this work, we leverage a contrastive learning framework to learn appropriate representations from single-cell fluorescent microscopy images for the task of Mechanism-of-Action classification. The proposed work is evaluated on the annotated BBBC021 dataset, and we obtain state-of-the-art results in NSC, NCSB and drop metrics for an unsupervised approach. We observe an improvement of 10% in NCSB accuracy and 11% in NSC-NSCB drop over the previously best unsupervised method. Moreover, the performance of our unsupervised approach ties with the best supervised approach. Additionally, we observe that our framework performs well even without post-processing, unlike earlier methods. With this, we conclude that one can learn robust cell representations with contrastive learning.      
### 56.Comparison of wide-band vibrotactile and friction modulation surface gratings  [ :arrow_down: ](https://arxiv.org/pdf/2103.16637.pdf)
>  This study seeks to understand conditions under which virtual gratings produced via vibrotaction and friction modulation are perceived as similar and to find physical origins in the results. To accomplish this, we developed two single-axis devices, one based on electroadhesion and one based on out-of-plane vibration. The two devices had identical touch surfaces, and the vibrotactile device used a novel closed-loop controller to achieve precise control of out-of-plane plate displacement under varying load conditions across a wide range of frequencies. A first study measured the perceptual intensity equivalence curve of gratings generated under electroadhesion and vibrotaction across the 20-400Hz frequency range. A second study assessed the perceptual similarity between two forms of skin excitation given the same driving frequency and same perceived intensity. Our results indicate that it is largely the out-of-plane velocity that predicts vibrotactile intensity relative to shear forces generated by friction modulation. A high degree of perceptual similarity between gratings generated through friction modulation and through vibrotaction is apparent and tends to scale with actuation frequency suggesting perceptual indifference to the manner of fingerpad actuation in the upper frequency range.      
### 57.Learning Robust Feedback Policies from Demonstrations  [ :arrow_down: ](https://arxiv.org/pdf/2103.16629.pdf)
>  In this work we propose and analyze a new framework to learn feedback control policies that exhibit provable guarantees on the closed-loop performance and robustness to bounded (adversarial) perturbations. These policies are learned from expert demonstrations without any prior knowledge of the task, its cost function, and system dynamics. In contrast to the existing algorithms in imitation learning and inverse reinforcement learning, we use a Lipschitz-constrained loss minimization scheme to learn control policies with certified robustness. We establish robust stability of the closed-loop system under the learned control policy and derive an upper bound on its regret, which bounds the sub-optimality of the closed-loop performance with respect to the expert policy. We also derive a robustness bound for the deterioration of the closed-loop performance under bounded (adversarial) perturbations on the state measurements. Ultimately, our results suggest the existence of an underlying tradeoff between nominal closed-loop performance and adversarial robustness, and that improvements in nominal closed-loop performance can only be made at the expense of robustness to adversarial perturbations. Numerical results validate our analysis and demonstrate the effectiveness of our robust feedback policy learning framework.      
### 58.An Integrated Mechanical Intelligence and Control Approach Towards Flight Control of Aerobat  [ :arrow_down: ](https://arxiv.org/pdf/2103.16566.pdf)
>  Our goal in this work is to expand the theory and practice of robot locomotion by addressing critical challenges associated with the robotic biomimicry of bat aerial locomotion. Bats are known for their pronounced, fast wing articulations, e.g., bats can mobilize as many as forty joints during a single wingbeat, with some joints reaching over one thousand degrees per second in angular speed. Copying bats flight is a significant ordeal, however, very rewarding. Aerial drones with morphing bodies similar to bats can be safer, agile and energy-efficient owing to their articulated and soft wings. Current design paradigms have failed to copy bat flight because they assume only closed-loop feedback roles and ignore computational roles carried out by morphology. To respond to the urgency, a design framework called Morphing via Integrated Mechanical Intelligence and Control (MIMIC) is proposed. In this paper, using the dynamic model of Northeastern University's Aerobat, which is designed to test the effectiveness of the MIMIC framework, it will be shown that computational structures and closed-loop feedback can be successfully used to mimic bats stable flight apparatus.      

# ArXiv eess --Mon, 19 Apr 2021
### 1.Iterative Model Predictive Control for Piecewise Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.08267.pdf)
>  In this paper, we present an iterative Model Predictive Control (MPC) design for piecewise nonlinear systems. We consider finite time control tasks where the goal of the controller is to steer the system from a starting configuration to a goal state while minimizing a cost function. First, we present an algorithm that leverages a feasible trajectory that completes the task to construct a control policy which guarantees that state and input constraints are recursively satisfied and that the closed-loop system reaches the goal state in finite time. Utilizing this construction, we present a policy iteration scheme that iteratively generates safe trajectories which have non-decreasing performance. Finally, we test the proposed strategy on a discretized Spring Loaded Inverted Pendulum (SLIP) model with massless legs. We show that our methodology is robust to changes in initial conditions and disturbances acting on the system. Furthermore, we demonstrate the effectiveness of our policy iteration algorithm in a minimum time control task.      
### 2.Adaptive Robust Model Predictive Control with Matched and Unmatched Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2104.08261.pdf)
>  We propose a learning-based robust predictive control algorithm that can handle large uncertainty in the dynamics for a class of discrete-time systems that are nominally linear with an additive nonlinear dynamics component. Such systems commonly model the nonlinear effects of an unknown environment on a nominal system. Motivated by an inability of existing learning-based predictive control algorithms to achieve safety guarantees in the presence of uncertainties of large magnitude in this setting, we achieve significant performance improvements by optimizing over a novel class of nonlinear feedback policies inspired by certainty equivalent "estimate-and-cancel" control laws pioneered in classical adaptive control. In contrast with previous work in robust adaptive MPC, this allows us to take advantage of the structure in the a priori unknown dynamics that are learned online through function approximation. Our approach also extends typical nonlinear adaptive control methods to systems with state and input constraints even when an additive uncertain function cannot directly be canceled from the dynamics. Moreover, our approach allows us to apply contemporary statistical estimation techniques to certify the safety of the system through persistent constraint satisfaction with high probability. We show that our method allows us to consider larger unknown terms in the dynamics than existing methods through simulated examples.      
### 3.Algorithm-driven Advances for Scientific CT Instruments: From Model-based to Deep Learning-based Approaches  [ :arrow_down: ](https://arxiv.org/pdf/2104.08228.pdf)
>  Multi-scale 3D characterization is widely used by materials scientists to further their understanding of the relationships between microscopic structure and macroscopic function. Scientific computed tomography (CT) instruments are one of the most popular choices for 3D non-destructive characterization of materials at length scales ranging from the angstrom-scale to the micron-scale. These instruments typically have a source of radiation that interacts with the sample to be studied and a detector assembly to capture the result of this interaction. A collection of such high-resolution measurements are made by re-orienting the sample which is mounted on a specially designed stage/holder after which reconstruction algorithms are used to produce the final 3D volume of interest. The end goal of scientific CT scans include determining the morphology,chemical composition or dynamic behavior of materials when subjected to external stimuli. In this article, we will present an overview of recent advances in reconstruction algorithms that have enabled significant improvements in the performance of scientific CT instruments - enabling faster, more accurate and novel imaging capabilities. In the first part, we will focus on model-based image reconstruction algorithms that formulate the inversion as solving a high-dimensional optimization problem involving a data-fidelity term and a regularization term. In the last part of the article, we will present an overview of recent approaches using deep-learning based algorithms for improving scientific CT instruments.      
### 4.TalkNet 2: Non-Autoregressive Depth-Wise Separable Convolutional Model Stanislav Beliaev, Boris Ginsburgfor Speech Synthesis with Explicit Pitch and Duration Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2104.08189.pdf)
>  We propose TalkNet, a non-autoregressive convolutional neural model for speech synthesis with explicit pitch and duration prediction. The model consists of three feed-forward convolutional networks. The first network predicts grapheme durations. An input text is expanded by repeating each symbol according to the predicted duration. The second network predicts pitch value for every mel frame. The third network generates a mel-spectrogram from the expanded text conditioned on predicted pitch. All networks are based on 1D depth-wise separable convolutional architecture. The explicit duration prediction eliminates word skipping and repeating. The quality of the generated speech nearly matches the best auto-regressive models - TalkNet trained on the LJSpeech dataset got MOS4.08. The model has only 13.2M parameters, almost 2x less than the present state-of-the-art text-to-speech models. The non-autoregressive architecture allows for fast training and inference - 422x times faster than real-time. The small model size and fast inference make the TalkNet an attractive candidate for embedded speech synthesis.      
### 5.Rate-Splitting Multiple Access for Joint Radar-Communications with Low-Resolution DACs  [ :arrow_down: ](https://arxiv.org/pdf/2104.08180.pdf)
>  In this paper, we introduce the design of a multi-antenna Joint Radar-Communication (JRC) system with Rate Splitting Multiple Access (RSMA) and low resolution Digital-to-Analog Converter (DAC) units. Using RSMA, the communication messages are split into private and common parts, then precoded and quantized before transmission. We use a problem formulation to design the JRC system with RSMA and low resolution DACs by maximizing communication sum-rate and the proximity of the resulting JRC waveform to an optimal radar beampattern under an average transmit power constraint. We solve the joint sum-rate maximization and beampattern error minimization problem using Alternating Direction Method of Multipliers (ADMM) method. The numerical results show that RSMA achieves a significantly higher sum-rate compared to Space Division Multiple Access (SDMA) while providing the same Normalized Mean Square Error (NMSE) for the designed radar beampattern.      
### 6.Automatic quality control of brain T1-weighted magnetic resonance images for a clinical data warehouse  [ :arrow_down: ](https://arxiv.org/pdf/2104.08131.pdf)
>  Many studies on machine learning (ML) for computer-aided diagnosis have so far been mostly restricted to high-quality research data. Clinical data warehouses, gathering routine examinations from hospitals, offer great promises for training and validation of ML models in a realistic setting. However, the use of such clinical data warehouses requires quality control (QC) tools. Visual QC by experts is time-consuming and does not scale to large datasets. In this paper, we propose a convolutional neural network (CNN) for the automatic QC of 3D T1-weighted brain MRI for a large heterogeneous clinical data warehouse. To that purpose, we used the data warehouse of the hospitals of the Greater Paris area (Assistance Publique-HÃ´pitaux de Paris [AP-HP]). Specifically, the objectives were: 1) to identify images which are not proper T1-weighted brain MRIs; 2) to identify acquisitions for which gadolinium was injected; 3) to rate the overall image quality. We used 5000 images for training and validation and a separate set of 500 images for testing. In order to train/validate the CNN, the data were annotated by two trained raters according to a visual QC protocol that we specifically designed for application in the setting of a data warehouse. For objectives 1 and 2, our approach achieved excellent accuracy (balanced accuracy and F1-score \textgreater 90\%), similar to the human raters. For objective 3, the performance was good but substantially lower than that of human raters. Nevertheless, the automatic approach accurately identified (balanced accuracy and F1-score \textgreater 80\%) low quality images, which would typically need to be excluded. Overall, our approach shall be useful for exploiting hospital data warehouses in medical image computing.      
### 7.Hardware Efficient Joint Radar-Communications with Hybrid Precoding and RF Chain Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2104.08127.pdf)
>  In this paper, we aim to achieve energy efficient design with minimum hardware requirement for hybrid precoding, which enables a large number of antennas with minimal number of RF chains, and sub-arrayed multiple-input multiple-output (MIMO) radar based joint radar-communication (JRC) systems. A dynamic active RF chain selection mechanism is implemented in the baseband processing and the energy efficiency (EE) maximization problem is solved using fractional programming to obtain the optimal number of RF chains at the current channel state. Subsequently hybrid precoders are computed employing a sub-arrayed MIMO structure for EE maximization with weighted formulation of the communication and radar metrics, and the solution is based on alternating minimization. The simulation results show that the proposed method with minimum hardware achieves the best EE while maintaining the rate performance, and an efficient trade-off between sensing and communication.      
### 8.Efficient Keyword Spotting through long-range interactions with Temporal Lambda Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.08086.pdf)
>  Recent models based on attention mechanisms have shown unprecedented performance in the speech recognition domain. These are computational expensive and unnecessarily complex for the keyword spotting task where its main usage is in small-footprint devices. This work explores the application of the Lambda networks, a framework for capturing long-range interactions, within this spotting task. The proposed architecture is inspired by current state-of-the-art models for keyword spotting built on residual connections. Our main contribution consists on swapping the residual blocks by temporal Lambda layers thus bypassing the expensive computation of attention maps, largely reducing the model complexity. Furthermore, the proposed Lambda network is built upon uni-dimensional convolutions which also dramatically decreases the number of floating point operations performed along the inference stage. This architecture does not only reach state-of-the-art accuracies on the Google Speech Commands dataset, but it is 85% and 65% lighter than its multi headed attention (MHAtt-RNN) and residual convolutional (Res15) counterparts, while being up to 100x faster than them. To the best of our knowledge, this is the first attempt to examine the Lambda framework within the speech domain and therefore, we unravel further research and development of future speech interfaces based on this architecture.      
### 9.Efficient QAM Signal Detector for Massive MIMO Systems via PS-ADMM Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.08064.pdf)
>  In this paper, we design an efficient quadrature amplitude modulation (QAM) signal detector for massive multiple-input multiple-output (MIMO) communication systems via the penalty-sharing alternating direction method of multipliers (PS-ADMM). Its main content is as follows: first, we formulate QAM-MIMO detection as a maximum-likelihood optimization problem with bound relaxation constraints. Decomposing QAM signals into a sum of multiple binary variables and exploiting introduced binary variables as penalty functions, we transform the detection optimization model to a non-convex sharing problem; second, a customized ADMM algorithm is presented to solve the formulated non-convex optimization problem. In the implementation, all variables can be solved analytically and in parallel; third, it is proved that the proposed PS-ADMM algorithm converges under mild conditions. Simulation results demonstrate the effectiveness of the proposed approach.      
### 10.Welfare Measure for Resource Allocation with Algorithmic Implementation: Beyond Average and Max-Min  [ :arrow_down: ](https://arxiv.org/pdf/2104.08010.pdf)
>  In this work, we propose an axiomatic approach for measuring the performance/welfare of a system consisting of concurrent agents in a resource-driven system. Our approach provides a unifying view on popular system optimality principles, such as the maximal average/total utilities and the max-min fairness. Moreover, it gives rise to other system optimality notions that have not been fully exploited yet, such as the maximal lowest total subgroup utilities. For the axiomatically defined welfare measures, we provide a generic gradient-based method to find an optimal resource allocation and present a theoretical guarantee for its success. Lastly, we demonstrate the power of our approach through the power control application in wireless networks.      
### 11.Scaling Beyond Bandwidth Limitations: Wireless Control With Stability Guarantees Under Overload  [ :arrow_down: ](https://arxiv.org/pdf/2104.07989.pdf)
>  An important class of cyber-physical systems relies on multiple agents that jointly perform a task by coordinating their actions over a wireless network. Examples include self-driving cars in intelligent transportation and production robots in smart manufacturing. However, the scalability of existing control-over-wireless solutions is limited as they cannot resolve overload situations in which the communication demand exceeds the available bandwidth. This paper presents a novel co-design of distributed control and wireless communication that overcomes this limitation by dynamically allocating the available bandwidth to agents with the greatest need to communicate. Experiments on a real cyber-physical testbed with 20 agents, each consisting of a wireless node and a cart-pole system, demonstrate that our solution achieves significantly better control performance under overload than the state of the art. We further prove that our co-design guarantees closed-loop stability for physical systems with stochastic linear time-invariant dynamics.      
### 12.OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based Fingerprinting  [ :arrow_down: ](https://arxiv.org/pdf/2104.07963.pdf)
>  Many applications require accurate indoor localization. Fingerprint-based localization methods propose a solution to this problem, but rely on a radio map that is effort-intensive to acquire. We automate the radio map acquisition phase using a software-defined radio (SDR) and a wheeled robot. Furthermore, we open-source a radio map acquired with our automated tool for a 3GPP Long-Term Evolution (LTE) wireless link. To the best of our knowledge, this is the first publicly available radio map containing channel state information (CSI). Finally, we describe first localization experiments on this radio map using a convolutional neural network to regress for location coordinates.      
### 13.Conditional Coding for Flexible Learned Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2104.07930.pdf)
>  This paper introduces a novel framework for end-to-end learned video coding. Image compression is generalized through conditional coding to exploit information from reference frames, allowing to process intra and inter frames with the same coder. The system is trained through the minimization of a rate-distortion cost, with no pre-training or proxy loss. Its flexibility is assessed under three coding configurations (All Intra, Low-delay P and Random Access), where it is shown to achieve performance competitive with the state-of-the-art video codec HEVC.      
### 14.Attention! Stay Focus!  [ :arrow_down: ](https://arxiv.org/pdf/2104.07925.pdf)
>  We develop a deep convolutional neural networks(CNNs) to deal with the blurry artifacts caused by the defocus of the camera using dual-pixel images. Specifically, we develop a double attention network which consists of attentional encoders, triple locals and global local modules to effectively extract useful information from each image in the dual-pixels and select the useful information from each image and synthesize the final output image. We demonstrate the effectiveness of the proposed deblurring algorithm in terms of both qualitative and quantitative aspects by evaluating on the test set in the NTIRE 2021 Defocus Deblurring using Dual-pixel Images Challenge. The code, and trained models are available at <a class="link-external link-https" href="https://github.com/tuvovan/ATTSF" rel="external noopener nofollow">this https URL</a>.      
### 15.Federated Learning for Internet of Things: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2104.07914.pdf)
>  The Internet of Things (IoT) is penetrating many facets of our daily life with the proliferation of intelligent services and applications empowered by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may not be feasible in realistic application scenarios due to the high scalability of modern IoT networks and growing data privacy concerns. Federated Learning (FL) has emerged as a distributed collaborative AI approach that can enable many intelligent IoT applications, by allowing for AI training at distributed IoT devices without the need for data sharing. In this article, we provide a comprehensive survey of the emerging applications of FL in IoT networks, beginning from an introduction to the recent advances in FL and IoT to a discussion of their integration. Particularly, we explore and analyze the potential of FL for enabling a wide range of IoT services, including IoT data sharing, data offloading and caching, attack detection, localization, mobile crowdsensing, and IoT privacy and security. We then provide an extensive survey of the use of FL in various key IoT applications such as smart healthcare, smart transportation, Unmanned Aerial Vehicles (UAVs), smart cities, and smart industry. The important lessons learned from this review of the FL-IoT services and applications are also highlighted. We complete this survey by highlighting the current challenges and possible directions for future research in this booming area.      
### 16.An Overview of Digital Twins Application Domains in Smart Energy Grid  [ :arrow_down: ](https://arxiv.org/pdf/2104.07904.pdf)
>  The Digital Twins offer promising solutions for smart grid challenges related to the optimal operation, management, and control of energy assets, for safe and reliable distribution of energy. These challenges are more pressing nowadays than ever due to the large-scale adoption of distributed renewable resources at the edge of the grid. The digital twins are leveraging technologies such as the Internet of Things, big data analytics, machine learning, and cloud computing, to analyze data from different energy sensors, view and verify the status of physical energy assets and extract useful information to predict and optimize the assets performance. In this paper, we will provide an overview of the Digital Twins application domains in the smart grid while analyzing existing the state of the art literature. We have focused on the following application domains: energy asset modeling, fault and security diagnosis, operational optimization, and business models. Most of the relevant literature approaches found are published in the last three years showing that the domain of Digital Twins application in smart grid is hot and gradually developing. Anyway, there is no unified view on the Digital Twins implementation and integration with energy management processes, thus, much work still needs to be done to understand and automatize the smart grid management.      
### 17.A Practical Assessment of the Power Grid Inertia Constant Using PMUs  [ :arrow_down: ](https://arxiv.org/pdf/2104.07884.pdf)
>  Installation of phasor measurement units (PMUs) in a number of substations in the power grid can help assess a set of its values and parameters, in particular those related to the dynamics when disturbances occur in the system. Inertia constant of the power grid is one of the system stability related parameters that is essential for planning of the system spinning reserve. Estimates of the grid inertia constant require precise information of the system frequency at the time of disturbance. In this paper, an improved method for such estimate is presented, which is based on the derived data of frequency variations obtained from PMUs. In addition, a way to obtain the appropriate interval for the lowest error estimate is discussed. The method has been applied to assess the inertia constant of the Iranian power grid, by obtaining the rate of change of frequency after a disturbance in the defined interval, and the rate of specified power imbalance between electrical power input and output.      
### 18.Turbulence-based load alleviation control for wind turbine in extreme turbulence situation  [ :arrow_down: ](https://arxiv.org/pdf/2104.07881.pdf)
>  The extreme loads experienced by the wind turbine in the extreme wind events are critical for the evaluation of structural reliability. Hence, the load alleviation control methods need to be designed and deployed to reduce the adverse effects of extreme wind events. This work demonstrates that the extreme loads are highly correlated to wind conditions such as turbulence-induced wind shears. Based on this insight, this work proposes a turbulence-based load alleviation control strategy for adapting the controller to changes in wind condition. The estimation of the rotor averaged wind shear based on the rotor loads is illustrated, and is herein used to statistically characterize the extreme wind events for control purpose. To demonstrates the benefits, simulations are carried out using high-fidelity aero-elastic tool and the DTU 10 MW reference turbine in normal and extreme turbulence wind conditions. The results indicate that the proposed method can effectively decrease the exceedance probability of the extreme loads. Meanwhile, the method can minimize the loss of annual energy production in normal operating condition.      
### 19.On the Importance of Trust in Next-Generation Networked CPS Systems: An AI Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2104.07853.pdf)
>  With the increasing scale, complexity, and heterogeneity of the next generation networked systems, seamless control, management, and security of such systems becomes increasingly challenging. Many diverse applications have driven interest in networked systems, including large-scale distributed learning, multi-agent optimization, 5G service provisioning, and network slicing, etc. In this paper, we propose trust as a measure to evaluate the status of network agents and improve the decision-making process. We interpret trust as a relation among entities that participate in various protocols. Trust relations are based on evidence created by the interactions of entities within a protocol and may be a composite of multiple metrics such as availability, reliability, resilience, etc. depending on application context. We first elaborate on the importance of trust as a metric and then present a mathematical framework for trust computation and aggregation within a network. Then we show in practice, how trust can be integrated into network decision-making processes by presenting two examples. In the first example, we show how utilizing the trust evidence can improve the performance and the security of Federated Learning. Second, we show how a 5G network resource provisioning framework can be improved when augmented with a trust-aware decision-making scheme. We verify the validity of our trust-based approach through simulations. Finally, we explain the challenges associated with aggregating the trust evidence and briefly explain our ideas to tackle them.      
### 20.Impact of the Low-level Controller on StringStability of Adaptive Cruise Control System  [ :arrow_down: ](https://arxiv.org/pdf/2104.07726.pdf)
>  Current factory adaptive cruise control (ACC) systems consist of an upper-level planner that computes the optimal trajectory of the vehicle and a low-level controller in charge of executing it. The literature on the string stability (SS) of ACC systems is mostly concerned with the upper-level planner. In this paper, we show that the low-level controller can have a significant impact on SS. We find that i) a fast controller improves the SS, ii) a slow controller can result from either insufficient control gains or from an undershooting gas/brake system or both, and iii) although the integral gain is helpful for effective control, the integral windup can cause overshooting, and in turn, undermines the SS of the ACC. Accordingly, we suggest tuning up the proportional/feedforward gain and ensuring the gas/brake is not to undershoot. An Anti-windup design is also needed to improve SS. The results of this paper are validated both numerically and empirically on commercial cars.      
### 21.The Immersion and Invariance Wind Speed Estimator Revisited and New Results  [ :arrow_down: ](https://arxiv.org/pdf/2104.07696.pdf)
>  The Immersion and Invariance (I&amp;I) wind speed estimator is a powerful and widely-used technique to estimate the rotor effective wind speed on horizontal axis wind turbines. Anyway, its global convergence proof is rather cumbersome, which hinders the extension of the method and proof to time-delayed and/or uncertain systems. In this letter, we illustrate that the circle criterion can be used as an alternative method to prove the global convergence of the I&amp;I estimator. This also opens up the inclusion of time-delays and uncertainties. First, we demonstrate that the I&amp;I wind speed estimator is equivalent to a torque balance estimator with a proportional correction term. As the nonlinearity in the estimator is sector bounded, the well-known circle criterion is applied to the estimator to guarantee its global convergence for time-delayed systems. By looking at the theoretical framework from this new perspective, this letter further proposes the addition of an integrator to the correction term to improve the estimator performance. Case studies show that the proposed estimator with an additional integral correction term is effective at wind speed estimation. Furthermore, its global convergence can be achieved by the circle criterion for time-delayed systems.      
### 22.Fully Homomorphic Encryption-enabled Distance-based Distributed Formation Control with Distance Mismatch Estimators  [ :arrow_down: ](https://arxiv.org/pdf/2104.07684.pdf)
>  This paper considers the use of fully homomorphic encryption for the realisation of distributed formation control of multi-agent systems via edge computer. In our proposed framework, the distributed control computation in the edge computer uses only the encrypted data without the need for a reset mechanism that is commonly required to avoid error accumulation. Simulation results show that, despite the use of encrypted data on the controller and errors introduced by the quantization process prior to the encryption, the formation is able to converge to the desired shape. The proposed architecture offers insight on the mechanism for realising distributed control computation in an edge/cloud computer while preserving the privacy of local information coming from each agent.      
### 23.Shoulder Implant X-Ray Manufacturer Classification: Exploring with Vision Transformer  [ :arrow_down: ](https://arxiv.org/pdf/2104.07667.pdf)
>  Shoulder replacement surgery, also called total shoulder replacement, is a common and complex surgery in Orthopedics discipline. It involves replacing a dead shoulder joint with an artificial implant. In the market, there are many artificial implant manufacturers and each of them may produce different implants with different structures compares to other providers. The problem arises in the following situation: a patient has some problems with the shoulder implant accessory and the manufacturer of that implant maybe unknown to either the patient or the doctor, therefore, correctly identification of the manufacturer is the key prior to the treatment. In this paper, we will demonstrate different methods for classifying the manufacturer of a shoulder implant. We will use Vision Transformer approach to this task for the first time ever      
### 24.Design of an Efficient, Ease-of-use and Affordable Artificial Intelligence based Nucleic Acid Amplification Diagnosis Technology for Tuberculosis and Multi-drug Resistant Tuberculosis  [ :arrow_down: ](https://arxiv.org/pdf/2104.08178.pdf)
>  Current technologies that facilitate diagnosis for simultaneous detection of Mycobacterium tuberculosis and its resistance to first-line anti-tuberculosis drugs (Isoniazid and Rifampicim) are designed for lab-based settings and are unaffordable for large scale testing implementations. The suitability of a TB diagnosis instrument, generally required in low-resource settings, to be implementable in point-of-care last mile public health centres depends on manufacturing cost, ease-of-use, automation and portability. This paper discusses a portable, low-cost, machine learning automated Nucleic acid amplification testing (NAAT) device that employs the use of a smartphone-based fluorescence detection using novel image processing and chromaticity detection algorithms. To test the instrument, real time polymerase chain reaction (qPCR) experiment on cDNA dilution spanning over two concentrations (40 ng/uL and 200 ng/uL) was performed and sensitive detection of multiplexed positive control assay was verified.      
### 25.Safe Exploration in Model-based Reinforcement Learning using Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2104.08171.pdf)
>  This paper studies the problem of developing an approximate dynamic programming (ADP) framework for learning online the value function of an infinite-horizon optimal problem while obeying safety constraints expressed as control barrier functions (CBFs). Our approach is facilitated by the development of a novel class of CBFs, termed Lyapunov-like CBFs (LCBFs), that retain the beneficial properties of CBFs for developing minimally-invasive safe control policies while also possessing desirable Lyapunov-like qualities such as positive semi-definiteness. We show how these LCBFs can be used to augment a learning-based control policy so as to guarantee safety and then leverage this approach to develop a safe exploration framework in a model-based reinforcement learning setting. We demonstrate that our developed approach can handle more general safety constraints than state-of-the-art safe ADP methods through a variety of numerical examples.      
### 26.AI-driven Bayesian inference of statistical microstructure descriptors from finite-frequency waves  [ :arrow_down: ](https://arxiv.org/pdf/2104.08114.pdf)
>  The ability to image materials at the microscale from long-wavelength wave data is a major challenge to the geophysical, engineering and medical fields. Here, we present a framework to constrain microstructure geometry and properties from long-scale waves. To realistically quantify microstructures we use two-point statistics, from which we derive scale-dependent effective wave properties - wavespeed and attenuation - using strong-contrast expansions (SCE) for (visco)elastic wavefields. By evaluating various two-point correlation functions we observe that both effective wavespeeds and attenuation of long-scale waves predominantly depend on volume fraction and phase properties, and that especially attenuation at small scales is highly sensitive to the geometry of microstructure heterogeneity (e.g. geometric hyperuniformity) due to incoherent inference of sub-wavelength multiple scattering. Our goal is to infer microstructure properties from observed effective wave parameters. To this end, we use the supervised machine learning method of Random Forests (RF) to construct a Bayesian inference approach. We can accurately resolve two-point correlation functions sampled from various microstructural configurations, including: a bead pack, Berea sandstone and Ketton limestone samples. Importantly, we show that inversion of small scale-induced effective elastic waves yields the best results, particularly compared to single-wave-mode (e.g., acoustic only) information. Additionally, we show that the retrieval of microscale medium contrasts is more difficult - as it is highly ill-posed - and can only be achieved with specific a priori knowledge. Our results are promising for many applications, such as earthquake hazard monitoring,non-destructive testing, imaging fluid flow in porous media, quantifying tissue properties in medical ultrasound, or designing materials with tailor-made wave properties.      
### 27.NeuroRAN: Rethinking Virtualization for AI-native Radio Access Networks in 6G  [ :arrow_down: ](https://arxiv.org/pdf/2104.08111.pdf)
>  Network softwarization has revolutionized the architecture of cellular wireless networks. State-of-the-art container based virtual radio access networks (vRAN) provide enormous flexibility and reduced life cycle management costs, but they also come with prohibitive energy consumption. We argue that for future AI-native wireless networks to be flexible and energy efficient, there is a need for a new abstraction in network softwarization that caters for neural network type of workloads and allows a large degree of service composability. In this paper we present the NeuroRAN architecture, which leverages stateful function as a user facing execution model, and is complemented with virtualized resources and decentralized resource management. We show that neural network based implementations of common transceiver functional blocks fit the proposed architecture, and we discuss key research challenges related to compilation and code generation, resource management, reliability and security.      
### 28.Embedding Dependencies Within Distributionally Robust Optimization of Modern Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.08101.pdf)
>  The increasing share of renewables in the electrical energy generation mix comes along with an increasing uncertainty in power supply. In the recent years, distributionally robust optimization has gained significant interest due to its ability to make informed decisions under uncertainty, which are robust to misrepresentations of the distributional information (e.g., from probabilistic forecasts). This is achieved by introducing an ambiguity set that describes the uncertainty around an empirical distribution of all uncertain parameters. However, this set typically overlooks the inherent dependencies of uncertainty, e.g., space-time dependencies of renewable energy sources. This paper goes beyond the state of the art by embedding such dependencies within the definition of the ambiguity set. In particular, we propose a metric-based ambiguity set with an additional constraint on dependence structure, using copula theory. We develop a conic reformulation which is kept generic such that it can be applied to any decision-making problem under uncertainty in power systems. As an example, we illustrate the performance of our proposed distributionally robust model applied to an energy and reserve dispatch problem in a power system with a high share of renewables.      
### 29.Cell-Free Massive MIMO with Large-Scale Fading Decoding and Dynamic Cooperation Clustering  [ :arrow_down: ](https://arxiv.org/pdf/2104.08047.pdf)
>  This paper considers the uplink of user-centric cell-free massive MIMO (multiple-input multiple-output) systems. We utilize the user-centric dynamic cooperation clustering (DCC) framework and derive the achievable spectral efficiency with two-layer decoding that is divided between the access points and the central processing unit (CPU). This decoding method is also known as large-scale fading decoding (LSFD). The fronthaul signaling load is analyzed and a nearly optimal second-layer decoding scheme at the CPU is proposed to reduce the fronthaul requirements compared to the optimal scheme. We also revisit the joint optimization of LSFD weights and uplink power control and show that the corresponding max-min fair optimization problem can be solved optimally via an efficient fixed-point algorithm. We provide simulations that bring new insights into the cell-free massive MIMO implementation.      
### 30.Real-time non-rigid 3D respiratory motion estimation for MR-guided radiotherapy using MR-MOTUS  [ :arrow_down: ](https://arxiv.org/pdf/2104.07957.pdf)
>  The MR-Linac is a combination of an MR-scanner and radiotherapy linear accelerator (Linac) which holds the promise to increase the precision of radiotherapy treatments with MR-guided radiotherapy by monitoring motion during radiotherapy with MRI, and adjusting the radiotherapy plan accordingly. Optimal MR-guidance for respiratory motion during radiotherapy requires MR-based 3D motion estimation with a latency of 200-500 ms. Currently this is still challenging since typical methods rely on MR-images, and are therefore limited to the 3D MR-imaging latency. In this work, we present a method to perform non-rigid 3D respiratory motion estimation with 170 ms latency, including both acquisition and reconstruction. The proposed method called real-time low-rank MR-MOTUS reconstructs motion-fields directly from k-space data, and leverages an explicit low-rank decomposition of motion-fields to split the large scale 3D+t motion-field reconstruction problem posed in our previous work into two parts: (I) a medium-scale offline preparation phase and (II) a small-scale online inference phase which exploits the results of the offline phase for real-time computations. The method was validated on free-breathing data of five volunteers, acquired with a 1.5T Elekta Unity MR-Linac. Results show that the reconstructed 3D motion-fields are anatomically plausible, highly correlated with a self-navigation motion surrogate (R = 0.975 +/- 0.0110), and can be reconstructed with a total latency of 170 ms that is sufficient for real-time MR-guided abdominal radiotherapy.      
### 31.SGL: Spectral Graph Learning from Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2104.07867.pdf)
>  This work introduces a highly scalable spectral graph densification framework for learning resistor networks with linear measurements, such as node voltages and currents. We prove that given $O(\log N)$ pairs of voltage and current measurements, it is possible to recover ultra-sparse $N$-node resistor networks which can well preserve the effective resistance distances on the graph. Also, the learned graphs preserve the structural (spectral) properties of the original graph, which can potentially be leveraged in many circuit design and optimization tasks. We show that the proposed graph learning approach is equivalent to solving the classical graphical Lasso problems with Laplacian-like precision matrices. Through extensive experiments for a variety of real-world test cases, we show that the proposed approach is highly scalable for learning ultra-sparse resistor networks without sacrificing solution quality.      
### 32.A Novel Hybrid Deep Learning Approach for Non-Intrusive Load Monitoring of Residential Appliance Based on Long Short Term Memory and Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.07809.pdf)
>  Energy disaggregation or nonintrusive load monitoring (NILM), is a single-input blind source discrimination problem, aims to interpret the mains user electricity consumption into appliance level measurement. This article presents a new approach for power disaggregation by using a deep recurrent long short term memory (LSTM) network combined with convolutional neural networks (CNN). Deep neural networks have been shown to be a significant way for these types of problems because of their complexity and huge number of trainable paramters. Hybrid method that proposed in the article could significantly increase the overall accuracy of NILM because it benefits from both network advantages. The proposed method used sequence-to-sequence learning, where the input is a window of the mains and the output is a window of the target appliance. The proposed deep neural network approach has been applied to real-world household energy dataset "REFIT". The REFIT electrical load measurements dataset described in this paper includes whole house aggregate loads and nine individual appliance measurements at 8-second intervals per house, collected continuously over a period of two years from 20 houses around the UK. The proposed method achieve significant performance, improving accuracy and F1-score measures by 95.93% and 80.93% ,respectively which demonstrates the effectiveness and superiority of the proposed approach for home energy monitoring. Comparison of proposed method and other recently published method has been presented and discussed based on accuracy, number of considered appliances and size of the deep neural network trainable parameters. The proposed method shows remarkable performance compare to other previous methods.      
### 33.Learning User's confidence for active learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.07791.pdf)
>  In this paper, we study the applicability of active learning in operative scenarios: more particularly, we consider the well-known contradiction between the active learning heuristics, which rank the pixels according to their uncertainty, and the user's confidence in labeling, which is related to both the homogeneity of the pixel context and user's knowledge of the scene. We propose a filtering scheme based on a classifier that learns the confidence of the user in labeling, thus minimizing the queries where the user would not be able to provide a class for the pixel. The capacity of a model to learn the user's confidence is studied in detail, also showing the effect of resolution is such a learning task. Experiments on two QuickBird images of different resolutions (with and without pansharpening) and considering committees of users prove the efficiency of the filtering scheme proposed, which maximizes the number of useful queries with respect to traditional active learning.      
### 34.Recent Advances in Domain Adaptation for the Classification of Remote Sensing Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.07778.pdf)
>  The success of supervised classification of remotely sensed images acquired over large geographical areas or at short time intervals strongly depends on the representativity of the samples used to train the classification algorithm and to define the model. When training samples are collected from an image (or a spatial region) different from the one used for mapping, spectral shifts between the two distributions are likely to make the model fail. Such shifts are generally due to differences in acquisition and atmospheric conditions or to changes in the nature of the object observed. In order to design classification methods that are robust to data-set shifts, recent remote sensing literature has considered solutions based on domain adaptation (DA) approaches. Inspired by machine learning literature, several DA methods have been proposed to solve specific problems in remote sensing data classification. This paper provides a critical review of the recent advances in DA for remote sensing and presents an overview of methods divided into four categories: i) invariant feature selection; ii) representation matching; iii) adaptation of classifiers and iv) selective sampling. We provide an overview of recent methodologies, as well as examples of application of the considered techniques to real remote sensing images characterized by very high spatial and spectral resolution. Finally, we propose guidelines to the selection of the method to use in real application scenarios.      
### 35.A global DC branch model incorporating power system flexibility  [ :arrow_down: ](https://arxiv.org/pdf/2104.07746.pdf)
>  In this letter we propose a generalized branch model to be used in DC optimal power flow (DCOPF) applications. Besides AC lines and transformers, the formulation allows for representing variable susceptance branches, phase shifting transformers, HVDC lines, zero impedance lines and open branches. The possibility to model branches with concurrently variable susceptance and controllable phase shift angles is also provided. The model is suited for use in DCOPF formulations aimed at the optimization of remedial actions so as to exploit power system flexibility; applications to small-, medium- and large-scale systems are presented to this purpose.      
### 36.Dual Contrastive Learning for Unsupervised Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2104.07689.pdf)
>  Unsupervised image-to-image translation tasks aim to find a mapping between a source domain X and a target domain Y from unpaired training data. Contrastive learning for Unpaired image-to-image Translation (CUT) yields state-of-the-art results in modeling unsupervised image-to-image translation by maximizing mutual information between input and output patches using only one encoder for both domains. In this paper, we propose a novel method based on contrastive learning and a dual learning setting (exploiting two encoders) to infer an efficient mapping between unpaired data. Additionally, while CUT suffers from mode collapse, a variant of our method efficiently addresses this issue. We further demonstrate the advantage of our approach through extensive ablation studies demonstrating superior performance comparing to recent approaches in multiple challenging image translation tasks. Lastly, we demonstrate that the gap between unsupervised methods and supervised methods can be efficiently closed.      

# ArXiv eess --Tue, 13 Apr 2021
### 1.Dynamic Matching Markets in Power Grid: Concepts and Solution using Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.05654.pdf)
>  This paper proposes a reinforcement learning based dynamic matching framework for power markets. These markets are challenging because of their dynamic nature and the uncertainty over the future load and generation. We propose a novel hybrid model for the matching policy that is a composition of a fixed rule-based function and a trainable component that can be trained from market data with no prior knowledge or expert supervision. The output of the trainable component is a probability distribution over the matching decisions for the individual customers. The hybrid model we propose enables the learning algorithm to find an effective matching policy and simultaneously satisfy the load servicing constraints. We show through extensive simulations that the learning algorithm learns an effective matching policy for different generation-consumption profiles and exhibits better performance compared to standard online matching heuristics such as Match on Arrival (MA), Match to the Highest (MH) and Match to the Earliest Deadline First (MED).      
### 2.A Dynamic Response Recovery Framework Using Ambient Synchrophasor Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.05614.pdf)
>  Wide-area dynamic studies are of paramount importance to ensure the stability and reliability of power grids. The rising deployment synchrophasor and other sensing technologies has made data-driven modeling and analysis possible using the synchronized fast-rate dynamic measurements. This paper presents a general model-free framework of inferring the grid dynamic responses using the ubiquitous ambient data collected during normal grid operations. Building upon the second-order dynamic model, we have established the connection from the cross-correlation of various types of angle, frequency, and line flow data at any two locations, to their corresponding dynamic responses. The theoretical results enabled a fully data-driven framework for estimating the latter using real-time ambient data. Numerical results using the WSCC 9-bus system and a synthetic 2000-bus Texas system have demonstrated the effectiveness of proposed approaches for dynamic modeling of realistic power systems.      
### 3.Deep Reinforcement Learning Based Controller for Active Heave Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05599.pdf)
>  Heave compensation is an essential part in various offshore operations. It is used in various applications, which include on-loading or off-loading systems, offshore drilling, landing helicopter on oscillating structures, and deploying and retrieving manned submersibles. In this paper, we propose a reinforcement learning (RL) based controller for active heave compensation using a deep deterministic policy gradient (DDPG) algorithm. A DDPG algorithm which is a model-free, online reinforcement learning method, is adopted to capture the experience of the agent during the training trials. The simulation results demonstrate upto 10% better heave compensation performance of RL controller as compared to a tuned Proportional-Derivative Control. The performance of the proposed method is compared with respect to heave compensation, offset tracking, disturbance rejection, and noise attenuation.      
### 4.Preemptive periodic epidemic control reduces life and healthcare system costs without aggravation of social and economic losses  [ :arrow_down: ](https://arxiv.org/pdf/2104.05597.pdf)
>  Many countries are managing COVID-19 epidemic by switching between lighter and heavier restrictions. While an open-close and a close-open cycle have comparable socio-economic costs, the former leads to a much heavier burden in terms of deaths and pressure on the healthcare system. An empirical demonstration of the toll ensuing from procrastination was recently observed in Israel, where both cycles were enforced from late August to mid-December 2020, yielding some 1,600 deaths with open-close compared to 440 with close-open.      
### 5.SC-GlowTTS: an Efficient Zero-Shot Multi-Speaker Text-To-Speech Model  [ :arrow_down: ](https://arxiv.org/pdf/2104.05557.pdf)
>  In this paper, we propose SC-GlowTTS: an efficient zero-shot multi-speaker text-to-speech model that improves similarity for speakers unseen in training. We propose a speaker-conditional architecture that explores a flow-based decoder that works in a zero-shot scenario. As text encoders, we explore a dilated residual convolutional-based encoder, gated convolutional-based encoder, and transformer-based encoder. Additionally, we have shown that adjusting a GAN-based vocoder for the spectrograms predicted by the TTS model on the training dataset can significantly improve the similarity and speech quality for new speakers. Our model is able to converge in training, using only 11 speakers, reaching state-of-the-art results for similarity with new speakers, as well as high speech quality.      
### 6.Efficient Model Monitoring for Quality Control in Cardiac Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05533.pdf)
>  Deep learning methods have reached state-of-the-art performance in cardiac image segmentation. Currently, the main bottleneck towards their effective translation into clinics requires assuring continuous high model performance and segmentation results. In this work, we present a novel learning framework to monitor the performance of heart segmentation models in the absence of ground truth. Formulated as an anomaly detection problem, the monitoring framework allows deriving surrogate quality measures for a segmentation and allows flagging suspicious results. We propose two different types of quality measures, a global score and a pixel-wise map. We demonstrate their use by reproducing the final rankings of a cardiac segmentation challenge in the absence of ground truth. Results show that our framework is accurate, fast, and scalable, confirming it is a viable option for quality control monitoring in clinical practice and large population studies.      
### 7.L3DAS21 Challenge: Machine Learning for 3D Audio Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2104.05499.pdf)
>  The L3DAS21 Challenge is aimed at encouraging and fostering collaborative research on machine learning for 3D audio signal processing, with particular focus on 3D speech enhancement (SE) and 3D sound localization and detection (SELD). Alongside with the challenge, we release the L3DAS21 dataset, a 65 hours 3D audio corpus, accompanied with a Python API that facilitates the data usage and results submission stage. Usually, machine learning approaches to 3D audio tasks are based on single-perspective Ambisonics recordings or on arrays of single-capsule microphones. We propose, instead, a novel multichannel audio configuration based multiple-source and multiple-perspective Ambisonics recordings, performed with an array of two first-order Ambisonics microphones. To the best of our knowledge, it is the first time that a dual-mic Ambisonics configuration is used for these tasks. We provide baseline models and results for both tasks, obtained with state-of-the-art architectures: FaSNet for SE and SELDNet for SELD. This report is aimed at providing all needed information to participate in the L3DAS21 Challenge, illustrating the details of the L3DAS21 dataset, the challenge tasks and the baseline models.      
### 8.Improvement of Noise-Robust Single-Channel Voice Activity Detection with Spatial Pre-processing  [ :arrow_down: ](https://arxiv.org/pdf/2104.05481.pdf)
>  Voice activity detection (VAD) remains a challenge in noisy environments. With access to multiple microphones, prior studies have attempted to improve the noise robustness of VAD by creating multi-channel VAD (MVAD) methods. However, MVAD is relatively new compared to single-channel VAD (SVAD), which has been thoroughly developed in the past. It might therefore be advantageous to improve SVAD methods with pre-processing to obtain superior VAD, which is under-explored. This paper improves SVAD through two pre-processing methods, a beamformer and a spatial target speaker detector. The spatial detector sets signal frames to zero when no potential speaker is present within a target direction. The detector may be implemented as a filter, meaning the input signal for the SVAD is filtered according to the detector's output; or it may be implemented as a spatial VAD to be combined with the SVAD output. The evaluation is made on a noisy reverberant speech database, with clean speech from the Aurora 2 database and with white and babble noise. The results show that SVAD algorithms are significantly improved by the presented pre-processing methods, especially the spatial detector, across all signal-to-noise ratios. The SVAD algorithms with pre-processing significantly outperform a baseline MVAD in challenging noise conditions.      
### 9.Stochastic Stability of Discrete-time Phase-coupled Oscillators over Uncertain and Random Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.05477.pdf)
>  This paper studies stochastic stability of a class of discrete-time phase-coupled oscillators. We introduce the two new notions of stochastic and ultimate stochastic phase-cohesiveness using the concepts of Harris and positive Harris recurrent Markov chains. Stochastic phase-cohesiveness of oscillators in two types of networks are studied. First, oscillators in a network with an underlying connected topology subject to both multiplicative and additive stochastic uncertainties are considered. Second, we study a special case of the former problem by assuming that the multiplicative uncertainties are governed by the Bernoulli process representing the well known Erd{\H o}s RÃ©nyi network.      
### 10.Improved Conformer-based End-to-End Speech Recognition Using Neural Architecture Search  [ :arrow_down: ](https://arxiv.org/pdf/2104.05390.pdf)
>  Recently neural architecture search(NAS) has been successfully used in image classification, natural language processing, and automatic speech recognition(ASR) tasks for finding the state-of-the-art(SOTA) architectures than those human-designed architectures. NAS can derive a SOTA and data-specific architecture over validation data from a pre-defined search space with a search algorithm. Inspired by the success of NAS in ASR tasks, we propose a NAS-based ASR framework containing one search space and one differentiable search algorithm called Differentiable Architecture Search(DARTS). Our search space follows the convolution-augmented transformer(Conformer) backbone, which is a more expressive ASR architecture than those used in existing NAS-based ASR frameworks. To improve the performance of our method, a regulation method called Dynamic Search Schedule(DSS) is employed. On a widely used Mandarin benchmark AISHELL-1, our best-searched architecture outperforms the baseline Conform model significantly with about 11% CER relative improvement, and our method is proved to be pretty efficient by the search cost comparisons.      
### 11.Dual-Octave Convolution for Accelerated Parallel MR Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2104.05345.pdf)
>  Magnetic resonance (MR) image acquisition is an inherently prolonged process, whose acceleration by obtaining multiple undersampled images simultaneously through parallel imaging has always been the subject of research. In this paper, we propose the Dual-Octave Convolution (Dual-OctConv), which is capable of learning multi-scale spatial-frequency features from both real and imaginary components, for fast parallel MR image reconstruction. By reformulating the complex operations using octave convolutions, our model shows a strong ability to capture richer representations of MR images, while at the same time greatly reducing the spatial redundancy. More specifically, the input feature maps and convolutional kernels are first split into two components (i.e., real and imaginary), which are then divided into four groups according to their spatial frequencies. Then, our Dual-OctConv conducts intra-group information updating and inter-group information exchange to aggregate the contextual information across different groups. Our framework provides two appealing benefits: (i) it encourages interactions between real and imaginary components at various spatial frequencies to achieve richer representational capacity, and (ii) it enlarges the receptive field by learning multiple spatial-frequency features of both the real and imaginary components. We evaluate the performance of the proposed model on the acceleration of multi-coil MR image reconstruction. Extensive experiments are conducted on an {in vivo} knee dataset under different undersampling patterns and acceleration factors. The experimental results demonstrate the superiority of our model in accelerated parallel MR image reconstruction. Our code is available at: <a class="link-external link-http" href="http://github.com/chunmeifeng/Dual-OctConv" rel="external noopener nofollow">this http URL</a>.      
### 12.Unsupervised foreign object detection based on dual-energy absorptiometry in the food industry  [ :arrow_down: ](https://arxiv.org/pdf/2104.05326.pdf)
>  X-ray imaging is a widely used technique for non-destructive inspection of agricultural food products. One application of X-ray imaging is the autonomous, in-line detection of foreign objects in food samples. Examples of such inclusions are bone fragments in meat products, plastic and metal debris in fish, fruit infestations. This article presents a processing methodology for unsupervised foreign object detection based on dual-energy X-ray absorptiometry (DEXA). A foreign object is defined as a fragment of material with different X-ray attenuation properties than those belonging to the food product. A novel thickness correction model is introduced as a pre-processing technique for DEXA data. The aim of the model is to homogenize regions in the image that belong to the food product and enhance contrast where the foreign object is present. In this way, the segmentation of the foreign object is more robust to noise and lack of contrast. The proposed methodology was applied to a dataset of 488 samples of meat products. The samples were acquired from a conveyor belt in a food processing factory. Approximately 60\% of the samples contain foreign objects of different types and sizes, while the rest of the samples are void of foreign objects. The results show that samples without foreign objects are correctly identified in 97% of cases, the overall accuracy of foreign object detection reaches 95%.      
### 13.Prospect-theoretic Q-learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.05311.pdf)
>  We consider a prospect theoretic version of the classical Q-learning algorithm for discounted reward Markov decision processes, wherein the controller perceives a distorted and noisy future reward, modeled by a nonlinearity that accentuates gains and underrepresents losses relative to a reference point. We analyze the asymptotic behavior of the scheme by analyzing its limiting differential equation and using the theory of monotone dynamical systems to infer its asymptotic behavior. Specifically, we show convergence to equilibria, and establish some qualitative facts about the equilibria themselves.      
### 14.Complex Spectral Mapping With Attention Based Convolution Recrrent Neural Network for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.05267.pdf)
>  Speech enhancement has benefited from the success of deep learning in terms of intelligibility and perceptual quality. Conventional time-frequency (TF) domain methods focus on predicting TF-masks or speech spectrum,via a naive convolution neural network or recurrent neural network.Some recent studies were based on Complex spectral Mapping convolution recurrent neural network (CRN) . These models skiped directly from encoder layers' output and decoder layers' input ,which maybe thoughtless. We proposed an attention mechanism based skip connection between encoder and decoder layers,namely Complex Spectral Mapping With Attention Based Convolution Recurrent Neural Network (CARN).Compared with CRN model,the proposed CARN model improved more than 10% relatively at several metrics such as PESQ,CBAK,COVL,CSIG and son,and outperformed the place 1st model in both real time and non-real time track of the DNS Challenge 2020 at these metrics.      
### 15.ENOS: Energy-Aware Network Operator Search for Hybrid Digital and Compute-in-Memory DNN Accelerators  [ :arrow_down: ](https://arxiv.org/pdf/2104.05217.pdf)
>  This work proposes a novel Energy-Aware Network Operator Search (ENOS) approach to address the energy-accuracy trade-offs of a deep neural network (DNN) accelerator. In recent years, novel inference operators have been proposed to improve the computational efficiency of a DNN. Augmenting the operators, their corresponding novel computing modes have also been explored. However, simplification of DNN operators invariably comes at the cost of lower accuracy, especially on complex processing tasks. Our proposed ENOS framework allows an optimal layer-wise integration of inference operators and computing modes to achieve the desired balance of energy and accuracy. The search in ENOS is formulated as a continuous optimization problem, solvable using typical gradient descent methods, thereby scalable to larger DNNs with minimal increase in training cost. We characterize ENOS under two settings. In the first setting, for digital accelerators, we discuss ENOS on multiply-accumulate (MAC) cores that can be reconfigured to different operators. ENOS training methods with single and bi-level optimization objectives are discussed and compared. We also discuss a sequential operator assignment strategy in ENOS that only learns the assignment for one layer in one training step, enabling greater flexibility in converging towards the optimal operator allocations. Furthermore, following Bayesian principles, a sampling-based variational mode of ENOS is also presented. ENOS is characterized on popular DNNs ShuffleNet and SqueezeNet on CIFAR10 and CIFAR100.      
### 16.On Thevenin-Norton and Maximum power transfer theorems  [ :arrow_down: ](https://arxiv.org/pdf/2104.05202.pdf)
>  In this paper we show how to compute port behaviour of multiports which have port equations of the general form $B v_P - Q i_P = s,$ which cannot even be put into the hybrid form, indeed may have number of equations ranging from $0$ to $2n,$ where $n$ is the number of ports. <br>We do this through repeatedly solving with different source inputs, a larger network obtained by terminating the multiport by its adjoint through a gyrator. The method works for linear multiports which are consistent for arbitrary internal source values and further have the property that the port conditions uniquely determine internal conditions. <br>We also present the most general version of maximum power transfer theorem possible. This version of the theorem states that `stationarity' (derivative zero condition) of power transfer occurs when the multiport is terminated by its adjoint, provided the resulting network has a solution. <br>If this network does not have a solution there is no port condition for which stationarity holds. This theorem does not require that the multiport has a hybrid immittance matrix.      
### 17.An Optimal Low-Complexity Energy-Efficient ADC Bit Allocation for Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2104.05186.pdf)
>  Fixed low-resolution Analog to Digital Converters (ADC) help reduce the power consumption in millimeter-wave Massive Multiple-Input Multiple-Output (Ma-MIMO) receivers operating at large bandwidths. However, they do not guarantee optimal Energy Efficiency (EE). It has been shown that adopting variable-resolution (VR) ADCs in Ma-MIMO receivers can improve performance with Mean Squared Error (MSE) and throughput while providing better EE. In this paper, we present an optimal energy-efficient bit allocation (BA) algorithm for Ma-MIMO receivers equipped with VR ADCs under a power constraint. We derive an expression for EE as a function of the Cramer-Rao Lower Bound on the MSE of the received, combined, and quantized signal. An optimal BA condition is derived by maximizing EE under a power constraint. We show that the optimal BA thus obtained is exactly the same as that obtained using the brute-force BA with a significant reduction in computational complexity. We also study the EE performance and computational complexity of a heuristic algorithm that yields a near-optimal solution.      
### 18.Soft then Hard: Rethinking the Quantization in Neural Image Compression  [ :arrow_down: ](https://arxiv.org/pdf/2104.05168.pdf)
>  Quantization is one of the core components in lossy image compression. For neural image compression, end-to-end optimization requires differentiable approximations of quantization, which can generally be grouped into three categories: additive uniform noise, straight-through estimator and soft-to-hard annealing. Training with additive uniform noise approximates the quantization error variationally but suffers from the train-test mismatch. The other two methods do not encounter this mismatch but, as shown in this paper, hurt the rate-distortion performance since the latent representation ability is weakened. We thus propose a novel soft-then-hard quantization strategy for neural image compression that first learns an expressive latent space softly, then eliminates the train-test mismatch with hard quantization. In addition, beyond the fixed integer quantization, we apply scaled additive uniform noise to adaptively control the quantization granularity by deriving a new variational upper bound on actual rate. Experiments demonstrate that our proposed methods are easy to adopt, stable to train, and highly effective especially on complex compression models.      
### 19.Maintenance of a collection of machines under partial observability: Indexability and computation of Whittle index  [ :arrow_down: ](https://arxiv.org/pdf/2104.05151.pdf)
>  We consider the problem of scheduling maintenance for a collection of machines under partial observations when the state of each machine deteriorates stochastically in a Markovian manner. We consider two observational models: first, the state of each machine is not observable at all, and second, the state of each machine is observable only if a service-person visits them. The agent takes a maintenance action, e.g., machine replacement, if he is chosen for the task. We model both problems as restless multi-armed bandit problem and propose the Whittle index policy for scheduling the visits. We show that both models are indexable. For the first model, we derive a closed-form expression for the Whittle index. For the second model, we propose an efficient algorithm to compute the Whittle index by exploiting the qualitative properties of the optimal policy. We present detailed numerical experiments which show that for multiple instances of the model, the Whittle index policy outperforms myopic policy and can be close-to-optimal in different setups.      
### 20.Detecting COVID-19 and Community Acquired Pneumonia using Chest CT scan images with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.05121.pdf)
>  We propose a two-stage Convolutional Neural Network (CNN) based classification framework for detecting COVID-19 and Community-Acquired Pneumonia (CAP) using the chest Computed Tomography (CT) scan images. In the first stage, an infection - COVID-19 or CAP, is detected using a pre-trained DenseNet architecture. Then, in the second stage, a fine-grained three-way classification is done using EfficientNet architecture. The proposed COVID+CAP-CNN framework achieved a slice-level classification accuracy of over 94% at identifying COVID-19 and CAP. Further, the proposed framework has the potential to be an initial screening tool for differential diagnosis of COVID-19 and CAP, achieving a validation accuracy of over 89.3% at the finer three-way COVID-19, CAP, and healthy classification. Within the IEEE ICASSP 2021 Signal Processing Grand Challenge (SPGC) on COVID-19 Diagnosis, our proposed two-stage classification framework achieved an overall accuracy of 90% and sensitivity of .857, .9, and .942 at distinguishing COVID-19, CAP, and normal individuals respectively, to rank first in the evaluation. Code and model weights are available at <a class="link-external link-https" href="https://github.com/shubhamchaudhary2015/ct_covid19_cap_cnn" rel="external noopener nofollow">this https URL</a>      
### 21.Transfer Learning for Neural Networks-based Equalizers in Coherent Optical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.05081.pdf)
>  In this work, we address the paramount question of generalizability and adaptability of artificial neural networks (NNs) used for impairment mitigation in optical transmission systems. We demonstrate that by using well-developed techniques based on the concept of transfer learning, we can efficaciously retrain NN-based equalizers to adapt to changes in the transmission system using just a fraction of the initial training data and resources. We evaluate the potential of transfer learning to adapt the NN to changes in the launch powers, modulation formats, symbol rates, or even fiber plant (different fiber types and lengths). In our numerical examples, we consider the recently introduced combined NN equalizer consisting of a convolutional layer coupled with bi-directional long-short term memory (biLSTM) recurrent NN elements. We focus our analysis on long-haul coherent optical transmission systems employing two types of transmission fibers: the standard single-mode fiber (SSMF) and the TrueWave Classic (TWC) fiber. We also underline the specific peculiarities that occur when transferring the learning in coherent optical communication systems. Our results demonstrate the effectiveness of transfer learning for the fast adaptation of NN architectures to different transmission regimes and scenarios, paving the way for engineering flexible universal solutions for nonlinearity mitigation.      
### 22.Comparison of Binaural RTF-Vector-Based Direction of Arrival Estimation Methods Exploiting an External Microphone  [ :arrow_down: ](https://arxiv.org/pdf/2104.05079.pdf)
>  In this paper we consider a binaural hearing aid setup, where in addition to the head-mounted microphones an external microphone is available. For this setup, we investigate the performance of several relative transfer function (RTF) vector estimation methods to estimate the direction of arrival(DOA) of the target speaker in a noisy and reverberant acoustic environment. More in particular, we consider the state-of-the-art covariance whitening (CW) and covariance subtraction (CS) methods, either incorporating the external microphone or not, and the recently proposed spatial coherence (SC) method, requiring the external microphone. To estimate the DOA from the estimated RTF vector, we propose to minimize the frequency-averaged Hermitian angle between the estimated head-mounted RTF vector and a database of prototype head-mounted RTF vectors. Experimental results with stationary and moving speech sources in a reverberant environment with diffuse-like noise show that the SC method outperforms the CS method and yields a similar DOA estimation accuracy as the CW method at a lower computational complexity.      
### 23.Priority Lists for Power System Investments: Locating Phasor Measurement Units  [ :arrow_down: ](https://arxiv.org/pdf/2104.05071.pdf)
>  Power systems incrementally and continuously upgrade their components, such as transmission lines, reactive capacitors, or generating units. Decision-making tools often support the selection of the best set of components to upgrade. Optimization models are often used to support decision making at a given point in time. After certain time intervals, re-optimization is performed to find new components to add. In this paper, we propose a decision-making framework for incrementally updating power system components. This is an alternative approach to the classical sequential re-optimization decision making for an investment problem with modeled budget constraints. Our approach provides a priority list as a solution with a list of new components to upgrade. We show that i) our framework is consistent with the evolution of power system upgrades, and ii) in particular circumstances, both frameworks provide the same solution if the problem satisfies submodularity property. We have selected the problem of phasor measurement unit localization and compared the solution with the classical sequential re-optimization framework. For this particular problem, we show that the two approaches provide close results, while only our proposed algorithm is applicable in practice. The cases of 14 and 118 IEEE buses are used to illustrate the proposed methodology.      
### 24.Blind Primed Supervised (BLIPS) Learning for MR Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2104.05028.pdf)
>  This paper examines a combined supervised-unsupervised framework involving dictionary-based blind learning and deep supervised learning for MR image reconstruction from under-sampled k-space data. A major focus of the work is to investigate the possible synergy of learned features in traditional shallow reconstruction using adaptive sparsity-based priors and deep prior-based reconstruction. Specifically, we propose a framework that uses an unrolled network to refine a blind dictionary learning-based reconstruction. We compare the proposed method with strictly supervised deep learning-based reconstruction approaches on several datasets of varying sizes and anatomies. We also compare the proposed method to alternative approaches for combining dictionary-based methods with supervised learning in MR image reconstruction. The improvements yielded by the proposed framework suggest that the blind dictionary-based approach preserves fine image details that the supervised approach can iteratively refine, suggesting that the features learned using the two methods are complementary      
### 25.Robust Image Watermarking in Wavelet Domain using GBT-DWT-SVD and Whale Optimization Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2104.05023.pdf)
>  As digital content can be copied easily, Copyright infringement has become a concern nowadays. Providing a solution to prevent the abuse of such contents is very necessary. One of the most common methods to solve this problem is watermarking. In this method, a logo belongs to the owner of the media is embedded in the media. So, they can prove the originality or ownership of the media content. Images are one of the most important digital media. Therefore, in this study, a method for digital image watermarking is proposed. The proposed method is based on Graph-based Transform (GBT), Singular Value Decomposition (SVD), and Discrete Wavelet Transform (DWT) which uses a Whale Optimization Algorithm (WOA) to find the best value for the embedding coefficient in the images as well as optimal blocks. The image is first transformed to a transform domain using the DWT and GBT, and then the watermark logo embedded onto the singular values of the cover image. The objective function defined for this task is based on the three parameters PSNR and NC, in the presence of image attacks. The results of the proposed algorithm on some known images show a high performance of this method compared to other similar methods.      
### 26.Estimating articulatory movements in speech production with transformer networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.05017.pdf)
>  We estimate articulatory movements in speech production from different modalities - acoustics and phonemes. Acoustic-to articulatory inversion (AAI) is a sequence-to-sequence task. On the other hand, phoneme to articulatory (PTA) motion estimation faces a key challenge in reliably aligning the text and the articulatory movements. To address this challenge, we explore the use of a transformer architecture - FastSpeech, with explicit duration modelling to learn hard alignments between the phonemes and articulatory movements. We also train a transformer model on AAI. We use correlation coefficient (CC) and root mean squared error (rMSE) to assess the estimation performance in comparison to existing methods on both tasks. We observe 154%, 11.8% &amp; 4.8% relative improvement in CC with subject-dependent, pooled and fine-tuning strategies, respectively, for PTA estimation. Additionally, on the AAI task, we obtain 1.5%, 3% and 3.1% relative gain in CC on the same setups compared to the state-of-the-art baseline. We further present the computational benefits of having transformer architecture as representation blocks.      
### 27.The DKU System Description for The Interspeech 2021 Auto-KWS Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2104.04993.pdf)
>  This paper introduces the system submitted by the DKU-SMIIP team for the Auto-KWS 2021 Challenge. Our implementation consists of a two-stage keyword spotting system based on query-by-example spoken term detection and a speaker verification system. We employ two different detection algorithms in our proposed keyword spotting system. The first stage adopts subsequence dynamic time warping for template matching based on frame-level language-independent bottleneck feature and phoneme posterior probability. We use a sliding window template matching algorithm based on acoustic word embeddings to further verify the detection from the first stage. As a result, our KWS system achieves an average score of 0.61 on the feedback dataset, which outperforms the baseline1 system by 0.25.      
### 28.Data-driven predictive control with estimated prediction matrices and integral action  [ :arrow_down: ](https://arxiv.org/pdf/2104.04972.pdf)
>  This paper presents a data-driven approach to the design of predictive controllers. The prediction matrices utilized in standard model predictive control (MPC) algorithms are typically constructed using knowledge of a system model such as, state-space or input-output models. Instead, we directly estimate the prediction matrices relating future outputs with current and future inputs from measured data, off-line. On-line, the developed data--driven predictive controller reduces to solving a quadratic program with a similar structure and complexity as linear MPC. Additionally, we develop a new procedure for estimating prediction matrices from data for predictive controllers with integral action, corresponding to the rate-based formulation of linear MPC. The effectiveness of the developed data-driven predictive controller is illustrated on position control of a linear motor model.      
### 29.Edge-Aware Image Compression using Deep Learning-based Super-resolution Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.04926.pdf)
>  We propose a learning-based compression scheme that envelopes a standard codec between pre and post-processing deep CNNs. Specifically, we demonstrate improvements over prior approaches utilizing a compression-decompression network by introducing: (a) an edge-aware loss function to prevent blurring that is commonly occurred in prior works &amp; (b) a super-resolution convolutional neural network (CNN) for post-processing along with a corresponding pre-processing network for improved rate-distortion performance in the low rate regime. The algorithm is assessed on a variety of datasets varying from low to high resolution namely Set 5, Set 7, Classic 5, Set 14, Live 1, Kodak, General 100, CLIC 2019. When compared to JPEG, JPEG2000, BPG, and recent CNN approach, the proposed algorithm contributes significant improvement in PSNR with an approximate gain of 20.75%, 8.47%, 3.22%, 3.23% and 24.59%, 14.46%, 10.14%, 8.57% at low and high bit-rates respectively. Similarly, this improvement in MS-SSIM is approximately 71.43%, 50%, 36.36%, 23.08%, 64.70% and 64.47%, 61.29%, 47.06%, 51.52%, 16.28% at low and high bit-rates respectively. With CLIC 2019 dataset, PSNR is found to be superior with approximately 16.67%, 10.53%, 6.78%, and 24.62%, 17.39%, 14.08% at low and high bit-rates respectively, over JPEG2000, BPG, and recent CNN approach. Similarly, the MS-SSIM is found to be superior with approximately 72%, 45.45%, 39.13%, 18.52%, and 71.43%, 50%, 41.18%, 17.07% at low and high bit-rates respectively, compared to the same approaches. A similar type of improvement is achieved with other datasets also.      
### 30.Nonlinear parameter-varying state-feedback design for a gyroscope using virtual control contraction metrics  [ :arrow_down: ](https://arxiv.org/pdf/2104.04917.pdf)
>  In this paper, we present a virtual control contraction metric (VCCM) based nonlinear parameter-varying (NPV) approach to design a state-feedback controller for a control moment gyroscope (CMG) to track a user-defined trajectory set. This VCCM based nonlinear stabilization and performance synthesis approach, which is similar to linear parameter-varying (LPV) control approaches, allows to achieve exact guarantees of exponential stability and $\mathcal{L}_2$-gain performance on nonlinear systems with respect to all trajectories from the predetermined set, which is not the case with the conventional LPV methods. Simulation and experimental studies conducted in both fully- and under-actuated operating modes of the CMG show effectiveness of this approach compared to standard LPV control methods.      
### 31.RAN Slicing in Multi-MVNO Environment under Dynamic Channel Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2104.04900.pdf)
>  With the increasing diversity in the requirement of wireless services with guaranteed quality of service(QoS), radio access network(RAN) slicing becomes an important aspect in implementation of next generation wireless systems(5G). RAN slicing involves division of network resources into many logical segments where each segment has specific QoS and can serve users of mobile virtual network operator(MVNO) with these requirements. This allows the Network Operator(NO) to provide service to multiple MVNOs each with different service requirements. Efficient allocation of the available resources to slices becomes vital in determining number of users and therefore, number of MVNOs that a NO can support. In this work, we study the problem of Modulation and Coding Scheme(MCS) aware RAN slicing(MaRS) in the context of a wireless system having MVNOs which have users with minimum data rate requirement. Channel Quality Indicator(CQI) report sent from each user in the network determines the MCS selected, which in turn determines the achievable data rate. But the channel conditions might not remain the same for the entire duration of user being served. For this reason, we consider the channel conditions to be dynamic where the choice of MCS level varies at each time instant. We model the MaRS problem as a Non-Linear Programming problem and show that it is NP-Hard. Next, we propose a solution based on greedy algorithm paradigm. We then develop an upper performance bound for this problem and finally evaluate the performance of proposed solution by comparing against the upper bound under various channel and network configurations.      
### 32.NeMo Toolbox for Speech Dataset Construction  [ :arrow_down: ](https://arxiv.org/pdf/2104.04896.pdf)
>  In this paper, we introduce a new toolbox for constructing speech datasets from long audio recording and raw reference texts. We develop tools for each step of the speech dataset construction pipeline including data preprocessing, audio-text alignment, data post-processing and filtering. The proposed pipeline also supports human-in-the-loop to address text-audio mismatch issues and remove samples that don't satisfy the quality requirements. We demonstrated the toolbox efficiency by building the Russian LibriSpeech corpus (RuLS) from LibriVox audiobooks. The toolbox is opne sourced in NeMo framework. The RuLS corpus is released in OpenSLR.      
### 33.A Moment-Based Safety Analysis for Stochastic Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.04892.pdf)
>  Given a stochastic dynamical system modelled via stochastic differential equations (SDEs), we evaluate the safety of the system through characterisations of its exit time moments. We lift the (possibly nonlinear) dynamics into the space of the occupation and exit measures to obtain a set of linear evolution equations which depend on the infinitesimal generator of the SDE. Coupled with appropriate semidefinite positive matrix constraints, this yields a moment-based approach for the computation of exit time moments of SDEs with polynomial drift and diffusion dynamics. To extend the capability of the moment approach, we propose a state augmentation method which allows us to generate the evolution equations for a broader class of nonlinear stochastic systems and apply the moment method to previously unsupported dynamics. In particular, we show a general augmentation strategy for sinusoidal dynamics which can be found in most physical systems. We employ the methodology on an Ornstein-Uhlenbeck process and stochastic spring-mass-damper model to characterise their safety via their expected exit times and show the additional exit distribution insights that are afforded through higher order moments.      
### 34.Real-time Operation Optimization of Microgrids with Battery Energy Storage System: A Tube-based Model Predictive Control Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.04819.pdf)
>  Battery energy storage systems (ESS) are widely used in microgrids to complement high renewables. However, the real-time energy management of microgrids with battery ESS is challenging in two aspects: 1) the evolution process of battery energy level is across-time coupled; 2) uncertainties unavoidably arise in the forecasting process for renewable generation. In this paper, a tube-based model predictive control (MPC) approach is innovatively proposed in accommodating the real-time energy management of microgrids with battery ESS. Firstly, a real-time operation model of battery, including the degradation cost and time-aware SoC range, is proposed for the battery ESS. In particular, the battery feature shallower-cheaper is depicted and the terminal SoC requirement is achieved. Secondly, two cascaded MPC controllers are designed in the proposed tube-based MPC, in which reference trajectories are generated by the nominal MPC without uncertainties, and then the ancillary MPC steers the actual trajectories to the nominal ones upon the realization of uncertainties. Specifically, in this paper, the battery SoC is viewed as the state variable of the system, while the generator power output and exchange power with the utility are seen as control variables. Lastly, numerous case studies demonstrate the effectiveness of the proposed approach, including both the low and high penetration level of renewables. Additional Monte Carlo simulations of consecutive 365 days show that the competitive ratio of the proposed approach is excellently below 1.10.      
### 35.Q-matrix Unaware Double JPEG Detection using DCT-Domain Deep BiLSTM Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.04765.pdf)
>  The double JPEG compression detection has received much attention in recent years due to its applicability as a forensic tool for the most widely used JPEG file format. Existing state-of-the-art CNN-based methods either use histograms of all the frequencies or rely on heuristics to select histograms of specific low frequencies to classify single and double compressed images. However, even amidst lower frequencies of double compressed images/patches, histograms of all the frequencies do not have distinguishable features to separate them from single compressed images. This paper directly extracts the quantized DCT coefficients from the JPEG images without decompressing them in the pixel domain, obtains all AC frequencies' histograms, uses a module based on $1\times 1$ depth-wise convolutions to learn the inherent relation between each histogram and corresponding q-factor, and utilizes a tailor-made BiLSTM network for selectively encoding these feature vector sequences. The proposed system outperforms several baseline methods on a relatively large and diverse publicly available dataset of single and double compressed patches. Another essential aspect of any single vs. double JPEG compression detection system is handling the scenario where test patches are compressed with entirely different quantization matrices (Q-matrices) than those used while training; different camera manufacturers and image processing software generally utilize their customized quantization matrices. A set of extensive experiments shows that the proposed system trained on a single dataset generalizes well on other datasets compressed with completely unseen quantization matrices and outperforms the state-of-the-art methods in both seen and unseen quantization matrices scenarios.      
### 36.Distributed Resilient Estimation over Directed Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2104.04680.pdf)
>  This paper addresses the problem of estimating an unknown static parameter by a network of sensor nodes in a distributed manner over a directed communication network in the presence of adversaries. We introduce an algorithm, Resilient Estimation through Weight Balancing (REWB), which ensures that all the nodes, both normal and malicious, asymptotically converge to the value to be estimated provided less than half of them are affected by adversaries. We discuss how our REWB algorithm is developed using the concepts of weight balancing of directed graphs, and the consensus+innovations approach for linear estimation. Numerical simulations are presented to show the performance of our algorithm over directed graphs and its resilience to sensor attacks.      
### 37.Accented Speech Recognition Inspired by Human Perception  [ :arrow_down: ](https://arxiv.org/pdf/2104.04627.pdf)
>  While improvements have been made in automatic speech recognition performance over the last several years, machines continue to have significantly lower performance on accented speech than humans. In addition, the most significant improvements on accented speech primarily arise by overwhelming the problem with hundreds or even thousands of hours of data. Humans typically require much less data to adapt to a new accent. This paper explores methods that are inspired by human perception to evaluate possible performance improvements for recognition of accented speech, with a specific focus on recognizing speech with a novel accent relative to that of the training data. Our experiments are run on small, accessible datasets that are available to the research community. We explore four methodologies: pre-exposure to multiple accents, grapheme and phoneme-based pronunciations, dropout (to improve generalization to a novel accent), and the identification of the layers in the neural network that can specifically be associated with accent modeling. Our results indicate that methods based on human perception are promising in reducing WER and understanding how accented speech is modeled in neural networks for novel accents.      
### 38.Millimeter-Wave UAV Coveragein Urban Environments  [ :arrow_down: ](https://arxiv.org/pdf/2104.04600.pdf)
>  With growing interest in mmWave connectivity for UAVs, a basic question is whether networks intended for terrestrial users can provide sufficient aerial coverage as well. To assess this possibility, the paper proposes a novel evaluation methodology using generative models trained on detailed ray tracing data. These models capture complex propagation characteristics and can be readily combined with antenna and beamforming assumptions. Extensive simulation using these models indicate that standard (street-level and downtilted) base stations at typical microcellular densities can indeed provide satisfactory UAV coverage. Interestingly, the coverage is possible via a conjunction of antenna sidelobes and strong reflections. With sparser deployments, the coverage is only guaranteed at progressively higher altitudes. Additional dedicated (rooftop-mounted and uptilted) base stations strengthen the coverage provided that their density is comparable to that of the standard deployment, and would be instrumental for sparse deployments of the latter.      
### 39.A review of artificial intelligence methods combined with Raman spectroscopy to identify the composition of substances  [ :arrow_down: ](https://arxiv.org/pdf/2104.04599.pdf)
>  In general, most of the substances in nature exist in mixtures, and the noninvasive identification of mixture composition with high speed and accuracy remains a difficult task. However, the development of Raman spectroscopy, machine learning, and deep learning techniques have paved the way for achieving efficient analytical tools capable of identifying mixture components, making an apparent breakthrough in the identification of mixtures beyond the traditional chemical analysis methods. This article summarizes the work of Raman spectroscopy in identifying the composition of substances as well as provides detailed reviews on the preprocessing process of Raman spectroscopy, the analysis methods and applications of artificial intelligence. This review summarizes the work of Raman spectroscopy in identifying the composition of substances and reviews the preprocessing process of Raman spectroscopy, the analysis methods and applications of artificial intelligence. Finally, the advantages and disadvantages and development prospects of Raman spectroscopy are discussed in detail.      
### 40.End-to-End Mandarin Tone Classification with Short Term Context Information  [ :arrow_down: ](https://arxiv.org/pdf/2104.05657.pdf)
>  In this paper, we propose an end-to-end Mandarin tone classification method from continuous speech utterances utilizing both the spectrogram and the short term context information as the inputs. Both Mel-spectrograms and context segment features are used to train the tone classifier. We first divide the spectrogram frames into syllable segments using force alignment results produced by an ASR model. Then we extract the short term segment features to capture the context information across multiple syllables. Feeding both the Mel-spectrogram and the short term context segment features into an end-to-end model could significantly improve the performance. Experiments are performed on a large scale open source Mandarin speech dataset to evaluate the proposed method. Results show that the this method improves the classification accuracy from $79.5\%$ to $88.7\%$ on the AISHELL3 database.      
### 41.Fruit Quality and Defect Image Classification with Conditional GAN Data Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05647.pdf)
>  Contemporary Artificial Intelligence technologies allow for the employment of Computer Vision to discern good crops from bad, providing a step in the pipeline of selecting healthy fruit from undesirable fruit, such as those which are mouldy or gangrenous. State-of-the-art works in the field report high accuracy results on small datasets (&lt;1000 images), which are not representative of the population regarding real-world usage. The goals of this study are to further enable real-world usage by improving generalisation with data augmentation as well as to reduce overfitting and energy usage through model pruning. In this work, we suggest a machine learning pipeline that combines the ideas of fine-tuning, transfer learning, and generative model-based training data augmentation towards improving fruit quality image classification. A linear network topology search is performed to tune a VGG16 lemon quality classification model using a publicly-available dataset of 2690 images. We find that appending a 4096 neuron fully connected layer to the convolutional layers leads to an image classification accuracy of 83.77%. We then train a Conditional Generative Adversarial Network on the training data for 2000 epochs, and it learns to generate relatively realistic images. Grad-CAM analysis of the model trained on real photographs shows that the synthetic images can exhibit classifiable characteristics such as shape, mould, and gangrene. A higher image classification accuracy of 88.75% is then attained by augmenting the training with synthetic images, arguing that Conditional Generative Adversarial Networks have the ability to produce new data to alleviate issues of data scarcity. Finally, model pruning is performed via polynomial decay, where we find that the Conditional GAN-augmented classification network can retain 81.16% classification accuracy when compressed to 50% of its original size.      
### 42.Common Limitations of Image Processing Metrics: A Picture Story  [ :arrow_down: ](https://arxiv.org/pdf/2104.05642.pdf)
>  While the importance of automatic image analysis is increasing at an enormous pace, recent meta-research revealed major flaws with respect to algorithm validation. Specifically, performance metrics are key for objective, transparent and comparative performance assessment, but relatively little attention has been given to the practical pitfalls when using specific metrics for a given image analysis task. A common mission of several international initiatives is therefore to provide researchers with guidelines and tools to choose the performance metrics in a problem-aware manner. This dynamically updated document has the purpose to illustrate important limitations of performance metrics commonly applied in the field of image analysis. The current version is based on a Delphi process on metrics conducted by an international consortium of image analysis experts.      
### 43.Rethinking and Improving the Robustness of Image Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2104.05623.pdf)
>  Extensive research in neural style transfer methods has shown that the correlation between features extracted by a pre-trained VGG network has a remarkable ability to capture the visual style of an image. Surprisingly, however, this stylization quality is not robust and often degrades significantly when applied to features from more advanced and lightweight networks, such as those in the ResNet family. By performing extensive experiments with different network architectures, we find that residual connections, which represent the main architectural difference between VGG and ResNet, produce feature maps of small entropy, which are not suitable for style transfer. To improve the robustness of the ResNet architecture, we then propose a simple yet effective solution based on a softmax transformation of the feature activations that enhances their entropy. Experimental results demonstrate that this small magic can greatly improve the quality of stylization results, even for networks with random weights. This suggests that the architecture used for feature extraction is more important than the use of learned weights for the task of style transfer.      
### 44.Spatial Feature Calibration and Temporal Fusion for Effective One-stage Video Instance Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05606.pdf)
>  Modern one-stage video instance segmentation networks suffer from two limitations. First, convolutional features are neither aligned with anchor boxes nor with ground-truth bounding boxes, reducing the mask sensitivity to spatial location. Second, a video is directly divided into individual frames for frame-level instance segmentation, ignoring the temporal correlation between adjacent frames. To address these issues, we propose a simple yet effective one-stage video instance segmentation framework by spatial calibration and temporal fusion, namely STMask. To ensure spatial feature calibration with ground-truth bounding boxes, we first predict regressed bounding boxes around ground-truth bounding boxes, and extract features from them for frame-level instance segmentation. To further explore temporal correlation among video frames, we aggregate a temporal fusion module to infer instance masks from each frame to its adjacent frames, which helps our framework to handle challenging videos such as motion blur, partial occlusion and unusual object-to-camera poses. Experiments on the YouTube-VIS valid set show that the proposed STMask with ResNet-50/-101 backbone obtains 33.5 % / 36.8 % mask AP, while achieving 28.6 / 23.4 FPS on video instance segmentation. The code is released online <a class="link-external link-https" href="https://github.com/MinghanLi/STMask" rel="external noopener nofollow">this https URL</a>.      
### 45.Investigating Methods to Improve Language Model Integration for Attention-based Encoder-Decoder ASR Models  [ :arrow_down: ](https://arxiv.org/pdf/2104.05544.pdf)
>  Attention-based encoder-decoder (AED) models learn an implicit internal language model (ILM) from the training transcriptions. The integration with an external LM trained on much more unpaired text usually leads to better performance. A Bayesian interpretation as in the hybrid autoregressive transducer (HAT) suggests dividing by the prior of the discriminative acoustic model, which corresponds to this implicit LM, similarly as in the hybrid hidden Markov model approach. The implicit LM cannot be calculated efficiently in general and it is yet unclear what are the best methods to estimate it. In this work, we compare different approaches from the literature and propose several novel methods to estimate the ILM directly from the AED model. Our proposed methods outperform all previous approaches. We also investigate other methods to suppress the ILM mainly by decreasing the capacity of the AED model, limiting the label context, and also by training the AED model together with a pre-existing LM.      
### 46.Enabling Content-Centric Device-to-Device Communication in the Millimeter-Wave Band  [ :arrow_down: ](https://arxiv.org/pdf/2104.05534.pdf)
>  The growth in wireless traffic and mobility of devices have congested the core network significantly. This bottleneck, along with spectrum scarcity, made the conventional cellular networks insufficient for the dissemination of large contents. In this paper, we propose a novel scheme that enables efficient initialization of CCN-based D2D networks in the mmWave band through addressing decentralized D2D peer association and antenna beamwidth selection. The proposed scheme considers mmWave characteristics such as directional communication and blockage susceptibility. We propose a heuristic peer association algorithm to associate D2D users using context information, including link stability time and content availability. The performance of the proposed scheme in terms of data throughput and transmission efficiency is evaluated through extensive simulations. Simulation results show that the proposed scheme improves network performance significantly and outperforms other methods in the literature.      
### 47.BART based semantic correction for Mandarin automatic speech recognition system  [ :arrow_down: ](https://arxiv.org/pdf/2104.05507.pdf)
>  Although automatic speech recognition (ASR) systems achieved significantly improvements in recent years, spoken language recognition error occurs which can be easily spotted by human beings. Various language modeling techniques have been developed on post recognition tasks like semantic correction. In this paper, we propose a Transformer based semantic correction method with pretrained BART initialization, Experiments on 10000 hours Mandarin speech dataset show that character error rate (CER) can be effectively reduced by 21.7% relatively compared to our baseline ASR system. Expert evaluation demonstrates that actual improvement of our model surpasses what CER indicates.      
### 48.An MRF-UNet Product of Experts for Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05495.pdf)
>  While convolutional neural networks (CNNs) trained by back-propagation have seen unprecedented success at semantic segmentation tasks, they are known to struggle on out-of-distribution data. Markov random fields (MRFs) on the other hand, encode simpler distributions over labels that, although less flexible than UNets, are less prone to over-fitting. In this paper, we propose to fuse both strategies by computing the product of distributions of a UNet and an MRF. As this product is intractable, we solve for an approximate distribution using an iterative mean-field approach. The resulting MRF-UNet is trained jointly by back-propagation. Compared to other works using conditional random fields (CRFs), the MRF has no dependency on the imaging data, which should allow for less over-fitting. We show on 3D neuroimaging data that this novel network improves generalisation to out-of-distribution samples. Furthermore, it allows the overall number of parameters to be reduced while preserving high accuracy. These results suggest that a classic MRF smoothness prior can allow for less over-fitting when principally integrated into a CNN model. Our implementation is available at <a class="link-external link-https" href="https://github.com/balbasty/nitorch" rel="external noopener nofollow">this https URL</a>.      
### 49.Deep Learning for Prominence Detection in Children's Read Speech  [ :arrow_down: ](https://arxiv.org/pdf/2104.05488.pdf)
>  Expressive reading, considered the defining attribute of oral reading fluency, comprises the prosodic realization of phrasing and prominence. In the context of evaluating oral reading, it helps to establish the speaker's comprehension of the text. We consider a labeled dataset of children's reading recordings for the speaker-independent detection of prominent words using acoustic-prosodic and lexico-syntactic features. A previous well-tuned random forest ensemble predictor is replaced by an RNN sequence classifier to exploit potential context dependency across the longer utterance. Further, deep learning is applied to obtain word-level features from low-level acoustic contours of fundamental frequency, intensity and spectral shape in an end-to-end fashion. Performance comparisons are presented across the different feature types and across different feature learning architectures for prominent word prediction to draw insights wherever possible.      
### 50.User Logic Development for the Muon Identifier Common Readout Unit for the ALICE Experiment at the Large Hadron Collider  [ :arrow_down: ](https://arxiv.org/pdf/2104.05476.pdf)
>  The Large Hadron Collider (LHC) at CERN is undergoing a major upgrade with the goal of increasing the luminosity as more statistics are needed for precision measurements. The presented work pertains to the corresponding upgrade of the ALICE Muon Trigger (MTR) Detector, now named the Muon Identifier (MID). Previously operated in a triggered readout manner, this detector has transitioned to continuous readout with time-delimited data payloads. However, this results in data rates much higher than the previous operation and hence a new Online-Offline (O2) computing system is also being developed for real-time data processing to reduce the storage requirements. Part of the O2 System is based on FPGA technology and is known as the Common Readout Unit (CRU). Being common to many detectors necessitates the development of custom user logic per detector. This work concerns the development of the ALICE MID user logic which will interface to the core CRU firmware and perform the required data processing. It presents the development of a conceptual design and a prototype for the user logic. The resulting prototype shows the ability to meet the established requirements in an effective and optimized manner. Additionally, the modular design approach employed, allows for more features to be easily introduced.      
### 51.Scalable Power Control/Beamforming in Heterogeneous Wireless Networks with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.05463.pdf)
>  Machine learning (ML) has been widely used for efficient resource allocation (RA) in wireless networks. Although superb performance is achieved on small and simple networks, most existing ML-based approaches are confronted with difficulties when heterogeneity occurs and network size expands. In this paper, specifically focusing on power control/beamforming (PC/BF) in heterogeneous device-to-device (D2D) networks, we propose a novel unsupervised learning-based framework named heterogeneous interference graph neural network (HIGNN) to handle these challenges. First, we characterize diversified link features and interference relations with heterogeneous graphs. Then, HIGNN is proposed to empower each link to obtain its individual transmission scheme after limited information exchange with neighboring links. It is noteworthy that HIGNN is scalable to wireless networks of growing sizes with robust performance after trained on small-sized networks. Numerical results show that compared with state-of-the-art benchmarks, HIGNN achieves much higher execution efficiency while providing strong performance.      
### 52.Model predictive control for linear uncertain systems using integral quadratic constraints  [ :arrow_down: ](https://arxiv.org/pdf/2104.05444.pdf)
>  In this work, we propose a tube-based model predictive control (MPC) scheme for state and input constrained linear systems subject to dynamic uncertainties described by integral quadratic constraints (IQCs). In particular, we extend the framework of \r{ho}-hard IQCs for exponential stability analysis to consider external inputs. This allows us to show that the model error between the true uncertain system and the nominal prediction model is bounded by an exponentially stable scalar system. In the proposed tube-based MPC scheme, the state of this error bounding system is predicted along with the nominal model and used as a scaling parameter for the tube size. We prove that this MPC scheme achieves robust constraint satisfaction and input-to-state stability in the presence of dynamic uncertainties and additive bounded disturbances. In a numerical example, we demonstrate the flexibility of the proposed tube dynamics and the reduced conservatism of the IQC approach compared to other characterizations of dynamic uncertainties that are used in robust MPC.      
### 53.Contrastive Learning of Global and Local Audio-Visual Representations  [ :arrow_down: ](https://arxiv.org/pdf/2104.05418.pdf)
>  Contrastive learning has delivered impressive results in many audio-visual representation learning scenarios. However, existing approaches optimize for learning either \textit{global} representations useful for tasks such as classification, or \textit{local} representations useful for tasks such as audio-visual source localization and separation. While they produce satisfactory results in their intended downstream scenarios, they often fail to generalize to tasks that they were not originally designed for. In this work, we propose a versatile self-supervised approach to learn audio-visual representations that generalize to both the tasks which require global semantic information (e.g., classification) and the tasks that require fine-grained spatio-temporal information (e.g. localization). We achieve this by optimizing two cross-modal contrastive objectives that together encourage our model to learn discriminative global-local visual information given audio signals. To show that our approach learns generalizable video representations, we evaluate it on various downstream scenarios including action/sound classification, lip reading, deepfake detection, and sound source localization.      
### 54.Energy-Efficient Coverage Enhancement of Indoor THz-MISO Systems: An FD-NOMA Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.05391.pdf)
>  Terahertz (THz) communication is gaining more interest as one of the envisioned enablers of high-data-rate short-distance indoor applications in beyond 5G networks. Moreover, non-orthogonal multiple-access (NOMA)-enabled schemes are promising schemes to realize the target spectral efficiency, low latency, and user fairness requirements in future networks. In this paper, an energy-efficient cooperative NOMA (CNOMA) scheme that guarantees the minimum required rate for cell-edge users in an indoor THz-MISO communications network, is proposed. The proposed cooperative scheme consists of three stages: (i) beamforming stage that allocates BS beams to THz cooperating cell-center users using analog beamforming with the aid of the cosine similarity metric, (ii) user pairing stage that is tackled using the Hungarian algorithm, and (iii) a power allocation stage for the BS THz-NOMA transmit power as well as the cooperation power of the cooperating cell-center users, which is optimized in a sequential manner. The obtained results quantify the EE of the proposed scheme and shed new light on both the performance and design of multi-user THz-NOMA-enabled networks.      
### 55.Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2104.05376.pdf)
>  Artistic style transfer aims at migrating the style from an example image to a content image. Currently, optimization-based methods have achieved great stylization quality, but expensive time cost restricts their practical applications. Meanwhile, feed-forward methods still fail to synthesize complex style, especially when holistic global and local patterns exist. Inspired by the common painting process of drawing a draft and revising the details, we introduce a novel feed-forward method named Laplacian Pyramid Network (LapStyle). LapStyle first transfers global style patterns in low-resolution via a Drafting Network. It then revises the local details in high-resolution via a Revision Network, which hallucinates a residual image according to the draft and the image textures extracted by Laplacian filtering. Higher resolution details can be easily generated by stacking Revision Networks with multiple Laplacian pyramid levels. The final stylized image is obtained by aggregating outputs of all pyramid levels. %We also introduce a patch discriminator to better learn local patterns adversarially. Experiments demonstrate that our method can synthesize high quality stylized images in real time, where holistic style patterns are properly transferred.      
### 56.Capacity-Driven Low-Interference Fast Beam Synthesis for Next Generation Base Stations  [ :arrow_down: ](https://arxiv.org/pdf/2104.05363.pdf)
>  The problem of the real-time multiple-input multiple-output (MIMO) array control when requirements on capacity performance, out-of-cell interference, and computational efficiency are simultaneously enforced is addressed by means of an innovative hybrid beamforming technique. The synthesis of the excitations of the MIMO system is first re-formulated as that of matching an ideal "hybrid" pattern fitting capacity or low-interference constraints along the angular coordinates. Then, a non-iterative processing scheme is derived for each MIMO beam where numerically-efficient synthesis techniques are profitably combined. Representative results, from an extensive numerical validation, are discussed to show, also comparatively, the advantages and the current limitations of the proposed synthesis method when dealing with different propagation scenarios, number of transmitters/receivers, and noise levels.      
### 57.UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models  [ :arrow_down: ](https://arxiv.org/pdf/2104.05358.pdf)
>  We propose a novel unpaired image-to-image translation method that uses denoising diffusion probabilistic models without requiring adversarial training. Our method, UNpaired Image Translation with Denoising Diffusion Probabilistic Models (UNIT-DDPM), trains a generative model to infer the joint distribution of images over both domains as a Markov chain by minimising a denoising score matching objective conditioned on the other domain. In particular, we update both domain translation models simultaneously, and we generate target domain images by a denoising Markov Chain Monte Carlo approach that is conditioned on the input source domain images, based on Langevin dynamics. Our approach provides stable model training for image-to-image translation and generates high-quality image outputs. This enables state-of-the-art FrÃ©chet Inception Distance (FID) performance on several public datasets, including both colour and multispectral imagery, significantly outperforming the contemporary adversarial image-to-image translation methods.      
### 58.The Value of Operational Coordination for EV Fleet Aggregators  [ :arrow_down: ](https://arxiv.org/pdf/2104.05319.pdf)
>  The integration of energy systems such as electricity and gas grids and power and thermal grids can bring significant benefits in terms of system security, reliability, and reduced emissions. Another alternative coupling of sectors with large potential benefits is the power and transportation networks. This is primarily due to the increasing use of electric vehicles (EV) and their demand on the power grid. Besides, the production and operating costs of EVs and battery technologies are steadily decreasing, while tax credits for EV purchase and usage are being offered to users in developed countries. The power grid is also undergoing major upgrades and changes with the aim of ensuring environmentally sustainable grids. These factors influence our work. We present a new operating model for an integrated EV-grid system that incorporates a set of aggregators (owning a fleet of EVs) with partial access to the distribution grid. Then, the Cooperative Game Theory is used to model the behavior of the system. The Core is used to describe the stability of the interaction between these aggregators, and the Shapley value is used to assign costs to them. The results obtained show the benefit of cooperation, which could lead to an overall reduction in energy consumption, reduced operating costs for electric vehicles and the distribution grid, and, in some cases, the additional monetary budget available to reinforce the transmission and grid infrastructures.      
### 59.A Hierarchical State-Machine-Based Framework for Platoon Manoeuvre Descriptions  [ :arrow_down: ](https://arxiv.org/pdf/2104.05305.pdf)
>  This paper introduces the SEAD framework that simplifies the process of designing and describing autonomous vehicle platooning manoeuvres. Although a large body of research has been formulating platooning manoeuvres, it is still challenging to design, describe, read, and understand them. This difficulty largely arises from missing formalisation. To fill this gap, we analysed existing ways of describing manoeuvres, derived the causes of difficulty, and designed a framework that simplifies the manoeuvre design process. Alongside, a Manoeuvre Design Language was developed to structurally describe manoeuvres in a machine-readable format. Unlike state-of-the-art manoeuvre descriptions that require one state machine for every participating vehicle, the SEAD framework allows describing any manoeuvre from the single perspective of the platoon leader. %As a proof of concept, the proposed framework was implemented in the mixed traffic simulation environment BEHAVE for an autonomous highway scenario. Using this framework, we implemented several manoeuvres as they were described in literature. To demonstrate the applicability of the framework, an experiment was performed to evaluate the execution time performance of multiple alternatives of the Join-Middle manoeuvre. This proof-of-concept experiment revealed that the manoeuvre execution time can be reduced by 28 \% through parallelising various steps without considerable secondary effects. We hope that the SEAD framework will pave the way for further research in the area of new manoeuvre design and optimisation by largely simplifying and unifying platooning manoeuvre representation.      
### 60.Impact of Electric Vehicle Routing with Stochastic Demand on Grid Operation  [ :arrow_down: ](https://arxiv.org/pdf/2104.05285.pdf)
>  Given the rise of electric vehicle (EV) adoption, supported by government policies and dropping technology prices, new challenges arise in the modeling and operation of electric transportation. In this paper, we present a model for solving the EV routing problem while accounting for real-life stochastic demand behavior. We present a mathematical formulation that minimizes travel time and energy costs of an EV fleet. The EV is represented by a battery energy consumption model. To adapt our formulation to real-life scenarios, customer pick-ups and drop-offs were modeled as stochastic parameters. A chance-constrained optimization model is proposed for addressing pick-ups and drop-offs uncertainties. Computational validation of the model is provided based on representative transportation scenarios. Results obtained showed a quick convergence of our model with verifiable solutions. Finally, the impact of electric vehicles charging is validated in Downtown Manhattan, New York by assessing the effect on the distribution grid.      
### 61.Ambient awareness for agricultural robotic vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2104.05270.pdf)
>  In the last few years, robotic technology has been increasingly employed in agriculture to develop intelligent vehicles that can improve productivity and competitiveness. Accurate and robust environmental perception is a critical requirement to address unsolved issues including safe interaction with field workers and animals, obstacle detection in controlled traffic applications, crop row guidance, surveying for variable rate applications, and situation awareness, in general, towards increased process automation. Given the variety of conditions thatmay be encountered in the field, no single sensor exists that can guarantee reliable results in every scenario. The development of a multi-sensory perception systemto increase the ambient awareness of an agricultural vehicle operating in crop fields is the objective of the Ambient Awareness for Autonomous Agricultural Vehicles (QUAD-AV) project. Different onboard sensor technologies, namely stereovision, LIDAR, radar, and thermography, are considered. Novel methods for their combination are proposed to automatically detect obstacles and discern traversable from non-traversable areas. Experimental results, obtained in agricultural contexts, are presented showing the effectiveness of the proposed methods.      
### 62.A multi-sensor robotic platform for ground mapping and estimation beyond the visible spectrum  [ :arrow_down: ](https://arxiv.org/pdf/2104.05259.pdf)
>  Accurate soil mapping is critical for a highly-automated agricultural vehicle to successfully accomplish important tasks including seeding, ploughing, fertilising and controlled traffic, with limited human supervision, ensuring at the same time high safety standards. In this research, a multi-sensor ground mapping and characterisation approach is proposed, whereby data coming from heterogeneous but complementary sensors, mounted on-board an unmanned rover, are combined to generate a multi-layer map of the environment and specifically of the supporting ground. The sensor suite comprises both exteroceptive and proprioceptive devices. Exteroceptive sensors include a stereo camera, a visible and near infrared camera and a thermal imager. Proprioceptive data consist of the vertical acceleration of the vehicle sprung mass as acquired by an inertial measurement unit. The paper details the steps for the integration of the different sensor data into a unique multi-layer map and discusses a set of exteroceptive and proprioceptive features for soil characterisation and change detection. Experimental results obtained with an all-terrain vehicle operating on different ground surfaces are presented. It is shown that the proposed technologies could be potentially used to develop all-terrain self-driving systems in agriculture. In addition, multi-modal soil maps could be useful to feed farm management systems that would present to the user various soil layers incorporating colour, geometric, spectral and mechanical properties.      
### 63.Neural Camera Simulators  [ :arrow_down: ](https://arxiv.org/pdf/2104.05237.pdf)
>  We present a controllable camera simulator based on deep neural networks to synthesize raw image data under different camera settings, including exposure time, ISO, and aperture. The proposed simulator includes an exposure module that utilizes the principle of modern lens designs for correcting the luminance level. It also contains a noise module using the noise level function and an aperture module with adaptive attention to simulate the side effects on noise and defocus blur. To facilitate the learning of a simulator model, we collect a dataset of the 10,000 raw images of 450 scenes with different exposure settings. Quantitative experiments and qualitative comparisons show that our approach outperforms relevant baselines in raw data synthesize on multiple cameras. Furthermore, the camera simulator enables various applications, including large-aperture enhancement, HDR, auto exposure, and data augmentation for training local feature detectors. Our work represents the first attempt to simulate a camera sensor's behavior leveraging both the advantage of traditional raw sensor features and the power of data-driven deep learning.      
### 64.Towards a Collective Agenda on AI for Earth Science Data Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.05107.pdf)
>  In the last years we have witnessed the fields of geosciences and remote sensing and artificial intelligence to become closer. Thanks to both the massive availability of observational data, improved simulations, and algorithmic advances, these disciplines have found common objectives and challenges to advance the modeling and understanding of the Earth system. Despite such great opportunities, we also observed a worrying tendency to remain in disciplinary comfort zones applying recent advances from artificial intelligence on well resolved remote sensing problems. Here we take a position on research directions where we think the interface between these fields will have the most impact and become potential game changers. In our declared agenda for AI on Earth sciences, we aim to inspire researchers, especially the younger generations, to tackle these challenges for a real advance of remote sensing and the geosciences.      
### 65.NeMo Inverse Text Normalization: From Development To Production  [ :arrow_down: ](https://arxiv.org/pdf/2104.05055.pdf)
>  Inverse text normalization (ITN) converts spoken-domain automatic speech recognition (ASR) output into written-domain text to improve the readability of the ASR output. Many state-of-the-art ITN systems use hand-written weighted finite-state transducer(WFST) grammars since this task has extremely low tolerance to unrecoverable errors. We introduce an open-source Python WFST-based library for ITN which enables a seamless path from development to production. We describe the specification of ITN grammar rules for English, but the library can be adapted for other languages. It can also be used for written-to-spoken text normalization. We evaluate the NeMo ITN library using a modified version of the Google Text normalization dataset.      
### 66.Learning the CSI Denoising and Feedback Without Supervision  [ :arrow_down: ](https://arxiv.org/pdf/2104.05002.pdf)
>  In this work, we develop a joint denoising and feedback strategy for channel state information in frequency division duplex systems. In such systems, the biggest challenge is the overhead incurred when the mobile terminal has to send the downlink channel state information or corresponding partial information to the base station, where the complete estimates can subsequently be restored. To this end, we propose a novel learning-based framework for denoising and compression of channel estimates. Unlike existing studies, we extend a recently proposed approach and show that based solely on noisy uplink data available at the base station, it is possible to learn an autoencoder neural network that generalizes to downlink data. Subsequently, half of the autoencoder can be offloaded to the mobile terminal to generate channel feedback there as efficiently as possible, without any training effort at the mobile terminal or corresponding transfer of training data to the base station. Numerical simulations demonstrate the near optimal performance of the proposed method.      
### 67.SIGAN: A Novel Image Generation Method for Solar Cell Defect Segmentation and Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.04953.pdf)
>  Solar cell electroluminescence (EL) defect segmentation is an interesting and challenging topic. Many methods have been proposed for EL defect detection, but these methods are still unsatisfactory due to the diversity of the defect and background. In this paper, we provide a new idea of using generative adversarial network (GAN) for defect segmentation. Firstly, the GAN-based method removes the defect region in the input defective image to get a defect-free image, while keeping the background almost unchanged. Then, the subtracted image is obtained by making difference between the defective input image with the generated defect-free image. Finally, the defect region can be segmented through thresholding the subtracted image. To keep the background unchanged before and after image generation, we propose a novel strong identity GAN (SIGAN), which adopts a novel strong identity loss to constraint the background consistency. The SIGAN can be used not only for defect segmentation, but also small-samples defective dataset augmentation. Moreover, we release a new solar cell EL image dataset named as EL-2019, which includes three types of images: crack, finger interruption and defect-free. Experiments on EL-2019 dataset show that the proposed method achieves 90.34% F-score, which outperforms many state-of-the-art methods in terms of solar cell defects segmentation results.      
### 68.Innovative Bert-based Reranking Language Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.04950.pdf)
>  More recently, Bidirectional Encoder Representations from Transformers (BERT) was proposed and has achieved impressive success on many natural language processing (NLP) tasks such as question answering and language understanding, due mainly to its effective pre-training then fine-tuning paradigm as well as strong local contextual modeling ability. In view of the above, this paper presents a novel instantiation of the BERT-based contextualized language models (LMs) for use in reranking of N-best hypotheses produced by automatic speech recognition (ASR). To this end, we frame N-best hypothesis reranking with BERT as a prediction problem, which aims to predict the oracle hypothesis that has the lowest word error rate (WER) given the N-best hypotheses (denoted by PBERT). In particular, we also explore to capitalize on task-specific global topic information in an unsupervised manner to assist PBERT in N-best hypothesis reranking (denoted by TPBERT). Extensive experiments conducted on the AMI benchmark corpus demonstrate the effectiveness and feasibility of our methods in comparison to the conventional autoregressive models like the recurrent neural network (RNN) and a recently proposed method that employed BERT to compute pseudo-log-likelihood (PLL) scores for N-best hypothesis reranking.      
### 69.MPPI-VS: Sampling-Based Model Predictive Control Strategy for Constrained Image-Based and Position-Based Visual Servoing  [ :arrow_down: ](https://arxiv.org/pdf/2104.04925.pdf)
>  In this paper, we open up new avenues for visual servoing systems built upon the Path Integral (PI) optimal control theory, in which the non-linear partial differential equation (PDE) can be transformed into an expectation over all possible trajectories using the Feynman-Kac (FK) lemma. More precisely, we propose an MPPI-VS control strategy, a real-time and inversion-free control strategy on the basis of sampling-based model predictive control (namely, Model Predictive Path Integral (MPPI) control) algorithm, for both image-based, 3D point, and position-based visual servoing techniques, taking into account the system constraints (such as visibility, 3D, and control constraints) and parametric uncertainties associated with the robot and camera models as well as measurement noise. Contrary to classical visual servoing control schemes, our control strategy directly utilizes the approximation of the interaction matrix, without the need for estimating the interaction matrix inversion or performing the pseudo-inversion. We validate the MPPI-VS control strategy as well as the classical control schemes on a 6-DoF Cartesian robot with an eye-in-hand camera based on the utilization of four points in the image plane as visual features. To better assess and demonstrate the robustness and potential advantages of our proposed control strategy compared to classical schemes, intensive simulations under various operating conditions are carried out and then discussed. The obtained results demonstrate the effectiveness and capability of the proposed scheme in coping easily with the system constraints, as well as its robustness in the presence of large errors in camera parameters and measurements.      
### 70.On the Accuracy of Deterministic Models for Viral Spread on Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.04913.pdf)
>  We consider the emergent behavior of viral spread when agents in a large population interact with each other over a contact network. When the number of agents is large and the contact network is a complete graph, it is well known that the population behavior -- that is, the fraction of susceptible, infected and recovered agents -- converges to the solution of an ordinary differential equation (ODE) known as the classical SIR model as the population size approaches infinity. In contrast, we study interactions over contact networks with generic topologies and derive conditions under which the population behavior concentrates around either the classic SIR model or other deterministic models. Specifically, we show that when most vertex degrees in the contact network are sufficiently large, the population behavior concentrates around an ODE known as the network SIR model. We then study the short and intermediate-term evolution of the network SIR model and show that if the contact network has an expander-type property or the initial set of infections is well-mixed in the population, the network SIR model reduces to the classical SIR model. To complement these results, we illustrate through simulations that the two models can yield drastically different predictions, hence use of the classical SIR model can be misleading in certain cases.      
### 71.NOMA for Next-generation Massive IoT: Performance Potential and Technology Directions  [ :arrow_down: ](https://arxiv.org/pdf/2104.04911.pdf)
>  Broader applications of the Internet of Things (IoT) are expected in the forthcoming 6G system, although massive IoT is already a key scenario in 5G, predominantly relying on physical layer solutions inherited from 4G LTE and primarily using orthogonal multiple access (OMA). In 6G IoT, supporting a massive number of connections will be required for diverse services of the vertical sectors, prompting fundamental studies on how to improve the spectral efficiency of the system. One of the key enabling technologies is non-orthogonal multiple access (NOMA). This paper consists of two parts. In the first part, finite block length theory and the diversity order of multi-user systems will be used to show the significant potential of NOMA compared to traditional OMA. The supremacy of NOMA over OMA is particularly pronounced for asynchronous contention-based systems relying on imperfect link adaptation, which are commonly assumed for massive IoT systems. To approach these performance bounds, in the second part of the paper, several promising technology directions are proposed for 6G massive IoT, including linear spreading, joint spreading &amp; modulation, multi-user channel coding in the context of various techniques for practical uncoordinated transmissions, cell-free operations, etc., from the perspective of NOMA.      
### 72.Global Convergence of Policy Gradient Primal-dual Methods for Risk-constrained LQRs  [ :arrow_down: ](https://arxiv.org/pdf/2104.04901.pdf)
>  While the techniques in optimal control theory are often model-based, the policy optimization (PO) approach can directly optimize the performance metric of interest without explicit dynamical models, and is an essential approach for reinforcement learning problems. However, it usually leads to a non-convex optimization problem in most cases, where there is little theoretical understanding on its performance. In this paper, we focus on the risk-constrained Linear Quadratic Regulator (LQR) problem with noisy input via the PO approach, which results in a challenging non-convex problem. To this end, we first build on our earlier result that the optimal policy has an affine structure to show that the associated Lagrangian function is locally gradient dominated with respect to the policy, based on which we establish strong duality. Then, we design policy gradient primal-dual methods with global convergence guarantees to find an optimal policy-multiplier pair in both model-based and sample-based settings. Finally, we use samples of system trajectories in simulations to validate our policy gradient primal-dual methods.      
### 73.The Atari Data Scraper  [ :arrow_down: ](https://arxiv.org/pdf/2104.04893.pdf)
>  Reinforcement learning has made great strides in recent years due to the success of methods using deep neural networks. However, such neural networks act as a black box, obscuring the inner workings. While reinforcement learning has the potential to solve unique problems, a lack of trust and understanding of reinforcement learning algorithms could prevent their widespread adoption. Here, we present a library that attaches a "data scraper" to deep reinforcement learning agents, acting as an observer, and then show how the data collected by the Atari Data Scraper can be used to understand and interpret deep reinforcement learning agents. The code for the Atari Data Scraper can be found here: <a class="link-external link-https" href="https://github.com/IRLL/Atari-Data-Scraper" rel="external noopener nofollow">this https URL</a>      
### 74.Affinity-Based Hierarchical Learning of Dependent Concepts for Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.04889.pdf)
>  In multi-class classification tasks, like human activity recognition, it is often assumed that classes are separable. In real applications, this assumption becomes strong and generates inconsistencies. Besides, the most commonly used approach is to learn classes one-by-one against the others. This computational simplification principle introduces strong inductive biases on the learned theories. In fact, the natural connections among some classes, and not others, deserve to be taken into account. In this paper, we show that the organization of overlapping classes (multiple inheritances) into hierarchies considerably improves classification performances. This is particularly true in the case of activity recognition tasks featured in the SHL dataset. After theoretically showing the exponential complexity of possible class hierarchies, we propose an approach based on transfer affinity among the classes to determine an optimal hierarchy for the learning process. Extensive experiments show improved performances and a reduction in the number of examples needed to learn.      
### 75.Quantum Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2104.04888.pdf)
>  This letter is a proof of concept for quantum power flow (QPF) algorithms which underpin various unprecedentedly efficient power system analytics exploiting quantum computing. Our contributions are three-fold: 1) Establish a quantum-state-based fast decoupled model empowered by Hermitian and constant Jacobian matrices; 2) Devise an enhanced Harrow-Hassidim-Lloyd (HHL) algorithm to solve the fast decoupled QPF; 3) Further improve the HHL efficiency by parameterizing quantum phase estimation and reciprocal rotation only at the beginning stage. Promising test results validate the accuracy and efficacy of QPF and demonstrate QPF's enormous potential in the era of quantum computing.      
### 76.Description of Structural Biases and Associated Data in Sensor-Rich Environments  [ :arrow_down: ](https://arxiv.org/pdf/2104.04885.pdf)
>  In this article, we study activity recognition in the context of sensor-rich environments. We address, in particular, the problem of inductive biases and their impact on the data collection process. To be effective and robust, activity recognition systems must take these biases into account at all levels and model them as hyperparameters by which they can be controlled. Whether it is a bias related to sensor measurement, transmission protocol, sensor deployment topology, heterogeneity, dynamicity, or stochastic effects, it is important to understand their substantial impact on the quality of activity recognition models. This study highlights the need to separate the different types of biases arising in real situations so that machine learning models, e.g., adapt to the dynamicity of these environments, resist to sensor failures, and follow the evolution of the sensors topology. We propose a metamodeling process in which the sensor data is structured in layers. The lower layers encode the various biases linked to transformations, transmissions, and topology of data. The upper layers encode biases related to the data itself. This way, it becomes easier to model hyperparameters and follow changes in the data acquisition infrastructure. We illustrate our approach on the SHL dataset which provides motion sensor data for a list of human activities collected under real conditions. The trade-offs exposed and the broader implications of our approach are discussed with alternative techniques to encode and incorporate knowledge into activity recognition models.      
### 77.Hyperspectral Pigment Analysis of Cultural Heritage Artifacts Using the Opaque Form of Kubelka-Munk Theory  [ :arrow_down: ](https://arxiv.org/pdf/2104.04884.pdf)
>  Kubelka-Munk (K-M) theory has been successfully used to estimate pigment concentrations in the pigment mixtures of modern paintings in spectral imagery. In this study the single-constant K-M theory has been utilized for the classification of green pigments in the Selden Map of China, a navigational map of the South China Sea likely created in the early seventeenth century. Hyperspectral data of the map was collected at the Bodleian Library, University of Oxford, and can be used to estimate the pigment diversity, and spatial distribution, within the map. This work seeks to assess the utility of analyzing the data in the K/S space from Kubelka-Munk theory, as opposed to the traditional reflectance domain. We estimate the dimensionality of the data and extract endmembers in the reflectance domain. Then we perform linear unmixing to estimate abundances in the K/S space, and following Bai, et al. (2017), we perform a classification in the abundance space. Finally, due to the lack of ground truth labels, the classification accuracy was estimated by computing the mean spectrum of each class as the representative signature of that class, and calculating the root mean squared error with all the pixels in that class to create a spatial representation of the error. This highlights both the magnitude of, and any spatial pattern in, the errors, indicating if a particular pigment is not well modeled in this approach.      
### 78.Quantum Machine Learning for Power System Stability Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2104.04855.pdf)
>  Transient stability assessment (TSA), a cornerstone for resilient operations of today's interconnected power grids, is a grand challenge yet to be addressed since the genesis of electric power systems. This paper is a confluence of quantum computing, data science and machine learning to potentially resolve the aforementioned challenge caused by high dimensionality, non-linearity and uncertainty. We devise a quantum TSA (qTSA) method, a low-depth, high expressibility quantum neural network, to enable scalable and efficient data-driven transient stability prediction for bulk power systems. qTSA renders the intractable TSA straightforward and effortless in the Hilbert space, and provides rich information that enables unprecedentedly resilient and secure power system operations. Extensive experiments on quantum simulators and real quantum computers verify the accuracy, noise-resilience, scalability and universality of qTSA. qTSA underpins a solid foundation of a quantum-enabled, ultra-resilient power grid which will benefit the people as well as various commercial and industrial sectors.      
### 79.Error Propagation in Satellite Multi-image Geometry  [ :arrow_down: ](https://arxiv.org/pdf/2104.04843.pdf)
>  This paper describes an investigation of the source of geospatial error in digital surface models (DSMs) constructed from multiple satellite images. In this study the uncertainty in surface geometry is separated into two spatial components; global error that affects the absolute position of the surface, and local error that varies from surface point to surface point. The global error component is caused by inaccuracy in the satellite imaging process, mainly due to uncertainty in the satellite position and orientation (pose) during image collection. A key result of the investigation is a new algorithm for determining the absolute geoposition of the DSM that takes into account the pose covariance of each satellite during image collection. This covariance information is used to weigh the evidence from each image in the computation of the global position of the DSM. The use of covariance information significantly decreases the overall uncertainty in global position. The paper also describes an approach to the prediction of local error in the DSM surface. The observed variance in surface position within a single stereo surface reconstruction defines the local horizontal error. The variance in the fused set of elevations from multiple stereo pairs at a single DSM location defines the local vertical error. These accuracy predictions are compared to ground truth provided by LiDAR scans of the same geographic region of interest.      
### 80.Non-autoregressive Transformer-based End-to-end ASR using BERT  [ :arrow_down: ](https://arxiv.org/pdf/2104.04805.pdf)
>  Transformer-based models have led to a significant innovation in various classic and practical subjects, including speech processing, natural language processing, and computer vision. On top of the transformer, the attention-based end-to-end automatic speech recognition (ASR) models have become a popular fashion in recent years. Specifically, the non-autoregressive modeling, which can achieve fast inference speed and comparable performance when compared to conventional autoregressive methods, is an emergent research topic. In the context of natural language processing, the bidirectional encoder representations from transformers (BERT) model has received widespread attention, partially due to its ability to infer contextualized word representations and to obtain superior performances of downstream tasks by performing only simple fine-tuning. In order to not only inherit the advantages of non-autoregressive ASR modeling, but also receive benefits from a pre-trained language model (e.g., BERT), a non-autoregressive transformer-based end-to-end ASR model based on BERT is presented in this paper. A series of experiments conducted on the AISHELL-1 dataset demonstrates competitive or superior results of the proposed model when compared to state-of-the-art ASR systems.      
### 81.Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization  [ :arrow_down: ](https://arxiv.org/pdf/2104.04785.pdf)
>  As climate change increases the intensity of natural disasters, society needs better tools for adaptation. Floods, for example, are the most frequent natural disaster, and better tools for flood risk communication could increase the support for flood-resilient infrastructure development. Our work aims to enable more visual communication of large-scale climate impacts via visualizing the output of coastal flood models as satellite imagery. We propose the first deep learning pipeline to ensure physical-consistency in synthetic visual satellite imagery. We advanced a state-of-the-art GAN called pix2pixHD, such that it produces imagery that is physically-consistent with the output of an expert-validated storm surge model (NOAA SLOSH). By evaluating the imagery relative to physics-based flood maps, we find that our proposed framework outperforms baseline models in both physical-consistency and photorealism. We envision our work to be the first step towards a global visualization of how climate change shapes our landscape. Continuing on this path, we show that the proposed pipeline generalizes to visualize arctic sea ice melt. We also publish a dataset of over 25k labelled image-pairs to study image-to-image translation in Earth observation.      
### 82.MobileStyleGAN: A Lightweight Convolutional Neural Network for High-Fidelity Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2104.04767.pdf)
>  In recent years, the use of Generative Adversarial Networks (GANs) has become very popular in generative image modeling. While style-based GAN architectures yield state-of-the-art results in high-fidelity image synthesis, computationally, they are highly complex. In our work, we focus on the performance optimization of style-based generative models. We analyze the most computationally hard parts of StyleGAN2, and propose changes in the generator network to make it possible to deploy style-based generative networks in the edge devices. We introduce MobileStyleGAN architecture, which has x3.5 fewer parameters and is x9.5 less computationally complex than StyleGAN2, while providing comparable quality.      
### 83.Adversarially-Trained Nonnegative Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2104.04757.pdf)
>  We consider an adversarially-trained version of the nonnegative matrix factorization, a popular latent dimensionality reduction technique. In our formulation, an attacker adds an arbitrary matrix of bounded norm to the given data matrix. We design efficient algorithms inspired by adversarial training to optimize for dictionary and coefficient matrices with enhanced generalization abilities. Extensive simulations on synthetic and benchmark datasets demonstrate the superior predictive performance on matrix completion tasks of our proposed method compared to state-of-the-art competitors, including other variants of adversarial nonnegative matrix factorization.      
### 84.Coastline extraction from ALOS-2 satellite SAR images  [ :arrow_down: ](https://arxiv.org/pdf/2104.04722.pdf)
>  The continuous monitoring of a shore plays an essential role in designing strategies for shore protection against erosion. To avoid the effect of clouds and sunlight, satellite-based imagery with synthetic aperture radar is used to provide the required data. We show how such data can be processed using state-of-the-art methods, namely, by a deep-learning-based approach, to detect the coastline location. We split the process into data reading, data preprocessing, model training, inference, ensembling, and postprocessing, and describe the best techniques for each of the parts. Finally, we present our own solution that is able to precisely extract the coastline from an image even if it is not recognizable by a human. Our solution has been validated against the real GPS location of the coastline during Signate's competition, where it was runner-up among 109 teams across the whole world.      
### 85.DuRIN: A Deep-unfolded Sparse Seismic Reflectivity Inversion Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.04704.pdf)
>  We consider the reflection seismology problem of recovering the locations of interfaces and the amplitudes of reflection coefficients from seismic data, which are vital for estimating the subsurface structure. The reflectivity inversion problem is typically solved using greedy algorithms and iterative techniques. Sparse Bayesian learning framework, and more recently, deep learning techniques have shown the potential of data-driven approaches to solve the problem. In this paper, we propose a weighted minimax-concave penalty-regularized reflectivity inversion formulation and solve it through a model-based neural network. The network is referred to as deep-unfolded reflectivity inversion network (DuRIN). We demonstrate the efficacy of the proposed approach over the benchmark techniques by testing on synthetic 1-D seismic traces and 2-D wedge models and validation with the simulated 2-D Marmousi2 model and real data from the Penobscot 3D survey off the coast of Nova Scotia, Canada.      
### 86.Boundary and Context Aware Training for CIF-based Non-Autoregressive End-to-end ASR  [ :arrow_down: ](https://arxiv.org/pdf/2104.04702.pdf)
>  Continuous integrate-and-fire (CIF) based models, which use a soft and monotonic alignment mechanism, have been well applied in non-autoregressive (NAR) speech recognition and achieved competitive performance compared with other NAR methods. However, such an alignment learning strategy may also result in inaccurate acoustic boundary estimation and deceleration in convergence speed. To eliminate these drawbacks and improve performance further, we incorporate an additional connectionist temporal classification (CTC) based alignment loss and a contextual decoder into the CIF-based NAR model. Specifically, we use the CTC spike information to guide the leaning of acoustic boundary and adopt a new contextual decoder to capture the linguistic dependencies within a sentence in the conventional CIF model. Besides, a recently proposed Conformer architecture is also employed to model both local and global acoustic dependencies. Experiments on the open-source Mandarin corpora AISHELL-1 show that the proposed method achieves a comparable character error rate (CER) of 4.9% with only 1/24 latency compared with a state-of-the-art autoregressive (AR) Conformer model.      
### 87.Hybrid Reconfigurable Intelligent Metasurfaces: Enabling Simultaneous Tunable Reflections and Sensing for 6G Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.04690.pdf)
>  Current discussions on the sixth Generation (6G) of wireless communications are envisioning future networks as a unified communication, sensing, and computing platform that intelligently enables diverse services, ranging from immersive to mission critical applications. The recently conceived concept of the smart radio environment, enabled by Reconfigurable Intelligent Surfaces (RISs), contributes towards this intelligent networking trend, offering programmable propagation of information-bearing signals, which can be jointly optimized with transceiver operations. Typical RIS implementations include metasurfaces with nearly passive meta-atoms, allowing to solely reflect the incident wave in an externally controllable way. However, this purely reflective nature induces significant challenges in the RIS orchestration from the wireless network. For example, channel estimation, which is essential for coherent communications in RIS-empowered wireless networks, is quite challenging with the available RIS designs. This article introduces the concept of Hybrid reflecting and sensing RISs (HRISs), which enables metasurfaces to reflect the impinging signal in a controllable manner, while simultaneously sense a portion of it. The sensing capability of HRISs facilitates various network management functionalities, including channel estimation and localization. We discuss a hardware design for HRISs and detail a full-wave proof-of-concept. We highlight their distinctive properties in comparison to reflective RISs and active relays, and present a simulation study evaluating the HRIS capability for performing channel estimation. Future research challenges and opportunities arising from the concept of HRISs are presented.      
### 88.A Flexible Lossy Depth Video Coding Scheme Based on Low-rank Tensor Modelling and HEVC Intra Prediction for Free Viewpoint Video  [ :arrow_down: ](https://arxiv.org/pdf/2104.04678.pdf)
>  The compression quality losses of depth sequences determine quality of view synthesis in free-viewpoint video. The depth map intra prediction in 3D extensions of the HEVC applies intra modes with auxiliary depth modeling modes (DMMs) to better preserve depth edges and handle motion discontinuities. Although such modes enable high efficiency compression, but at the cost of very high encoding complexity. Skipping conventional intra coding modes and DMMs in depth coding limits practical applicability of the HEVC for 3D display applications. In this paper, we introduce a novel low-complexity scheme for depth video compression based on low-rank tensor decomposition and HEVC intra coding. The proposed scheme leverages spatial and temporal redundancy by compactly representing the depth sequence as a high-order tensor. Tensor factorization into a set of factor matrices following CANDECOMP PARAFAC (CP) decomposition via alternating least squares give a low-rank approximation of the scene geometry. Further, compression of factor matrices with HEVC intra prediction support arbitrary target accuracy by flexible adjustment of bitrate, varying tensor decomposition ranks and quantization parameters. The results demonstrate proposed approach achieves significant rate gains by efficiently compressing depth planes in low-rank approximated representation. The proposed algorithm is applied to encode depth maps of benchmark Ballet and Breakdancing sequences. The decoded depth sequences are used for view synthesis in a multi-view video system, maintaining appropriate rendering quality.      
### 89.Unified Source-Filter GAN: Unified Source-filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN  [ :arrow_down: ](https://arxiv.org/pdf/2104.04668.pdf)
>  We propose a unified approach to data-driven source-filter modeling using a single neural network for developing a neural vocoder capable of generating high-quality synthetic speech waveforms while retaining flexibility of the source-filter model to control their voice characteristics. Our proposed network called unified source-filter generative adversarial networks (uSFGAN) is developed by factorizing quasi-periodic parallel WaveGAN (QPPWG), one of the neural vocoders based on a single neural network, into a source excitation generation network and a vocal tract resonance filtering network by additionally implementing a regularization loss. Moreover, inspired by neural source filter (NSF), only a sinusoidal waveform is additionally used as the simplest clue to generate a periodic source excitation waveform while minimizing the effect of approximations in the source filter model. The experimental results demonstrate that uSFGAN outperforms conventional neural vocoders, such as QPPWG and NSF in both speech quality and pitch controllability.      
### 90.Regression Networks For Calculating Englacial Layer Thickness  [ :arrow_down: ](https://arxiv.org/pdf/2104.04654.pdf)
>  Ice thickness estimation is an important aspect of ice sheet studies. In this work, we use convolutional neural networks with multiple output nodes to regress and learn the thickness of internal ice layers in Snow Radar images collected in northwest Greenland. We experiment with some state-of-the-art networks and find that with the residual connections of ResNet50, we could achieve a mean absolute error of 1.251 pixels over the test set. Such regression-based networks can further be improved by embedding domain knowledge and radar information in the neural network in order to reduce the requirement of manual annotations.      
### 91.CodedStereo: Learned Phase Masks for Large Depth-of-field Stereo  [ :arrow_down: ](https://arxiv.org/pdf/2104.04641.pdf)
>  Conventional stereo suffers from a fundamental trade-off between imaging volume and signal-to-noise ratio (SNR) -- due to the conflicting impact of aperture size on both these variables. Inspired by the extended depth of field cameras, we propose a novel end-to-end learning-based technique to overcome this limitation, by introducing a phase mask at the aperture plane of the cameras in a stereo imaging system. The phase mask creates a depth-dependent point spread function, allowing us to recover sharp image texture and stereo correspondence over a significantly extended depth of field (EDOF) than conventional stereo. The phase mask pattern, the EDOF image reconstruction, and the stereo disparity estimation are all trained together using an end-to-end learned deep neural network. We perform theoretical analysis and characterization of the proposed approach and show a 6x increase in volume that can be imaged in simulation. We also build an experimental prototype and validate the approach using real-world results acquired using this prototype system.      
### 92.Cross-Modal learning for Audio-Visual Video Parsing  [ :arrow_down: ](https://arxiv.org/pdf/2104.04598.pdf)
>  In this paper we present a novel approach to the Audio-visual video parsing task that takes into cognizance how event categories bind to audio and visual modalities. The proposed parsing approach simultaneously detects the temporal boundaries in terms of start and end times of such events. This task can be naturally formulated as a Multimodal Multiple Instance Learning (MMIL) problem. We show how the MMIL task can benefit from the following techniques geared toward self and cross modal learning: (i) self-supervised pre-training based on highly aligned task audio-video grounding, (ii) global context aware attention and (iii) adversarial training. As for pre-training, we boostrap on the Uniter (style) %\todo{add citation} transformer architecture using a self-supervised objective audio-video grounding over the relatively large AudioSet dataset. This pretrained model is fine-tuned on an architectural variant of the state-of-the-art Hybrid Attention Network (HAN) %\todo{Add citation} that uses global context aware attention and adversarial training objectives for audio visual video parsing. %Further, we use a hybrid attention network and adversarial training to improve self and cross modal learning. Attentive MMIL pooling method is leveraged to adaptively explore useful audio and visual signals from different temporal segments and modalities. We present extensive experimental evaluations on the Look, Listen, and Parse (LLP) dataset and compare it against HAN. We also present several ablation tests to validate the effect of pre-training, attention and adversarial training.      
### 93.Lookup-Table Recurrent Language Models for Long Tail Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.04552.pdf)
>  We introduce Lookup-Table Language Models (LookupLM), a method for scaling up the size of RNN language models with only a constant increase in the floating point operations, by increasing the expressivity of the embedding table. In particular, we instantiate an (additional) embedding table which embeds the previous n-gram token sequence, rather than a single token. This allows the embedding table to be scaled up arbitrarily -- with a commensurate increase in performance -- without changing the token vocabulary. Since embeddings are sparsely retrieved from the table via a lookup; increasing the size of the table adds neither extra operations to each forward pass nor extra parameters that need to be stored on limited GPU/TPU memory. We explore scaling n-gram embedding tables up to nearly a billion parameters. When trained on a 3-billion sentence corpus, we find that LookupLM improves long tail log perplexity by 2.44 and long tail WER by 23.4% on a downstream speech recognition task over a standard RNN language model baseline, an improvement comparable to a scaling up the baseline by 6.2x the number of floating point operations.      

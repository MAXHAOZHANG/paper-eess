# ArXiv eess --Wed, 21 Apr 2021
### 1.Optimal Design of Electric Micromobility Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2104.10155.pdf)
>  This paper presents a modeling and optimization framework to design battery electric micromobility vehicles, minimizing their total cost of ownership (TCO). Specifically, we first identify a model of the electric powertrain of an e-scooter and an e-moped consisting of a battery, a single electric motor and a transmission. Second, we frame an optimal joint design and control problem minimizing the TCO of the vehicles. Since this problem is nonlinear w.r.t. the motor size and the total mass of the vehicle, but convex if their value is given, we efficiently solve the problem for a range of motor sizes with an algorithm based on second-order conic programming iterating on the vehicle's mass. Finally, we showcase our framework on custom-created driving cycles for both vehicles on hilly and flat scenarios, providing an in-depth analysis of the results and a numerical validation with high-fidelity simulations. Our results show that the characteristics of the area where the vehicles are employed have a significant impact on their optimal design, whilst revealing that regenerative braking and gear-changing capabilities (as in the case of a continuously variable transmission) may not be worth implementing.      
### 2.Kalman-based interacting multiple-model wind speed estimator for wind turbines  [ :arrow_down: ](https://arxiv.org/pdf/2104.10063.pdf)
>  The use of state estimation technique offers a means of inferring the rotor-effective wind speed based upon solely standard measurements of the turbine. For the ease of design and computational concerns, such estimators are typically built based upon simplified turbine models that characterise the turbine with rigid blades. Large model mismatch, particularly in the power coefficient, could lead to degradation in estimation performance. Therefore, in order to effectively reduce the adverse impact of parameter uncertainties in the estimator model, this paper develops a wind sped estimator based on the concept of interacting multiple-model adaptive estimation. The proposed estimator is composed of a bank of extended Kalman filters and each filter model is developed based on different power coefficient mapping to match the operating turbine parameter. Subsequently, the algorithm combines the wind speed estimates provided by each filter based on their statistical properties. In addition, the proposed estimator not only can infer the rotor-effective wind speed, but also the uncertain system parameters, namely, the power coefficient. Simulation results demonstrate the proposed estimator achieved better improvement in estimating the rotor-effective wind speed and power coefficient compared to the standard Kalman filter approach.      
### 3.Coverage Characterization of STAR-RIS Networks: NOMA and OMA  [ :arrow_down: ](https://arxiv.org/pdf/2104.10006.pdf)
>  The novel concept of simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is investigated, where incident signals can be transmitted and reflected to users located at different sides of the surface. In particular, the fundamental coverage range of STAR-RIS aided two-user communication networks is studied. A sum coverage range maximization problem is formulated for both non-orthogonal multiple access (NOMA) and orthogonal multiple access (OMA), where the resource allocation at the access point and the transmission and reflection coefficients at the STAR-RIS are jointly optimized to satisfy the communication requirements of users. For NOMA, we transform the non-convex decoding order constraint into a linear constraint and the resulting problem is convex, which can be optimally solved. For OMA, we first show that the optimization problem for given time/frequency resource allocation is convex. Then, we employ the one dimensional search-based algorithm to obtain the optimal solution. Numerical results reveal that the coverage can be significantly extended by the STAR-RIS compared with conventional RISs.      
### 4.Comparison of remote experiments using crowdsourcing and laboratory experiments on speech intelligibility  [ :arrow_down: ](https://arxiv.org/pdf/2104.10001.pdf)
>  Many subjective experiments have been performed to develop objective speech intelligibility measures, but the novel coronavirus outbreak has made it very difficult to conduct experiments in a laboratory. One solution is to perform remote testing using crowdsourcing; however, because we cannot control the listening conditions, it is unclear whether the results are entirely reliable. In this study, we compared speech intelligibility scores obtained in remote and laboratory experiments. The results showed that the mean and standard deviation (SD) of the remote experiments' speech reception threshold (SRT) were higher than those of the laboratory experiments. However, the variance in the SRTs across the speech-enhancement conditions revealed similarities, implying that remote testing results may be as useful as laboratory experiments to develop an objective measure. We also show that the practice session scores correlate with the SRT values. This is a priori information before performing the main tests and would be useful for data screening to reduce the variability of the SRT distribution.      
### 5.Nonlinear Tracking and Rejection using Linear Parameter-Varying Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.09938.pdf)
>  The Linear Parameter-Varying (LPV) framework has been introduced with the intention to provide stability and performance guarantees for analysis and controller synthesis for Nonlinear (NL) systems via convex methods. By extending results of the Linear Time-Invariant framework, mainly based on quadratic stability and $\mathcal{L}_2$-gain performance, it was assumed that they generalize tracking and disturbance rejection guarantees for NL systems. But as we show through examples, the notion of $\mathcal{L}_2$-gain stability and performance is not sufficient in order to satisfy the desired guarantees in case of tracking and disturbance rejection. We propose to solve this problem by the application of incremental stability and performance, which does indeed ensure these specifications. A novel approach is proposed to synthesize and realize an LPV controller which is able to guarantee incremental stability and performance for NL systems via convex optimization. Through examples, the presented method is compared to standard $\mathcal{L}_2$-gain optimal LPV controller design, showing significant performance improvements. Finally, the approach is experimentally verified on an unbalanced disc setup, demonstrating the shortcomings of standard $\mathcal{L}_2$-gain optimal LPV controllers.      
### 6.A General 3D Space-Time-Frequency Non-Stationary THz Channel Model for 6G Ultra-Massive MIMO Wireless Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09934.pdf)
>  In this paper, a novel three-dimensional (3D) space-time-frequency (STF) non-stationary geometry-based stochastic model (GBSM) is proposed for the sixth generation (6G) terahertz (THz) wireless communication systems. The proposed THz channel model is very general having the capability to capture different channel characteristics in multiple THz application scenarios such as indoor scenarios, device-to-device (D2D) communications, ultra-massive multiple-input multiple-output (MIMO) communications, and long traveling paths of users. Also, the generality of the proposed channel model is demonstrated by the fact that it can easily be reduced to different simplified channel models to fit specific scenarios by properly adjusting model parameters. The proposed general channel model takes into consideration the non-stationarities in space, time, and frequency domains caused by ultra-massive MIMO, long traveling paths, and large bandwidths of THz communications, respectively. Statistical properties of the proposed general THz channel model are investigated. The accuracy and generality of the proposed channel model are verified by comparing the simulation results of the relative angle spread and root mean square (RMS) delay spread with corresponding channel measurements.      
### 7.GPS-denied Navigation: Attitude, Position, Linear Velocity, and Gravity Estimation with Nonlinear Stochastic Observer  [ :arrow_down: ](https://arxiv.org/pdf/2104.09920.pdf)
>  Successful navigation of a rigid-body traveling with six degrees of freedom (6 DoF) requires accurate estimation of attitude , position, and linear velocity. The true navigation dynamics are highly nonlinear and are modeled on the matrix Lie group of SE2(3). This paper presents novel geometric nonlinear continuous stochastic navigation observers on SE2(3) capturing the true nonlinearity of the problem. The proposed observers combines IMU and landmark measurements. It efficiently handles the IMU measurement noise. The proposed observers are guaranteed to be almost semi-globally uniformly ultimately bounded in the mean square. Quaternion representation is provided. A real-world quadrotor measurement dataset is used to validate the effectiveness of the proposed observers in its discrete form. Keywords: Inertial navigation, stochastic system, Brownian motion process, stochastic filter algorithm, stochastic differential equation, Lie group, SE(3), SO(3), pose estimator, position, attitude, feature measurement, inertial measurement unit, IMU.      
### 8.Coverage Analysis for 3D Terahertz Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09913.pdf)
>  We conduct novel coverage probability analysis of downlink transmission in a three-dimensional (3D) terahertz (THz) communication (THzCom) system. In this system, we address the unique propagation properties in THz band, e.g., absorption loss, super-narrow directional beams, and high vulnerability towards blockage, which are fundamentally different from those at lower frequencies. Different from existing studies, we characterize the performance while considering the effect of 3D directional antennas at both access points (APs) and user equipments (UEs), and the joint impact of the blockage caused by the user itself, moving humans, and wall blockers in a 3D environment. Under such consideration, we develop a tractable analytical framework to derive a new expression for the coverage probability by examining the regions where dominant interferers (i.e., those can cause outage by themselves) can exist, and the average number of interferers existing in these regions. Aided by numerical results, we validate our analysis and reveal that ignoring the impact of the vertical heights of THz devices in the analysis leads to a substantial underestimation of the coverage probability. We also show that it is more worthwhile to increase the antenna directivity at the APs than at the UEs, to produce a more reliable THzCom system.      
### 9.An Attention-based Weakly Supervised framework for Spitzoid Melanocytic Lesion Diagnosis in WSI  [ :arrow_down: ](https://arxiv.org/pdf/2104.09878.pdf)
>  Melanoma is an aggressive neoplasm responsible for the majority of deaths from skin cancer. Specifically, spitzoid melanocytic tumors are one of the most challenging melanocytic lesions due to their ambiguous morphological features. The gold standard for its diagnosis and prognosis is the analysis of skin biopsies. In this process, dermatopathologists visualize skin histology slides under a microscope, in a high time-consuming and subjective task. In the last years, computer-aided diagnosis (CAD) systems have emerged as a promising tool that could support pathologists in daily clinical practice. Nevertheless, no automatic CAD systems have yet been proposed for the analysis of spitzoid lesions. Regarding common melanoma, no proposed system allows both the selection of the tumoral region and the prediction of the diagnosis as benign or malignant. Motivated by this, we propose a novel end-to-end weakly-supervised deep learning model, based on inductive transfer learning with an improved convolutional neural network (CNN) to refine the embedding features of the latent space. The framework is composed of a source model in charge of finding the tumor patch-level patterns, and a target model focuses on the specific diagnosis of a biopsy. The latter retrains the backbone of the source model through a multiple instance learning workflow to obtain the biopsy-level scoring. To evaluate the performance of the proposed methods, we perform extensive experiments on a private skin database with spitzoid lesions. Test results reach an accuracy of 0.9231 and 0.80 for the source and the target models, respectively. Besides, the heat map findings are directly in line with the clinicians' medical decision and even highlight, in some cases, patterns of interest that were overlooked by the pathologist due to the huge workload.      
### 10.Multiscale deep context modeling for lossless point cloud geometry compression  [ :arrow_down: ](https://arxiv.org/pdf/2104.09859.pdf)
>  We propose a practical deep generative approach for lossless point cloud geometry compression, called MSVoxelDNN, and show that it significantly reduces the rate compared to the MPEG G-PCC codec. Our previous work based on autoregressive models (VoxelDNN) has a fast training phase, however, inference is slow as the occupancy probabilities are predicted sequentially, voxel by voxel. In this work, we employ a multiscale architecture which models voxel occupancy in coarse-to-fine order. At each scale, MSVoxelDNN divides voxels into eight conditionally independent groups, thus requiring a single network evaluation per group instead of one per voxel. We evaluate the performance of MSVoxelDNN on a set of point clouds from Microsoft Voxelized Upper Bodies (MVUB) and MPEG, showing that the current method speeds up encoding/decoding times significantly compared to the previous VoxelDNN, while having average rate saving over G-PCC of 17.5%. The implementation is available at <a class="link-external link-https" href="https://github.com/Weafre/MSVoxelDNN" rel="external noopener nofollow">this https URL</a>.      
### 11.Microshift: An Efficient Image Compression Algorithm for Hardware  [ :arrow_down: ](https://arxiv.org/pdf/2104.09820.pdf)
>  In this paper, we propose an image compression algorithm called Microshift. We employ an algorithm hardware co-design methodology, yielding a hardware-friendly compression approach with low power consumption. In our method, the image is first micro-shifted, then the sub-quantized values are further compressed. Two methods, the FAST and MRF model, are proposed to recover the bit-depth by exploiting the spatial correlation of natural images. Both methods can decompress images progressively. Our compression algorithm compresses images to 1.25 bits per pixel on average with PSNR of 33.16 dB, outperforming other on-chip compression algorithms. Then, we propose a hardware architecture and implement the algorithm on an FPGA and ASIC. The results on the VLSI design further validate the low hardware complexity and high power efficiency, showing our method is promising, particularly for low-power wireless vision sensor networks.      
### 12.Model-predictive control and reinforcement learning in multi-energy system case studies  [ :arrow_down: ](https://arxiv.org/pdf/2104.09785.pdf)
>  Model-predictive-control (MPC) offers an optimal control technique to establish and ensure that the total operation cost of multi-energy systems remains at a minimum while fulfilling all system constraints. However, this method presumes an adequate model of the underlying system dynamics, which is prone to modelling errors and is not necessarily adaptive. This has an associated initial and ongoing project-specific engineering cost. In this paper, we present an on- and off-policy multi-objective reinforcement learning (RL) approach, that does not assume a model a priori, benchmarking this against a linear MPC (LMPC - to reflect current practice, though non-linear MPC performs better) - both derived from the general optimal control problem, highlighting their differences and similarities. In a simple multi-energy system (MES) configuration case study, we show that a twin delayed deep deterministic policy gradient (TD3) RL agent offers potential to match and outperform the perfect foresight LMPC benchmark (101.5%). This while the realistic LMPC, i.e. imperfect predictions, only achieves 98%. While in a more complex MES system configuration, the RL agent's performance is generally lower (94.6%), yet still better than the realistic LMPC (88.9%). In both case studies, the RL agents outperformed the realistic LMPC after a training period of 2 years using quarterly interactions with the environment. We conclude that reinforcement learning is a viable optimal control technique for multi-energy systems given adequate constraint handling and pre-training, to avoid unsafe interactions and long training periods, as is proposed in fundamental future work.      
### 13.Distributed nonlinear model predictive control of an autonomous tractor-trailer system  [ :arrow_down: ](https://arxiv.org/pdf/2104.09708.pdf)
>  This paper addresses the trajectory tracking problem of an autonomous tractor-trailer system by using a fast distributed nonlinear model predictive control algorithm in combination with nonlinear moving horizon estimation for the state and parameter estimation in which constraints on the inputs and the states can be incorporated. The proposed control algorithm is capable of driving the tractor-trailer system to any desired trajectory ensuring high control accuracy and robustness against environmental disturbances.      
### 14.Free-form tumor synthesis in computed tomography images via richer generative adversarial network  [ :arrow_down: ](https://arxiv.org/pdf/2104.09701.pdf)
>  The insufficiency of annotated medical imaging scans for cancer makes it challenging to train and validate data-hungry deep learning models in precision oncology. We propose a new richer generative adversarial network for free-form 3D tumor/lesion synthesis in computed tomography (CT) images. The network is composed of a new richer convolutional feature enhanced dilated-gated generator (RicherDG) and a hybrid loss function. The RicherDG has dilated-gated convolution layers to enable tumor-painting and to enlarge perceptive fields; and it has a novel richer convolutional feature association branch to recover multi-scale convolutional features especially from uncertain boundaries between tumor and surrounding healthy tissues. The hybrid loss function, which consists of a diverse range of losses, is designed to aggregate complementary information to improve optimization. <br>We perform a comprehensive evaluation of the synthesis results on a wide range of public CT image datasets covering the liver, kidney tumors, and lung nodules. The qualitative and quantitative evaluations and ablation study demonstrated improved synthesizing results over advanced tumor synthesis methods.      
### 15.Domain adaptation based self-correction model for COVID-19 infection segmentation in CT images  [ :arrow_down: ](https://arxiv.org/pdf/2104.09699.pdf)
>  The capability of generalization to unseen domains is crucial for deep learning models when considering real-world scenarios. However, current available medical image datasets, such as those for COVID-19 CT images, have large variations of infections and domain shift problems. To address this issue, we propose a prior knowledge driven domain adaptation and a dual-domain enhanced self-correction learning scheme. Based on the novel learning schemes, a domain adaptation based self-correction model (DASC-Net) is proposed for COVID-19 infection segmentation on CT images. DASC-Net consists of a novel attention and feature domain enhanced domain adaptation model (AFD-DA) to solve the domain shifts and a self-correction learning process to refine segmentation results. The innovations in AFD-DA include an image-level activation feature extractor with attention to lung abnormalities and a multi-level discrimination module for hierarchical feature domain alignment. The proposed self-correction learning process adaptively aggregates the learned model and corresponding pseudo labels for the propagation of aligned source and target domain information to alleviate the overfitting to noises caused by pseudo labels. Extensive experiments over three publicly available COVID-19 CT datasets demonstrate that DASC-Net consistently outperforms state-of-the-art segmentation, domain shift, and coronavirus infection segmentation methods. Ablation analysis further shows the effectiveness of the major components in our model. The DASC-Net enriches the theory of domain adaptation and self-correction learning in medical imaging and can be generalized to multi-site COVID-19 infection segmentation on CT images for clinical deployment.      
### 16.Singular Perturbation-based Reinforcement Learning of Two-Point Boundary Optimal Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09652.pdf)
>  This work presents a technique for learning systems, where the learning process is guided by knowledge of the physics of the system. In particular, we solve the problem of the two-point boundary optimal control problem of linear time-varying systems with unknown model dynamics using reinforcement learning. Borrowing techniques from singular perturbation theory, we transform the time-varying optimal control problem into a couple of time-invariant subproblems. This allows the utilization of an off-policy iteration method to learn the controller gains. We show that the performance of the learning-based controller approximates that of the model-based optimal controller and the accuracy of the approximation improves as the time horizon of the control problem increases. Finally, we provide a simulation example to verify the results of the paper.      
### 17.Memory Efficient 3D U-Net with Reversible Mobile Inverted Bottlenecks for Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.09648.pdf)
>  We propose combining memory saving techniques with traditional U-Net architectures to increase the complexity of the models on the Brain Tumor Segmentation (BraTS) challenge. The BraTS challenge consists of a 3D segmentation of a 240x240x155x4 input image into a set of tumor classes. Because of the large volume and need for 3D convolutional layers, this task is very memory intensive. To address this, prior approaches use smaller cropped images while constraining the model's depth and width. Our 3D U-Net uses a reversible version of the mobile inverted bottleneck block defined in MobileNetV2, MnasNet and the more recent EfficientNet architectures to save activation memory during training. Using reversible layers enables the model to recompute input activations given the outputs of that layer, saving memory by eliminating the need to store activations during the forward pass. The inverted residual bottleneck block uses lightweight depthwise separable convolutions to reduce computation by decomposing convolutions into a pointwise convolution and a depthwise convolution. Further, this block inverts traditional bottleneck blocks by placing an intermediate expansion layer between the input and output linear 1x1 convolution, reducing the total number of channels. Given a fixed memory budget, with these memory saving techniques, we are able to train image volumes up to 3x larger, models with 25% more depth, or models with up to 2x the number of channels than a corresponding non-reversible network.      
### 18.Selective Harmonic Elimination in a Cascaded H-Bridge Multilevel Inverter fed by High-Frequency Isolated DC-DC Converter  [ :arrow_down: ](https://arxiv.org/pdf/2104.09643.pdf)
>  In recent years, the use of multilevel inverter has become popular due to its many advantages. Due to the popularity of multilevel inverters in industries and in applications that require a wide range of voltages, there have been many challenges to achieve high-quality voltage. Many pieces of research have been done to solve the problem of annoying harmonics in multilevel inverters. In this study, pulse width modulation (PWM) has been proposed as a switching method. Using the Selective Harmonic Elimination (SHE) technique, the inverter switching can be carried out in low frequency, and also, this method can reduce the annoying harmonics significantly. However, in the lower modulation index, eliminating such harmonics is challenging, resulting in a considerable increase in output voltage distortion. This study suggests a way to solve the problem. In this research, eliminating selected harmonics in a multilevel inverter with variable DC links is proposed. The DC-link variable method in this study is to use a high-frequency isolated DC-DC converter. The proposed method is verified on a 5-level Cascaded H-Bridge (CHB) inverter using the SHE-PWM method solved by particle swarm optimization (PSO) algorithm.      
### 19.Reducing Harmonic Distortion in a 5-Level Cascaded H-bridge Inverter Fed by a 12-Pulse Thyristor Rectifier  [ :arrow_down: ](https://arxiv.org/pdf/2104.09642.pdf)
>  This paper investigates a multilevel inverter with a capability that produces a wide voltage range with high quality. The selective harmonic elimination (SHE) method is considered for a single-phase 5-level cascaded H-bridge (CHB) inverter, in which the particle swarm optimization (PSO) algorithm solves the nonlinear equations. However, eliminating the low-order harmonics has been challenging when a low range of output voltage is required. To surmount such challenges and access to a wide range of output voltage, an adjustable dc-link is introduced that allows the inverter to increase the modulation index, resulting in a significant decrease in total harmonic distortion (THD). In this paper, to regulate the dc-link voltage amount, a 12-pulse rectifier is employed to allow the inverter to produce the output voltage requirements with less distortion. To prove such claims, the PSO algorithm is modified to calculate the optimal angles, as a result, the switching angles are applied in SIMULINK MATLAB to generate a 5-level output voltage.      
### 20.Characterizing the UAV-to-Machine UWB Radio Channel in Smart Factories  [ :arrow_down: ](https://arxiv.org/pdf/2104.09629.pdf)
>  In this work, the results of Ultra-Wideband air-to-ground measurements carried out in a real-world factory environment are presented and discussed. With intelligent in-dustrial deployments in mind, we envision a scenario where the Unmanned Aerial Vehicle can be used as a supplementary tool for factory operation, optimization and control. Measurements address narrow band and wide band characterization of the wireless radio channel, and can be used for link budget calculation, interference studies and time dispersion assessment in real factories, without the usual limitation for both radio terminals to be close to ground. The measurements are performed at different locations and different heights over the 3.1-5.3 GHz band. Some fundamental propagation parameters values are determined vs. distance, height and propagation conditions. The measurements are complemented with, and compared to, conventional ground-to-ground measurements with the same setup. The conducted measurement campaign gives an insight for realizing wireless applications in smart connected factories, including UAV-assisted applications.      
### 21.Dissensus Algorithms for Opinion Dynamics on the Sphere  [ :arrow_down: ](https://arxiv.org/pdf/2104.09618.pdf)
>  In this paper, novel dissensus algorithms based on the Oja principal component analysis (PCA) flow are proposed to model opinion dynamics on the unit sphere. The information of the covariance formed by the opinion state of each agent is used to achieve a dissensus equilibrium on unsigned graphs. This differs from most of the existing work where antagonistic interactions represented by negative weights in signed graphs are used to achieve a dissensus equilibrium. The nonlinear algorithm is analyzed under both constant covariance and time-varying covariance leading to different behaviors. Stability analysis for the unstable consensus and stable dissensus equilibria is provided under various conditions. The performance of the algorithm is illustrated through a simulation experiment of a multi-agent system.      
### 22.Robust parameter design for Wiener-based binaural noise reduction methods in hearing aids  [ :arrow_down: ](https://arxiv.org/pdf/2104.09615.pdf)
>  This work presents a method for designing the weighting parameter required by Wiener-based binaural noise reduction methods. This parameter establishes the desired tradeoff between noise reduction and binaural cue preservation in hearing aid applications. The proposed strategy was specially derived for the preservation of interaural level difference, interaural time difference and interaural coherence binaural cues. It is defined as a function of the average input noise power at the microphones, providing robustness against the influence of joint changes in noise and speech power (Lombard effect), as well as to signal to noise ratio (SNR) variations. A theoretical framework, based on the mathematical definition of the homogeneity degree, is presented and applied to a generic augmented Wiener-based cost function. The theoretical insights obtained are supported bycomputational simulations and psychoacoustic experiments using the multichannel Wiener filter with interaural transfer function preservation technique (MWF-ITF), as a case study. Statistical analysis indicates that the proposed dynamic structure for the weighting parameter and the design method of its fixed part provide significant robustness against changes in the original binaural cues of both speech and residual noise, at the cost of a small decrease in the noise reduction performance, as compared to the use of a purely fixed weighting parameter.      
### 23.MBRL-Lib: A Modular Library for Model-based Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.10159.pdf)
>  Model-based reinforcement learning is a compelling framework for data-efficient learning of agents that interact with the world. This family of algorithms has many subcomponents that need to be carefully selected and tuned. As a result the entry-bar for researchers to approach the field and to deploy it in real-world tasks can be daunting. In this paper, we present MBRL-Lib -- a machine learning library for model-based reinforcement learning in continuous state-action spaces based on PyTorch. MBRL-Lib is designed as a platform for both researchers, to easily develop, debug and compare new algorithms, and non-expert user, to lower the entry-bar of deploying state-of-the-art algorithms. MBRL-Lib is open-source at <a class="link-external link-https" href="https://github.com/facebookresearch/mbrl-lib" rel="external noopener nofollow">this https URL</a>.      
### 24.On the Impact of Word Error Rate on Acoustic-Linguistic Speech Emotion Recognition: An Update for the Deep Learning Era  [ :arrow_down: ](https://arxiv.org/pdf/2104.10121.pdf)
>  Text encodings from automatic speech recognition (ASR) transcripts and audio representations have shown promise in speech emotion recognition (SER) ever since. Yet, it is challenging to explain the effect of each information stream on the SER systems. Further, more clarification is required for analysing the impact of ASR's word error rate (WER) on linguistic emotion recognition per se and in the context of fusion with acoustic information exploitation in the age of deep ASR systems. In order to tackle the above issues, we create transcripts from the original speech by applying three modern ASR systems, including an end-to-end model trained with recurrent neural network-transducer loss, a model with connectionist temporal classification loss, and a wav2vec framework for self-supervised learning. Afterwards, we use pre-trained textual models to extract text representations from the ASR outputs and the gold standard. For extraction and learning of acoustic speech features, we utilise openSMILE, openXBoW, DeepSpectrum, and auDeep. Finally, we conduct decision-level fusion on both information streams -- acoustics and linguistics. Using the best development configuration, we achieve state-of-the-art unweighted average recall values of $73.6\,\%$ and $73.8\,\%$ on the speaker-independent development and test partitions of IEMOCAP, respectively.      
### 25.Detection of Audio-Video Synchronization Errors Via Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.10116.pdf)
>  We present a new method and a large-scale database to detect audio-video synchronization(A/V sync) errors in tennis videos. A deep network is trained to detect the visual signature of the tennis ball being hit by the racquet in the video stream. Another deep network is trained to detect the auditory signature of the same event in the audio stream. During evaluation, the audio stream is searched by the audio network for the audio event of the ball being hit. If the event is found in audio, the neighboring interval in video is searched for the corresponding visual signature. If the event is not found in the video stream but is found in the audio stream, A/V sync error is flagged. We developed a large-scaled database of 504,300 frames from 6 hours of videos of tennis events, simulated A/V sync errors, and found our method achieves high accuracy on the task.      
### 26.Towards Autonomous Robotic Precision Harvesting  [ :arrow_down: ](https://arxiv.org/pdf/2104.10110.pdf)
>  This paper presents an integrated system for performing precision harvesting missions using a walking harvester. Our harvester performs the challenging task of autonomous navigation and tree grabbing in a confined, GPS denied forest environment. Strategies for mapping, localization, planning, and control are proposed and integrated into a fully autonomous system. The mission starts with a human or a mobile robot mapping the area of interest using a custom-made sensor module. Subsequently, a human expert or a data-supported algorithm selects the trees for harvesting. The sensor module is then mounted on the machine and used for localization within the given map. A planning algorithm searches for both an approach pose and a path in a single path planning problem. We design a path following controller leveraging the walking harvester's capabilities for negotiating rough terrain. Upon reaching the approach pose, the machine grabs a tree with a general-purpose gripper. This process repeats for all the trees selected by the operator (algorithm). Our system has been tested on a testing field with tree trunks and in a natural forest. To the best of our knowledge, this is the first time this level of autonomy has been shown on a full-size hydraulic machine operating in a realistic environment.      
### 27.Turning Channel Noise into an Accelerator for Over-the-Air Principal Component Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.10095.pdf)
>  Recently years, the attempts on distilling mobile data into useful knowledge has been led to the deployment of machine learning algorithms at the network edge. Principal component analysis (PCA) is a classic technique for extracting the linear structure of a dataset, which is useful for feature extraction and data compression. In this work, we propose the deployment of distributed PCA over a multi-access channel based on the algorithm of stochastic gradient descent to learn the dominant feature space of a distributed dataset at multiple devices. Over-the-air aggregation is adopted to reduce the multi-access latency, giving the name over-the-air PCA. The novelty of this design lies in exploiting channel noise to accelerate the descent in the region around each saddle point encountered by gradient descent, thereby increasing the convergence speed of over-the-air PCA. The idea is materialized by proposing a power-control scheme which detects the type of descent region and controlling the level of channel noise accordingly. The scheme is proved to achieve a faster convergence rate than in the case without power control.      
### 28.Pseudo-Boolean Functions for Optimal Z-Complementary Code Sets with Flexible Lengths  [ :arrow_down: ](https://arxiv.org/pdf/2104.10062.pdf)
>  This paper aims to construct optimal Z-complementary code set (ZCCS) with non-power-of-two (NPT) lengths to enable interference-free multicarrier code-division multiple access (MC-CDMA) systems. The existing ZCCSs with NPT lengths, which are constructed from generalized Boolean functions (GBFs), are sub-optimal only with respect to the set size upper bound. For the first time in the literature, we advocate the use of pseudo-Boolean functions (PBFs) (each of which transforms a number of binary variables to a real number as a natural generalization of GBF) for direct constructions of optimal ZCCSs with NPT lengths.      
### 29.Geometric Deep Learning on Anatomical Meshes for the Prediction of Alzheimer's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2104.10047.pdf)
>  Geometric deep learning can find representations that are optimal for a given task and therefore improve the performance over pre-defined representations. <br>While current work has mainly focused on point representations, meshes also contain connectivity information and are therefore a more comprehensive characterization of the underlying anatomical surface. <br>In this work, we evaluate four recent geometric deep learning approaches that operate on mesh representations. <br>These approaches can be grouped into template-free and template-based approaches, where the template-based methods need a more elaborate pre-processing step with the definition of a common reference template and correspondences. <br>We compare the different networks for the prediction of Alzheimer's disease based on the meshes of the hippocampus. <br>Our results show advantages for template-based methods in terms of accuracy, number of learnable parameters, and training speed. <br>While the template creation may be limiting for some applications, neuroimaging has a long history of building templates with automated tools readily available. <br>Overall, working with meshes is more involved than working with simplistic point clouds, but they also offer new avenues for designing geometric deep learning architectures.      
### 30.Safety-enhanced UAV Path Planning with Spherical Vector-based Particle Swarm Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2104.10033.pdf)
>  This paper presents a new algorithm named spherical vector-based particle swarm optimization (SPSO) to deal with the problem of path planning for unmanned aerial vehicles (UAVs) in complicated environments subjected to multiple threats. A cost function is first formulated to convert the path planning into an optimization problem that incorporates requirements and constraints for the feasible and safe operation of the UAV. SPSO is then used to find the optimal path that minimizes the cost function by efficiently searching the configuration space of the UAV via the correspondence between the particle position and the speed, turn angle and climb/dive angle of the UAV. To evaluate the performance of SPSO, eight benchmarking scenarios have been generated from real digital elevation model maps. The results show that the proposed SPSO outperforms not only other particle swarm optimization (PSO) variants including the classic PSO, phase angle-encoded PSO and quantum-behave PSO but also other state-of-the-art metaheuristic optimization algorithms including the genetic algorithm (GA), artificial bee colony (ABC), and differential evolution (DE) in most scenarios. In addition, experiments have been conducted to demonstrate the validity of the generated paths for real UAV operations. Source code of the algorithm can be found at <a class="link-external link-https" href="https://github.com/duongpm/SPSO" rel="external noopener nofollow">this https URL</a>.      
### 31.Multiple Sclerosis Lesion Analysis in Brain Magnetic Resonance Images: Techniques and Clinical Applications  [ :arrow_down: ](https://arxiv.org/pdf/2104.10029.pdf)
>  Multiple sclerosis (MS) is a chronic inflammatory and degenerative disease of the central nervous system, characterized by the appearance of focal lesions in the white and gray matter that topographically correlate with an individual patient's neurological symptoms and signs. Magnetic resonance imaging (MRI) provides detailed in-vivo structural information, permitting the quantification and categorization of MS lesions that critically inform disease management. Traditionally, MS lesions have been manually annotated on 2D MRI slices, a process that is inefficient and prone to inter-/intra-observer errors. Recently, automated statistical imaging analysis techniques have been proposed to extract and segment MS lesions based on MRI voxel intensity. However, their effectiveness is limited by the heterogeneity of both MRI data acquisition techniques and the appearance of MS lesions. By learning complex lesion representations directly from images, deep learning techniques have achieved remarkable breakthroughs in the MS lesion segmentation task. Here, we provide a comprehensive review of state-of-the-art automatic statistical and deep-learning MS segmentation methods and discuss current and future clinical applications. Further, we review technical strategies, such as domain adaptation, to enhance MS lesion segmentation in real-world clinical settings.      
### 32.A Decentralized Shared CAV System Design and Application  [ :arrow_down: ](https://arxiv.org/pdf/2104.10022.pdf)
>  In this study, we propose a novel heuristic two-step algorithm for shared ridehailing in which users can share their rides with only one more user. The algorithm, which is centrally formulated, starts with matching users and creating a set of passenger pairs in step 1 and is followed by solving an assignment problem to assign passenger pairs to the vehicles. To solve the problem of high computational time in dynamic ride-matching problems, we propose a distributed system that is based on vehicle to infrastructure (V2I) and infrastructure to infrastructure (I2I) communication. To evaluate the distributed system's performance, we compare it with the proposed centralized ridehailing algorithm. Both centralized and distributed systems are implemented in a micro-traffic simulator to assess their performance and their impact on traffic congestion. Downtown Toronto road network was chosen as the study area. Based on our obtained results, the service rate of the distributed system was 91.59% which is close to 95.80% in the centralized system. However, the distributed system yielded much lower computational time compared to centralized. Furthermore, the scalability of the distributed system was shown by testing it on a small network and comparing with the entire network.      
### 33.Review of end-to-end speech synthesis technology based on deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.09995.pdf)
>  As an indispensable part of modern human-computer interaction system, speech synthesis technology helps users get the output of intelligent machine more easily and intuitively, thus has attracted more and more attention. Due to the limitations of high complexity and low efficiency of traditional speech synthesis technology, the current research focus is the deep learning-based end-to-end speech synthesis technology, which has more powerful modeling ability and a simpler pipeline. It mainly consists of three modules: text front-end, acoustic model, and vocoder. This paper reviews the research status of these three parts, and classifies and compares various methods according to their emphasis. Moreover, this paper also summarizes the open-source speech corpus of English, Chinese and other languages that can be used for speech synthesis tasks, and introduces some commonly used subjective and objective speech quality evaluation method. Finally, some attractive future research directions are pointed out.      
### 34.A Survey on Fundamental Limits of Integrated Sensing and Communication  [ :arrow_down: ](https://arxiv.org/pdf/2104.09954.pdf)
>  The integrated sensing and communication (ISAC), in which the sensing and communication share the same frequency band and hardware, has emerged as a key technology in future wireless systems. Early works on ISAC have been focused on the design, analysis and optimization of practical ISAC technologies for various ISAC systems. While this line of works are necessary, it is equally important to study the fundamental limits of ISAC in order to understand the gap between the current state-of-the-art technologies and the performance limits, and provide useful insights and guidance for the development of better ISAC technologies that can approach the performance limits. In this paper, we aim to provide a comprehensive survey for the current research progress on the fundamental limits of ISAC. Particularly, we first propose a systematic classification method for both traditional radio sensing (such as radar sensing and wireless localization) and ISAC so that they can be naturally incorporated into a unified framework. Then we summarize the major performance metrics and bounds used in sensing, communications and ISAC, respectively. After that, we present the current research progresses on fundamental limits of each class of the traditional sensing and ISAC systems. Finally, the open problems and future research directions are discussed.      
### 35.A cappella: Audio-visual Singing Voice Separation  [ :arrow_down: ](https://arxiv.org/pdf/2104.09946.pdf)
>  Music source separation can be interpreted as the estimation of the constituent music sources that a music clip is composed of. In this work, we explore the single-channel singing voice separation problem from a multimodal perspective, by jointly learning from audio and visual modalities. To do so, we present Acappella, a dataset spanning around 46 hours of a cappella solo singing videos sourced from YouTube. We propose Y-Net, an audio-visual convolutional neural network which achieves state-of-the-art singing voice separation results on the Acappella dataset and compare it against its audio-only counterpart, U-Net, and a state-of-the-art audio-visual speech separation model. Singing voice separation can be particularly challenging when the audio mixture also comprises of other accompaniment voices and background sounds along with the target voice of interest. We demonstrate that our model can outperform the baseline models in the singing voice separation task in such challenging scenarios. The code, the pre-trained models and the dataset will be publicly available at <a class="link-external link-https" href="https://ipcv.github.io/Acappella/" rel="external noopener nofollow">this https URL</a>      
### 36.Active and sparse methods in smoothed model checking  [ :arrow_down: ](https://arxiv.org/pdf/2104.09940.pdf)
>  Smoothed model checking based on Gaussian process classification provides a powerful approach for statistical model checking of parametric continuous time Markov chain models. The method constructs a model for the functional dependence of satisfaction probability on the Markov chain parameters. This is done via Gaussian process inference methods from a limited number of observations for different parameter combinations. In this work we consider extensions to smoothed model checking based on sparse variational methods and active learning. Both are used successfully to improve the scalability of smoothed model checking. In particular, we see that active learning-based ideas for iteratively querying the simulation model for observations can be used to steer the model-checking to more informative areas of the parameter space and thus improve sample efficiency. Online extensions of sparse variational Gaussian process inference algorithms are demonstrated to provide a scalable method for implementing active learning approaches for smoothed model checking.      
### 37.Market Value of Differentially-Private Smart Meter Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.09898.pdf)
>  This paper proposes a framework to investigate the value of sharing privacy-protected smart meter data between domestic consumers and load serving entities. The framework consists of a discounted differential privacy model to ensure individuals cannot be identified from aggregated data, a ANN-based short-term load forecasting to quantify the impact of data availability and privacy protection on the forecasting error and an optimal procurement problem in day-ahead and balancing markets to assess the market value of the privacy-utility trade-off. The framework demonstrates that when the load profile of a consumer group differs from the system average, which is quantified using the Kullback-Leibler divergence, there is significant value in sharing smart meter data while retaining individual consumer privacy.      
### 38.Distributed Online Aggregative Optimization for Dynamic Multi-robot Coordination  [ :arrow_down: ](https://arxiv.org/pdf/2104.09847.pdf)
>  This paper focuses on an online version of the emerging distributed constrained aggregative optimization framework, which is particularly suited for applications arising in cooperative robotics. Agents in a network want to minimize the sum of local cost functions, each one depending both on a local optimization variable, subject to a local constraint, and on an aggregated version of all the variables (e.g., the mean). We focus on a challenging online scenario in which the cost, the aggregation functions and the constraints can all change over time, thus enlarging the class of captured applications. Inspired by an existing scheme, we propose a distributed algorithm with constant step size, named Projected Aggregative Tracking, to solve the online optimization problem. We prove that the dynamic regret is bounded by a constant term and a linear term related to time variations. Moreover, in the static case (i.e., with constant cost and constraints), the solution estimates are proved to converge with a linear rate to the optimal solution. Finally, numerical examples show the efficacy of the proposed approach on a multi-robot basketball game and a robotic surveillance scenario.      
### 39.WiFiMod: Transformer-based Indoor Human Mobility Modeling using Passive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2104.09835.pdf)
>  Modeling human mobility has a wide range of applications from urban planning to simulations of disease spread. It is well known that humans spend 80% of their time indoors but modeling indoor human mobility is challenging due to three main reasons: (i) the absence of easily acquirable, reliable, low-cost indoor mobility datasets, (ii) high prediction space in modeling the frequent indoor mobility, and (iii) multi-scalar periodicity and correlations in mobility. To deal with all these challenges, we propose WiFiMod, a Transformer-based, data-driven approach that models indoor human mobility at multiple spatial scales using WiFi system logs. WiFiMod takes as input enterprise WiFi system logs to extract human mobility trajectories from smartphone digital traces. Next, for each extracted trajectory, we identify the mobility features at multiple spatial scales, macro, and micro, to design a multi-modal embedding Transformer that predicts user mobility for several hours to an entire day across multiple spatial granularities. Multi-modal embedding captures the mobility periodicity and correlations across various scales while Transformers capture long-term mobility dependencies boosting model prediction performance. This approach significantly reduces the prediction space by first predicting macro mobility, then modeling indoor scale mobility, micro-mobility, conditioned on the estimated macro mobility distribution, thereby using the topological constraint of the macro-scale. Experimental results show that WiFiMod achieves a prediction accuracy of at least 10% points higher than the current state-of-art models. Additionally, we present 3 real-world applications of WiFiMod - (i) predict high-density hot pockets for policy-making decisions for COVID19 or ILI, (ii) generate a realistic simulation of indoor mobility, (iii) design personal assistants.      
### 40.Identification of fake stereo audio  [ :arrow_down: ](https://arxiv.org/pdf/2104.09832.pdf)
>  Channel is one of the important criterions for digital audio quality. General-ly, stereo audio two channels can provide better perceptual quality than mono audio. To seek illegal commercial benefit, one might convert mono audio to stereo one with fake quality. Identifying of stereo faking audio is still a less-investigated audio forensic issue. In this paper, a stereo faking corpus is first present, which is created by Haas Effect technique. Then the effect of stereo faking on Mel Frequency Cepstral Coefficients (MFCC) is analyzed to find the difference between the real and faked stereo audio. Fi-nally, an effective algorithm for identifying stereo faking audio is proposed, in which 80-dimensional MFCC features and Support Vector Machine (SVM) classifier are adopted. The experimental results on three datasets with five different cut-off frequencies show that the proposed algorithm can ef-fectively detect stereo faking audio and achieve a good robustness.      
### 41.A simple vision-based navigation and control strategy for autonomous drone racing  [ :arrow_down: ](https://arxiv.org/pdf/2104.09815.pdf)
>  In this paper, we present a control system that allows a drone to fly autonomously through a series of gates marked with ArUco tags. A simple and low-cost DJI Tello EDU quad-rotor platform was used. Based on the API provided by the manufacturer, we have created a Python application that enables the communication with the drone over WiFi, realises drone positioning based on visual feedback, and generates control. Two control strategies were proposed, compared, and critically analysed. In addition, the accuracy of the positioning method used was measured. The application was evaluated on a laptop computer (about 40 fps) and a Nvidia Jetson TX2 embedded GPU platform (about 25 fps). We provide the developed code on GitHub.      
### 42.Deep Learning based Efficient Symbol-Level Precoding Design for MU-MISO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09799.pdf)
>  The recently emerged symbol-level precoding (SLP) technique has been regarded as a promising solution in multi-user wireless communication systems, since it can convert harmful multi-user interference (MUI) into beneficial signals for enhancing system performance. However, the tremendous computational complexity of conventional symbol-level precoding designs severely hinders the practical implementations. In order to tackle this difficulty, we propose a novel deep learning (DL) based approach to efficiently design the symbol-level precoders. Particularly, in this correspondence, we consider a multi-user multi-input single-output (MU-MISO) downlink system. An efficient precoding neural network (EPNN) is introduced to optimize the symbol-level precoders for maximizing the minimum quality-of-service (QoS) of all users under the power constraint. Simulation results demonstrate that the proposed EPNN based SLP design can dramatically reduce the computing time at the price of slight performance loss compared with the conventional convex optimization based SLP design.      
### 43.CoDR: Computation and Data Reuse Aware CNN Accelerator  [ :arrow_down: ](https://arxiv.org/pdf/2104.09798.pdf)
>  Computation and Data Reuse is critical for the resource-limited Convolutional Neural Network (CNN) accelerators. This paper presents Universal Computation Reuse to exploit weight sparsity, repetition, and similarity simultaneously in a convolutional layer. Moreover, CoDR decreases the cost of weight memory access by proposing a customized Run-Length Encoding scheme and the number of memory accesses to the intermediate results by introducing an input and output stationary dataflow. Compared to two recent compressed CNN accelerators with the same area of 2.85 mm^2, CoDR decreases SRAM access by 5.08x and 7.99x, and consumes 3.76x and 6.84x less energy.      
### 44.An Efficient Approach for Anomaly Detection in Traffic Videos  [ :arrow_down: ](https://arxiv.org/pdf/2104.09758.pdf)
>  Due to its relevance in intelligent transportation systems, anomaly detection in traffic videos has recently received much interest. It remains a difficult problem due to a variety of factors influencing the video quality of a real-time traffic feed, such as temperature, perspective, lighting conditions, and so on. Even though state-of-the-art methods perform well on the available benchmark datasets, they need a large amount of external training data as well as substantial computational resources. In this paper, we propose an efficient approach for a video anomaly detection system which is capable of running at the edge devices, e.g., on a roadside camera. The proposed approach comprises a pre-processing module that detects changes in the scene and removes the corrupted frames, a two-stage background modelling module and a two-stage object detector. Finally, a backtracking anomaly detection algorithm computes a similarity statistic and decides on the onset time of the anomaly. We also propose a sequential change detection algorithm that can quickly adapt to a new scene and detect changes in the similarity statistic. Experimental results on the Track 4 test set of the 2021 AI City Challenge show the efficacy of the proposed framework as we achieve an F1-score of 0.9157 along with 8.4027 root mean square error (RMSE) and are ranked fourth in the competition.      
### 45.Supervisory Control of Quantum Discrete Event Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09753.pdf)
>  Discrete event systems (DES) have been established and deeply developed in the framework of probabilistic and fuzzy computing models due to the necessity of practical applications in fuzzy and probabilistic systems. With the development of quantum computing and quantum control, a natural problem is to simulate DES by means of quantum computing models and to establish {\it quantum DES} (QDES). The motivation is twofold: on the one hand, QDES have potential applications when DES are simulated and processed by quantum computers, where quantum systems are employed to simulate the evolution of states driven by discrete events, and on the other hand, QDES may have essential advantages over DES concerning state complexity for imitating some practical problems. The goal of this paper is to establish a basic framework of QDES by using {\it quantum finite automata} (QFA) as the modelling formalisms, and the supervisory control theorems of QDES are established and proved. Then we present a polynomial-time algorithm to decide whether or not the controllability condition holds. In particular, we construct a number of new examples of QFA to illustrate the supervisory control of QDES and to verify the essential advantages of QDES over DES in state complexity.      
### 46.Waveform Phasicity Prediction from Arterial Sounds through Spectogram Analysis using Convolutional Neural Networks for Limb Perfusion Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2104.09748.pdf)
>  Peripheral Arterial Disease (PAD) is a common form of arterial occlusive disease that is challenging to evaluate at the point-of-care. Hand-held dopplers are the most ubiquitous device used to evaluate circulation and allows providers to audibly "listen" to the blood flow. Providers use the audible feedback to subjectively assess whether the sound characteristics are consistent with Monophasic, Biphasic, or Triphasic waveforms. Subjective assessment of doppler sounds raises suspicion of PAD and leads to further testing, often delaying definitive treatment. Misdiagnoses are also possible with subjective interpretation of doppler waveforms. This paper presents a Deep Learning system that has the ability to predict waveform phasicity through analysis of hand-held doppler sounds. We collected 268 four-second recordings on an iPhone taken during a formal vascular lab study in patients with cardiovascular disease. Our end-to-end system works by converting input sound into a spectrogram which visually represents frequency changes in temporal patterns. This conversion enables visual differentiation between the phasicity classes. With these changes present, a custom trained Convolutional Neural Network (CNN) is used for prediction through learned feature extraction. The performance of the model was evaluated via calculation of the F1 score and accuracy metrics. The system received an F1 score of 90.57\% and an accuracy of 96.23\%. Our Deep Learning system is not computationally expensive and has the ability for integration within several applications. When used in a clinic, this system has the capability of preventing misdiagnosis and gives practitioners a second opinion that can be useful in the evaluation of PAD.      
### 47.AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.09715.pdf)
>  Text to speech (TTS) is widely used to synthesize personal voice for a target speaker, where a well-trained source TTS model is fine-tuned with few paired adaptation data (speech and its transcripts) on this target speaker. However, in many scenarios, only untranscribed speech data is available for adaptation, which brings challenges to the previous TTS adaptation pipelines (e.g., AdaSpeech). In this paper, we develop AdaSpeech 2, an adaptive TTS system that only leverages untranscribed speech data for adaptation. Specifically, we introduce a mel-spectrogram encoder to a well-trained TTS model to conduct speech reconstruction, and at the same time constrain the output sequence of the mel-spectrogram encoder to be close to that of the original phoneme encoder. In adaptation, we use untranscribed speech data for speech reconstruction and only fine-tune the TTS decoder. AdaSpeech 2 has two advantages: 1) Pluggable: our system can be easily applied to existing trained TTS models without re-training. 2) Effective: our system achieves on-par voice quality with the transcribed TTS adaptation (e.g., AdaSpeech) with the same amount of untranscribed data, and achieves better voice quality than previous untranscribed adaptation methods. Synthesized speech samples can be found at <a class="link-external link-https" href="https://speechresearch.github.io/adaspeech2/" rel="external noopener nofollow">this https URL</a>.      
### 48.Controlling Pivoting Gait using Graph Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.09689.pdf)
>  Pivoting gait is efficient for manipulating a big and heavy object with relatively small manipulating force, in which a robot iteratively tilts the object, rotates it around the vertex, and then puts it down to the floor. However, pivoting gait can easily fail even with a small external disturbance due to its instability in nature. To cope with this problem, we propose a controller to robustly control the object motion during the pivoting gait by introducing two gait modes, i.e., one is the double-support mode, which can manipulate a relatively light object with faster speed, and the other is the quadruple-support mode, which can manipulate a relatively heavy object with lower speed. To control the pivoting gait, a graph model predictive control is applied taking into account of these two gait modes. By adaptively switching the gait mode according to the applied external disturbance, a robot can stably perform the pivoting gait even if the external disturbance is applied to the object.      
### 49.Exploiting Underlay Spectrum Sharing in Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.09671.pdf)
>  We investigate the coexistence of underlay spectrum sharing in cell-free massive multiple-input multiple-output (MIMO) systems. A primary system with geographically distributed primary access points (P-APs) serves a multitude of primary users (PUs), while a secondary system serves a large number of secondary users (SUs) in the same primary/licensed spectrum by exploiting the underlay spectrum sharing. To mitigate the secondary co-channel interference inflected at PUs, stringent secondary transmit power constraints are defined for the secondary access points (S-APs). A generalized pilots sharing scheme is used to locally estimate the uplink channels at P-APs/S-APs, and thereby, conjugate precoders are adopted to serve PUs/SUs in the same time-frequency resource element. Moreover, the effect of a user-centric AP clustering scheme is investigated by assigning a suitable set of APs to a particular user. The impact of estimated downlink (DL) channels at PUs/SUs via DL pilots beamformed by P-APs/S-APs is investigated. The achievable primary/secondary rates at PUs/SUs are derived for the statistical DL and estimated DL CSI cases. User-fairness for PUs/SUs is achieved by designing efficient transmit power control policies based on a multi-objective optimization problem formulation of joint underlay spectrum sharing and max-min criteria. The proposed orthogonal multiple-access based analytical framework is also extended to facilitate non-orthogonal multiple-access. Our analysis and numerical results manifest that the primary/secondary performance of underlay spectrum sharing can be boosted by virtue of the average reduction of transmit powers/path-losses, uniform coverage/service, and macro-diversity gains, which are inherent to distributed transmissions/receptions of cell-free massive MIMO.      
### 50.A New Class of Efficient Adaptive Filters for Online Nonlinear Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2104.09641.pdf)
>  Nonlinear models are known to provide excellent performance in real-world applications that often operate in non-ideal conditions. However, such applications often require online processing to be performed with limited computational resources. In this paper, we propose a new efficient nonlinear model for online applications. The proposed algorithm is based on the linear-in-the-parameters (LIP) nonlinear filters and their implementation as functional link adaptive filters (FLAFs). We focus here on a new effective and efficient approach for FLAFs based on frequency-domain adaptive filters. We introduce the class of frequency-domain functional link adaptive filters (FD-FLAFs) and propose a partitioned block approach for their implementation. We also investigate on the functional link expansions that provide the most significant benefits operating with limited resources in the frequency-domain. We present and compare FD-FLAFs with different expansions to identify the LIP nonlinear filters showing the best tradeoff between performance and computational complexity. Experimental results prove that the frequency domain LIP nonlinear filters can be considered as an efficient and effective solution for online applications, like the nonlinear acoustic echo cancellation.      
### 51.Quaternion Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.09630.pdf)
>  Latest Generative Adversarial Networks (GANs) are gathering outstanding results through a large-scale training, thus employing models composed of millions of parameters requiring extensive computational capabilities. Building such huge models undermines their replicability and increases the training instability. Moreover, multi-channel data, such as images or audio, are usually processed by real-valued convolutional networks that flatten and concatenate the input, losing any intra-channel spatial relation. To address these issues, here we propose a family of quaternion-valued generative adversarial networks (QGANs). QGANs exploit the properties of quaternion algebra, e.g., the Hamilton product for convolutions. This allows to process channels as a single entity and capture internal latent relations, while reducing by a factor of 4 the overall number of parameters. We show how to design QGANs and to extend the proposed approach even to advanced models. We compare the proposed QGANs with real-valued counterparts on multiple image generation benchmarks. Results show that QGANs are able to generate visually pleasing images and to obtain better FID scores with respect to their real-valued GANs. Furthermore, QGANs save up to 75% of the training parameters. We believe these results may pave the way to novel, more accessible, GANs capable of improving performance and saving computational resources.      
### 52.Towards Guaranteed Safety Assurance of Automated Driving Systems with Scenario Sampling: An Invariant Set Perspective (Extended Version)  [ :arrow_down: ](https://arxiv.org/pdf/2104.09595.pdf)
>  How many scenarios are sufficient to validate the safe Operational Design Domain (ODD) of an Automated Driving System (ADS) equipped vehicle? Is a more significant number of sampled scenarios guaranteeing a more accurate safety assessment of the ADS? Despite the various empirical success of ADS safety evaluation with scenario sampling in practice, some of the fundamental properties are largely unknown. This paper seeks to remedy this gap by formulating and tackling the scenario sampling safety assurance problem from a set invariance perspective. First, a novel conceptual equivalence is drawn between the scenario sampling safety assurance problem and the data-driven robustly controlled forward invariant set validation and quantification problem. This paper then provides a series of resolution complete and probabilistic complete solutions with finite-sampling analyses for the safety validation problem that authenticates a given ODD. On the other hand, the quantification problem escalates the validation challenge and starts looking for a safe sub-domain of a particular property. This inspires various algorithms that are provably probabilistic incomplete, probabilistic complete but sub-optimal, and asymptotically optimal. Finally, the proposed asymptotically optimal scenario sampling safety quantification algorithm is also empirically demonstrated through simulation experiments.      
### 53.Robust Uncertainty Bounds in Reproducing Kernel Hilbert Spaces: A Convex Optimization Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.09582.pdf)
>  Let a labeled dataset be given with scattered samples and consider the hypothesis of the ground-truth belonging to the reproducing kernel Hilbert space (RKHS) of a known positive-definite kernel. It is known that out-of-sample bounds can be established at unseen input locations, thus limiting the risk associated with learning this function. We show how computing tight, finite-sample uncertainty bounds amounts to solving parametric quadratically constrained linear programs. In our setting, the outputs are assumed to be contaminated by bounded measurement noise that can otherwise originate from any compactly supported distribution. No independence assumptions are made on the available data. Numerical experiments are presented to compare the present results with other closed-form alternatives.      
### 54.Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.09556.pdf)
>  Recent development of Under-Display Camera (UDC) systems provides a true bezel-less and notch-free viewing experience on smartphones (and TV, laptops, tablets), while allowing images to be captured from the selfie camera embedded underneath. In a typical UDC system, the microstructure of the semi-transparent organic light-emitting diode (OLED) pixel array attenuates and diffracts the incident light on the camera, resulting in significant image quality degradation. Oftentimes, noise, flare, haze, and blur can be observed in UDC images. In this work, we aim to analyze and tackle the aforementioned degradation problems. We define a physics-based image formation model to better understand the degradation. In addition, we utilize one of the world's first commodity UDC smartphone prototypes to measure the real-world Point Spread Function (PSF) of the UDC system, and provide a model-based data synthesis pipeline to generate realistically degraded images. We specially design a new domain knowledge-enabled Dynamic Skip Connection Network (DISCNet) to restore the UDC images. We demonstrate the effectiveness of our method through extensive experiments on both synthetic and real UDC data. Our physics-based image formation model and proposed DISCNet can provide foundations for further exploration in UDC image restoration, and even for general diffraction artifact removal in a broader sense.      

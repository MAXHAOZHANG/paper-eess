# ArXiv eess --Mon, 26 Apr 2021
### 1.Dynamic CT Reconstruction from Limited Views with Implicit Neural Representations and Parametric Motion Fields  [ :arrow_down: ](https://arxiv.org/pdf/2104.11745.pdf)
>  Reconstructing dynamic, time-varying scenes with computed tomography (4D-CT) is a challenging and ill-posed problem common to industrial and medical settings. Existing 4D-CT reconstructions are designed for sparse sampling schemes that require fast CT scanners to capture multiple, rapid revolutions around the scene in order to generate high quality results. However, if the scene is moving too fast, then the sampling occurs along a limited view and is difficult to reconstruct due to spatiotemporal ambiguities. In this work, we design a reconstruction pipeline using implicit neural representations coupled with a novel parametric motion field warping to perform limited view 4D-CT reconstruction of rapidly deforming scenes. Importantly, we utilize a differentiable analysis-by-synthesis approach to compare with captured x-ray sinogram data in a self-supervised fashion. Thus, our resulting optimization method requires no training data to reconstruct the scene. We demonstrate that our proposed system robustly reconstructs scenes containing deformable and periodic motion and validate against state-of-the-art baselines. Further, we demonstrate an ability to reconstruct continuous spatiotemporal representations of our scenes and upsample them to arbitrary volumes and frame rates post-optimization. This research opens a new avenue for implicit neural representations in computed tomography reconstruction in general.      
### 2.On the Optimal Power Allocation and User Pairing for Uplink Non-Orthogonal Multiple Access Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.11679.pdf)
>  In this paper, we derive the optimal user pairing and power allocation in uplink non orthogonal multiple access (NOMA) networks. The optimal power allocation that maximizes the sum rate is found for two user NOMA networks, while ensuring that the individual rates of NOMA users are at least equal to those they would achieve with orthogonal multiple access (OMA). Next, we prove that in a 2K user network and when the optimal power allocation is used, the optimal pairing reduces to pairing the user with index k to the user with index 2K-k+1, i.e., the user with the best channel condition and the one with the worst channel condition are paired together, the second best with the second worst and so on. Finally, the expressions of the corresponding optimal NOMA power coefficients are derived analytically for networks with more than two users. With these expressions at hand, our simulation results validate the superiority of NOMA over OMA in terms of sum rates.      
### 3.Output Regulation of Linear Stochastic Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.11675.pdf)
>  We address the output regulation problem for a general class of linear stochastic systems. Specifically, we formulate and solve the ideal full-information and output-feedback problems, obtaining perfect, but non-causal, asymptotic regulation. A characterisation of the problem solvability is deduced. We point out that the ideal problems cannot be solved in practice because they unrealistically require that the Brownian motion affecting the system is available for feedback. Drawing from the ideal solution, we formulate and solve approximate versions of the full-information and output-feedback problems, which do not yield perfect asymptotic tracking but can be solved in a realistic scenario. These solutions rely on two key ideas: first we introduce a discrete-time a-posteriori estimator of the variations of the Brownian motion obtained causally by sampling the system state or output; second we introduce a hybrid state observer and a hybrid regulator scheme which employ the estimated Brownian variations. The approximate solution tends to the ideal as the sampling period tends to zero. The proposed theory is validated by the regulation of a circuit subject to electromagnetic noise.      
### 4.An inexact-penalty method for GNE seeking in games with dynamic agents  [ :arrow_down: ](https://arxiv.org/pdf/2104.11609.pdf)
>  We consider a network of autonomous agents whose outputs are actions in a game with coupled constraints. In such network scenarios, agents seeking to minimize coupled cost functions using distributed information while satisfying the coupled constraints. Current methods consider the small class of multi-integrator agents using primal-dual methods. These methods can only ensure constraint satisfaction in steady-state. In contrast, we propose an inexact penalty method using a barrier function for nonlinear agents with equilibrium-independent passive dynamics. We show that these dynamics converge to an epsilon-GNE while satisfying the constraints for all time, not only in steady-state. We develop these dynamics in both the full-information and partial-information settings. In the partial-information setting, dynamic estimates of the others' actions are used to make decisions and are updated through local communication. Applications to optical networks and velocity synchronization of flexible robots are provided.      
### 5.Research on the Detection Method of Breast Cancer Deep Convolutional Neural Network Based on Computer Aid  [ :arrow_down: ](https://arxiv.org/pdf/2104.11551.pdf)
>  Traditional breast cancer image classification methods require manual extraction of features from medical images, which not only require professional medical knowledge, but also have problems such as time-consuming and labor-intensive and difficulty in extracting high-quality features. Therefore, the paper proposes a computer-based feature fusion Convolutional neural network breast cancer image classification and detection method. The paper pre-trains two convolutional neural networks with different structures, and then uses the convolutional neural network to automatically extract the characteristics of features, fuse the features extracted from the two structures, and finally use the classifier classifies the fused features. The experimental results show that the accuracy of this method in the classification of breast cancer image data sets is 89%, and the classification accuracy of breast cancer images is significantly improved compared with traditional methods.      
### 6.Antenna Efficiency in Massive MIMO Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.11549.pdf)
>  In this paper, we consider the multi-user detection problem in a multiple-input multiple-output (MIMO) system, where the number of receive antennas at the base station (BS) grows infinitely large. We propose a new performance metric, called antenna efficiency, to characterize how fast the vector error probability (VEP) decreases as the number of receive antennas increases in the large system limit. We analyze the optimal maximum-likelihood (ML) detector and the simple zero-forcing (ZF) detector and prove that their antenna efficiency admits a simple closed form, which quantifies the impacts of the user-to-antenna ratio, the signal-to-noise ratio (SNR), and the constellation set on the VEP. Numerical results show that our analysis can well describe the empirical detection error performance in a realistic massive MIMO system.      
### 7.Deep Multi-Stage CSI Acquisition for Reconfigurable Intelligent Surface Aided MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.11541.pdf)
>  This article aims to reduce huge pilot overhead when estimating the reconfigurable intelligent surface (RIS) relayed wireless channel. Motivated by the compelling grasp of deep learning in tackling nonlinear mapping problems, the proposed approach only activates a part of RIS elements and utilizes the corresponding cascaded channel estimate to predict another part. Through a synthetic deep neural network (DNN), the direct channel and active cascaded channel are first estimated sequentially, followed by the channel prediction for the inactive RIS elements. A three-stage training strategy is developed for this synthetic DNN. From simulation results, the proposed deep learning based approach is effective in reducing the pilot overhead and guaranteeing the reliable estimation accuracy.      
### 8.Non-Stationary Wireless Channel Modeling Approach Based on Extreme Value Theory for Ultra-Reliable Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.11516.pdf)
>  A proper channel modeling methodology that characterizes the statistics of extreme events is key in the design of a system at an ultra-reliable regime of operation. The strict constraint of ultra-reliability corresponds to the packet error rate (PER) in the range of $10^{-9}-10^{-5}$ within the acceptable latency on the order of milliseconds. Extreme value theory (EVT) is a robust framework for modeling the statistical behavior of extreme events in the channel data. In this paper, we propose a methodology based on EVT to model the extreme events of a non-stationary wireless channel for the ultra-reliable regime of operation. This methodology includes techniques for splitting the channel data sequence into multiple groups concerning the environmental factors causing non-stationarity, and fitting the lower tail distribution of the received power in each group to the generalized Pareto distribution (GPD). The proposed approach also consists of optimally determining the time-varying threshold over which the tail statistics are derived as a function of time, and assessing the validity of the derived Pareto model. Finally, the proposed approach chooses the best model with minimum complexity that represents the time variation behavior of the non-stationary channel data sequence. Based on the data collected within the engine compartment of Fiat Linea under various engine vibrations and driving scenarios, we demonstrate the capability of the proposed methodology in providing the best fit to the extremes of the non-stationary data, significantly outperforming the channel modeling approach in characterizing the extreme events with the stationary channel assumption.      
### 9.Probabilistic Rainfall Estimation from Automotive Lidar  [ :arrow_down: ](https://arxiv.org/pdf/2104.11467.pdf)
>  Robust sensing and perception in adverse weather conditions remains one of the biggest challenges for realizing reliable autonomous vehicle mobility services. Prior work has established that rainfall rate is a useful measure for adversity of atmospheric weather conditions. This work presents a probabilistic hierarchical Bayesian model that infers rainfall rate from automotive lidar point cloud sequences with high accuracy and reliability. The model is a hierarchical mixture of expert model, or a probabilistic decision tree, with gating and expert nodes consisting of variational logistic and linear regression models. Experimental data used to train and evaluate the model is collected in a large-scale rainfall experiment facility from both stationary and moving vehicle platforms. The results show prediction accuracy comparable to the measurement resolution of a disdrometer, and the soundness and usefulness of the uncertainty estimation. The model achieves RMSE 2.42 mm/h after filtering out uncertain predictions. The error is comparable to the mean rainfall rate change of 3.5 mm/h between measurements. Model parameter studies show how predictive performance changes with tree depth, sampling duration, and crop box dimension. A second experiment demonstrate the predictability of higher rainfall above 300 mm/h using a different lidar sensor, demonstrating sensor independence.      
### 10.Integrating Sensing and Communications for Ubiquitous IoT: Applications, Trends and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2104.11457.pdf)
>  Recent advances in wireless communication and solid-state circuits together with the enormous demands of sensing ability have given rise to a new enabling technology, integrated sensing and communications (ISAC). The ISAC captures two main advantages over dedicated sensing and communication functionalities: 1) Integration gain to efficiently utilize congested resources, and even, 2) Coordination gain to balance dual-functional performance or/and perform mutual assistance. Meanwhile, triggered by ISAC, we are also witnessing a paradigm shift in the ubiquitous IoT architecture, in which the sensing and communication layers are tending to converge into a new layer, namely, the signaling layer. <br>In this paper, we first attempt to introduce a definition of ISAC, analyze the various influencing forces, and present several novel use cases. Then, we complement the understanding of the signaling layer by presenting several key benefits in the IoT era. We classify existing dominant ISAC solutions based on the layers in which integration is applied. Finally, several challenges and opportunities are discussed. We hope that this overview article will serve as a primary starting point for new researchers and offer a bird's-eye view of the existing ISAC-related advances from academia and industry, ranging from solid-state circuitry, signal processing, and wireless communication to mobile computing.      
### 11.Learning from Ambiguous Labels for Lung Nodule Malignancy Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2104.11436.pdf)
>  Lung nodule malignancy prediction is an essential step in the early diagnosis of lung cancer. Besides the difficulties commonly discussed, the challenges of this task also come from the ambiguous labels provided by annotators, since deep learning models may learn, even amplify, the bias embedded in them. In this paper, we propose a multi-view "divide-and-rule" (MV-DAR) model to learn from both reliable and ambiguous annotations for lung nodule malignancy prediction. According to the consistency and reliability of their annotations, we divide nodules into three sets: a consistent and reliable set (CR-Set), an inconsistent set (IC-Set), and a low reliable set (LR-Set). The nodule in IC-Set is annotated by multiple radiologists inconsistently, and the nodule in LR-Set is annotated by only one radiologist. The proposed MV-DAR contains three DAR submodels to characterize a lung nodule from three orthographic views. Each DAR consists of a prediction network (Prd-Net), a counterfactual network (CF-Net), and a low reliable network (LR-Net), learning on CR-Set, IC-Set, and LR-Set, respectively. The image representation ability learned by CF-Net and LR-Net is then transferred to Prd-Net by negative-attention module (NA-Module) and consistent-attention module (CA-Module), aiming to boost the prediction ability of Prd-Net. The MV-DAR model has been evaluated on the LIDC-IDRI dataset and LUNGx dataset. Our results indicate not only the effectiveness of the proposed MV-DAR model in learning from ambiguous labels but also its superiority over present noisy label-learning models in lung nodule malignancy prediction.      
### 12.Graph Neural Network Reinforcement Learning for Autonomous Mobility-on-Demand Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.11434.pdf)
>  Autonomous mobility-on-demand (AMoD) systems represent a rapidly developing mode of transportation wherein travel requests are dynamically handled by a coordinated fleet of robotic, self-driving vehicles. Given a graph representation of the transportation network - one where, for example, nodes represent areas of the city, and edges the connectivity between them - we argue that the AMoD control problem is naturally cast as a node-wise decision-making problem. In this paper, we propose a deep reinforcement learning framework to control the rebalancing of AMoD systems through graph neural networks. Crucially, we demonstrate that graph neural networks enable reinforcement learning agents to recover behavior policies that are significantly more transferable, generalizable, and scalable than policies learned through other approaches. Empirically, we show how the learned policies exhibit promising zero-shot transfer capabilities when faced with critical portability tasks such as inter-city generalization, service area expansion, and adaptation to potentially complex urban topologies.      
### 13.Predicting Distant Metastases in Soft-Tissue Sarcomas from PET-CT scans using Constrained Hierarchical Multi-Modality Feature Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.11416.pdf)
>  Distant metastases (DM) refer to the dissemination of tumors, usually, beyond the organ where the tumor originated. They are the leading cause of death in patients with soft-tissue sarcomas (STSs). Positron emission tomography-computed tomography (PET-CT) is regarded as the imaging modality of choice for the management of STSs. It is difficult to determine from imaging studies which STS patients will develop metastases. 'Radiomics' refers to the extraction and analysis of quantitative features from medical images and it has been employed to help identify such tumors. The state-of-the-art in radiomics is based on convolutional neural networks (CNNs). Most CNNs are designed for single-modality imaging data (CT or PET alone) and do not exploit the information embedded in PET-CT where there is a combination of an anatomical and functional imaging modality. Furthermore, most radiomic methods rely on manual input from imaging specialists for tumor delineation, definition and selection of radiomic features. This approach, however, may not be scalable to tumors with complex boundaries and where there are multiple other sites of disease. We outline a new 3D CNN to help predict DM in STS patients from PET-CT data. The 3D CNN uses a constrained feature learning module and a hierarchical multi-modality feature learning module that leverages the complementary information from the modalities to focus on semantically important regions. Our results on a public PET-CT dataset of STS patients show that multi-modal information improves the ability to identify those patients who develop DM. Further our method outperformed all other related state-of-the-art methods.      
### 14.Passive soft-reset controllers for nonlinear systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.11414.pdf)
>  Soft-reset controllers are introduced as a way to approximate hard-reset controllers. The focus is on implementing reset controllers that are (strictly) passive and on analyzing their interconnection with passive plants. A passive hard-reset controller that has a strongly convex energy function can be approximated as a soft-reset controller. A hard-reset controller is a hybrid system whereas a soft-reset controller corresponds to a differential inclusion, living entirely in the continuous-time domain. This feature may make soft-reset controllers easier to understand and implement. A soft-reset controller contains a parameter that can be adjusted to better approximate the action of the hard-reset controller. Closed-loop asymptotic stability is established for the interconnection of a passive soft-reset controller with a passive plant, under appropriate detectability assumptions. Several examples are used to illustrate the efficacy of soft-reset controllers.      
### 15.Backup Control Barrier Functions: Formulation and Comparative Study  [ :arrow_down: ](https://arxiv.org/pdf/2104.11332.pdf)
>  The backup control barrier function (CBF) was recently proposed as a tractable formulation that guarantees the feasibility of the CBF quadratic programming (QP) via an implicitly defined control invariant set. The control invariant set is based on a fixed backup policy and evaluated online by forward integrating the dynamics under the backup policy. This paper is intended as a tutorial of the backup CBF approach and a comparative study to some benchmarks. First, the backup CBF approach is presented step by step with the underlying math explained in detail. Second, we prove that the backup CBF always has a relative degree 1 under mild assumptions. Third, the backup CBF approach is compared with benchmarks such as Hamilton Jacobi PDE and Sum-of-Squares on the computation of control invariant sets, which shows that one can obtain a control invariant set close to the maximum control invariant set under a good backup policy for many practical problems.      
### 16.Real-time NLOS/LOS Identification for Smartphone-based Indoor Positioning System using WiFi RTT and RSS  [ :arrow_down: ](https://arxiv.org/pdf/2104.11316.pdf)
>  The accuracy of smartphone-based positioning methods using WiFi usually suffers from ranging errors caused by non-line-of-sight (NLOS) conditions. Previous research usually exploits several statistical features from a long time series (hundreds of samples) of WiFi received signal strength (RSS) or WiFi round-trip time (RTT) to achieve a high identification accuracy. However, the long time series or large sample size attributes to high power and time consumption in data collection for both training and testing. This will also undoubtedly be detrimental to user experience as the waiting time of getting enough samples is quite long. Therefore, this paper proposes a new real-time NLOS/LOS identification method for smartphone-based indoor positioning system using WiFi RTT and RSS. Based on our extensive analysis of RSS and RTT features, a machine learning-based method using random forest was chosen and developed to separate the samples for NLOS/LOS conditions. Experiments in different environments show that our method achieves a discrimination accuracy of about 94% with a sample size of 10. Considering the theoretically shortest WiFi ranging interval of 100ms of the RTT-enabled smartphones, our algorithm is able to provide the shortest latency of 1s to get the testing result among all of the state-of-art methods.      
### 17.Integrated Framework of Vehicle Dynamics, Instabilities, Energy Models, and Sparse Flow Smoothing Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2104.11267.pdf)
>  This work presents an integrated framework of: vehicle dynamics models, with a particular attention to instabilities and traffic waves; vehicle energy models, with particular attention to accurate energy values for strongly unsteady driving profiles; and sparse Lagrangian controls via automated vehicles, with a focus on controls that can be executed via existing technology such as adaptive cruise control systems. This framework serves as a key building block in developing control strategies for human-in-the-loop traffic flow smoothing on real highways. In this contribution, we outline the fundamental merits of integrating vehicle dynamics and energy modeling into a single framework, and we demonstrate the energy impact of sparse flow smoothing controllers via simulation results.      
### 18.Beyond Voice Activity Detection: Hybrid Audio Segmentation for Direct Speech Translation  [ :arrow_down: ](https://arxiv.org/pdf/2104.11710.pdf)
>  The audio segmentation mismatch between training data and those seen at run-time is a major problem in direct speech translation. Indeed, while systems are usually trained on manually segmented corpora, in real use cases they are often presented with continuous audio requiring automatic (and sub-optimal) segmentation. After comparing existing techniques (VAD-based, fixed-length and hybrid segmentation methods), in this paper we propose enhanced hybrid solutions to produce better results without sacrificing latency. Through experiments on different domains and language pairs, we show that our methods outperform all the other techniques, reducing by at least 30% the gap between the traditional VAD-based approach and optimal manual segmentation.      
### 19.Safe Chance Constrained Reinforcement Learning for Batch Process Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.11706.pdf)
>  Reinforcement Learning (RL) controllers have generated excitement within the control community. The primary advantage of RL controllers relative to existing methods is their ability to optimize uncertain systems independently of explicit assumption of process uncertainty. Recent focus on engineering applications has been directed towards the development of safe RL controllers. Previous works have proposed approaches to account for constraint satisfaction through constraint tightening from the domain of stochastic model predictive control. Here, we extend these approaches to account for plant-model mismatch. Specifically, we propose a data-driven approach that utilizes Gaussian processes for the offline simulation model and use the associated posterior uncertainty prediction to account for joint chance constraints and plant-model mismatch. The method is benchmarked against nonlinear model predictive control via case studies. The results demonstrate the ability of the methodology to account for process uncertainty, enabling satisfaction of joint chance constraints even in the presence of plant-model mismatch.      
### 20.Deep Learning Based Assessment of Synthetic Speech Naturalness  [ :arrow_down: ](https://arxiv.org/pdf/2104.11673.pdf)
>  In this paper, we present a new objective prediction model for synthetic speech naturalness. It can be used to evaluate Text-To-Speech or Voice Conversion systems and works language independently. The model is trained end-to-end and based on a CNN-LSTM network that previously showed to give good results for speech quality estimation. We trained and tested the model on 16 different datasets, such as from the Blizzard Challenge and the Voice Conversion Challenge. Further, we show that the reliability of deep learning-based naturalness prediction can be improved by transfer learning from speech quality prediction models that are trained on objective POLQA scores. The proposed model is made publicly available and can, for example, be used to evaluate different TTS system configurations.      
### 21.Encrypted Distributed Lasso for Sparse Data Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.11632.pdf)
>  The least squares problem with L1-regularized regressors, called Lasso, is a widely used approach in optimization problems where sparsity of the regressors is desired. This formulation is fundamental for many applications in signal processing, machine learning and control. As a motivating problem, we investigate a sparse data predictive control problem, run at a cloud service to control a system with unknown model, using L1-regularization to limit the behavior complexity. The input-output data collected for the system is privacy-sensitive, hence, we design a privacy-preserving solution using homomorphically encrypted data. The main challenges are the non-smoothness of the L1-norm, which is difficult to evaluate on encrypted data, as well as the iterative nature of the Lasso problem. We use a distributed ADMM formulation that enables us to exchange substantial local computation for little communication between multiple servers. We first give an encrypted multi-party protocol for solving the distributed Lasso problem, by approximating the non-smooth part with a Chebyshev polynomial, evaluating it on encrypted data, and using a more cost effective distributed bootstrapping operation. For the example of data predictive control, we prefer a non-homogeneous splitting of the data for better convergence. We give an encrypted multi-party protocol for this non-homogeneous splitting of the Lasso problem to a non-homogeneous set of servers: one powerful server and a few less powerful devices, added for security reasons. Finally, we provide numerical results for our proposed solutions.      
### 22.DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for Embedded Speech and Audio Processing from Decentralised Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.11629.pdf)
>  Deep neural speech and audio processing systems have a large number of trainable parameters, a relatively complex architecture, and require a vast amount of training data and computational power. These constraints make it more challenging to integrate such systems into embedded devices and utilise them for real-time, real-world applications. We tackle these limitations by introducing DeepSpectrumLite, an open-source, lightweight transfer learning framework for on-device speech and audio recognition using pre-trained image convolutional neural networks (CNNs). The framework creates and augments Mel-spectrogram plots on-the-fly from raw audio signals which are then used to finetune specific pre-trained CNNs for the target classification task. Subsequently, the whole pipeline can be run in real-time with a mean inference lag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola moto e7 plus smartphone. DeepSpectrumLite operates decentralised, eliminating the need for data upload for further processing. By obtaining state-of-the-art results on a set of paralinguistics tasks, we demonstrate the suitability of the proposed transfer learning approach for embedded audio signal processing, even when data is scarce. We provide an extensive command-line interface for users and developers which is comprehensively documented and publicly available at <a class="link-external link-https" href="https://github.com/DeepSpectrum/DeepSpectrumLite" rel="external noopener nofollow">this https URL</a>.      
### 23.Improving Neural Silent Speech Interface Models by Adversarial Training  [ :arrow_down: ](https://arxiv.org/pdf/2104.11601.pdf)
>  Besides the well-known classification task, these days neural networks are frequently being applied to generate or transform data, such as images and audio signals. In such tasks, the conventional loss functions like the mean squared error (MSE) may not give satisfactory results. To improve the perceptual quality of the generated signals, one possibility is to increase their similarity to real signals, where the similarity is evaluated via a discriminator network. The combination of the generator and discriminator nets is called a Generative Adversarial Network (GAN). Here, we evaluate this adversarial training framework in the articulatory-to-acoustic mapping task, where the goal is to reconstruct the speech signal from a recording of the movement of articulatory organs. As the generator, we apply a 3D convolutional network that gave us good results in an earlier study. To turn it into a GAN, we extend the conventional MSE training loss with an adversarial loss component provided by a discriminator network. As for the evaluation, we report various objective speech quality metrics such as the Perceptual Evaluation of Speech Quality (PESQ), and the Mel-Cepstral Distortion (MCD). Our results indicate that the application of the adversarial training loss brings about a slight, but consistent improvement in all these metrics.      
### 24.Region-Adaptive Deformable Network for Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2104.11599.pdf)
>  Image quality assessment (IQA) aims to assess the perceptual quality of images. The outputs of the IQA algorithms are expected to be consistent with human subjective perception. In image restoration and enhancement tasks, images generated by generative adversarial networks (GAN) can achieve better visual performance than traditional CNN-generated images, although they have spatial shift and texture noise. Unfortunately, the existing IQA methods have unsatisfactory performance on the GAN-based distortion partially because of their low tolerance to spatial misalignment. To this end, we propose the reference-oriented deformable convolution, which can improve the performance of an IQA network on GAN-based distortion by adaptively considering this misalignment. We further propose a patch-level attention module to enhance the interaction among different patch regions, which are processed independently in previous patch-based methods. The modified residual block is also proposed by applying modifications to the classic residual block to construct a patch-region-based baseline called WResNet. Equipping this baseline with the two proposed modules, we further propose Region-Adaptive Deformable Network (RADN). The experiment results on the NTIRE 2021 Perceptual Image Quality Assessment Challenge dataset show the superior performance of RADN, and the ensemble approach won fourth place in the final testing phase of the challenge. Code is available at <a class="link-external link-https" href="https://github.com/IIGROUP/RADN" rel="external noopener nofollow">this https URL</a>.      
### 25.Reconstructing Speech from Real-Time Articulatory MRI Using Neural Vocoders  [ :arrow_down: ](https://arxiv.org/pdf/2104.11598.pdf)
>  Several approaches exist for the recording of articulatory movements, such as eletromagnetic and permanent magnetic articulagraphy, ultrasound tongue imaging and surface electromyography. Although magnetic resonance imaging (MRI) is more costly than the above approaches, the recent developments in this area now allow the recording of real-time MRI videos of the articulators with an acceptable resolution. Here, we experiment with the reconstruction of the speech signal from a real-time MRI recording using deep neural networks. Instead of estimating speech directly, our networks are trained to output a spectral vector, from which we reconstruct the speech signal using the WaveGlow neural vocoder. We compare the performance of three deep neural architectures for the estimation task, combining convolutional (CNN) and recurrence-based (LSTM) neural layers. Besides the mean absolute error (MAE) of our networks, we also evaluate our models by comparing the speech signals obtained using several objective speech quality metrics like the mean cepstral distortion (MCD), Short-Time Objective Intelligibility (STOI), Perceptual Evaluation of Speech Quality (PESQ) and Signal-to-Distortion Ratio (SDR). The results indicate that our approach can successfully reconstruct the gross spectral shape, but more improvements are needed to reproduce the fine spectral details.      
### 26.A Prioritized Trajectory Planning Algorithm for Connected and Automated Vehicle Mandatory Lane Changes  [ :arrow_down: ](https://arxiv.org/pdf/2104.11590.pdf)
>  We introduce a prioritized system-optimal algorithm for mandatory lane change (MLC) behavior of connected and automated vehicles (CAV) from a dedicated lane. Our approach applies a cooperative lane change that prioritizes the decisions of lane changing vehicles which are closer to the end of the diverging zone (DZ), and optimizes the predicted total system travel time. Our experiments on synthetic data show that the proposed algorithm improves the traffic network efficiency by attaining higher speeds in the dedicated lane and earlier MLC positions while ensuring a low computational time. Our approach outperforms the traditional gap acceptance model.      
### 27.ESResNe(X)t-fbsp: Learning Robust Time-Frequency Transformation of Audio  [ :arrow_down: ](https://arxiv.org/pdf/2104.11587.pdf)
>  Environmental Sound Classification (ESC) is a rapidly evolving field that recently demonstrated the advantages of application of visual domain techniques to the audio-related tasks. Previous studies indicate that the domain-specific modification of cross-domain approaches show a promise in pushing the whole area of ESC forward. <br>In this paper, we present a new time-frequency transformation layer that is based on complex frequency B-spline (fbsp) wavelets. Being used with a high-performance audio classification model, the proposed fbsp-layer provides an accuracy improvement over the previously used Short-Time Fourier Transform (STFT) on standard datasets. We also investigate the influence of different pre-training strategies, including the joint use of two large-scale datasets for weight initialization: ImageNet and AudioSet. Our proposed model out-performs other approaches by achieving accuracies of 95.20 % on the ESC-50 and 89.14 % on the UrbanSound8K datasets. <br>Additionally, we assess the increase of model robustness against additive white Gaussian noise and reduction of an effective sample rate introduced by the proposed layer and demonstrate that the fbsp-layer improves the model's ability to withstand signal perturbations, in comparison to STFT-based training. For the sake of reproducibility, our code is made available.      
### 28.Practical Hybrid Beamforming for Millimeter Wave Massive MIMO Full Duplex with Limited Dynamic Range  [ :arrow_down: ](https://arxiv.org/pdf/2104.11537.pdf)
>  In this paper, we present a novel joint hybrid beamforming (HYBF) and combining scheme in a single-cell millimeter wave (mmWave) massive MIMO full-duplex (FD) system for weighted sum-rate (WSR) maximization with multi-antenna half-duplex (HD) uplink and downlink users with non-ideal hardware. Moreover, we present a novel interference and self-interference (SI) aware power allocation scheme for the optimal beamforming directions. Compared to the traditional sum-power constraints, the proposed algorithm is designed under the joint sum-power and per-antenna power constraints. The sum-power constraints are naturally imposed to limit the maximum transmission power. However, each antenna has its power amplifier (PA), and the per-antenna power constraints consider the physical limits of each PA while maximizing the communication system's performance. To model the non-ideal hardware of the FD base station and the half-duplex users, we extend the traditional limited dynamic range (LDR) noise model to mmWave with a FD hybrid transceiver. Our design relies on alternating optimization based on the minorization-maximization method. A detailed numerical analysis is presented, and the impact of the different levels of the LDR noise variance on the maximum achievable performance for HYBF in a practical FD system is investigated. Simulation results show significant performance improvement compared to the traditional HD system. However, the maximum achievable performance gain results to be limited by the LDR noise level.      
### 29.3D Convolutional Neural Networks for Ultrasound-Based Silent Speech Interfaces  [ :arrow_down: ](https://arxiv.org/pdf/2104.11532.pdf)
>  Silent speech interfaces (SSI) aim to reconstruct the speech signal from a recording of the articulatory movement, such as an ultrasound video of the tongue. Currently, deep neural networks are the most successful technology for this task. The efficient solution requires methods that do not simply process single images, but are able to extract the tongue movement information from a sequence of video frames. One option for this is to apply recurrent neural structures such as the long short-term memory network (LSTM) in combination with 2D convolutional neural networks (CNNs). Here, we experiment with another approach that extends the CNN to perform 3D convolution, where the extra dimension corresponds to time. In particular, we apply the spatial and temporal convolutions in a decomposed form, which proved very successful recently in video action recognition. We find experimentally that our 3D network outperforms the CNN+LSTM model, indicating that 3D CNNs may be a feasible alternative to CNN+LSTM networks in SSI systems.      
### 30.UAV Communications with WPT-aided Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.11513.pdf)
>  Cell-free (CF) massive multiple-input multiple-output (MIMO) is a promising solution to provide uniform good performance for unmanned aerial vehicle (UAV) communications. In this paper, we propose the UAV communication with wireless power transfer (WPT) aided CF massive MIMO systems, where the harvested energy (HE) from the downlink WPT is used to support both uplink data and pilot transmission. We derive novel closed-form downlink HE and uplink spectral efficiency (SE) expressions that take hardware impairments of UAV into account. UAV communications with current small cell (SC) and cellular massive MIMO enabled WPT systems are also considered for comparison. It is significant to show that CF massive MIMO achieves two and five times higher 95\%-likely uplink SE than the ones of SC and cellular massive MIMO, respectively. Besides, the large-scale fading decoding receiver cooperation can reduce the interference of the terrestrial user. Moreover, the maximum SE can be achieved by changing the time-splitting fraction. We prove that the optimal time-splitting fraction for maximum SE is determined by the number of antennas, altitude and hardware quality factor of UAVs. Furthermore, we propose three UAV trajectory design schemes to improve the SE. It is interesting that the angle search scheme performs best than both AP search and line path schemes. Finally, simulation results are presented to validate the accuracy of our expressions.      
### 31.Inductive biases and Self Supervised Learning in modelling a physical heating system  [ :arrow_down: ](https://arxiv.org/pdf/2104.11478.pdf)
>  Model Predictive Controllers (MPC) require a good model for the controlled process. In this paper I infer inductive biases about a physical system. I use these biases to derive a new neural network architecture that can model this real system that has noise and inertia. The main inductive biases exploited here are: the delayed impact of some inputs on the system and the separability between the temporal component and how the inputs interact to produce the output of a system. The inputs are independently delayed using shifted convolutional kernels. Feature interactions are modelled using a fully connected network that does not have access to temporal information. The available data and the problem setup allow the usage of Self Supervised Learning in order to train the models. The baseline architecture is an Attention based Reccurent network adapted to work with MPC like inputs. The proposed networks are faster, better at exploiting larger data volumes and are almost as good as baseline networks in terms of prediction performance. The proposed architecture family called Delay can be used in a real scenario to control systems with delayed responses with respect to its controls or inputs. Ablation studies show that the presence of delay kernels are vital to obtain any learning in proposed architecture. Code and some experimental data are available online.      
### 32.LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech  [ :arrow_down: ](https://arxiv.org/pdf/2104.11462.pdf)
>  Self-Supervised Learning (SSL) using huge unlabeled data has been successfully explored for image and natural language processing. Recent works also investigated SSL from speech. They were notably successful to improve performance on downstream tasks such as automatic speech recognition (ASR). While these works suggest it is possible to reduce dependence on labeled data for building efficient speech systems, their evaluation was mostly made on ASR and using multiple and heterogeneous experimental settings (most of them for English). This renders difficult the objective comparison between SSL approaches and the evaluation of their impact on building speech systems. In this paper, we propose LeBenchmark: a reproducible framework for assessing SSL from speech. It not only includes ASR (high and low resource) tasks but also spoken language understanding, speech translation and emotion recognition. We also target speech technologies in a language different than English: French. SSL models of different sizes are trained from carefully sourced and documented datasets. Experiments show that SSL is beneficial for most but not all tasks which confirms the need for exhaustive and reliable benchmarks to evaluate its real impact. LeBenchmark is shared with the scientific community for reproducible research in SSL from speech.      
### 33.A Framework for Recognizing and Estimating Human Concentration Levels  [ :arrow_down: ](https://arxiv.org/pdf/2104.11421.pdf)
>  One of the major tasks in online education is to estimate the concentration levels of each student. Previous studies have a limitation of classifying the levels using discrete states only. The purpose of this paper is to estimate the subtle levels as specified states by using the minimum amount of body movement data. This is done by a framework composed of a Deep Neural Network and Kalman Filter. Using this framework, we successfully extracted the concentration levels, which can be used to aid lecturers and expand to other areas.      
### 34.Intentional Deep Overfit Learning (IDOL): A Novel Deep Learning Strategy for Adaptive Radiation Therapy  [ :arrow_down: ](https://arxiv.org/pdf/2104.11401.pdf)
>  In this study, we propose a tailored DL framework for patient-specific performance that leverages the behavior of a model intentionally overfitted to a patient-specific training dataset augmented from the prior information available in an ART workflow - an approach we term Intentional Deep Overfit Learning (IDOL). Implementing the IDOL framework in any task in radiotherapy consists of two training stages: 1) training a generalized model with a diverse training dataset of N patients, just as in the conventional DL approach, and 2) intentionally overfitting this general model to a small training dataset-specific the patient of interest (N+1) generated through perturbations and augmentations of the available task- and patient-specific prior information to establish a personalized IDOL model. The IDOL framework itself is task-agnostic and is thus widely applicable to many components of the ART workflow, three of which we use as a proof of concept here: the auto-contouring task on re-planning CTs for traditional ART, the MRI super-resolution (SR) task for MRI-guided ART, and the synthetic CT (sCT) reconstruction task for MRI-only ART. In the re-planning CT auto-contouring task, the accuracy measured by the Dice similarity coefficient improves from 0.847 with the general model to 0.935 by adopting the IDOL model. In the case of MRI SR, the mean absolute error (MAE) is improved by 40% using the IDOL framework over the conventional model. Finally, in the sCT reconstruction task, the MAE is reduced from 68 to 22 HU by utilizing the IDOL framework.      
### 35.Infant Vocal Tract Development Analysis and Diagnosis by Cry Signals with CNN Age Classification  [ :arrow_down: ](https://arxiv.org/pdf/2104.11395.pdf)
>  From crying to babbling and then to speech, infant's vocal tract goes through anatomic restructuring. In this paper, we propose a non-invasive fast method of using infant cry signals with convolutional neural network (CNN) based age classification to diagnose the abnormality of the vocal tract development as early as 4-month age. We study F0, F1, F2, and spectrograms and relate them to the postnatal development of infant vocalization. A novel CNN based age classification is performed with binary age pairs to discover the pattern and tendency of the vocal tract changes. The effectiveness of this approach is evaluated on Baby2020 with healthy infant cries and Baby Chillanto database with pathological infant cries. The results show that our approach yields 79.20% accuracy for healthy cries, 84.80% for asphyxiated cries, and 91.20% for deaf cries. Our method first reveals that infants' vocal tract develops to a certain level at 4-month age and infants can start controlling the vocal folds to produce discontinuous cry sounds leading to babbling. Early diagnosis of growth abnormality of the vocal tract can help parents keep vigilant and adopt medical treatment or training therapy for their infants as early as possible.      
### 36.Analysis and Modeling of Driver Behavior with Integrated Feedback of Visual and Haptic Information Under Shared Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.11370.pdf)
>  The thesis presents contributions made to the evaluation and design of a haptic guidance system on improving driving performance in cases of normal and degraded visual information, which are based on behavior experiments, modeling and numerical simulations. The effect of shared control on driver behavior in cases of normal and degraded visual information has been successfully evaluated experimentally and numerically. The evaluation results indicate that the proposed haptic guidance system is capable of providing reliable haptic information, and is effective on improving lane following performance in the conditions of visual occlusion from road ahead and declined visual attention under fatigue driving. Moreover, the appropriate degree of haptic guidance is highly related to the reliability of visual information perceived by the driver, which suggests that designing the haptic guidance system based on the reliability of visual information would allow for greater driver acceptance. Furthermore, the parameterized driver model, which considers the integrated feedback of visual and haptic information, is capable of predicting driver behavior under shared control, and has the potential of being used for designing and evaluating the haptic guidance system.      
### 37.Optimal Cost Design for Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.11353.pdf)
>  Many robotics domains use some form of nonconvex model predictive control (MPC) for planning, which sets a reduced time horizon, performs trajectory optimization, and replans at every step. The actual task typically requires a much longer horizon than is computationally tractable, and is specified via a cost function that cumulates over that full horizon. For instance, an autonomous car may have a cost function that makes a desired trade-off between efficiency, safety, and obeying traffic laws. In this work, we challenge the common assumption that the cost we optimize using MPC should be the same as the ground truth cost for the task (plus a terminal cost). MPC solvers can suffer from short planning horizons, local optima, incorrect dynamics models, and, importantly, fail to account for future replanning ability. Thus, we propose that in many tasks it could be beneficial to purposefully choose a different cost function for MPC to optimize: one that results in the MPC rollout having low ground truth cost, rather than the MPC planned trajectory. We formalize this as an optimal cost design problem, and propose a zeroth-order optimization-based approach that enables us to design optimal costs for an MPC planning robot in continuous MDPs. We test our approach in an autonomous driving domain where we find costs different from the ground truth that implicitly compensate for replanning, short horizon, incorrect dynamics models, and local minima issues. As an example, the learned cost incentivizes MPC to delay its decision until later, implicitly accounting for the fact that it will get more information in the future and be able to make a better decision. Code and videos available at <a class="link-external link-https" href="https://sites.google.com/berkeley.edu/ocd-mpc/" rel="external noopener nofollow">this https URL</a>.      
### 38.Earnings-21: A Practical Benchmark for ASR in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2104.11348.pdf)
>  Commonly used speech corpora inadequately challenge academic and commercial ASR systems. In particular, speech corpora lack metadata needed for detailed analysis and WER measurement. In response, we present Earnings-21, a 39-hour corpus of earnings calls containing entity-dense speech from nine different financial sectors. This corpus is intended to benchmark ASR systems in the wild with special attention towards named entity recognition. We benchmark four commercial ASR models, two internal models built with open-source tools, and an open-source LibriSpeech model and discuss their differences in performance on Earnings-21. Using our recently released fstalign tool, we provide a candid analysis of each model's recognition capabilities under different partitions. Our analysis finds that ASR accuracy for certain NER categories is poor, presenting a significant impediment to transcript comprehension and usage. Earnings-21 bridges academic and commercial ASR system evaluation and enables further research on entity modeling and WER on real world audio.      
### 39.Restoring degraded speech via a modified diffusion model  [ :arrow_down: ](https://arxiv.org/pdf/2104.11347.pdf)
>  There are many deterministic mathematical operations (e.g. compression, clipping, downsampling) that degrade speech quality considerably. In this paper we introduce a neural network architecture, based on a modification of the DiffWave model, that aims to restore the original speech signal. DiffWave, a recently published diffusion-based vocoder, has shown state-of-the-art synthesized speech quality and relatively shorter waveform generation times, with only a small set of parameters. We replace the mel-spectrum upsampler in DiffWave with a deep CNN upsampler, which is trained to alter the degraded speech mel-spectrum to match that of the original speech. The model is trained using the original speech waveform, but conditioned on the degraded speech mel-spectrum. Post-training, only the degraded mel-spectrum is used as input and the model generates an estimate of the original speech. Our model results in improved speech quality (original DiffWave model as baseline) on several different experiments. These include improving the quality of speech degraded by LPC-10 compression, AMR-NB compression, and signal clipping. Compared to the original DiffWave architecture, our scheme achieves better performance on several objective perceptual metrics and in subjective comparisons. Improvements over baseline are further amplified in a out-of-corpus evaluation setting.      
### 40.Landmark-Aware and Part-based Ensemble Transfer Learning Network for Facial Expression Recognition from Static images  [ :arrow_down: ](https://arxiv.org/pdf/2104.11274.pdf)
>  Facial Expression Recognition from static images is a challenging problem in computer vision applications. Convolutional Neural Network (CNN), the state-of-the-art method for various computer vision tasks, has had limited success in predicting expressions from faces having extreme poses, illumination, and occlusion conditions. To mitigate this issue, CNNs are often accompanied by techniques like transfer, multi-task, or ensemble learning that often provide high accuracy at the cost of high computational complexity. In this work, we propose a Part-based Ensemble Transfer Learning network, which models how humans recognize facial expressions by correlating the spatial orientation pattern of the facial features with a specific expression. It consists of 5 sub-networks, in which each sub-network performs transfer learning from one of the five subsets of facial landmarks: eyebrows, eyes, nose, mouth, or jaw to expression classification. We test the proposed network on the CK+, JAFFE, and SFEW datasets, and it outperforms the benchmark for CK+ and JAFFE datasets by 0.51\% and 5.34\%, respectively. Additionally, it consists of a total of 1.65M model parameters and requires only 3.28 $\times$ $10^{6}$ FLOPS, which ensures computational efficiency for real-time deployment. Grad-CAM visualizations of our proposed ensemble highlight the complementary nature of its sub-networks, a key design parameter of an effective ensemble network. Lastly, cross-dataset evaluation results reveal that our proposed ensemble has a high generalization capacity. Our model trained on the SFEW Train dataset achieves an accuracy of 47.53\% on the CK+ dataset, which is higher than what it achieves on the SFEW Valid dataset.      

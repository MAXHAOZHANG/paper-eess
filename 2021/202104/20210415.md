# ArXiv eess --Thu, 15 Apr 2021
### 1.Resource Rationing for Wireless Federated Learning: Concept, Benefits, and Challenges  [ :arrow_down: ](https://arxiv.org/pdf/2104.06990.pdf)
>  We advocate a new resource allocation framework, which we term resource rationing, for wireless federated learning (FL). Unlike existing resource allocation methods for FL, resource rationing focuses on balancing resources across learning rounds so that their collective impact on the federated learning performance is explicitly captured. This new framework can be integrated seamlessly with existing resource allocation schemes to optimize the convergence of FL. In particular, a novel "later-is-better" principle is at the front and center of resource rationing, which is validated empirically in several instances of wireless FL. We also point out technical challenges and research opportunities that are worth pursuing. Resource rationing highlights the benefits of treating the emerging FL as a new class of service that has its own characteristics, and designing communication algorithms for this particular service.      
### 2.A fast and accurate similarity-constrained subspace clustering algorithm for land cover segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2104.06975.pdf)
>  Accurate land cover segmentation of spectral images is challenging and has drawn widespread attention in remote sensing due to its inherent complexity. Although significant efforts have been made for developing a variety of methods, most of them rely on supervised strategies. Subspace clustering methods, such as Sparse Subspace Clustering (SSC), have become a popular tool for unsupervised learning due to their high performance. However, the computational complexity of SSC methods prevents their use on large spectral remotely sensed datasets. Furthermore, since SSC ignores the spatial information in the spectral images, its discrimination capability is limited, hampering the clustering results' spatial homogeneity. To address these two relevant issues, in this paper, we propose a fast algorithm that obtains a sparse representation coefficient matrix by first selecting a small set of pixels that best represent their neighborhood. Then, it performs spatial filtering to enforce the connectivity of neighboring pixels and uses fast spectral clustering to get the final segmentation. Extensive simulations with our method demonstrate its effectiveness in land cover segmentation, obtaining remarkable high clustering performance compared with state-of-the-art SSC-based algorithms and even novel unsupervised-deep-learning-based methods. Besides, the proposed method is up to three orders of magnitude faster than SSC when clustering more than 2x10^4 spectral pixels.      
### 3.Towards agrobots: Identification of the yaw dynamics and trajectory tracking of an autonomous tractor  [ :arrow_down: ](https://arxiv.org/pdf/2104.06833.pdf)
>  More efficient agricultural machinery is needed as agricultural areas become more limited and energy and labor costs increase. To increase their efficiency, trajectory tracking problem of an autonomous tractor, as an agricultural production machine, has been investigated in this study. As a widely used model-based approach, model predictive control is preferred in this paper to control the yaw dynamics of the tractor which can deal with the constraints on the states and the actuators in a system. The yaw dynamics is identified by using nonlinear least squares frequency domain system identification. The speed is controlled by a proportional-integral-derivative controller and a kinematic trajectory controller is used to calculate the desired speed and the desired yaw rate signals for the subsystems in order to minimize the tracking errors in both the longitudinal and transversal directions. The experimental results show the accuracy and the efficiency of the proposed control scheme in which the euclidean error is below $40$ cm for time-based straight line trajectories and $60$ cm for time-based curved line trajectories, respectively.      
### 4.Neural-network-based MDG and Optical SNR Estimation in SDM Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2104.06803.pdf)
>  We propose a neural network model for MDG and optical SNR estimation in SDM transmission. We show that the proposed neural-network-based solution estimates MDG and SNR with high accuracy and low complexity from features extracted after DSP.      
### 5.Two-Dimensional DOA Estimation for L-shaped Nested Array via Tensor Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2104.06799.pdf)
>  The problem of two-dimensional (2-D) direction-of-arrival (DOA) estimation for L-shaped nested array is considered. Typically, the multi-dimensional structure of the received signal in co-array domain is ignored in the problem considered. Moreover, the cross term generated by the correlated signal and noise components degrades the 2-D DOA estimation performance seriously. To tackle these issues, an iterative 2-D DOA estimation approach based on tensor modeling is proposed. To develop such approach, a higher-order tensor is constructed, whose factor matrices contain the target azimuth and elevation information. By exploiting the Vandermonde structure of the factor matrix, a computationally efficient tensor decomposition method is then developed to estimate the targets DOA information in each dimension independently. Then, an eigenvalue-based approach that exploits a natural coupling of the 2-D spatial parameters is proposed to pair the azimuth and elevation angles. Finally, an iterative method is designed to improve the DOA estimation performance. Specifically, the cross term is estimated and removed in the next step of such iterative procedure on the basis of the DOA estimates originated from the tensor decomposition in the previous step. Consequently, the DOA estimation with better accuracy and higher resolution is obtained. The proposed iterative 2-D DOA estimation method for L-shaped nested array can resolve more targets than the number of real elements, even when the azimuth or elevation angles are identical, which is superior to conventional approaches. Simulation results validate the performance improvement of the proposed 2-D DOA estimation method as compared to existing state-of-the-art DOA estimation techniques for L-shaped nested array.      
### 6.Audio-based cough counting using independent subspace analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.06798.pdf)
>  In this paper, an algorithm designed to detect characteristic cough events in audio recordings is presented, significantly reducing the time required for manual counting. Using time-frequency representations and independent subspace analysis (ISA), sound events that exhibit characteristics of coughs are automatically detected, producing a summary of the events detected. Using a dataset created from publicly available audio recordings, this algorithm has been tested on a variety of synthesized audio scenarios representative of those likely to be encountered by subjects undergoing an ambulatory cough recording, achieving a true positive rate of 76% with an average of 2.85 false positives per minute.      
### 7.Systems-Theoretic Safety Assessment of Teleoperated Road Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2104.06795.pdf)
>  Teleoperation is becoming an essential feature in automated vehicle concepts, as it will help the industry overcome challenges facing automated vehicles today. Teleoperation follows the idea to get humans back into the loop for certain rare situations the automated vehicle cannot resolve. Teleoperation therefore has the potential to expand the operational design domain and increase the availability of automated vehicles. This is especially relevant for concepts with no backup driver inside the vehicle. While teleoperation resolves certain issues an automated vehicle will face, it introduces new challenges in terms of safety requirements. While safety and regulatory approval is a major research topic in the area of automated vehicles, it is rarely discussed in the context of teleoperated road vehicles. The focus of this paper is to systematically analyze the potential hazards of teleoperation systems. An appropriate hazard analysis method (STPA) is chosen from literature and applied to the system at hand. The hazard analysis is an essential part in developing a safety concept (e.g., according to ISO26262) and thus far has not been discussed for teleoperated road vehicles.      
### 8.Optimization-Based Path-Planning for Connected and non-Connected Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2104.06778.pdf)
>  A path-planning algorithm for connected and non-connected automated road vehicles on multilane motorways is derived from the opportune formulation of an optimal control problem. In this framework, the objective function to be minimized contains appropriate respective terms to reflect: the goals of vehicle advancement; passenger comfort; and avoidance of collisions with other vehicles, of road departures and of negative speeds. Connectivity implies that connected vehicles are able to exchange with each other (V2V) or the infrastructure (V2I), real-time information about their last generated path. For the numerical solution of the optimal control problem, an efficient feasible direction algorithm is used. To ensure high-quality local minima, a simplified Dynamic Programming algorithm is also conceived to deliver the initial guess trajectory for the feasible direction algorithm. Thanks to low computation times, the approach is readily executable within a model predictive control (MPC) framework. The proposed MPC-based approach is embedded within the Aimsun microsimulation platform, which enables the evaluation of a plethora of realistic vehicle driving and advancement scenarios. Results obtained on a multilane motorway stretch indicate higher efficiency of the optimally controlled vehicles in driving closer to their desired speed, compared to ordinary Aimsun vehicles. Increased penetration rates of automated vehicles are found to increase the efficiency of the overall traffic flow, benefiting manual vehicles as well. Moreover, connected controlled vehicles appear to be more efficient compared to the corresponding non-connected controlled vehicles, due to the improved real-time information and short-term prediction.      
### 9.VTGAN: Semi-supervised Retinal Image Synthesis and Disease Prediction using Vision Transformers  [ :arrow_down: ](https://arxiv.org/pdf/2104.06757.pdf)
>  In Fluorescein Angiography (FA), an exogenous dye is injected in the bloodstream to image the vascular structure of the retina. The injected dye can cause adverse reactions such as nausea, vomiting, anaphylactic shock, and even death. In contrast, color fundus imaging is a non-invasive technique used for photographing the retina but does not have sufficient fidelity for capturing its vascular structure. The only non-invasive method for capturing retinal vasculature is optical coherence tomography-angiography (OCTA). However, OCTA equipment is quite expensive, and stable imaging is limited to small areas on the retina. In this paper, we propose a novel conditional generative adversarial network (GAN) capable of simultaneously synthesizing FA images from fundus photographs while predicting retinal degeneration. The proposed system has the benefit of addressing the problem of imaging retinal vasculature in a non-invasive manner as well as predicting the existence of retinal abnormalities. We use a semi-supervised approach to train our GAN using multiple weighted losses on different modalities of data. Our experiments validate that the proposed architecture exceeds recent state-of-the-art generative networks for fundus-to-angiography synthesis. Moreover, our vision transformer-based discriminators generalize quite well on out-of-distribution data sets for retinal disease prediction.      
### 10.Towards off-the-grid algorithms for total variation regularized inverse problems  [ :arrow_down: ](https://arxiv.org/pdf/2104.06706.pdf)
>  We introduce an algorithm to solve linear inverse problems regularized with the total (gradient) variation in a gridless manner. Contrary to most existing methods, that produce an approximate solution which is piecewise constant on a fixed mesh, our approach exploits the structure of the solutions and consists in iteratively constructing a linear combination of indicator functions of simple polygons.      
### 11.Out-of-Step Detection Based On an Improved Line Potential Energy Criterion  [ :arrow_down: ](https://arxiv.org/pdf/2104.06702.pdf)
>  The line potential energy in the cutset is used as the criterion for monitoring the generator instability, but the criterion has the following two limitations due to narrowly defined conditions. The assumption of an ideal constant power load is difficult to satisfy, and the condition of the critical cutset is too narrow. The limitations are addressed by analyzing the relationship between the power of the load elements and the power of the cutset based on the two-machine equivalent. Modifications of the theoretical derivation steps of this criterion are presented to extend the applications of the criterion and provide theoretical support for its online use. Two simple strategies are proposed to ensure early detection of the generator instability.      
### 12.Redesigning Cellular Networks for UAVs: Exclusive and Inclusive BS Service Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2104.06679.pdf)
>  Different to the conventional terrestrial network, an unmanned aerial vehicle (UAV) network is required to serve aerial users (AUs) as well as ground users (GUs). In order to serve both GUs and AUs, we first consider two base station (BS) service schemes: the inclusive-service BS (IS-BS) scheme, which makes BSs serve both GUs and AUs simultaneously, and the exclusive-service BS (ES-BS) scheme, which has BSs for GUs and BSs for AUs exclusively. We also model a BS antenna power gain, which is determined by the BS antenna tilt angle and the horizontal distance between a BS and a user (GU or AU). For each BS service scheme, we derive a network outage probability by taking into account the characteristics of the BS antenna power gain and channel components for line-of-sight (LoS) and non-line-of-sight (NLoS) environments. Finally, we show the effect of the total BS density, the interfering BS density, and the user density on the optimal BS antenna tilt angle and the network outage probability, and provide an appropriate BS service scheme for different network setups      
### 13.Semi-supervised Learning Framework for UAV Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.06614.pdf)
>  The use of supervised learning with various sensing techniques such as audio, visual imaging, thermal sensing, RADAR, and radio frequency (RF) have been widely applied in the detection of unmanned aerial vehicles (UAV) in an environment. However, little or no attention has been given to the application of unsupervised or semi-supervised algorithms for UAV detection. In this paper, we proposed a semi-supervised technique and architecture for detecting UAVs in an environment by exploiting the RF signals (i.e., fingerprints) between a UAV and its flight-controller communication under wireless inference such as Bluetooth and WiFi. By decomposing the RF signals using a two-level wavelet packet transform, we estimated the second moment statistic (i.e., variance) of the coefficients in each packet as a feature set. We developed a local outlier factor model as the UAV detection algorithm using the coefficient variances of the wavelet packets from WiFi and Bluetooth signals. When detecting the presence of RF-based UAV, we achieved an accuracy of 96.7$\%$ and 86$\%$ at a signal-to-noise ratio of 30~dB and 18~dB, respectively. The application of this approach is not limited to UAV detection as it can be extended to the detection of rogue RF devices in an environment.      
### 14.Learning Metrics from Mean Teacher: A Supervised Learning Method for Improving the Generalization of Speaker Verification System  [ :arrow_down: ](https://arxiv.org/pdf/2104.06604.pdf)
>  Most speaker verification tasks are studied as an open-set evaluation scenario considering the real-world condition. Thus, the generalization power to unseen speakers is of paramount important to the performance of the speaker verification system. We propose to apply \textit {Mean Teacher}, a temporal averaging model, to extract speaker embeddings with small intra-class variance and large inter-class variance. The mean teacher network refers to the temporal averaging of deep neural network parameters; it can produces more accurate and stable representations than using weights after the training finished. By learning the reliable intermediate representation of the mean teacher network, we expect that the proposed method can explore more discriminatory embedding spaces and improve the generalization performance of the speaker verification system. Experimental results on the VoxCeleb1 test set demonstrate that the proposed method relatively improves performance by 11.61\%, compared to a baseline system.      
### 15.Attitude Observation for Second Order Attitude Kinematics  [ :arrow_down: ](https://arxiv.org/pdf/2104.06596.pdf)
>  This paper addresses the problem of estimating the attitude and angular velocity of a rigid object by exploiting its second order kinematic model. The approach is particularly useful in cases where angular velocity measurements are not available and the attitude and angular velocity of an object need to be estimated from accelerometers and magnetometers. We propose a novel sensor modality that uses multiple accelerometers to measure the angular acceleration of an object as well as using magnetometers to measure partial attitude. We extend the approach of equivariant observer design to second order attitude kinematics by demonstrating that the special Euclidean group acts as a symmetry group on the system considered. The observer design is based on the lifted kinematics and we prove almost global asymptotic stability and local uniform exponential stability of the estimation error. The performance of the observer is demonstrated in simulation.      
### 16.Data-driven modeling of power networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.06478.pdf)
>  We develop a non-intrusive data-driven modeling framework for power network dynamics using the Lift and Learn approach of \cite{QianWillcox2020}. A lifting map is applied to the snapshot data obtained from the original nonlinear swing equations describing the underlying power network such that the lifted-data corresponds to quadratic nonlinearity. The lifted data is then projected onto a lower dimensional basis and the reduced quadratic matrices are fit to this reduced lifted data using a least-squares measure. The effectiveness of the proposed approach is investigated by two power network models.      
### 17.Topology Estimation Following Islanding and its Impact on Preventive Control of Cascading Failure  [ :arrow_down: ](https://arxiv.org/pdf/2104.06473.pdf)
>  Knowledge of power grid's topology during cascading failure is an essential element of centralized blackout prevention control, given that multiple islands are typically formed, as a cascade progresses. Moreover, academic research on interdependency between cyber and physical layers of the grid indicate that power failure during a cascade may lead to outages in communication networks, which progressively reduce the observable areas. These challenge the current literature on line outage detection, which assumes that the grid remains as a single connected component. We propose a new approach to eliminate that assumption. Following an islanding event, first the buses forming that connected components are identified and then further line outages within the individual islands are detected. In addition to the power system measurements, observable breaker statuses are integrated as constraints in our topology identification algorithm. The impact of error propagation on the estimation process as reliance on previous estimates keeps growing during cascade is also studied. Finally, the estimated admittance matrix is used in preventive control of cascading failure, creating a closed-loop system. The impact of such an interlinked estimation and control on that total load served is studied for the first time. Simulations in IEEE-118 bus system and 2,383-bus Polish network demonstrate the effectiveness of our approach.      
### 18.Joint Matrix Completion and Compressed Sensing for State Estimation in Low-observable Distribution System  [ :arrow_down: ](https://arxiv.org/pdf/2104.06470.pdf)
>  Limited measurement availability at the distribution grid presents challenges for state estimation and situational awareness. This paper combines the advantages of two sparsity-based state estimation approaches (matrix completion and compressive sensing) that have been proposed recently to address the challenge of unobservability. The proposed approach exploits both the low rank structure and a suitable transform domain representation to leverage the correlation structure of the spatio-temporal data matrix while incorporating the power-flow constraints of the distribution grid. Simulations are carried out on three phase unbalanced IEEE 37 test system to verify the effectiveness of the proposed approach. The performance results reveal - (1) the superiority over traditional matrix completion and (2) very low state estimation errors for high compression ratios representing very low observability.      
### 19.ViT-V-Net: Vision Transformer for Unsupervised Volumetric Medical Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2104.06468.pdf)
>  In the last decade, convolutional neural networks (ConvNets) have dominated and achieved state-of-the-art performances in a variety of medical imaging applications. However, the performances of ConvNets are still limited by lacking the understanding of long-range spatial relations in an image. The recently proposed Vision Transformer (ViT) for image classification uses a purely self-attention-based model that learns long-range spatial relations to focus on the relevant parts of an image. Nevertheless, ViT emphasizes the low-resolution features because of the consecutive downsamplings, result in a lack of detailed localization information, making it unsuitable for image registration. Recently, several ViT-based image segmentation methods have been combined with ConvNets to improve the recovery of detailed localization information. Inspired by them, we present ViT-V-Net, which bridges ViT and ConvNet to provide volumetric medical image registration. The experimental results presented here demonstrate that the proposed architecture achieves superior performance to several top-performing registration methods.      
### 20.Learning to Jointly Deblur, Demosaick and Denoise Raw Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.06459.pdf)
>  We address the problem of non-blind deblurring and demosaicking of noisy raw images. We adapt an existing learning-based approach to RGB image deblurring to handle raw images by introducing a new interpretable module that jointly demosaicks and deblurs them. We train this model on RGB images converted into raw ones following a realistic invertible camera pipeline. We demonstrate the effectiveness of this model over two-stage approaches stacking demosaicking and deblurring modules on quantitive benchmarks. We also apply our approach to remove a camera's inherent blur (its color-dependent point-spread function) from real images, in essence deblurring sharp images.      
### 21.FastS2S-VC: Streaming Non-Autoregressive Sequence-to-Sequence Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2104.06900.pdf)
>  This paper proposes a non-autoregressive extension of our previously proposed sequence-to-sequence (S2S) model-based voice conversion (VC) methods. S2S model-based VC methods have attracted particular attention in recent years for their flexibility in converting not only the voice identity but also the pitch contour and local duration of input speech, thanks to the ability of the encoder-decoder architecture with the attention mechanism. However, one of the obstacles to making these methods work in real-time is the autoregressive (AR) structure. To overcome this obstacle, we develop a method to obtain a model that is free from an AR structure and behaves similarly to the original S2S models, based on a teacher-student learning framework. In our method, called "FastS2S-VC", the student model consists of encoder, decoder, and attention predictor. The attention predictor learns to predict attention distributions solely from source speech along with a target class index with the guidance of those predicted by the teacher model from both source and target speech. Thanks to this structure, the model is freed from an AR structure and allows for parallelization. Furthermore, we show that FastS2S-VC is suitable for real-time implementation based on a sliding-window approach, and describe how to make it run in real-time. Through speaker-identity and emotional-expression conversion experiments, we confirmed that FastS2S-VC was able to speed up the conversion process by 70 to 100 times compared to the original AR-type S2S-VC methods, without significantly degrading the audio quality and similarity to target speech. We also confirmed that the real-time version of FastS2S-VC can be run with a latency of 32 ms when run on a GPU.      
### 22.Efficient conformer-based speech recognition with linear attention  [ :arrow_down: ](https://arxiv.org/pdf/2104.06865.pdf)
>  Recently, conformer-based end-to-end automatic speech recognition, which outperforms recurrent neural network based ones, has received much attention. Although the parallel computing of conformer is more efficient than recurrent neural networks, the computational complexity of its dot-product self-attention is quadratic with respect to the length of the input feature. To reduce the computational complexity of the self-attention layer, we propose multi-head linear self-attention for the self-attention layer, which reduces its computational complexity to linear order. In addition, we propose to factorize the feed forward module of the conformer by low-rank matrix factorization, which successfully reduces the number of the parameters by approximate 50% with little performance loss. The proposed model, named linear attention based conformer (LAC), can be trained and inferenced jointly with the connectionist temporal classification objective, which further improves the performance of LAC. To evaluate the effectiveness of LAC, we conduct experiments on the AISHELL-1 and LibriSpeech corpora. Results show that the proposed LAC achieves better performance than 7 recently proposed speech recognition models, and is competitive with the state-of-the-art conformer. Meanwhile, the proposed LAC has a number of parameters of only 50% over the conformer with faster training speed than the latter.      
### 23.Dependency Parsing based Semantic Representation Learning with Graph Neural Network for Enhancing Expressiveness of Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2104.06835.pdf)
>  Semantic information of a sentence is crucial for improving the expressiveness of a text-to-speech (TTS) system, but can not be well learned from the limited training TTS dataset just by virtue of the nowadays encoder structures. As large scale pre-trained text representation develops, bidirectional encoder representations from transformers (BERT) has been proven to embody text-context semantic information and applied to TTS as additional input. However BERT can not explicitly associate semantic tokens from point of dependency relations in a sentence. In this paper, to enhance expressiveness, we propose a semantic representation learning method based on graph neural network, considering dependency relations of a sentence. Dependency graph of input text is composed of edges from dependency tree structure considering both the forward and the reverse directions. Semantic representations are then extracted at word level by the relational gated graph network (RGGN) fed with features from BERT as nodes input. Upsampled semantic representations and character-level embeddings are concatenated to serve as the encoder input of Tacotron-2. Experimental results show that our proposed method outperforms the baseline using vanilla BERT features both in LJSpeech and Bilzzard Challenge 2013 datasets, and semantic representations learned from the reverse direction are more effective for enhancing expressiveness.      
### 24.Towards Unsupervised Fine-Tuning for Edge Video Analytics  [ :arrow_down: ](https://arxiv.org/pdf/2104.06826.pdf)
>  Judging by popular and generic computer vision challenges, such as the ImageNet or PASCAL VOC, neural networks have proven to be exceptionally accurate in recognition tasks. However, state-of-the-art accuracy often comes at a high computational price, requiring equally state-of-the-art and high-end hardware acceleration to achieve anything near real-time performance. At the same time, use cases such as smart cities or autonomous vehicles require an automated analysis of images from fixed cameras in real-time. Due to the huge and constant amount of network bandwidth these streams would generate, we cannot rely on offloading compute to the omnipresent and omnipotent cloud. Therefore, a distributed Edge Cloud must be in charge to process images locally. However, the Edge Cloud is, by nature, resource-constrained, which puts a limit on the computational complexity of the models executed in the edge. Nonetheless, there is a need for a meeting point between the Edge Cloud and accurate real-time video analytics. In this paper, we propose a method for improving accuracy of edge models without any extra compute cost by means of automatic model specialization. First, we show how the sole assumption of static cameras allows us to make a series of considerations that greatly simplify the scope of the problem. Then, we present Edge AutoTuner, a framework that implements and brings these considerations together to automate the end-to-end fine-tuning of models. Finally, we show that complex neural networks - able to generalize better - can be effectively used as teachers to annotate datasets for the fine-tuning of lightweight neural networks and tailor them to the specific edge context, which boosts accuracy at constant computational cost, and do so without any human interaction. Results show that our method can automatically improve accuracy of pre-trained models by an average of 21%.      
### 25.Stochastic geometry analysis of a distance-based JT scheme in C-RAN  [ :arrow_down: ](https://arxiv.org/pdf/2104.06807.pdf)
>  This paper considers a joint transmission scheme (JT) developed for cloud radio access networks (C-RANs). This proposed scheme features cooperative sets of remote radio heads (RRH) defined in a disk around each user location. The nodes belonging to each of these sets perform a weighted maximum ratio transmission to jointly serve the user. The powers allocated to the beamformers are computed at the network baseband unit, taking into account channel gains, as well an equity criterion between the users. In comparison with the existing literature, our model includes a saturation assumption, with all transmissions taking place over the same resource block. A RRH belonging to multiple sets can hence transmit to several users simultaneously. The distributions of the network coverage and spectral efficiency are calculated by means of stochastic geometry (SG), and compared with Monte Carlo simulations. The derived expressions take into account the power allocation, the user and RRH densities, as well as the statistical correlation resulting from the set overlaps.      
### 26.Revisiting Light Field Rendering with Deep Anti-Aliasing Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.06797.pdf)
>  The light field (LF) reconstruction is mainly confronted with two challenges, large disparity and the non-Lambertian effect. Typical approaches either address the large disparity challenge using depth estimation followed by view synthesis or eschew explicit depth information to enable non-Lambertian rendering, but rarely solve both challenges in a unified framework. In this paper, we revisit the classic LF rendering framework to address both challenges by incorporating it with advanced deep learning techniques. First, we analytically show that the essential issue behind the large disparity and non-Lambertian challenges is the aliasing problem. Classic LF rendering approaches typically mitigate the aliasing with a reconstruction filter in the Fourier domain, which is, however, intractable to implement within a deep learning pipeline. Instead, we introduce an alternative framework to perform anti-aliasing reconstruction in the image domain and analytically show comparable efficacy on the aliasing issue. To explore the full potential, we then embed the anti-aliasing framework into a deep neural network through the design of an integrated architecture and trainable parameters. The network is trained through end-to-end optimization using a peculiar training set, including regular LFs and unstructured LFs. The proposed deep learning pipeline shows a substantial superiority in solving both the large disparity and the non-Lambertian challenges compared with other state-of-the-art approaches. In addition to the view interpolation for an LF, we also show that the proposed pipeline also benefits light field view extrapolation.      
### 27.Non-autoregressive sequence-to-sequence voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2104.06793.pdf)
>  This paper proposes a novel voice conversion (VC) method based on non-autoregressive sequence-to-sequence (NAR-S2S) models. Inspired by the great success of NAR-S2S models such as FastSpeech in text-to-speech (TTS), we extend the FastSpeech2 model for the VC problem. We introduce the convolution-augmented Transformer (Conformer) instead of the Transformer, making it possible to capture both local and global context information from the input sequence. Furthermore, we extend variance predictors to variance converters to explicitly convert the source speaker's prosody components such as pitch and energy into the target speaker. The experimental evaluation with the Japanese speaker dataset, which consists of male and female speakers of 1,000 utterances, demonstrates that the proposed model enables us to perform more stable, faster, and better conversion than autoregressive S2S (AR-S2S) models such as Tacotron2 and Transformer.      
### 28.Visual Comfort Aware-Reinforcement Learning for Depth Adjustment of Stereoscopic 3D Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.06782.pdf)
>  Depth adjustment aims to enhance the visual experience of stereoscopic 3D (S3D) images, which accompanied with improving visual comfort and depth perception. For a human expert, the depth adjustment procedure is a sequence of iterative decision making. The human expert iteratively adjusts the depth until he is satisfied with the both levels of visual comfort and the perceived depth. In this work, we present a novel deep reinforcement learning (DRL)-based approach for depth adjustment named VCA-RL (Visual Comfort Aware Reinforcement Learning) to explicitly model human sequential decision making in depth editing operations. We formulate the depth adjustment process as a Markov decision process where actions are defined as camera movement operations to control the distance between the left and right cameras. Our agent is trained based on the guidance of an objective visual comfort assessment metric to learn the optimal sequence of camera movement actions in terms of perceptual aspects in stereoscopic viewing. With extensive experiments and user studies, we show the effectiveness of our VCA-RL model on three different S3D databases.      
### 29.Towards a Better Understanding of VR Sickness: Physical Symptom Prediction for VR Contents  [ :arrow_down: ](https://arxiv.org/pdf/2104.06780.pdf)
>  We address the black-box issue of VR sickness assessment (VRSA) by evaluating the level of physical symptoms of VR sickness. For the VR contents inducing the similar VR sickness level, the physical symptoms can vary depending on the characteristics of the contents. Most of existing VRSA methods focused on assessing the overall VR sickness score. To make better understanding of VR sickness, it is required to predict and provide the level of major symptoms of VR sickness rather than overall degree of VR sickness. In this paper, we predict the degrees of main physical symptoms affecting the overall degree of VR sickness, which are disorientation, nausea, and oculomotor. In addition, we introduce a new large-scale dataset for VRSA including 360 videos with various frame rates, physiological signals, and subjective scores. On VRSA benchmark and our newly collected dataset, our approach shows a potential to not only achieve the highest correlation with subjective scores, but also to better understand which symptoms are the main causes of VR sickness.      
### 30.Deep Evaluation Metric: Learning to Evaluate Simulated Radar Point Clouds for Virtual Testing of Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2104.06772.pdf)
>  The usage of environment sensor models for virtual testing is a promising approach to reduce the testing effort of autonomous driving. However, in order to deduce any statements regarding the performance of an autonomous driving function based on simulation, the sensor model has to be validated to determine the discrepancy between the synthetic and real sensor data. Since a certain degree of divergence can be assumed to exist, the sufficient level of fidelity must be determined, which poses a major challenge. In particular, a method for quantifying the fidelity of a sensor model does not exist and the problem of defining an appropriate metric remains. In this work, we train a neural network to distinguish real and simulated radar sensor data with the purpose of learning the latent features of real radar point clouds. Furthermore, we propose the classifier's confidence score for the `real radar point cloud' class as a metric to determine the degree of fidelity of synthetically generated radar data. The presented approach is evaluated and it can be demonstrated that the proposed deep evaluation metric outperforms conventional metrics in terms of its capability to identify characteristic differences between real and simulated radar data.      
### 31.Optimal Downlink Training Sequence for Massive MIMO Secret-Key Generation  [ :arrow_down: ](https://arxiv.org/pdf/2104.06742.pdf)
>  In this paper, the secret-key capacity is maximized by optimizing the downlink training sequence in a time division duplexing (TDD) massive multiple-input-multiple-output (MIMO) scenario. Both single-user and multiple user cases are considered. As opposed to previous works, the optimal training sequence and the related secret-key capacity is characterized in closed-form in the single-user case and the large antenna multiple-user case. Designs taking into account a constraint on the maximal number of pilots are also proposed. In the multiple-user case, both the max-min and the sum capacity criteria are considered, including potential user priorities. In the end, it is shown that massive MIMO boosts the secret-key capacity by leveraging: i) spatial dimensionality gain and ii) array gain. Moreover, in the large antenna case, the multiple-user capacity is obtained with no extra pilot overhead as compared to the single-user case.      
### 32.Change Detection in Synthetic Aperture Radar Images Using a Dual-Domain Network  [ :arrow_down: ](https://arxiv.org/pdf/2104.06699.pdf)
>  Change detection from synthetic aperture radar (SAR) imagery is a critical yet challenging task. Existing methods mainly focus on feature extraction in spatial domain, and little attention has been paid to frequency domain. Furthermore, in patch-wise feature analysis, some noisy features in the marginal region may be introduced. To tackle the above two challenges, we propose a Dual-Domain Network. Specifically, we take features from the discrete cosine transform domain into consideration and the reshaped DCT coefficients are integrated into the proposed model as the frequency domain branch. Feature representations from both frequency and spatial domain are exploited to alleviate the speckle noise. In addition, we further propose a multi-region convolution module, which emphasizes the central region of each patch. The contextual information and central region features are modeled adaptively. The experimental results on three SAR datasets demonstrate the effectiveness of the proposed model. Our codes are available at <a class="link-external link-https" href="https://github.com/summitgao/SAR_CD_DDNet" rel="external noopener nofollow">this https URL</a>.      
### 33.End-to-end Keyword Spotting using Neural Architecture Search and Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2104.06666.pdf)
>  This paper introduces neural architecture search (NAS) for the automatic discovery of end-to-end keyword spotting (KWS) models in limited resource environments. We employ a differentiable NAS approach to optimize the structure of convolutional neural networks (CNNs) operating on raw audio waveforms. After a suitable KWS model is found with NAS, we conduct quantization of weights and activations to reduce the memory footprint. We conduct extensive experiments on the Google speech commands dataset. In particular, we compare our end-to-end approach to mel-frequency cepstral coefficient (MFCC) based systems. For quantization, we compare fixed bit-width quantization and trained bit-width quantization. Using NAS only, we were able to obtain a highly efficient model with an accuracy of 95.55% using 75.7k parameters and 13.6M operations. Using trained bit-width quantization, the same model achieves a test accuracy of 93.76% while using on average only 2.91 bits per activation and 2.51 bits per weight.      
### 34.Revisiting the Onsets and Frames Model with Additive Attention  [ :arrow_down: ](https://arxiv.org/pdf/2104.06607.pdf)
>  Recent advances in automatic music transcription (AMT) have achieved highly accurate polyphonic piano transcription results by incorporating onset and offset detection. The existing literature, however, focuses mainly on the leverage of deep and complex models to achieve state-of-the-art (SOTA) accuracy, without understanding model behaviour. In this paper, we conduct a comprehensive examination of the Onsets-and-Frames AMT model, and pinpoint the essential components contributing to a strong AMT performance. This is achieved through exploitation of a modified additive attention mechanism. The experimental results suggest that the attention mechanism beyond a moderate temporal context does not benefit the model, and that rule-based post-processing is largely responsible for the SOTA performance. We also demonstrate that the onsets are the most significant attentive feature regardless of model complexity. The findings encourage AMT research to weigh more on both a robust onset detector and an effective post-processor.      
### 35.OneVision: Centralized to Distributed Controller Synthesis with Delay Compensation  [ :arrow_down: ](https://arxiv.org/pdf/2104.06588.pdf)
>  We propose a new algorithm to simplify the controller development for distributed robotic systems subject to external observations, disturbances, and communication delays. Unlike prior approaches that propose specialized solutions to handling communication latency for specific robotic applications, our algorithm uses an arbitrary centralized controller as the specification and automatically generates distributed controllers with communication management and delay compensation. We formulate our goal as nonlinear optimal control -- using a regret minimizing objective that measures how much the distributed agents behave differently from the delay-free centralized response -- and solve for optimal actions w.r.t. local estimations of this objective using gradient-based optimization. We analyze our proposed algorithm's behavior under a linear time-invariant special case and prove that the closed-loop dynamics satisfy a form of input-to-state stability w.r.t. unexpected disturbances and observations. Our experimental results on both simulated and real-world robotic tasks demonstrate the practical usefulness of our approach and show significant improvement over several baseline approaches.      
### 36.Fast digital refocusing and depth of field extended Fourier ptychography microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2104.06580.pdf)
>  Fourier ptychography microscopy (FPM), sharing its roots with synthetic aperture technique and phase retrieval method, is a recently developed computational microscopic super-resolution technique. By turning on the light-emitting diode (LED) elements sequentially and acquiring the corresponding images that contain different spatial frequencies, FPM can achieve a wide field-of-view (FOV), high-spatial-resolution imaging, and phase recovery simultaneously. Conventional FPM assumes that the sample is sufficiently thin and strictly in focus. Nevertheless, even for a relatively thin sample, the non-planar distribution characteristics and the non-ideal position/posture of the sample will cause all or part of FOV to be defocused. In this paper, we proposed a fast digital refocusing and depth-of-field (DOF) extended FPM strategy by taking the advantages of image lateral shift caused by sample defocusing and varied-angle illuminations. The lateral shift amount is proportional to the defocus distance and the tangent of the illumination angle. Instead of searching the optimal defocus distance in optimization strategy, which is time-consuming, the defocus distance of each subregion of the sample can be precisely and quickly obtained by calculating the relative lateral shift amounts corresponding to different oblique illuminations. And then, the digital refocusing strategy rooting in the Fresnel propagator is integrated into the FPM framework to achieve the high-resolution and phase information reconstruction for each part of the sample, which means the DOF the FPM is effectively extended. The feasibility of the proposed method in fast digital refocusing and FOV extending is verified in the actual experiments with the USAF chart and biological samples.      
### 37.Comparison and Analysis of Deep Audio Embeddings for Music Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.06517.pdf)
>  Emotion is a complicated notion present in music that is hard to capture even with fine-tuned feature engineering. In this paper, we investigate the utility of state-of-the-art pre-trained deep audio embedding methods to be used in the Music Emotion Recognition (MER) task. Deep audio embedding methods allow us to efficiently capture the high dimensional features into a compact representation. We implement several multi-class classifiers with deep audio embeddings to predict emotion semantics in music. We investigate the effectiveness of L3-Net and VGGish deep audio embedding methods for music emotion inference over four music datasets. The experiments with several classifiers on the task show that the deep audio embedding solutions can improve the performances of the previous baseline MER models. We conclude that deep audio embeddings represent musical emotion semantics for the MER task without expert human engineering.      
### 38.Modeling and Development of Operation Guidelines for Leader-Follower Autonomous Truck-Mounted Attenuator Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2104.06507.pdf)
>  Mobile and slow moving operations, such as striping, sweeping, bridge flushing and pothole patching, are critical for efficient and safe operation of the highway transportation system. A successfully implemented leader follower autonomous truck mounted attenuators system will eliminate all injuries to DOT employees in follow truck provided appropriate Statutory authority. The leader follower system design imposes more requirements to the lead truck drivers in order to ensure a safe and smooth system operation. The driver is now required to make driving decisions not only from the lead truck's perspective, but also consider the potential implications of his decisions to the follow truck. This project aims to develop a set of rules and clear instructions for ATMA system operation      
### 39.Machine-learned 3D Building Vectorization from Satellite Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2104.06485.pdf)
>  We propose a machine learning based approach for automatic 3D building reconstruction and vectorization. Taking a single-channel photogrammetric digital surface model (DSM) and panchromatic (PAN) image as input, we first filter out non-building objects and refine the building shapes of input DSM with a conditional generative adversarial network (cGAN). The refined DSM and the input PAN image are then used through a semantic segmentation network to detect edges and corners of building roofs. Later, a set of vectorization algorithms are proposed to build roof polygons. Finally, the height information from the refined DSM is added to the polygons to obtain a fully vectorized level of detail (LoD)-2 building model. We verify the effectiveness of our method on large-scale satellite images, where we obtain state-of-the-art performance.      
### 40.Source and Target Bidirectional Knowledge Distillation for End-to-end Speech Translation  [ :arrow_down: ](https://arxiv.org/pdf/2104.06457.pdf)
>  A conventional approach to improving the performance of end-to-end speech translation (E2E-ST) models is to leverage the source transcription via pre-training and joint training with automatic speech recognition (ASR) and neural machine translation (NMT) tasks. However, since the input modalities are different, it is difficult to leverage source language text successfully. In this work, we focus on sequence-level knowledge distillation (SeqKD) from external text-based NMT models. To leverage the full potential of the source language information, we propose backward SeqKD, SeqKD from a target-to-source backward NMT model. To this end, we train a bilingual E2E-ST model to predict paraphrased transcriptions as an auxiliary task with a single decoder. The paraphrases are generated from the translations in bitext via back-translation. We further propose bidirectional SeqKD in which SeqKD from both forward and backward NMT models is combined. Experimental evaluations on both autoregressive and non-autoregressive models show that SeqKD in each direction consistently improves the translation performance, and the effectiveness is complementary regardless of the model capacity.      

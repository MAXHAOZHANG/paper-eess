# ArXiv eess --Tue, 27 Apr 2021
### 1.Simultaneous Wireless Information and Power Transfer for Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.12749.pdf)
>  In the Internet of Things, learning is one of most prominent tasks. In this paper, we consider an Internet of Things scenario where federated learning is used with simultaneous transmission of model data and wireless power. We investigate the trade-off between the number of communication rounds and communication round time while harvesting energy to compensate the energy expenditure. We formulate and solve an optimization problem by considering the number of local iterations on devices, the time to transmit-receive the model updates, and to harvest sufficient energy. Numerical results indicate that maximum ratio transmission and zero-forcing beamforming for the optimization of the local iterations on devices substantially boost the test accuracy of the learning task. Moreover, maximum ratio transmission instead of zero-forcing provides the best test accuracy and communication round time trade-off for various energy harvesting percentages. Thus, it is possible to learn a model quickly with few communication rounds without depleting the battery.      
### 2.Symplectic Transformations on Wigner Distributions and Time Frequency Signal Design  [ :arrow_down: ](https://arxiv.org/pdf/2104.12703.pdf)
>  This work considers uncertainty relations on time frequency distributions from a signal processing viewpoint. An uncertainty relation on the marginalizable time frequency distributions is given. A result from quantum mechanics is used on Wigner distributions and marginalizable time frequency distributions to investigate the change in variance of time and frequency variables from a signal processing perspective. Moreover, operations on signals which leave uncertainty relations unchanged are studied.      
### 3.Uncertainty Relations for MIMO Ambiguity Functions  [ :arrow_down: ](https://arxiv.org/pdf/2104.12691.pdf)
>  In this paper, uncertainty relations for MIMO ambiguity functions are given. Norm inequalities on the MIMO ambiguity functions in terms of signals of concern are studied. A signal dependent lower bound on the support of MIMO ambiguity functions is given via application of a local uncertainty relation. The uncertainty of Lieb and MIMO ambiguity functions are related. Uncertainty relations on MIMO covariance matrix are given in terms of matrix norms.      
### 4.MIMO Ambiguity Functions and Harmonic Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.12684.pdf)
>  Multi input multi output (MIMO) systems\' capability of using seperate signals brings many advantages to radar signal processing and time frequency analysis. In this paper, a variety of properties of MIMO ambiguity functions related with representations of Heisenberg group are given. Some of the existing results for SIMO ambiguity functions are generalized to MIMO case. Combined effect of seperate signals is investigated.      
### 5.Clean Images are Hard to Reblur: A New Clue for Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2104.12665.pdf)
>  The goal of dynamic scene deblurring is to remove the motion blur present in a given image. Most learning-based approaches implement their solutions by minimizing the L1 or L2 distance between the output and reference sharp image. Recent attempts improve the perceptual quality of the deblurred image by using features learned from visual recognition tasks. However, those features are originally designed to capture the high-level contexts rather than the low-level structures of the given image, such as blurriness. We propose a novel low-level perceptual loss to make image sharper. To better focus on image blurriness, we train a reblurring module amplifying the unremoved motion blur. Motivated that a well-deblurred clean image should contain zero-magnitude motion blur that is hard to be amplified, we design two types of reblurring loss functions. The supervised reblurring loss at training stage compares the amplified blur between the deblurred image and the reference sharp image. The self-supervised reblurring loss at inference stage inspects if the deblurred image still contains noticeable blur to be amplified. Our experimental results demonstrate the proposed reblurring losses improve the perceptual quality of the deblurred images in terms of NIQE and LPIPS scores as well as visual sharpness.      
### 6.Head-synchronous Decoding for Transformer-based Streaming ASR  [ :arrow_down: ](https://arxiv.org/pdf/2104.12631.pdf)
>  Online Transformer-based automatic speech recognition (ASR) systems have been extensively studied due to the increasing demand for streaming applications. Recently proposed Decoder-end Adaptive Computation Steps (DACS) algorithm for online Transformer ASR was shown to achieve state-of-the-art performance and outperform other existing methods. However, like any other online approach, the DACS-based attention heads in each of the Transformer decoder layers operate independently (or asynchronously) and lead to diverged attending positions. Since DACS employs a truncation threshold to determine the halting position, some of the attention weights are cut off untimely and might impact the stability and precision of decoding. To overcome these issues, here we propose a head-synchronous (HS) version of the DACS algorithm, where the boundary of attention is jointly detected by all the DACS heads in each decoder layer. ASR experiments on Wall Street Journal (WSJ), AIShell-1 and Librispeech show that the proposed method consistently outperforms vanilla DACS and achieves state-of-the-art performance. We will also demonstrate that HS-DACS has reduced decoding cost when compared to vanilla DACS.      
### 7.Fatigue Life Estimation of Structures under Statistically and Spectrally Similar Variable Amplitude Loading  [ :arrow_down: ](https://arxiv.org/pdf/2104.12605.pdf)
>  Engineering fatigue is a very prevalent and dangerous phenomenon that limits the useful life span of mechanical structures. It can be found in most engineered structures and machinery that are made from metallic or composite materials. The life prediction methodology under variable amplitude loading (VAL), however, has not reached maturity due to the complexity of the loading. This complexity results in load sequence effects, which significantly alter the fatigue life. Since most of the realistic loading experienced by engineered structures is of variable amplitude nature, and the corresponding responses at the defect site are highly irregular, characterization of the VAL and its resulting damage is paramount. Fatigue life estimation under VAL conventionally uses methods based on the Miner's Rule or the cumulative damage rule (CDR) in conjunction with the rainflow counting method. However, CDR does not account for the load interaction/sequence effects induced by local residual stress (or crack opening stress) variations.      
### 8.FedDPGAN: Federated Differentially Private Generative Adversarial Networks Framework for the Detection of COVID-19 Pneumonia  [ :arrow_down: ](https://arxiv.org/pdf/2104.12581.pdf)
>  Existing deep learning technologies generally learn the features of chest X-ray data generated by Generative Adversarial Networks (GAN) to diagnose COVID-19 pneumonia. However, the above methods have a critical challenge: data privacy. GAN will leak the semantic information of the training data which can be used to reconstruct the training samples by attackers, thereby this method will leak the privacy of the patient. Furthermore, for this reason that is the limitation of the training data sample, different hospitals jointly train the model through data sharing, which will also cause the privacy leakage. To solve this problem, we adopt the Federated Learning (FL) frame-work which is a new technique being used to protect the data privacy. Under the FL framework and Differentially Private thinking, we propose a FederatedDifferentially Private Generative Adversarial Network (FedDPGAN) to detectCOVID-19 pneumonia for sustainable smart cities. Specifically, we use DP-GAN to privately generate diverse patient data in which differential privacy technology is introduced to make sure the privacy protection of the semantic information of training dataset. Furthermore, we leverage FL to allow hospitals to collaboratively train COVID-19 models without sharing the original data. Under Independent and Identically Distributed (IID) and non-IID settings, The evaluation of the proposed model is on three types of chest X-ray (CXR) images dataset (COVID-19, normal, and normal pneumonia). A large number of the truthful reports make the verification of our model can effectively diagnose COVID-19 without compromising privacy.      
### 9.Multi-scale PIIFD for Registration of Multi-source Remote Sensing Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.12572.pdf)
>  This paper aims at providing multi-source remote sensing images registered in geometric space for image fusion. Focusing on the characteristics and differences of multi-source remote sensing images, a feature-based registration algorithm is implemented. The key technologies include image scale-space for implementing multi-scale properties, Harris corner detection for keypoints extraction, and partial intensity invariant feature descriptor (PIIFD) for keypoints description. Eventually, a multi-scale Harris-PIIFD image registration algorithm framework is proposed. The experimental results of four sets of representative real data show that the algorithm has excellent, stable performance in multi-source remote sensing image registration, and can achieve accurate spatial alignment, which has strong practical application value and certain generalization ability.      
### 10.Semantic Data Augmentation for End-to-End Mandarin Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.12521.pdf)
>  End-to-end models have gradually become the preferred option for automatic speech recognition (ASR) applications. During the training of end-to-end ASR, data augmentation is a quite effective technique for regularizing the neural networks. This paper proposes a novel data augmentation technique based on semantic transposition of the transcriptions via syntax rules for end-to-end Mandarin ASR. Specifically, we first segment the transcriptions based on part-of-speech tags. Then transposition strategies, such as placing the object in front of the subject or swapping the subject and the object, are applied on the segmented sentences. Finally, the acoustic features corresponding to the transposed transcription are reassembled based on the audio-to-text forced-alignment produced by a pre-trained ASR system. The combination of original data and augmented one is used for training a new ASR system. The experiments are conducted on the Transformer[2] and Conformer[3] based ASR. The results show that the proposed method can give consistent performance gain to the system. Augmentation related issues, such as comparison of different strategies and ratios for data combination are also investigated.      
### 11.Learning Safe and Optimal Control Strategies for Storm Water Detention Ponds  [ :arrow_down: ](https://arxiv.org/pdf/2104.12509.pdf)
>  Storm water detention ponds are used to manage the discharge of rainfall runoff from urban areas to nearby streams. Their purpose is to reduce the hydraulic impact and sediment loads of the receiving waters. Detention ponds are currently designed based on static controls: the output flow of a pond is capped at a fixed value. This is not optimal with respect to the current infrastructure capacity and for some detention ponds it might even violate current regulations set by the European Water Framework Directive. We apply formal methods to synthesize (i.e., derive automatically) a safe and optimal active controller. We model the storm water detention pond, including the urban catchment area and the rain forecasts, as a hybrid Markov decision process. Subsequently, we use the tool Uppaal Stratego to synthesize a control strategy minimizing the cost related to pollution (optimality) while guaranteeing no emergency overflow of the detention pond (safety). Simulation results for an existing pond show that Uppaal Stratego can learn optimal strategies that prevent emergency overflows, where the current static control is not always able to prevent it. At the same time, our approach can improve sedimentation during low rain periods.      
### 12.Distributed Eco-Driving Algorithm of Vehicle Platoon Using Traffic Light and Road Slope Information  [ :arrow_down: ](https://arxiv.org/pdf/2104.12499.pdf)
>  This paper investigates the problem of ecological driving (Eco-driving) of vehicle platoons. To reduce the probability of a platoon stopping at red lights and increase fuel efficiency, a two-layer control architecture is proposed. The first layer is in charge of optimizing the leader's long-term speed profile using traffic light and road slope information. The second layer is short-term adaptation, in which the leader attempts to follow the planning speed profile in real time, while the follower keeps track of the nearest preceding vehicle and leader, to preserve the desired inter-vehicular distances. The long-term planning is formulated as a complex optimization problem with dynamic inequality constraints. An algorithm combining Pontryagins minimum principle and particle swarm optimization (PSO) is established to efficiently solve the long-term planning problem. The short-term adaptation is described as model predictive control (MPC) problems, of which the solutions are analytically designed. The effectiveness of the proposed algorithm is illustrated by the simulations.      
### 13.A deep learning model for gastric diffuse-type adenocarcinoma classification in whole slide images  [ :arrow_down: ](https://arxiv.org/pdf/2104.12478.pdf)
>  Gastric diffuse-type adenocarcinoma represents a disproportionately high percentage of cases of gastric cancers occurring in the young, and its relative incidence seems to be on the rise. Usually it affects the body of the stomach, and presents shorter duration and worse prognosis compared with the differentiated (intestinal) type adenocarcinoma. The main difficulty encountered in the differential diagnosis of gastric adenocarcinomas occurs with the diffuse-type. As the cancer cells of diffuse-type adenocarcinoma are often single and inconspicuous in a background desmoplaia and inflammation, it can often be mistaken for a wide variety of non-neoplastic lesions including gastritis or reactive endothelial cells seen in granulation tissue. In this study we trained deep learning models to classify gastric diffuse-type adenocarcinoma from WSIs. We evaluated the models on five test sets obtained from distinct sources, achieving receiver operator curve (ROC) area under the curves (AUCs) in the range of 0.95-0.99. The highly promising results demonstrate the potential of AI-based computational pathology for aiding pathologists in their diagnostic workflow system.      
### 14.Improving precision of objective image/video quality metrics  [ :arrow_down: ](https://arxiv.org/pdf/2104.12448.pdf)
>  Although subjective tests are most accurate image/video quality assessment tools, they are extremely time demanding. In the past two decades, a variety of objective tools, such as SSIM, IW-SSIM, SPSIM, FSIM, etc., have been devised, that well correlate with the subjective tests results. However, the main problem with these methods is that, they do not discriminate the measured quality well enough, especially at high quality range. In this article we show how the accuracy/precision of these Image Quality Assessment (IQA) meters can be increased by mapping them into a Logistic Function (LF). The precisions are tested over a variety of image/video databases. Our experimental tests indicate while the used high-quality images can be discriminated by 23% resolution on the MOS subjective scores, discrimination resolution by the widely used IQAs are only 2%, but their mapped IQAs to Logistic Function at this quality range can be improved to 9.4%. Moreover, their precision at low to mid quality range can also be improved. At this quality range, while the discrimination resolution of MOS of the tested images is 23.2%, those of raw IQAs is nearly 8.9%, but their adapted logistic functions can lead to 17.7%, very close to that of MOS. Moreover, with the used image databases the Pearson correlation of MOS with the logistic function can be improved by 2%-20.2% as well.      
### 15.Joint Activity Detection and Data Decoding in Massive Random Access via a Turbo Receiver  [ :arrow_down: ](https://arxiv.org/pdf/2104.12443.pdf)
>  In this paper, we propose a turbo receiver for joint activity detection and data decoding in grant-free massive random access, which iterates between a detector and a belief propagation (BP)-based channel decoder. Specifically, responsible for user activity detection, channel estimation and soft data symbol detection, the detector is developed based on a bilinear inference problem that exploits the common sparsity pattern in the received pilot and data signals. The bilinear generalized approximate message passing (BiG-AMP) algorithm is adopted to solve the problem using probabilities of the transmitted data symbols estimated by the channel decoder as prior knowledge. In addition, extrinsic information is also derived from the detector to improve the channel decoding accuracy in the decoder. Simulation results show significant improvements achieved by the proposed turbo receiver compared with conventional designs.      
### 16.Designing Optimal Key Lengths and Control Laws for Encrypted Control Systems based on Sample Identifying Complexity and Deciphering Time  [ :arrow_down: ](https://arxiv.org/pdf/2104.12436.pdf)
>  In the state-of-the-art literature on cryptography and control theory, there has been no systematic methodology of constructing cyber-physical systems that can achieve desired control performance while being protected against eavesdropping attacks. In this paper, we tackle this challenging problem. We first propose two novel notions referred to as sample identifying complexity and sample deciphering time in an encrypted-control framework. The former explicitly captures the relation between the dynamical characteristics of control systems and the level of identifiability of the systems while the latter shows the relation between the computation time for the identification and the key length of a cryptosystem. Based on these two tractable new notions, we propose a systematic method for designing the both of an optimal key length to prevent system identification with a given precision within a given life span of systems, and of an optimal controller to maximize both of the control performance and the difficulty of the identification. The efficiency of the proposed method in terms of security level and realtime-ness is investigated through numerical simulations. To the best of our knowledge, this paper first connect the relationship between the security of cryptography and dynamical systems from a control-theoretic perspective.      
### 17.Phrase break prediction with bidirectional encoder representations in Japanese text-to-speech synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2104.12395.pdf)
>  We propose a novel phrase break prediction method that combines implicit features extracted from a pre-trained large language model, a.k.a BERT, and explicit features extracted from BiLSTM with linguistic features. In conventional BiLSTM based methods, word representations and/or sentence representations are used as independent components. The proposed method takes account of both representations to extract the latent semantics, which cannot be captured by previous methods. The objective evaluation results show that the proposed method obtains an absolute improvement of 3.2 points for the F1 score compared with BiLSTM-based conventional methods using linguistic features. Moreover, the perceptual listening test results verify that a TTS system that applied our proposed method achieved a mean opinion score of 4.39 in prosody naturalness, which is highly competitive with the score of 4.37 for synthesized speech with ground-truth phrase breaks.      
### 18.Recalibration of Aleatoric and Epistemic Regression Uncertainty in Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2104.12376.pdf)
>  The consideration of predictive uncertainty in medical imaging with deep learning is of utmost importance. We apply estimation of both aleatoric and epistemic uncertainty by variational Bayesian inference with Monte Carlo dropout to regression tasks and show that predictive uncertainty is systematically underestimated. We apply $ \sigma $ scaling with a single scalar value; a simple, yet effective calibration method for both types of uncertainty. The performance of our approach is evaluated on a variety of common medical regression data sets using different state-of-the-art convolutional network architectures. In our experiments, $ \sigma $ scaling is able to reliably recalibrate predictive uncertainty. It is easy to implement and maintains the accuracy. Well-calibrated uncertainty in regression allows robust rejection of unreliable predictions or detection of out-of-distribution samples. Our source code is available at <a class="link-external link-https" href="https://github.com/mlaves/well-calibrated-regression-uncertainty" rel="external noopener nofollow">this https URL</a>      
### 19.Game-Theoretic Mode Scheduling for Dynamic TDD in 5G Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.12367.pdf)
>  Dynamic time-division duplexing (TDD) enables independent uplink/downlink mode scheduling at each cell, based on the local traffic. However, this creates cross-interference among cells. Thus, the joint power allocation and scheduling problem becomes mixed-integer non-convex and turns out to be NP-hard. We propose a low-complexity and decentralized solution, where power allocation and scheduling are decoupled. First, power is allocated in a decentralized fashion, and then modes are scheduled by a non-cooperative game to achieve the mixed-strategy Nash equilibrium. We consider two possible approaches to compute the payoffs in the game, according to the cross-interference power model and the entailed communication overhead among cells. Simulation results are presented for an outdoor dense small-cell scenario, showing that our approaches outperform static TDD significantly.      
### 20.Underwater Target Recognition based on Multi-Decision LOFAR Spectrum Enhancement: A Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.12362.pdf)
>  The Low frequency analysis and recording (LOFAR) spectrum is one of the key features of the under water target, which can be used for underwater target recognition. However, the underwater environment noise is complicated and the signal-to-noise ratio of the underwater target is rather low, which introduces the breakpoints to the LOFAR spectrum and thus hinders the underwater target recognition. To overcome this issue and to further improve the recognition performance, we adopt a deep learning approach for underwater target recognition and propose a LOFAR spectrum enhancement (LSE)-based underwater target recognition scheme, which consists of preprocessing, offline training, and online testing. In preprocessing, a LOFAR spectrum enhancement based on multi-step decision algorithm is specifically designed to recover the breakpoints in LOFAR spectrum. In offline training, we then adopt the enhanced LOFAR spectrum as the input of convolutional neural network (CNN) and develop a LOFAR-based CNN (LOFAR-CNN) for online recognition. Taking advantage of the powerful capability of CNN in feature extraction, the proposed LOFAR-CNN can further improve the recognition accuracy. Finally, extensive simulation results demonstrate that the LOFAR-CNN network can achieve a recognition accuracy of $95.22\%$, which outperforms the state-of-the-art methods.      
### 21.Accuracy Improvement for Fully Convolutional Networks via Selective Augmentation with Applications to Electrocardiogram Data  [ :arrow_down: ](https://arxiv.org/pdf/2104.12284.pdf)
>  Deep learning methods have shown suitability for time series classification in the health and medical domain, with promising results for electrocardiogram data classification. Successful identification of myocardial infarction holds life saving potential and any meaningful improvement upon deep learning models in this area is of great interest. Conventionally, data augmentation methods are applied universally to the training set when data are limited in order to ameliorate data resolution or sample size. In the method proposed in this study, data augmentation was not applied in the context of data scarcity. Instead, samples that yield low confidence predictions were selectively augmented in order to bolster the model's sensitivity to features or patterns less strongly associated with a given class. This approach was tested for improving the performance of a Fully Convolutional Network. The proposed approach achieved 90 percent accuracy for classifying myocardial infarction as opposed to 82 percent accuracy for the baseline, a marked improvement. Further, the accuracy of the proposed approach was optimal near a defined upper threshold for qualifying low confidence samples and decreased as this threshold was raised to include higher confidence samples. This suggests exclusively selecting lower confidence samples for data augmentation comes with distinct benefits for electrocardiogram data classification with Fully Convolutional Networks.      
### 22.Intelligent Internal Temperature Control of Food in Standard Convection Ovens  [ :arrow_down: ](https://arxiv.org/pdf/2104.12162.pdf)
>  This paper introduces a feedback-based temperature controller design for intelligent regulation of food internal temperature inside of standard convection ovens. Typical convection ovens employ an open-loop control system that requires a person to estimate the amount of time needed to cook foods in order to achieve desired internal temperatures. This approach, however, can result in undesired results with the final food temperatures being too high or too low due to the inherent difficulty in accurately predicting required cooking times without continuously measuring internal states and accounting for noise in the system. By implementing and introducing a feedback controller with a full-order Luenberger observer to create a closed-loop system, an oven can be instrumented to measure and regulate the internal temperatures of food in order to automatically control oven heat output and confidently achieve desired results.      
### 23.Learning to Address Intra-segment Misclassification in Retinal Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2104.12138.pdf)
>  Accurate multi-class segmentation is a long-standing challenge in medical imaging, especially in scenarios where classes share strong similarity. Segmenting retinal blood vessels in retinal photographs is one such scenario, in which arteries and veins need to be identified and differentiated from each other and from the background. Intra-segment misclassification, i.e. veins classified as arteries or vice versa, frequently occurs when arteries and veins intersect, whereas in binary retinal vessel segmentation, error rates are much lower. We thus propose a new approach that decomposes multi-class segmentation into multiple binary, followed by a binary-to-multi-class fusion network. The network merges representations of artery, vein, and multi-class feature maps, each of which are supervised by expert vessel annotation in adversarial training. A skip-connection based merging process explicitly maintains class-specific gradients to avoid gradient vanishing in deep layers, to favor the discriminative features. The results show that, our model respectively improves F1-score by 4.4\%, 5.1\%, and 4.2\% compared with three state-of-the-art deep learning based methods on DRIVE-AV, LES-AV, and HRF-AV data sets.      
### 24.Semi-Passive 3D Positioning of Multiple RIS-Enabled Users  [ :arrow_down: ](https://arxiv.org/pdf/2104.12113.pdf)
>  Reconfigurable intelligent surfaces (RISs) are set to be a revolutionary technology in the 6th generation of wireless systems. In this work, we study the application of RIS in a multi-user passive localization scenario, where we have one transmitter (Tx) and multiple asynchronous receivers (Rxs) with known locations. We aim to estimate the locations of multiple users equipped with RISs. The RISs only reflect the signal from the Tx to the Rxs and are not used as active transceivers themselves. Each Rx receives the signal from the Tx (LOS path) and the reflected signal from the RISs (NLOS path). We show that users' 3D position can be estimated with submeter accuracy in a large area around the transmitter, using the LOS and NLOS time-of-arrival measurements at the Rxs. We do so, by developing the signal model, deriving the Cramer-Rao bounds, and devising an estimator that attains these bounds. Furthermore, by orthogonalizing the RIS phase profiles across different users, we circumvent inter-path interference.      
### 25.Scalable End-to-End RF Classification: A Case Study on Undersized Dataset Regularization by Convolutional-MST  [ :arrow_down: ](https://arxiv.org/pdf/2104.12103.pdf)
>  Unlike areas such as computer vision and speech recognition where convolutional and recurrent neural networks-based approaches have proven effective to the nature of the respective areas of application, deep learning (DL) still lacks a general approach suitable for the unique nature and challenges of RF systems such as radar, signals intelligence, electronic warfare, and communications. Existing approaches face problems in robustness, consistency, efficiency, repeatability and scalability. One of the main challenges in RF sensing such as radar target identification is the difficulty and cost of obtaining data. Hundreds to thousands of samples per class are typically used when training for classifying signals into 2 to 12 classes with reported accuracy ranging from 87% to 99%, where accuracy generally decreases with more classes added. In this paper, we present a new DL approach based on multistage training and demonstrate it on RF sensing signal classification. We consistently achieve over 99% accuracy for up to 17 diverse classes using only 11 samples per class for training, yielding up to 35% improvement in accuracy over standard DL approaches.      
### 26.Multi-Scale Hourglass Hierarchical Fusion Network for Single Image Deraining  [ :arrow_down: ](https://arxiv.org/pdf/2104.12100.pdf)
>  Rain streaks bring serious blurring and visual quality degradation, which often vary in size, direction and density. Current CNN-based methods achieve encouraging performance, while are limited to depict rain characteristics and recover image details in the poor visibility environment. To address these issues, we present a Multi-scale Hourglass Hierarchical Fusion Network (MH2F-Net) in end-to-end manner, to exactly captures rain streak features with multi-scale extraction, hierarchical distillation and information aggregation. For better extracting the features, a novel Multi-scale Hourglass Extraction Block (MHEB) is proposed to get local and global features across different scales through down- and up-sample process. Besides, a Hierarchical Attentive Distillation Block (HADB) then employs the dual attention feature responses to adaptively recalibrate the hierarchical features and eliminate the redundant ones. Further, we introduce a Residual Projected Feature Fusion (RPFF) strategy to progressively discriminate feature learning and aggregate different features instead of directly concatenating or adding. Extensive experiments on both synthetic and real rainy datasets demonstrate the effectiveness of the designed MH2F-Net by comparing with recent state-of-the-art deraining algorithms. Our source code will be available on the GitHub: <a class="link-external link-https" href="https://github.com/cxtalk/MH2F-Net" rel="external noopener nofollow">this https URL</a>.      
### 27.A 3D Non-Stationary Channel Model for 6G Wireless Systems Employing Intelligent Reflecting Surfaces with Practical Phase Shifts  [ :arrow_down: ](https://arxiv.org/pdf/2104.12093.pdf)
>  In this paper, a three-dimensional (3D) geometry based stochastic model (GBSM) for a massive multiple-input multiple-output (MIMO) communication system employing practical discrete intelligent reflecting surface (IRS) is proposed. The proposed channel model supports the scenario where both transceivers and environments move. The evolution of clusters in the space domain and the practical discrete phase shifts are considered in the channel model. The steering vector is set at the base station for the cooperation with IRS. Through studying statistical properties, the non-stationary properties are verified. We find that IRS plays a role in separating the whole channel and make the absolute value of time autocorrelation function (ACF) larger than the situation without employing IRS. Time ACF of the case using discrete phase shifts is also compared with the continuous case.      
### 28.Swimmer Stroke Rate Estimation From Overhead Race Video  [ :arrow_down: ](https://arxiv.org/pdf/2104.12056.pdf)
>  In this work, we propose a swimming analytics system for automatically determining swimmer stroke rates from overhead race video (ORV). General ORV is defined as any footage of swimmers in competition, taken for the purposes of viewing or analysis. Examples of this are footage from live streams, broadcasts, or specialized camera equipment, with or without camera motion. These are the most typical forms of swimming competition footage. We detail how to create a system that will automatically collect swimmer stroke rates in any competition, given the video of the competition of interest. With this information, better systems can be created and additions to our analytics system can be proposed to automatically extract other swimming metrics of interest.      
### 29.Multi-Cycle-Consistent Adversarial Networks for Edge Denoising of Computed Tomography Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.12044.pdf)
>  As one of the most commonly ordered imaging tests, computed tomography (CT) scan comes with inevitable radiation exposure that increases the cancer risk to patients. However, CT image quality is directly related to radiation dose, thus it is desirable to obtain high-quality CT images with as little dose as possible. CT image denoising tries to obtain high dose like high-quality CT images (domain X) from low dose low-quality CTimages (domain Y), which can be treated as an image-to-image translation task where the goal is to learn the transform between a source domain X (noisy images) and a target domain Y (clean images). In this paper, we propose a multi-cycle-consistent adversarial network (MCCAN) that builds intermediate domains and enforces both local and global cycle-consistency for edge denoising of CT images. The global cycle-consistency couples all generators together to model the whole denoising process, while the local cycle-consistency imposes effective supervision on the process between adjacent domains. Experiments show that both local and global cycle-consistency are important for the success of MCCAN, which outperformsCCADN in terms of denoising quality with slightly less computation resource consumption.      
### 30.Riemannian Trust-Region based Adaptive Kalman filter with unknown noise Covariance matrices  [ :arrow_down: ](https://arxiv.org/pdf/2104.12035.pdf)
>  The problem of adaptive Kalman filtering for a discrete observable linear time-varying system with unknown noise covariance matrices is addressed in this paper. The measurement difference autocovariance method is used to formulate a linear least squares cost function containing the measurements and the process and measurement noise covariance matrices. Subsequently, a Riemannian trust-region optimization approach is designed to minimize the least squares cost function and ensure symmetry and positive definiteness for the estimates of the noise covariance matrices. The noise covariance matrix estimates, under sufficient excitation of the system, are shown to converge to their unknown true values. Saliently, the exponential stability and convergence guarantees for the proposed adaptive Kalman filter to the optimal Kalman filter with known noise covariance matrices is shown to be achieved under the relatively mild assumptions of uniform observability and uniform controllability. Numerical simulations on a linear time-varying system demonstrate the effectiveness of the proposed adaptive filtering algorithm.      
### 31.Deep Convolutional Neural Network for Non-rigid Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2104.12034.pdf)
>  Images taken at different times or positions undergo transformations such as rotation, scaling, skewing, and more. The process of aligning different images which have undergone transformations can be done via registration. Registration is desirable when analyzing time-series data for tracking, averaging, or differential diagnoses of diseases. Efficient registration methods exist for rigid (including linear or affine) transformations; however, for non-rigid (also known as non-affine) transformations, current methods are computationally expensive and time-consuming. In this report, I will explore the ability of a deep neural network (DNN) and, more specifically, a deep convolutional neural network (CNN) to efficiently perform non-rigid image registration. The experimental results show that a CNN can be used for efficient non-rigid image registration and in significantly less computational time than a conventional Diffeomorphic Demons or Pyramiding approach.      
### 32.Language ID Prediction from Speech Using Self-Attentive Pooling and 1D-Convolutions  [ :arrow_down: ](https://arxiv.org/pdf/2104.11985.pdf)
>  This memo describes NTR-TSU submission for SIGTYP 2021 Shared Task on predicting language IDs from speech. <br>Spoken Language Identification (LID) is an important step in a multilingual Automated Speech Recognition (ASR) system pipeline. For many low-resource and endangered languages, only single-speaker recordings may be available, demanding a need for domain and speaker-invariant language ID systems. In this memo, we show that a convolutional neural network with a Self-Attentive Pooling layer shows promising results for the language identification task.      
### 33.Exploiting Spatial Correlation for Pilot Reuse in Single-Cell mMTC  [ :arrow_down: ](https://arxiv.org/pdf/2104.11978.pdf)
>  As a key enabler for massive machine-type communications (mMTC), spatial multiplexing relies on massive multiple-input multiple-output (mMIMO) technology to serve the massive number of user equipments (UEs). To exploit spatial multiplexing, accurate channel estimation through pilot signals is needed. In mMTC systems, it is impractical to allocate a unique orthogonal pilot sequence to each UE as it would require too long pilot sequences, degrading the spectral efficiency. This work addresses the design of channel features from correlated fading channels to assist the pilot assignment in multi-sector mMTC systems under pilot reuse of orthogonal sequences. In order to reduce pilot collisions and to enable pilot reuse, we propose to extract features from the channel covariance matrices that reflect the level of orthogonality between the UEs channels. Two features are investigated: covariance matrix distance (CMD) feature and CMD-aided channel charting (CC) feature. In terms of symbol error rate and achievable rate, the CC-based feature shows superior performance than the CMD-based feature and baseline pilot assignment algorithms.      
### 34.Automatic Diagnosis of COVID-19 from CT Images using CycleGAN and Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.11949.pdf)
>  The outbreak of the corona virus disease (COVID-19) has changed the lives of most people on Earth. Given the high prevalence of this disease, its correct diagnosis in order to quarantine patients is of the utmost importance in steps of fighting this pandemic. Among the various modalities used for diagnosis, medical imaging, especially computed tomography (CT) imaging, has been the focus of many previous studies due to its accuracy and availability. In addition, automation of diagnostic methods can be of great help to physicians. In this paper, a method based on pre-trained deep neural networks is presented, which, by taking advantage of a cyclic generative adversarial net (CycleGAN) model for data augmentation, has reached state-of-the-art performance for the task at hand, i.e., 99.60% accuracy. Also, in order to evaluate the method, a dataset containing 3163 images from 189 patients has been collected and labeled by physicians. Unlike prior datasets, normal data have been collected from people suspected of having COVID-19 disease and not from data from other diseases, and this database is made available publicly.      
### 35.Automata-based Controller Synthesis for Stochastic Systems: A Game Framework via Approximate Probabilistic Relations  [ :arrow_down: ](https://arxiv.org/pdf/2104.11803.pdf)
>  In this work, we propose an abstraction and refinement methodology for the controller synthesis of discrete-time stochastic systems to enforce complex logical properties expressed by deterministic finite automata (a.k.a. DFA). Our proposed scheme is based on a notion of so-called $(\epsilon,\delta)$-approximate probabilistic relations, allowing one to quantify the similarity between stochastic systems modeled by discrete-time stochastic games and their corresponding finite abstractions. Leveraging this type of relations, the lower bound for the probability of satisfying the desired specifications can be well ensured by refining controllers synthesized over abstract systems to the original games. Moreover, we propose an algorithmic procedure to construct such a relation for a particular class of nonlinear stochastic systems with slope restrictions on the nonlinearity. The proposed methods are demonstrated on a quadrotor example, and the results indicate that the desired lower bound for the probability of satisfaction is guaranteed.      
### 36.Adaptive Feedback Regulator for Powered Lower-Limb Exoskeleton under Model Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2104.11775.pdf)
>  This paper presents a neural network (NN) based adaptive feedback regulator to ensure the lateral and longitudinal stability and regulate the desired walking velocity of a lower-limb exoskeleton under model uncertainty. The traditional model-based controllers for lower-limb exoskeletons often fail to stabilize the robot or accurately track the desired behaviors under model uncertainties or external disturbances. This paper proposes a neural network (NN) based online adaptive regulator that compensates for the unknown changes in model parameters and external disturbances by modifying the nominal joint trajectory. A gradient descent-based delta rule is implemented to update the weights of a single layer NN, which can be efficiently performed online by design. We demonstrate the performance of the presented regulator on ATALANTE, a fully actuated lower limb exoskeleton designed for paraplegic patients. The simulation results show that the proposed approach noticeably improves stability and the tracking performance of the system, despite significant changes in model parameters and large adversarial pushes.      
### 37.Identifying Actions for Sound Event Classification  [ :arrow_down: ](https://arxiv.org/pdf/2104.12693.pdf)
>  In Psychology, actions are paramount for humans to perceive and separate sound events. In Machine Learning (ML), action recognition achieves high accuracy; however, it has not been asked if identifying actions can benefit Sound Event Classification (SEC), as opposed to mapping the audio directly to a sound event. Therefore, we propose a new Psychology-inspired approach for SEC that includes identification of actions via human listeners. To achieve this goal, we used crowdsourcing to have listeners identify 20 actions that in isolation or in combination may have produced any of the 50 sound events in the well-studied dataset ESC-50. The resulting annotations for each audio recording relate actions to a database of sound events for the first time~\footnote{Annotations will be released after revision.}. The annotations were used to create semantic representations called Action Vectors (AVs). We evaluated SEC by comparing the AVs with two types of audio features -- log-mel spectrograms and state of the art audio embeddings. Because audio features and AVs capture different abstractions of the acoustic content, we combined them and achieved one of the highest reported accuracies (86.75%) in ESC-50, showing that Psychology-inspired approaches can improve SEC.      
### 38.MAQ-CaF: A Modular Air Quality Calibration and Forecasting method for cross-sensitive pollutants  [ :arrow_down: ](https://arxiv.org/pdf/2104.12594.pdf)
>  The climatic challenges are rising across the globe in general and in worst hit under-developed countries in particular. The need for accurate measurements and forecasting of pollutants with low-cost deployment is more pertinent today than ever before. Low-cost air quality monitoring sensors are prone to erroneous measurements, frequent downtimes, and uncertain operational conditions. Such a situation demands a prudent approach to ensure an effective and flexible calibration scheme. We propose MAQ-CaF, a modular air quality calibration, and forecasting methodology, that side-steps the challenges of unreliability through its modular machine learning-based design which leverages the potential of IoT framework. It stores the calibrated data both locally and remotely with an added feature of future predictions. Our specially designed validation process helps to establish the proposed solution's applicability and flexibility without compromising accuracy. CO, SO2, NO2, O3, PM1.0, PM2.5 and PM10 were calibrated and monitored with reasonable accuracy. Such an attempt is a step toward addressing climate change's global challenge through appropriate monitoring and air quality tracking across a wider geographical region via affordable monitoring.      
### 39.Spatio-Temporal Pruning and Quantization for Low-latency Spiking Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.12528.pdf)
>  Spiking Neural Networks (SNNs) are a promising alternative to traditional deep learning methods since they perform event-driven information processing. However, a major drawback of SNNs is high inference latency. The efficiency of SNNs could be enhanced using compression methods such as pruning and quantization. Notably, SNNs, unlike their non-spiking counterparts, consist of a temporal dimension, the compression of which can lead to latency reduction. In this paper, we propose spatial and temporal pruning of SNNs. First, structured spatial pruning is performed by determining the layer-wise significant dimensions using principal component analysis of the average accumulated membrane potential of the neurons. This step leads to 10-14X model compression. Additionally, it enables inference with lower latency and decreases the spike count per inference. To further reduce latency, temporal pruning is performed by gradually reducing the timesteps while training. The networks are trained using surrogate gradient descent based backpropagation and we validate the results on CIFAR10 and CIFAR100, using VGG architectures. The spatiotemporally pruned SNNs achieve 89.04% and 66.4% accuracy on CIFAR10 and CIFAR100, respectively, while performing inference with 3-30X reduced latency compared to state-of-the-art SNNs. Moreover, they require 8-14X lesser compute energy compared to their unpruned standard deep learning counterparts. The energy numbers are obtained by multiplying the number of operations with energy per operation. These SNNs also provide 1-4% higher robustness against Gaussian noise corrupted inputs. Furthermore, we perform weight quantization and find that performance remains reasonably stable up to 5-bit quantization.      
### 40.Simulation Modelling and Analysis of Primary Health Centre Operations  [ :arrow_down: ](https://arxiv.org/pdf/2104.12492.pdf)
>  We present discrete-event simulation models of the operations of primary health centres (PHCs) in the Indian context. Our PHC simulation models incorporate four types of patients seeking medical care: outpatients, limited inpatient care, childbirth cases, and patients seeking antenatal care. A generic modelling approach involving development of reconfigurable simulations was adopted to simulate PHC operations. This involved developing an archetype PHC simulation, which was then modified to represent the three PHC configurations, differing in the number and type of services provided, encountered during PHC visits. A model representing the government-mandated case was also developed. Simulation outcomes for all three observed configurations indicate negligible average patient waiting times and low resource utilization values at observed estimates of patient demand. Simulation outcomes for the government mandated configuration model based on demand estimated from public health data and larger outpatient consultation times indicated significantly higher resource utilization. Simulation experiments to evaluate the effect of potential changes in operational patterns on reducing the utilization of stressed resources for the government mandated case were performed. Our analysis also motivated the development of simple analytical approximations of the average utilization of a server in a queueing system with characteristics similar to the PHC doctor/patient system.      
### 41.Points2Sound: From mono to binaural audio using 3D point cloud scenes  [ :arrow_down: ](https://arxiv.org/pdf/2104.12462.pdf)
>  Binaural sound that matches the visual counterpart is crucial to bring meaningful and immersive experiences to people in augmented reality (AR) and virtual reality (VR) applications. Recent works have shown the possibility to generate binaural audio from mono using 2D visual information as guidance. Using 3D visual information may allow for a more accurate representation of a virtual audio scene for VR/AR applications. This paper proposes Points2Sound, a multi-modal deep learning model which generates a binaural version from mono audio using 3D point cloud scenes. Specifically, Points2Sound consist of a vision network which extracts visual features from the point cloud scene to condition an audio network, which operates in the waveform domain, to synthesize the binaural version. Both quantitative and perceptual evaluations indicate that our proposed model is preferred over a reference case, based on a recent 2D mono-to-binaural model.      
### 42.3D Scene Compression through Entropy Penalized Neural Representation Functions  [ :arrow_down: ](https://arxiv.org/pdf/2104.12456.pdf)
>  Some forms of novel visual media enable the viewer to explore a 3D scene from arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.      
### 43.Uncertain AoI in Stochastic Optimal Control of Networked and Constrained LTI Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.12435.pdf)
>  This paper addresses finite-time horizon optimal control of single-loop networked control systems with stochastically modeled communication channel and disturbances. To cope with the uncertainties, an optimization-based control scheme is proposed which uses a disturbance feedback and the age of information as central aspects. The disturbance feedback is an extension of the control law used for balanced stochastic optimal control previously proposed for control systems without network. Balanced optimality is understood as a compromise between minimizing of expected deviations from the reference and minimization of the uncertainty of future states. Time-varying state constraints as well as time-invariant input constraints are considered, and the controllers are synthesized by semi-definite programs.      
### 44.Generation of musical patterns through operads  [ :arrow_down: ](https://arxiv.org/pdf/2104.12432.pdf)
>  We introduce the notion of multi-pattern, a combinatorial abstraction of polyphonic musical phrases. The interest of this approach lies in the fact that this offers a way to compose two multi-patterns in order to produce a longer one. This dives musical phrases into an algebraic context since the set of multi-patterns has the structure of an operad; operads being structures offering a formalization of the notion of operators and their compositions. Seeing musical phrases as operators allows us to perform computations on phrases and admits applications in generative music: given a set of short patterns, we propose various algorithms to randomly generate a new and longer phrase inspired by the inputted patterns.      
### 45.Index Modulation Based Coordinate Interleaved Orthogonal Design for Secure Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.12430.pdf)
>  In this paper, we propose a physical layer security scheme that exploits a novel index modulation (IM) technique for coordinate interleaved orthogonal designs (CIOD). Utilizing the diversity gain of CIOD transmission, the proposed scheme, named CIOD-IM, provides an improved spectral efficiency by means of IM. In order to provide a satisfactory secrecy rate, we design a particular artificial noise matrix, which does not affect the performance of the legitimate receiver, while deteriorating the performance of the eavesdropper. We derive expressions of the ergodic secrecy rate and the theoretical bit error rate upper bound. In addition, we analyze the case of imperfect channel estimation by taking practical concerns into consideration. It is shown via computer simulations that the proposed scheme outperforms the existing IM-based schemes and might be a candidate for future secure communication systems.      
### 46.Cold-Start Modeling and On-Line Optimal Control of the Three-Way Catalyst  [ :arrow_down: ](https://arxiv.org/pdf/2104.12390.pdf)
>  We present a three-way catalyst (TWC) cold-start model, calibrate the model based on experimental data from multiple operating points, and use the model to generate a Pareto-optimal cold-start controller suitable for implementation in standard engine control unit hardware. The TWC model is an extension of a previously presented physics-based model that predicts carbon monoxide, hydrocarbon, and nitrogen oxides tailpipe emissions. The model axially and radially resolves the temperatures in the monolith using very few state variables, thus allowing for use with control-policy based optimal control methods. In this paper we extend the model to allow for variable axial discretization lengths, include the heat of reaction from hydrogen gas generated from the combustion engine, and reformulate the model parameters to be expressed in conventional units. We experimentally measured the temperature and emission evolution for cold-starts with ten different engine load points, which was subsequently used to tune the model parameters (e.g.~chemical reaction rates, specific heats, and thermal resistances). The simulated cumulative tailpipe emission modeling error was found to be typically -20% to +80% of the measured emissions. We have constructed and simulated the performance of a Pareto-optimal controller using this model that balances fuel efficiency and the cumulative emissions of each individual species. A benchmark of the optimal controller with a conventional cold-start strategy shows the potential for reducing the cold-start emissions.      
### 47.Variational Pedestrian Detection  [ :arrow_down: ](https://arxiv.org/pdf/2104.12389.pdf)
>  Pedestrian detection in a crowd is a challenging task due to a high number of mutually-occluding human instances, which brings ambiguity and optimization difficulties to the current IoU-based ground truth assignment procedure in classical object detection methods. In this paper, we develop a unique perspective of pedestrian detection as a variational inference problem. We formulate a novel and efficient algorithm for pedestrian detection by modeling the dense proposals as a latent variable while proposing a customized Auto Encoding Variational Bayes (AEVB) algorithm. Through the optimization of our proposed algorithm, a classical detector can be fashioned into a variational pedestrian detector. Experiments conducted on CrowdHuman and CityPersons datasets show that the proposed algorithm serves as an efficient solution to handle the dense pedestrian detection problem for the case of single-stage detectors. Our method can also be flexibly applied to two-stage detectors, achieving notable performance enhancement.      
### 48.Complex Neural Spatial Filter: Enhancing Multi-channel Target Speech Separation in Complex Domain  [ :arrow_down: ](https://arxiv.org/pdf/2104.12359.pdf)
>  To date, mainstream target speech separation (TSS) approaches are formulated to estimate the complex ratio mask (cRM) of the target speech in time-frequency domain under supervised deep learning framework. However, the existing deep models for estimating cRM are designed in the way that the real and imaginary parts of the cRM are separately modeled using real-valued training data pairs. The research motivation of this study is to design a deep model that fully exploits the temporal-spectral-spatial information of multi-channel signals for estimating cRM directly and efficiently in complex domain. As a result, a novel TSS network is designed consisting of two modules, a complex neural spatial filter (cNSF) and an MVDR. Essentially, cNSF is a cRM estimation model and an MVDR module is cascaded to the cNSF module to reduce the nonlinear speech distortions introduced by neural network. Specifically, to fit the cRM target, all input features of cNSF are reformulated into complex-valued representations following the supervised learning paradigm. Then, to achieve good hierarchical feature abstraction, a complex deep neural network (cDNN) is delicately designed with U-Net structure. Experiments conducted on simulated multi-channel speech data demonstrate the proposed cNSF outperforms the baseline NSF by 12.1% scale-invariant signal-to-distortion ratio and 33.1% word error rate.      
### 49.A tutorial on generalized eigendecomposition for source separation in multichannel electrophysiology  [ :arrow_down: ](https://arxiv.org/pdf/2104.12356.pdf)
>  The goal of this paper is to present a theoretical and practical introduction to generalized eigendecomposition (GED), which is a robust and flexible framework used for dimension reduction and source separation in multichannel signal processing. In cognitive electrophysiology, GED is used to create spatial filters that maximize a researcher-specified contrast, such as relative spectral power or experiment condition differences. GED is fast and easy to compute, performs well in simulated and real data, and is easily adaptable to a variety of specific research goals. This paper introduces GED in a way that ties together myriad individual publications and applications of GED in electrophysiology. Practical considerations and issues that often arise in applications are discussed.      
### 50.Deep Learning-Empowered Predictive Beamforming for IRS-Assisted Multi-User Communications  [ :arrow_down: ](https://arxiv.org/pdf/2104.12309.pdf)
>  The realization of practical intelligent reflecting surface (IRS)-assisted multi-user communication (IRS-MUC) systems critically depends on the proper beamforming design exploiting accurate channel state information (CSI). However, channel estimation (CE) in IRS-MUC systems requires a significantly large training overhead due to the numerous reflection elements involved in IRS. In this paper, we adopt a deep learning approach to implicitly learn the historical channel features and directly predict the IRS phase shifts for the next time slot to maximize the average achievable sum-rate of an IRS-MUC system taking into account the user mobility. By doing this, only a low-dimension multiple-input single-output (MISO) CE is needed for transmit beamforming design, thus significantly reducing the CE overhead. To this end, a location-aware convolutional long short-term memory network (LA-CLNet) is first developed to facilitate predictive beamforming at IRS, where the convolutional and recurrent units are jointly adopted to exploit both the spatial and temporal features of channels simultaneously. Given the predictive IRS phase shift beamforming, an instantaneous CSI (ICSI)-aware fully-connected neural network (IA-FNN) is then proposed to optimize the transmit beamforming matrix at the access point. Simulation results demonstrate that the sum-rate performance achieved by the proposed method approaches that of the genie-aided scheme with the full perfect ICSI.      
### 51.Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2104.12292.pdf)
>  Speech synthesis and music audio generation from symbolic input differ in many aspects but share some similarities. In this study, we investigate how text-to-speech synthesis techniques can be used for piano MIDI-to-audio synthesis tasks. Our investigation includes Tacotron and neural source-filter waveform models as the basic components, with which we build MIDI-to-audio synthesis systems in similar ways to TTS frameworks. We also include reference systems using conventional sound modeling techniques such as sample-based and physical-modeling-based methods. The subjective experimental results demonstrate that the investigated TTS components can be applied to piano MIDI-to-audio synthesis with minor modifications. The results also reveal the performance bottleneck -- while the waveform model can synthesize high quality piano sound given natural acoustic features, the conversion from MIDI to acoustic features is challenging. The full MIDI-to-audio synthesis system is still inferior to the sample-based or physical-modeling-based approaches, but we encourage TTS researchers to test their TTS models for this new task and improve the performance.      
### 52.HyperRNN: Deep Learning-Aided Downlink CSI Acquisition via Partial Channel Reciprocity for FDD Massive MIMO  [ :arrow_down: ](https://arxiv.org/pdf/2104.12274.pdf)
>  In order to unlock the full advantages of massive multiple input multiple output (MIMO) in the downlink, channel state information (CSI) is required at the base station (BS) to optimize the beamforming matrices. In frequency division duplex (FDD) systems, full channel reciprocity does not hold, and CSI acquisition generally requires downlink pilot transmission followed by uplink feedback. Prior work proposed the end-to-end design of pilot transmission, feedback, and CSI estimation via deep learning. In this work, we introduce an enhanced end-to-end design that leverages partial uplink-downlink reciprocity and temporal correlation of the fading processes by utilizing jointly downlink and uplink pilots. The proposed method is based on a novel deep learning architecture -- HyperRNN -- that combines hypernetworks and recurrent neural networks (RNNs) to optimize the transfer of long-term channel features from uplink to downlink. Simulation results demonstrate that the HyperRNN achieves a lower normalized mean square error (NMSE) performance, and that it reduces requirements in terms of pilot lengths.      
### 53.Frequency Superposition -- A Multi-Frequency Stimulation Method in SSVEP-based BCIs  [ :arrow_down: ](https://arxiv.org/pdf/2104.12187.pdf)
>  The steady-state visual evoked potential (SSVEP) is one of the most widely used modalities in brain-computer interfaces (BCIs) due to its many advantages. However, the existence of harmonics and the limited range of responsive frequencies in SSVEP make it challenging to further expand the number of targets without sacrificing other aspects of the interface or putting additional constraints on the system. This paper introduces a novel multi-frequency stimulation method for SSVEP and investigates its potential to effectively and efficiently increase the number of targets presented. The proposed stimulation method, obtained by the superposition of the stimulation signals at different frequencies, is size-efficient, allows single-step target identification, puts no strict constraints on the usable frequency range, can be suited to self-paced BCIs, and does not require specific light sources. In addition to the stimulus frequencies and their harmonics, the evoked SSVEP waveforms include frequencies that are integer linear combinations of the stimulus frequencies. Results of decoding SSVEPs collected from nine subjects using canonical correlation analysis (CCA) with only the frequencies and harmonics as reference, also demonstrate the potential of using such a stimulation paradigm in SSVEP-based BCIs.      
### 54.An Adaptive Learning based Generative Adversarial Network for One-To-One Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2104.12159.pdf)
>  Voice Conversion (VC) emerged as a significant domain of research in the field of speech synthesis in recent years due to its emerging application in voice-assisting technology, automated movie dubbing, and speech-to-singing conversion to name a few. VC basically deals with the conversion of vocal style of one speaker to another speaker while keeping the linguistic contents unchanged. VC task is performed through a three-stage pipeline consisting of speech analysis, speech feature mapping, and speech reconstruction. Nowadays the Generative Adversarial Network (GAN) models are widely in use for speech feature mapping from source to target speaker. In this paper, we propose an adaptive learning-based GAN model called ALGAN-VC for an efficient one-to-one VC of speakers. Our ALGAN-VC framework consists of some approaches to improve the speech quality and voice similarity between source and target speakers. The model incorporates a Dense Residual Network (DRN) like architecture to the generator network for efficient speech feature learning, for source to target speech feature conversion. We also integrate an adaptive learning mechanism to compute the loss function for the proposed model. Moreover, we use a boosted learning rate approach to enhance the learning capability of the proposed model. The model is trained by using both forward and inverse mapping simultaneously for a one-to-one VC. The proposed model is tested on Voice Conversion Challenge (VCC) 2016, 2018, and 2020 datasets as well as on our self-prepared speech dataset, which has been recorded in Indian regional languages and in English. A subjective and objective evaluation of the generated speech samples indicated that the proposed model elegantly performed the voice conversion task by achieving high speaker similarity and adequate speech quality.      
### 55.Development of a Soft Actor Critic Deep Reinforcement Learning Approach for Harnessing Energy Flexibility in a Large Office Building  [ :arrow_down: ](https://arxiv.org/pdf/2104.12125.pdf)
>  This research is concerned with the novel application and investigation of `Soft Actor Critic' (SAC) based Deep Reinforcement Learning (DRL) to control the cooling setpoint (and hence cooling loads) of a large commercial building to harness energy flexibility. The research is motivated by the challenge associated with the development and application of conventional model-based control approaches at scale to the wider building stock. SAC is a model-free DRL technique that is able to handle continuous action spaces and which has seen limited application to real-life or high-fidelity simulation implementations in the context of automated and intelligent control of building energy systems. Such control techniques are seen as one possible solution to supporting the operation of a smart, sustainable and future electrical grid. This research tests the suitability of the SAC DRL technique through training and deployment of the agent on an EnergyPlus based environment of the office building. The SAC DRL was found to learn an optimal control policy that was able to minimise energy costs by 9.7% compared to the default rule-based control (RBC) scheme and was able to improve or maintain thermal comfort limits over a test period of one week. The algorithm was shown to be robust to the different hyperparameters and this optimal control policy was learnt through the use of a minimal state space consisting of readily available variables. The robustness of the algorithm was tested through investigation of the speed of learning and ability to deploy to different seasons and climates. It was found that the SAC DRL requires minimal training sample points and outperforms the RBC after three months of operation and also without disruption to thermal comfort during this period. The agent is transferable to other climates and seasons although further retraining or hyperparameter tuning is recommended.      
### 56.Making GAN-Generated Images Difficult To Spot: A New Attack Against Synthetic Image Detectors  [ :arrow_down: ](https://arxiv.org/pdf/2104.12069.pdf)
>  Visually realistic GAN-generated images have recently emerged as an important misinformation threat. Research has shown that these synthetic images contain forensic traces that are readily identifiable by forensic detectors. Unfortunately, these detectors are built upon neural networks, which are vulnerable to recently developed adversarial attacks. In this paper, we propose a new anti-forensic attack capable of fooling GAN-generated image detectors. Our attack uses an adversarially trained generator to synthesize traces that these detectors associate with real images. Furthermore, we propose a technique to train our attack so that it can achieve transferability, i.e. it can fool unknown CNNs that it was not explicitly trained against. We demonstrate the performance of our attack through an extensive set of experiments, where we show that our attack can fool eight state-of-the-art detection CNNs with synthetic images created using seven different GANs.      
### 57.MusCaps: Generating Captions for Music Audio  [ :arrow_down: ](https://arxiv.org/pdf/2104.11984.pdf)
>  Content-based music information retrieval has seen rapid progress with the adoption of deep learning. Current approaches to high-level music description typically make use of classification models, such as in auto-tagging or genre and mood classification. In this work, we propose to address music description via audio captioning, defined as the task of generating a natural language description of music audio content in a human-like manner. To this end, we present the first music audio captioning model, MusCaps, consisting of an encoder-decoder with temporal attention. Our method combines convolutional and recurrent neural network architectures to jointly process audio-text inputs through a multimodal encoder and leverages pre-training on audio data to obtain representations that effectively capture and summarise musical features in the input. Evaluation of the generated captions through automatic metrics shows that our method outperforms a baseline designed for non-music audio captioning. Through an ablation study, we unveil that this performance boost can be mainly attributed to pre-training of the audio encoder, while other design choices - modality fusion, decoding strategy and the use of attention - contribute only marginally. Our model represents a shift away from classification-based music description and combines tasks requiring both auditory and linguistic understanding to bridge the semantic gap in music information retrieval.      
### 58.UNIFY: Multi-Belief Bayesian Grid Framework based on Automotive Radar  [ :arrow_down: ](https://arxiv.org/pdf/2104.11979.pdf)
>  Grid maps are widely established for the representation of static objects in robotics and automotive applications. Though, incorporating velocity information is still widely examined because of the increased complexity of dynamic grids concerning both velocity measurement models for radar sensors and the representation of velocity in a grid framework. In this paper, both issues are addressed: sensor models and an efficient grid framework, which are required to ensure efficient and robust environment perception with radar. To that, we introduce new inverse radar sensor models covering radar sensor artifacts such as measurement ambiguities to integrate automotive radar sensors for improved velocity estimation. <br>Furthermore, we introduce UNIFY, a multiple belief Bayesian grid map framework for static occupancy and velocity estimation with independent layers. The proposed UNIFY framework utilizes a grid-cell-based layer to provide occupancy information and a particle-based velocity layer for motion state estimation in an autonomous vehicle's environment. Each UNIFY layer allows individual execution as well as simultaneous execution of both layers for optimal adaption to varying environments in autonomous driving applications. <br>UNIFY was tested and evaluated in terms of plausibility and efficiency on a large real-world radar data-set in challenging traffic scenarios covering different densities in urban and rural sceneries.      
### 59.Aligned Contrastive Predictive Coding  [ :arrow_down: ](https://arxiv.org/pdf/2104.11946.pdf)
>  We investigate the possibility of forcing a self-supervised model trained using a contrastive predictive loss to extract slowly varying latent representations. Rather than producing individual predictions for each of the future representations, the model emits a sequence of predictions shorter than that of the upcoming representations to which they will be aligned. In this way, the prediction network solves a simpler task of predicting the next symbols, but not their exact timing, while the encoding network is trained to produce piece-wise constant latent codes. We evaluate the model on a speech coding task and demonstrate that the proposed Aligned Contrastive Predictive Coding (ACPC) leads to higher linear phone prediction accuracy and lower ABX error rates, while being slightly faster to train due to the reduced number of prediction heads.      
### 60.A Review on C3I Systems' Security: Vulnerabilities, Attacks, and Countermeasures  [ :arrow_down: ](https://arxiv.org/pdf/2104.11906.pdf)
>  Command, Control, Communication, and Intelligence (C3I) system is a kind of system-of-system that integrates computing machines, sensors, and communication networks. C3I systems are increasingly used in critical civil and military operations for achieving information superiority, assurance, and operational efficacy. C3I systems are no exception to the traditional systems facing widespread cyber-threats. However, the sensitive nature of the application domain (e.g., military operations) of C3I systems makes their security a critical concern. For instance, a cyber-attack on military installations can have detrimental impacts on national security. Therefore, in this paper, we review the state-of-the-art on the security of C3I systems. In particular, this paper aims to identify the security vulnerabilities, attack vectors, and countermeasures for C3I systems. We used the well-known systematic literature review method to select and review 77 studies on the security of C3I systems. Our review enabled us to identify 27 vulnerabilities, 22 attack vectors, and 62 countermeasures for C3I systems. This review has also revealed several areas for future research and identified key lessons with regards to C3I systems' security.      
### 61.A Survey of Modern Deep Learning based Object Detection Models  [ :arrow_down: ](https://arxiv.org/pdf/2104.11892.pdf)
>  Object Detection is the task of classification and localization of objects in an image or video. It has gained prominence in recent years due to its widespread applications. This article surveys recent developments in deep learning based object detectors. Concise overview of benchmark datasets and evaluation metrics used in detection is also provided along with some of the prominent backbone architectures used in recognition tasks. It also covers contemporary lightweight classification models used on edge devices. Lastly, we compare the performances of these architectures on multiple metrics.      
### 62.MILIOM: Tightly Coupled Multi-Input Lidar-Inertia Odometry and Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2104.11888.pdf)
>  In this paper we investigate a tightly coupled Lidar-Inertia Odometry and Mapping (LIOM) scheme, with the capability to incorporate multiple lidars with complementary field of view (FOV). In essence, we devise a time-synchronized scheme to combine extracted features from separate lidars into a single pointcloud, which is then used to construct a local map and compute the feature-map matching (FMM) coefficients. These coefficients, along with the IMU preinteration observations, are then used to construct a factor graph that will be optimized to produce an estimate of the sliding window trajectory. We also propose a key frame-based map management strategy to marginalize certain poses and pointclouds in the sliding window to grow a global map, which is used to assemble the local map in the later stage. The use of multiple lidars with complementary FOV and the global map ensures that our estimate has low drift and can sustain good localization in situations where single lidar use gives poor result, or even fails to work. Multi-thread computation implementations are also adopted to fractionally cut down the computation time and ensure real-time performance. We demonstrate the efficacy of our system via a series of experiments on public datasets collected from an aerial vehicle.      
### 63.Music Embedding: A Tool for Incorporating Music Theory into Computational Music Applications  [ :arrow_down: ](https://arxiv.org/pdf/2104.11880.pdf)
>  Advancements in the digital technologies have enabled researchers to develop a variety of Computational Music applications. Such applications are required to capture, process, and generate data related to music. Therefore, it is important to digitally represent music in a music theoretic and concise manner. Existing approaches for representing music are ineffective in terms of utilizing music theory. In this paper, we address the disjoint of music theory and computational music by developing an opensource representation tool based on music theory. Through the wide range of use cases, we run an analysis on the classical music pieces to show the usefulness of the developed music embedding.      
### 64.Suboptimal coverings for continuous spaces of control tasks  [ :arrow_down: ](https://arxiv.org/pdf/2104.11865.pdf)
>  We propose the {\alpha}-suboptimal covering number to characterize multi-task control problems where the set of dynamical systems and/or cost functions is infinite, analogous to the cardinality of finite task sets. This notion may help quantify the function class expressiveness needed to represent a good multi-task policy, which is important for learning-based control methods that use parameterized function approximation. We study suboptimal covering numbers for linear dynamical systems with quadratic cost (LQR problems) and construct a class of multi-task LQR problems amenable to analysis. For the scalar case, we show logarithmic dependence on the "breadth" of the space. For the matrix case, we present experiments 1) measuring the efficiency of a particular constructive cover, and 2) visualizing the behavior of two candidate systems for the lower bound.      
### 65.Do All MobileNets Quantize Poorly? Gaining Insights into the Effect of Quantization on Depthwise Separable Convolutional Networks Through the Eyes of Multi-scale Distributional Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2104.11849.pdf)
>  As the "Mobile AI" revolution continues to grow, so does the need to understand the behaviour of edge-deployed deep neural networks. In particular, MobileNets are the go-to family of deep convolutional neural networks (CNN) for mobile. However, they often have significant accuracy degradation under post-training quantization. While studies have introduced quantization-aware training and other methods to tackle this challenge, there is limited understanding into why MobileNets (and potentially depthwise-separable CNNs (DWSCNN) in general) quantize so poorly compared to other CNN architectures. Motivated to gain deeper insights into this phenomenon, we take a different strategy and study the multi-scale distributional dynamics of MobileNet-V1, a set of smaller DWSCNNs, and regular CNNs. Specifically, we investigate the impact of quantization on the weight and activation distributional dynamics as information propagates from layer to layer, as well as overall changes in distributional dynamics at the network level. This fine-grained analysis revealed significant dynamic range fluctuations and a "distributional mismatch" between channelwise and layerwise distributions in DWSCNNs that lead to increasing quantized degradation and distributional shift during information propagation. Furthermore, analysis of the activation quantization errors show that there is greater quantization error accumulation in DWSCNN compared to regular CNNs. The hope is that such insights can lead to innovative strategies for reducing such distributional dynamics changes and improve post-training quantization for mobile.      
### 66.Ensembles of GANs for synthetic training data generation  [ :arrow_down: ](https://arxiv.org/pdf/2104.11797.pdf)
>  Insufficient training data is a major bottleneck for most deep learning practices, not least in medical imaging where data is difficult to collect and publicly available datasets are scarce due to ethics and privacy. This work investigates the use of synthetic images, created by generative adversarial networks (GANs), as the only source of training data. We demonstrate that for this application, it is of great importance to make use of multiple GANs to improve the diversity of the generated data, i.e. to sufficiently cover the data distribution. While a single GAN can generate seemingly diverse image content, training on this data in most cases lead to severe over-fitting. We test the impact of ensembled GANs on synthetic 2D data as well as common image datasets (SVHN and CIFAR-10), and using both DCGANs and progressively growing GANs. As a specific use case, we focus on synthesizing digital pathology patches to provide anonymized training data.      

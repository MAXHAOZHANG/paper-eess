# ArXiv eess --Thu, 29 Apr 2021
### 1.LambdaUNet: 2.5D Stroke Lesion Segmentation of Diffusion-weighted MR Images  [ :arrow_down: ](https://arxiv.org/pdf/2104.13917.pdf)
>  Diffusion-weighted (DW) magnetic resonance imaging is essential for the diagnosis and treatment of ischemic stroke. DW images (DWIs) are usually acquired in multi-slice settings where lesion areas in two consecutive 2D slices are highly discontinuous due to large slice thickness and sometimes even slice gaps. Therefore, although DWIs contain rich 3D information, they cannot be treated as regular 3D or 2D images. Instead, DWIs are somewhere in-between (or 2.5D) due to the volumetric nature but inter-slice discontinuities. Thus, it is not ideal to apply most existing segmentation methods as they are designed for either 2D or 3D images. To tackle this problem, we propose a new neural network architecture tailored for segmenting highly-discontinuous 2.5D data such as DWIs. Our network, termed LambdaUNet, extends UNet by replacing convolutional layers with our proposed Lambda+ layers. In particular, Lambda+ layers transform both intra-slice and inter-slice context around a pixel into linear functions, called lambdas, which are then applied to the pixel to produce informative 2.5D features. LambdaUNet is simple yet effective in combining sparse inter-slice information from adjacent slices while also capturing dense contextual features within a single slice. Experiments on a unique clinical dataset demonstrate that LambdaUNet outperforms existing 3D/2D image segmentation methods including recent variants of UNet. Code for LambdaUNet will be released with the publication to facilitate future research.      
### 2.A Verifiable Framework for Cyber-Physical Attacks and Countermeasures in a Resilient Electric Power Grid  [ :arrow_down: ](https://arxiv.org/pdf/2104.13908.pdf)
>  In this paper, we investigate the feasibility and physical consequences of cyber attacks against energy management systems (EMS). Within this framework, we have designed a complete simulation platform to emulate realistic EMS operations: it includes state estimation (SE), real-time contingency analysis (RTCA), and security constrained economic dispatch (SCED). This software platform allowed us to achieve two main objectives: 1) to study the cyber vulnerabilities of an EMS and understand their consequences on the system, and 2) to formulate and implement countermeasures against cyber-attacks exploiting these vulnerabilities. Our results show that the false data injection attacks against state estimation described in the literature do not easily cause base-case overflows because of the conservatism introduced by RTCA. For a successful attack, a more sophisticated model that includes all of the EMS blocks is needed; even in this scenario, only post-contingency violations can be achieved. Nonetheless, we propose several countermeasures that can detect changes due to cyber-attacks and limit their impact on the system.      
### 3.Data-Driven Reachability Analysis with Christoffel Functions  [ :arrow_down: ](https://arxiv.org/pdf/2104.13902.pdf)
>  We present an algorithm for data-driven reachability analysis that estimates finite-horizon forward reachable sets for general nonlinear systems using level sets of a certain class of polynomials known as Christoffel functions. The level sets of Christoffel functions are known empirically to provide good approximations to the support of probability distributions: the algorithm uses this property for reachability analysis by solving a probabilistic relaxation of the reachable set computation problem. We also provide a guarantee that the output of the algorithm is an accurate reachable set approximation in a probabilistic sense, provided that a certain sample size is attained. We also investigate three numerical examples to demonstrate the algorithm's capabilities, such as providing non-convex reachable set approximations and detecting holes in the reachable set.      
### 4.Closed-loop Control Design and Motor Allocation for a Lower-limb Cable-driven Exoskeleton: A Switched Systems Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.13895.pdf)
>  Powered lower-limb exoskeletons provide assistive torques to coordinate limb motion during walking in individuals with movement disorders. Advances in sensing and actuation have improved the wearability and portability of state-of-the-art exoskeletons for walking. Cable-driven exoskeletons offload the actuators away from the user, thus rendering light-weight devices to facilitate locomotion training. However, cable-driven mechanisms experience a slacking behavior if tension is not accurately controlled. Moreover, counteracting forces can arise between the agonist and antagonist motors yielding undesired joint motion. In this paper, the strategy is to develop two control layers to improve the performance of a cable-driven exoskeleton. First, a joint tracking controller is designed using a high-gain robust approach to track desired knee and hip trajectories. Second, a motor synchronization objective is developed to mitigate the effects of cable slacking for a pair of electric motors that actuate each joint. A sliding-mode robust controller is designed for the motor synchronization objective. A Lyapunov-based stability analysis is developed to guarantee a uniformly ultimately bounded result for joint tracking and exponential tracking for the motor synchronization objective. Moreover, an average dwell time analysis provides a bound on the number of motor switches when allocating the control between motors that actuate each joint. An experimental result with an able-bodied individual illustrates the feasibility of the developed control methods.      
### 5.Weighed $\ell_1$ on the simplex: Compressive sensing meets locality  [ :arrow_down: ](https://arxiv.org/pdf/2104.13894.pdf)
>  Sparse manifold learning algorithms combine techniques in manifold learning and sparse optimization to learn features that could be utilized for downstream tasks. The standard setting of compressive sensing can not be immediately applied to this setup. Due to the intrinsic geometric structure of data, dictionary atoms might be redundant and do not satisfy the restricted isometry property or coherence condition. In addition, manifold learning emphasizes learning local geometry which is not reflected in a standard $\ell_1$ minimization problem. We propose weighted $\ell_0$ and weighted $\ell_1$ metrics that encourage representation via neighborhood atoms suited for dictionary based manifold learning. Assuming that the data is generated from Delaunay triangulation, we show the equivalence of weighted $\ell_1$ and weighted $\ell_0$. We discuss an optimization program that learns the dictionaries and sparse coefficients and demonstrate the utility of our regularization on synthetic and real datasets.      
### 6.Communication Topology Co-Design in Graph Recurrent Neural Network Based Distributed Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.13868.pdf)
>  When designing large-scale distributed controllers, the information-sharing constraints between sub-controllers, as defined by a communication topology interconnecting them, are as important as the controller itself. Controllers implemented using dense topologies typically outperform those implemented using sparse topologies, but it is also desirable to minimize the cost of controller deployment. Motivated by the above, we introduce a compact but expressive graph recurrent neural network (GRNN) parameterization of distributed controllers that is well suited for distributed controller and communication topology co-design. Our proposed parameterization enjoys a local and distributed architecture, similar to previous Graph Neural Network (GNN)-based parameterizations, while further naturally allowing for joint optimization of the distributed controller and communication topology needed to implement it. We show that the distributed controller/communication topology co-design task can be posed as an $\ell_1$-regularized empirical risk minimization problem that can be efficiently solved using stochastic gradient methods. We run extensive simulations to study the performance of GRNN-based distributed controllers and show that (a) they achieve performance comparable to GNN-based controllers while having fewer free parameters, and (b) our method allows for performance/communication density tradeoff curves to be efficiently approximated.      
### 7.Deep Learning Body Region Classification of MRI and CT examinations  [ :arrow_down: ](https://arxiv.org/pdf/2104.13826.pdf)
>  Standardized body region labelling of individual images provides data that can improve human and computer use of medical images. A CNN-based classifier was developed to identify body regions in CT and MRI. 17 CT (18 MRI) body regions covering the entire human body were defined for the classification task. Three retrospective databases were built for the AI model training, validation, and testing, with a balanced distribution of studies per body region. The test databases originated from a different healthcare network. Accuracy, recall and precision of the classifier was evaluated for patient age, patient gender, institution, scanner manufacturer, contrast, slice thickness, MRI sequence, and CT kernel. The data included a retrospective cohort of 2,934 anonymized CT cases (training: 1,804 studies, validation: 602 studies, test: 528 studies) and 3,185 anonymized MRI cases (training: 1,911 studies, validation: 636 studies, test: 638 studies). 27 institutions from primary care hospitals, community hospitals and imaging centers contributed to the test datasets. The data included cases of all genders in equal proportions and subjects aged from a few months old to +90 years old. An image-level prediction accuracy of 91.9% (90.2 - 92.1) for CT, and 94.2% (92.0 - 95.6) for MRI was achieved. The classification results were robust across all body regions and confounding factors. Due to limited data, performance results for subjects under 10 years-old could not be reliably evaluated. We show that deep learning models can classify CT and MRI images by body region including lower and upper extremities with high accuracy.      
### 8.Recent Advances on Non-Line-of-Sight Imaging: Conventional Physical Models, Deep Learning, and New Scenes  [ :arrow_down: ](https://arxiv.org/pdf/2104.13807.pdf)
>  As an emerging technology that has attracted huge attention, non-line-of-sight (NLOS) imaging can reconstruct hidden objects by analyzing the diffuse reflection on a relay surface, with broad application prospects in the fields of autonomous driving, medical imaging, and defense. Despite the challenges of low signal-to-noise ratio (SNR) and high ill-posedness, NLOS imaging has been developed rapidly in recent years. Most current NLOS imaging technologies use conventional physical models, constructing imaging models through active or passive illumination and using reconstruction algorithms to restore hidden scenes. Moreover, deep learning algorithms for NLOS imaging have also received much attention recently. This paper presents a comprehensive overview of both conventional and deep learning-based NLOS imaging techniques. Besides, we also survey new proposed NLOS scenes, and discuss the challenges and prospects of existing technologies. Such a survey can help readers have an overview of different types of NLOS imaging, thus expediting the development of seeing around corners.      
### 9.Image Synthesis as a Pretext for Unsupervised Histopathological Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2104.13797.pdf)
>  Anomaly detection in visual data refers to the problem of differentiating abnormal appearances from normal cases. Supervised approaches have been successfully applied to different domains, but require an abundance of labeled data. Due to the nature of how anomalies occur and their underlying generating processes, it is hard to characterize and label them. Recent advances in deep generative-based models have sparked interest in applying such methods for unsupervised anomaly detection and have shown promising results in medical and industrial inspection domains. In this work we evaluate a crucial part of the unsupervised visual anomaly detection pipeline, that is needed for normal appearance modeling, as well as the ability to reconstruct closest looking normal and tumor samples. We adapt and evaluate different high-resolution state-of-the-art generative models from the face synthesis domain and demonstrate their superiority over currently used approaches on a challenging domain of digital pathology. Multifold improvement in image synthesis is demonstrated in terms of the quality and resolution of the generated images, validated also against the supervised model.      
### 10.Unsupervised Detection of Cancerous Regions in Histology Imagery using Image-to-Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2104.13786.pdf)
>  Detection of visual anomalies refers to the problem of finding patterns in different imaging data that do not conform to the expected visual appearance and is a widely studied problem in different domains. Due to the nature of anomaly occurrences and underlying generating processes, it is hard to characterize them and obtain labeled data. Obtaining labeled data is especially difficult in biomedical applications, where only trained domain experts can provide labels, which often come in large diversity and complexity. Recently presented approaches for unsupervised detection of visual anomalies approaches omit the need for labeled data and demonstrate promising results in domains, where anomalous samples significantly deviate from the normal appearance. Despite promising results, the performance of such approaches still lags behind supervised approaches and does not provide a one-fits-all solution. In this work, we present an image-to-image translation-based framework that significantly surpasses the performance of existing unsupervised methods and approaches the performance of supervised methods in a challenging domain of cancerous region detection in histology imagery.      
### 11.Optimal Cooperative Driving at Signal-Free Intersections with Polynomial-Time Complexity  [ :arrow_down: ](https://arxiv.org/pdf/2104.13721.pdf)
>  Cooperative driving at signal-free intersections, which aims to improve driving safety and efficiency for connected and automated vehicles, has attracted increasing interest in recent years. However, existing cooperative driving strategies either suffer from computational complexity or cannot guarantee global optimality. To fill this research gap, this paper proposes an optimal and computationally efficient cooperative driving strategy with the polynomial-time complexity. By modeling the conflict relations among the vehicles, the solution space of the cooperative driving problem is completely represented by a newly designed small-size state space. Then, based on dynamic programming, the globally optimal solution can be searched inside the state space efficiently. It is proved that the proposed strategy can reduce the time complexity of computation from exponential to a small-degree polynomial. Simulation results further demonstrate that the proposed strategy can obtain the globally optimal solution within a limited computation time under various traffic demand settings.      
### 12.Graph topology inference with derivative-reproducing property in RKHS: algorithm and convergence analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.13687.pdf)
>  In many areas such as computational biology, finance or social sciences, knowledge of an underlying graph explaining the interactions between agents is of paramount importance but still challenging. Considering that these interactions may be based on nonlinear relationships adds further complexity to the topology inference problem. Among the latest methods that respond to this need is a topology inference one proposed by the authors, which estimates a possibly directed adjacency matrix in an online manner. Contrasting with previous approaches based on linear models, the considered model is able to explain nonlinear interactions between the agents in a network. The novelty in the considered method is the use of a derivative-reproducing property to enforce network sparsity, while reproducing kernels are used to model the nonlinear interactions. The aim of this paper is to present a thorough convergence analysis of this method. The analysis is proven to be sane both in the mean and mean square sense. In addition, stability conditions are devised to ensure the convergence of the analyzed method.      
### 13.Multiple Antenna Selection and Successive Signal Detection for SM-based IRS-aided Communication  [ :arrow_down: ](https://arxiv.org/pdf/2104.13686.pdf)
>  Intelligent reflecting surface (IRS) is being considered as a prospective candidate for next-generation wireless communication due to its ability to significantly improve coverage and spectral efficiency by controlling the propagation environment. One of the ways IRS increases spectral efficiency is by adjusting phase shifts to perform passive beamforming. In this letter, we integrate the concept of IRS-aided communication to the domain of multi-direction beamforming, whereby multiple receive antennas are selected to convey more information bits than existing spatial modulation (SM) techniques at any specific time. To complement this system, we also propose a successive signal detection (SSD) technique at the receiver. Numerical results show that the proposed design is able to improve the average successful bits transmitted (ASBT) by the system, which outperforms other state-of-the-art methods proposed in the literature.      
### 14.Adaptive Channel Estimation Based on Model-Driven Deep Learning for Wideband mmWave Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.13656.pdf)
>  Channel estimation in wideband millimeter-wave (mmWave) systems is very challenging due to the beam squint effect. To solve the problem, we propose a learnable iterative shrinkage thresholding algorithm-based channel estimator (LISTA-CE) based on deep learning. The proposed channel estimator can learn to transform the beam-frequency mmWave channel into the domain with sparse features through training data. The transform domain enables us to adopt a simple denoiser with few trainable parameters. We further enhance the adaptivity of the estimator by introducing \emph{hypernetwork} to automatically generate learnable parameters for LISTA-CE online. Simulation results show that the proposed approach can significantly outperform the state-of-the-art deep learning-based algorithms with lower complexity and fewer parameters and adapt to new scenarios rapidly.      
### 15.Packet-Loss-Tolerant Split Inference for Delay-Sensitive Deep Learning in Lossy Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.13629.pdf)
>  The distributed inference framework is an emerging technology for real-time applications empowered by cutting-edge deep machine learning (ML) on resource-constrained Internet of things (IoT) devices. In distributed inference, computational tasks are offloaded from the IoT device to other devices or the edge server via lossy IoT networks. However, narrow-band and lossy IoT networks cause non-negligible packet losses and retransmissions, resulting in non-negligible communication latency. This study solves the problem of the incremental retransmission latency caused by packet loss in a lossy IoT network. We propose a split inference with no retransmissions (SI-NR) method that achieves high accuracy without any retransmissions, even when packet loss occurs. In SI-NR, the key idea is to train the ML model by emulating the packet loss by a dropout method, which randomly drops the output of hidden units in a DNN layer. This enables the SI-NR system to obtain robustness against packet losses. Our ML experimental evaluation reveals that SI-NR obtains accurate predictions without packet retransmission at a packet loss rate of 60%.      
### 16.IDMT-Traffic: An Open Benchmark Dataset for Acoustic Traffic Monitoring Research  [ :arrow_down: ](https://arxiv.org/pdf/2104.13620.pdf)
>  In many urban areas, traffic load and noise pollution are constantly increasing. Automated systems for traffic monitoring are promising countermeasures, which allow to systematically quantify and predict local traffic flow in order to to support municipal traffic planning decisions. In this paper, we present a novel open benchmark dataset, containing 2.5 hours of stereo audio recordings of 4718 vehicle passing events captured with both high-quality sE8 and medium-quality MEMS microphones. This dataset is well suited to evaluate the use-case of deploying audio classification algorithms to embedded sensor devices with restricted microphone quality and hardware processing power. In addition, this paper provides a detailed review of recent acoustic traffic monitoring (ATM) algorithms as well as the results of two benchmark experiments on vehicle type classification and direction of movement estimation using four state-of-the-art convolutional neural network architectures.      
### 17.Multi-scale Deep Learning Architecture for Nucleus Detection in Renal Cell Carcinoma Microscopy Image  [ :arrow_down: ](https://arxiv.org/pdf/2104.13557.pdf)
>  Clear cell renal cell carcinoma (ccRCC) is one of the most common forms of intratumoral heterogeneity in the study of renal cancer. ccRCC originates from the epithelial lining of proximal convoluted renal tubules. These cells undergo abnormal mutations in the presence of Ki67 protein and create a lump-like structure through cell proliferation. Manual counting of tumor cells in the tissue-affected sections is one of the strongest prognostic markers for renal cancer. However, this procedure is time-consuming and also prone to subjectivity. These assessments are based on the physical cell appearance and suffer wide intra-observer variations. Therefore, better cell nucleus detection and counting techniques can be an important biomarker for the assessment of tumor cell proliferation in routine pathological investigations. In this paper, we introduce a deep learning-based detection model for cell classification on IHC stained histology images. These images are classified into binary classes to find the presence of Ki67 protein in cancer-affected nucleus regions. Our model maps the multi-scale pyramid features and saliency information from local bounded regions and predicts the bounding box coordinates through regression. Our method validates the impact of Ki67 expression across a cohort of four hundred histology images treated with localized ccRCC and compares our results with the existing state-of-the-art nucleus detection methods. The precision and recall scores of the proposed method are computed and compared on the clinical data sets. The experimental results demonstrate that our model improves the F1 score up to 86.3% and an average area under the Precision-Recall curve as 85.73%.      
### 18.AMSS-Net: Audio Manipulation on User-Specified Sources with Textual Queries  [ :arrow_down: ](https://arxiv.org/pdf/2104.13553.pdf)
>  This paper proposes a neural network that performs audio transformations to user-specified sources (e.g., vocals) of a given audio track according to a given description while preserving other sources not mentioned in the description. Audio Manipulation on a Specific Source (AMSS) is challenging because a sound object (i.e., a waveform sample or frequency bin) is `transparent'; it usually carries information from multiple sources, in contrast to a pixel in an image. To address this challenging problem, we propose AMSS-Net, which extracts latent sources and selectively manipulates them while preserving irrelevant sources. We also propose an evaluation benchmark for several AMSS tasks, and we show that AMSS-Net outperforms baselines on several AMSS tasks via objective metrics and empirical verification.      
### 19.Deep Two-Stage High-Resolution Image Inpainting  [ :arrow_down: ](https://arxiv.org/pdf/2104.13464.pdf)
>  In recent years, the field of image inpainting has developed rapidly, learning based approaches show impressive results in the task of filling missing parts in an image. But most deep methods are strongly tied to the resolution of the images on which they were trained. A slight resolution increase leads to serious artifacts and unsatisfactory filling quality. These methods are therefore unsuitable for interactive image processing. In this article, we propose a method that solves the problem of inpainting arbitrary-size images. We also describe a way to better restore texture fragments in the filled area. For this, we propose to use information from neighboring pixels by shifting the original image in four directions. Moreover, this approach can work with existing inpainting models, making them almost resolution independent without the need for retraining. We also created a GIMP plugin that implements our technique. The plugin, code, and model weights are available at <a class="link-external link-https" href="https://github.com/a-mos/High_Resolution_Image_Inpainting" rel="external noopener nofollow">this https URL</a>.      
### 20.Boundary controlled irreversible port-Hamiltonian systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.13459.pdf)
>  Boundary controlled irreversible port-Hamiltonian systems (BC-IPHS) on 1-dimensional spatial domains are defined by extending the formulation of reversible BC-PHS to irreversible thermodynamic systems controlled at the boundaries of their spatial domains. The structure of BC-IPHS has clear physical interpretation, characterizing the coupling between energy storing and energy dissipating elements. By extending the definition of boundary port variables of BC-PHS to deal with the dissipative terms, a set of boundary port variables are defined such that BC-IPHS are passive with respect to a given set of conjugated inputs and outputs. As for finite dimensional IPHS, the first and second principle are satisfied as a structural property. Several examples are given to illustrate the proposed approach.      
### 21.Mitigation of Saturated Cut-sets During Multiple Outages to Enhance Power System Security  [ :arrow_down: ](https://arxiv.org/pdf/2104.13445.pdf)
>  Ensuring reliable operation of large power systems subjected to multiple outages is a challenging task because of the combinatorial nature of the problem. Traditional approaches for security assessment are often limited by their scope and/or speed, resulting in missing of critical contingencies that could lead to cascading failures. This paper proposes a two-component methodology to enhance power system security. The first component combines an efficient algorithm to detect cut-set saturation (called the feasibility test (FT) algorithm) with real-time contingency analysis (RTCA) to create an integrated corrective action (iCA), whose goal is to secure the system against cut-set saturation as well as critical branch overloads. The second component only employs the results of the FT to create a relaxed corrective action (rCA) to secure the system against post-contingency cut-set saturation. The first component is more comprehensive, but the latter is computationally more efficient. The effectiveness of the two components is evaluated based upon the number of cascade triggering contingencies alleviated, and the computation time. The results obtained by analyzing different case-studies on the IEEE 118-bus and 2000-bus synthetic Texas systems indicate that the proposed two-component methodology successfully enhances the scope and speed of power system security assessment during multiple outages.      
### 22.DASEE A Synthetic Database of Domestic Acoustic Scenes and Events in Dementia Patients Environment  [ :arrow_down: ](https://arxiv.org/pdf/2104.13423.pdf)
>  Access to informative databases is a crucial part of notable research developments. In the field of domestic audio classification, there have been significant advances in recent years. Although several audio databases exist, these can be limited in terms of the amount of information they provide, such as the exact location of the sound sources, and the associated noise levels. In this work, we detail our approach on generating an unbiased synthetic domestic audio database, consisting of sound scenes and events, emulated in both quiet and noisy environments. Data is carefully curated such that it reflects issues commonly faced in a dementia patients environment, and recreate scenarios that could occur in real-world settings. Similarly, the room impulse response generated is based on a typical one-bedroom apartment at Hebrew SeniorLife Facility. As a result, we present an 11-class database containing excerpts of clean and noisy signals at 5-seconds duration each, uniformly sampled at 16 kHz. Using our baseline model using Continues Wavelet Transform Scalograms and AlexNet, this yielded a weighted F1-score of 86.24 percent.      
### 23.Symbolic Abstractions From Data: A PAC Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.13901.pdf)
>  Symbolic control techniques aim to satisfy complex logic specifications. A critical step in these techniques is the construction of a symbolic (discrete) abstraction, a finite-state system whose behaviour mimics that of a given continuous-state system. The methods used to compute symbolic abstractions, however, require knowledge of an accurate closed-form model. To generalize them to systems with unknown dynamics, we present a new data-driven approach that does not require closed-form dynamics, instead relying only the ability to evaluate successors of each state under given inputs. To provide guarantees for the learned abstraction, we use the Probably Approximately Correct (PAC) statistical framework. We first introduce a PAC-style behavioural relationship and an appropriate refinement procedure. We then show how the symbolic abstraction can be constructed to satisfy this new behavioural relationship. Moreover, we provide PAC bounds that dictate the number of data required to guarantee a prescribed level of accuracy and confidence. Finally, we present an illustrative example.      
### 24.Evaluating the Performance of Over-the-Air Time Synchronization for 5G and TSN Integration  [ :arrow_down: ](https://arxiv.org/pdf/2104.13873.pdf)
>  The IEEE 802.1 time-sensitive networking (TSN) standards aim at improving the real-time capabilities of standard Ethernet. TSN is widely recognized as the long-term replacement of proprietary technologies for industrial control systems. However, wired connectivity alone is not sufficient to meet the requirements of future industrial systems. The fifth-generation (5G) mobile/cellular technology has been designed with native support for ultra-reliable low-latency communication (uRLLC). 5G is promising to meet the stringent requirements of industrial systems in the wireless domain. Converged operation of 5G and TSN systems is crucial for achieving end-to-end deterministic connectivity in industrial networks. Accurate time synchronization is key to integrated operation of 5G and TSN systems. To this end, this paper evaluates the performance of over-the-air time synchronization mechanism which has been proposed in 3GPP Release 16. We analyze the accuracy of time synchronization through the boundary clock approach in the presence of clock drift and different air-interface timing errors related to reference time indication. We also investigate frequency and scalability aspects of over-the-air time synchronization. Our performance evaluation reveals the conditions under which 1 \(\mu\)s or below requirement for TSN time synchronization can be achieved.      
### 25.Learning deep autoregressive models for hierarchical data  [ :arrow_down: ](https://arxiv.org/pdf/2104.13853.pdf)
>  We propose a model for hierarchical structured data as an extension to the stochastic temporal convolutional network (STCN). The proposed model combines an autoregressive model with a hierarchical variational autoencoder and downsampling to achieve superior computational complexity. We evaluate the proposed model on two different types of sequential data: speech and handwritten text. The results are promising with the proposed model achieving state-of-the-art performance.      
### 26.Structural averaged controllability of linear ensemble systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.13839.pdf)
>  In the paper, we introduce and address the problem of structural averaged controllability for linear ensemble systems. We provide examples highlighting the differences between this problem and others. In particular, we show that structural averaged controllability is strictly weaker than structural controllability for single (or ensembles of) linear systems. We establish a set of necessary or sufficient conditions for sparsity patterns to be structurally averaged controllable.      
### 27.CLPVG: Circular limited penetrable visibility graph as a new network model for time series  [ :arrow_down: ](https://arxiv.org/pdf/2104.13772.pdf)
>  Visibility Graph (VG) transforms time series into graphs, facilitating signal processing by advanced graph data mining algorithms. In this paper, based on the classic Limited Penetrable Visibility Graph (LPVG) method, we propose a novel nonlinear mapping method named Circular Limited Penetrable Visibility Graph (CLPVG). The testing on degree distribution and clustering coefficient on the generated graphs of typical time series validates that our CLPVG is able to effectively capture the important features of time series and has better anti-noise ability than traditional LPVG. The experiments on real-world time-series datasets of radio signal and electroencephalogram (EEG) also suggest that the structural features provided by CLPVG, rather than LPVG, are more useful for time-series classification, leading to higher accuracy. And this classification performance can be further enhanced through structural feature expansion by adopting Subgraph Networks (SGN). All of these results validate the effectiveness of our CLPVG model.      
### 28.A Functional Safety Assessment Method for Cooperative Automotive Architecture  [ :arrow_down: ](https://arxiv.org/pdf/2104.13729.pdf)
>  The scope of automotive functions has grown from a single-vehicle as an entity to multiple vehicles working together as an entity, referred to as cooperative driving. The current automotive safety standard, ISO 26262, is designed for single vehicles. With the increasing number of cooperative driving capable vehicles on the road, it is now imperative to systematically assess the functional safety of architectures of these vehicles. Many methods are proposed to assess architectures with respect to different quality attributes in the software architecture domain, but to the best of our knowledge, functional safety assessment of automotive architectures is not explored in the literature. We present a method, that leverages existing research in software architecture and safety engineering domains, to check whether the functional safety requirements for a cooperative driving scenario are fulfilled in the technical architecture of a vehicle. We apply our method on a real-life academic prototype for a cooperative driving scenario, platooning, and discuss our insights.      
### 29.Low-Complexity Distance-Based Scheduling for Multi-User XL-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.13690.pdf)
>  We introduce DBS, a new technique for user selection in downlink multi-user communications with extra-large (XL) antenna arrays. DBS categorizes users according to their equivalent distance to the antenna array. Such categorization effectively accounts for inter-user interference while largely reducing the computational burden. Results show that (i) DBS achieves the same performance as the reference zero-forcing beamforming scheme with a lower complexity; (ii) a simplified version of DBS achieves a similar performance when realistic spherical-wavefront (SW) propagation features are considered; (iii) SW propagation brings additional degrees of freedom, which allows for increasing the number of served users.      
### 30.A Survey on User-Centric Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.13667.pdf)
>  The mobile data traffic has been exponentially growing during the last decades, which has been enabled by the densification of the network infrastructure, in terms of increased cell density (i.e., ultra-dense network (UDN)) and/or increased number of active antennas per access point (AP) (i.e., massive multiple-input multiple-output (mMIMO)). However, neither UDN nor mMIMO will meet the increasing data rate demands of the sixth generation (6G) wireless communications due to the inter-cell interference and large quality-of-service variations, respectively. Cell-free (CF) mMIMO, which combines the best aspects of UDN with mMIMO, is viewed as a key solution to this issue. In such systems, each user equipment (UE) is served by a preferred set of surrounding APs that cooperate to serve the UE in a CF approach. In this paper, we provide a survey of the state-of-the-art literature on CF mMIMO systems. As a starting point, we present the significance and challenges of improving the user-experienced data rates which motivate CF mMIMO, derive the basic properties of CF mMIMO, and provide an introduction to other technologies related to CF mMIMO. We then provide the canonical framework for CF mMIMO, where the essential details (i.e., transmission procedure and mathematical system model) are discussed. Next, we provide a deep look at the resource allocation and signal processing problems related to CF mMIMO and survey the state-of-the-art schemes and algorithms. After that, we discuss the practical issues when implementing CF mMIMO, including fronthaul limitations and hardware impairment. Potential future directions of CF mMIMO research are then highlighted. We conclude this paper with a summary of the key lessons learned in this field. The objective of this paper is to provide a starting point for anyone who wants to conduct research on CF mMIMO for future wireless networks.      
### 31.End-to-End Approach for Recognition of Historical Digit Strings  [ :arrow_down: ](https://arxiv.org/pdf/2104.13666.pdf)
>  The plethora of digitalised historical document datasets released in recent years has rekindled interest in advancing the field of handwriting pattern recognition. In the same vein, a recently published data set, known as ARDIS, presents handwritten digits manually cropped from 15.000 scanned documents of Swedish church books and exhibiting various handwriting styles. To this end, we propose an end-to-end segmentation-free deep learning approach to handle this challenging ancient handwriting style of dates present in the ARDIS dataset (4-digits long strings). We show that with slight modifications in the VGG-16 deep model, the framework can achieve a recognition rate of 93.2%, resulting in a feasible solution free of heuristic methods, segmentation, and fusion methods. Moreover, the proposed approach outperforms the well-known CRNN method (a model widely applied in handwriting recognition tasks).      
### 32.A Perceptual Model for Eccentricity-dependent Spatio-temporal Flicker Fusion and its Applications to Foveated Graphics  [ :arrow_down: ](https://arxiv.org/pdf/2104.13514.pdf)
>  Virtual and augmented reality (VR/AR) displays strive to provide a resolution, framerate and field of view that matches the perceptual capabilities of the human visual system, all while constrained by limited compute budgets and transmission bandwidths of wearable computing systems. Foveated graphics techniques have emerged that could achieve these goals by exploiting the falloff of spatial acuity in the periphery of the visual field. However, considerably less attention has been given to temporal aspects of human vision, which also vary across the retina. This is in part due to the lack of a unified eccentricity-dependent spatio-temporal model of the visual system. Here, we introduce the first such model, experimentally measuring and computationally fitting a model of critical flicker fusion. In this way, our model is unique in enabling the prediction of temporal information that is imperceptible for a certain spatial frequency, eccentricity, and range of luminance levels. We validate our model with an image quality user study, and use it to predict potential bandwidth savings 7x higher than those afforded by current spatial-only foveated models. As such, this work forms the enabling foundation for new temporally foveated graphics techniques.      
### 33.A macro-micro approach to modeling parking  [ :arrow_down: ](https://arxiv.org/pdf/2104.13509.pdf)
>  In this paper, we propose a new macro-micro approach to modeling parking. We first develop a microscopic parking simulation model considering both on- and off-street parking with limited capacity. In the microscopic model, a parking search algorithm is proposed to mimic cruising-for-parking based on the principle of proximity, and a parking-related state tracking algorithm is proposed to acquire an event-based simulated data set. Some key aspects of parking modeling are discussed based on the sim-ulated evidence and theoretical analysis. Results suggest (i) although the low cruising speed reduces the network performance, it does not significantly alter the macroscopic or network fundamental diagram (MFD or NFD) unless the cruising vehicles dominate the traffic stream; (ii) distance to park is not uniquely determined by parking occupancy because factors such as cruising speed and parking dura-tion also contribute; and (iii) multiscale parking occupancy-driven intelligent parking guidance can re-duce distance to park yielding considerable network efficiency gains. Using the microscopic model, we then extend, calibrate, and validate a macroscopic parking dynamics model with an NFD representation. The demonstrated consistency between the macro- and micro-models permits integration of the two for online parking pricing optimization via model predictive control. Numerical experiments highlight the effectiveness of the proposed approach as well as one caveat. That is, when pricing on-street parking, the road network connected to the alternate off-street parking lots must have sufficient capacity to ac-commodate the increased parking demand; otherwise, local congestion may arise that violates the ho-mogeneity assumption underlying the macroscopic model.      
### 34.General Scenario Program: Application in Smart Grid Optimization under Endogenous Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2104.13494.pdf)
>  This paper generalized the theory of scenario programming (SP) deeming that, as a direct data-driven optimization paradigm, the SP is an ideal solution to decision-making under uncertainty in the era of data. First, a general SP (GSP) problem under both exogenous and endogenous uncertainty is defined and its mathematical formulation in the form of nonlinear program is developed. Then, some key aspects of the GSP theory are discussed, which include its relation with the existing logic models of optimization under uncertainty, a confidence theorem under random sampling, and a new direction of high-performance solution methods based on strategic sampling. Finally, the proposed methods are preliminarily applied to a smartgrid optimization problem under endogenous uncertainty.      
### 35.A ridesharing simulation platform that considers dynamic supply-demand interactions  [ :arrow_down: ](https://arxiv.org/pdf/2104.13463.pdf)
>  This paper presents a new ridesharing simulation platform that accounts for dynamic driver supply and passenger demand, and complex interactions between drivers and passengers. The proposed simulation platform explicitly considers driver and passenger acceptance/rejection on the matching options, and cancellation before/after being matched. New simulation events, procedures and modules have been developed to handle these realistic interactions. The capabilities of the simulation platform are illustrated using numerical experiments. The experiments confirm the importance of considering supply and demand interactions and provide new insights to ridesharing operations. Results show that increase of driver supply does not always increase matching option accept rate, and larger matching window could have negative impacts on overall ridesharing success rate. These results emphasize the importance of a careful planning of a ridesharing system.      
### 36.Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings  [ :arrow_down: ](https://arxiv.org/pdf/2104.13450.pdf)
>  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. Retrieving messages from 2D renderings of such meshes, however, is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From extensive experiments, we show that our models learn to embed information visually imperceptible to humans, and to reconstruct the embedded information from 2D renderings robust to 3D distortions. In addition, we demonstrate that our method can be generalized to work with different renderers, such as ray tracers and real-time renderers.      

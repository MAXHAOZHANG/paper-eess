# ArXiv eess --Fri, 2 Apr 2021
### 1.Deep Multi-Resolution Dictionary Learning for Histopathology Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2104.00669.pdf)
>  The problem of recognizing various types of tissues present in multi-gigapixel histology images is an important fundamental pre-requisite for downstream analysis of the tumor microenvironment in a bottom-up analysis paradigm for computational pathology. In this paper, we propose a deep dictionary learning approach to solve the problem of tissue phenotyping in histology images. We propose deep Multi-Resolution Dictionary Learning (deepMRDL) in order to benefit from deep texture descriptors at multiple different spatial resolutions. We show the efficacy of the proposed approach through extensive experiments on four benchmark histology image datasets from different organs (colorectal cancer, breast cancer and breast lymphnodes) and tasks (namely, cancer grading, tissue phenotyping, tumor detection and tissue type classification). We also show that the proposed framework can employ most off-the-shelf CNNs models to generate effective deep texture descriptors.      
### 2.Distributed Video Adaptive Block Compressive Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2104.00636.pdf)
>  Video block compressive sensing has been studied for use in resource constrained scenarios, such as wireless sensor networks, but the approach still suffers from low performance and long reconstruction time. Inspired by classical distributed video coding, we design a lightweight encoder with computationally intensive operations, such as video frame interpolation, performed at the decoder. Straying from recent trends in training end-to-end neural networks, we propose two algorithms that leverage convolutional neural network components to reconstruct video with greatly reduced reconstruction time. At the encoder, we leverage temporal correlation between frames and deploy adaptive techniques based on compressive measurements from previous frames. At the decoder, we exploit temporal correlation by using video frame interpolation and temporal differential pulse code modulation. Simulations show that our two proposed algorithms, VAL-VFI and VAL-IDA-VFI reconstruct higher quality video, achieving state-of-the-art performance.      
### 3.Multi-layered simulation relations for linear stochastic systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.00625.pdf)
>  The design of provably correct controllers for continuous-state stochastic systems crucially depends on approximate finite-state abstractions and their accuracy quantification. For this quantification, one generally uses approximate stochastic simulation relations, whose constant precision limits the achievable guarantees on the control design. This limitation especially affects higher dimensional stochastic systems and complex formal specifications. This work allows for variable precision by defining a simulation relation that contains multiple precision layers. For bi-layered simulation relations, we develop a robust dynamic programming approach yielding a lower bound on the satisfaction probability of temporal logic specifications. We illustrate the benefit of bi-layered simulation relations for linear stochastic systems in an example.      
### 4.Fast DCTTS: Efficient Deep Convolutional Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2104.00624.pdf)
>  We propose an end-to-end speech synthesizer, Fast DCTTS, that synthesizes speech in real time on a single CPU thread. The proposed model is composed of a carefully-tuned lightweight network designed by applying multiple network reduction and fidelity improvement techniques. In addition, we propose a novel group highway activation that can compromise between computational efficiency and the regularization effect of the gating mechanism. As well, we introduce a new metric called Elastic mel-cepstral distortion (EMCD) to measure the fidelity of the output mel-spectrogram. In experiments, we analyze the effect of the acceleration techniques on speed and speech quality. Compared with the baseline model, the proposed model exhibits improved MOS from 2.62 to 2.74 with only 1.76% computation and 2.75% parameters. The speed on a single CPU thread was improved by 7.45 times, which is fast enough to produce mel-spectrogram in real time without GPU.      
### 5.Dispersion from Diffuse Reflectors and its Effect of Terahertz Wireless Communication Performance  [ :arrow_down: ](https://arxiv.org/pdf/2104.00621.pdf)
>  This work investigates the temporal dispersion of a wireless terahertz communication signal caused by reflection from a rough (diffuse) surface, and its subsequent impact on symbol error rate versus data rate. Broadband measurements of diffuse reflectors using terahertz time-domain spectroscopy were used to establish and validate a scattering model that uses stochastic methods to describe the effects of surface roughness on the phase and amplitude of a reflected terahertz signal, expressed as a communication channel transfer function. The modeled channel was used to simulate a quadrature phase shift keying (QPSK)- modulated wireless communication link to determine the relationships between symbol error rate and data rate as a function of surface roughness. The simulations reveal that surface roughness from wall texturing results in group delay dispersion that limits achievable data rate with low errors. A distinct dispersion limit in surface roughness is discovered beyond which unacceptable numbers of symbol errors begin to accrue for a given data rate.      
### 6.Fundamental Performance Limits on Terahertz Wireless Links Imposed by Group Velocity Dispersion  [ :arrow_down: ](https://arxiv.org/pdf/2104.00611.pdf)
>  A theoretical framework and numerical simulations quantifying the impact of atmospheric group velocity dispersion on wireless terahertz communication link error rate were developed based upon experimental work. We present, for the first time, predictions of symbol error rate as a function of link distance, signal bandwidth, signal-to-noise ratio, and atmospheric conditions, revealing that long-distance, broadband terahertz communication systems may be limited by inter-symbol interference stemming from group velocity dispersion, rather than attenuation. In such dispersion limited links, increasing signal strength does not improve the symbol error rate and, consequently, theoretical predictions of symbol error rate based only on signal-to-noise ratio are invalid for the broadband case. This work establishes a new and necessary foundation for link budget analysis in future long-distance terahertz communication systems that accounts for the non-negligible effects of both attenuation and dispersion.      
### 7.Extending Neural P-frame Codecs for B-frame Coding  [ :arrow_down: ](https://arxiv.org/pdf/2104.00531.pdf)
>  While most neural video codecs address P-frame coding (predicting each frame from past ones), in this paper we address B-frame compression (predicting frames using both past and future reference frames). Our B-frame solution is based on the existing P-frame methods. As a result, B-frame coding capability can easily be added to an existing neural codec. The basic idea of our B-frame coding method is to interpolate the two reference frames to generate a single reference frame and then use it together with an existing P-frame codec to encode the input B-frame. Our studies show that the interpolated frame is a much better reference for the P-frame codec compared to using the previous frame as is usually done. Our results show that using the proposed method with an existing P-frame codec can lead to 28.5%saving in bit-rate on the UVG dataset compared to the P-frame codec while generating the same video quality.      
### 8.Hetero-functional Network Minimum Cost Flow Optimization: A Hydrogen-Natural Gas Network Example  [ :arrow_down: ](https://arxiv.org/pdf/2104.00504.pdf)
>  Over the past decades, engineering systems have developed as networks of systems that deliver multiple services across multiple domains. This work aims to develop an optimization program for a dynamic, hetero-functional graph theory-based model of an engineering system. The manuscript first introduces a general approach to define a dynamic system model by integrating the device models in the hetero-functional graph theory structural model. To this end, the work leverages Petri net dynamics and the hetero-functional incidence tensor. The respective Petri net-based models are translated into the quadratic program canonical form to finalize the optimization program. The optimization program is demonstrated through the application of the program to a hydrogen-natural gas infrastructure test case. Four distinct scenarios are optimized to demonstrate potential synergies or cascading network effects of policy across infrastructures. <br>This work develops the first hetero-functional graph theory-based optimization program and demonstrates that the program can be used to optimize flows across a multi-operand network, transform the operands in the network, store operands over time, analyze the behavior for a quadratic cost function, and implement it for a generic, continuous, large flexible engineering systems of arbitrary topology.      
### 9.Communication-efficient Coordinated RSS-based Distributed Passive Localization via Drone Cluster  [ :arrow_down: ](https://arxiv.org/pdf/2104.00490.pdf)
>  Recently, passive unmanned aerial vehicle (UAV) localization has become popular due to mobility and convenience. In this paper, we consider a scenario of using distributed drone cluster to estimate the position of a passive emitter via received signal strength (RSS). First, a distributed majorizeminimization (DMM) RSS-based localization method is proposed. To accelerate its convergence, a tight upper bound of the objective function from the primary one is derived. Furthermore, to reduce communication overhead, a distributed estimation scheme using the Fisher information matrix (DEF) is presented, with only requiring one-round communication between edge UAVs and center UAV. Additionally, a local search solution is used as the initial value of DEF. Simulation results show that the proposed DMM performs better than the existing distributed Gauss-Newton method (DGN) in terms of root of mean square error (RMSE) under a limited low communication overhead constraint. Moreover, the proposed DEF performs much better than MM in terms of RMSE, but has a higher computational complexity than the latter.      
### 10.Reconfigurable Intelligent Surfaces for N-LOS Radar Surveillance  [ :arrow_down: ](https://arxiv.org/pdf/2104.00456.pdf)
>  This paper deals with the use of Reconfigurable Intelligent Surfaces (RISs) for radar surveillance in Non-Line Of Sight (N-LOS) scenarios. First of all, the geometry of the scene and the new system concept is described with emphasis on the required operative modes and the role played by the RIS. Then, the specific radar equation (including the RIS effect) is developed to manage the coverage requirements in the challenging region where the LOS is not present. Both noise and clutter interference cases (pulse length-limited and beamwidth-limited surface clutter as well as volume clutter) are considered. Hence, a digression on the use of the radar timeline for the new operative mode is presented together with the data acquisition procedure and the resolution issues for the range, azimuth, and Doppler domains. Finally, the interplay among the system parameters and, in particular, those involving the RIS is discussed and analyzed via numerical simulations.      
### 11.Expressive Text-to-Speech using Style Tag  [ :arrow_down: ](https://arxiv.org/pdf/2104.00436.pdf)
>  As recent text-to-speech (TTS) systems have been rapidly improved in speech quality and generation speed, many researchers now focus on a more challenging issue: expressive TTS. To control speaking styles, existing expressive TTS models use categorical style index or reference speech as style input. In this work, we propose StyleTagging-TTS (ST-TTS), a novel expressive TTS model that utilizes a style tag written in natural language. Using a style-tagged TTS dataset and a pre-trained language model, we modeled the relationship between linguistic embedding and speaking style domain, which enables our model to work even with style tags unseen during training. As style tag is written in natural language, it can control speaking style in a more intuitive, interpretable, and scalable way compared with style index or reference speech. In addition, in terms of model architecture, we propose an efficient non-autoregressive (NAR) TTS architecture with single-stage training. The experimental result shows that ST-TTS outperforms the existing expressive TTS model, Tacotron2-GST in speech quality and expressiveness.      
### 12.Explaining COVID-19 and Thoracic Pathology Model Predictions by Identifying Informative Input Features  [ :arrow_down: ](https://arxiv.org/pdf/2104.00411.pdf)
>  Neural networks have demonstrated remarkable performance in classification and regression tasks on chest X-rays. In order to establish trust in the clinical routine, the networks' prediction mechanism needs to be interpretable. One principal approach to interpretation is feature attribution. Feature attribution methods identify the importance of input features for the output prediction. Building on Information Bottleneck Attribution (IBA) method, for each prediction we identify the chest X-ray regions that have high mutual information with the network's output. Original IBA identifies input regions that have sufficient predictive information. We propose Inverse IBA to identify all informative regions. Thus all predictive cues for pathologies are highlighted on the X-rays, a desirable property for chest X-ray diagnosis. Moreover, we propose Regression IBA for explaining regression models. Using Regression IBA we observe that a model trained on cumulative severity score labels implicitly learns the severity of different X-ray regions. Finally, we propose Multi-layer IBA to generate higher resolution and more detailed attribution/saliency maps. We evaluate our methods using both human-centric (ground-truth-based) interpretability metrics, and human-independent feature importance metrics on NIH Chest X-ray8 and BrixIA datasets. The Code is publicly available.      
### 13.Distributed support-vector-machine over dynamic balanced directed networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.00399.pdf)
>  In this paper, we consider the binary classification problem via distributed Support-Vector-Machines (SVM), where the idea is to train a network of agents, with limited share of data, to cooperatively learn the SVM classifier for the global database. Agents only share processed information regarding the classifier parameters and the gradient of the local loss functions instead of their raw data. In contrast to the existing work, we propose a continuous-time algorithm that incorporates network topology changes in discrete jumps. This hybrid nature allows us to remove chattering that arises because of the discretization of the underlying CT process. We show that the proposed algorithm converges to the SVM classifier over time-varying weight balanced directed graphs by using arguments from the matrix perturbation theory.      
### 14.Delay-Tolerant Consensus-based Distributed Estimation: Full-Rank Systems with Potentially Unstable Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2104.00394.pdf)
>  Classical distributed estimation scenarios typically assume timely and reliable exchange of information over the multi-agent network. This paper, in contrast, considers single time-scale distributed estimation of (potentially) unstable full-rank dynamical systems via a multi-agent network subject to transmission time-delays. The proposed networked estimator consists of two steps: (i) consensus on (delayed) a-priori estimates, and (ii) measurement update. The agents only share their a-priori estimates with their in-neighbors over time-delayed transmission links. Considering the most general case, the delays are assumed to be time-varying, arbitrary, unknown, but upper-bounded. In contrast to most recent distributed observers assuming system observability in the neighborhood of each agent, our proposed estimator makes no such assumption. This may significantly reduce the communication/sensing loads on agents in large-scale, while making the (distributed) observability analysis more challenging. Using the notions of augmented matrices and Kronecker product, the geometric convergence of the proposed estimator over strongly-connected networks is proved irrespective of the bound on the time-delay. Simulations are provided to support our theoretical results.      
### 15.CycleDRUMS: Automatic Drum Arrangement For Bass Lines Using CycleGAN  [ :arrow_down: ](https://arxiv.org/pdf/2104.00353.pdf)
>  The two main research threads in computer-based music generation are: the construction of autonomous music-making systems, and the design of computer-based environments to assist musicians. In the symbolic domain, the key problem of automatically arranging a piece music was extensively studied, while relatively fewer systems tackled this challenge in the audio domain. In this contribution, we propose CycleDRUMS, a novel method for generating drums given a bass line. After converting the waveform of the bass into a mel-spectrogram, we are able to automatically generate original drums that follow the beat, sound credible and can be directly mixed with the input bass. We formulated this task as an unpaired image-to-image translation problem, and we addressed it with CycleGAN, a well-established unsupervised style transfer framework, originally designed for treating images. The choice to deploy raw audio and mel-spectrograms enabled us to better represent how humans perceive music, and to potentially draw sounds for new arrangements from the vast collection of music recordings accumulated in the last century. In absence of an objective way of evaluating the output of both generative adversarial networks and music generative systems, we further defined a possible metric for the proposed task, partially based on human (and expert) judgement. Finally, as a comparison, we replicated our results with Pix2Pix, a paired image-to-image translation network, and we showed that our approach outperforms it.      
### 16.Intuitive Tasks Planning Using Visuo-Tactile Perception for Human Robot Cooperation  [ :arrow_down: ](https://arxiv.org/pdf/2104.00342.pdf)
>  Designing robotic tasks for co-manipulation necessitates to exploit not only proprioceptive but also exteroceptive information for improved safety and autonomy. Following such instinct, this research proposes to formulate intuitive robotic tasks following human viewpoint by incorporating visuo-tactile perception. The visual data using depth cameras surveils and determines the object dimensions and human intentions while the tactile sensing ensures to maintain the desired contact to avoid slippage. Experiment performed on robot platform with human assistance under industrial settings validates the performance and applicability of proposed intuitive task formulation.      
### 17.SpectralNET: Exploring Spatial-Spectral WaveletCNN for Hyperspectral Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2104.00341.pdf)
>  Hyperspectral Image (HSI) classification using Convolutional Neural Networks (CNN) is widely found in the current literature. Approaches vary from using SVMs to 2D CNNs, 3D CNNs, 3D-2D CNNs. Besides 3D-2D CNNs and FuSENet, the other approaches do not consider both the spectral and spatial features together for HSI classification task, thereby resulting in poor performances. 3D CNNs are computationally heavy and are not widely used, while 2D CNNs do not consider multi-resolution processing of images, and only limits itself to the spatial features. Even though 3D-2D CNNs try to model the spectral and spatial features their performance seems limited when applied over multiple dataset. In this article, we propose SpectralNET, a wavelet CNN, which is a variation of 2D CNN for multi-resolution HSI classification. A wavelet CNN uses layers of wavelet transform to bring out spectral features. Computing a wavelet transform is lighter than computing 3D CNN. The spectral features extracted are then connected to the 2D CNN which bring out the spatial features, thereby creating a spatial-spectral feature vector for classification. Overall a better model is achieved that can classify multi-resolution HSI data with high accuracy. Experiments performed with SpectralNET on benchmark dataset, i.e. Indian Pines, University of Pavia, and Salinas Scenes confirm the superiority of proposed SpectralNET with respect to the state-of-the-art methods. The code is publicly available in <a class="link-external link-https" href="https://github.com/tanmay-ty/SpectralNET" rel="external noopener nofollow">this https URL</a>.      
### 18.High-quality Low-dose CT Reconstruction Using Convolutional Neural Networks with Spatial and Channel Squeeze and Excitation  [ :arrow_down: ](https://arxiv.org/pdf/2104.00325.pdf)
>  Low-dose computed tomography (CT) allows the reduction of radiation risk in clinical applications at the expense of image quality, which deteriorates the diagnosis accuracy of radiologists. In this work, we present a High-Quality Imaging network (HQINet) for the CT image reconstruction from Low-dose computed tomography (CT) acquisitions. HQINet was a convolutional encoder-decoder architecture, where the encoder was used to extract spatial and temporal information from three contiguous slices while the decoder was used to recover the spacial information of the middle slice. We provide experimental results on the real projection data from low-dose CT Image and Projection Data (LDCT-and-Projection-data), demonstrating that the proposed approach yielded a notable improvement of the performance in terms of image quality, with a rise of 5.5dB in terms of peak signal-to-noise ratio (PSNR) and 0.29 in terms of mutual information (MI).      
### 19.Interactive spatial speech recognition maps based on simulated speech recognition experiments  [ :arrow_down: ](https://arxiv.org/pdf/2104.00259.pdf)
>  In their everyday life, the speech recognition performance of human listeners is influenced by diverse factors, such as the acoustic environment, the talker and listener positions, possibly impaired hearing, and optional hearing devices. Prediction models come closer to considering all required factors simultaneously to predict the individual speech recognition performance in complex acoustic environments. While such predictions may still not be sufficiently accurate for serious applications, they can already be performed and demand an accessible representation. In this contribution, an interactive representation of speech recognition performance is proposed, which focuses on the listeners head orientation and the spatial dimensions of an acoustic scene. A exemplary modeling toolchain, including an acoustic rendering model, a hearing device model, and a listener model, was used to generate a data set for demonstration purposes. Using the spatial speech recognition maps to explore this data set demonstrated the suitability of the approach to observe possibly relevant behavior. The proposed representation provides a suitable target to compare and validate different modeling approaches in ecologically relevant contexts. Eventually, it may serve as a tool to use validated prediction models in the design of spaces and devices which take speech communication into account.      
### 20.Strategic Hub-Based Platoon Coordination under Uncertain Travel Times  [ :arrow_down: ](https://arxiv.org/pdf/2104.00255.pdf)
>  We study the strategic interaction among vehicles in a non-cooperative platoon coordination game. Vehicles have predefined routes in a transportation network with a set of hubs where vehicles can wait for other vehicles to form platoons. Vehicles decide on their waiting times at hubs and the utility function of each vehicle includes both the benefit from platooning and the cost of waiting. We show that the platoon coordination game is a potential game when the travel times are either deterministic or stochastic, and the vehicles decide on their waiting times at the beginning of their journeys. We also propose two feedback solutions for the coordination problem when the travel times are stochastic and vehicles are allowed to update their strategies along their routes. The solutions are evaluated in a simulation study over the Swedish road network. It is shown that uncertainty in travel times affects the total benefit of platooning drastically and the benefit from platooning in the system increases significantly when utilizing feedback solutions.      
### 21.Learning Deep Latent Subspaces for Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2104.00253.pdf)
>  Heterogeneity exists in most camera images. This heterogeneity manifests itself across the image space as varied Moire ringing, motion-blur, color-bleaching or lens based projection distortions. Moreover, combinations of these image artifacts can be present in small or large pixel neighborhoods, within an acquired image. Current camera image processing pipelines, including deep trained versions, tend to rectify the issue applying a single filter that is homogeneously applied to the entire image. This is also particularly true when an encoder-decoder type deep architecture is trained for the task. In this paper, we present a structured deep learning model that solves the heterogeneous image artifact filtering problem. We call our deep trained model the Patch Subspace Variational Autoencoder (PS-VAE) for Camera ISP. PS-VAE does not necessarily assume uniform image distortion levels nor similar artifact types within the image. Rather, our model attempts to learn to cluster different patches extracted from images into artifact type and distortion levels, within multiple latent subspaces (e.g. Moire ringing artifacts are often a higher dimensional latent distortion than a Gaussian motion blur artifact). Each image's patches are encoded into soft-clusters in their appropriate latent sub-space, using a prior mixture model. The decoders of the PS-VAE are also trained in an unsupervised manner for each of the image patches in each soft-cluster. Our experimental results demonstrates the flexibility and performance that one can achieve through improved heterogeneous filtering. We compare our results to a conventional one-encoder-one-decoder architecture.      
### 22.Bidirectional Multiscale Feature Aggregation for Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2104.00230.pdf)
>  In this paper, we propose a novel bidirectional multiscale feature aggregation (BMFA) network with attentional fusion modules for text-independent speaker verification. The feature maps from different stages of the backbone network are iteratively combined and refined in both a bottom-up and top-down manner. Furthermore, instead of simple concatenation or element-wise addition of feature maps from different stages, an attentional fusion module is designed to compute the fusion weights. Experiments are conducted on the NIST SRE16 and VoxCeleb1 datasets. The experimental results demonstrate the effectiveness of the bidirectional aggregation strategy and show that the proposed attentional fusion module can further improve the performance.      
### 23.Radar Human Motion Classification Using Multi-Antenna System  [ :arrow_down: ](https://arxiv.org/pdf/2104.00217.pdf)
>  This paper considers human activity classification for an indoor radar system. Human motions generate nonstationary radar returns which represent Doppler and micro-Doppler signals. The time-frequency (TF) analysis of micro-Doppler signals can discern subtle variations on the motion by precisely revealing velocity components of various moving body parts. We consider radar for activity monitoring using TF-based machine learning approach exploiting both temporal and spatial degrees of freedom. The proposed approach captures different human motion representations more vividly in joint-variable data domains achieved through beamforming at the receiver. The radar data is collected using real time measurements at 77 GHz using four receive antennas, and subsequently micro-Doppler signatures are analyzed through machine learning algorithm for classifications of human walking motions. We present the performance of the proposed multi antenna approach in separating and classifying two closely walking persons moving in opposite directions.      
### 24.A Novel Algorithm to Report CSI in MIMO-Based Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.00200.pdf)
>  In wireless communication, accurate channel state information (CSI) is of pivotal importance. In practice, due to processing and feedback delays, estimated CSI can be outdated, which can severely deteriorate the performance of the communication system. Besides, to feedback estimated CSI, a strong compression of the CSI, evaluated at the user equipment (UE), is performed to reduce the over-the-air (OTA) overhead. Such compression strongly reduces the precision of the estimated CSI, which ultimately impacts the performance of multiple-input multiple-output (MIMO) precoding. Motivated by such issues, we present a novel scalable idea of reporting CSI in wireless networks, which is applicable to both time-division duplex (TDD) and frequency-division duplex (FDD) systems. In particular, the novel approach introduces the use of a channel predictor function, e.g., Kalman filter (KF), at both ends of the communication system to predict CSI. Simulation-based results demonstrate that the novel approach reduces not only the channel mean-squared-error (MSE) but also the OTA overhead to feedback the estimated CSI when there is immense variation in the mobile radio channel. Besides, in the immobile radio channel, feedback can be eliminated, which brings the benefit of further reducing the OTA overhead. Additionally, the proposed method provides a significant signal-to-noise ratio (SNR) gain in both the channel conditions, i.e., highly mobile and immobile.      
### 25.Data-Driven Optimized Tracking Control Heuristic for MIMO Structures: A Balance System Case Study  [ :arrow_down: ](https://arxiv.org/pdf/2104.00199.pdf)
>  A data-driven computational heuristic is proposed to control MIMO systems without prior knowledge of their dynamics. The heuristic is illustrated on a two-input two-output balance system. It integrates a self-adjusting nonlinear threshold accepting heuristic with a neural network to compromise between the desired transient and steady state characteristics of the system while optimizing a dynamic cost function. The heuristic decides on the control gains of multiple interacting PID control loops. The neural network is trained upon optimizing a weighted-derivative like objective cost function. The performance of the developed mechanism is compared with another controller that employs a combined PID-Riccati approach. One of the salient features of the proposed control schemes is that they do not require prior knowledge of the system dynamics. However, they depend on a known region of stability for the control gains to be used as a search space by the optimization algorithm. The control mechanism is validated using different optimization criteria which address different design requirements.      
### 26.Full-Duplex mmWave Massive MIMO Systems: A Joint Hybrid Precoding/Combining and Self-Interference Cancellation Design  [ :arrow_down: ](https://arxiv.org/pdf/2104.00191.pdf)
>  Millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems have been considered as one of the primary candidates for the fifth generation (5G) and beyond 5G wireless communication networks to satisfy the ever-increasing capacity demands. Full-duplex technology can further enhance the advantages of mmWave massive MIMO systems. However, strong self-interference (SI) is the major limiting factor in full-duplex technology. Hence, this paper proposes a novel angular-based joint hybrid precoding/combining (AB-JHPC) technique for the full-duplex mmWave massive-MIMO systems. Our primary goals are listed as: (i) improving the self-interference cancellation (SIC), (ii) increasing the intended signal power, (iii) decreasing the channel estimation overhead, (iv) designing the massive MIMO systems with a low number of RF chains. First, the RF-stage of AB-JHPC is developed via slow time-varying angle-of-departure (AoD) and angle-of-arrival (AoA) information. A joint transmit/receive RF beamformer design is proposed for covering (excluding) the AoD/AoA support of intended (SI) channel. Second, the BB-stage of AB-JHPC is constructed via the reduced-size effective intended channel. After using the well-known singular value decomposition(SVD) approach at the BB-stage, we also propose a new semi-blind minimum mean square error (S-MMSE) technique to further suppress the residual SI power by using AoD/AoA parameters. The numerical results demonstrate that the SI signal is remarkably canceled via the proposed AB-JHPC technique. It is shown that AB-JHPC achieves 85.7 dB SIC and the total amount of SIC almost linearly increases via antenna isolation techniques. We observe that the proposed full-duplex mmWave massive MIMO systems double the achievable rate capacity compared to its half-duplex counterpart as the antenna array size increases and the transmit/receive antenna isolation improves.      
### 27.Trajectory Tracking of Underactuated Sea Vessels With Uncertain Dynamics: An Integral Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.00190.pdf)
>  Underactuated systems like sea vessels have degrees of motion that are insufficiently matched by a set of independent actuation forces. In addition, the underlying trajectory-tracking control problems grow in complexity in order to decide the optimal rudder and thrust control signals. This enforces several difficult-to-solve constraints that are associated with the error dynamical equations using classical optimal tracking and adaptive control approaches. An online machine learning mechanism based on integral reinforcement learning is proposed to find a solution for a class of nonlinear tracking problems with partial prior knowledge of the system dynamics. The actuation forces are decided using innovative forms of temporal difference equations relevant to the vessel's surge and angular velocities. The solution is implemented using an online value iteration process which is realized by employing means of the adaptive critics and gradient descent approaches. The adaptive learning mechanism exhibited well-functioning and interactive features in react to different desired reference-tracking scenarios.      
### 28.Dealing with CSI Compression to Reduce Losses and Overhead: An Artificial Intelligence Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.00189.pdf)
>  Motivated by the issue of inaccurate channel state information (CSI) at the base station (BS), which is commonly due to feedback/processing delays and compression problems, in this paper, we introduce a scalable idea of adopting artificial intelligence (AI) aided CSI acquisition. The proposed scheme enhances the CSI compression, which is done at the mobile terminal (MT), along with accurate recovery of estimated CSI at the BS. Simulation-based results corroborate the validity of the proposed scheme. Numerically, nearly 100\% recovery of the estimated CSI is observed with relatively lower overhead than the benchmark scheme. The proposed idea can bring potential benefits in the wireless communication environment, e.g., ultra-reliable and low latency communication (URLLC), where imperfect CSI and overhead is intolerable.      
### 29.A Semidefinite Programming Approach to Discrete-time Infinite Horizon Persistent Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2104.00166.pdf)
>  We investigate the problem of persistent monitoring, where a mobile agent has to survey multiple targets in an environment in order to estimate their internal states. These internal states evolve with linear stochastic dynamics and the agent can observe them with a linear observation model. However, the signal to noise ratio is a monotonically decreasing function of the distance between the agent and the target. The goal is to minimize the uncertainty in the state estimates over the infinite horizon. We show that, for a periodic trajectory with fixed cycle length, the problem can be formulated as a set of semidefinite programs. We design a scheme that leverages the spatial configuration of the targets to guide the search over this set of optimization problems in order to provide efficient trajectories. Results are compared to a state of the art approach and we obtain improvements of up to 91% in terms of cost in a simple scenario, with much lower computational time.      
### 30.State-of-the-art segmentation network fooled to segment a heart symbol in chest X-Ray images  [ :arrow_down: ](https://arxiv.org/pdf/2104.00139.pdf)
>  Adversarial attacks consist in maliciously changing the input data to mislead the predictions of automated decision systems and are potentially a serious threat for automated medical image analysis. Previous studies have shown that it is possible to adversarially manipulate automated segmentations produced by neural networks in a targeted manner in the white-box attack setting. In this article, we studied the effectiveness of adversarial attacks in targeted modification of segmentations of anatomical structures in chest X-rays. Firstly, we experimented with using anatomically implausible shapes as targets for adversarial manipulation. We showed that, by adding almost imperceptible noise to the image, we can reliably force state-of-the-art neural networks to segment the heart as a heart symbol instead of its real anatomical shape. Moreover, such heart-shaping attack did not appear to require higher adversarial noise level than an untargeted attack based the same attack method. Secondly, we attempted to explore the limits of adversarial manipulation of segmentations. For that, we assessed the effectiveness of shrinking and enlarging segmentation contours for the three anatomical structures. We observed that adversarially extending segmentations of structures into regions with intensity and texture uncharacteristic for them presented a challenge to our attacks, as well as, in some cases, changing segmentations in ways that conflict with class adjacency priors learned by the target network. Additionally, we evaluated performances of the untargeted attacks and targeted heart attacks in the black-box attack scenario, using a surrogate network trained on a different subset of images. In both cases, the attacks were substantially less effective. We believe these findings bring novel insights into the current capabilities and limits of adversarial attacks for semantic segmentation.      
### 31.Rapid quantification of COVID-19 pneumonia burden from computed tomography with convolutional LSTM networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.00138.pdf)
>  Quantitative lung measures derived from computed tomography (CT) have been demonstrated to improve prognostication in coronavirus disease (COVID-19) patients, but are not part of the clinical routine since required manual segmentation of lung lesions is prohibitively time-consuming. We propose a new fully automated deep learning framework for rapid quantification and differentiation between lung lesions in COVID-19 pneumonia from both contrast and non-contrast CT images using convolutional Long Short-Term Memory (ConvLSTM) networks. Utilizing the expert annotations, model training was performed 5 times with separate hold-out sets using 5-fold cross-validation to segment ground-glass opacity and high opacity (including consolidation and pleural effusion). The performance of the method was evaluated on CT data sets from 197 patients with positive reverse transcription polymerase chain reaction test result for SARS-CoV-2. Strong agreement between expert manual and automatic segmentation was obtained for lung lesions with a Dice score coefficient of 0.876 $\pm$ 0.005; excellent correlations of 0.978 and 0.981 for ground-glass opacity and high opacity volumes. In the external validation set of 67 patients, there was dice score coefficient of 0.767 $\pm$ 0.009 as well as excellent correlations of 0.989 and 0.996 for ground-glass opacity and high opacity volumes. Computations for a CT scan comprising 120 slices were performed under 2 seconds on a personal computer equipped with NVIDIA Titan RTX graphics processing unit. Therefore, our deep learning-based method allows rapid fully-automated quantitative measurement of pneumonia burden from CT and may generate results with an accuracy similar to the expert readers.      
### 32.Safe Online Learning-based Formation Control of Multi-Agent Systems with Gaussian Processes  [ :arrow_down: ](https://arxiv.org/pdf/2104.00130.pdf)
>  Formation control algorithms for multi-agent systems have gained much attention in the recent years due to the increasing amount of mobile and aerial robotic swarms. The design of safe controllers for these vehicles is a substantial aspect for an increasing range of application domains. However, parts of the vehicle's dynamics and external disturbances are often unknown or very time-consuming to model. To overcome this issue, we present a safe formation control law for multiagent systems based on double integrator dynamics by using Gaussian Processes for an online learning of the unknown dynamics. The presented approach guarantees a bounded error to desired formations with high probability, where the bound is explicitly given. A numerical example highlights the effectiveness of the learning-based formation control law.      
### 33.Generalized Reinforcement Learning for Building Control using Behavioral Cloning  [ :arrow_down: ](https://arxiv.org/pdf/2104.00123.pdf)
>  Advanced building control methods such as model predictive control (MPC) offer significant potential benefits to both consumers and grid operators, but the high computational requirements have acted as barriers to more widespread adoption. Local control computation requires installation of expensive computational hardware, while cloud computing introduces data security and privacy concerns. In this paper, we drastically reduce the local computational requirements of advanced building control through a reinforcement learning (RL)-based approach called Behavioral Cloning, which represents the MPC policy as a neural network that can be locally implemented and quickly computed on a low-cost programmable logic controller. While previous RL and approximate MPC methods must be specifically trained for each building, our key improvement is that our controller can generalize to many buildings, electricity rates, and thermostat setpoint schedules without additional, effort-intensive retraining. To provide this versatility, we have adapted the traditional Behavioral Cloning approach through (1) a constraint-informed parameter grouping (CIPG) method that provides a more efficient representation of the training data; (2) an MPC-Guided training data generation method using the DAgger algorithm that improves stability and constraint satisfaction; and (3) a new deep learning model-structure called reverse-time recurrent neural networks (RT-RNN) that allows future information to flow backward in time to more effectively interpret the temporal information in disturbance predictions. The result is an easy-to-deploy, generalized behavioral clone of MPC that can be implemented on a programmable logic controller and requires little building-specific controller tuning, reducing the effort and costs associated with implementing smart residential heat pump control.      
### 34.Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2104.00120.pdf)
>  Stream fusion, also known as system combination, is a common technique in automatic speech recognition for traditional hybrid hidden Markov model approaches, yet mostly unexplored for modern deep neural network end-to-end model architectures. Here, we investigate various fusion techniques for the all-attention-based encoder-decoder architecture known as the transformer, striving to achieve optimal fusion by investigating different fusion levels in an example single-microphone setting with fusion of standard magnitude and phase features. We introduce a novel multi-encoder learning method that performs a weighted combination of two encoder-decoder multi-head attention outputs only during training. Employing then only the magnitude feature encoder in inference, we are able to show consistent improvement on Wall Street Journal (WSJ) with language model and on Librispeech, without increase in runtime or parameters. Combining two such multi-encoder trained models by a simple late fusion in inference, we achieve state-of-the-art performance for transformer-based models on WSJ with a significant WER reduction of 19\% relative compared to the current benchmark approach.      
### 35.High-order Barrier Functions: Robustness, Safety and Performance-Critical Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.00101.pdf)
>  In this paper, we propose a notion of high-order (zeroing) barrier functions that generalizes the concept of zeroing barrier functions and guarantees set forward invariance by checking their higher order derivatives. The proposed formulation guarantees asymptotic stability of the forward invariant set, which is highly favorable for robustness with respect to model perturbations. No forward completeness assumption is needed in our setting in contrast to existing high order barrier function methods. For the case of controlled dynamical systems, we relax the requirement of uniform relative degree and propose a singularity-free control scheme that yields a locally Lipschitz control signal and guarantees safety. Furthermore, the proposed formulation accounts for "performance-critical" control: it guarantees that a subset of the forward invariant set will admit any existing, bounded control law, while still ensuring forward invariance of the set. Finally, a non-trivial case study with rigid-body attitude dynamics and interconnected cell regions as the safe region is investigated.      
### 36.Balancing Fairness and Efficiency in Traffic Routing via Interpolated Traffic Assignment  [ :arrow_down: ](https://arxiv.org/pdf/2104.00098.pdf)
>  System optimum (SO) routing, wherein the total travel time of all users is minimized, is a holy grail for transportation authorities. However, SO routing may discriminate against users who incur much larger travel times than others to achieve high system efficiency, i.e., low total travel times. To address the inherent unfairness of SO routing, we study the $\beta$-fair SO problem whose goal is to minimize the total travel time while guaranteeing a $\beta\geq 1$ level of unfairness, which specifies the maximal ratio between the travel times of different users with shared origins and destinations. To obtain feasible solutions to the $\beta$-fair SO problem while achieving high system efficiency, we develop a new convex program, the Interpolated Traffic Assignment Problem (I-TAP), which interpolates between a fair and an efficient traffic-assignment objective. We then leverage the structure of I-TAP to develop two pricing mechanisms to collectively enforce the I-TAP solution in the presence of selfish homogeneous and heterogeneous users, respectively, that independently choose routes to minimize their own travel costs. We mention that this is the first study of pricing in the context of fair routing. Finally, we use origin-destination demand data for a range of transportation networks to numerically evaluate the performance of I-TAP as compared to a state-of-the-art algorithm. The numerical results indicate that our approach is faster by several orders of magnitude, while achieving higher system efficiency for most levels of unfairness.      
### 37.Online Non-linear Topology Identification from Graph-connected Time Series  [ :arrow_down: ](https://arxiv.org/pdf/2104.00030.pdf)
>  Estimating the unknown causal dependencies among graph-connected time series plays an important role in many applications, such as sensor network analysis, signal processing over cyber-physical systems, and finance engineering. Inference of such causal dependencies, often know as topology identification, is not well studied for non-linear non-stationary systems, and most of the existing methods are batch-based which are not capable of handling streaming sensor signals. In this paper, we propose an online kernel-based algorithm for topology estimation of non-linear vector autoregressive time series by solving a sparse online optimization framework using the composite objective mirror descent method. Experiments conducted on real and synthetic data sets show that the proposed algorithm outperforms the state-of-the-art methods for topology estimation.      
### 38.Edge Differential Privacy for Algebraic Connectivity of Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2104.00654.pdf)
>  Graphs are the dominant formalism for modeling multi-agent systems. The algebraic connectivity of a graph is particularly important because it provides the convergence rates of consensus algorithms that underlie many multi-agent control and optimization techniques. However, sharing the value of algebraic connectivity can inadvertently reveal sensitive information about the topology of a graph, such as connections in social networks. Therefore, in this work we present a method to release a graph's algebraic connectivity under a graph-theoretic form of differential privacy, called edge differential privacy. Edge differential privacy obfuscates differences among graphs' edge sets and thus conceals the absence or presence of sensitive connections therein. We provide privacy with bounded Laplace noise, which improves accuracy relative to conventional unbounded noise. The private algebraic connectivity values are analytically shown to provide accurate estimates of consensus convergence rates, as well as accurate bounds on the diameter of a graph and the mean distance between its nodes. Simulation results confirm the utility of private algebraic connectivity in these contexts.      
### 39.Residual Model Learning for Microrobot Control  [ :arrow_down: ](https://arxiv.org/pdf/2104.00631.pdf)
>  A majority of microrobots are constructed using compliant materials that are difficult to model analytically, limiting the utility of traditional model-based controllers. Challenges in data collection on microrobots and large errors between simulated models and real robots make current model-based learning and sim-to-real transfer methods difficult to apply. We propose a novel framework residual model learning (RML) that leverages approximate models to substantially reduce the sample complexity associated with learning an accurate robot model. We show that using RML, we can learn a model of the Harvard Ambulatory MicroRobot (HAMR) using just 12 seconds of passively collected interaction data. The learned model is accurate enough to be leveraged as "proxy-simulator" for learning walking and turning behaviors using model-free reinforcement learning algorithms. RML provides a general framework for learning from extremely small amounts of interaction data, and our experiments with HAMR clearly demonstrate that RML substantially outperforms existing techniques.      
### 40.Detecting Hidden Units and Network Size from Perceptible Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2104.00607.pdf)
>  The number of units of a network dynamical system, its size, arguably constitutes its most fundamental property. Many units of a network, however, are typically experimentally inaccessible such that the network size is often unknown. Here we introduce a \emph{detection matrix }that suitably arranges multiple transient time series from the subset of accessible units to detect network size via matching rank constraints. The proposed method is model-free, applicable across system types and interaction topologies and applies to non-stationary dynamics near fixed points, as well as periodic and chaotic collective motion. Even if only a small minority of units is perceptible and for systems simultaneously exhibiting nonlinearities, heterogeneities and noise, \emph{exact} size detection is feasible. We illustrate applicability for a paradigmatic class of biochemical reaction networks.      
### 41.Design and development of an Aerial Surveillance Security System  [ :arrow_down: ](https://arxiv.org/pdf/2104.00604.pdf)
>  Aerial security means performing security-aimed monitoring and surveillance operations with the help of airborne vehicles. This kind of activities suggest that human officers (security organizations, law enforcement, police etc.) would be able to remotely monitor and view video and data acquired from Drones while planning and evaluating their operations. The spectrum of applications where drones are used for security purposes is vast: scouting and reporting emergencies, monitoring accidents and crimes, surveillance of a certain landscape area, operating in highly busy and pedestrians as well as their tracking from up in the sky, and so on. The project will serve as a bridge to connect actual happening in areas that cannot be navigated easily by security personnel of corporate institution as the Drone will be used to hover and record the actual happening as it transmit to a ground station which records and analyses the events as they streams in, also due its capability of flying over different altitudes the drone can generally be used on areas with rugged terrains or over water bodies for a time dependent on its power capacity.      
### 42.Reinforcement Learning Beyond Expectation  [ :arrow_down: ](https://arxiv.org/pdf/2104.00540.pdf)
>  The inputs and preferences of human users are important considerations in situations where these users interact with autonomous cyber or cyber-physical systems. In these scenarios, one is often interested in aligning behaviors of the system with the preferences of one or more human users. Cumulative prospect theory (CPT) is a paradigm that has been empirically shown to model a tendency of humans to view gains and losses differently. In this paper, we consider a setting where an autonomous agent has to learn behaviors in an unknown environment. In traditional reinforcement learning, these behaviors are learned through repeated interactions with the environment by optimizing an expected utility. In order to endow the agent with the ability to closely mimic the behavior of human users, we optimize a CPT-based cost. We introduce the notion of the CPT-value of an action taken in a state, and establish the convergence of an iterative dynamic programming-based approach to estimate this quantity. We develop two algorithms to enable agents to learn policies to optimize the CPT-vale, and evaluate these algorithms in environments where a target state has to be reached while avoiding obstacles. We demonstrate that behaviors of the agent learned using these algorithms are better aligned with that of a human user who might be placed in the same environment, and is significantly improved over a baseline that optimizes an expected utility.      
### 43.Prediction of Wind Speed Using Artificial Neural Networks and ANFIS Methods (Observation Buoy Example)  [ :arrow_down: ](https://arxiv.org/pdf/2104.00538.pdf)
>  Estimation of the wind speed plays an important role in many issues such as route determination of ships, efficient use of wind roses, and correct planning of agricultural activities. In this study, wind velocity estimation is calculated using artificial neural networks (ANN) and adaptive artificial neural fuzzy inference system (ANFIS) methods. The data required for estimation was obtained from the float named E1M3A, which is a float inside the POSEIDON float system. The proposed ANN is a Nonlinear Auto Regressive with External Input (NARX) type of artificial neural network with 3 layers, 50 neurons, 6 inputs and 1 output. The ANFIS system introduced is a fuzzy inference system with 6 inputs, 1 output, and 3 membership functions (MF) per input. The proposed systems were trained to make wind speed estimates after 3 hours and the data obtained were obtained and the successes of the systems were revealed by comparing the obtained values with real measurements. Mean Squarred Error (MSE) and the regression between the predictions and expected values (R) were used to evaluate the success of the estimation values obtained from the systems. According to estimation results, ANN achieved 2.19 MSE and 0.897 R values in training, 2.88 MSE and 0.866 R values in validation, and 2.93 MSE and 0.857 R values in testing. ANFIS method has obtained 0.31634 MSE and 0.99 R values      
### 44.Improved Image Generation via Sparse Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2104.00464.pdf)
>  The interest of the deep learning community in image synthesis has grown massively in recent years. Nowadays, deep generative methods, and especially Generative Adversarial Networks (GANs), are leading to state-of-the-art performance, capable of synthesizing images that appear realistic. While the efforts for improving the quality of the generated images are extensive, most attempts still consider the generator part as an uncorroborated "black-box". In this paper, we aim to provide a better understanding and design of the image generation process. We interpret existing generators as implicitly relying on sparsity-inspired models. More specifically, we show that generators can be viewed as manifestations of the Convolutional Sparse Coding (CSC) and its Multi-Layered version (ML-CSC) synthesis processes. We leverage this observation by explicitly enforcing a sparsifying regularization on appropriately chosen activation layers in the generator, and demonstrate that this leads to improved image synthesis. Furthermore, we show that the same rationale and benefits apply to generators serving inverse problems, demonstrated on the Deep Image Prior (DIP) method.      
### 45.Enriched Music Representations with Multiple Cross-modal Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.00437.pdf)
>  Modeling various aspects that make a music piece unique is a challenging task, requiring the combination of multiple sources of information. Deep learning is commonly used to obtain representations using various sources of information, such as the audio, interactions between users and songs, or associated genre metadata. Recently, contrastive learning has led to representations that generalize better compared to traditional supervised methods. In this paper, we present a novel approach that combines multiple types of information related to music using cross-modal contrastive learning, allowing us to learn an audio feature from heterogeneous data simultaneously. We align the latent representations obtained from playlists-track interactions, genre metadata, and the tracks' audio, by maximizing the agreement between these modality representations using a contrastive loss. We evaluate our approach in three tasks, namely, genre classification, playlist continuation and automatic tagging. We compare the performances with a baseline audio-based CNN trained to predict these modalities. We also study the importance of including multiple sources of information when training our embedding model. The results suggest that the proposed method outperforms the baseline in all the three downstream tasks and achieves comparable performance to the state-of-the-art.      
### 46.Speech Resynthesis from Discrete Disentangled Self-Supervised Representations  [ :arrow_down: ](https://arxiv.org/pdf/2104.00355.pdf)
>  We propose using self-supervised discrete representations for the task of speech resynthesis. To generate disentangled representation, we separately extract low-bitrate representations for speech content, prosodic information, and speaker identity. This allows to synthesize speech in a controllable manner. We analyze various state-of-the-art, self-supervised representation learning methods and shed light on the advantages of each method while considering reconstruction quality and disentanglement properties. Specifically, we evaluate the F0 reconstruction, speaker identification performance (for both resynthesis and voice conversion), recordings' intelligibility, and overall quality using subjective human evaluation. Lastly, we demonstrate how these representations can be used for an ultra-lightweight speech codec. Using the obtained representations, we can get to a rate of 365 bits per second while providing better speech quality than the baseline methods. Audio samples can be found under <a class="link-external link-https" href="https://resynthesis-ssl.github.io/" rel="external noopener nofollow">this https URL</a>.      
### 47.Unsupervised Sound Localization via Iterative Contrastive Learning  [ :arrow_down: ](https://arxiv.org/pdf/2104.00315.pdf)
>  Sound localization aims to find the source of the audio signal in the visual scene. However, it is labor-intensive to annotate the correlations between the signals sampled from the audio and visual modalities, thus making it difficult to supervise the learning of a machine for this task. In this work, we propose an iterative contrastive learning framework that requires no data annotations. At each iteration, the proposed method takes the 1) localization results in images predicted in the previous iteration, and 2) semantic relationships inferred from the audio signals as the pseudo-labels. We then use the pseudo-labels to learn the correlation between the visual and audio signals sampled from the same video (intra-frame sampling) as well as the association between those extracted across videos (inter-frame relation). Our iterative strategy gradually encourages the localization of the sounding objects and reduces the correlation between the non-sounding regions and the reference audio. Quantitative and qualitative experimental results demonstrate that the proposed framework performs favorably against existing unsupervised and weakly-supervised methods on the sound localization task.      
### 48.Positive Sample Propagation along the Audio-Visual Event Line  [ :arrow_down: ](https://arxiv.org/pdf/2104.00239.pdf)
>  Visual and audio signals often coexist in natural environments, forming audio-visual events (AVEs). Given a video, we aim to localize video segments containing an AVE and identify its category. In order to learn discriminative features for a classifier, it is pivotal to identify the helpful (or positive) audio-visual segment pairs while filtering out the irrelevant ones, regardless whether they are synchronized or not. To this end, we propose a new positive sample propagation (PSP) module to discover and exploit the closely related audio-visual pairs by evaluating the relationship within every possible pair. It can be done by constructing an all-pair similarity map between each audio and visual segment, and only aggregating the features from the pairs with high similarity scores. To encourage the network to extract high correlated features for positive samples, a new audio-visual pair similarity loss is proposed. We also propose a new weighting branch to better exploit the temporal correlations in weakly supervised setting. We perform extensive experiments on the public AVE dataset and achieve new state-of-the-art accuracy in both fully and weakly supervised settings, thus verifying the effectiveness of our method.      
### 49.Multilingual and code-switching ASR challenges for low resource Indian languages  [ :arrow_down: ](https://arxiv.org/pdf/2104.00235.pdf)
>  Recently, there is increasing interest in multilingual automatic speech recognition (ASR) where a speech recognition system caters to multiple low resource languages by taking advantage of low amounts of labeled corpora in multiple languages. With multilingualism becoming common in today's world, there has been increasing interest in code-switching ASR as well. In code-switching, multiple languages are freely interchanged within a single sentence or between sentences. The success of low-resource multilingual and code-switching ASR often depends on the variety of languages in terms of their acoustics, linguistic characteristics as well as the amount of data available and how these are carefully considered in building the ASR system. In this challenge, we would like to focus on building multilingual and code-switching ASR systems through two different subtasks related to a total of seven Indian languages, namely Hindi, Marathi, Odia, Tamil, Telugu, Gujarati and Bengali. For this purpose, we provide a total of ~600 hours of transcribed speech data, comprising train and test sets, in these languages including two code-switched language pairs, Hindi-English and Bengali-English. We also provide a baseline recipe for both the tasks with a WER of 30.73% and 32.45% on the test sets of multilingual and code-switching subtasks, respectively.      
### 50.Rate-Splitting Multiple Access for Multi-Antenna Broadcast Channels with Statistical CSIT  [ :arrow_down: ](https://arxiv.org/pdf/2104.00220.pdf)
>  Rate-splitting multiple access (RSMA) is a promising technique for downlink multi-antenna communications owning to its capability of enhancing the system performance in a wide range of network loads, user deployments and channel state information at the transmitter (CSIT) inaccuracies. In this paper, we investigate the achievable rate performance of RSMA in a multi-user multiple-input single-output (MU-MISO) network where only slow-varying statistical channel state information (CSI) is available at the transmitter. RSMA-based statistical beamforming and the split of the common stream is optimized with the objective of maximizing the minimum user rate subject to a sum power budget of the transmitter. Two statistical CSIT scenarios are investigated, namely the Rayleigh fading channels with only spatial correlations known at the transmitter, and the uniform linear array (ULA) deployment with only channel amplitudes and mean of phase known at the transmitter. Numerical results demonstrate the explicit max min fairness (MMF) rate gain of RSMA over space division multiple access (SDMA) in both scenarios. Moreover, we demonstrate that RSMA is more robust to the inaccuracy of statistical CSIT.      
### 51.Rate-Splitting Multiple Access for Multigroup Multicast Cellular and Satellite Communications: PHY Layer Design and Link-Level Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2104.00206.pdf)
>  Rate-splitting multiple access (RSMA), relying on linearly precoded rate-splitting (RS) at the transmitter and successive interference cancellation (SIC) at the receivers has emerged as a powerful and flexible multiple access strategy for downlink multi-user multi-antenna systems. Through message splitting and the transmission of both common and private messages, RSMA has been demonstrated to be a robust interference management strategy which enables partially decoding interference and partially treating interference as noise. In this work, we consider the application of RSMA in a multigroup multicast scenario, where each message is intended to a group of users. By leveraging the recent results on the max-min fair (MMF) optimization problem of RSMA-based multigroup multicast beamforming with imperfect channel state information at the transmitter (CSIT), we investigate the design of the physical (PHY) layer including finite length polar coding, finite alphabet modulation, adaptive modulation and coding (AMC) algorithm, and SIC receivers, etc. Link-level simulation (LLS) results verify the superiority of RSMA-based multigroup multicast transmission compared with space-division multiple access (SDMA)-based strategy in both cellular systems and multibeam satellite systems.      
### 52.$\textbf{MyoMapNet}$: Accelerated Modified Look-Locker Inversion Recovery Myocardial T1 Mapping via Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.00143.pdf)
>  Purpose: To develop and evaluate MyoMapNet, a rapid myocardial T1 mapping approach that uses neural networks (NN) to estimate voxel-wise myocardial T1 and extracellular (ECV) from T1-weighted images collected after a single inversion pulse over 4-5 heartbeats. Method: MyoMapNet utilizes a simple fully-connected NN to estimate T1 values from 5 (native) or 4 (post-contrast) T1-weighted images. Native MOLLI-5(3)3 T1 was collected in 717 subjects (386 males, 55$\pm$16.5 years) and post-contrast MOLLI-4(1)3(1)2 in 535 subjects (232 male, 56.5$\pm$15 years). The dataset was divided into training (80%) and testing (20%), where 20% of the training set was used to optimize MyoMapNet architecture (size and loss functions). We used MyoMapNet to estimate T1 and ECV maps with the first 5 (native) or 4 (post-contrast) T1-weighted images from the corresponding MOLLI sequence compared to the conventional and an abbreviated MOLLI using similar number of T1-weighted images with 3-parameter curve-fitting. Results: In our preliminary optimizaiton step, we determined that a 5-layers NN trained using mean-absolute-error loss yields lower estimation errors and was used subsequently in independent testing study. The myocardial T1 by MyoMapNet was similar to MOLLI (1200$\pm$45ms vs. 1199$\pm$46ms; P=0.3 for native T1, and 27.3$\pm$3.5% vs. 27.1$\pm$4%; P=0.4 for ECV). MyoMapNet had significantly smaller errors in T1 estimations compared to abbreviated-MOLLI (1$\pm$17ms vs. 31$\pm$34ms, P&lt;0.01 for in native T1, and 0.1$\pm$1.3% vs. 1.9$\pm$2.5%, P&lt;0.01 for ECV). The duration of T1 estimation was approximately 2 ms per slice using MyoMapNet. Conclusion: MyoMapNet T1 mapping enables myocardial T1 quantification in 4-5 heartbeats with near-instantaneous map estimation time with similar accuracy and precision as MOLLI. Keywords: Myocardial T1 mapping, MOLLI, T1 reconstruction, Neural network, Deep Learning.      
### 53.MR Slice Profile Estimation by Learning to Match Internal Patch Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2104.00100.pdf)
>  To super-resolve the through-plane direction of a multi-slice 2D magnetic resonance (MR) image, its slice selection profile can be used as the degeneration model from high resolution (HR) to low resolution (LR) to create paired data when training a supervised algorithm. Existing super-resolution algorithms make assumptions about the slice selection profile since it is not readily known for a given image. In this work, we estimate a slice selection profile given a specific image by learning to match its internal patch distributions. Specifically, we assume that after applying the correct slice selection profile, the image patch distribution along HR in-plane directions should match the distribution along the LR through-plane direction. Therefore, we incorporate the estimation of a slice selection profile as part of learning a generator in a generative adversarial network (GAN). In this way, the slice selection profile can be learned without any external data. Our algorithm was tested using simulations from isotropic MR images, incorporated in a through-plane super-resolution algorithm to demonstrate its benefits, and also used as a tool to measure image resolution. Our code is at <a class="link-external link-https" href="https://github.com/shuohan/espreso2" rel="external noopener nofollow">this https URL</a>.      
### 54.An Online Survey on the Perception of Mediated Social Touch Interaction and Device Design  [ :arrow_down: ](https://arxiv.org/pdf/2104.00086.pdf)
>  Social touch is essential for our social interactions, communication, and well-being. It has been shown to reduce anxiety and loneliness; and is a key channel to transmit emotions for which words are not sufficient, such as love, sympathy, reassurance, etc. However, direct physical contact is not always possible due to being remotely located, interacting in a virtual environment, or as a result of a health issue. Mediated social touch enables physical interactions, despite the distance, by transmitting the haptic cues that constitute social touch through devices. As this technology is fairly new, the users' needs and their expectations on a device design and its features are unclear, as well as who would use this technology, and in which conditions. To better understand these aspects of the mediated interaction, we conducted an online survey on 258 respondents located in the USA. Results give insights on the type of interactions and device features that the US population would like to use.      
### 55.Force-and-moment-based Model Predictive Control for Achieving Highly Dynamic Locomotion on Bipedal Robots  [ :arrow_down: ](https://arxiv.org/pdf/2104.00065.pdf)
>  In this paper, we propose a novel framework on force-and-moment-based Model Predictive Control (MPC) for dynamic legged robots. In specific, we present a formulation of MPC designed for 10 degree-of-freedom (DoF) bipedal robots using a simplified rigid body dynamics with input forces and moments. This MPC controller will calculate the optimal inputs applied to the robot, including 3-D forces and 2-D moments at each foot. These desired inputs will then be generated by mapping these forces and moments to motor torques of 5 actuators on each leg. We evaluate our proposed control design on physical simulation of a 10 degree-of-freedom (DoF) bipedal robot. The robot can achieve fast walking speed up to 1.6 m/s on rough terrain, with accurate velocity tracking. With the same control framework, our proposed approach can achieve a wide range of dynamic motions including walking, hopping, and running using the same set of control parameters.      
### 56.Structured input-output analysis of transitional wall-bounded flows  [ :arrow_down: ](https://arxiv.org/pdf/2104.00062.pdf)
>  Input-output analysis of transitional channel flows has proven to be a valuable analytical tool for identifying important flow structures and energetic motions. The traditional approach abstracts the nonlinear terms as forcing that is unstructured, in the sense that is not directly tied to the underlying nonlinearity in the dynamics. This paper instead employs a structured singular value-based approach that preserves certain input-output properties of the nonlinear forcing function in an effort to recover the larger range of key flow features identified through nonlinear analysis, experiments, and direct numerical simulation (DNS) of transitional channel flows. Application of this method to transitional plane Couette and plane Poiseuille flows leads to identification of not only the streamwise coherent structures predicted through traditional input-output approaches but also characterization of the oblique flow structures as those requiring the least energy to induce transition in agreement with DNS studies, and nonlinear optimal perturbation analysis. The proposed approach also captures the recently observed oblique turbulent bands that have been linked to transition in experiments and DNS with very large channel size. The ability to identify the larger amplification of the streamwise varying structures predicted from DNS and nonlinear analysis in both flow regimes suggests that the structured approach allows one to maintain the nonlinear effects associated with the saturation of the lift-up mechanism, which is known to dominate the linear operator. Capturing this key nonlinear mechanism enables the prediction of the wider range of known transitional flow structures within the analytical input--output modeling paradigm.      
### 57.Passive Inter-Photon Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2104.00059.pdf)
>  Digital camera pixels measure image intensities by converting incident light energy into an analog electrical current, and then digitizing it into a fixed-width binary representation. This direct measurement method, while conceptually simple, suffers from limited dynamic range and poor performance under extreme illumination -- electronic noise dominates under low illumination, and pixel full-well capacity results in saturation under bright illumination. We propose a novel intensity cue based on measuring inter-photon timing, defined as the time delay between detection of successive photons. Based on the statistics of inter-photon times measured by a time-resolved single-photon sensor, we develop theory and algorithms for a scene brightness estimator which works over extreme dynamic range; we experimentally demonstrate imaging scenes with a dynamic range of over ten million to one. The proposed techniques, aided by the emergence of single-photon sensors such as single-photon avalanche diodes (SPADs) with picosecond timing resolution, will have implications for a wide range of imaging applications: robotics, consumer photography, astronomy, microscopy and biomedical imaging.      

# ArXiv eess --Wed, 28 Apr 2021
### 1.BeamLearning: an end-to-end Deep Learning approach for the angular localization of sound sources using raw multichannel acoustic pressure data  [ :arrow_down: ](https://arxiv.org/pdf/2104.13347.pdf)
>  Sound sources localization using multichannel signal processing has been a subject of active research for decades. In recent years, the use of deep learning in audio signal processing has allowed to drastically improve performances for machine hearing. This has motivated the scientific community to also develop machine learning strategies for source localization applications. In this paper, we present BeamLearning, a multi-resolution deep learning approach that allows to encode relevant information contained in unprocessed time domain acoustic signals captured by microphone arrays. The use of raw data aims at avoiding simplifying hypothesis that most traditional model-based localization methods rely on. Benefits of its use are shown for realtime sound source 2D-localization tasks in reverberating and noisy environments. Since supervised machine learning approaches require large-sized, physically realistic, precisely labelled datasets, we also developed a fast GPU-based computation of room impulse responses using fractional delays for image source models. A thorough analysis of the network representation and extensive performance tests are carried out using the BeamLearning network with synthetic and experimental datasets. Obtained results demonstrate that the BeamLearning approach significantly outperforms the wideband MUSIC and SRP-PHAT methods in terms of localization accuracy and computational efficiency in presence of heavy measurement noise and reverberation.      
### 2.CAIM: Cooperative Angle of Arrival Estimation using the Ising Method  [ :arrow_down: ](https://arxiv.org/pdf/2104.13296.pdf)
>  This paper proposes a cooperative angle-of-arrival(AoA) estimation, taking advantage of co-processing channel state information (CSI) from a group of access points that receive signals of the same source. Since received signals are sparse, we use Compressive Sensing (CS) to address the AoA estimation problem. We formulate this problem as a penalized l0-norm minimization, reformulate it as an Ising energy problem, and solve it using Markov Chain Monte Carlo (MCMC). Simulation results show that our proposed method outperforms the existing methods in the literature.      
### 3.Evidential segmentation of 3D PET/CT images  [ :arrow_down: ](https://arxiv.org/pdf/2104.13293.pdf)
>  PET and CT are two modalities widely used in medical image analysis. Accurately detecting and segmenting lymphomas from these two imaging modalities are critical tasks for cancer staging and radiotherapy planning. However, this task is still challenging due to the complexity of PET/CT images, and the computation cost to process 3D data. In this paper, a segmentation method based on belief functions is proposed to segment lymphomas in 3D PET/CT images. The architecture is composed of a feature extraction module and an evidential segmentation (ES) module. The ES module outputs not only segmentation results (binary maps indicating the presence or absence of lymphoma in each voxel) but also uncertainty maps quantifying the classification uncertainty. The whole model is optimized by minimizing Dice and uncertainty loss functions to increase segmentation accuracy. The method was evaluated on a database of 173 patients with diffuse large b-cell lymphoma. Quantitative and qualitative results show that our method outperforms the state-of-the-art methods.      
### 4.Learning Markov models of fading channels in wireless control networks: a regression trees based approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.13280.pdf)
>  Finite-state Markov models are widely used for modeling wireless channels affected by a variety of non-idealities, ranging from shadowing to interference. In an industrial environment, the derivation of a Markov model based on the wireless communication physics can be prohibitive as it requires a complete knowledge of both the communication dynamics parameters and of the disturbances/interferers. In this work, a novel methodology is proposed to learn a Markov model of a fading channel via historical data of the signal-to-interference-plus-noise-ratio (SINR). Such methodology can be used to derive a Markov jump model of a wireless control network, and thus to design a stochastic optimal controller that takes into account the interdependence between the plant and the wireless channel dynamics. The proposed method is validated by comparing its prediction accuracy and control performance with those of a stationary finite-state Markov chain derived assuming perfect knowledge of the physical channel model and parameters of a WirelessHART point-to-point communication based on the IEEE-802.15.4 standard.      
### 5.Multiple radio frequency measurement with an improved frequency resolution based on stimulated Brillouin scattering with a reduced gain bandwidth  [ :arrow_down: ](https://arxiv.org/pdf/2104.13258.pdf)
>  A photonic-assisted multiple radio frequency (RF) measurement approach based on stimulated Brillouin scattering (SBS) and frequency-to-time mapping with high accuracy and high-frequency resolution is reported. A two-tone signal is single-sideband (SSB) modulated on an optical carrier via a dual-parallel Mach-Zehnder modulator to construct one SBS gain and two SBS losses for SBS gain bandwidth reduction. The unknown RF signal is also SSB modulated on a carrier that has been modulated by a sweep signal, thus the unknown RF signal is converted to a sweep optical signal along with the sweep optical carrier. The bandwidth-reduced SBS gain spectrum is detected by the sweep optical signals at different specific time, mapping the RF frequencies to the time domain. An experiment is performed. RF frequencies from 0.3 to 7.6 GHz are simultaneously measured with a root mean square error of less than 1 MHz. In addition, the frequency resolution of the measurement can be much lower than 10 MHz, which is now the best result in the RF frequency measurement methods employing the SBS effect.      
### 6.IATos: AI-powered pre-screening tool for COVID-19 from cough audio samples  [ :arrow_down: ](https://arxiv.org/pdf/2104.13247.pdf)
>  OBJECTIVE: Our objective is to evaluate the possibility of using cough audio recordings (spontaneous or simulated) to detect sound patterns in people who are diagnosed with COVID-19. The research question that led our work was: what is the sensitivity and specificity of a machine learning based COVID-19 cough classifier, using RT-PCR tests as gold standard? <br>SETTING: The audio samples that were collected for this study belong to individuals who were swabbed in the City of Buenos Aires in 20 public and 1 private facilities where RT-PCR studies were carried out on patients suspected of COVID, and 14 out-of-hospital isolation units for patients with confirmed COVID mild cases. The audios were collected through the Buenos Aires city government WhatsApp chatbot that was specifically designed to address citizen inquiries related to the coronavirus pandemic (COVID-19). <br>PARTICIPANTS: The data collected corresponds to 2821 individuals who were swabbed in the City of Buenos Aires, between August 11 and December 2, 2020. Individuals were divided into 1409 that tested positive for COVID-19 and 1412 that tested negative. From this sample group, 52.6% of the individuals were female and 47.4% were male. 2.5% were between the age of 0 and 20 , 61.1% between the age of 21 and 40 , 30.3% between the age of 41 and 60 and 6.1% were over 61 years of age. <br>RESULTS: Using the dataset of 2821 individuals our results showed that the neural network classifier was able to discriminate between the COVID-19 positive and the healthy coughs with an accuracy of 88%. This accuracy obtained during the training process was later tested and confirmed with a second dataset corresponding to 492 individuals.      
### 7.Three-Dimensional Embedded Attentive RNN (3D-EAR) Segmentor for Left Ventricle Delineation from Myocardial Velocity Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2104.13214.pdf)
>  Myocardial Velocity Mapping Cardiac MR (MVM-CMR) can be used to measure global and regional myocardial velocities with proved reproducibility. Accurate left ventricle delineation is a prerequisite for robust and reproducible myocardial velocity estimation. Conventional manual segmentation on this dataset can be time-consuming and subjective, and an effective fully automated delineation method is highly in demand. By leveraging recently proposed deep learning-based semantic segmentation approaches, in this study, we propose a novel fully automated framework incorporating a 3D-UNet backbone architecture with Embedded multichannel Attention mechanism and LSTM based Recurrent neural networks (RNN) for the MVM-CMR datasets (dubbed 3D-EAR segmentor). The proposed method also utilises the amalgamation of magnitude and phase images as input to realise an information fusion of this multichannel dataset and exploring the correlations of temporal frames via the embedded RNN. By comparing the baseline model of 3D-UNet and ablation studies with and without embedded attentive LSTM modules and various loss functions, we can demonstrate that the proposed model has outperformed the state-of-the-art baseline models with significant improvement.      
### 8.CPS Engineering: Gap Analysis and Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2104.13210.pdf)
>  Virtualization of computing and networking, IT-OT convergence, cybersecurity and AI-based enhancement of autonomy are significantly increasing the complexity of CPS and CPSoS. New challenges have emerged to demonstrate that these systems are safe and secure. We emphasize the role of control and emerging fields therein, like symbolic control or set-based fault-tolerant and decentralized control, to address safety. We have chosen three open verification problems we deem central in cost-effective development and certification of safety critical CPSoS. We review some promising threads of research that could lead in the long term to a scalable and powerful verification strategy. Its main components are set-based and invariant-based design, contracts, adversarial testing, algorithmic geometry of dynamics, and probabilistic estimation derived from compositional massive testing. To explore these orientations in collaborative projects, and to promote them in certification arenas, we propose to continue and upgrade an open innovation drone-based use case that originated from a collaborative research project in aeronautic certification reformation      
### 9.Practical Output Consensus of Nonlinear Heterogeneous Multi-Agent Systems with Limited Data Rate  [ :arrow_down: ](https://arxiv.org/pdf/2104.13179.pdf)
>  This paper investigates the consensus problem for nonlinear heterogeneous multi-agent systems with limited communication data rate. Each agent is modeled by a higher-order strict-feedback continuous-time system with unknown nonlinearities andexternal disturbance, and only the first state variable being measurable. Extended state observers (ESOs) are used to estimate the unmeasurable agent states and the unknown nonlinear dynamics. An ESO-based distributed output feedback protocol with dynamic encoding and decoding is then presented. It is shown that, for a connected undirected network, the proposed protocol guarantees practical output consensus, in which the steady-state consensus error can be made arbitrarily small. The ESO-based protocol also shapes the transient consensus performance, as it is capable of recovering the consensus performance of a linear counterpart with fully measurable states. Furthermore, we prove that for higher-order uncertain nonlinear multi-agent systems, consensus can be achieved with merely one bit information exchange between each pair of adjacent agents at each time step. Finally, simulations on third-order pendulum systems are given, which verify the theoretical results.      
### 10.dEchorate: a Calibrated Room Impulse Response Database for Echo-aware Signal Processing  [ :arrow_down: ](https://arxiv.org/pdf/2104.13168.pdf)
>  This paper presents dEchorate: a new database of measured multichannel Room Impulse Responses (RIRs) including annotations of early echo timings and 3D positions of microphones, real sources and image sources under different wall configurations in a cuboid room. These data provide a tool for benchmarking recent methods in echo-aware speech enhancement, room geometry estimation, RIR estimation, acoustic echo retrieval, microphone calibration, echo labeling and reflectors estimation. The database is accompanied with software utilities to easily access, manipulate and visualize the data as well as baseline methods for echo-related tasks.      
### 11.Quadratic Optimization-Based Nonlinear Control for Protein Conformation Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2104.13147.pdf)
>  Predicting the final folded structure of protein molecules and simulating their folding pathways is of crucial importance for designing viral drugs and studying diseases such as Alzheimer's at the molecular level. To this end, this paper investigates the problem of protein conformation prediction under the constraint of avoiding high-entropy-loss routes during folding. Using the well-established kinetostatic compliance (KCM)-based nonlinear dynamics of a protein molecule, this paper formulates the protein conformation prediction as a pointwise optimal control synthesis problem cast as a quadratic program (QP). It is shown that the KCM torques in the protein folding literature can be utilized for defining a reference vector field for the QP-based control generation problem. The resulting kinetostatic control torque inputs will be close to the KCM-based reference vector field and guaranteed to be constrained by a predetermined bound; hence, high-entropy-loss routes during folding are avoided while the energy of the molecule is decreased.      
### 12.Compressive Sampling Using a Pushframe Camera  [ :arrow_down: ](https://arxiv.org/pdf/2104.13085.pdf)
>  The recently described pushframe imager, a parallelized single pixel camera capturing with a pushbroom-like motion, is intrinsically suited to both remote-sensing and compressive sampling. It optically applies a 2D mask to the imaged scene, before performing light integration along a single spatial axis, but previous work has not made use of the architecture's potential for taking measurements sparsely. In this paper we develop a strongly performing static binarized noiselet compressive sampling mask design, tailored to pushframe hardware, allowing both a single exposure per motion time-step, and retention of 2D correlations in the scene. Results from simulated and real-world captures are presented, with performance shown to be similar to that of immobile -- and hence inappropriate for satellite use -- whole-scene imagers. A particular feature of our sampling approach is that the degree of compression can be varied without altering the pattern, and we demonstrate the utility of this for efficiently storing and transmitting multi-spectral images.      
### 13.Visualization of Linear Operations in the Spherical Harmonics Domain  [ :arrow_down: ](https://arxiv.org/pdf/2104.13069.pdf)
>  Linear operations on coefficients in the spherical harmonics (SH) transform domain which again yield SH-domain coefficients are an important toolset in many disciplines of research and engineering. They comprise rotations, spatially selective filters, and many other modifications for various applications, or describe a MIMO system's response to an excitation. It is of particular importance to characterize these operations both qualitatively and quantitatively, and make them accessible for people to work with. In this paper, we identify different key properties of such operations and propose a method for their visualization. With our proposed method, we succeed to show many important aspects of an operation in a single plot and give rise to a comprehensive interpretation of a system's behavior. In our evaluation, we show the potential of the proposed method on the basis of various practical examples from spatial audio signal processing, where SH-domain filtering is used to modify acoustic scenes given by higher-order Ambisonics signals.      
### 14.Ancillary Services Acquisition Model: considering market interactions in policy design  [ :arrow_down: ](https://arxiv.org/pdf/2104.13047.pdf)
>  A rapidly changing electricity sector requires adjusted and new ancillary services, which enable the secure and reliable operation of the electricity system. However, assessments and policy advice regarding ancillary services and market design lack methods to evaluate the complex interaction of markets and services. Therefore, this paper contributes an open-source agent-based model to test design options for ancillary services and electricity markets. The Ancillary Services Acquisition Model (ASAM) combines the agent-based modeling framework MESA with the toolbox Python for Power System Analysis (PyPSA). The model provides various design parameters per market and agent-specific strategies as well as detailed clearing algorithms for the day-ahead market, intra-day continuous trading, redispatch, and imbalances. Moreover, ASAM includes numerous policy performance indicators, including a novel price mark-up indicator and novel redispatch performance indicators. A stylized simulation scenario verified and validated the model and addressed a redispatch design question. The results displayed the following implications from order types in redispatch markets with multi-period all-or-none design: (1) The order design provides few risks for market parties, as orders are fully cleared. (2) Large orders may lead to dispatch ramps before and after the delivery period and may cause ramp-risk mark-ups as well as additional trading of imbalances on intra-day. (3) All-or-none design in a liquid situation leads to the over-procurement of redispatch by the grid operator, as orders cannot be partially activated. Moreover, it is likely that the grid operator induces imbalances to the system by incomplete redispatch activation (i.e. upward and downward redispatch volumes are not equal).      
### 15.An In-router Identification Scheme for Selective Discard of Video Packets  [ :arrow_down: ](https://arxiv.org/pdf/2104.13013.pdf)
>  High quality (HQ) video services occupy large portions of the total bandwidth and are among the main causes of congestion at network bottlenecks. Since video is resilient to data loss, throwing away less important video packets can ease network congestion with minimal damage to video quality and free up bandwidth for other data flows. Frame type is one of the features that can be used to determine the importance of video packets, but this information is stored in the packet payload. Due to limited processing power of devices in high throughput/speed networks, data encryption and user credibility issues, it is costly for the network to find the frame type of each packet. Therefore, a fast and reliable standalone method to recognize video packet types at network level is desired. This paper proposes a method to model the structure of live video streams in a network node which results in determining the frame type of each packet. It enables the network nodes to mark and if need be to discard less important video packets ahead of congestion, and therefore preserve video quality and free up bandwidth for more important packet types. The method does not need to read the IP layer payload and uses only the packet header data for decisions. Experimental results indicate while dropping packets under packet type prediction degrades video quality with respect to its true type by 0.5-3 dB, it has 7-20 dB improvement over when packets are dropped randomly.      
### 16.Accelerating Coordinate Descent via Active Set Selection for Device Activity Detection for Multi-Cell Massive Random Access  [ :arrow_down: ](https://arxiv.org/pdf/2104.12984.pdf)
>  We propose a computationally efficient algorithm for the device activity detection problem in the multi-cell massive multi-input multi-output (MIMO) system, where the active devices transmit their signature sequences to multiple BSs in multiple cells and all the BSs cooperate to detect the active devices. The device activity detection problem has been formulated as a maximum likelihood maximization (MLE) problem in the literature. The state-of-the-art algorithm for solving the problem is the (random) coordinate descent (CD) algorithm. However, the CD algorithm fails to exploit the special sparsity structure of the solution of the device activity detection problem, i.e., most of devices are not active in each time slot. In this paper, we propose a novel active set selection strategy to accelerate the CD algorithm and propose an efficient active set CD algorithm for solving the considered problem. Specifically, at each iteration, the proposed active set CD algorithm first selects a small subset of all devices, namely the active set, which contains a few devices that contribute the most to the deviation from the first-order optimality condition of the MLE problem thus potentially can provide the most improvement to the objective function, then applies the CD algorithm to perform the detection for the devices in the active set. Simulation results show that the proposed active set CD algorithm significantly outperforms the state-of-the-art CD algorithm in terms of the computational efficiency.      
### 17.Greedy Sensor Placement for Weighted Linear-Least Squares Estimation under Correlated Noise  [ :arrow_down: ](https://arxiv.org/pdf/2104.12951.pdf)
>  Optimization for sensor placement has been intensely studied to monitor complex, large scale systems, whereas one needs to overcome its intractable nature of the objective function for the optimization. In this study, a fast algorithm for greedy sensor selection is presented for a linear reduced-ordered reconstruction under the assumption of correlated noise on the sensor signals. The presented algorithm accomplishes the maximization of the determinant of the Fisher information matrix in the linear inverse problem, while this study firstly shows that the objective function with correlated noise is neither submodular nor supermodular. Efficient one-rank computations in the greedy selection procedure are introduced in both of the underdetermined and oversampled problem. Several numerical experiments show the effectiveness of the selection algorithm for its accuracy in the estimation of the states of large dimensional measurement data.      
### 18.Provably Convergent Learned Inexact Descent Algorithm for Low-Dose CT Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2104.12939.pdf)
>  We propose a provably convergent method, called Efficient Learned Descent Algorithm (ELDA), for low-dose CT (LDCT) reconstruction. ELDA is a highly interpretable neural network architecture with learned parameters and meanwhile retains convergence guarantee as classical optimization algorithms. To improve reconstruction quality, the proposed ELDA also employs a new non-local feature mapping and an associated regularizer. We compare ELDA with several state-of-the-art deep image methods, such as RED-CNN and Learned Primal-Dual, on a set of LDCT reconstruction problems. Numerical experiments demonstrate improvement of reconstruction quality using ELDA with merely 19 layers, suggesting the promising performance of ELDA in solution accuracy and parameter efficiency.      
### 19.Neuromimetic Control -- A Linear Model Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2104.12926.pdf)
>  Stylized models of the neurodynamics that underpin sensory motor control in animals are proposed and studied. The voluntary motions of animals are typically initiated by high level intentions created in the primary cortex through a combination of perceptions of the current state of the environment along with memories of past reactions to similar states. Muscle movements are produced as a result of neural processes in which the parallel activity of large multiplicities of neurons generate signals that collectively lead to desired actions. Essential to coordinated muscle movement are intentionality, prediction, regions of the cortex dealing with misperceptions of sensory cues, and a significant level of resilience with respect to disruptions in the neural pathways through which signals must propagate. While linear models of feedback control systems have been well studied over many decades, this paper proposes and analyzes a class of models whose aims are to capture some of the essential features of neural control of movement. Whereas most linear models of feedback systems entail a state component whose dimension is higher than the number of inputs or outputs, the work that follows will treat models in which the numbers of input and output channels greatly exceed the state dimension. While we begin by considering continuous-time systems governed by differential equations, the aim will be to treat systems whose evolution involves classes of inputs that emulate neural spike trains. Within the proposed class of models, the paper will study resilience to channel dropouts, the ways in which noise and uncertainty can be mitigated by an appropriate notion of consensus among noisy inputs, and finally, by simple models of predictive control in which errors are fed back to adjust the weights given to inputs from different channels.      
### 20.Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2104.12870.pdf)
>  Confidence scores are very useful for downstream applications of automatic speech recognition (ASR) systems. Recent works have proposed using neural networks to learn word or utterance confidence scores for end-to-end ASR. In those studies, word confidence by itself does not model deletions, and utterance confidence does not take advantage of word-level training signals. This paper proposes to jointly learn word confidence, word deletion, and utterance confidence. Empirical results show that multi-task learning with all three objectives improves confidence metrics (NCE, AUC, RMSE) without the need for increasing the model size of the confidence estimation module. Using the utterance-level confidence for rescoring also decreases the word error rates on Google's Voice Search and Long-tail Maps datasets by 3-5% relative, without needing a dedicated neural rescorer.      
### 21.Multi-Density Attention Network for Loop Filtering in Video Compression  [ :arrow_down: ](https://arxiv.org/pdf/2104.12865.pdf)
>  Video compression is a basic requirement for consumer and professional video applications alike. Video coding standards such as H.264/AVC and H.265/HEVC are widely deployed in the market to enable efficient use of bandwidth and storage for many video applications. To reduce the coding artifacts and improve the compression efficiency, neural network based loop filtering of the reconstructed video has been developed in the literature. However, loop filtering is a challenging task due to the variation in video content and sampling densities. In this paper, we propose a on-line scaling based multi-density attention network for loop filtering in video compression. The core of our approach lies in several aspects: (a) parallel multi-resolution convolution streams for extracting multi-density features, (b) single attention branch to learn the sample correlations and generate mask maps, (c) a channel-mutual attention procedure to fuse the data from multiple branches, (d) on-line scaling technique to further optimize the output results of network according to the actual signal. The proposed multi-density attention network learns rich features from multiple sampling densities and performs robustly on video content of different resolutions. Moreover, the online scaling process enhances the signal adaptability of the off-line pre-trained model. Experimental results show that 10.18% bit-rate reduction at the same video quality can be achieved over the latest Versatile Video Coding (VVC) standard. The objective performance of the proposed algorithm outperforms the state-of-the-art methods and the subjective quality improvement is obvious in terms of detail preservation and artifact alleviation.      
### 22.Advances on image interpolation based on ant colony algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2104.12863.pdf)
>  This paper presents an advance on image interpolation based on ant colony algorithm (AACA) for high-resolution image scaling. The difference between the proposed algorithm and the previously proposed optimization of bilinear interpolation based on ant colony algorithm (OBACA) is that AACA uses global weighting, whereas OBACA uses a local weighting scheme. The strength of the proposed global weighting of the AACA algorithm depends on employing solely the pheromone matrix information present on any group of four adjacent pixels to decide which case deserves a maximum global weight value or not. Experimental results are further provided to show the higher performance of the proposed AACA algorithm with reference to the algorithms mentioned in this paper.      
### 23.A digital score of tumour-associated stroma infiltrating lymphocytes predicts survival in head and neck squamous cell carcinoma  [ :arrow_down: ](https://arxiv.org/pdf/2104.12862.pdf)
>  The infiltration of T-lymphocytes in the stroma and tumour is an indication of an effective immune response against the tumour, resulting in better survival. In this study, our aim is to explore the prognostic significance of tumour-associated stroma infiltrating lymphocytes (TASILs) in head and neck squamous cell carcinoma (HNSCC) through an AI based automated method. A deep learning based automated method was employed to segment tumour, stroma and lymphocytes in digitally scanned whole slide images of HNSCC tissue slides. The spatial patterns of lymphocytes and tumour-associated stroma were digitally quantified to compute the TASIL-score. Finally, prognostic significance of the TASIL-score for disease-specific and disease-free survival was investigated with the Cox proportional hazard analysis. Three different cohorts of Haematoxylin &amp; Eosin (H&amp;E) stained tissue slides of HNSCC cases (n=537 in total) were studied, including publicly available TCGA head and neck cancer cases. The TASIL-score carries prognostic significance (p=0.002) for disease-specific survival of HNSCC patients. The TASIL-score also shows a better separation between low- and high-risk patients as compared to the manual TIL scoring by pathologists for both disease-specific and disease-free survival. A positive correlation of TASIL-score with molecular estimates of CD8+ T cells was also found, which is in line with existing findings. To the best of our knowledge, this is the first study to automate the quantification of TASIL from routine H&amp;E slides of head and neck cancer. Our TASIL-score based findings are aligned with the clinical knowledge with the added advantages of objectivity, reproducibility and strong prognostic value. A comprehensive evaluation on large multicentric cohorts is required before the proposed digital score can be adopted in clinical practice.      
### 24.A MIMO approach for Weather Radars  [ :arrow_down: ](https://arxiv.org/pdf/2104.12859.pdf)
>  This article develops the multiple-input multiple-output (MIMO) technology for weather radar sensing. There are ample advantages of MIMO that have been highlighted that can improve the spatial resolution of the observations and also the accuracy of the radar variables. These concepts have been introduced here pertaining to weather radar observations with supporting simulations demonstrating improvements to existing phased array technology. Already MIMO is being used in a big way for hard target detection and tracking and also in the automotive radar industry and it offers similar improvements for weather radar observations. Some of the benefits are discussed here with a phased array platform in mind which offers quadrant outputs.      
### 25.Control of Mechanical Systems via Feedback Linearization Based on Black-Box Gaussian Process Models  [ :arrow_down: ](https://arxiv.org/pdf/2104.12854.pdf)
>  In this paper, we consider the use of black-box Gaussian process (GP) models for trajectory tracking control based on feedback linearization, in the context of mechanical systems. We considered two strategies. The first computes the control input directly by using the GP model, whereas the second computes the input after estimating the individual components of the dynamics. We tested the two strategies on a simulated manipulator with seven degrees of freedom, also varying the GP kernel choice. Results show that the second implementation is more robust w.r.t. the kernel choice and model inaccuracies. Moreover, as regards the choice of kernel, the obtained performance shows that the use of a structured kernel, such as a polynomial kernel, is advantageous, because of its effectiveness with both strategies.      
### 26.One-dimensional Active Contour Models for Raman Spectrum Baseline Correction  [ :arrow_down: ](https://arxiv.org/pdf/2104.12839.pdf)
>  Raman spectroscopy is a powerful and non-invasive method for analysis of chemicals and detection of unknown substances. However, Raman signal is so weak that background noise can distort the actual Raman signal. These baseline shifts that exist in the Raman spectrum might deteriorate analytical results. In this paper, a modified version of active contour models in one-dimensional space has been proposed for the baseline correction of Raman spectra. Our technique, inspired by principles of physics and heuristic optimization methods, iteratively deforms an initialized curve toward the desired baseline. The performance of the proposed algorithm was evaluated and compared with similar techniques using simulated Raman spectra. The results showed that the 1D active contour model outperforms many iterative baseline correction methods. The proposed algorithm was successfully applied to experimental Raman spectral data, and the results indicate that the baseline of Raman spectra can be automatically subtracted.      
### 27.Sufficient Lyapunov conditions for exponential mean square stability of discrete-time systems with markovian delays (extended version)  [ :arrow_down: ](https://arxiv.org/pdf/2104.12809.pdf)
>  This paper introduces sufficient Lyapunov conditions guaranteeing exponential mean square stability of discrete-time systems with markovian delays. We provide a transformation of the discrete-time system with markovian delays into a discrete-time Markov jump system. Then, we extend sufficient Lyapunov conditions existing for the global asymptotic stability of discrete-time systems with delays digraphs to the mean square stability of discrete-time systems with markovian delays. Finally, an example is provided to illustrate the efficiency and advantage of the proposed method.      
### 28.Explaining in Style: Training a GAN to explain a classifier in StyleSpace  [ :arrow_down: ](https://arxiv.org/pdf/2104.13369.pdf)
>  Image classification models can depend on multiple different semantic attributes of the image. An explanation of the decision of the classifier needs to both discover and visualize these properties. Here we present StylEx, a method for doing this, by training a generative model to specifically explain multiple attributes that underlie classifier decisions. A natural source for such attributes is the StyleSpace of StyleGAN, which is known to generate semantically meaningful dimensions in the image. However, because standard GAN training is not dependent on the classifier, it may not represent these attributes which are important for the classifier decision, and the dimensions of StyleSpace may represent irrelevant attributes. To overcome this, we propose a training procedure for a StyleGAN, which incorporates the classifier model, in order to learn a classifier-specific StyleSpace. Explanatory attributes are then selected from this space. These can be used to visualize the effect of changing multiple attributes per image, thus providing image-specific explanations. We apply StylEx to multiple domains, including animals, leaves, faces and retinal images. For these, we show how an image can be modified in different ways to change its classifier output. Our results show that the method finds attributes that align well with semantic ones, generate meaningful image-specific explanations, and are human-interpretable as measured in user-studies.      
### 29.NTIRE 2021 Depth Guided Image Relighting Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2104.13365.pdf)
>  Image relighting is attracting increasing interest due to its various applications. From a research perspective, image relighting can be exploited to conduct both image normalization for domain adaptation, and also for data augmentation. It also has multiple direct uses for photo montage and aesthetic enhancement. In this paper, we review the NTIRE 2021 depth guided image relighting challenge. <br>We rely on the VIDIT dataset for each of our two challenge tracks, including depth information. The first track is on one-to-one relighting where the goal is to transform the illumination setup of an input image (color temperature and light source position) to the target illumination setup. In the second track, the any-to-any relighting challenge, the objective is to transform the illumination settings of the input image to match those of another guide image, similar to style transfer. In both tracks, participants were given depth information about the captured scenes. We had nearly 250 registered participants, leading to 18 confirmed team submissions in the final competition stage. The competitions, methods, and final results are presented in this paper.      
### 30.An Event-based Parameter Switching Method for Controlling Cybersecurity Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2104.13339.pdf)
>  This paper proposes a new event-based parameter switching method for the control tasks of cybersecurity in the context of preventive and reactive cyber defense dynamics. Our parameter switching method helps avoid excessive control costs as well as guarantees the dynamics to converge as our desired speed. Meanwhile, it can be proved that this approach is Zeno-free. A new estimation method with adaptive time windows is used to bridge the gap between the probability state and the sampling state. With the new estimation method, several practical experiments are given afterwards.      
### 31.End-to-End Video-To-Speech Synthesis using Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.13332.pdf)
>  Video-to-speech is the process of reconstructing the audio speech from a video of a spoken utterance. Previous approaches to this task have relied on a two-step process where an intermediate representation is inferred from the video, and is then decoded into waveform audio using a vocoder or a waveform reconstruction algorithm. In this work, we propose a new end-to-end video-to-speech model based on Generative Adversarial Networks (GANs) which translates spoken video to waveform end-to-end without using any intermediate representation or separate waveform synthesis algorithm. Our model consists of an encoder-decoder architecture that receives raw video as input and generates speech, which is then fed to a waveform critic and a power critic. The use of an adversarial loss based on these two critics enables the direct synthesis of raw audio waveform and ensures its realism. In addition, the use of our three comparative losses helps establish direct correspondence between the generated audio and the input video. We show that this model is able to reconstruct speech with remarkable realism for constrained datasets such as GRID, and that it is the first end-to-end model to produce intelligible speech for LRW (Lip Reading in the Wild), featuring hundreds of speakers recorded entirely `in the wild'. We evaluate the generated samples in two different scenarios -- seen and unseen speakers -- using four objective metrics which measure the quality and intelligibility of artificial speech. We demonstrate that the proposed approach outperforms all previous works in most metrics on GRID and LRW.      
### 32.Downlink Precoding for DP-UPA FDD Massive MIMO via Multi-Dimensional Active Channel Sparsification  [ :arrow_down: ](https://arxiv.org/pdf/2104.13309.pdf)
>  In this paper, we consider user selection and downlink precoding for an over-loaded single-cell massive multiple-input multiple-output (MIMO) system in frequency division duplexing (FDD) mode, where the base station is equipped with a dual-polarized uniform planar array (DP-UPA) and serves a large number of single-antenna users. Due to the absence of uplink-downlink channel reciprocity and the high-dimensionality of channel matrices, it is extremely challenging to design downlink precoders using closed-loop channel probing and feedback with limited spectrum resource. To address these issues, a novel methodology -- active channel sparsification (ACS) -- has been proposed recently in the literature for uniform linear array (ULA) to design sparsifying precoders, which boosts spectral efficiency for multi-user downlink transmission with substantially reduced channel feedback overhead. Pushing forward this line of research, we aim to facilitate the potential deployment of ACS in practical FDD massive MIMO systems, by extending it from ULA to DP-UPA with explicit user selection and making the current ACS implementation simplified. To this end, by leveraging Toeplitz structure of channel covariance matrices, we extend the original ACS using scale-weight bipartite graph representation to the matrix-weight counterpart. Building upon this, we propose a multi-dimensional ACS (MD-ACS) method, which is a generalization of original ACS formulation and is more suitable for DP-UPA antenna configurations. The nonlinear integer program formulation of MD-ACS can be classified as a generalized multi-assignment problem (GMAP), for which we propose a simple yet efficient greedy algorithm to solve it. Simulation results demonstrate the performance improvement of the proposed MD-ACS with greedy algorithm over the state-of-the-art methods based on the QuaDRiGa channel models.      
### 33.MULTIMODAL ANALYSIS: Informed content estimation and audio source separation  [ :arrow_down: ](https://arxiv.org/pdf/2104.13276.pdf)
>  This dissertation proposes the study of multimodal learning in the context of musical signals. Throughout, we focus on the interaction between audio signals and text information. Among the many text sources related to music that can be used (e.g. reviews, metadata, or social network feedback), we concentrate on lyrics. The singing voice directly connects the audio signal and the text information in a unique way, combining melody and lyrics where a linguistic dimension complements the abstraction of musical instruments. Our study focuses on the audio and lyrics interaction for targeting source separation and informed content estimation.      
### 34.Batebit Controller: Popularizing Digital Musical Instruments Development Process  [ :arrow_down: ](https://arxiv.org/pdf/2104.13266.pdf)
>  In this paper, we present an ongoing research project related to popularizing the mindset of building new digital musical instruments. We developed a physical kit and software intended to provide beginner users with the first grasp on the development process of a digital musical instrument. We expect that, by using the kit and the software, the users could experiment in a short period the various steps in developing a DMI such as physical structure, electronics, programming, mapping, and sound design. Our approach to popularizing the DMI development process is twofold: reducing the cognitive load for beginners by encapsulating technical details and lowering the costs of the kit by using simple components and open-source software. In the end, we expect that by increasing the interest of beginners in the building process of digital musical instruments, we could make the community of new interfaces for musical expression stronger.      
### 35.Throughput Maximization for IRS-Assisted Wireless Powered Hybrid NOMA and TDMA  [ :arrow_down: ](https://arxiv.org/pdf/2104.13265.pdf)
>  The high reflect beamforming gain of the intelligent reflecting surface (IRS) makes it appealing not only for wireless information transmission but also for wireless power transfer. In this letter, we consider an IRS-assisted wireless powered communication network, where a base station (BS) transmits energy to multiple users grouped into multiple clusters in the downlink, and the clustered users transmit information to the BS in the manner of hybrid non-orthogonal multiple access and time division multiple access in the uplink. We investigate optimizing the reflect beamforming of the IRS and the time allocation among the BS's power transfer and different user clusters' information transmission to maximize the throughput of the network, and we propose an efficient algorithm based on the block coordinate ascent, semidefinite relaxation, and sequential rank-one constraint relaxation techniques to solve the resultant problem. Simulation results have verified the effectiveness of the proposed algorithm and have shown the impact of user clustering setup on the throughput performance of the network.      
### 36.UAV-Assisted Underwater Sensor Networks using RF and Optical Wireless Links  [ :arrow_down: ](https://arxiv.org/pdf/2104.13236.pdf)
>  Underwater sensor networks (UWSNs) are of interest to gather data from underwater sensor nodes (SNs) and deliver information to a terrestrial access point (AP) in the uplink transmission, and transfer data from the AP to the SNs in the downlink transmission. In this paper, we investigate a triple-hop UWSN in which autonomous underwater vehicle (AUV) and unmanned aerial vehicle (UAV) relays enable end-to-end communications between the SNs and the AP. It is assumed that the SN--AUV, AUV--UAV, and UAV--AP links are deployed by underwater optical communication (UWOC), free-space optic (FSO), and radio frequency (RF) technologies, respectively. Two scenarios are proposed for the FSO uplink and downlink transmissions between the AUV and the UAV, subject to water-to-air and air-to-water interface impacts; direct transmission scenario (DTS) and retro-reflection scenario (RRS). After providing the channel models and their statistics, the UWSN's outage probability and average bit error rate (BER) are computed. Besides, a tracking procedure is proposed to set up reliable and stable AUV--UAV FSO communications. Through numerical results, it is concluded that the RSS scheme outperforms the DTS one with about 200% (32%) and 80% (17%) better outage probability (average BER) in the uplink and downlink, respectively. It is also shown that the tracking procedure provides on average 480% and 170% improvements in the network's outage probability and average BER, respectively, compared to poorly aligned FSO conditions. The results are verified by applying Monte-Carlo simulations.      
### 37.Visually grounded models of spoken language: A survey of datasets, architectures and evaluation techniques  [ :arrow_down: ](https://arxiv.org/pdf/2104.13225.pdf)
>  This survey provides an overview of the evolution of visually grounded models of spoken language over the last 20 years. Such models are inspired by the observation that when children pick up a language, they rely on a wide range of indirect and noisy clues, crucially including signals from the visual modality co-occurring with spoken utterances. Several fields have made important contributions to this approach to modeling or mimicking the process of learning language: Machine Learning, Natural Language and Speech Processing, Computer Vision and Cognitive Science. The current paper brings together these contributions in order to provide a useful introduction and overview for practitioners in all these areas. We discuss the central research questions addressed, the timeline of developments, and the datasets which enabled much of this work. We then summarize the main modeling architectures and offer an exhaustive overview of the evaluation metrics and analysis techniques.      
### 38.Efficient channel charting via phase-insensitive distance computation  [ :arrow_down: ](https://arxiv.org/pdf/2104.13184.pdf)
>  Channel charting is an unsupervised learning task whose objective is to encode channels so that the obtained representation reflects the relative spatial locations of the corresponding users. It has many potential applications, ranging from user scheduling to proactive handover. In this paper, a channel charting method is proposed, based on a distance measure specifically designed to reduce the effect of small scale fading, which is an irrelevant phenomenon with respect to the channel charting task. A nonlinear dimensionality reduction technique aimed at preserving local distances (Isomap) is then applied to actually get the channel representation. The approach is empirically validated on realistic synthetic MIMO channels, achieving better results than previously proposed approaches, at a lower cost.      
### 39.Modeling and Coverage Analysis for RIS-aided NOMA Transmissions in Heterogeneous Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.13182.pdf)
>  Reconfigurable intelligent surface (RIS) has been regarded as a promising tool to strengthen the quality of signal transmissions in non-orthogonal multiple access (NOMA) networks. This article introduces a heterogeneous network (HetNet) structure into RIS-aided NOMA multi-cell networks. A practical user equipment (UE) association scheme for maximizing the average received power is adopted. To evaluate system performance, we provide a stochastic geometry based analytical framework, where the locations of RISs, base stations (BSs), and UEs are modeled as homogeneous Poisson point processes (PPPs). Based on this framework, we first derive the closed-form probability density function (PDF) to characterize the distribution of the reflective links created by RISs. Then, both the exact expressions and upper/lower bounds of UE association probability are calculated. Lastly, the analytical expressions of the signal-to-interference-plus-noise-ratio (SINR) and rate coverage probability are deduced. Additionally, to investigate the impact of RISs on system coverage, the asymptotic expressions of two coverage probabilities are derived. The theoretical results show that RIS length is not the decisive factor for coverage improvement. Numerical results demonstrate that the proposed RIS HetNet structure brings significant enhancement in rate coverage. Moreover, there exists an optimal combination of RISs and BSs deployment densities to maximize coverage probability.      
### 40.Generating Lead Sheets with Affect: A Novel Conditional seq2seq Framework  [ :arrow_down: ](https://arxiv.org/pdf/2104.13056.pdf)
>  The field of automatic music composition has seen great progress in the last few years, much of which can be attributed to advances in deep neural networks. There are numerous studies that present different strategies for generating sheet music from scratch. The inclusion of high-level musical characteristics (e.g., perceived emotional qualities), however, as conditions for controlling the generation output remains a challenge. In this paper, we present a novel approach for calculating the valence (the positivity or negativity of the perceived emotion) of a chord progression within a lead sheet, using pre-defined mood tags proposed by music experts. Based on this approach, we propose a novel strategy for conditional lead sheet generation that allows us to steer the music generation in terms of valence, phrasing, and time signature. Our approach is similar to a Neural Machine Translation (NMT) problem, as we include high-level conditions in the encoder part of the sequence-to-sequence architectures used (i.e., long-short term memory networks, and a Transformer network). We conducted experiments to thoroughly analyze these two architectures. The results show that the proposed strategy is able to generate lead sheets in a controllable manner, resulting in distributions of musical attributes similar to those of the training dataset. We also verified through a subjective listening test that our approach is effective in controlling the valence of a generated chord progression.      
### 41.Toward Blockchain for Edge-of-Things: A New Paradigm, Opportunities, and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2104.13049.pdf)
>  Blockchain is gaining momentum as a promising technology for many application domains, one of them being the Edge-of- Things (EoT) that is enabled by the integration of edge computing and the Internet-of-Things (IoT). Particularly, the amalgamation of blockchain and EoT leads to a new paradigm, called blockchain enabled EoT (BEoT) that is crucial for enabling future low-latency and high-security services and applications. This article envisions a novel BEoT architecture for supporting industrial applications under the management of blockchain at the network edge in a wide range of IoT use cases such as smart home, smart healthcare, smart grid, and smart transportation. The potentials of BEoT in providing security services are also explored, including access authentication, data privacy preservation, attack detection, and trust management. Finally, we point out some key research challenges and future directions in this emerging area.      
### 42.The music box operad: Random generation of musical phrases from patterns  [ :arrow_down: ](https://arxiv.org/pdf/2104.13040.pdf)
>  We introduce the notion of multi-pattern, a combinatorial abstraction of polyphonic musical phrases. The interest of this approach to encode musical phrases lies in the fact that it becomes possible to compose multi-patterns in order to produce new ones. This dives the set of musical phrases into an algebraic framework since the set of multi-patterns has the structure of an operad. Operads are algebraic structures offering a formalization of the notion of operators and their compositions. Seeing musical phrases as operators allows us to perform computations on phrases and admits applications in generative music. Indeed, given a set of short patterns, we propose various algorithms to randomly generate a new and longer phrase inspired by the inputted patterns.      
### 43.Structural Health Monitoring system with Narrowband IoT and MEMS sensors  [ :arrow_down: ](https://arxiv.org/pdf/2104.13029.pdf)
>  Monitoring of civil infrastructures is critically needed to track aging, damages and ultimately to prevent severe failures which can endanger many lives. The ability to monitor in a continuous and fine-grained fashion the integrity of a wide variety of buildings, referred to as structural health monitoring, with low-cost, long-term and continuous measurements is essential from both an economic and a life-safety standpoint. To address these needs, we propose a low-cost wireless sensor node specifically designed to support modal analysis over extended periods of time with long-range connectivity at low power consumption. Our design uses very cost-effective MEMS accelerometers and exploits the Narrowband IoT protocol (NB-IoT) to establish long-distance connection with 4G infrastructure networks. Long-range wireless connectivity, cabling-free installation and multi-year lifetime are a unique combination of features, not available, to the best of our knowledge, in any commercial or research device. We discuss in detail the hardware architecture and power management of the node. Experimental tests demonstrate a lifetime of more than ten years with a 17000 mAh battery or completely energy-neutral operation with a small solar panel (60 mm x 120 mm). Further, we validate measurement accuracy and confirm the feasibility of modal analysis with the MEMS sensors: compared with a high-precision instrument based on a piezoelectric transducer, our sensor node achieves a maximum difference of 0.08% at a small fraction of the cost and power consumption.      
### 44.Performance Analysis of Satellite Communication System Under the Shadowed-Rician Fading: A Stochastic Geometry Approach  [ :arrow_down: ](https://arxiv.org/pdf/2104.13010.pdf)
>  In this paper, we consider a downlink satellite communication system where multiple satellites are uniformly distributed over a sphere at a certain altitude. We analytically derive three things: 1) the satellite-visible probability for a given location, which is defined as the probability that a terminal sees at least one satellite above the minimum elevation angle, i.e., a pre-defined elevation angle above which the terminal can be served by a satellite, 2) the distribution of distance between the terminal and serving satellite when the terminal is associated with the nearest satellite, and 3) the exact expressions for the outage probability and throughput of the system. With the derived expressions, the system throughput maximization problem is formulated under the satellite-visibility and outage constraints. To solve the problem, we reformulate the problem with bounded feasible sets and obtain the optimal solution by using an exhaustive search. Using the Poisson limit theorem, we derive approximated expressions for the satellite-visible probability, outage probability, and system throughput, which reduce computational complexity of performance evaluation and search time for the optimal solution of the throughput maximization problem. Simulation results perfectly match the derived exact expressions for the outage probability and system throughput. It is also shown that the analytical results of the approximated expressions are fairly close to those of the exact expressions.      
### 45.DPT-FSNet:Dual-path Transformer Based Full-band and Sub-band Fusion Network for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2104.13002.pdf)
>  Recently, dual-path networks have achieved promising performance due to their ability to model local and global features of the input sequence. However, previous studies are based on simple time-domain features and do not fully investigate the impact of the input features of the dual-path network on the enhancement performance. In this paper, we propose a dual-path transformer-based full-band and sub-band fusion network (DPT-FSNet) for speech enhancement in the frequency domain. The intra and inter parts of the dual-path transformer network in our model can be seen as sub-band and full-band modeling respectively, which have stronger interpretability as well as more information compared to the features utilized by the time-domain transformer. We conducted experiments on the Voice Bank + DEMAND dataset to evaluate the proposed method. Experimental results show that the proposed method outperforms the current state-of-the-arts in terms of PESQ, STOI, CSIG, COVL. (The PESQ, STOI, CSIG, and COVL scores on the Voice Bank + DEMAND dataset were 3.30, 0.95, 4.51, and 3.94, respectively).      
### 46.Avalanche Photodetectors with Photon Trapping Structures for Biomedical Imaging Applications  [ :arrow_down: ](https://arxiv.org/pdf/2104.12981.pdf)
>  Enhancing photon detection efficiency and time resolution in photodetectors in the entire visible range is critical to improve the image quality of time-of-flight (TOF)-based imaging systems and fluorescence lifetime imaging (FLIM). In this work, we evaluate the gain, detection efficiency, and timing performance of avalanche photodiodes (APD) with photon trapping nanostructures for photons with 450 and 850 nm wavelengths. At 850 nm wavelength, our photon trapping avalanche photodiodes showed 30 times higher gain, an increase from 16% to &gt;60% enhanced absorption efficiency, and a 50% reduction in the full width at half maximum (FWHM) pulse response time close to the breakdown voltage. At 450 nm wavelength, the external quantum efficiency increased from 54% to 82%, while the gain was enhanced more than 20-fold. Therefore, silicon APDs with photon trapping structures exhibited a dramatic increase in absorption compared to control devices. Results suggest very thin devices with fast timing properties and high absorption between the near-ultraviolet and the near infrared region can be manufactured for high-speed applications in biomedical imaging. This study paves the way towards obtaining single photon detectors with photon trapping structures with gains above 10^6 for the entire visible range      
### 47.Realtime Mobile Bandwidth and Handoff Predictions in 4G/5G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2104.12959.pdf)
>  Mobile apps are increasingly relying on high-throughput and low-latency content delivery, while the available bandwidth on wireless access links is inherently time-varying. The handoffs between base stations and access modes due to user mobility present additional challenges to deliver a high level of user Quality-of-Experience (QoE). The ability to predict the available bandwidth and the upcoming handoffs will give applications valuable leeway to make proactive adjustments to avoid significant QoE degradation. In this paper, we explore the possibility and accuracy of realtime mobile bandwidth and handoff predictions in 4G/LTE and 5G networks. Towards this goal, we collect long consecutive traces with rich bandwidth, channel, and context information from public transportation systems. We develop Recurrent Neural Network models to mine the temporal patterns of bandwidth evolution in fixed-route mobility scenarios. Our models consistently outperform the conventional univariate and multivariate bandwidth prediction models. For 4G \&amp; 5G co-existing networks, we propose a new problem of handoff prediction between 4G and 5G, which is important for low-latency applications like self-driving strategy in realistic 5G scenarios. We develop classification and regression based prediction models, which achieve more than 80\% accuracy in predicting 4G and 5G handoffs in a recent 5G dataset.      
### 48.Navigation of a Self-Driving Vehicle Using One Fiducial Marker  [ :arrow_down: ](https://arxiv.org/pdf/2104.12954.pdf)
>  Navigation using only one marker, which contains four artificial features, is a challenging task since camera pose estimation using only four coplanar points suffers from the rotational ambiguity problem in a real-world application. This paper presents a framework of vision-based navigation for a self-driving vehicle equipped with multiple cameras and a wheel odometer. A multiple camera setup is presented for the camera cluster which has $360^{\circ}$ vision such that our framework solely requires one planar marker. A Kalman-Filter-based fusion method is introduced for the multiple-camera and wheel odometry. Furthermore, an algorithm is proposed to resolve the rotational ambiguity problem using the prediction of the Kalman Filter as additional information. Finally, the lateral and longitudinal controllers are provided. Experiments are conducted to illustrate the effectiveness of the theory.      
### 49.Quantitative Risk Indices for Autonomous Vehicle Training Systems  [ :arrow_down: ](https://arxiv.org/pdf/2104.12945.pdf)
>  The development of Autonomous Vehicles (AV) presents an opportunity to save and improve lives. However, achieving SAE Level 5 (full) autonomy will require overcoming many technical challenges. There is a gap in the literature regarding the measurement of safety for self-driving systems. Measuring safety and risk is paramount for the generation of useful simulation scenarios for training and validation of autonomous systems. The limitation of current approaches is the dependence on near-crash data. Although near-miss data can substantially increase scarce available accident data, the definition of a near-miss or near-crash is arbitrary. A promising alternative is the introduction of the Responsibility-Sensitive Safety (RSS) model by Shalev-Shwartz et al., which defines safe lateral and longitudinal distances that can guarantee impossibility of collision under reasonable assumptions for vehicle dynamics. We present a framework that extends the RSS model for cases when reasonable assumptions or safe distances are violated. The proposed framework introduces risk indices that quantify the likelihood of a collision by using vehicle dynamics and driver's risk aversion. The present study concludes with proposed experiments for tuning the parameters of the formulated risk indices.      
### 50.One Billion Audio Sounds from GPU-enabled Modular Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2104.12922.pdf)
>  We release synth1B1, a multi-modal audio corpus consisting of 1 billion 4-second synthesized sounds, which is 100x larger than any audio dataset in the literature. Each sound is paired with the corresponding latent parameters used to generate it. synth1B1 samples are deterministically generated on-the-fly 16200x faster than real-time (714MHz) on a single GPU using torchsynth (<a class="link-external link-https" href="https://github.com/torchsynth/torchsynth" rel="external noopener nofollow">this https URL</a>), an open-source modular synthesizer we release. Additionally, we release two new audio datasets: FM synth timbre (<a class="link-external link-https" href="https://zenodo.org/record/4677102" rel="external noopener nofollow">this https URL</a>) and subtractive synth pitch (<a class="link-external link-https" href="https://zenodo.org/record/4677097" rel="external noopener nofollow">this https URL</a>). Using these datasets, we demonstrate new rank-based synthesizer-motivated evaluation criteria for existing audio representations. Finally, we propose novel approaches to synthesizer hyperparameter optimization, and demonstrate how perceptually-correlated auditory distances could enable new applications in synthesizer design.      
### 51.Energy Savings by Task Offloading to a Fog Considering Radio Front-End Characteristics  [ :arrow_down: ](https://arxiv.org/pdf/2104.12913.pdf)
>  Fog computing can be used to offload computationally intensive tasks from battery powered Internet of Things (IoT) devices. Although it reduces energy required for computations in an IoT device, it uses energy for communications with the fog. This paper analyzes when usage of fog computing is more energy efficient than local computing. Detailed energy consumption models are built in both scenarios with the focus set on the relation between energy consumption and distortion introduced by a Power Amplifier (PA). Numerical results show that task offloading to a fog is the most energy efficient for short, wideband links.      
### 52.Multi-resource allocation for federated settings: A non-homogeneous Markov chain model  [ :arrow_down: ](https://arxiv.org/pdf/2104.12828.pdf)
>  In a federated setting, agents coordinate with a central agent or a server to solve an optimization problem in which agents do not share their information with each other. Wirth and his co-authors, in a recent paper, describe how the basic additive-increase multiplicative-decrease (AIMD) algorithm can be modified in a straightforward manner to solve a class of optimization problems for federated settings for a single shared resource with no inter-agent communication. The AIMD algorithm is one of the most successful distributed resource allocation algorithms currently deployed in practice. It is best known as the backbone of the Internet and is also widely explored in other application areas. We extend the single-resource algorithm to multiple heterogeneous shared resources that emerge in smart cities, sharing economy, and many other applications. Our main results show the convergence of the average allocations to the optimal values. We model the system as a non-homogeneous Markov chain with place-dependent probabilities. Furthermore, simulation results are presented to demonstrate the efficacy of the algorithms and to highlight the main features of our analysis.      
### 53.Multimodal Self-Supervised Learning of General Audio Representations  [ :arrow_down: ](https://arxiv.org/pdf/2104.12807.pdf)
>  We present a multimodal framework to learn general audio representations from videos. Existing contrastive audio representation learning methods mainly focus on using the audio modality alone during training. In this work, we show that additional information contained in video can be utilized to greatly improve the learned features. First, we demonstrate that our contrastive framework does not require high resolution images to learn good audio features. This allows us to scale up the training batch size, while keeping the computational load incurred by the additional video modality to a reasonable level. Second, we use augmentations that mix together different samples. We show that this is effective to make the proxy task harder, which leads to substantial performance improvements when increasing the batch size. As a result, our audio model achieves a state-of-the-art of 42.4 mAP on the AudioSet classification downstream task, closing the gap between supervised and self-supervised methods trained on the same dataset. Moreover, we show that our method is advantageous on a broad range of non-semantic audio tasks, including speaker identification, keyword spotting, language identification, and music instrument classification.      
### 54.Adaptive Encoding for Constrained Video Delivery in HEVC, VP9, AV1 and VVC Compression Standards and Adaptation to Video Content  [ :arrow_down: ](https://arxiv.org/pdf/2104.12770.pdf)
>  The dissertation proposes the use of a multi-objective optimization framework for designing and selecting among enhanced GOP configurations in video compression standards. The proposed methods achieve fine optimization over a set of general modes that include: (i) maximum video quality, (ii) minimum bitrate, (iii) maximum encoding rate (previously minimum encoding time mode) and (iv) can be shown to improve upon the YouTube/Netflix default encoder mode settings over a set of opposing constraints to guarantee satisfactory performance. The dissertation describes the implementation of a codec-agnostic approach using different video coding standards (x265, VP9, AV1) on a wide range of videos derived from different video datasets. The results demonstrate that the optimal encoding parameters obtained from the Pareto front space can provide significant bandwidth savings without sacrificing video quality. This is achieved by the use of effective regression models that allow for the selection of video encoding settings that are jointly optimal in the encoding time, bitrate, and video quality space. The dissertation applies the proposed methods to x265, VP9, AV1 and using new GOP configurations in x265, delivering over 40% of the optimal encodings in two standard reference videos.      

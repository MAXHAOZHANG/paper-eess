# ArXiv eess --Fri, 18 Jun 2021
### 1.Automatic Segmentation of the Prostate on 3D Trans-rectal Ultrasound Images using Statistical Shape Models and Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.09662.pdf)
>  In this work we propose to segment the prostate on a challenging dataset of trans-rectal ultrasound (TRUS) images using convolutional neural networks (CNNs) and statistical shape models (SSMs). TRUS is commonly used for a number of image-guided interventions on the prostate. Fast and accurate segmentation on the organ in these images is crucial to planning and fusion with other modalities such as magnetic resonance images (MRIs) . However, TRUS has limited soft tissue contrast and signal to noise ratio which makes the task of segmenting the prostate challenging and subject to inter-observer and intra-observer variability. This is especially problematic at the base and apex where the gland boundary is hard to define. In this paper, we aim to tackle this problem by taking advantage of shape priors learnt on an MR dataset which has higher soft tissue contrast allowing the prostate to be contoured more accurately. We use this shape prior in combination with a prostate tissue probability map computed by a CNN for segmentation.      
### 2.WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.09660.pdf)
>  This paper introduces WaveGrad 2, a non-autoregressive generative model for text-to-speech synthesis. WaveGrad 2 is trained to estimate the gradient of the log conditional density of the waveform given a phoneme sequence. The model takes an input phoneme sequence, and through an iterative refinement process, generates an audio waveform. This contrasts to the original WaveGrad vocoder which conditions on mel-spectrogram features, generated by a separate model. The iterative refinement process starts from Gaussian noise, and through a series of refinement steps (e.g., 50 steps), progressively recovers the audio sequence. WaveGrad 2 offers a natural way to trade-off between inference speed and sample quality, through adjusting the number of refinement steps. Experiments show that the model can generate high fidelity audio, approaching the performance of a state-of-the-art neural TTS system. We also report various ablation studies over different model configurations. Audio samples are available at <a class="link-external link-https" href="https://wavegrad.github.io/v2" rel="external noopener nofollow">this https URL</a>.      
### 3.Robustness and Consistency in Linear Quadratic Control with Predictions  [ :arrow_down: ](https://arxiv.org/pdf/2106.09659.pdf)
>  We study the problem of learning-augmented predictive linear quadratic control. Our goal is to design a controller that balances consistency, which measures the competitive ratio when predictions are accurate, and robustness, which bounds the competitive ratio when predictions are inaccurate. We propose a novel $\lambda$-confident controller and prove that it maintains a competitive ratio upper bound of $1+\min\{O(\lambda^2\varepsilon)+ O(1-\lambda)^2,O(1)+O(\lambda^2)\}$ where $\lambda\in [0,1]$ is a trust parameter set based on the confidence in the predictions, and $\varepsilon$ is the prediction error. Further, we design a self-tuning policy that adaptively learns the trust parameter $\lambda$ with a regret that depends on $\varepsilon$ and the variation of perturbations and predictions.      
### 4.Microgrid Resilience: A Holistic and Context-Aware Resilience Metric  [ :arrow_down: ](https://arxiv.org/pdf/2106.09640.pdf)
>  Microgrids present an effective solution for the coordinated deployment of various distributed energy resources and furthermore provide myriad additional benefits such as resilience, decreased carbon footprint, and reliability to energy consumers and the energy system as a whole. Boosting the resilience of distribution systems is another major benefit of microgrids. This is because they can also serve as a backup power source when the utility grid operations are interrupted due to either high-probability low-impact events like a component failure or low-probability high-impact events - be it a natural disaster or a planned cyberattack. However, the degree to which any particular system can defend, adapt, and restore normal operation depends on various factors including the type and severity of events to which a microgrid is subjected. These factors, in turn, are dependent on the geographical location of the deployed microgrid as well as the cyber risk profile of the site where the microgrid is operating. Therefore, in this work, we attempt to capture this multi-dimensional interplay of various factors in quantifying the ability of the microgrid to be resilient in these varying aspects. This paper, thus, proposes a customized site-specific quantification of the resilience strength for the individual microgrid capability to absorb, restore, and adapt to the changing circumstances for sustaining the critical load when a low-probability high-impact event occurs - termed as - context-aware resilience metric. We also present a case study to illustrate the key elements of our integrated analytical approach.      
### 5.An Endless Optical Phase Delay for Phase Synchronization in High-Capacity DCIs  [ :arrow_down: ](https://arxiv.org/pdf/2106.09634.pdf)
>  In this work, we propose and demonstrate a module to linearly add an arbitrary amount of continuous (reset-free) phase delay to an optical signal. The proposed endless optical phase delay (EOPD) uses an optical IQ modulator and control electronics (CE) to add the desired amount of phase delay that can continuously increase with time. In order to adjust for the bias voltages and control voltage amplitudes in the EOPD, some of which may be time varying, a multivariate gradient descent algorithm is used. The EOPD has been demonstrated experimentally, and its use in a high-capacity data center interconnect (DCI) application has been outlined in this letter. The EOPD may find its use in many other applications that require precise phase/frequency adjustments in real-time.      
### 6.Probabilistic Stability Assessment for Active Distribution Grids  [ :arrow_down: ](https://arxiv.org/pdf/2106.09624.pdf)
>  This paper demonstrates the concept of probabilistic stability assessment on large-signal stability in the use case of short circuits in an active distribution grid. Here, the concept of survivability is applied, which extends classical stability assessments by evaluating the stability and operational limits during transients for a wide range of operating points and failures. For this purpose, a free, open-source, and computationally efficient environment (Julia) for dynamic simulation of power grids is used to demonstrate its capabilities. The model implementation is validated against established commercial software and deviations are minimal with respect to power flow and dynamic simulations.The results of a large-scale survivability analysis reveal i) a broad field of application for probabilistic stability analysis and ii) that new non-intuitive stability correlations can be obtained. Hence,the proposed method shows strong potential to efficiently conduct power system stability analysis in active distribution grids.      
### 7.Extracting Different Levels of Speech Information from EEG Using an LSTM-Based Model  [ :arrow_down: ](https://arxiv.org/pdf/2106.09622.pdf)
>  Decoding the speech signal that a person is listening to from the human brain via electroencephalography (EEG) can help us understand how our auditory system works. Linear models have been used to reconstruct the EEG from speech or vice versa. Recently, Artificial Neural Networks (ANNs) such as Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) based architectures have outperformed linear models in modeling the relation between EEG and speech. Before attempting to use these models in real-world applications such as hearing tests or (second) language comprehension assessment we need to know what level of speech information is being utilized by these models. In this study, we aim to analyze the performance of an LSTM-based model using different levels of speech features. The task of the model is to determine which of two given speech segments is matched with the recorded EEG. We used low- and high-level speech features including: envelope, mel spectrogram, voice activity, phoneme identity, and word embedding. Our results suggest that the model exploits information about silences, intensity, and broad phonetic classes from the EEG. Furthermore, the mel spectrogram, which contains all this information, yields the highest accuracy (84%) among all the features.      
### 8.Deep Reinforcement Learning Based Optimization for IRS Based UAV-NOMA Downlink Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.09616.pdf)
>  This paper investigates the application of deep deterministic policy gradient (DDPG) to intelligent reflecting surface (IRS) based unmanned aerial vehicles (UAV) assisted non-orthogonal multiple access (NOMA) downlink networks. The deployment of the UAV equipped with an IRS is important, as the UAV increases the flexibility of the IRS significantly, especially for the case of users who have no line of sight (LoS) path to the base station (BS). Therefore, the aim of this letter is to maximize the sum rate by jointly optimizing the power allocation of the BS, the phase shifting of the IRS and the horizontal position of the UAV. Because the formulated problem is not convex, the DDPG algorithm is utilized to solve it. The computer simulation results are provided to show the superior performance of the proposed DDPG based algorithm.      
### 9.A Reinforcement Learning Approach for an IRS-assisted NOMA Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.09611.pdf)
>  This letter investigates a sum rate maximizationproblem in an intelligent reflective surface (IRS) assisted non-orthogonal multiple access (NOMA) downlink network. Specif-ically, the sum rate of all the users is maximized by jointlyoptimizing the beams at the base station and the phase shiftat the IRS. The deep reinforcement learning (DRL), which hasachieved massive successes, is applied to solve this sum ratemaximization problem. In particular, an algorithm based on thedeep deterministic policy gradient (DDPG) is proposed. Both therandom channel case and the fixed channel case are studied inthis letter. The simulation result illustrates that the DDPG basedalgorithm has the competitive performance on both case.      
### 10.Localization based on enhanced low frequency interaural level difference  [ :arrow_down: ](https://arxiv.org/pdf/2106.09574.pdf)
>  The processing of low-frequency interaural time differences is found to be problematic among hearing-impaired people. The current generation of beamformers does not consider this deficiency. In an attempt to tackle this issue, we propose to replace the inaudible interaural time differences in the low-frequency region with the interaural level differences. In addition, a beamformer is introduced and analyzed, which enhances the low-frequency interaural level differences of the sound sources using a near-field transformation. The proposed beamforming problem is relaxed to a convex problem using semi-definite relaxation. The instrumental analysis suggests that the low-frequency interaural level differences are enhanced without hindering the provided intelligibility. A psychoacoustic localization test is done using a listening experiment, which suggests that the replacement of time differences into level differences improves the localization performance of normal-hearing listeners for an anechoic scene but not for a reverberant scene.      
### 11.Guided Nonlocal Means Estimation of Polarimetric Covariance for Canopy State Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.09550.pdf)
>  We have developed a nonlocal algorithm for estimating polarimetric synthetic aperture radar (PolSAR) covariance matrices on single-look complex (SLC) format resolution. The algorithm is inspired by recent work with guided nonlocal means (NLM) speckle filtering, where a co-registered optical image is used to aid the filtering. Based on patch-wise dissimilarities in the SAR and optical domains we set the weights used for the nonlocal average of the outer product of the lexicographic target vectors which form the estimate. By use of this method we show that the estimated covariance matrices preserve the local structure better than previous filtering methods and improve the separation of live from defoliated and dead forest. The detail preserving nature of the algorithm also means that it can be applicable in other settings where preserving the SLC format resolution is necessary.      
### 12.STAN: A stuttering therapy analysis helper  [ :arrow_down: ](https://arxiv.org/pdf/2106.09545.pdf)
>  Stuttering is a complex speech disorder identified by repeti-tions, prolongations of sounds, syllables or words and blockswhile speaking. Specific stuttering behaviour differs strongly,thus needing personalized therapy. Therapy sessions requirea high level of concentration by the therapist. We introduceSTAN, a system to aid speech therapists in stuttering therapysessions. Such an automated feedback system can lower thecognitive load on the therapist and thereby enable a more con-sistent therapy as well as allowing analysis of stuttering overthe span of multiple therapy sessions.      
### 13.Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit  [ :arrow_down: ](https://arxiv.org/pdf/2106.09539.pdf)
>  Researchers have recently started to study how the emotional speech heard by young infants can affect their developmental outcomes. As a part of this research, hundreds of hours of daylong recordings from preterm infants' audio environments were collected from two hospitals in Finland and Estonia in the context of so-called APPLE study. In order to analyze the emotional content of speech in such a massive dataset, an automatic speech emotion recognition (SER) system is required. However, there are no emotion labels or existing indomain SER systems to be used for this purpose. In this paper, we introduce this initially unannotated large-scale real-world audio dataset and describe the development of a functional SER system for the Finnish subset of the data. We explore the effectiveness of alternative state-of-the-art techniques to deploy a SER system to a new domain, comparing cross-corpus generalization, WGAN-based domain adaptation, and active learning in the task. As a result, we show that the best-performing models are able to achieve a classification performance of 73.4% unweighted average recall (UAR) and 73.2% UAR for a binary classification for valence and arousal, respectively. The results also show that active learning achieves the most consistent performance compared to the two alternatives.      
### 14.ASR Adaptation for E-commerce Chatbots using Cross-Utterance Context and Multi-Task Language Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2106.09532.pdf)
>  Automatic Speech Recognition (ASR) robustness toward slot entities are critical in e-commerce voice assistants that involve monetary transactions and purchases. Along with effective domain adaptation, it is intuitive that cross utterance contextual cues play an important role in disambiguating domain specific content words from speech. In this paper, we investigate various techniques to improve contextualization, content word robustness and domain adaptation of a Transformer-XL neural language model (NLM) to rescore ASR N-best hypotheses. To improve contextualization, we utilize turn level dialogue acts along with cross utterance context carry over. Additionally, to adapt our domain-general NLM towards e-commerce on-the-fly, we use embeddings derived from a finetuned masked LM on in-domain data. Finally, to improve robustness towards in-domain content words, we propose a multi-task model that can jointly perform content word detection and language modeling tasks. Compared to a non-contextual LSTM LM baseline, our best performing NLM rescorer results in a content WER reduction of 19.2% on e-commerce audio test set and a slot labeling F1 improvement of 6.4%.      
### 15.The promise of energy-efficient battery-powered urban aircraft  [ :arrow_down: ](https://arxiv.org/pdf/2106.09513.pdf)
>  Improvements in rechargeable batteries are enabling several electric urban air mobility (UAM) aircraft designs with up to 300 miles of range with payload equivalents of up to 7 passengers. We find that novel UAM aircraft consume between 130 Wh/passenger-mile up to ~1,200 Wh/passenger-mile depending on the design and utilization, relative to an expected consumption of over 220 Wh/passenger-mi for terrestrial electric vehicles and 1,000 Wh/passenger-mile for combustion engine vehicles. We also find that several UAM aircraft designs are approaching technological viability with current Li-ion batteries, based on the specific power-and-energy while rechargeability and lifetime performance remain uncertain. These aspects highlight the technological readiness of a new segment of transportation.      
### 16.Scaling Laws for Acoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2106.09488.pdf)
>  There is a recent trend in machine learning to increase model quality by growing models to sizes previously thought to be unreasonable. Recent work has shown that autoregressive generative models with cross-entropy objective functions exhibit smooth power-law relationships, or scaling laws, that predict model quality from model size, training set size, and the available compute budget. These scaling laws allow one to choose nearly optimal hyper-parameters given constraints on available training data, model parameter count, or training computation budget. In this paper, we demonstrate that acoustic models trained with an auto-predictive coding loss behave as if they are subject to similar scaling laws. We extend previous work to jointly predict loss due to model size, to training set size, and to the inherent "irreducible loss" of the task. We find that the scaling laws accurately match model performance over two orders of magnitude in both model size and training set size, and make predictions about the limits of model performance.      
### 17.A New Dissipativity Condition for Asymptotic Stability of Discounted Economic MPC  [ :arrow_down: ](https://arxiv.org/pdf/2106.09377.pdf)
>  Economic Model Predictive Control has recently gained popularity due to its ability to directly optimize a given performance criterion, while enforcing constraint satisfaction for nonlinear systems. Recent research has developed both numerical algorithms and stability analysis for the undiscounted case. The introduction of a discount factor in the cost, however, can be desirable in some cases of interest, e.g., economics, stochastically terminating processes, Markov decision processes, etc. Unfortunately, the stability theory in this case is still not fully developed. In this paper we propose a new dissipativity condition to prove asymptotic stability in the infinite horizon case and we connect our results with existing ones in the literature on discounted economic optimal control. Numerical examples are provided to illustrate the theoretical results.      
### 18.Minimax Estimation of Partially-Observed Vector AutoRegressions  [ :arrow_down: ](https://arxiv.org/pdf/2106.09327.pdf)
>  To understand the behavior of large dynamical systems like transportation networks, one must often rely on measurements transmitted by a set of sensors, for instance individual vehicles. Such measurements are likely to be incomplete and imprecise, which makes it hard to recover the underlying signal of interest.Hoping to quantify this phenomenon, we study the properties of a partially-observed state-space model. In our setting, the latent state $X$ follows a high-dimensional Vector AutoRegressive process $X_t = \theta X_{t-1} + \varepsilon_t$. Meanwhile, the observations $Y$ are given by a noise-corrupted random sample from the state $Y_t = \Pi_t X_t + \eta_t$. Several random sampling mechanisms are studied, allowing us to investigate the effect of spatial and temporal correlations in the distribution of the sampling matrices $\Pi_t$.We first prove a lower bound on the minimax estimation error for the transition matrix $\theta$. We then describe a sparse estimator based on the Dantzig selector and upper bound its non-asymptotic error, showing that it achieves the optimal convergence rate for most of our sampling mechanisms. Numerical experiments on simulated time series validate our theoretical findings, while an application to open railway data highlights the relevance of this model for public transport traffic analysis.      
### 19.Precoding Design for Multi-user MIMO Systems with Delay-Constrained and -Tolerant Users  [ :arrow_down: ](https://arxiv.org/pdf/2106.09322.pdf)
>  In both academia and industry, multi-user multiple-input multiple-output (MU-MIMO) techniques have shown enormous gains in spectral efficiency by exploiting spatial degrees of freedom. So far, an underlying assumption in most of the existing MU-MIMO design has been that all the users use infinite blocklength, so that they can achieve the Shannon capacity. This setup, however, is not suitable considering delay-constrained users whose blocklength tends to be finite. In this paper, we consider a heterogeneous setting in MU-MIMO systems where delay-constrained users and delay-tolerant users coexist, called a DCTU-MIMO network. To maximize the sum spectral efficiency in this system, we present the spectral efficiency for delay-tolerant users and provide a lower bound of the spectral efficiency for delay-constrained users. We consider an optimization problem that maximizes the sum spectral efficiency of delay-tolerant users while satisfying the latency constraint of delay-constrained users, and propose a generalized power iteration (GPI) precoding algorithm that finds a principal precoding vector. Furthermore, we extend a DCTU-MIMO network to the multiple time slots scenario and propose a recursive generalized power iteration precoding algorithm. In simulation results, we prove proposed methods outperform baseline schemes and present the effect of network parameters on the ergodic sum spectral efficiency.      
### 20.Controllable Confidence-Based Image Denoising  [ :arrow_down: ](https://arxiv.org/pdf/2106.09311.pdf)
>  Image denoising is a classic restoration problem. Yet, current deep learning methods are subject to the problems of generalization and interpretability. To mitigate these problems, in this project, we present a framework that is capable of controllable, confidence-based noise removal. The framework is based on the fusion between two different denoised images, both derived from the same noisy input. One of the two is denoised using generic algorithms (e.g. Gaussian), which make few assumptions on the input images, therefore, generalize in all scenarios. The other is denoised using deep learning, performing well on seen datasets. We introduce a set of techniques to fuse the two components smoothly in the frequency domain. Beyond that, we estimate the confidence of a deep learning denoiser to allow users to interpret the output, and provide a fusion strategy that safeguards them against out-of-distribution inputs. Through experiments, we demonstrate the effectiveness of the proposed framework in different use cases.      
### 21.A Multi-task convolutional neural network for blind stereoscopic image quality assessment using naturalness analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.09303.pdf)
>  This paper addresses the problem of blind stereoscopic image quality assessment (NR-SIQA) using a new multi-task deep learning based-method. In the field of stereoscopic vision, the information is fairly distributed between the left and right views as well as the binocular phenomenon. In this work, we propose to integrate these characteristics to estimate the quality of stereoscopic images without reference through a convolutional neural network. Our method is based on two main tasks: the first task predicts naturalness analysis based features adapted to stereo images, while the second task predicts the quality of such images. The former, so-called auxiliary task, aims to find more robust and relevant features to improve the quality prediction. To do this, we compute naturalness-based features using a Natural Scene Statistics (NSS) model in the complex wavelet domain. It allows to capture the statistical dependency between pairs of the stereoscopic images. Experiments are conducted on the well known LIVE PHASE I and LIVE PHASE II databases. The results obtained show the relevance of our method when comparing with those of the state-of-the-art. Our code is available online on <a class="link-external link-https" href="https://github.com/Bourbia-Salima/multitask-cnn-nrsiqa_2021" rel="external noopener nofollow">this https URL</a>.      
### 22.Temporal Logic Planning for Minimum-Time Positioning of Multiple Threat-Seduction Decoys  [ :arrow_down: ](https://arxiv.org/pdf/2106.09252.pdf)
>  Reusable decoys offer a cost-effective alternative to the single-use hardware commonly applied to protect surface assets from threats. Such decoys portray fake assets to lure threats away from the true asset. To deceive a threat, a decoy first has to position itself such that it can break the radar lock. Considering multiple simultaneous threats, this paper introduces an approach for controlling multiple decoys to minimise the time required to break the locks of all the threats. The method includes the optimal allocation of one decoy to every threat with an assignment procedure that provides local position constraints to guarantee collision avoidance and thereby decouples the control of the decoys. A crude model of a decoy with uncertainty is considered for motion planning. The task of a decoy reaching a state in which the lock of the assigned threat can be broken is formulated as a temporal logic specification. To this end, the requirements to complete the task are modelled as time-varying set-membership constraints. The temporal and logical combination of the constraints is encoded in a mixed-integer optimisation problem. To demonstrate the results a simulated case study is provided.      
### 23.Layer Pruning on Demand with Intermediate CTC  [ :arrow_down: ](https://arxiv.org/pdf/2106.09216.pdf)
>  Deploying an end-to-end automatic speech recognition (ASR) model on mobile/embedded devices is a challenging task, since the device computational power and energy consumption requirements are dynamically changed in practice. To overcome the issue, we present a training and pruning method for ASR based on the connectionist temporal classification (CTC) which allows reduction of model depth at run-time without any extra fine-tuning. To achieve the goal, we adopt two regularization methods, intermediate CTC and stochastic depth, to train a model whose performance does not degrade much after pruning. We present an in-depth analysis of layer behaviors using singular vector canonical correlation analysis (SVCCA), and efficient strategies for finding layers which are safe to prune. Using the proposed method, we show that a Transformer-CTC model can be pruned in various depth on demand, improving real-time factor from 0.005 to 0.002 on GPU, while each pruned sub-model maintains the accuracy of individually trained model of the same depth.      
### 24.Impact of Communication Loss on MPC based Cooperative Adaptive Cruise Control and Platooning  [ :arrow_down: ](https://arxiv.org/pdf/2106.09094.pdf)
>  Cooperative driving, enabled by communication between automated vehicle systems, is expected to significantly contribute to transportation safety and efficiency. Cooperative Adaptive Cruise Control (CACC) and platooning are two of the main cooperative driving applications that are currently under study. These applications offer significant improvements over current advanced driver assistant systems such as adaptive cruise control (ACC). The primary motivation of CACC and Platooning is to reduce traffic congestion and improve traffic flow, traffic throughput, and highway capacity. These applications need an efficient controller to consider the computational cost and ensure driving comfort and high responsiveness. The advantage of Model Predictive Control is that we can realize high control performance since all constrain for these applications can be explicitly dealt with through solving an optimization problem. These applications highly depend on information update and Communication reliability for their safety and stability purposes. In this paper, we propose a Model Predictive Control (MPC) based approach for CACC and platooning, and examine the impact of communication loss on the performance and robustness of the control scheme. The results show an improvement in response time and string stability, demonstrating the potential of cooperation to attenuate disturbances and improve traffic flow.      
### 25.A Hands-on Comparison of DNNs for Dialog SeparationUsing Transfer Learning from Music Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2106.09093.pdf)
>  This paper describes a hands-on comparison on using state-of-the-art music source separation deep neural networks (DNNs) before and after task-specific fine-tuning for separating speech content from non-speech content in broadcast audio (i.e., dialog separation). The music separation models are selected as they share the number of channels (2) and sampling rate (44.1 kHz or higher) with the considered broadcast content, and vocals separation in music is considered as a parallel for dialog separation in the target application domain. These similarities are assumed to enable transfer learning between the tasks. Three models pre-trained on music (Open-Unmix, Spleeter, and Conv-TasNet) are considered in the experiments, and fine-tuned with real broadcast data. The performance of the models is evaluated before and after fine-tuning with computational evaluation metrics (SI-SIRi, SI-SDRi, 2f-model), as well as with a listening test simulating an application where the non-speech signal is partially attenuated, e.g., for better speech intelligibility. The evaluations include two reference systems specifically developed for dialog separation. The results indicate that pre-trained music source separation models can be used for dialog separation to some degree, and that they benefit from the fine-tuning, reaching a performance close to task-specific solutions.      
### 26.A factor graph EM algorithm for inference of kinetic microstates from patch clamp measurements  [ :arrow_down: ](https://arxiv.org/pdf/2106.09594.pdf)
>  We derive a factor graph EM (FGEM) algorithm, a technique that permits combined parameter estimation and statistical inference, to determine hidden kinetic microstates from patch clamp measurements. Using the cystic fibrosis transmembrane conductance regulator (CFTR) and nicotinic acetylcholine receptor (nAChR) as examples, we perform {\em Monte Carlo} simulations to demonstrate the performance of the algorithm. We show that the performance, measured in terms of the probability of estimation error, approaches the theoretical performance limit of maximum {\em a posteriori} estimation. Moreover, the algorithm provides a reliability score for its estimates, and we demonstrate that the score can be used to further improve the performance of estimation. We use the algorithm to estimate hidden kinetic states in lab-obtained CFTR single channel patch clamp traces.      
### 27.Future mobility as a bio-inspired collaborative system  [ :arrow_down: ](https://arxiv.org/pdf/2106.09543.pdf)
>  The current trends towards vehicle-sharing, electrification, and autonomy are predicted to transform mobility. Combined appropriately, they have the potential of significantly improving urban mobility. However, what will come after most vehicles are shared, electric, and autonomous remains an open question, especially regarding the interactions between vehicles and how these interactions will impact system-level behaviour. Inspired by nature and supported by swarm robotics and vehicle platooning models, this paper proposes a future mobility in which shared, electric, and autonomous vehicles behave as a bio-inspired collaborative system. The collaboration between vehicles will lead to a system-level behaviour analogous to natural swarms. Natural swarms can divide tasks, cluster, build together, or transport cooperatively. In this future mobility, vehicles will cluster by connecting either physically or virtually, which will enable the possibility of sharing energy, data or computational power, provide services or transfer cargo, among others. Vehicles will collaborate either with vehicles that are part of the same fleet, or with any other vehicle on the road, by finding mutualistic relationships that benefit both parties. The field of swarm robotics has already translated some of the behaviours from natural swarms to artificial systems and, if we further translate these concepts into urban mobility, exciting ideas emerge. Within mobility-related research, the coordinated movement proposed in vehicle platooning models can be seen as a first step towards collaborative mobility. This paper contributes with the proposal of a framework for future mobility that integrates current research and mobility trends in a novel and unique way.      
### 28.Exploring deterministic frequency deviations with explainable AI  [ :arrow_down: ](https://arxiv.org/pdf/2106.09538.pdf)
>  Deterministic frequency deviations (DFDs) critically affect power grid frequency quality and power system stability. A better understanding of these events is urgently needed as frequency deviations have been growing in the European grid in recent years. DFDs are partially explained by the rapid adjustment of power generation following the intervals of electricity trading, but this intuitive picture fails especially before and around noonday. In this article, we provide a detailed analysis of DFDs and their relation to external features using methods from explainable Artificial Intelligence. We establish a machine learning model that well describes the daily cycle of DFDs and elucidate key interdependencies using SHapley Additive exPlanations (SHAP). Thereby, we identify solar ramps as critical to explain patterns in the Rate of Change of Frequency (RoCoF).      
### 29.Secure Multi-Function Computation with Private Remote Sources  [ :arrow_down: ](https://arxiv.org/pdf/2106.09485.pdf)
>  We consider a distributed function computation problem in which parties observing noisy versions of a remote source facilitate the computation of a function of their observations at a fusion center through public communication. The distributed function computation is subject to constraints, including not only reliability and storage but also privacy and secrecy. Specifically, 1) the remote source should remain private from an eavesdropper and the fusion center, measured in terms of the information leaked about the remote source; 2) the function computed should remain secret from the eavesdropper, measured in terms of the information leaked about the arguments of the function, to ensure secrecy regardless of the exact function used. We derive the exact rate regions for lossless and lossy single-function computation and illustrate the lossy single-function computation rate region for an information bottleneck example, in which the optimal auxiliary random variables are characterized for binary-input symmetric-output channels. We extend the approach to lossless and lossy asynchronous multiple-function computations with joint secrecy and privacy constraints, in which case inner and outer bounds for the rate regions differing only in the Markov chain conditions imposed are characterized.      
### 30.Modelling resource allocation in uncertain system environment through deep reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.09461.pdf)
>  Reinforcement Learning has applications in field of mechatronics, robotics, and other resource-constrained control system. Problem of resource allocation is primarily solved using traditional predefined techniques and modern deep learning methods. The drawback of predefined and most deep learning methods for resource allocation is failing to meet the requirements in cases of uncertain system environment. We can approach problem of resource allocation in uncertain system environment alongside following certain criteria using deep reinforcement learning. Also, reinforcement learning has ability for adapting to new uncertain environment for prolonged period of time. The paper provides a detailed comparative analysis on various deep reinforcement learning methods by applying different components to modify architecture of reinforcement learning with use of noisy layers, prioritized replay, bagging, duelling networks, and other related combination to obtain improvement in terms of performance and reduction of computational cost. The paper identifies problem of resource allocation in uncertain environment could be effectively solved using Noisy Bagging duelling double deep Q network achieving efficiency of 97.7% by maximizing reward with significant exploration in given simulated environment for resource allocation.      
### 31.Simultaneous Transmission and Reflection Reconfigurable Intelligent Surface Assisted MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.09450.pdf)
>  In this work, we investigate a novel simultaneous transmission and reflection reconfigurable intelligent surface (RIS)-assisted multiple-input multiple-output downlink system, where three practical transmission protocols, namely, energy splitting (ES), mode selection (MS), and time splitting (TS), are studied. For the system under consideration, we maximize the weighted sum rate with multiple coupled variables. To solve this optimization problem, a block coordinate descent algorithm is proposed to reformulate this problem and design the precoding matrices and the transmitting and reflecting coefficients (TARCs) in an alternate manner. Specifically, for the ES scheme, the precoding matrices are solved using the Lagrange dual method, while the TARCs are obtained using the penalty concave-convex method. Additionally, the proposed method is extended to the MS scheme by solving a mixed-integer problem. Moreover, we solve the formulated problem for the TS scheme using a one-dimensional search and the Majorization-Minimization technique. Our simulation results reveal that: 1) Simultaneous transmission and reflection RIS (STAR-RIS) can achieve better performance than reflecting-only RIS; 2) In unicast communication, TS scheme outperforms the ES and MS schemes, while in broadcast communication, ES scheme outperforms the TS and MS schemes.      
### 32.Dynamic Metasurface Antennas for Energy Efficient Massive MIMO Uplink Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.09442.pdf)
>  Future wireless communications are largely inclined to deploy a massive number of antennas at the base stations (BS) by exploiting energy-efficient and environmentally friendly technologies. An emerging technology called dynamic metasurface antennas (DMAs) is promising to realize such massive antenna arrays with reduced physical size, hardware cost, and power consumption. This paper aims to optimize the energy efficiency (EE) performance of DMAs-assisted massive MIMO uplink communications. We propose an algorithmic framework for designing the transmit precoding of each multi-antenna user and the DMAs tuning strategy at the BS to maximize the EE performance, considering the availability of the instantaneous and statistical channel state information (CSI), respectively. Specifically, the proposed framework includes Dinkelbach's transform, alternating optimization, and deterministic equivalent methods. In addition, we obtain a closed-form solution to the optimal transmit signal directions for the statistical CSI case, which simplifies the corresponding transmission design. The numerical results show good convergence performance of our proposed algorithms as well as considerable EE performance gains of the DMAs-assisted massive MIMO uplink communications over the baseline schemes.      
### 33.Convergence of Dynamic Programming on the Semidefinite Cone  [ :arrow_down: ](https://arxiv.org/pdf/2106.09391.pdf)
>  The goal of this paper is to investigate new and simple convergence analysis of dynamic programming for linear quadratic regulator problem of discrete-time linear time-invariant systems. In particular, bounds on errors are given in terms of both matrix inequalities and matrix norm. Under a mild assumption on the initial parameter, we prove that the Q-value iteration exponentially converges to the optimal solution. Moreover, a global asymptotic convergence is also presented. These results are then extended to the policy iteration. We prove that in contrast to the Q-value iteration, the policy iteration always converges exponentially fast. An example is given to illustrate the results.      
### 34.Area Optimisation of Two Stage Miller Compensated Op-Amp in 65 nm Using Hybrid PSO  [ :arrow_down: ](https://arxiv.org/pdf/2106.09383.pdf)
>  Analog circuit design can be formulated as a non-linear constrained optimisation problem that can be solved using any suitable optimisation algorithms. Different optimisation techniques have been reported to reduce the design time of analog circuits. A hybrid particle swarm optimisation algorithm with linearly decreasing inertia weight for the optimisation of analog circuit design is proposed in this study. The proposed method is used to design a two-stage operational amplifier circuit with Miller compensation. The results show that the proposed optimisation method can substantially reduce the design time needed for analog circuits.      
### 35.Deep generative modeling for probabilistic forecasting in power systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.09370.pdf)
>  Greater direct electrification of end-use sectors with a higher share of renewables is one of the pillars to power a carbon-neutral society by 2050. This study uses a recent deep learning technique, the normalizing flows, to produce accurate probabilistic forecasts that are crucial for decision-makers to face the new challenges in power systems applications. Through comprehensive empirical evaluations using the open data of the Global Energy Forecasting Competition 2014, we demonstrate that our methodology is competitive with other state-of-the-art deep learning generative models: generative adversarial networks and variational autoencoders. The models producing weather-based wind, solar power, and load scenarios are properly compared both in terms of forecast value, by considering the case study of an energy retailer, and quality using several complementary metrics.      
### 36.Multi-Level Transfer Learning from Near-Field to Far-Field Speaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2106.09320.pdf)
>  In far-field speaker verification, the performance of speaker embeddings is susceptible to degradation when there is a mismatch between the conditions of enrollment and test speech. To solve this problem, we propose the feature-level and instance-level transfer learning in the teacher-student framework to learn a domain-invariant embedding space. For the feature-level knowledge transfer, we develop the contrastive loss to transfer knowledge from teacher model to student model, which can not only decrease the intra-class distance, but also enlarge the inter-class distance. Moreover, we propose the instance-level pairwise distance transfer method to force the student model to preserve pairwise instances distance from the well optimized embedding space of the teacher model. On FFSVC 2020 evaluation set, our EER on Full-eval trials is relatively reduced by 13.9% compared with the fusion system result on Partial-eval trials of Task2. On Task1, compared with the winner's DenseNet result on Partial-eval trials, our minDCF on Full-eval trials is relatively reduced by 6.3%. On Task3, the EER and minDCF of our proposed method on Full-eval trials are very close to the result of the fusion system on Partial-eval trials. Our results also outperform other competitive domain adaptation methods.      
### 37.EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model  [ :arrow_down: ](https://arxiv.org/pdf/2106.09317.pdf)
>  Recently, there has been an increasing interest in neural speech synthesis. While the deep neural network achieves the state-of-the-art result in text-to-speech (TTS) tasks, how to generate a more emotional and more expressive speech is becoming a new challenge to researchers due to the scarcity of high-quality emotion speech dataset and the lack of advanced emotional TTS model. In this paper, we first briefly introduce and publicly release a Mandarin emotion speech dataset including 9,724 samples with audio files and its emotion human-labeled annotation. After that, we propose a simple but efficient architecture for emotional speech synthesis called EMSpeech. Unlike those models which need additional reference audio as input, our model could predict emotion labels just from the input text and generate more expressive speech conditioned on the emotion embedding. In the experiment phase, we first validate the effectiveness of our dataset by an emotion classification task. Then we train our model on the proposed dataset and conduct a series of subjective evaluations. Finally, by showing a comparable performance in the emotional speech synthesis task, we successfully demonstrate the ability of the proposed model.      
### 38.Optimized Power Control Design for Over-the-Air Federated Edge Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.09316.pdf)
>  This paper investigates the transmission power control in over-the-air federated edge learning (Air-FEEL) system. Different from conventional power control designs (e.g., to minimize the individual mean squared error (MSE) of the over-the-air aggregation at each round), we consider a new power control design aiming at directly maximizing the convergence speed. Towards this end, we first analyze the convergence behavior of Air-FEEL (in terms of the optimality gap) subject to aggregation errors at different communication rounds. It is revealed that if the aggregation estimates are unbiased, then the training algorithm would converge exactly to the optimal point with mild conditions; while if they are biased, then the algorithm would converge with an error floor determined by the accumulated estimate bias over communication rounds. Next, building upon the convergence results, we optimize the power control to directly minimize the derived optimality gaps under both biased and unbiased aggregations, subject to a set of average and maximum power constraints at individual edge devices. We transform both problems into convex forms, and obtain their structured optimal solutions, both appearing in a form of regularized channel inversion, by using the Lagrangian duality method. Finally, numerical results show that the proposed power control policies achieve significantly faster convergence for Air-FEEL, as compared with benchmark policies with fixed power transmission or conventional MSE minimization.      
### 39.Design of a prototypical platform for autonomous and connected vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2106.09307.pdf)
>  Self-driving technology is expected to revolutionize different sectors and is seen as the natural evolution of road vehicles. In the last years, real-world validation of designed and virtually tested solutions is growing in importance since simulated environments will never fully replicate all the aspects that can affect results in the real world. To this end, this paper presents our prototype platform for experimental research on connected and autonomous driving projects. In detail, the paper presents the overall architecture of the vehicle focusing both on mechanical aspects related to remote actuation and sensors set-up and software aspects by means of a comprehensive description of the main algorithms required for autonomous driving as ego-localization, environment perception, motion planning, and actuation. Finally, experimental tests conducted in an urban-like environment are reported to validate and assess the performances of the overall system.      
### 40.Voice2Series: Reprogramming Acoustic Models for Time Series Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.09296.pdf)
>  Learning to classify time series with limited data is a practical yet challenging problem. Current methods are primarily based on hand-designed feature extraction rules or domain-specific data augmentation. Motivated by the advances in deep speech processing models and the fact that voice data are univariate temporal signals, in this paper, we propose Voice2Series (V2S), a novel end-to-end approach that reprograms acoustic models for time series classification, through input transformation learning and output label mapping. Leveraging the representation learning power of a large-scale pre-trained speech processing model, on 30 different time series tasks we show that V2S either outperforms or is tied with state-of-the-art methods on 20 tasks, and improves their average accuracy by 1.84%. We further provide a theoretical justification of V2S by proving its population risk is upper bounded by the source risk and a Wasserstein distance accounting for feature alignment via reprogramming. Our results offer new and effective means to time series classification.      
### 41.Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-EndSpeech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.09236.pdf)
>  End-to-end models are favored in automatic speech recognition (ASR) because of their simplified system structure and superior performance. Among these models, Transformer and Conformer have achieved state-of-the-art recognition accuracy in which self-attention plays a vital role in capturing important global information. However, the time and memory complexity of self-attention increases squarely with the length of the sentence. In this paper, a prob-sparse self-attention mechanism is introduced into Conformer to sparse the computing process of self-attention in order to accelerate inference speed and reduce space consumption. Specifically, we adopt a Kullback-Leibler divergence based sparsity measurement for each query to decide whether we compute the attention function on this query. By using the prob-sparse attention mechanism, we achieve impressively 8% to 45% inference speed-up and 15% to 45% memory usage reduction of the self-attention module of Conformer Transducer while maintaining the same level of error rate.      
### 42.Square Root Principal Component Pursuit: Tuning-Free Noisy Robust Matrix Recovery  [ :arrow_down: ](https://arxiv.org/pdf/2106.09211.pdf)
>  We propose a new framework -- Square Root Principal Component Pursuit -- for low-rank matrix recovery from observations corrupted with noise and outliers. Inspired by the square root Lasso, this new formulation does not require prior knowledge of the noise level. We show that a single, universal choice of the regularization parameter suffices to achieve reconstruction error proportional to the (a priori unknown) noise level. In comparison, previous formulations such as stable PCP rely on noise-dependent parameters to achieve similar performance, and are therefore challenging to deploy in applications where the noise level is unknown. We validate the effectiveness of our new method through experiments on simulated and real datasets. Our simulations corroborate the claim that a universal choice of the regularization parameter yields near optimal performance across a range of noise levels, indicating that the proposed method outperforms the (somewhat loose) bound proved here.      
### 43.LiRA: Learning Visual Speech Representations from Audio through Self-supervision  [ :arrow_down: ](https://arxiv.org/pdf/2106.09171.pdf)
>  The large amount of audiovisual content being shared online today has drawn substantial attention to the prospect of audiovisual self-supervised learning. Recent works have focused on each of these modalities separately, while others have attempted to model both simultaneously in a cross-modal fashion. However, comparatively little attention has been given to leveraging one modality as a training objective to learn from the other. In this work, we propose Learning visual speech Representations from Audio via self-supervision (LiRA). Specifically, we train a ResNet+Conformer model to predict acoustic features from unlabelled visual speech. We find that this pre-trained model can be leveraged towards word-level and sentence-level lip-reading through feature extraction and fine-tuning experiments. We show that our approach significantly outperforms other self-supervised methods on the Lip Reading in the Wild (LRW) dataset and achieves state-of-the-art performance on Lip Reading Sentences 2 (LRS2) using only a fraction of the total labelled data.      
### 44.Mungojerrie: Reinforcement Learning of Linear-Time Objectives  [ :arrow_down: ](https://arxiv.org/pdf/2106.09161.pdf)
>  Reinforcement learning synthesizes controllers without prior knowledge of the system. At each timestep, a reward is given. The controllers optimize the discounted sum of these rewards. Applying this class of algorithms requires designing a reward scheme, which is typically done manually. The designer must ensure that their intent is accurately captured. This may not be trivial, and is prone to error. An alternative to this manual programming, akin to programming directly in assembly, is to specify the objective in a formal language and have it "compiled" to a reward scheme. Mungojerrie (<a class="link-external link-https" href="https://plv.colorado.edu/mungojerrie/" rel="external noopener nofollow">this https URL</a>) is a tool for testing reward schemes for $\omega$-regular objectives on finite models. The tool contains reinforcement learning algorithms and a probabilistic model checker. Mungojerrie supports models specified in PRISM and $\omega$-automata specified in HOA.      
### 45.EEG-GNN: Graph Neural Networks for Classification of Electroencephalogram (EEG) Signals  [ :arrow_down: ](https://arxiv.org/pdf/2106.09135.pdf)
>  Convolutional neural networks (CNN) have been frequently used to extract subject-invariant features from electroencephalogram (EEG) for classification tasks. This approach holds the underlying assumption that electrodes are equidistant analogous to pixels of an image and hence fails to explore/exploit the complex functional neural connectivity between different electrode sites. We overcome this limitation by tailoring the concepts of convolution and pooling applied to 2D grid-like inputs for the functional network of electrode sites. Furthermore, we develop various graph neural network (GNN) models that project electrodes onto the nodes of a graph, where the node features are represented as EEG channel samples collected over a trial, and nodes can be connected by weighted/unweighted edges according to a flexible policy formulated by a neuroscientist. The empirical evaluations show that our proposed GNN-based framework outperforms standard CNN classifiers across ErrP, and RSVP datasets, as well as allowing neuroscientific interpretability and explainability to deep learning methods tailored to EEG related classification problems. Another practical advantage of our GNN-based framework is that it can be used in EEG channel selection, which is critical for reducing computational cost, and designing portable EEG headsets.      
### 46.Convex Optimization for Trajectory Generation  [ :arrow_down: ](https://arxiv.org/pdf/2106.09125.pdf)
>  Reliable and efficient trajectory generation methods are a fundamental need for autonomous dynamical systems of tomorrow. The goal of this article is to provide a comprehensive tutorial of three major convex optimization-based trajectory generation methods: lossless convexification (LCvx), and two sequential convex programming algorithms known as SCvx and GuSTO. In this article, trajectory generation is the computation of a dynamically feasible state and control signal that satisfies a set of constraints while optimizing key mission objectives. The trajectory generation problem is almost always nonconvex, which typically means that it is not readily amenable to efficient and reliable solution onboard an autonomous vehicle. The three algorithms that we discuss use problem reformulation and a systematic algorithmic strategy to nonetheless solve nonconvex trajectory generation tasks through the use of a convex optimizer. The theoretical guarantees and computational speed offered by convex optimization have made the algorithms popular in both research and industry circles. To date, the list of applications includes rocket landing, spacecraft hypersonic reentry, spacecraft rendezvous and docking, aerial motion planning for fixed-wing and quadrotor vehicles, robot motion planning, and more. Among these applications are high-profile rocket flights conducted by organizations like NASA, Masten Space Systems, SpaceX, and Blue Origin. This article aims to give the reader the tools and understanding necessary to work with each algorithm, and to know what each method can and cannot do. A publicly available source code repository supports the provided numerical examples. By the end of the article, the reader should be ready to use the methods, to extend them, and to contribute to their many exciting modern applications.      
### 47.Safe Reinforcement Learning Using Advantage-Based Intervention  [ :arrow_down: ](https://arxiv.org/pdf/2106.09110.pdf)
>  Many sequential decision problems involve finding a policy that maximizes total reward while obeying safety constraints. Although much recent research has focused on the development of safe reinforcement learning (RL) algorithms that produce a safe policy after training, ensuring safety during training as well remains an open problem. A fundamental challenge is performing exploration while still satisfying constraints in an unknown Markov decision process (MDP). In this work, we address this problem for the chance-constrained setting. We propose a new algorithm, SAILR, that uses an intervention mechanism based on advantage functions to keep the agent safe throughout training and optimizes the agent's policy using off-the-shelf RL algorithms designed for unconstrained MDPs. Our method comes with strong guarantees on safety during both training and deployment (i.e., after training and without the intervention mechanism) and policy performance compared to the optimal safety-constrained policy. In our experiments, we show that SAILR violates constraints far less during training than standard safe RL and constrained MDP approaches and converges to a well-performing policy that can be deployed safely without intervention. Our code is available at <a class="link-external link-https" href="https://github.com/nolanwagener/safe_rl" rel="external noopener nofollow">this https URL</a>.      
### 48.Identifiability-Guaranteed Simplex-Structured Post-Nonlinear Mixture Learning via Autoencoder  [ :arrow_down: ](https://arxiv.org/pdf/2106.09070.pdf)
>  This work focuses on the problem of unraveling nonlinearly mixed latent components in an unsupervised manner. The latent components are assumed to reside in the probability simplex, and are transformed by an unknown post-nonlinear mixing system. This problem finds various applications in signal and data analytics, e.g., nonlinear hyperspectral unmixing, image embedding, and nonlinear clustering. Linear mixture learning problems are already ill-posed, as identifiability of the target latent components is hard to establish in general. With unknown nonlinearity involved, the problem is even more challenging. Prior work offered a function equation-based formulation for provable latent component identification. However, the identifiability conditions are somewhat stringent and unrealistic. In addition, the identifiability analysis is based on the infinite sample (i.e., population) case, while the understanding for practical finite sample cases has been elusive. Moreover, the algorithm in the prior work trades model expressiveness with computational convenience, which often hinders the learning performance. Our contribution is threefold. First, new identifiability conditions are derived under largely relaxed assumptions. Second, comprehensive sample complexity results are presented -- which are the first of the kind. Third, a constrained autoencoder-based algorithmic framework is proposed for implementation, which effectively circumvents the challenges in the existing algorithm. Synthetic and real experiments corroborate our theoretical analyses.      

# ArXiv eess --Thu, 17 Jun 2021
### 1.A Flow-Based Neural Network for Time Domain Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.09008.pdf)
>  Speech enhancement involves the distinction of a target speech signal from an intrusive background. Although generative approaches using Variational Autoencoders or Generative Adversarial Networks (GANs) have increasingly been used in recent years, normalizing flow (NF) based systems are still scarse, despite their success in related fields. Thus, in this paper we propose a NF framework to directly model the enhancement process by density estimation of clean speech utterances conditioned on their noisy counterpart. The WaveGlow model from speech synthesis is adapted to enable direct enhancement of noisy utterances in time domain. In addition, we demonstrate that nonlinear input companding benefits the model performance by equalizing the distribution of input samples. Experimental evaluation on a publicly available dataset shows comparable results to current state-of-the-art GAN-based approaches, while surpassing the chosen baselines using objective evaluation metrics.      
### 2.Mean-value exergy modeling of internal combustion engines: characterization of feasible operating regions  [ :arrow_down: ](https://arxiv.org/pdf/2106.08941.pdf)
>  In this paper, a novel mean-value exergy-based modeling framework for internal combustion engines is developed. Starting from a detailed description of the in-cylinder dynamics, the exergy balance is solved for each engine operating point and, for the first time, static maps describing the availability transfer and destruction phenomena as a function of speed and load are derived. The application of the proposed modeling strategy, from the construction of the static maps to their usage, is shown for a military series hybrid electric vehicle. Ultimately, these static maps, while providing insightful information about inefficiencies over the whole operating field of the engine, are the enabling step for the development of exergy-based control strategies aiming at minimizing the overall operational losses of ground vehicles.      
### 3.Improved CNN-based Learning of Interpolation Filters for Low-Complexity Inter Prediction in Video Coding  [ :arrow_down: ](https://arxiv.org/pdf/2106.08936.pdf)
>  The versatility of recent machine learning approaches makes them ideal for improvement of next generation video compression solutions. Unfortunately, these approaches typically bring significant increases in computational complexity and are difficult to interpret into explainable models, affecting their potential for implementation within practical video coding applications. This paper introduces a novel explainable neural network-based inter-prediction scheme, to improve the interpolation of reference samples needed for fractional precision motion compensation. The approach requires a single neural network to be trained from which a full quarter-pixel interpolation filter set is derived, as the network is easily interpretable due to its linear structure. A novel training framework enables each network branch to resemble a specific fractional shift. This practical solution makes it very efficient to use alongside conventional video coding schemes. When implemented in the context of the state-of-the-art Versatile Video Coding (VVC) test model, 0.77%, 1.27% and 2.25% BD-rate savings can be achieved on average for lower resolution sequences under the random access, low-delay B and low-delay P configurations, respectively, while the complexity of the learned interpolation schemes is significantly reduced compared to the interpolation with full CNNs.      
### 4.Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.08922.pdf)
>  Pseudo-labeling (PL) has been shown to be effective in semi-supervised automatic speech recognition (ASR), where a base model is self-trained with pseudo-labels generated from unlabeled data. While PL can be further improved by iteratively updating pseudo-labels as the model evolves, most of the previous approaches involve inefficient retraining of the model or intricate control of the label update. We present momentum pseudo-labeling (MPL), a simple yet effective strategy for semi-supervised ASR. MPL consists of a pair of online and offline models that interact and learn from each other, inspired by the mean teacher method. The online model is trained to predict pseudo-labels generated on the fly by the offline model. The offline model maintains a momentum-based moving average of the online model. MPL is performed in a single training process and the interaction between the two models effectively helps them reinforce each other to improve the ASR performance. We apply MPL to an end-to-end ASR model based on the connectionist temporal classification. The experimental results demonstrate that MPL effectively improves over the base model and is scalable to different semi-supervised scenarios with varying amounts of data or domain mismatch.      
### 5.Nonlinear Trajectory-Based Region of Attraction Estimation for Aircraft Dynamics Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.08850.pdf)
>  Current flight control validation is heavily based on linear analysis and high fidelity, nonlinear simulations. Continuing developments of nonlinear analysis tools for flight control has greatly enhanced the validation process. Many analysis tools are reliant on assuming the analytical flight dynamics but this paper proposes an approach using only simulation data. First, this paper presents improvements to a method for estimating the region of attraction (ROA) of nonlinear systems governed by ordinary differential equations (ODEs) based only on trajectory measurements. Faster and more accurate convergence to the true ROA results. These improvements make the proposed algorithm feasible in higher-dimensional and more complex systems. Next, these tools are used to analyze the four-state longitudinal dynamics of NASA's Generic Transport Model (GTM) aircraft. A piecewise polynomial model of the GTM is used to simulate trajectories and the developed analysis tools are used to estimate the ROA around a trim condition based only on this trajectory data. Finally, the algorithm presented is extended to estimate the ROA of finitely many equilibrium point systems and of general equilibrium set (arbitrary equilibrium points and limit cycles) systems.      
### 6.Regularization-Induced Bias and Consistency in Recursive Least Squares  [ :arrow_down: ](https://arxiv.org/pdf/2106.08799.pdf)
>  Within the context of recursive least squares (RLS) parameter estimation, the goal of the present paper is to study the effect of regularization-induced bias on the transient and asymptotic accuracy of the parameter estimates. We consider this question in three stages. First, we consider regression with random data, in which case persistency is guaranteed. Next, we apply RLS to finite-impulse-response (FIR) system identification and, finally, to infinite-impulse-response (IIR) system identification. For each case, we relate the condition number of the regressor matrix to the transient response and rate of convergence of the parameter estimates.      
### 7.Reflector Antennas Characterization and Diagnostics using a Single Set of Far Field Phaseless Data and Crosswords-like Processing  [ :arrow_down: ](https://arxiv.org/pdf/2106.08792.pdf)
>  We introduce and discuss a new approach to the phase retrieval of fields radiated by continuous aperture sources having a circular support, which is of interest in many applications including the detection of shape deformations on reflector antennas. The approach is based on a decomposition of the actual 2-D problem into a number of 1-D phase retrieval problems along diameters and concentric rings of the visible part of the spectrum. In particular, the 1-D problems are effectively solved by using the spectral factorization method, while discrimination arguments at the crossing points allows to complete the retrieval of the 2-D complex field. The proposed procedure, which just requires a single set of far field amplitudes, takes advantage from up to now unexplored field properties and it is assessed in terms of reflector aperture fields.      
### 8.Persistent Excitation is Unnecessary for On-line Exponential Parameter Estimation: A New Algorithm that Overcomes this Obstacle  [ :arrow_down: ](https://arxiv.org/pdf/2106.08773.pdf)
>  In this paper, we prove that it is possible to estimate online the parameters of a classical vector linear regression equation $ Y=\Omega \theta$, where $ Y \in \mathbb{R}^n,\;\Omega \in \mathbb{R}^{n \times q}$ are bounded, measurable signals and $\theta \in \mathbb{R}^q$ is a constant vector of unknown parameters, even when the regressor $\Omega$ is not persistently exciting. Moreover, the convergence of the new parameter estimator is global and exponential and is given for both continuous-time and discrete-time implementations. As an illustration example, we consider the problem of parameter estimation of a linear time-invariant system, when the input signal is not sufficiently exciting, which is known to be a necessary and sufficient condition for the solution of the problem with the standard gradient or least-squares adaptation algorithms.      
### 9.Enriching Source Style Transfer in Recognition-Synthesis based Non-Parallel Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2106.08741.pdf)
>  Current voice conversion (VC) methods can successfully convert timbre of the audio. As modeling source audio's prosody effectively is a challenging task, there are still limitations of transferring source style to the converted speech. This study proposes a source style transfer method based on recognition-synthesis framework. Previously in speech generation task, prosody can be modeled explicitly with prosodic features or implicitly with a latent prosody extractor. In this paper, taking advantages of both, we model the prosody in a hybrid manner, which effectively combines explicit and implicit methods in a proposed prosody module. Specifically, prosodic features are used to explicit model prosody, while VAE and reference encoder are used to implicitly model prosody, which take Mel spectrum and bottleneck feature as input respectively. Furthermore, adversarial training is introduced to remove speaker-related information from the VAE outputs, avoiding leaking source speaker information while transferring style. Finally, we use a modified self-attention based encoder to extract sentential context from bottleneck features, which also implicitly aggregates the prosodic aspects of source speech from the layered representations. Experiments show that our approach is superior to the baseline and a competitive system in terms of style transfer; meanwhile, the speech quality and speaker similarity are well maintained.      
### 10.Probability of Resolution of MUSIC and g-MUSIC: An Asymptotic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.08738.pdf)
>  In this article, the outlier production mechanism of the conventional Multiple Signal Classification (MUSIC) and the g-MUSIC Direction-of-Arrival (DoA) estimation technique is investigated using tools from Random Matrix Theory (RMT). A general Central Limit Theorem (CLT) is derived that allows to analyze the asymptotic stochastic behavior of eigenvector-based cost functions in the asymptotic regime where the number of snapshots and the number of antennas increase without bound at the same rate. Furthermore, this CLT is used to provide an accurate prediction of the resolution capabilities of the MUSIC and the g-MUSIC DoA estimation method. The finite dimensional distribution of the MUSIC and the g-MUSIC cost function is shown to be asymptotically jointly Gaussian distributed in the asymptotic regime.      
### 11.Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI  [ :arrow_down: ](https://arxiv.org/pdf/2106.08706.pdf)
>  Speech sounds of spoken language are obtained by varying configuration of the articulators surrounding the vocal tract. They contain abundant information that can be utilized to better understand the underlying mechanism of human speech production. We propose a novel deep neural network-based learning framework that understands acoustic information in the variable-length sequence of vocal tract shaping during speech production, captured by real-time magnetic resonance imaging (rtMRI), and translate it into text. The proposed framework comprises of spatiotemporal convolutions, a recurrent network, and the connectionist temporal classification loss, trained entirely end-to-end. On the USC-TIMIT corpus, the model achieved a 40.6% PER at sentence-level, much better compared to the existing models. To the best of our knowledge, this is the first study that demonstrates the recognition of entire spoken sentence based on an individual's articulatory motions captured by rtMRI video. We also performed an analysis of variations in the geometry of articulation in each sub-regions of the vocal tract (i.e., pharyngeal, velar and dorsal, hard palate, labial constriction region) with respect to different emotions and genders. Results suggest that each sub-regions distortion is affected by both emotion and gender.      
### 12.A Review of Lithium-Ion Battery Models in Techno-economic Analyses of Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.08702.pdf)
>  The penetration of the lithium-ion battery energy storage system (BESS) into the power system environment occurs at a colossal rate worldwide. This is mainly because it is considered as one of the major tools to decarbonize, digitalize, and democratize the electricity grid. The economic viability and technical reliability of projects with batteries require appropriate assessment because of high capital expenditures, deterioration in charging/discharging performance and uncertainty with regulatory policies. Most of the power system economic studies employ a simple power-energy representation coupled with an empirical description of degradation to model the lithium-ion battery. This approach to modelling may result in violations of the safe operation and misleading estimates of the economic benefits. Recently, the number of publications on techno-economic analysis of BESS with more details on the lithium-ion battery performance has increased. The aim of this review paper is to explore these publications focused on the grid-scale BESS applications and to discuss the impacts of using more sophisticated modelling approaches. First, an overview of the three most popular battery models is given, followed by a review of the applications of such models. The possible directions of future research of employing detailed battery models in power systems' techno-economic studies are then explored.      
### 13.DCCRN+: Channel-wise Subband DCCRN with SNR Estimation for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.08672.pdf)
>  Deep complex convolution recurrent network (DCCRN), which extends CRN with complex structure, has achieved superior performance in MOS evaluation in Interspeech 2020 deep noise suppression challenge (DNS2020). This paper further extends DCCRN with the following significant revisions. We first extend the model to sub-band processing where the bands are split and merged by learnable neural network filters instead of engineered FIR filters, leading to a faster noise suppressor trained in an end-to-end manner. Then the LSTM is further substituted with a complex TF-LSTM to better model temporal dependencies along both time and frequency axes. Moreover, instead of simply concatenating the output of each encoder layer to the input of the corresponding decoder layer, we use convolution blocks to first aggregate essential information from the encoder output before feeding it to the decoder layers. We specifically formulate the decoder with an extra a priori SNR estimation module to maintain good speech quality while removing noise. Finally a post-processing module is adopted to further suppress the unnatural residual noise. The new model, named DCCRN+, has surpassed the original DCCRN as well as several competitive models in terms of PESQ and DNSMOS, and has achieved superior performance in the new Interspeech 2021 DNS challenge      
### 14.Improving the expressiveness of neural vocoding with non-affine Normalizing Flows  [ :arrow_down: ](https://arxiv.org/pdf/2106.08649.pdf)
>  This paper proposes a general enhancement to the Normalizing Flows (NF) used in neural vocoding. As a case study, we improve expressive speech vocoding with a revamped Parallel Wavenet (PW). Specifically, we propose to extend the affine transformation of PW to the more expressive invertible non-affine function. The greater expressiveness of the improved PW leads to better-perceived signal quality and naturalness in the waveform reconstruction and text-to-speech (TTS) tasks. We evaluate the model across different speaking styles on a multi-speaker, multi-lingual dataset. In the waveform reconstruction task, the proposed model closes the naturalness and signal quality gap from the original PW to recordings by $10\%$, and from other state-of-the-art neural vocoding systems by more than $60\%$. We also demonstrate improvements in objective metrics on the evaluation test set with L2 Spectral Distance and Cross-Entropy reduced by $3\%$ and $6\unicode{x2030}$ comparing to the affine PW. Furthermore, we extend the probability density distillation procedure proposed by the original PW paper, so that it works with any non-affine invertible and differentiable function.      
### 15.MPC-based Reinforcement Learning for a Simplified Freight Mission of Autonomous Surface Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2106.08634.pdf)
>  In this work, we propose a Model Predictive Control (MPC)-based Reinforcement Learning (RL) method for Autonomous Surface Vehicles (ASVs). The objective is to find an optimal policy that minimizes the closed-loop performance of a simplified freight mission, including collision-free path following, autonomous docking, and a skillful transition between them. We use a parametrized MPC-scheme to approximate the optimal policy, which considers path-following/docking costs and states (position, velocity)/inputs (thruster force, angle) constraints. The Least Squares Temporal Difference (LSTD)-based Deterministic Policy Gradient (DPG) method is then applied to update the policy parameters. Our simulation results demonstrate that the proposed MPC-LSTD-based DPG method could improve the closed-loop performance during learning for the freight mission problem of ASV.      
### 16.Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain  [ :arrow_down: ](https://arxiv.org/pdf/2106.08595.pdf)
>  Non-autoregressive (NAR) models have achieved a large inference computation reduction and comparable results with autoregressive (AR) models on various sequence to sequence tasks. However, there has been limited research aiming to explore the NAR approaches on sequence to multi-sequence problems, like multi-speaker automatic speech recognition (ASR). In this study, we extend our proposed conditional chain model to NAR multi-speaker ASR. Specifically, the output of each speaker is inferred one-by-one using both the input mixture speech and previously-estimated conditional speaker features. In each step, a NAR connectionist temporal classification (CTC) encoder is used to perform parallel computation. With this design, the total inference steps will be restricted to the number of mixed speakers. Besides, we also adopt the Conformer and incorporate an intermediate CTC loss to improve the performance. Experiments on WSJ0-Mix and LibriMix corpora show that our model outperforms other NAR models with only a slight increase of latency, achieving WERs of 22.3% and 24.9%, respectively. Moreover, by including the data of variable numbers of speakers, our model can even better than the PIT-Conformer AR model with only 1/7 latency, obtaining WERs of 19.9% and 34.3% on WSJ0-2mix and WSJ0-3mix sets. All of our codes are publicly available at <a class="link-external link-https" href="https://github.com/pengchengguo/espnet/tree/conditional-multispk" rel="external noopener nofollow">this https URL</a>.      
### 17.Correlated Non-Coherent Radar Detection for Gamma-Fluctuating Targets in Compound Clutter  [ :arrow_down: ](https://arxiv.org/pdf/2106.08593.pdf)
>  This work studies the problem of radar detection of correlated gamma-fluctuating targets in the presence of clutter described by compound models with correlated speckle. If the correlation is not accounted for in a radar model, the required signal-to-interference ratio for a given probability of detection will be incorrect, resulting in over-estimated performance. Although more generally applicable, the is focus on airborne maritime radar systems. Hence K-distributed sea clutter is used as the main example. Detection via square-law non-coherent pulse integration is formulated in a way that accommodates arbitrary partial correlation for both target radar cross-section (RCS) and clutter speckle. The obstacle to including this degree of generality in previous work was the fact that Swerling's original characterization of the standard RCS fluctuation classes as gamma distributions for the power is not sufficient for the inclusion of both correlation sources (i.e.target and clutter speckle) for gamma-fluctuating targets. An extension of the model is required at the quadrature component (i.e. voltage) level, as phase relationships can no longer be neglected. This is addressed in the present work, which not only postulates an extended model, but also demonstrates how to efficiently compute it, with and without a number of simplifying approximation schemes within the framework of the saddle-point technique.      
### 18.Multi-resolution intra-predictive coding of 3D point cloud attributes  [ :arrow_down: ](https://arxiv.org/pdf/2106.08562.pdf)
>  We propose an intra frame predictive strategy for compression of 3D point cloud attributes. Our approach is integrated with the region adaptive graph Fourier transform (RAGFT), a multi-resolution transform formed by a composition of localized block transforms, which produces a set of low pass (approximation) and high pass (detail) coefficients at multiple resolutions. Since the transform operations are spatially localized, RAGFT coefficients at a given resolution may still be correlated. To exploit this phenomenon, we propose an intra-prediction strategy, in which decoded approximation coefficients are used to predict uncoded detail coefficients. The prediction residuals are then quantized and entropy coded. For the 8i dataset, we obtain gains up to 0.5db as compared to intra predicted point cloud compresion based on the region adaptive Haar transform (RAHT).      
### 19.Detection of Consonant Errors in Disordered Speech Based on Consonant-vowel Segment Embedding  [ :arrow_down: ](https://arxiv.org/pdf/2106.08536.pdf)
>  Speech sound disorder (SSD) refers to a type of developmental disorder in young children who encounter persistent difficulties in producing certain speech sounds at the expected age. Consonant errors are the major indicator of SSD in clinical assessment. Previous studies on automatic assessment of SSD revealed that detection of speech errors concerning short and transitory consonants is less satisfactory. This paper investigates a neural network based approach to detecting consonant errors in disordered speech using consonant-vowel (CV) diphone segment in comparison to using consonant monophone segment. The underlying assumption is that the vowel part of a CV segment carries important information of co-articulation from the consonant. Speech embeddings are extracted from CV segments by a recurrent neural network model. The similarity scores between the embeddings of the test segment and the reference segments are computed to determine if the test segment is the expected consonant or not. Experimental results show that using CV segments achieves improved performance on detecting speech errors concerning those "difficult" consonants reported in the previous studies.      
### 20.Global Rhythm Style Transfer Without Text Transcriptions  [ :arrow_down: ](https://arxiv.org/pdf/2106.08519.pdf)
>  Prosody plays an important role in characterizing the style of a speaker or an emotion, but most non-parallel voice or emotion style transfer algorithms do not convert any prosody information. Two major components of prosody are pitch and rhythm. Disentangling the prosody information, particularly the rhythm component, from the speech is challenging because it involves breaking the synchrony between the input speech and the disentangled speech representation. As a result, most existing prosody style transfer algorithms would need to rely on some form of text transcriptions to identify the content information, which confines their application to high-resource languages only. Recently, SpeechSplit has made sizeable progress towards unsupervised prosody style transfer, but it is unable to extract high-level global prosody style in an unsupervised manner. In this paper, we propose AutoPST, which can disentangle global prosody style from speech without relying on any text transcriptions. AutoPST is an Autoencoder-based Prosody Style Transfer framework with a thorough rhythm removal module guided by the self-expressive representation learning. Experiments on different style transfer tasks show that AutoPST can effectively convert prosody that correctly reflects the styles of the target domains.      
### 21.Collision Avoidance with Stochastic Model Predictive Control for Systems with a Twofold Uncertainty Structure  [ :arrow_down: ](https://arxiv.org/pdf/2106.08463.pdf)
>  Model Predictive Control (MPC) has shown to be a successful method for many applications that require control. Especially in the presence of prediction uncertainty, various types of MPC offer robust or efficient control system behavior. For modeling, uncertainty is most often approximated in such a way that established MPC approaches are applicable for specific uncertainty types. However, for a number of applications, especially automated vehicles, uncertainty in predicting the future behavior of other agents is more suitably modeled by a twofold description: a high-level task uncertainty and a low-level execution uncertainty of individual tasks. In this work, we present an MPC framework that is capable of dealing with this twofold uncertainty. A scenario MPC approach considers the possibility of other agents performing one of multiple tasks, with an arbitrary probability distribution, while an analytic stochastic MPC method handles execution uncertainty within a specific task, based on a Gaussian distribution. Combining both approaches allows to efficiently handle the twofold uncertainty structure of many applications. Application of the proposed MPC method is demonstrated in an automated vehicle simulation study.      
### 22.Assessment of Subjective and Objective Quality of Live Streaming Sports Videos  [ :arrow_down: ](https://arxiv.org/pdf/2106.08431.pdf)
>  Video live streaming is gaining prevalence among video streaming services, especially for the delivery of popular sporting events. Many objective Video Quality Assessment (VQA) models have been developed to predict the perceptual quality of videos. Appropriate databases that exemplify the distortions encountered in live streaming videos are important to designing and learning objective VQA models. Towards making progress in this direction, we built a video quality database specifically designed for live streaming VQA research. The new video database is called the Laboratory for Image and Video Engineering (LIVE) Live stream Database. The LIVE Livestream Database includes 315 videos of 45 contents impaired by 6 types of distortions. We also performed a subjective quality study using the new database, whereby more than 12,000 human opinions were gathered from 40 subjects. We demonstrate the usefulness of the new resource by performing a holistic evaluation of the performance of current state-of-the-art (SOTA) VQA models. The LIVE Livestream database is being made publicly available for these purposes at <a class="link-external link-https" href="https://live.ece.utexas.edu/research/LIVE_APV_Study/apv_index.html" rel="external noopener nofollow">this https URL</a>.      
### 23.Design and analysis of deployable clustered tensegrity cable domes  [ :arrow_down: ](https://arxiv.org/pdf/2106.08424.pdf)
>  This study presents the design and analysis of deployable cable domes based on the clustered tensegrity structures (CTS). In this paper, the statics and dynamics equations of the CTS are first given. Using a traditional Levy cable dome as an example, we show the approach to modify the Levy dome to a deployable CTS one. The strings to be clustered are determined by the requirement of prestress mode and global stability. The deployment trajectory is proposed by changing the deployment ratio (the ratio between the radius of the inner and outer rings of the cable dome). Then, the quasi-static and dynamic deployment of clustered tensegrity dome is studied. Results show that the proposed CTS cable dome always has one prestress mode and is globally stable in its deployment trajectory. In the deployment process analysis, the dynamics show that the system's dynamic response differs from the quasi-static simulation as the actuation speed increases. That is, for a fast deployment process, quasi-static simulation is not accurate enough. The dynamics effects of the deployment must be considered. The developed approaches can also be used for the design and analysis of various kinds of CTS.      
### 24.Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.08352.pdf)
>  Text does not fully specify the spoken form, so text-to-speech models must be able to learn from speech data that vary in ways not explained by the corresponding text. One way to reduce the amount of unexplained variation in training data is to provide acoustic information as an additional learning signal. When generating speech, modifying this acoustic information enables multiple distinct renditions of a text to be produced. <br>Since much of the unexplained variation is in the prosody, we propose a model that generates speech explicitly conditioned on the three primary acoustic correlates of prosody: $F_{0}$, energy and duration. The model is flexible about how the values of these features are specified: they can be externally provided, or predicted from text, or predicted then subsequently modified. <br>Compared to a model that employs a variational auto-encoder to learn unsupervised latent features, our model provides more interpretable, temporally-precise, and disentangled control. When automatically predicting the acoustic features from text, it generates speech that is more natural than that from a Tacotron 2 model with reference encoder. Subsequent human-in-the-loop modification of the predicted acoustic features can significantly further increase naturalness.      
### 25.End-to-End Spoken Language Understanding for Generalized Voice Assistants  [ :arrow_down: ](https://arxiv.org/pdf/2106.09009.pdf)
>  End-to-end (E2E) spoken language understanding (SLU) systems predict utterance semantics directly from speech using a single model. Previous work in this area has focused on targeted tasks in fixed domains, where the output semantic structure is assumed a priori and the input speech is of limited complexity. In this work we present our approach to developing an E2E model for generalized SLU in commercial voice assistants (VAs). We propose a fully differentiable, transformer-based, hierarchical system that can be pretrained at both the ASR and NLU levels. This is then fine-tuned on both transcription and semantic classification losses to handle a diverse set of intent and argument combinations. This leads to an SLU system that achieves significant improvements over baselines on a complex internal generalized VA dataset with a 43% improvement in accuracy, while still meeting the 99% accuracy benchmark on the popular Fluent Speech Commands dataset. We further evaluate our model on a hard test set, exclusively containing slot arguments unseen in training, and demonstrate a nearly 20% improvement, showing the efficacy of our approach in truly demanding VA scenarios.      
### 26.Deriving Autism Spectrum Disorder Functional Networks from RS-FMRI Data using Group ICA and Dictionary Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.09000.pdf)
>  The objective of this study is to derive functional networks for the autism spectrum disorder (ASD) population using the group ICA and dictionary learning model together and to classify ASD and typically developing (TD) participants using the functional connectivity calculated from the derived functional networks. In our experiments, the ASD functional networks were derived from resting-state functional magnetic resonance imaging (rs-fMRI) data. We downloaded a total of 120 training samples, including 58 ASD and 62 TD participants, which were obtained from the public repository: Autism Brain Imaging Data Exchange I (ABIDE I). Our methodology and results have five main parts. First, we utilize a group ICA model to extract functional networks from the ASD group and rank the top 20 regions of interest (ROIs). Second, we utilize a dictionary learning model to extract functional networks from the ASD group and rank the top 20 ROIs. Third, we merged the 40 selected ROIs from the two models together as the ASD functional networks. Fourth, we generate three corresponding masks based on the 20 selected ROIs from group ICA, the 20 ROIs selected from dictionary learning, and the 40 combined ROIs selected from both. Finally, we extract ROIs for all training samples using the above three masks, and the calculated functional connectivity was used as features for ASD and TD classification. The classification results showed that the functional networks derived from ICA and dictionary learning together outperform those derived from a single ICA model or a single dictionary learning model.      
### 27.Deep-learning based Tools for Automated Protocol Definition of Advanced Diagnostic Imaging Exams  [ :arrow_down: ](https://arxiv.org/pdf/2106.08963.pdf)
>  Purpose: This study evaluates the effectiveness and impact of automated order-based protocol assignment for magnetic resonance imaging (MRI) exams using natural language processing (NLP) and deep learning (DL). <br>Methods: NLP tools were applied to retrospectively process orders from over 116,000 MRI exams with 200 unique sub-specialized protocols ("Local" protocol class). Separate DL models were trained on 70\% of the processed data for "Local" protocols as well as 93 American College of Radiology ("ACR") protocols and 48 "General" protocols. The DL Models were assessed in an "auto-protocoling (AP)" inference mode which returns the top recommendation and in a "clinical decision support (CDS)" inference mode which returns up to 10 protocols for radiologist review. The accuracy of each protocol recommendation was computed and analyzed based on the difference between the normalized output score of the corresponding neural net for the top two recommendations. <br>Results: The top predicted protocol in AP mode was correct for 82.8%, 73.8%, and 69.3% of the test cases for "General", "ACR", and "Local" protocol classes, respectively. Higher levels of accuracy over 96% were obtained for all protocol classes in CDS mode. However, at current validation performance levels, the proposed models offer modest, positive, financial impact on large-scale imaging networks. <br>Conclusions: DL-based protocol automation is feasible and can be tuned to route substantial fractions of exams for auto-protocoling, with higher accuracy with more general protocols. Economic analyses of the tested algorithms indicate that improved algorithm performance is required to yield a practical exam auto-protocoling tool for sub-specialized imaging exams.      
### 28.Intelligent Tire-Based Slip Ratio Estimation Using Different Machine Learning Algorithms  [ :arrow_down: ](https://arxiv.org/pdf/2106.08961.pdf)
>  Estimation of the longitudinal slip ratio of tires is important in boosting the control performance of the vehicle under driving and braking conditions. In this paper, the slip ratio is estimated using four machine learning algorithms (Neural Network, Gradient Boosting Machine, Random Forest and Support Vector Machine) based on the acceleration signals from the tri-axial MEMS accelerometers utilized in the intelligent tire system. The experimental data are collected through the MTS experimental platform. The corresponding acceleration signals within the tire contact patch are extracted after filtering to be used for the training the aforesaid machine learning algorithms. A comparison is provided between the implemented ML algorithms using a 10-fold CV. NRMS errors in the CV results indicate that NN has the highest accuracy in comparison with other techniques. The NRSM errors of NN, GBM, RF, and SVM are 2.59\%, 3.30\%, 4.21\%, and 5.34\%, respectively. Among these techniques, GBM has a more stable results as it has the smallest output variance. The present study with the fusion of intelligent tire system and machine learning algorithms paves the way for the accurate estimation of tire slip ratio, which is critical for the development of reliable vehicle control algorithms.      
### 29.Early fault detection with multi-target neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.08957.pdf)
>  Wind power is seeing a strong growth around the world. At the same time, shrinking profit margins in the energy markets let wind farm managers explore options for cost reductions in the turbine operation and maintenance. Sensor-based condition monitoring facilitates remote diagnostics of turbine subsystems, enabling faster responses when unforeseen maintenance is required. Condition monitoring with data from the turbines' supervisory control and data acquisition (SCADA) systems was proposed and SCADA-based fault detection and diagnosis approaches introduced based on single-task normal operation models of turbine state variables. As the number of SCADA channels has grown strongly, thousands of independent single-target models are in place today for monitoring a single turbine. Multi-target learning was recently proposed to limit the number of models. This study applied multi-target neural networks to the task of early fault detection in drive-train components. The accuracy and delay of detecting gear bearing faults were compared to state-of-the-art single-target approaches. We found that multi-target multi-layer perceptrons (MLPs) detected faults at least as early and in many cases earlier than single-target MLPs. The multi-target MLPs could detect faults up to several days earlier than the single-target models. This can deliver a significant advantage in the planning and performance of maintenance work. At the same time, the multi-target MLPs achieved the same level of prediction stability.      
### 30.FGLP: A Federated Fine-Grained Location Prediction System for Mobile Users  [ :arrow_down: ](https://arxiv.org/pdf/2106.08946.pdf)
>  Fine-grained location prediction on smart phones can be used to improve app/system performance. Application scenarios include video quality adaptation as a function of the 5G network quality at predicted user locations, and augmented reality apps that speed up content rendering based on predicted user locations. Such use cases require prediction error in the same range as the GPS error, and no existing works on location prediction can achieve this level of accuracy. We present a system for fine-grained location prediction (FGLP) of mobile users, based on GPS traces collected on the phones. FGLP has two components: a federated learning framework and a prediction model. The framework runs on the phones of the users and also on a server that coordinates learning from all users in the system. FGLP represents the user location data as relative points in an abstract 2D space, which enables learning across different physical spaces. The model merges Bidirectional Long Short-Term Memory (BiLSTM) and Convolutional Neural Networks (CNN), where BiLSTM learns the speed and direction of the mobile users, and CNN learns information such as user movement preferences. FGLP uses federated learning to protect user privacy and reduce bandwidth consumption. Our experimental results, using a dataset with over 600,000 users, demonstrate that FGLP outperforms baseline models in terms of prediction accuracy. We also demonstrate that FGLP works well in conjunction with transfer learning, which enables model reusability. Finally, benchmark results on several types of Android phones demonstrate FGLP's feasibility in real life.      
### 31.Autonomous Navigation System for a Delivery Drone  [ :arrow_down: ](https://arxiv.org/pdf/2106.08878.pdf)
>  The use of delivery services is an increasing trend worldwide, further enhanced by the COVID pandemic. In this context, drone delivery systems are of great interest as they may allow for faster and cheaper deliveries. This paper presents a navigation system that makes feasible the delivery of parcels with autonomous drones. The system generates a path between a start and a final point and controls the drone to follow this path based on its localization obtained through GPS, 9DoF IMU, and barometer. In the landing phase, information of poses estimated by a marker (ArUco) detection technique using a camera, ultra-wideband (UWB) devices, and the drone's software estimation are merged by utilizing an Extended Kalman Filter algorithm to improve the landing precision. A vector field-based method controls the drone to follow the desired path smoothly, reducing vibrations or harsh movements that could harm the transported parcel. Real experiments validate the delivery strategy and allow to evaluate the performance of the adopted techniques. Preliminary results state the viability of our proposal for autonomous drone delivery.      
### 32.Voicy: Zero-Shot Non-Parallel Voice Conversion in Noisy Reverberant Environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.08873.pdf)
>  Voice Conversion (VC) is a technique that aims to transform the non-linguistic information of a source utterance to change the perceived identity of the speaker. While there is a rich literature on VC, most proposed methods are trained and evaluated on clean speech recordings. However, many acoustic environments are noisy and reverberant, severely restricting the applicability of popular VC methods to such scenarios. To address this limitation, we propose Voicy, a new VC framework particularly tailored for noisy speech. Our method, which is inspired by the de-noising auto-encoders framework, is comprised of four encoders (speaker, content, phonetic and acoustic-ASR) and one decoder. Importantly, Voicy is capable of performing non-parallel zero-shot VC, an important requirement for any VC system that needs to work on speakers not seen during training. We have validated our approach using a noisy reverberant version of the LibriSpeech dataset. Experimental results show that Voicy outperforms other tested VC techniques in terms of naturalness and target speaker similarity in noisy reverberant environments.      
### 33.Attention-Based Keyword Localisation in Speech using Visual Grounding  [ :arrow_down: ](https://arxiv.org/pdf/2106.08859.pdf)
>  Visually grounded speech models learn from images paired with spoken captions. By tagging images with soft text labels using a trained visual classifier with a fixed vocabulary, previous work has shown that it is possible to train a model that can detect whether a particular text keyword occurs in speech utterances or not. Here we investigate whether visually grounded speech models can also do keyword localisation: predicting where, within an utterance, a given textual keyword occurs without any explicit text-based or alignment supervision. We specifically consider whether incorporating attention into a convolutional model is beneficial for localisation. Although absolute localisation performance with visually supervised models is still modest (compared to using unordered bag-of-word text labels for supervision), we show that attention provides a large gain in performance over previous visually grounded models. As in many other speech-image studies, we find that many of the incorrect localisations are due to semantic confusions, e.g. locating the word 'backstroke' for the query keyword 'swimming'.      
### 34.Power Minimization of Downlink Spectrum Slicing for eMBB and URLLC Users  [ :arrow_down: ](https://arxiv.org/pdf/2106.08847.pdf)
>  A critical task in 5G networks with heterogeneous services is spectrum slicing of the shared radio resources, through which each service gets performance guarantees. In this paper, we consider a setup in which a Base Station (BS) should serve two types of traffic in the downlink, enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC), respectively. Two resource allocation strategies are considered, non-orthogonal multiple access (NOMA) and orthogonal multiple access (OMA). A framework for power minimization is presented, in which the BS knows the channel state information (CSI) of the eMBB users only. Nevertheless, due to the resource sharing, it is shown that this knowledge can be used also to the benefit of the URLLC users. The numerical results show that NOMA leads to a lower power consumption compared to OMA for every simulation parameter under test.      
### 35.Algorithm to Compilation Codesign: An Integrated View of Neural Network Sparsity  [ :arrow_down: ](https://arxiv.org/pdf/2106.08846.pdf)
>  Reducing computation cost, inference latency, and memory footprint of neural networks are frequently cited as research motivations for pruning and sparsity. However, operationalizing those benefits and understanding the end-to-end effect of algorithm design and regularization on the runtime execution is not often examined in depth. <br>Here we apply structured and unstructured pruning to attention weights of transformer blocks of the BERT language model, while also expanding block sparse representation (BSR) operations in the TVM compiler. Integration of BSR operations enables the TVM runtime execution to leverage structured pattern sparsity induced by model regularization. <br>This integrated view of pruning algorithms enables us to study relationships between modeling decisions and their direct impact on sparsity-enhanced execution. Our main findings are: 1) we validate that performance benefits of structured sparsity block regularization must be enabled by the BSR augmentations to TVM, with 4x speedup relative to vanilla PyTorch and 2.2x speedup relative to standard TVM compilation (without expanded BSR support). 2) for BERT attention weights, the end-to-end optimal block sparsity shape in this CPU inference context is not a square block (as in \cite{gray2017gpu}) but rather a linear 32x1 block 3) the relationship between performance and block size / shape is is suggestive of how model regularization parameters interact with task scheduler optimizations resulting in the observed end-to-end performance.      
### 36.Conformal Three-Dimensional Interphase of Li Metal Anode Revealed by Low Dose Cryo-Electron Microscopy  [ :arrow_down: ](https://arxiv.org/pdf/2106.08754.pdf)
>  Using cryogenic transmission electron microscopy, we revealed three dimensional (3D) structural details of the electrochemically plated lithium (Li) flakes and their solid electrolyte interphase (SEI), including the composite SEI skin-layer and SEI fossil pieces buried inside the Li matrix. As the SEI skin-layer is largely comprised of nanocrystalline LiF and Li2O in amorphous polymeric matrix, when complete Li stripping occurs, the compromised SEI three-dimensional framework buckles, forming nanoscale bends and wrinkles. We showed that the flexibility and resilience of the SEI skin-layer plays a vital role in preserving an intact SEI 3D framework after Li stripping. The intact SEI network enables the nucleation and growth of the newly plated Li inside the previously formed SEI network in the subsequent cycles, preventing additional large amount of SEI formation between newly plated Li metal and the electrolyte. In addition, cells cycled under the accurately controlled uniaxial pressure can further enhance the repeated utilization of the SEI framework and improve the coulombic efficiency (CE) by up to 97%, demonstrating an effective strategy of reducing the formation of additional SEI and inactive dead Li. The identification of such flexible and porous 3D SEI framework clarifies the working mechanism of SEI in lithium metal anode for batteries. The insights provided in this work will inspire researchers to design more functional artificial 3D SEI on other metal anodes to improve rechargeable metal battery with long cycle life.      
### 37.Source Separation-based Data Augmentation for Improved Joint Beat and Downbeat Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2106.08703.pdf)
>  Due to advances in deep learning, the performance of automatic beat and downbeat tracking in musical audio signals has seen great improvement in recent years. In training such deep learning based models, data augmentation has been found an important technique. However, existing data augmentation methods for this task mainly target at balancing the distribution of the training data with respect to their tempo. In this paper, we investigate another approach for data augmentation, to account for the composition of the training data in terms of the percussive and non-percussive sound sources. Specifically, we propose to employ a blind drum separation model to segregate the drum and non-drum sounds from each training audio signal, filtering out training signals that are drumless, and then use the obtained drum and non-drum stems to augment the training data. We report experiments on four completely unseen test sets, validating the effectiveness of the proposed method, and accordingly the importance of drum sound composition in the training data for beat and downbeat tracking.      
### 38.Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study  [ :arrow_down: ](https://arxiv.org/pdf/2106.08686.pdf)
>  Several variants of deep neural networks have been successfully employed for building parametric models that project variable-duration spoken word segments onto fixed-size vector representations, or acoustic word embeddings (AWEs). However, it remains unclear to what degree we can rely on the distance in the emerging AWE space as an estimate of word-form similarity. In this paper, we ask: does the distance in the acoustic embedding space correlate with phonological dissimilarity? To answer this question, we empirically investigate the performance of supervised approaches for AWEs with different neural architectures and learning objectives. We train AWE models in controlled settings for two languages (German and Czech) and evaluate the embeddings on two tasks: word discrimination and phonological similarity. Our experiments show that (1) the distance in the embedding space in the best cases only moderately correlates with phonological distance, and (2) improving the performance on the word discrimination task does not necessarily yield models that better reflect word phonological similarity. Our findings highlight the necessity to rethink the current intrinsic evaluations for AWEs.      
### 39.Drum-Aware Ensemble Architecture for Improved Joint Musical Beat and Downbeat Tracking  [ :arrow_down: ](https://arxiv.org/pdf/2106.08685.pdf)
>  This paper presents a novel system architecture that integrates blind source separation with joint beat and downbeat tracking in musical audio signals. The source separation module segregates the percussive and non-percussive components of the input signal, over which beat and downbeat tracking are performed separately and then the results are aggregated with a learnable fusion mechanism. This way, the system can adaptively determine how much the tracking result for an input signal should depend on the input's percussive or non-percussive components. Evaluation on four testing sets that feature different levels of presence of drum sounds shows that the new architecture consistently outperforms the widely-adopted baseline architecture that does not employ source separation.      
### 40.STAR-RIS Enabled Heterogeneous Networks: Ubiquitous NOMA Communication and Pervasive Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.08592.pdf)
>  This paper integrates non-orthogonal multiple access (NOMA) and over-the-air federated learning (AirFL) into a unified framework using a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). The STAR-RIS plays an important role in adjusting the decoding order of hybrid users for efficient interference mitigation and omni-directional coverage extension. To capture the impact of non-ideal wireless channels on AirFL, a closed-form expression for the optimality gap (a.k.a. convergence upper bound) between the actual loss and the optimal loss is derived. This analysis reveals that the learning performance is significantly affected by active and passive beamforming schemes as well as wireless noise. Furthermore, when the learning rate diminishes as the training proceeds, the optimality gap is explicitly characterized to converge with a linear rate. To accelerate convergence while satisfying QoS requirements, a mixed-integer non-linear programming (MINLP) problem is formulated by jointly designing the transmit power at users and the configuration mode of STAR-RIS. Next, a trust region-based successive convex approximation method and a penalty-based semidefinite relaxation approach is proposed to handle the decoupled non-convex subproblems iteratively. An alternating optimization algorithm is then developed to find a suboptimal solution for the original MINLP problem. Extensive simulation results show that i) the proposed framework can efficiently support NOMA and AirFL users via concurrent uplink communications, ii) our algorithms can achieve a faster convergence rate on the IID and non-IID settings as compared to baselines, and iii) both the spectrum efficiency and learning performance can be significantly improved with the aid of the well-tuned STAR-RIS.      
### 41.iBatch: Saving Ethereum Fees via Secure and Cost-Effective Batching of Smart-Contract Invocations  [ :arrow_down: ](https://arxiv.org/pdf/2106.08554.pdf)
>  This paper presents iBatch, a middleware system running on top of an operational Ethereum network to enable secure batching of smart-contract invocations against an untrusted relay server off-chain. iBatch does so at a low overhead by validating the server's batched invocations in smart contracts without additional states. The iBatch mechanism supports a variety of policies, ranging from conservative to aggressive batching, and can be configured adaptively to the current workloads. iBatch automatically rewrites smart contracts to integrate with legacy applications and support large-scale deployment. <br>We built an evaluation platform for fast and cost-accurate transaction replaying and constructed real transaction benchmarks on popular Ethereum applications. With a functional prototype of iBatch, we conduct extensive cost evaluations, which shows iBatch saves $14.6\%\sim{}59.1\%$ Gas cost per invocation with a moderate 2-minute delay and $19.06\%\sim{}31.52\%$ Ether cost per invocation with a delay of $0.26\sim{}1.66$ blocks.      
### 42.WSRGlow: A Glow-based Waveform Generative Model for Audio Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.08507.pdf)
>  Audio super-resolution is the task of constructing a high-resolution (HR) audio from a low-resolution (LR) audio by adding the missing band. Previous methods based on convolutional neural networks and mean squared error training objective have relatively low performance, while adversarial generative models are difficult to train and tune. Recently, normalizing flow has attracted a lot of attention for its high performance, simple training and fast inference. In this paper, we propose WSRGlow, a Glow-based waveform generative model to perform audio super-resolution. Specifically, 1) we integrate WaveNet and Glow to directly maximize the exact likelihood of the target HR audio conditioned on LR information; and 2) to exploit the audio information from low-resolution audio, we propose an LR audio encoder and an STFT encoder, which encode the LR information from the time domain and frequency domain respectively. The experimental results show that the proposed model is easier to train and outperforms the previous works in terms of both objective and perceptual quality. WSRGlow is also the first model to produce 48kHz waveforms from 12kHz LR audio.      
### 43.Tonal Frequencies, Consonance, Dissonance: A Math-Bio Intersection  [ :arrow_down: ](https://arxiv.org/pdf/2106.08479.pdf)
>  To date, calculating the frequencies of musical notes requires one to know the frequency of some reference note. In this study, first-order ordinary differential equations are used to arrive at a mathematical model to determine tonal frequencies using their respective note indices. In the next part of the study, an analysis that is based on the fundamental musical frequencies is conducted to theoretically and neurobiologically explain the consonance and dissonance caused by the different musical notes in the chromatic scale which is based on the fact that systematic patterns of sound invoke pleasure. The reason behind the richness of harmony and the sonic interference and degree of consonance in musical chords are discussed. Since a human mind analyses everything relatively, anything other than the most consonant notes sounds dissonant. In conclusion, the study explains clearly why musical notes and in toto, music sounds the way it does.      
### 44.Multi-Resolution Continuous Normalizing Flows  [ :arrow_down: ](https://arxiv.org/pdf/2106.08462.pdf)
>  Recent work has shown that Neural Ordinary Differential Equations (ODEs) can serve as generative models of images using the perspective of Continuous Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and invertible generation/density estimation. In this work we introduce a Multi-Resolution variant of such models (MRCNF), by characterizing the conditional distribution over the additional information required to generate a fine image that is consistent with the coarse image. We introduce a transformation between resolutions that allows for no change in the log likelihood. We show that this approach yields comparable likelihood values for various image datasets, with improved performance at higher resolutions, with fewer parameters, using only 1 GPU.      
### 45.Co-Design of Free-Space Metasurface Optical Neuromorphic Classifiers for High Performance  [ :arrow_down: ](https://arxiv.org/pdf/2106.08435.pdf)
>  Classification of features in a scene typically requires conversion of the incoming photonic field into the electronic domain. Recently, an alternative approach has emerged whereby passive structured materials can perform classification tasks by directly using free-space propagation and diffraction of light. In this manuscript, we present a theoretical and computational study of such systems and establish the basic features that govern their performance. We show that system architecture, material structure, and input light field are intertwined and need to be co-designed to maximize classification accuracy. Our simulations show that a single layer metasurface can achieve classification accuracy better than conventional linear classifiers, with an order of magnitude fewer diffractive features than previously reported. For a wavelength {\lambda}, single layer metasurfaces of size with aperture density achieve ~96% testing accuracy on the MNIST dataset, for an optimized distance ~ to the output plane. This is enabled by an intrinsic nonlinearity in photodetection, despite the use of linear optical metamaterials. Furthermore, we find that once the system is optimized, the number of diffractive features is the main determinant of classification performance. The slow asymptotic scaling with the number of apertures suggests a reason why such systems may benefit from multiple layer designs. Finally, we show a trade-off between the number of apertures and fabrication noise.      
### 46.Optimal control of a 2D diffusion-advection process with a team of mobile actuators under jointly optimal guidance  [ :arrow_down: ](https://arxiv.org/pdf/2106.08429.pdf)
>  This paper describes an optimization framework to control a distributed parameter system (DPS) using a team of mobile actuators. The framework simultaneously seeks optimal control of the DPS and optimal guidance of the mobile actuators such that a cost function associated with both the DPS and the mobile actuators is minimized subject to the dynamics of each. The cost incurred from controlling the DPS is linear-quadratic, which is transformed into an equivalent form as a quadratic term associated with an operator-valued Riccati equation. This equivalent form reduces the problem to seeking for guidance only because the optimal control can be recovered once the optimal guidance is obtained. We establish conditions for the existence of a solution to the proposed problem. Since computing an optimal solution requires approximation, we also establish the conditions for convergence to the exact optimal solution of the approximate optimal solution. That is, when evaluating these two solutions by the original cost function, the difference becomes arbitrarily small as the approximation gets finer. Two numerical examples demonstrate the performance of the optimal control and guidance obtained from the proposed approach.      
### 47.Pathological voice adaptation with autoencoder-based voice conversion  [ :arrow_down: ](https://arxiv.org/pdf/2106.08427.pdf)
>  In this paper, we propose a new approach to pathological speech synthesis. Instead of using healthy speech as a source, we customise an existing pathological speech sample to a new speaker's voice characteristics. This approach alleviates the evaluation problem one normally has when converting typical speech to pathological speech, as in our approach, the voice conversion (VC) model does not need to be optimised for speech degradation but only for the speaker change. This change in the optimisation ensures that any degradation found in naturalness is due to the conversion process and not due to the model exaggerating characteristics of a speech pathology. To show a proof of concept of this method, we convert dysarthric speech using the UASpeech database and an autoencoder-based VC technique. Subjective evaluation results show reasonable naturalness for high intelligibility dysarthric speakers, though lower intelligibility seems to introduce a marginal degradation in naturalness scores for mid and low intelligibility speakers compared to ground truth. Conversion of speaker characteristics for low and high intelligibility speakers is successful, but not for mid. Whether the differences in the results for the different intelligibility levels is due to the intelligibility levels or due to the speakers needs to be further investigated.      
### 48.A Framework for Discovering Optimal Solutions in Photonic Inverse Design  [ :arrow_down: ](https://arxiv.org/pdf/2106.08419.pdf)
>  Photonic inverse design has emerged as an indispensable engineering tool for complex optical systems. In many instances it is important to optimize for both material and geometry configurations, which results in complex non-smooth search spaces with multiple local minima. Finding solutions approaching global optimum may present a computationally intractable task. Here, we develop a framework that allows expediting the search of solutions close to global optimum on complex optimization spaces. We study the way representative black box optimization algorithms work, including genetic algorithm (GA), particle swarm optimization (PSO), simulated annealing (SA), and mesh adaptive direct search (NOMAD). We then propose and utilize a two-step approach that identifies best performance algorithms on arbitrarily complex search spaces. We reveal a connection between the search space complexity and algorithm performance and find that PSO and NOMAD consistently deliver better performance for mixed integer problems encountered in photonic inverse design, particularly with the account of material combinations. Our results differ from a commonly anticipated advantage of GA. Our findings will foster more efficient design of photonic systems with optimal performance.      
### 49.On the Sample Complexity and Metastability of Heavy-tailed Policy Search in Continuous Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.08414.pdf)
>  Reinforcement learning is a framework for interactive decision-making with incentives sequentially revealed across time without a system dynamics model. Due to its scaling to continuous spaces, we focus on policy search where one iteratively improves a parameterized policy with stochastic policy gradient (PG) updates. In tabular Markov Decision Problems (MDPs), under persistent exploration and suitable parameterization, global optimality may be obtained. By contrast, in continuous space, the non-convexity poses a pathological challenge as evidenced by existing convergence results being mostly limited to stationarity or arbitrary local extrema. To close this gap, we step towards persistent exploration in continuous space through policy parameterizations defined by distributions of heavier tails defined by tail-index parameter alpha, which increases the likelihood of jumping in state space. Doing so invalidates smoothness conditions of the score function common to PG. Thus, we establish how the convergence rate to stationarity depends on the policy's tail index alpha, a Holder continuity parameter, integrability conditions, and an exploration tolerance parameter introduced here for the first time. Further, we characterize the dependence of the set of local maxima on the tail index through an exit and transition time analysis of a suitably defined Markov chain, identifying that policies associated with Levy Processes of a heavier tail converge to wider peaks. This phenomenon yields improved stability to perturbations in supervised learning, which we corroborate also manifests in improved performance of policy search, especially when myopic and farsighted incentives are misaligned.      
### 50.Plane and Sample: Maximizing Information about Autonomous Vehicle Performance using Submodular Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.08389.pdf)
>  As autonomous vehicles (AVs) take on growing Operational Design Domains (ODDs), they need to go through a systematic, transparent, and scalable evaluation process to demonstrate their benefits to society. Current scenario sampling techniques for AV performance evaluation usually focus on a specific functionality, such as lane changing, and do not accommodate a transfer of information about an AV system from one ODD to the next. In this paper, we reformulate the scenario sampling problem across ODDs and functionalities as a submodular optimization problem. To do so, we abstract AV performance as a Bayesian Hierarchical Model, which we use to infer information gained by revealing performance in new scenarios. We propose the information gain as a measure of scenario relevance and evaluation progress. Furthermore, we leverage the submodularity, or diminishing returns, property of the information gain not only to find a near-optimal scenario set, but also to propose a stopping criterion for an AV performance evaluation campaign. We find that we only need to explore about 7.5% of the scenario space to meet this criterion, a 23% improvement over Latin Hypercube Sampling.      
### 51.A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2106.08372.pdf)
>  With the increasing safety validation requirements for the release of a self-driving car, alternative approaches, such as simulation-based testing, are emerging in addition to conventional real-world testing. In order to rely on virtual tests the employed sensor models have to be validated. For this reason, it is necessary to quantify the discrepancy between simulation and reality in order to determine whether a certain fidelity is sufficient for a desired intended use. There exists no sound method to measure this simulation-to-reality gap of radar perception for autonomous driving. We address this problem by introducing a multi-layered evaluation approach, which consists of a combination of an explicit and an implicit sensor model evaluation. The former directly evaluates the realism of the synthetically generated sensor data, while the latter refers to an evaluation of a downstream target application. In order to demonstrate the method, we evaluated the fidelity of three typical radar model types (ideal, data-driven, ray tracing-based) and their applicability for virtually testing radar-based multi-object tracking. We have shown the effectiveness of the proposed approach in terms of providing an in-depth sensor model assessment that renders existing disparities visible and enables a realistic estimation of the overall model fidelity across different scenarios.      

# ArXiv eess --Wed, 23 Jun 2021
### 1.Failing with Grace: Learning Neural Network Controllers that are Boundedly Unsafe  [ :arrow_down: ](https://arxiv.org/pdf/2106.11881.pdf)
>  In this work, we consider the problem of learning a feed-forward neural network (NN) controller to safely steer an arbitrarily shaped planar robot in a compact and obstacle-occluded workspace. Unlike existing methods that depend strongly on the density of data points close to the boundary of the safe state space to train NN controllers with closed-loop safety guarantees, we propose an approach that lifts such assumptions on the data that are hard to satisfy in practice and instead allows for graceful safety violations, i.e., of a bounded magnitude that can be spatially controlled. To do so, we employ reachability analysis methods to encapsulate safety constraints in the training process. Specifically, to obtain a computationally efficient over-approximation of the forward reachable set of the closed-loop system, we partition the robot's state space into cells and adaptively subdivide the cells that contain states which may escape the safe set under the trained control law. To do so, we first design appropriate under- and over-approximations of the robot's footprint to adaptively subdivide the configuration space into cells. Then, using the overlap between each cell's forward reachable set and the set of infeasible robot configurations as a measure for safety violations, we introduce penalty terms into the loss function that penalize this overlap in the training process. As a result, our method can learn a safe vector field for the closed-loop system and, at the same time, provide numerical worst-case bounds on safety violation over the whole configuration space, defined by the overlap between the over-approximation of the forward reachable set of the closed-loop system and the set of unsafe states. Moreover, it can control the tradeoff between computational complexity and tightness of these bounds. Finally, we provide a simulation study that verifies the efficacy of the proposed scheme.      
### 2.Reconfigurable Intelligent Surface-Aided Wireless Power Transfer Systems: Analysis and Implementation  [ :arrow_down: ](https://arxiv.org/pdf/2106.11805.pdf)
>  Reconfigurable intelligent surface (RIS) is a promising technology for RF wireless power transfer (WPT) as it is capable of beamforming and beam focusing without using active and power-hungry components. In this paper, we propose a multi-tile RIS beam scanning (MTBS) algorithm for powering up internet-of-things (IoT) devices. Considering the hardware limitations of the IoT devices, the proposed algorithm requires only power information to enable the beam focusing capability of the RIS. Specifically, we first divide the RIS into smaller RIS tiles. Then, all RIS tiles and the phased array transmitter are iteratively scanned and optimized to maximize the receive power. We elaborately analyze the proposed algorithm and build a simulator to verify it. Furthermore, we have built a real-life testbed of RIS-aided WPT systems to validate the algorithm. The experimental results show that the proposed MTBS algorithm can properly control the transmission phase of the transmitter and the reflection phase of the RIS to focus the power at the receiver. Consequently, after executing the algorithm, about 20 dB improvement of the receive power is achieved compared to the case that all unit cells of the RIS are in OFF state. By experiments, we confirm that the RIS with the MTBS algorithm can greatly enhance the power transfer efficiency.      
### 3.Deep neural network Based Low-latency Speech Separation with Asymmetric analysis-Synthesis Window Pair  [ :arrow_down: ](https://arxiv.org/pdf/2106.11794.pdf)
>  Time-frequency masking or spectrum prediction computed via short symmetric windows are commonly used in low-latency deep neural network (DNN) based source separation. In this paper, we propose the usage of an asymmetric analysis-synthesis window pair which allows for training with targets with better frequency resolution, while retaining the low-latency during inference suitable for real-time speech enhancement or assisted hearing applications. In order to assess our approach across various model types and datasets, we evaluate it with both speaker-independent deep clustering (DC) model and a speaker-dependent mask inference (MI) model. We report an improvement in separation performance of up to 1.5 dB in terms of source-to-distortion ratio (SDR) while maintaining an algorithmic latency of 8 ms.      
### 4.Improving Ultrasound Tongue Image Reconstruction from Lip Images Using Self-supervised Learning and Attention Mechanism  [ :arrow_down: ](https://arxiv.org/pdf/2106.11769.pdf)
>  Speech production is a dynamic procedure, which involved multi human organs including the tongue, jaw and lips. Modeling the dynamics of the vocal tract deformation is a fundamental problem to understand the speech, which is the most common way for human daily communication. Researchers employ several sensory streams to describe the process simultaneously, which are incontrovertibly statistically related to other streams. In this paper, we address the following question: given an observable image sequences of lips, can we picture the corresponding tongue motion. We formulated this problem as the self-supervised learning problem, and employ the two-stream convolutional network and long-short memory network for the learning task, with the attention mechanism. We evaluate the performance of the proposed method by leveraging the unlabeled lip videos to predict an upcoming ultrasound tongue image sequence. The results show that our model is able to generate images that close to the real ultrasound tongue images, and results in the matching between two imaging modalities.      
### 5.Analysis and Tuning of a Voice Assistant System for Dysfluent Speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.11759.pdf)
>  Dysfluencies and variations in speech pronunciation can severely degrade speech recognition performance, and for many individuals with moderate-to-severe speech disorders, voice operated systems do not work. Current speech recognition systems are trained primarily with data from fluent speakers and as a consequence do not generalize well to speech with dysfluencies such as sound or word repetitions, sound prolongations, or audible blocks. The focus of this work is on quantitative analysis of a consumer speech recognition system on individuals who stutter and production-oriented approaches for improving performance for common voice assistant tasks (i.e., "what is the weather?"). At baseline, this system introduces a significant number of insertion and substitution errors resulting in intended speech Word Error Rates (isWER) that are 13.64\% worse (absolute) for individuals with fluency disorders. We show that by simply tuning the decoding parameters in an existing hybrid speech recognition system one can improve isWER by 24\% (relative) for individuals with fluency disorders. Tuning these parameters translates to 3.6\% better domain recognition and 1.7\% better intent recognition relative to the default setup for the 18 study participants across all stuttering severities.      
### 6.Optimizing Partial Power Processing for Second-Use Battery Energy Storage Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.11749.pdf)
>  Repurposing automotive batteries to second-use battery energy storage systems (2-BESS) may have environmental and economic benefits. The challenge with second-use batteries is the uncertainty and diversity of the expected packs in terms of their chemistry, capacity and remaining useful life. This paper introduces a new strategy to optimize 2-BESS performance despite the diversity or heterogeneity of individual batteries while reducing the cost of power conversion. In this paper, the statistical distribution of the power heterogeneity in the supply of batteries is considered when optimizing the choice of power converters and designing the power flow within the battery energy storage system (BESS) to maximize battery utilization. By leveraging a new lite-sparse hierarchical partial power processing (LS-HiPPP) approach, we show a hierarchy in partial power processing (PPP) partitions power converters to a) significantly reduce converter ratings, b) process less power to achieve high system efficiency with lower cost (lower efficiency) converters, and c) take advantage of economies of scale by requiring only a minimal number of sets of identical converters. The results demonstrate that LS-HiPPP architectures offer the best tradeoff between battery utilization and converter cost and had higher system efficiency than conventional partial power processing (C-PPP) in all cases.      
### 7.MIMIR: Deep Regression for Automated Analysis of UK Biobank Body MRI  [ :arrow_down: ](https://arxiv.org/pdf/2106.11731.pdf)
>  UK Biobank (UKB) is conducting a large-scale study of more than half a million volunteers, collecting health-related information on genetics, lifestyle, blood biochemistry, and more. Medical imaging furthermore targets 100,000 subjects, with 70,000 follow-up sessions, enabling measurements of organs, muscle, and body composition. With up to 170,000 mounting MR images, various methodologies are accordingly engaged in large-scale image analysis. This work presents an experimental inference engine that can automatically predict a comprehensive profile of subject metadata from UKB neck-to-knee body MRI. In cross-validation, it accurately inferred baseline characteristics such as age, height, weight, and sex, but also emulated measurements of body composition by DXA, organ volumes, and abstract properties like grip strength, pulse rate, and type 2 diabetic status (AUC: 0.866). The proposed system can automatically analyze thousands of subjects within hours and provide individual confidence intervals. The underlying methodology is based on convolutional neural networks for image-based mean-variance regression on two-dimensional representations of the MRI data. This work aims to make the proposed system available for free to researchers, who can use it to obtain fast and fully-automated estimates of 72 different measurements immediately upon release of new UK Biobank image data.      
### 8.Deep Stereo Image Compression with Decoder Side Information using Wyner Common Information  [ :arrow_down: ](https://arxiv.org/pdf/2106.11723.pdf)
>  We present a novel deep neural network (DNN) architecture for compressing an image when a correlated image is available as side information only at the decoder. This problem is known as distributed source coding (DSC) in information theory. In particular, we consider a pair of stereo images, which generally have high correlation with each other due to overlapping fields of view, and assume that one image of the pair is to be compressed and transmitted, while the other image is available only at the decoder. In the proposed architecture, the encoder maps the input image to a latent space, quantizes the latent representation, and compresses it using entropy coding. The decoder is trained to extract the Wyner's common information between the input image and the correlated image from the latter. The received latent representation and the locally generated common information are passed through a decoder network to obtain an enhanced reconstruction of the input image. The common information provides a succinct representation of the relevant information at the receiver. We train and demonstrate the effectiveness of the proposed approach on the KITTI dataset of stereo image pairs. Our results show that the proposed architecture is capable of exploiting the decoder-only side information, and outperforms previous work on stereo image compression with decoder side information.      
### 9.Robust EMRAN based Neural Aided Learning Controller for Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2106.11716.pdf)
>  This paper presents an online evolving neural network-based inverse dynamics learning controller for an autonomous vehicles' longitudinal and lateral control under model uncertainties and disturbances. The inverse dynamics of the vehicle is approximated using a feedback error learning mechanism that utilizes a dynamic Radial Basis Function neural network, referred to as the Extended Minimal Resource Allocating Network (EMRAN). EMRAN uses an extended Kalman filter approach for learning and a growing/pruning condition helps in keeping the number of hidden neurons minimum. The online learning algorithm helps in handling the uncertainties and dynamic variations and also the unknown disturbances on the road. The proposed control architecture employs two coupled conventional controllers aided by the EMRAN inverse dynamics controller. The control architecture has a conventional PID controller for cruise control and a Stanley controller for path-tracking. Performances of both the longitudinal and lateral controllers are compared with existing control methods and the results clearly indicate that the proposed control scheme handles the disturbances and parametric uncertainties better, and also provides better tracking performance in autonomous vehicles.      
### 10.A New Channel Estimation Strategy in Intelligent Reflecting Surface Assisted Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.11700.pdf)
>  Channel estimation is the main hurdle to reaping the benefits promised by the intelligent reflecting surface (IRS), due to its absence of ability to transmit/receive pilot signals as well as the huge number of channel coefficients associated with its reflecting elements. Recently, a breakthrough was made in reducing the channel estimation overhead by revealing that the IRS-BS (base station) channels are common in the cascaded user-IRS-BS channels of all the users, and if the cascaded channel of one typical user is estimated, the other users' cascaded channels can be estimated very quickly based on their correlation with the typical user's channel \cite{b5}. One limitation of this strategy, however, is the waste of user energy, because many users need to keep silent when the typical user's channel is estimated. In this paper, we reveal another correlation hidden in the cascaded user-IRS-BS channels by observing that the user-IRS channel is common in all the cascaded channels from users to each BS antenna as well. Building upon this finding, we propose a novel two-phase channel estimation protocol in the uplink communication. Specifically, in Phase I, the correlation coefficients between the channels of a typical BS antenna and those of the other antennas are estimated; while in Phase II, the cascaded channel of the typical antenna is estimated. In particular, all the users can transmit throughput Phase I and Phase II. Under this strategy, it is theoretically shown that the minimum number of time instants required for perfect channel estimation is the same as that of the aforementioned strategy in the ideal case without BS noise. Then, in the case with BS noise, we show by simulation that the channel estimation error of our proposed scheme is significantly reduced thanks to the full exploitation of the user energy.      
### 11.Over-the-Air Computation via Cloud Radio Access Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.11649.pdf)
>  Over-the-air computation (AirComp) has recently been recognized as a promising scheme for a fusion center to achieve fast distributed data aggregation in wireless networks via exploiting the superposition property of multiple-access channels. Since it is challenging to provide reliable data aggregation for a large number of devices using AirComp, in this paper, we propose to enable AirComp via the cloud radio access network (Cloud-RAN) architecture, where a large number of antennas are deployed at separate sites called remote radio heads (RRHs). However, the potential densification gain provided by Cloud-RAN is generally bottlenecked by the limited capacity of the fronthaul links connecting the RRHs and the fusion center. To this end, we formulate a joint design problem for AirComp transceivers and quantization bits allocation and propose an efficient algorithm to tackle this problem. Our numerical results shows the advantages of the proposed architecture compared with the state-of-the-art solutions.      
### 12.Machine Learning for Model Order Selection in MIMO OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.11633.pdf)
>  A variety of wireless channel estimation methods, e.g., MUSIC and ESPRIT, rely on prior knowledge of the model order. Therefore, it is important to correctly estimate the number of multipath components (MPCs) which compose such channels. However, environments with many scatterers may generate MPCs which are closely spaced. This clustering of MPCs in addition to noise makes the model order selection task difficult in practice to currently known algorithms. In this paper, we exploit the multidimensional characteristics of MIMO orthogonal frequency division multiplexing (OFDM) systems and propose a machine learning (ML) method capable of determining the number of MPCs with a higher accuracy than state of the art methods in almost coherent scenarios. Moreover, our results show that our proposed ML method has an enhanced reliability.      
### 13.Learning-Based Practical Light Field Image Compression Using A Disparity-Aware Model  [ :arrow_down: ](https://arxiv.org/pdf/2106.11558.pdf)
>  Light field technology has increasingly attracted the attention of the research community with its many possible applications. The lenslet array in commercial plenoptic cameras helps capture both the spatial and angular information of light rays in a single exposure. While the resulting high dimensionality of light field data enables its superior capabilities, it also impedes its extensive adoption. Hence, there is a compelling need for efficient compression of light field images. Existing solutions are commonly composed of several separate modules, some of which may not have been designed for the specific structure and quality of light field data. This increases the complexity of the codec and results in impractical decoding runtimes. We propose a new learning-based, disparity-aided model for compression of 4D light field images capable of parallel decoding. The model is end-to-end trainable, eliminating the need for hand-tuning separate modules and allowing joint learning of rate and distortion. The disparity-aided approach ensures the structural integrity of the reconstructed light fields. Comparisons with the state of the art show encouraging performance in terms of PSNR and MS-SSIM metrics. Also, there is a notable gain in the encoding and decoding runtimes. Source code is available at <a class="link-external link-https" href="https://moha23.github.io/LF-DAAE" rel="external noopener nofollow">this https URL</a>.      
### 14.On Minimizing Symbol Error Rate Over Fading Channels with Low-Resolution Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2106.11524.pdf)
>  We analyze the symbol error probability (SEP) of $M$-ary pulse amplitude modulation ($M$-PAM) receivers equipped with optimal low-resolution quantizers. We first show that the optimum detector can be reduced to a simple decision rule. Using this simplification, an exact SEP expression for quantized $M$-PAM receivers is obtained when Nakagami-$m$ fading channel is considered. The derived expression enables the optimization of the quantizer and/or constellation under the minimum SEP criterion. Our analysis of optimal quantization for equidistant $M$-PAM receiver reveals the existence of error floor which decays at a double exponential rate with increasing quantization bits, $b$. Moreover, by also allowing the transmitter to optimize the constellation based on the statistics of the fading channel, we prove that the error floor can be eliminated but at a lower decay exponent than the unquantized case. Characterization of this decay exponent is provided in this paper. We also expose the outage performance limitations of SEP-optimal uniform quantizers. To be more precise, its decay exponent does not improve with $b$. Lastly, we demonstrate that the decay exponent of a quantized receiver can be complemented by receive antenna diversity techniques.      
### 15.Cooperative mmWave PHD-SLAM with Moving Scatterers  [ :arrow_down: ](https://arxiv.org/pdf/2106.11515.pdf)
>  Using the multiple-model (MM) probability hypothesis density (PHD) filter, millimeter wave (mmWave) radio simultaneous localization and mapping (SLAM) in vehicular scenarios is susceptible to movements of objects, in particular vehicles driving in parallel with the ego vehicle. We propose and evaluate two countermeasures to track vehicle scatterers (VSs) in mmWave radio MM-PHD-SLAM. First, locally at each vehicle, we generate and treat the VS map PHD in the context of Bayesian recursion, and modify vehicle state correction with the VS map PHD. Second, in the global map fusion process at the base station, we average the VS map PHD and upload it with self-vehicle posterior density, compute fusion weights, and prune the target with low Gaussian weight in the context of arithmetic average-based map fusion. From simulation results, the proposed cooperative mmWave radio MM-PHD-SLAM filter is shown to outperform the previous filter in VS scenarios.      
### 16.Encoder-Decoder Architectures for Clinically Relevant Coronary Artery Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.11447.pdf)
>  Coronary X-ray angiography is a crucial clinical procedure for the diagnosis and treatment of coronary artery disease, which accounts for roughly 16% of global deaths every year. However, the images acquired in these procedures have low resolution and poor contrast, making lesion detection and assessment challenging. Accurate coronary artery segmentation not only helps mitigate these problems, but also allows the extraction of relevant anatomical features for further analysis by quantitative methods. Although automated segmentation of coronary arteries has been proposed before, previous approaches have used non-optimal segmentation criteria, leading to less useful results. Most methods either segment only the major vessel, discarding important information from the remaining ones, or segment the whole coronary tree based mostly on contrast information, producing a noisy output that includes vessels that are not relevant for diagnosis. We adopt a better-suited clinical criterion and segment vessels according to their clinical relevance. Additionally, we simultaneously perform catheter segmentation, which may be useful for diagnosis due to the scale factor provided by the catheter's known diameter, and is a task that has not yet been performed with good results. To derive the optimal approach, we conducted an extensive comparative study of encoder-decoder architectures trained on a combination of focal loss and a variant of generalized dice loss. Based on the EfficientNet and the UNet++ architectures, we propose a line of efficient and high-performance segmentation models using a new decoder architecture, the EfficientUNet++, whose best-performing version achieved average dice scores of 0.8904 and 0.7526 for the artery and catheter classes, respectively, and an average generalized dice score of 0.9234.      
### 17.Dual-port grid-forming control of MMCs and its applications to grids of grids  [ :arrow_down: ](https://arxiv.org/pdf/2106.11378.pdf)
>  Motivated by the emergence of power systems that consist of HVAC and HVDC subgrids this work focuses on grid-forming (GFM) control of Interconnecting Power Converters (IPCs) that are the key elements for connecting HVAC and HVDC systems. We introduce the concept of dual-port GFM control that leverages the ability of Modular Multilevel Converters (MMCs) to simultaneously form its AC and DC terminal voltage and present two dual-port GFM MMC controls. We provide analytical results and high-fidelity simulations that demonstrate that (i) dual-port GFM control is more resilient to contingencies (i.e., line and generator outages) than state-of-the-art single-port GFM control, and (ii) unlike single-port GFM control, dual-port GFM control does not require assigning grid-forming and grid-following (GFL) roles to the IPC terminals in grids of grids. Finally, we provide an in-depth discussion and comparison of single-port GFM control and the proposed dual-port GFM controls.      
### 18.Tensor Learning-based Precoder Codebooks for FD-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.11374.pdf)
>  This paper develops an efficient procedure for designing low-complexity codebooks for precoding in a full-dimension (FD) multiple-input multiple-output (MIMO) system with a uniform planar array (UPA) antenna at the transmitter (Tx) using tensor learning. In particular, instead of using statistical channel models, we utilize a model-free data-driven approach with foundations in machine learning to generate codebooks that adapt to the surrounding propagation conditions. We use a tensor representation of the FD-MIMO channel and exploit its properties to design quantized version of the channel precoders. We find the best representation of the optimal precoder as a function of Kronecker Product (KP) of two low-dimensional precoders, respectively corresponding to the horizontal and vertical dimensions of the UPA, obtained from the tensor decomposition of the channel. We then quantize this precoder to design product codebooks such that an average loss in mutual information due to quantization of channel state information (CSI) is minimized. The key technical contribution lies in exploiting the constraints on the precoders to reduce the product codebook design problem to an unsupervised clustering problem on a Cartesian Product Grassmann manifold (CPM), where the cluster centroids form a finite-sized precoder codebook. This codebook can be found efficiently by running a $K$-means clustering on the CPM. With a suitable induced distance metric on the CPM, we show that the construction of product codebooks is equivalent to finding the optimal set of centroids on the factor manifolds corresponding to the horizontal and vertical dimensions. Simulation results are presented to demonstrate the capability of the proposed design criterion in learning the codebooks and the attractive performance of the designed codebooks.      
### 19.Reinforcement Learning for Resource Allocation in Steerable Laser-based Optical Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.11368.pdf)
>  Vertical Cavity Surface Emitting Lasers (VCSELs) have demonstrated suitability for data transmission in indoor optical wireless communication (OWC) systems due to the high modulation bandwidth and low manufacturing cost of these sources. Specifically, resource allocation is one of the major challenges that can affect the performance of multi-user optical wireless systems. In this paper, an optimisation problem is formulated to optimally assign each user to an optical access point (AP) composed of multiple VCSELs within a VCSEL array at a certain time to maximise the signal to interference plus noise ratio (SINR). In this context, a mixed-integer linear programming (MILP) model is introduced to solve this optimisation problem. Despite the optimality of the MILP model, it is considered impractical due to its high complexity, high memory and full system information requirements. Therefore, reinforcement Learning (RL) is considered, which recently has been widely investigated as a practical solution for various optimization problems in cellular networks due to its ability to interact with environments with no previous experience. In particular, a Q-learning (QL) algorithm is investigated to perform resource management in a steerable VCSEL-based OWC systems. The results demonstrate the ability of the QL algorithm to achieve optimal solutions close to the MILP model. Moreover, the adoption of beam steering, using holograms implemented by exploiting liquid crystal devices, results in further enhancement in the performance of the network considered.      
### 20.Adaptive Sampling for Structure Preserving Model Order Reduction of Port-Hamiltonian Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.11366.pdf)
>  We present an adaptive sampling strategy for the optimization-based structure preserving model order reduction (MOR) algorithm developed in [Schwerdtner, P. and Voigt, M. (2020). Structure preserving model order reduction by parameter optimization, Preprint <a class="link-https" data-arxiv-id="2011.07567" href="https://arxiv.org/abs/2011.07567">arXiv:2011.07567</a>]. This strategy reduces the computational demand and the required a priori knowledge about the given full order model, while at the same time retaining a high accuracy compared to other structure preserving but also unstructured MOR algorithms. A numerical study with a port-Hamiltonian benchmark system demonstrates the effectiveness of our method combined with its new adaptive sampling strategy. We also investigate the distribution of the sample points.      
### 21.Port-Hamiltonian System Identification from Noisy Frequency Response Data  [ :arrow_down: ](https://arxiv.org/pdf/2106.11355.pdf)
>  We present a new method for the identification of linear time-invariant passive systems from noisy frequency response data. In particular, we propose to fit a parametrized port-Hamiltonian (pH) system, which is automatically passive, to supplied data with respect to a least-squares objective function. In a numerical study, we assess the accuracy of the resulting identified models by comparing our method to two other frequency domain system identification methods. One of the methods being compared is a recently published identification procedure that also computes pH systems and the other one is the well-known vector-fitting algorithm, which provides unstructured models. The numerical evaluation demonstrates a substantial increase in accuracy of our method compared to the other pH identification procedure and a slightly improved accuracy compared to vector-fitting. This underlines the suitability of our method for the estimation of passive or pH systems - in particular from noisy frequency response data.      
### 22.Towards Deep Learning-assisted Quantification of Inflammation in Spondyloarthritis: Intensity-based Lesion Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.11343.pdf)
>  Purpose: To develop a semi-automated, AI-assisted workflow for segmentation of inflammatory lesions on STIR MRI of sacroiliac joints (SIJs) in adult patients with axial spondyloarthritis. <br>Methods: Baseline human performance in manual segmentation of inflammatory lesions was first established in eight patients with axial spondyloarthritis recruited within a prospective study conducted between April 2018 and July 2019. To improve readers' consistency a semi-automated procedure was developed, comprising (1) manual segmentation of 'normal bone' and 'disease' regions (2) automatic segmentation of lesions, i.e., voxels in the disease region with outlying intensity with respect to the normal bone, and (3) human intervention to remove erroneously segmented areas. Segmentation of disease region (subchondral bone) was automated via supervised deep learning; 200 image slices (eight subjects) were used for algorithm training with cross validation, 48 (two subjects) - for testing and 500 (20 subjects) - for evaluation based on visual assessment. The data, code, and model are available at <a class="link-external link-https" href="https://github.com/c-hepburn/Bone_MRI" rel="external noopener nofollow">this https URL</a>. Human and model performance were assessed in terms of Dice coefficient. <br>Results: Intra-reader median Dice coefficients, evaluated from comparison of manual segmentation trials of inflammatory lesions, were 0.63 and 0.69 for the two readers, respectively. Inter-reader median Dice was in the range of 0.53 to 0.56 and increased to 0.84 using the semi-automated approach. Deep learning model ensemble showed average Dice of 0.94 in subchondral bone segmentation. <br>Conclusions: We describe a semi-automated, AI-assisted workflow which improves the objectivity and consistency of radiological segmentation of inflammatory load in SIJs.      
### 23.Context-aware PolyUNet for Liver and Lesion Segmentation from Abdominal CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.11330.pdf)
>  Accurate liver and lesion segmentation from computed tomography (CT) images are highly demanded in clinical practice for assisting the diagnosis and assessment of hepatic tumor disease. However, automatic liver and lesion segmentation from contrast-enhanced CT volumes is extremely challenging due to the diversity in contrast, resolution, and quality of images. Previous methods based on UNet for 2D slice-by-slice or 3D volume-by-volume segmentation either lack sufficient spatial contexts or suffer from high GPU computational cost, which limits the performance. To tackle these issues, we propose a novel context-aware PolyUNet for accurate liver and lesion segmentation. It jointly explores structural diversity and consecutive t-adjacent slices to enrich feature expressive power and spatial contextual information while avoiding the overload of GPU memory consumption. In addition, we utilize zoom out/in and two-stage refinement strategy to exclude the irrelevant contexts and focus on the specific region for the fine-grained segmentation. Our method achieved very competitive performance at the MICCAI 2017 Liver Tumor Segmentation (LiTS) Challenge among all tasks with a single model and ranked the $3^{rd}$, $12^{th}$, $2^{nd}$, and $5^{th}$ places in the liver segmentation, lesion segmentation, lesion detection, and tumor burden estimation, respectively.      
### 24.Distributed Beam Training for Intelligent Reflecting Surface Enabled Multi-Hop Routing  [ :arrow_down: ](https://arxiv.org/pdf/2106.11896.pdf)
>  Intelligent reflecting surface (IRS) is an emerging technology to enhance the spectral and energy efficiency of wireless communications cost-effectively. This letter considers a new multi-IRS aided wireless network where a cascaded line-of-sight (LoS) link is established between the base station (BS) and a remote user by leveraging the multi-hop signal reflection of selected IRSs. As compared to the conventional single-/double-hop IRS system, multi-hop IRS system provides more pronounced path diversity and cooperative passive beamforming gains, especially in the environment with dense obstacles. However, a more challenging joint active/passive beamforming and multi-hop beam routing problem also arises for maximizing the end-to-end channel gain. Furthermore, the number of IRS-associated channel coefficients increases drastically with the number of IRS hops. To tackle the above issues, in this letter we propose a new and efficient beam training based solution by considering the use of practical codebook-based BS/IRS active/passive beamforming without the need of explicit channel estimation. Instead of exhaustively or sequentially searching over all combinations of active and passive beam patterns for each beam route, a distributed beam training scheme is proposed to reduce the complexity, by exploiting the (nearly) time-invariant BS-IRS and inter-IRS channels and the cooperative training among the BS and IRSs' controllers. Simulation results show that our proposed design achieves the end-to-end channel gain close to that of the sequential beam search, but at a much lower training overhead and complexity.      
### 25.Glance and Gaze: A Collaborative Learning Framework for Single-channel Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.11789.pdf)
>  The capability of the human to pay attention to both coarse and fine-grained regions has been applied to computer vision tasks. Motivated by that, we propose a collaborative learning framework in the complex domain for monaural noise suppression. The proposed system consists of two principal modules, namely spectral feature extraction module (FEM) and stacked glance-gaze modules (GGMs). In FEM, the UNet-block is introduced after each convolution layer, enabling the feature recalibration from multiple scales. In each GGM, we decompose the multi-target optimization in the complex spectrum into two sub-tasks. Specifically, the glance path aims to suppress the noise in the magnitude domain to obtain a coarse estimation, and meanwhile, the gaze path attempts to compensate for the lost spectral detail in the complex domain. The two paths work collaboratively and facilitate spectral estimation from complementary perspectives. Besides, by repeatedly unfolding the GGMs, the intermediate result can be iteratively refined across stages and lead to the ultimate estimation of the spectrum. The experiments are conducted on the WSJ0-SI84, DNS-Challenge dataset, and Voicebank+Demand dataset. Results show that the proposed approach achieves state-of-the-art performance over previous advanced systems on the WSJ0-SI84 and DNS-Challenge dataset, and meanwhile, competitive performance is achieved on the Voicebank+Demand corpus.      
### 26.A Review of the Vision-based Approaches for Dietary Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2106.11776.pdf)
>  Dietary-related problems such as obesity are a growing concern in todays modern world. If the current trend continues, it is most likely that the quality of life, in general, is significantly affected since obesity is associated with other chronic diseases such as hypertension, irregular blood sugar levels, and increased risk of heart attacks. The primary cause of these problems is poor lifestyle choices and unhealthy dietary habits, with emphasis on a select few food groups such as sugars, fats, and carbohydrates. In this regard, computer-based food recognition offers automatic visual-based methods to assess dietary intake and help people make healthier choices. Thus, the following paper presents a brief review of visual-based methods for food recognition, including their accuracy, performance, and the use of popular food databases to evaluate existing models. The work further aims to highlight future challenges in this area. New high-quality studies for developing standard benchmarks and using continual learning methods for food recognition are recommended.      
### 27.Formation Control with Lane Preference for Connected and Automated Vehicles in Multi-lane Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2106.11763.pdf)
>  Multi-lane roads are typical scenarios in the real-world traffic system. Vehicles usually have preference on lanes according to their routes and destinations. Few of the existing studies looks into the problem of controlling vehicles to drive on their desired lanes. This paper proposes a formation control method that considers vehicles' preference on different lanes. The bi-level formation control framework is utilized to plan collision-free motion for vehicles, where relative target assignment and path planning are performed in the upper level, and trajectory planning and tracking are performed in the lower level. The collision-free multi-vehicle path planning problem considering lane preference is decoupled into two sub problems: calculating assignment list with non-decreasing cost and planning collision-free paths according to given assignment result. The Conflict-based Searching (CBS) method is utilized to plan collision-free paths for vehicles based on given assignment results. Case study is conducted and simulations are carried out in a three-lane road scenario. The results indicate that the proposed formation control method significantly reduces congestion and improves traffic efficiency at high traffic volumes, compared to the rule-based method.      
### 28.Carbon-Aware Computing for Datacenters  [ :arrow_down: ](https://arxiv.org/pdf/2106.11750.pdf)
>  The amount of CO$_2$ emitted per kilowatt-hour on an electricity grid varies by time of day and substantially varies by location due to the types of generation. Networked collections of warehouse scale computers, sometimes called Hyperscale Computing, emit more carbon than needed if operated without regard to these variations in carbon intensity. This paper introduces Google's system for Carbon-Intelligent Compute Management, which actively minimizes electricity-based carbon footprint and power infrastructure costs by delaying temporally flexible workloads. The core component of the system is a suite of analytical pipelines used to gather the next day's carbon intensity forecasts, train day-ahead demand prediction models, and use risk-aware optimization to generate the next day's carbon-aware Virtual Capacity Curves (VCCs) for all datacenter clusters across Google's fleet. VCCs impose hourly limits on resources available to temporally flexible workloads while preserving overall daily capacity, enabling all such workloads to complete within a day. Data from operation shows that VCCs effectively limit hourly capacity when the grid's energy supply mix is carbon intensive and delay the execution of temporally flexible workloads to "greener" times.      
### 29.Learning to Inference with Early Exit in the Progressive Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.11730.pdf)
>  In real scenarios, it is often necessary and significant to control the inference speed of speech enhancement systems under different conditions. To this end, we propose a stage-wise adaptive inference approach with early exit mechanism for progressive speech enhancement. Specifically, in each stage, once the spectral distance between adjacent stages lowers the empirically preset threshold, the inference will terminate and output the estimation, which can effectively accelerate the inference speed. To further improve the performance of existing speech enhancement systems, PL-CRN++ is proposed, which is an improved version over our preliminary work PL-CRN and combines stage recurrent mechanism and complex spectral mapping. Extensive experiments are conducted on the TIMIT corpus, the results demonstrate the superiority of our system over state-of-the-art baselines in terms of PESQ, ESTOI and DNSMOS. Moreover, by adjusting the threshold, we can easily control the inference efficiency while sustaining the system performance.      
### 30.Multi-accent Speech Separation with One Shot Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.11713.pdf)
>  Speech separation is a problem in the field of speech processing that has been studied in full swing recently. However, there has not been much work studying a multi-accent speech separation scenario. Unseen speakers with new accents and noise aroused the domain mismatch problem which cannot be easily solved by conventional joint training methods. Thus, we applied MAML and FOMAML to tackle this problem and obtained higher average Si-SNRi values than joint training on almost all the unseen accents. This proved that these two methods do have the ability to generate well-trained parameters for adapting to speech mixtures of new speakers and accents. Furthermore, we found out that FOMAML obtains similar performance compared to MAML while saving a lot of time.      
### 31.Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw  [ :arrow_down: ](https://arxiv.org/pdf/2106.11603.pdf)
>  We present a number of low-resource approaches to the tasks of the Zero Resource Speech Challenge 2021. We build on the unsupervised representations of speech proposed by the organizers as a baseline, derived from CPC and clustered with the k-means algorithm. We demonstrate that simple methods of refining those representations can narrow the gap, or even improve upon the solutions which use a high computational budget. The results lead to the conclusion that the CPC-derived representations are still too noisy for training language models, but stable enough for simpler forms of pattern matching and retrieval.      
### 32.Reinforcement learning for PHY layer communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.11595.pdf)
>  In this chapter, we will give comprehensive examples of applying RL in optimizing the physical layer of wireless communications by defining different class of problems and the possible solutions to handle them. In Section 9.2, we present all the basic theory needed to address a RL problem, i.e. Markov decision process (MDP), Partially observable Markov decision process (POMDP), but also two very important and widely used algorithms for RL, i.e. the Q-learning and SARSA algorithms. We also introduce the deep reinforcement learning (DRL) paradigm and the section ends with an introduction to the multi-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples to illustrate how the basic concepts of RL are employed in communication systems. We present applications extracted from literature with simplified system models using similar notation as in Section 9.2 of this Chapter. In Section 9.3, we also focus on modeling RL problems, i.e. how action and state spaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a prospective thought on RL trends and it ends with a review of a broader state of the art in Section 9.5.      
### 33.Tunable Graphene-based Pulse Compressor for Terahertz Application  [ :arrow_down: ](https://arxiv.org/pdf/2106.11567.pdf)
>  Pulse shaping is important for communications, spectroscopy, and other applications that require high peak power and pulsed operation, such as radar systems. Unfortunately, pulse shaping remains largely elusive for terahertz (THz) frequencies. To address this void, a comprehensive study on the dispersion tunability properties of THz chirped pulses traveling through a dielectric-lined hollow-core waveguide loaded with a helical graphene ribbon is presented.      
### 34.Hand-Drawn Electrical Circuit Recognition using Object Detection and Node Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.11559.pdf)
>  With the recent developments in neural networks, there has been a resurgence in algorithms for the automatic generation of simulation ready electronic circuits from hand-drawn circuits. However, most of the approaches in literature were confined to classify different types of electrical components and only a few of those methods have shown a way to rebuild the circuit schematic from the scanned image, which is extremely important for further automation of netlist generation. This paper proposes a real-time algorithm for the automatic recognition of hand-drawn electrical circuits based on object detection and circuit node recognition. The proposed approach employs You Only Look Once version 5 (YOLOv5) for detection of circuit components and a novel Hough transform based approach for node recognition. Using YOLOv5 object detection algorithm, a mean average precision (mAP0.5) of 98.2% is achieved in detecting the components. The proposed method is also able to rebuild the circuit schematic with 80% accuracy.      
### 35.Key-Sparse Transformer with Cascaded Cross-Attention Block for Multimodal Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.11532.pdf)
>  Speech emotion recognition is a challenging and important research topic that plays a critical role in human-computer interaction. Multimodal inputs can improve the performance as more emotional information is used for recognition. However, existing studies learnt all the information in the sample while only a small portion of it is about emotion. Moreover, under the multimodal framework, the interaction between different modalities is shallow and insufficient. In this paper, a keysparse Transformer is proposed for efficient SER by only focusing on emotion related information. Furthermore, a cascaded cross-attention block, which is specially designed for multimodal framework, is introduced to achieve deep interaction between different modalities. The proposed method is evaluated by IEMOCAP corpus and the experimental results show that the proposed method gives better performance than the state-of-theart approaches.      
### 36.Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations  [ :arrow_down: ](https://arxiv.org/pdf/2106.11519.pdf)
>  There have been many recent advances on provably efficient Reinforcement Learning (RL) in problems with rich observation spaces. However, all these works share a strong realizability assumption about the optimal value function of the true MDP. Such realizability assumptions are often too strong to hold in practice. In this work, we consider the more realistic setting of agnostic RL with rich observation spaces and a fixed class of policies $\Pi$ that may not contain any near-optimal policy. We provide an algorithm for this setting whose error is bounded in terms of the rank $d$ of the underlying MDP. Specifically, our algorithm enjoys a sample complexity bound of $\widetilde{O}\left((H^{4d} K^{3d} \log |\Pi|)/\epsilon^2\right)$ where $H$ is the length of episodes, $K$ is the number of actions and $\epsilon&gt;0$ is the desired sub-optimality. We also provide a nearly matching lower bound for this agnostic setting that shows that the exponential dependence on rank is unavoidable, without further assumptions.      
### 37.High Resolution Radar Sensing with Compressive Illumination  [ :arrow_down: ](https://arxiv.org/pdf/2106.11490.pdf)
>  We present a compressive radar design that combines multitone linear frequency modulated (LFM) waveforms in the transmitter with a classical stretch processor and sub-Nyquist sampling in the receiver. The proposed compressive illumination scheme has fewer random elements resulting in reduced storage and complexity for implementation than previously proposed compressive radar designs based on stochastic waveforms. We analyze this illumination scheme for the task of a joint range-angle of arrival estimation in the multi-input and multi-output (MIMO) radar system. We present recovery guarantees for the proposed illumination technique. We show that for a sufficiently large number of modulating tones, the system achieves high-resolution in range and successfully recovers the range and angle-of-arrival of targets in a sparse scene. Furthermore, we present an algorithm that estimates the target range, angle of arrival, and scattering coefficient in the continuum. Finally, we present simulation results to illustrate the recovery performance as a function of system parameters.      
### 38.VoxelEmbed: 3D Instance Segmentation and Tracking with Voxel Embedding based Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.11480.pdf)
>  Recent advances in bioimaging have provided scientists a superior high spatial-temporal resolution to observe dynamics of living cells as 3D volumetric videos. Unfortunately, the 3D biomedical video analysis is lagging, impeded by resource insensitive human curation using off-the-shelf 3D analytic tools. Herein, biologists often need to discard a considerable amount of rich 3D spatial information by compromising on 2D analysis via maximum intensity projection. Recently, pixel embedding-based cell instance segmentation and tracking provided a neat and generalizable computing paradigm for understanding cellular dynamics. In this work, we propose a novel spatial-temporal voxel-embedding (VoxelEmbed) based learning method to perform simultaneous cell instance segmenting and tracking on 3D volumetric video sequences. Our contribution is in four-fold: (1) The proposed voxel embedding generalizes the pixel embedding with 3D context information; (2) Present a simple multi-stream learning approach that allows effective spatial-temporal embedding; (3) Accomplished an end-to-end framework for one-stage 3D cell instance segmentation and tracking without heavy parameter tuning; (4) The proposed 3D quantification is memory efficient via a single GPU with 12 GB memory. We evaluate our VoxelEmbed method on four 3D datasets (with different cell types) from the ISBI Cell Tracking Challenge. The proposed VoxelEmbed method achieved consistent superior overall performance (OP) on two densely annotated datasets. The performance is also competitive on two sparsely annotated cohorts with 20.6% and 2% of data-set having segmentation annotations. The results demonstrate that the VoxelEmbed method is a generalizable and memory-efficient solution.      
### 39.Attention-based cross-modal fusion for audio-visual voice activity detection in musical video streams  [ :arrow_down: ](https://arxiv.org/pdf/2106.11411.pdf)
>  Many previous audio-visual voice-related works focus on speech, ignoring the singing voice in the growing number of musical video streams on the Internet. For processing diverse musical video data, voice activity detection is a necessary step. This paper attempts to detect the speech and singing voices of target performers in musical video streams using audiovisual information. To integrate information of audio and visual modalities, a multi-branch network is proposed to learn audio and image representations, and the representations are fused by attention based on semantic similarity to shape the acoustic representations through the probability of anchor vocalization. Experiments show the proposed audio-visual multi-branch network far outperforms the audio-only model in challenging acoustic environments, indicating the cross-modal information fusion based on semantic correlation is sensible and successful.      
### 40.Do sound event representations generalize to other audio tasks? A case study in audio transfer learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.11335.pdf)
>  Transfer learning is critical for efficient information transfer across multiple related learning problems. A simple, yet effective transfer learning approach utilizes deep neural networks trained on a large-scale task for feature extraction. Such representations are then used to learn related downstream tasks. In this paper, we investigate transfer learning capacity of audio representations obtained from neural networks trained on a large-scale sound event detection dataset. We build and evaluate these representations across a wide range of other audio tasks, via a simple linear classifier transfer mechanism. We show that such simple linear transfer is already powerful enough to achieve high performance on the downstream tasks. We also provide insights into the attributes of sound event representations that enable such efficient information transfer.      
### 41.Distributed strategy-updating rules for aggregative games of multi-integrator systems with coupled constraints  [ :arrow_down: ](https://arxiv.org/pdf/2106.10697.pdf)
>  In this paper, we explore aggregative games over networks of multi-integrator agents with coupled constraints. To reach the general Nash equilibrium of an aggregative game, a distributed strategy-updating rule is proposed by a combination of the coordination of Lagrange multipliers and the estimation of the aggregator. Each player has only access to partial-decision information and communicates with his neighbors in a weight-balanced digraph which characterizes players' preferences as to the values of information received from neighbors. We first consider networks of double-integrator agents and then focus on multi-integrator agents. The effectiveness of the proposed strategy-updating rules is demonstrated by analyzing the convergence of corresponding dynamical systems via the Lyapunov stability theory, singular perturbation theory and passive theory. Numerical examples are given to illustrate our results.      

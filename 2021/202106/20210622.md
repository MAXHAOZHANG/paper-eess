# ArXiv eess --Tue, 22 Jun 2021
### 1.Fully automated quantification of in vivo viscoelasticity of prostate zones using magnetic resonance elastography with Dense U-net segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.11284.pdf)
>  Magnetic resonance elastography (MRE) for measuring viscoelasticity heavily depends on proper tissue segmentation, especially in heterogeneous organs such as the prostate. Using trained network-based image segmentation, we investigated if MRE data suffice to extract anatomical and viscoelastic information for automatic tabulation of zonal mechanical properties of the prostate. Overall, 40 patients with benign prostatic hyperplasia (BPH) or prostate cancer (PCa) were examined with three magnetic resonance imaging (MRI) sequences: T2-weighted MRI (T2w), diffusion-weighted imaging (DWI), and MRE-based tomoelastography yielding six independent sets of imaging data per patient (T2w, DWI, apparent diffusion coefficient (ADC), MRE magnitude, shear wave speed, and loss angle maps). Combinations of these data were used to train Dense U-nets with manually segmented masks of the entire prostate gland (PG), central zone (CZ), and peripheral zone (PZ) in 30 patients and to validate them in 10 patients. Dice score (DS), sensitivity, specificity, and Hausdorff distance were determined. We found that segmentation based on MRE magnitude maps alone (DS, PG: 0.93$\pm$0.04, CZ: 0.95$\pm$0.03, PZ: 0.77$\pm$0.05) was more accurate than magnitude maps combined with T2w and DWI_b (DS, PG: 0.91$\pm$0.04, CZ: 0.91$\pm$0.06, PZ: 0.63$\pm$0.16) or T2w alone (DS, PG: 0.92$\pm$0.03, CZ: 0.91$\pm$0.04, PZ: 0.65$\pm$0.08). Automatically tabulated MRE values were not different from ground-truth values (P&gt;0.05). In conclusion: MRE combined with Dense U-net segmentation allows tabulation of quantitative imaging markers without manual analysis and independent of other MRI sequences and can thus contribute to PCa detection and classification.      
### 2.Active and Dynamic Beam Tracking UnderStochastic Mobility  [ :arrow_down: ](https://arxiv.org/pdf/2106.11281.pdf)
>  We consider the problem of active and sequential beam tracking at mmWave frequencies and above. We focus on the dynamic scenario of a UAV to UAV communications where we formulate the problem to be equivalent to tracking an optimal beamforming vector along the line-of-sight path. In this setting, the resulting beam ideally points in the direction of the angle of arrival with sufficiently high resolution. Existing solutions account for predictable movements or small random movements using filtering strategies or by accounting for predictable mobility but must resort to re-estimation protocols when tracking fails due to unpredictable movements. We propose an algorithm for active learning of the AoA through evolving a Bayesian posterior probability belief which is utilized for a sequential selection of beamforming vectors. We propose an adaptive pilot allocation strategy based on a trade-off of mutual information versus spectral efficiency. Numerically, we analyze the performance of our proposed algorithm and demonstrate significant improvements over existing strategies.      
### 3.A comparative study of model approximation methods applied to economic MPC  [ :arrow_down: ](https://arxiv.org/pdf/2106.11258.pdf)
>  Economic model predictive control (EMPC) has attracted significant attention in recent years and is recognized as a promising advanced process control method for the next generation smart manufacturing. It can lead to improving economic performance but at the same time increases the computational complexity significantly. Model approximation has been a standard approach for reducing computational complexity in process control. In this work, we perform a study on three types of representative model approximation methods applied to EMPC, including model reduction based on available first-principle models (e.g., proper orthogonal decomposition), system identification based on input-output data (e.g., subspace identification) that results in an explicitly expressed mathematical model, and neural networks based on input-output data. A representative algorithm from each model approximation method is considered. Two processes that are very different in dynamic nature and complexity were selected as benchmark processes for computational complexity and economic performance comparison, namely an alkylation process and a wastewater treatment plant (WWTP). The strengths and drawbacks of each method are summarized according to the simulation results, with future research direction regarding control oriented model approximation proposed at the end.      
### 4.Cylindrical coordinates for LiDAR point cloud compression  [ :arrow_down: ](https://arxiv.org/pdf/2106.11237.pdf)
>  We present an efficient voxelization method to encode the geometry and attributes of 3D point clouds obtained from autonomous vehicles. Due to the circular scanning trajectory of sensors, the geometry of LiDAR point clouds is inherently different from that of point clouds captured from RGBD cameras. Our method exploits these specific properties to representing points in cylindrical coordinates instead of conventional Cartesian coordinates. We demonstrate thatRegion Adaptive Hierarchical Transform (RAHT) can be extended to this setting, leading to attribute encoding based on a volumetric partition in cylindrical coordinates. Experimental results show that our proposed voxelization outperforms conventional approaches based on Cartesian coordinates for this type of data. We observe a significant improvement in attribute coding performance with 5-10%reduction in bitrate and octree representation with 35-45% reduction in bits.      
### 5.Machine Learning based optimization for interval uncertainty propagation with application to vibro-acoustic models  [ :arrow_down: ](https://arxiv.org/pdf/2106.11215.pdf)
>  Two non-intrusive uncertainty propagation approaches are proposed for the performance analysis of engineering systems described by expensive-to-evaluate deterministic computer models with parameters defined as interval variables. These approaches employ a machine learning based optimization strategy, the so-called Bayesian optimization, for evaluating the upper and lower bounds of a generic response variable over the set of possible responses obtained when each interval variable varies independently over its range. The lack of knowledge caused by not evaluating the response function for all the possible combinations of the interval variables is accounted for by developing a probabilistic description of the response variable itself by using a Gaussian Process regression model. An iterative procedure is developed for selecting a small number of simulations to be evaluated for updating this statistical model by using well-established acquisition functions and to assess the response bounds. In both approaches, an initial training dataset is defined. While one approach builds iteratively two distinct training datasets for evaluating separately the upper and lower bounds of the response variable, the other builds iteratively a single training dataset. Consequently, the two approaches will produce different bound estimates at each iteration. The upper and lower bound responses are expressed as point estimates obtained from the mean function of the posterior distribution. Moreover, a confidence interval on each estimate is provided for effectively communicating to engineers when these estimates are obtained for a combination of the interval variables for which no deterministic simulation has been run. Finally, two metrics are proposed to define conditions for assessing if the predicted bound estimates can be considered satisfactory.      
### 6.Multi-functional microwave photonic radar system for simultaneous distance and velocity measurement and high-resolution microwave imaging  [ :arrow_down: ](https://arxiv.org/pdf/2106.11172.pdf)
>  A photonic-assisted multi-functional radar system for simultaneous distance and velocity measurement and high-resolution microwave imaging is proposed and experimentally demonstrated by using a composite transmitted microwave signal of a single-chirped linearly frequency-modulated (LFM) signal and a single-tone microwave signal. In the system, the transmitted signal is generated via photonic frequency up-conversion based on a single integrated dual-polarization dual-parallel Mach-Zehnder modulator (DPol-DPMZM), whereas the echo signals scattered from the target are de-chirped to two low-frequency signals using a microwave photonic frequency mixer. By using the two low-frequency de-chirped signals, the real-time distance and radial velocity of the moving target can be measured accurately according to the round-trip time of the echo signal and its Doppler frequency shift. Compared with the previous reported distance and velocity measurement methods, where two LFM signals with opposite chirps are used, these parameters can be obtained using only a single-chirped LFM signal and a single-tone microwave signal. Meanwhile, high-resolution inverse synthetic aperture radar (ISAR) imaging can also be realized using ISAR imaging algorithms. An experiment is performed to verify the proposed multi-functional microwave photonic radar system. An up-chirped LFM signal from 8.5 to 12.5 GHz and an 8.0 GHz single-tone microwave signal are used as the transmitted signal. The results show that the absolute measurement errors of distance and radial velocity are less than 5.9 cm and 2.8 cm/s, respectively. ISAR imaging results are also demonstrated, which proves the high-resolution and real-time ISAR imaging ability of the proposed system.      
### 7.UniTTS: Residual Learning of Unified Embedding Space for Speech Style Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.11171.pdf)
>  We propose a novel high-fidelity expressive speech synthesis model, UniTTS, that learns and controls overlapping style attributes avoiding interference. UniTTS represents multiple style attributes in a single unified embedding space by the residuals between the phoneme embeddings before and after applying the attributes. The proposed method is especially effective in controlling multiple attributes that are difficult to separate cleanly, such as speaker ID and emotion, because it minimizes redundancy when adding variance in speaker ID and emotion, and additionally, predicts duration, pitch, and energy based on the speaker ID and emotion. In experiments, the visualization results exhibit that the proposed methods learned multiple attributes harmoniously in a manner that can be easily separated again. As well, UniTTS synthesized high-fidelity speech signals controlling multiple style attributes. The synthesized speech samples are presented at <a class="link-external link-https" href="https://jackson-kang.github.io/paper_works/UniTTS/demos" rel="external noopener nofollow">this https URL</a>.      
### 8.Transformer-based Spatial-Temporal Feature Learning for EEG Decoding  [ :arrow_down: ](https://arxiv.org/pdf/2106.11170.pdf)
>  At present, people usually use some methods based on convolutional neural networks (CNNs) for Electroencephalograph (EEG) decoding. However, CNNs have limitations in perceiving global dependencies, which is not adequate for common EEG paradigms with a strong overall relationship. Regarding this issue, we propose a novel EEG decoding method that mainly relies on the attention mechanism. The EEG data is firstly preprocessed and spatially filtered. And then, we apply attention transforming on the feature-channel dimension so that the model can enhance more relevant spatial features. The most crucial step is to slice the data in the time dimension for attention transforming, and finally obtain a highly distinguishable representation. At this time, global averaging pooling and a simple fully-connected layer are used to classify different categories of EEG data. Experiments on two public datasets indicate that the strategy of attention transforming effectively utilizes spatial and temporal features. And we have reached the level of the state-of-the-art in multi-classification of EEG, with fewer parameters. As far as we know, it is the first time that a detailed and complete method based on the transformer idea has been proposed in this field. It has good potential to promote the practicality of brain-computer interface (BCI). The source code can be found at: \textit{<a class="link-external link-https" href="https://github.com/anranknight/EEG-Transformer" rel="external noopener nofollow">this https URL</a>}.      
### 9.Signals to Spikes for Neuromorphic Regulated Reservoir Computing and EMG Hand Gesture Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.11169.pdf)
>  We propose a simple yet novel approach for optimizing the spike encoding algorithm's hyper-parameters inspired by the readout layer concept in reservoir computing. Using a simple machine learning algorithm after spike encoding, we report performance higher than the state-of-the-art spiking neural networks on two open-source datasets for hand gesture recognition. Surface electromyogram (sEMG) signals result from muscle movement and hence they are an ideal candidate for benchmarking event-driven sensing and computing. The spike encoded data is processed through a spiking reservoir with a biologically inspired topology and neuron model. When trained with the unsupervised activity regulation CRITICAL algorithm to operate at the edge of chaos, the reservoir yields better performance than state-of-the-art convolutional neural networks. The reservoir performance with regulated activity was found to be 89.72% for the Roshambo EMG dataset and 70.6% for the EMG subset of sensor fusion dataset. Therefore, the biologically-inspired computing paradigm, which is known for being power efficient, also proves to have a great potential when compared with conventional AI algorithms.      
### 10.From Unsupervised to Semi-supervised Anomaly Detection Methods for HRRP Targets  [ :arrow_down: ](https://arxiv.org/pdf/2106.11168.pdf)
>  Responding to the challenge of detecting unusual radar targets in a well identified environment, innovative anomaly and novelty detection methods keep emerging in the literature. This work aims at presenting a benchmark gathering common and recently introduced unsupervised anomaly detection (AD) methods, the results being generated using high-resolution range profiles. A semi-supervised AD (SAD) is considered to demonstrate the added value of having a few labeled anomalies to improve performances. Experiments were conducted with and without pollution of the training set with anomalous samples in order to be as close as possible to real operational contexts. The common AD methods composing our baseline will be One-Class Support Vector Machines (OC-SVM), Isolation Forest (IF), Local Outlier Factor (LOF) and a Convolutional Autoencoder (CAE). The more innovative AD methods put forward by this work are Deep Support Vector Data Description (Deep SVDD) and Random Projection Depth (RPD), belonging respectively to deep and shallow AD. The semi-supervised adaptation of Deep SVDD constitutes our SAD method. HRRP data was generated by a coastal surveillance radar, our results thus suggest that AD can contribute to enhance maritime and coastal situation awareness.      
### 11.Design criteria of flexible capacitive pressure sensors using DIY-techniques and household materials  [ :arrow_down: ](https://arxiv.org/pdf/2106.11164.pdf)
>  The flexible capacitive pressure sensors are one of the most essential and famous devices with vast applications in automobile, aerospace, marine, healthcare, wearables, consumer, and portable electronics. The fabrication of pressure sensors in a cleanroom is expensive and time-consuming; however, the sensitivity, linearity, and other performance factors of those pressure sensors are exceptional. Moreover, sometimes we require sensors that are not expensive and can be fabricated rapidly where the other performance factors do not need to be highly remarkable. In this modern era, household materials and DIY (Do-it-yourself) techniques are quite helpful, highly utilized. They are recommended to fabricate low-cost sensors and healthcare devices for personalized medicine and low-cost consumer electronics. Different flexible capacitive pressure sensors are presented and experimentally characterized for acoustic and air-pressure monitoring in this thesis. The design criteria of a cantilever-based capacitive pressure sensor are discussed. The three different designs are analysed with aspect ratios of 1.5, 1.0, and 0.67. The sensor with an aspect ratio of 0.67 shows maximum sensitivity (mechanical and electrical), better response time, and the 1st and 2nd mode of resonant frequencies is comparatively less than the other two. The cantilever designs are susceptible to slight pressure; therefore, the diaphragm-based normal mode capacitive pressure sensor is introduced in the second chapter, which defines the design criteria of diaphragm shapes. The five different diaphragms analysed are circular, elliptical, pentagon, square, and rectangular shapes. The circular capacitive pressure sensor shows maximum sensitivity, however, maximum non-linear response.....      
### 12.Brushless Motor Performance Optimization by Eagle Strategy with Firefly and PSO  [ :arrow_down: ](https://arxiv.org/pdf/2106.11135.pdf)
>  Brushless motors has special place though different motors are available because of its special features like absence in commutation, reduced noise and longer lifetime etc., The experimental parameter tracking of BLDC Motor can be achieved by developing a Reference system and their stability is guaranteed by adopting Lyapunov Stability theorems. But the stability is guaranteed only if the adaptive system is incorporated with the powerful and efficient optimization techniques. In this paper the powerful eagle strategy with Particle Swarm optimization and Firefly algorithms are applied to evaluate the performance of brushless motor Where, Eagle Strategy(ES) with the use of Levys walk distribution function performs diversified global search and the Particle Swarm Optimization (PSO) and Firefly Algorithm(FFA) performs the efficient intensive local search. The combined operation makes the overall optimization technique as much convenient The simulation results are obtained by using MATLAB Simulink software      
### 13.Mobile Optical Communications Using Second Harmonic of Intra-Cavity Laser  [ :arrow_down: ](https://arxiv.org/pdf/2106.11116.pdf)
>  Optical wireless communication (OWC) meets the demands of the future six-generation mobile network (6G) as it operates at several hundreds of Terahertz and has the potential to enable data rate in the order of Tbps. However, most beam-steering OWC technologies require high-accuracy positioning and high-speed control. Resonant beam communication (RBCom), as one kind of non-positioning OWC technologies, has been proposed for high-rate mobile communications. The mobility of RBCom relies on its self-alignment characteristic where no positioning is required. In a previous study, an external-cavity second-harmonic-generation (SHG) RBCom system has been proposed for eliminating the echo interference inside the resonator. However, its energy conversion efficiency and complexity are of concern. In this paper, we propose an intra-cavity SHG RBCom system to simplify the system design and improve the energy conversion efficiency. We elaborate the system structure and establish an analytical model. Numerical results show that the energy consumption of the proposed intra-cavity design is reduced to reach the same level of channel capacity at the receiver compared with the external-cavity one.      
### 14.Electromagnetic Interference in RIS-Aided Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.11107.pdf)
>  The prospects of using a reconfigurable intelligent surface (RIS) to aid wireless communication systems have recently received much attention. Among the different use cases, the most popular one is where each element of the RIS scatters the incoming signal with a controllable phase-shift, without increasing its power. In prior literature, this setup has been analyzed by neglecting the electromagnetic interference, consisting of the inevitable incoming waves from external sources. In this letter, we provide a physically meaningful model for the electromagnetic interference that can be used as a baseline when evaluating RIS-aided communications. The model is used to show that electromagnetic interference has a non-negligible impact on communication performance, especially when the size of the RIS grows large. When the direct link is present (though with a relatively weak gain), the RIS can even reduce the communication performance. Importantly, it turns out that the SNR grows quadratically with the number of RIS elements only when the spatial correlation matrix of the electromagnetic interference is asymptotically orthogonal to that of the channel vector towards the intended receiver. Otherwise, the SNR only increases linearly.      
### 15.A Taxonomy to Unify Fault Tolerance Regimes for Automotive Systems: Defining Fail-Operational, Fail-Degraded, and Fail-Safe  [ :arrow_down: ](https://arxiv.org/pdf/2106.11042.pdf)
>  This paper presents a taxonomy that allows to define the fault tolerance regimes "fail-operational", "fail-degraded", and "fail-safe" in the context of automotive systems. Fault tolerance regimes such as these are widely used in recent publications related to automated driving, yet without definitions, which largely holds true for automotive safety standards, too. Moreover, we show that fault tolerance regimes defined in scientific publications related to the automotive domain are partially ambiguous as well as taxonomically unrelated. The presented taxonomy is based on terminology stemming from ISO 26262 as well as from systems engineering and uses four criteria to distinguish fault tolerance regimes. In addition to "fail-operational", "fail-degraded", and "fail-safe", the core terminology consists of "operational" and "fail-unsafe". These terms are supported by definitions of "available performance", "nominal performance", and a novel definition of the "safe state". For verification, we show by means of two examples from the automotive domain that the taxonomy can be applied to hierarchical systems of different complexity. Finally, we relate the definitions to the recently published technical report ISO/TR 4804, which also presents definitions of fault tolerance regimes.      
### 16.3D Printed Metallic Dual-Polarized Vivaldi Arrays on Square and Triangular Lattices  [ :arrow_down: ](https://arxiv.org/pdf/2106.11020.pdf)
>  We report the first Vivaldi arrays monolithically fabricated exclusively using commercial, low-cost, 3D metal printing (direct metal laser sintering). Furthermore, we developed one of the first dual-polarized Vivaldi arrays on a triangular lattice, and compare it to a square lattice array. The triangular lattice is attractive because it has a 15.5% larger cell size compared to the square lattice and can be more naturally truncated into a wide range of aperture shapes such as a rectangle, hexagon, or triangle. Both arrays operate at 3-20 GHz and scan angles out to 60 degree from normal. The fabrication process is significantly simplified compared to previously published Vivaldi arrays since the antenna is ready for use directly after the standard printing process is complete. This rapid manufacturing is further expedited by printing the 'Sub-Miniature Push-on, Micro' (SMPM) connectors directly onto the radiating elements, which simplifies assembly and reduces cost compared to utilizing discrete RF connectors. The arrays have a modular design that allow for combining multiple sub-arrays together for arbitrarily increasing the aperture size. Simulations and measurement show that our arrays have similar performance as previously published Vivaldi arrays, but with simpler fabrication.      
### 17.Towards sound based testing of COVID-19 -- Summary of the first Diagnostics of COVID-19 using Acoustics (DiCOVA) Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2106.10997.pdf)
>  The technology development for point-of-care tests (POCTs) targeting respiratory diseases has witnessed a growing demand in the recent past. Investigating the presence of acoustic biomarkers in modalities such as cough, breathing and speech sounds, and using them for building POCTs can offer fast, contactless and inexpensive testing. In view of this, over the past year, we launched the ``Coswara'' project to collect cough, breathing and speech sound recordings via worldwide crowdsourcing. With this data, a call for development of diagnostic tools was announced in the Interspeech 2021 as a special session titled ``Diagnostics of COVID-19 using Acoustics (DiCOVA) Challenge''. The goal was to bring together researchers and practitioners interested in developing acoustics-based COVID-19 POCTs by enabling them to work on the same set of development and test datasets. As part of the challenge, datasets with breathing, cough, and speech sound samples from COVID-19 and non-COVID-19 individuals were released to the participants. The challenge consisted of two tracks. The Track-1 focused only on cough sounds, and participants competed in a leaderboard setting. In Track-2, breathing and speech samples were provided for the participants, without a competitive leaderboard. The challenge attracted 85 plus registrations with 29 final submissions for Track-1. This paper describes the challenge (datasets, tasks, baseline system), and presents a focused summary of the various systems submitted by the participating teams. An analysis of the results from the top four teams showed that a fusion of the scores from these teams yields an area-under-the-curve of 95.1% on the blind test data. By summarizing the lessons learned, we foresee the challenge overview in this paper to help accelerate technology for acoustic-based POCTs.      
### 18.Estimating MRI Image Quality via Image Reconstruction Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2106.10992.pdf)
>  Quality control (QC) in medical image analysis is time-consuming and laborious, leading to increased interest in automated methods. However, what is deemed suitable quality for algorithmic processing may be different from human-perceived measures of visual quality. In this work, we pose MR image quality assessment from an image reconstruction perspective. We train Bayesian CNNs using a heteroscedastic uncertainty model to recover clean images from noisy data, providing measures of uncertainty over the predictions. This framework enables us to divide data corruption into learnable and non-learnable components and leads us to interpret the predictive uncertainty as an estimation of the achievable recovery of an image. Thus, we argue that quality control for visual assessment cannot be equated to quality control for algorithmic processing. We validate this statement in a multi-task experiment combining artefact recovery with uncertainty prediction and grey matter segmentation. Recognising this distinction between visual and algorithmic quality has the impact that, depending on the downstream task, less data can be excluded based on ``visual quality" reasons alone.      
### 19.Realization of multi-input/multi-output switched linear systems from Markov parameters  [ :arrow_down: ](https://arxiv.org/pdf/2106.10942.pdf)
>  This paper presents a four-stage algorithm for the realization of multi-input/multi-output (MIMO) switched linear systems (SLSs) from Markov parameters. In the first stage, a linear time-varying (LTV) realization that is topologically equivalent to the true SLS is derived from the Markov parameters assuming that the submodels have a common MacMillan degree and a mild condition on their dwell times holds. In the second stage, zero sets of LTV Hankel matrices where the realized system has a linear time-invariant (LTI) pulse response matching that of the original SLS are exploited to extract the submodels, up to arbitrary similarity transformations, by a clustering algorithm using a statistics that is invariant to similarity transformations. Recovery is shown to be complete if the dwell times are sufficiently long and some mild identifiability conditions are met. In the third stage, the switching sequence is estimated by three schemes. The first scheme is based on forward/backward corrections and works on the short segments. The second scheme matches Markov parameter estimates to the true parameters for LTV systems and works on the medium-to-long segments. The third scheme also matches Markov parameters, but for LTI systems only and works on the very short segments. In the fourth stage, the submodels estimated in Stage~2 are brought to a common basis by applying a novel basis transformation method which is necessary before performing output predictions to given inputs. A numerical example illustrates the properties of the realization algorithm. A key role in this algorithm is played by time-dependent switching sequences that partition the state-space according to time, unlike many other works in the literature in which partitioning is state and/or input dependent.      
### 20.Holographic Smart EM Skins for Advanced Beam Power Shaping in Next Generation Wireless Environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.10932.pdf)
>  An innovative approach for the synthesis of inexpensive holographic smart electromagnetic (EM) skins with advanced beamforming features is proposed. The complex multiscale smart skin design is formulated within the Generalized Sheet Transition Condition (GSTC) framework as a combination of a mask-constrained isophoric inverse source problem and a micro-scale susceptibility dyadic optimization. The solution strategy integrates a local search procedure based on the iterative projection technique (IPT) and a System-by-Design (SbD)-based optimization loop for the identification of optimal metasurface descriptors matching the desired surface currents. The performance and the efficiency of the proposed approach are assessed in a set of representative test cases concerned with different smart skin apertures and target pattern masks.      
### 21.Speech prosody and remote experiments: a technical report  [ :arrow_down: ](https://arxiv.org/pdf/2106.10915.pdf)
>  The aim of this paper is twofold. First, we present a review of different recording options for gathering prosodic data in the event that fieldwork is impracticable (e.g. due to pandemics). Under this light, we mimic a long-distance reading task experiment using different software and hardware synchronously. In order to evaluate the employed methodologies, we extract noise levels and frequency manipulation of the recordings. Subsequently, we examine the impact of the different recordings onto linguistic variables, such as the pitch curves and values. We also include a discussion on experimental practicalities. After balancing these factors, we decree an online platform, Zencastr, as the most affordable and practical for acoustic data collection. Secondly, we want to open up a debate on the most optimal remote methodology that researchers on speech prosody can deploy.      
### 22.Channel Estimation for Hybrid RIS Aided MIMO Communications via Atomic Norm Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.10909.pdf)
>  Reconfigurable intelligent surfaces (RISs) have been introduced as a remedy for mitigating frequent blockages in millimeter wave (mmWave) multiple-input multiple-output (MIMO) communication networks. However, perfect or nearly perfect channel state information (CSI) is fundamental in order to achieve their full potential. Traditionally, an RIS is fully passive without any baseband processing capabilities, which poses great challenges for CSI acquisition. Thus, we focus on the hybrid RIS architecture, where a small portion of RIS elements are active and able to processing the received pilot signals for estimating the corresponding channel. The channel estimation (CE) is done by resorting to off-the-grid compressive sensing technique, i.e., atomic norm minimization, for exacting channel parameters through two stages. Simulation results show that the proposed scheme outperforms the passive RIS CE under the same training overhead.      
### 23.Brain tumor grade classification Using LSTM Neural Networks with Domain Pre-Transforms  [ :arrow_down: ](https://arxiv.org/pdf/2106.10889.pdf)
>  The performance of image classification methodsheavily relies on the high-quality annotations, which are noteasily affordable, particularly for medical data. To alleviate thislimitation, in this study, we propose a weakly supervised imageclassification method based on combination of hand-craftedfeatures. We hypothesize that integration of these hand-craftedfeatures alongside Long short-term memory (LSTM) classifiercan reduce the adverse effects of weak labels in classificationaccuracy. Our proposed algorithm is based on selecting theappropriate domain representations of the data in Wavelet andDiscrete Cosine Transform (DCT) domains. This informationis then fed into LSTM network to account for the sequentialnature of the data. The proposed efficient, low dimensionalfeatures exploit the power of shallow deep learning modelsto achieve higher performance with lower computational <a class="link-external link-http" href="http://cost.In" rel="external noopener nofollow">this http URL</a> order to show efficacy of the proposed strategy, we haveexperimented classification of brain tumor grades and achievedthe state of the art performance with the resolution of 256 x 256. We also conducted a comprehensive set of experiments toanalyze the effect of each component on the performance.      
### 24.Basis transform in switched linear system state-space models from input-output data  [ :arrow_down: ](https://arxiv.org/pdf/2106.10888.pdf)
>  This paper tackles the basis selection issue in the context of state-space hybrid system identification from input-output data. It is often the case that an identification scheme responsible for state-space switched linear system (SLS) estimation from input-output data operates on local levels. Such individually identified local estimates reside in distinct state bases, which call for the need to perform some basis correction mechanism that facilitates their coherent patching for the ultimate goal of performing output predictions for predefined input test signals. We derive necessary and sufficient conditions on the submodel set, the switching sequence, and the dwell times that guarantee the presented approach's success. Such conditions turn out to be relatively mild, which contributes to the application potential of the devised algorithm. We also provide a linkage between this work and the existing literature by providing several insightful remarks that highlight the discussed method's favorability. We supplement the theoretical findings by an elaborative numerical simulation that puts our methodology into action.      
### 25.EM-based Solutions for Covariance Structure Detection and Classification in Polarimetric SAR Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.10872.pdf)
>  This paper addresses the challenge of classifying polarimetric SAR images by leveraging the peculiar characteristics of the polarimetric covariance matrix (PCM). To this end, a general framework to solve a multiple hypothesis test is introduced with the aim to detect and classify contextual spatial variations in polarimetric SAR images. Specifically, under the null hypothesis, only an unknown structure is assumed for data belonging to a 2-dimensional spatial sliding window, whereas under each alternative hypothesis, data are partitioned into subsets sharing different structures. The problem of partition estimation is solved by resorting to hidden random variables representative of covariance structure classes and the expectation-maximization algorithm. The effectiveness of the proposed detection strategies is demonstrated on both simulated and real polarimetric SAR data also in comparison with existing classification algorithms.      
### 26.Non-native English lexicon creation for bilingual speech synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.10870.pdf)
>  Bilingual English speakers speak English as one of their languages. Their English is of a non-native kind, and their conversations are of a code-mixed fashion. The intelligibility of a bilingual text-to-speech (TTS) system for such non-native English speakers depends on a lexicon that captures the phoneme sequence used by non-native speakers. However, due to the lack of non-native English lexicon, existing bilingual TTS systems employ native English lexicons that are widely available, in addition to their native language lexicon. Due to the inconsistency between the non-native English pronunciation in the audio and native English lexicon in the text, the intelligibility of synthesized speech in such TTS systems is significantly reduced. <br>This paper is motivated by the knowledge that the native language of the speaker highly influences non-native English pronunciation. We propose a generic approach to obtain rules based on letter to phoneme alignment to map native English lexicon to their non-native version. The effectiveness of such mapping is studied by comparing bilingual (Indian English and Hindi) TTS systems trained with and without the proposed rules. The subjective evaluation shows that the bilingual TTS system trained with the proposed non-native English lexicon rules obtains a 6% absolute improvement in preference.      
### 27.Glow-WaveGAN: Learning Speech Representations from GAN-based Variational Auto-Encoder For High Fidelity Flow-based Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.10831.pdf)
>  Current two-stage TTS framework typically integrates an acoustic model with a vocoder -- the acoustic model predicts a low resolution intermediate representation such as Mel-spectrum while the vocoder generates waveform from the intermediate representation. Although the intermediate representation is served as a bridge, there still exists critical mismatch between the acoustic model and the vocoder as they are commonly separately learned and work on different distributions of representation, leading to inevitable artifacts in the synthesized speech. In this work, different from using pre-designed intermediate representation in most previous studies, we propose to use VAE combining with GAN to learn a latent representation directly from speech and then utilize a flow-based acoustic model to model the distribution of the latent representation from text. In this way, the mismatch problem is migrated as the two stages work on the same distribution. Results demonstrate that the flow-based acoustic model can exactly model the distribution of our learned speech representation and the proposed TTS framework, namely Glow-WaveGAN, can produce high fidelity speech outperforming the state-of-the-art GAN-based model.      
### 28.Controllable Context-aware Conversational Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.10828.pdf)
>  In spoken conversations, spontaneous behaviors like filled pause and prolongations always happen. Conversational partner tends to align features of their speech with their interlocutor which is known as entrainment. To produce human-like conversations, we propose a unified controllable spontaneous conversational speech synthesis framework to model the above two phenomena. Specifically, we use explicit labels to represent two typical spontaneous behaviors filled-pause and prolongation in the acoustic model and develop a neural network based predictor to predict the occurrences of the two behaviors from text. We subsequently develop an algorithm based on the predictor to control the occurrence frequency of the behaviors, making the synthesized speech vary from less disfluent to more disfluent. To model the speech entrainment at acoustic level, we utilize a context acoustic encoder to extract a global style embedding from the previous speech conditioning on the synthesizing of current speech. Furthermore, since the current and previous utterances belong to the different speakers in a conversation, we add a domain adversarial training module to eliminate the speaker-related information in the acoustic encoder while maintaining the style-related information. Experiments show that our proposed approach can synthesize realistic conversations and control the occurrences of the spontaneous behaviors naturally.      
### 29.Ensemble of ACCDOA- and EINV2-based Systems with D3Nets and Impulse Response Simulation for Sound Event Localization and Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.10806.pdf)
>  This report describes our systems submitted to the DCASE2021 challenge task 3: sound event localization and detection (SELD) with directional interference. Our previous system based on activity-coupled Cartesian direction of arrival (ACCDOA) representation enables us to solve a SELD task with a single target. This ACCDOA-based system with efficient network architecture called RD3Net and data augmentation techniques outperformed state-of-the-art SELD systems in terms of localization and location-dependent detection. Using the ACCDOA-based system as a base, we perform model ensembles by averaging outputs of several systems trained with different conditions such as input features, training folds, and model architectures. We also use the event independent network v2 (EINV2)-based system to increase the diversity of the model ensembles. To generalize the models, we further propose impulse response simulation (IRS), which generates simulated multi-channel signals by convolving simulated room impulse responses (RIRs) with source signals extracted from the original dataset. Our systems significantly improved over the baseline system on the development dataset.      
### 30.MeshRIR: A Dataset of Room Impulse Responses on Meshed Grid Points For Evaluating Sound Field Analysis and Synthesis Methods  [ :arrow_down: ](https://arxiv.org/pdf/2106.10801.pdf)
>  A new impulse response (IR) dataset called "MeshRIR" is introduced. Currently available datasets usually include IRs at an array of microphones from several source positions under various room conditions, which are basically designed for evaluating speech enhancement and distant speech recognition methods. On the other hand, methods of estimating or controlling spatial sound fields have been extensively investigated in recent years; however, the current IR datasets are not applicable to validating and comparing these methods because of the low spatial resolution of measurement points. MeshRIR consists of IRs measured at positions obtained by finely discretizing a spatial region. Two subdatasets are currently available: one consists of IRs in a three-dimensional cuboidal region from a single source, and the other consists of IRs in a two-dimensional square region from an array of 32 sources. Therefore, MeshRIR is suitable for evaluating sound field analysis and synthesis methods. This dataset is freely available at \url{<a class="link-external link-https" href="https://sh01k.github.io/MeshRIR/" rel="external noopener nofollow">this https URL</a>} with some codes of sample applications.      
### 31.Covariance Matching based robust Adaptive Cubature Kalman Filter  [ :arrow_down: ](https://arxiv.org/pdf/2106.10775.pdf)
>  This letter explores covariance matching-based adaptive robust cubature Kalman filter (CMRACKF). In this method, the innovation sequence is used to determine the covariance matrix of measurement noise that can overcome the limitation of conventional CKF. In the proposed algorithm, weights are adaptively adjusted and used for updating the measurement noise covariance matrices online. It can also enhance the adaptive capability of the ACKF. The simulation results are illustrated to evaluate the performance of the proposed algorithm.      
### 32.Random Paraunitary Projections  [ :arrow_down: ](https://arxiv.org/pdf/2106.10746.pdf)
>  Transforms using random matrices have been found to have many applications. We are concerned with the projection of a signal onto Gaussian-distributed random orthogonal bases. We also would like to easily invert the process through transposes in order to facilitate iterative reconstruction. We derive an efficient method to implement random unitary matrices of larger sizes through a set of Givens rotations. Random angles are hierarchically generated on-the-fly and the inverse merely requires traversing the angles in reverse order. Hierarchical randomization of angles also enables reduced storage. Using the random unitary matrices as building blocks we introduce random paraunitary systems (filter banks). We also highlight an efficient implementation of the paraunitary system and of its inverse. We also derive an adaptive under-decimated system, wherein one can control and adapt the amount of projections the signal undergoes, in effect, varying the sampling compression ratio as we go along the signal, without segmenting it. It may locally range from very compressive sampling matrices to (para) unitary random ones. One idea is to adapt to local sparseness characteristics of non-stationary signals.      
### 33.Windowing and random weighting based cubature RTS smoothing for target tracking  [ :arrow_down: ](https://arxiv.org/pdf/2106.10737.pdf)
>  This paper presents windowing and random weighting (WRW) based adaptive cubature Rauch Tung Striebel (CRTS) smoother (WRWACRTS). The Unscented KF (WRWUKF) has already existed as an alternative to nonlinear smoothing solutions. In the proposed method, both windowing and random weighted estimation methods are combined together and used to estimate the noise statistics. Subsequently, the weights of each window are adjusting randomly, and update the process and measurement noise covariances matrices at each epoch. The developed WRWACRTS algorithm overcomes the limitation of the conventional CKS. The Lyapunov function-based approach is used to investigate the convergence proof of the WRWACRTS algorithm. A numerical example is shown to demonstrate the performance of the proposed algorithm.      
### 34.Underwater Image Restoration via Contrastive Learning and a Real-world Dataset  [ :arrow_down: ](https://arxiv.org/pdf/2106.10718.pdf)
>  Underwater image restoration is of significant importance in unveiling the underwater world. Numerous techniques and algorithms have been developed in the past decades. However, due to fundamental difficulties associated with imaging/sensing, lighting, and refractive geometric distortions, in capturing clear underwater images, no comprehensive evaluations have been conducted of underwater image restoration. To address this gap, we have constructed a large-scale real underwater image dataset, dubbed `HICRD' (Heron Island Coral Reef Dataset), for the purpose of benchmarking existing methods and supporting the development of new deep-learning based methods. We employ accurate water parameter (diffuse attenuation coefficient) in generating reference images. There are 2000 reference restored images and 6003 original underwater images in the unpaired training set. Further, we present a novel method for underwater image restoration based on unsupervised image-to-image translation framework. Our proposed method leveraged contrastive learning and generative adversarial networks to maximize the mutual information between raw and restored images. Extensive experiments with comparisons to recent approaches further demonstrate the superiority of our proposed method. Our code and dataset are publicly available at GitHub.      
### 35.A New Signal Representation Using Complex Conjugate Pair Sums  [ :arrow_down: ](https://arxiv.org/pdf/2106.10710.pdf)
>  This letter introduces a real valued summation known as Complex Conjugate Pair Sum (CCPS). The space spanned by CCPS and its one circular downshift is called {\em Complex Conjugate Subspace (CCS)}. For a given positive integer $N\geq3$, there exists $\frac{\varphi(N)}{2}$ CCPSs forming $\frac{\varphi(N)}{2}$ CCSs, where $\varphi(N)$ is the Euler's totient function. We prove that these CCSs are mutually orthogonal and their direct sum form a $\varphi(N)$ dimensional subspace $s_N$ of $\mathbb{C}^N$. We propose that any signal of finite length $N$ is represented as a linear combination of elements from a special basis of $s_d$, for each divisor $d$ of $N$. This defines a new transform named as Complex Conjugate Periodic Transform (CCPT). Later, we compared CCPT with DFT (Discrete Fourier Transform) and RPT (Ramanujan Periodic Transform). It is shown that, using CCPT we can estimate the period, hidden periods and frequency information of a signal. Whereas, RPT does not provide the frequency information. For a complex valued input signal, CCPT offers computational benefit over DFT. A CCPT dictionary based method is proposed to extract non-divisor period information.      
### 36.Minimizing Delay in Network Function Visualization with Quantum Computing  [ :arrow_down: ](https://arxiv.org/pdf/2106.10707.pdf)
>  Network function virtualization (NFV) is a crucial technology for the 5G network development because it can improve the flexibility of employing hardware and reduce the construction of base stations. There are vast service chains in NFV to meet users' requests, which are composed of a sequence of network functions. These virtual network functions (VNFs) are implemented in virtual machines by software and virtual environment. How to deploy VMs to process VNFs of the service chains as soon as possible when users' requests are received is very challenging to solve by traditional algorithms on a large scale. Compared with traditional algorithms, quantum computing has better computational performance because of quantum parallelism. We build an integer linear programming model of the VNF scheduling problem with the objective of minimizing delays and transfer it into the quadratic unconstrained binary optimization (QUBO) model. Our proposed heuristic algorithm employs a quantum annealer to solve the model. Finally, we evaluate the computational results and explore the feasibility of leveraging quantum computing to solve the VNFs scheduling problem.      
### 37.Fusion of Complex Networks-based Global and Local Features for Texture Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.10701.pdf)
>  To realize accurate texture classification, this article proposes a complex networks (CN)-based multi-feature fusion method to recognize texture images. Specifically, we propose two feature extractors to detect the global and local features of texture images respectively. To capture the global features, we first map a texture image as an undirected graph based on pixel location and intensity, and three feature measurements are designed to further decipher the image features, which retains the image information as much as possible. Then, given the original band images (BI) and the generated feature images, we encode them based on the local binary patterns (LBP). Therefore, the global feature vector is obtained by concatenating four spatial histograms. To decipher the local features, we jointly transfer and fine-tune the pre-trained VGGNet-16 model. Next, we fuse and connect the middle outputs of max-pooling layers (MP), and generate the local feature vector by a global average pooling layer (GAP). Finally, the global and local feature vectors are concatenated to form the final feature representation of texture images. Experiment results show that the proposed method outperforms the state-of-the-art statistical descriptors and the deep convolutional neural networks (CNN) models.      
### 38.Generative Model Adversarial Training for Deep Compressed Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2106.10696.pdf)
>  Deep compressed sensing assumes the data has sparse representation in a latent space, i.e., it is intrinsically of low-dimension. The original data is assumed to be mapped from a low-dimensional space through a low-to-high-dimensional generator. In this work, we propound how to design such a low-to-high dimensional deep learning-based generator suiting for compressed sensing, while satisfying robustness to universal adversarial perturbations in the latent domain. We also justify why the noise is considered in the latent space. The work is also buttressed with theoretical analysis on the robustness of the trained generator to adversarial perturbations. Experiments on real-world datasets are provided to substantiate the efficacy of the proposed \emph{generative model adversarial training for deep compressed sensing.}      
### 39.Parallel Statistical Model Checking for Safety Verification in Smart Grids  [ :arrow_down: ](https://arxiv.org/pdf/2106.10692.pdf)
>  By using small computing devices deployed at user premises, Autonomous Demand Response (ADR) adapts users electricity consumption to given time-dependent electricity tariffs. This allows end-users to save on their electricity bill and Distribution System Operators to optimise (through suitable time-dependent tariffs) management of the electric grid by avoiding demand peaks. Unfortunately, even with ADR, users power consumption may deviate from the expected (minimum cost) one, e.g., because ADR devices fail to correctly forecast energy needs at user premises. As a result, the aggregated power demand may present undesirable peaks. In this paper we address such a problem by presenting methods and a software tool (APD-Analyser) implementing them, enabling Distribution System Operators to effectively verify that a given time-dependent electricity tariff achieves the desired goals even when end-users deviate from their expected behaviour. We show feasibility of the proposed approach through a realistic scenario from a medium voltage Danish distribution network.      
### 40.Encoder-Decoder Based Attractor Calculation for End-to-End Neural Diarization  [ :arrow_down: ](https://arxiv.org/pdf/2106.10654.pdf)
>  This paper investigates an end-to-end neural diarization (EEND) method for an unknown number of speakers. In contrast to the conventional pipeline approach to speaker diarization, EEND methods are better in terms of speaker overlap handling. However, EEND still has a disadvantage in that it cannot deal with a flexible number of speakers. To remedy this problem, we introduce encoder-decoder-based attractor calculation module (EDA) to EEND. Once frame-wise embeddings are obtained, EDA sequentially generates speaker-wise attractors on the basis of a sequence-to-sequence method using an LSTM encoder-decoder. The attractor generation continues until a stopping condition is satisfied; thus, the number of attractors can be flexible. Diarization results are then estimated as dot products of the attractors and embeddings. The embeddings from speaker overlaps result in larger dot product values with multiple attractors; thus, this method can deal with speaker overlaps. Because the maximum number of output speakers is still limited by the training set, we also propose an iterative inference method to remove this restriction. Further, we propose a method that aligns the estimated diarization results with the results of an external speech activity detector, which enables fair comparison against pipeline approaches. Extensive evaluations on simulated and real datasets show that EEND-EDA outperforms the conventional pipeline approach.      
### 41.Implementing a Detection System for COVID-19 based on Lung Ultrasound Imaging and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.10651.pdf)
>  The COVID-19 pandemic started in China in December 2019 and quickly spread to several countries. The consequences of this pandemic are incalculable, causing the death of millions of people and damaging the global economy. To achieve large-scale control of this pandemic, fast tools for detection and treatment of patients are needed. Thus, the demand for alternative tools for the diagnosis of COVID-19 has increased dramatically since accurated and automated tools are not available. In this paper we present the ongoing work on a system for COVID-19 detection using ultrasound imaging and using Deep Learning techniques. Furthermore, such a system is implemented on a Raspberry Pi to make it portable and easy to use in remote regions without an Internet connection.      
### 42.Nuclei Grading of Clear Cell Renal Cell Carcinoma in Histopathological Image by Composite High-Resolution Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.10641.pdf)
>  The grade of clear cell renal cell carcinoma (ccRCC) is a critical prognostic factor, making ccRCC nuclei grading a crucial task in RCC pathology analysis. Computer-aided nuclei grading aims to improve pathologists' work efficiency while reducing their misdiagnosis rate by automatically identifying the grades of tumor nuclei within histopathological images. Such a task requires precisely segment and accurately classify the nuclei. However, most of the existing nuclei segmentation and classification methods can not handle the inter-class similarity property of nuclei grading, thus can not be directly applied to the ccRCC grading task. In this paper, we propose a Composite High-Resolution Network for ccRCC nuclei grading. Specifically, we propose a segmentation network called W-Net that can separate the clustered nuclei. Then, we recast the fine-grained classification of nuclei to two cross-category classification tasks, based on two high-resolution feature extractors (HRFEs) which are proposed for learning these two tasks. The two HRFEs share the same backbone encoder with W-Net by a composite connection so that meaningful features for the segmentation task can be inherited for the classification task. Last, a head-fusion block is applied to generate the predicted label of each nucleus. Furthermore, we introduce a dataset for ccRCC nuclei grading, containing 1000 image patches with 70945 annotated nuclei. We demonstrate that our proposed method achieves state-of-the-art performance compared to existing methods on this large ccRCC grading dataset.      
### 43.Learning Signal Representations for EEG Cross-Subject Channel Selection and Trial Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.10633.pdf)
>  EEG technology finds applications in several domains. Currently, most EEG systems require subjects to wear several electrodes on the scalp to be effective. However, several channels might include noisy information, redundant signals, induce longer preparation times and increase computational times of any automated system for EEG decoding. One way to reduce the signal-to-noise ratio and improve classification accuracy is to combine channel selection with feature extraction, but EEG signals are known to present high inter-subject variability. In this work we introduce a novel algorithm for subject-independent channel selection of EEG recordings. Considering multi-channel trial recordings as statistical units and the EEG decoding task as the class of reference, the algorithm (i) exploits channel-specific 1D-Convolutional Neural Networks (1D-CNNs) as feature extractors in a supervised fashion to maximize class separability; (ii) it reduces a high dimensional multi-channel trial representation into a unique trial vector by concatenating the channels' embeddings and (iii) recovers the complex inter-channel relationships during channel selection, by exploiting an ensemble of AutoEncoders (AE) to identify from these vectors the most relevant channels to perform classification. After training, the algorithm can be exploited by transferring only the parametrized subgroup of selected channel-specific 1D-CNNs to new signals from new subjects and obtain low-dimensional and highly informative trial vectors to be fed to any classifier.      
### 44.A Scalable 256-Elements E-Band Phased-Array Transceiver for Broadband Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.10623.pdf)
>  For E-band wireless communications, a high gain steerable antenna with sub-arrays is desired to reduce the implementation complexity. This paper presents an E-band communication link with 256-elements antennas based on 8-elements sub-arrays and four beam-forming chips in silicon germanium (SiGe) bipolar complementary metal-oxide-semiconductor (BiCMOS), which is packaged on a 19-layer low temperature co-fired ceramic (LTCC) substrate. After the design and manufacture of the 256-elements antenna, a fast near-field calibration method is proposed for calibration, where a single near-field measurement is required. Then near-field to far-field (NFFF) transform and far-field to near-field (FFNF) transform are used for the bore-sight calibration. The comparison with high frequency structure simulator (HFSS) is utilized for the non-bore-sight calibration. Verified on the 256-elements antenna, the beam-forming performance measured in the chamber is in good agreement with the simulations. The communication in the office environment is also realized using a fifth generation (5G) new radio (NR) system, whose bandwidth is 400 megahertz (MHz) and waveform format is orthogonal frequency division multiplexing (OFDM) with 120 kilohertz (kHz) sub-carrier spacing.      
### 45.Cloud-Assisted Nonlinear Model Predictive Control for Finite-Duration Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10604.pdf)
>  Cloud computing creates new possibilities for control applications by offering powerful computation and storage capabilities. In this paper, we propose a novel cloud-assisted model predictive control (MPC) framework in which we systematically fuse a cloud MPC that uses a high-fidelity nonlinear model but is subject to communication delays with a local MPC that exploits simplified dynamics (due to limited computation) but has timely feedback. Unlike traditional cloud-based control that treats the cloud as powerful, remote, and sole controller in a networked-system control setting, the proposed framework aims at seamlessly integrating the two controllers for enhanced performance. In particular, we formalize the fusion problem for finite-duration tasks by explicitly considering model mismatches and errors due to request-response communication delays. We analyze stability-like properties of the proposed cloud-assisted MPC framework and establish approaches to robustly handling constraints within this framework in spite of plant-model mismatch and disturbances. A fusion scheme is then developed to enhance control performance while satisfying stability-like conditions, the efficacy of which is demonstrated with multiple simulation examples, including an automotive control example to show its industrial application potentials.      
### 46.Optimal adaptive control of a knee joint exoskeleton for lower limb functional rehabilitation  [ :arrow_down: ](https://arxiv.org/pdf/2106.10578.pdf)
>  Lower limb exoskeleton robots hold great potential for rehabilitation, movement assistance, and strength augmentation. Design control to guarantee optimal needed assistance is still a challenge considering the pathological variances between patients. In this paper, we proposed an optimal adaptive control scheme based on Particle Swarm Optimization (PSO) Algorithm. The proposed controller is based on a well-known dynamic model of the knee joint exoskeleton, and the optimization algorithm is used to minimize a square error fitness function, which quantifies tracking performances. Control parameters are tuned respecting some nonlinear constraints for step response of the system and boundaries constraints. Numerical simulation results are presented to show the validity and the high performances of the proposed approach.      
### 47.Enhancing and Localizing Surface Wave Propagation with Reconfigurable Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2106.10569.pdf)
>  As an attempt to develop a reconfigurable surface architecture that can use liquid metal such as Galinstan to shape surface channels on demand, this paper considers a punctured surface where cavities are evenly distributed and can be filled with liquid metal potentially via digitally controlled pumps. In this paper, we look at the benefits of such architecture in terms of surface-wave signal enhancement and isolation, and examine how various system parameters impact the performance using full wave 3-dimensional electromagnetic simulations. It is shown that extraordinary signal shaping can be obtained.      
### 48.EMG Signal Classification Using Reflection Coefficients and Extreme Value Machine  [ :arrow_down: ](https://arxiv.org/pdf/2106.10561.pdf)
>  Electromyography is a promising approach to the gesture recognition of humans if an efficient classifier with high accuracy is available. In this paper, we propose to utilize Extreme Value Machine (EVM) as a high-performance algorithm for the classification of EMG signals. We employ reflection coefficients obtained from an Autoregressive (AR) model to train a set of classifiers. Our experimental results indicate that EVM has better accuracy in comparison to the conventional classifiers approved in the literature based on K-Nearest Neighbors (KNN) and Support Vector Machine (SVM).      
### 49.Signal Processing Based Deep Learning for Blind Symbol Decoding and Modulation Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.10543.pdf)
>  Blindly decoding a signal requires estimating its unknown transmit parameters, compensating for the wireless channel impairments, and identifying the modulation type. While deep learning can solve complex problems, digital signal processing (DSP) is interpretable and can be more computationally efficient. To combine both, we propose the dual path network (DPN). It consists of a signal path of DSP operations that recover the signal, and a feature path of neural networks that estimate the unknown transmit parameters. By interconnecting the paths over several recovery stages, later stages benefit from the recovered signals and reuse all the previously extracted features. The proposed design is demonstrated to provide 5% improvement in modulation classification compared to alternative designs lacking either feature sharing or access to recovered signals. The estimation results of DPN along with its blind decoding performance are shown to outperform a blind signal processing algorithm for BPSK and QPSK on a simulated dataset. An over-the-air software-defined-radio capture was used to verify DPN results at high SNRs. DPN design can process variable length inputs and is shown to outperform relying on fixed length inputs with prediction averaging on longer signals by up to 15% in modulation classification.      
### 50.Reversible Colour Density Compression of Images using cGANs  [ :arrow_down: ](https://arxiv.org/pdf/2106.10542.pdf)
>  Image compression using colour densities is historically impractical to decompress losslessly. We examine the use of conditional generative adversarial networks in making this transformation more feasible, through learning a mapping between the images and a loss function to train on. We show that this method is effective at producing visually lossless generations, indicating that efficient colour compression is viable.      
### 51.Simultaneous Suspension Control and Energy Harvesting through Novel Design and Control of a New Nonlinear Energy Harvesting Shock Absorber  [ :arrow_down: ](https://arxiv.org/pdf/2106.10540.pdf)
>  Simultaneous vibration control and energy harvesting of vehicle suspensions have attracted significant research attention over the past decades. However, existing energy harvesting shock absorbers (EHSAs) are mainly designed based on the principle of linear resonance, thereby compromising suspension performance for high-efficiency energy harvesting and being only responsive to narrow bandwidth vibrations. In this paper, we propose a new EHSA design -- inerter pendulum vibration absorber (IPVA) -- that integrates an electromagnetic rotary EHSA with a nonlinear pendulum vibration absorber. We show that this design simultaneously improves ride comfort and energy harvesting efficiency by exploiting the nonlinear effects of pendulum inertia. To further improve the performance, we develop a novel stochastic linearization model predictive control (SL-MPC) approach in which we employ stochastic linearization to approximate the nonlinear dynamics of EHSA that has superior accuracy compared to standard linearization. In particular, we develop a new stochastic linearization method with guaranteed stabilizability, which is a prerequisite for control designs. This leads to an MPC problem that is much more computationally efficient than the nonlinear MPC counterpart with no major performance degradation. Extensive simulations are performed to show the superiority of the proposed new nonlinear EHSA and to demonstrate the efficacy of the proposed SL-MPC.      
### 52.Learning to Reach, Swim, Walk and Fly in One Trial: Data-Driven Control with Scarce Data and Side Information  [ :arrow_down: ](https://arxiv.org/pdf/2106.10533.pdf)
>  We develop a learning-based control algorithm for unknown dynamical systems under very severe data limitations. Specifically, the algorithm has access to streaming data only from a single and ongoing trial. Despite the scarcity of data, we show -- through a series of examples -- that the algorithm can provide performance comparable to reinforcement learning algorithms trained over millions of environment interactions. It accomplishes such performance by effectively leveraging various forms of side information on the dynamics to reduce the sample complexity. Such side information typically comes from elementary laws of physics and qualitative properties of the system. More precisely, the algorithm approximately solves an optimal control problem encoding the system's desired behavior. To this end, it constructs and refines a differential inclusion that contains the unknown vector field of the dynamics. The differential inclusion, used in an interval Taylor-based method, enables to over-approximate the set of states the system may reach. Theoretically, we establish a bound on the suboptimality of the approximate solution with respect to the case of known dynamics. We show that the longer the trial or the more side information is available, the tighter the bound. Empirically, experiments in a high-fidelity F-16 aircraft simulator and MuJoCo's environments such as the Reacher, Swimmer, and Cheetah illustrate the algorithm's effectiveness.      
### 53.DiffLoop: Tuning PID controllers by differentiating through the feedback loop  [ :arrow_down: ](https://arxiv.org/pdf/2106.10516.pdf)
>  Since most industrial control applications use PID controllers, PID tuning and anti-windup measures are significant problems. This paper investigates tuning the feedback gains of a PID controller via back-calculation and automatic differentiation tools. In particular, we episodically use a cost function to generate gradients and perform gradient descent to improve controller performance. We provide a theoretical framework for analyzing this non-convex optimization and establish a relationship between back-calculation and disturbance feedback policies. We include numerical experiments on linear systems with actuator saturation to show the efficacy of this approach.      
### 54.Cooperative Evasion by Translating Targets with Variable Speeds  [ :arrow_down: ](https://arxiv.org/pdf/2106.10514.pdf)
>  We consider a problem of cooperative evasion between a single pursuer and multiple evaders in which the evaders are constrained to move in the positive Y direction. The evaders are slower than the vehicle and can choose their speeds from a bounded interval. The pursuer aims to intercept all evaders in a given sequence by executing a Manhattan pursuit strategy of moving parallel to the X axis, followed by moving parallel to the Y axis. The aim of the evaders is to cooperatively pick their individual speeds so that the total time to intercept all evaders is maximized. We first obtain conditions under which evaders should cooperate in order to maximize the total time to intercept as opposed to each moving greedily to optimize its own intercept time. Then, we propose and analyze an algorithm that assigns evasive strategies to the evaders in two iterations as opposed to performing an exponential search over the choice of evader speeds. We also characterize a fundamental limit on the total time taken by the pursuer to capture all evaders when the number of evaders is large. Finally, we provide numerical comparisons against random sampling heuristics.      
### 55.Cooperative Magneto-Inductive Localization  [ :arrow_down: ](https://arxiv.org/pdf/2106.10483.pdf)
>  Wireless localization is a key requirement for many applications. It concerns position estimation of mobile nodes (agents) relative to fixed nodes (anchors) from wireless channel measurements. Cooperative localization is an advanced concept that considers the joint estimation of multiple agent positions based on channel measurements of all agent-anchor links together with all agent-agent links. In this paper we present the first study of cooperative localization for magneto-inductive wireless sensor networks, which are of technological interest due to good material penetration and channel predictability. We demonstrate significant accuracy improvements (a factor of 3 for 10 cooperating agents) over the non-cooperative scheme. The evaluation uses the Cramér-Rao lower bound on the cooperative position estimation error, which is derived herein. To realize this accuracy, the maximum-likelihood estimate (MLE) must be computed by solving a high-dimensional least-squares problem, whereby convergence to local minima proves to be problematic. A proposed cooperative localization algorithm addresses this issue: first, preliminary estimates of the agent positions and orientations are computed, which then serve as initial values for a gradient search. In all our test cases, this method yields the MLE and the associated high accuracy (comprising the cooperation gain) from a single solver run. The preliminary estimates use novel closed-form MLE formulas of the distance, direction and orientation for single links between three-axis coils, which are given in detail.      
### 56.A Robust CACC Scheme Against Cyberattacks Via Multiple Vehicle-to-Vehicle Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10448.pdf)
>  Cooperative Adaptive Cruise Control (CACC) is a vehicular technology that allows groups of vehicles on the highway to form in closely-coupled automated platoons to increase highway capacity and safety, and decrease fuel consumption and CO2 emissions. The underlying mechanism behind CACC is the use of Vehicle-to-Vehicle (V2V) wireless communication networks to transmit acceleration commands to adjacent vehicles in the platoon. However, the use of V2V networks leads to increased vulnerabilities against faults and cyberattacks at the communication channels. Communication networks serve as new access points for malicious agents trying to deteriorate the platooning performance or even cause crashes. Here, we address the problem of increasing robustness of CACC schemes against cyberattacks by the use of multiple V2V networks and a data fusion algorithm. The idea is to transmit acceleration commands multiple times through different communication networks (channels) to create redundancy at the receiver side. We exploit this redundancy to obtain attack-free estimates of acceleration commands. To accomplish this, we propose a data-fusion algorithm that takes data from all channels, returns an estimate of the true acceleration command, and isolates compromised channels. Note, however, that using estimated data for control introduces uncertainty into the loop and thus decreases performance. To minimize performance degradation, we propose a robust $H_{\infty}$ controller that reduces the joint effect of estimation errors and sensor/channel noise in the platooning performance (tracking performance and string stability). We present simulation results to illustrate the performance of our approach.      
### 57.One-to-many Approach for Improving Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.10437.pdf)
>  Super-resolution (SR) is a one-to-many task with multiple possible solutions. However, previous works were not concerned about this characteristic. For a one-to-many pipeline, the generator should be able to generate multiple estimates of the reconstruction, and not be penalized for generating similar and equally realistic images. To achieve this, we propose adding weighted pixel-wise noise after every Residual-in-Residual Dense Block (RRDB) to enable the generator to generate various images. We modify the strict content loss to not penalize the stochastic variation in reconstructed images as long as it has consistent content. Additionally, we observe that there are out-of-focus regions in the DIV2K, DIV8K datasets that provide unhelpful guidelines. We filter blurry regions in the training data using the method of [10]. Finally, we modify the discriminator to receive the low-resolution image as a reference image along with the target image to provide better feedback to the generator. Using our proposed methods, we were able to improve the performance of ESRGAN in x4 perceptual SR and achieve the state-of-the-art LPIPS score in x16 perceptual extreme SR.      
### 58.A Survey on Machine Learning Algorithms for Applications in Cognitive Radio Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10413.pdf)
>  In this paper, we present a survey on the utility of machine learning (ML) algorithms for applications in cognitive radio networks (CRN). We start with a high-level overview of some of the major challenges in CRNs, and mention the ML architectures and algorithms that can be used to alleviate them. In particular, our focus is on two fundamental applications in CRNs, namely spectrum sensing -- with non-cooperative and cooperative scenarios, and dynamic spectrum access -- with spectrum auction and prediction. We present a detailed study of recent advancements in the field of ML in CRNs for these applications, and briefly discuss the set of challenges in real-time implementation of ML techniques for CRNs.      
### 59.Cascaded Channel Estimation for RIS Assisted mmWave MIMO Transmissions  [ :arrow_down: ](https://arxiv.org/pdf/2106.10405.pdf)
>  Channel estimation is challenging for the reconfigurable intelligence surface (RIS) assisted millimeter wave (mmWave) communications. Since the number of coefficients of the cascaded channels in such systems is closely dependent on the product of the number of base station antennas and the number of RIS elements, the pilot overhead would be prohibitively high. In this letter, we propose a cascaded channel estimation framework for an RIS assisted mmWave multiple-input multiple-output system, where the wideband effect on transmission model is considered. Then, we transform the wideband channel estimation into a parameter recovery problem and use a few pilot symbols to detect the channel parameters by the Newtonized orthogonal matching pursuit algorithm. Moreover, the Cramer-Rao lower bound on the channel estimation is introduced. Numerical results show the effectiveness of the proposed channel estimation scheme.      
### 60.Parallel frequency function-deep neural network for efficient complex broadband signal approximation  [ :arrow_down: ](https://arxiv.org/pdf/2106.10401.pdf)
>  A neural network is essentially a high-dimensional complex mapping model by adjusting network weights for feature fitting. However, the spectral bias in network training leads to unbearable training epochs for fitting the high-frequency components in broadband signals. To improve the fitting efficiency of high-frequency components, the PhaseDNN was proposed recently by combining complex frequency band extraction and frequency shift techniques [Cai et al. SIAM J. SCI. COMPUT. 42, A3285 (2020)]. Our paper is devoted to an alternative candidate for fitting complex signals with high-frequency components. Here, a parallel frequency function-deep neural network (PFF-DNN) is proposed to suppress computational overhead while ensuring fitting accuracy by utilizing fast Fourier analysis of broadband signals and the spectral bias nature of neural networks. The effectiveness and efficiency of the proposed PFF-DNN method are verified based on detailed numerical experiments for six typical broadband signals.      
### 61.Direct Reconstruction of Linear Parametric Images from Dynamic PET Using Nonlocal Deep Image Prior  [ :arrow_down: ](https://arxiv.org/pdf/2106.10359.pdf)
>  Direct reconstruction methods have been developed to estimate parametric images directly from the measured PET sinograms by combining the PET imaging model and tracer kinetics in an integrated framework. Due to limited counts received, signal-to-noise-ratio (SNR) and resolution of parametric images produced by direct reconstruction frameworks are still limited. Recently supervised deep learning methods have been successfully applied to medical imaging denoising/reconstruction when large number of high-quality training labels are available. For static PET imaging, high-quality training labels can be acquired by extending the scanning time. However, this is not feasible for dynamic PET imaging, where the scanning time is already long enough. In this work, we proposed an unsupervised deep learning framework for direct parametric reconstruction from dynamic PET, which was tested on the Patlak model and the relative equilibrium Logan model. The patient's anatomical prior image, which is readily available from PET/CT or PET/MR scans, was supplied as the network input to provide a manifold constraint, and also utilized to construct a kernel layer to perform non-local feature denoising. The linear kinetic model was embedded in the network structure as a 1x1 convolution layer. The training objective function was based on the PET statistical model. Evaluations based on dynamic datasets of 18F-FDG and 11C-PiB tracers show that the proposed framework can outperform the traditional and the kernel method-based direct reconstruction methods.      
### 62.Liquid Sensing Using WiFi Signals  [ :arrow_down: ](https://arxiv.org/pdf/2106.10356.pdf)
>  The popularity of Internet-of-Things (IoT) has provided us with unprecedented opportunities to enable a variety of emerging services in a smart home environment. Among those services, sensing the liquid level in a container is critical to building many smart home and mobile healthcare applications that improve the quality of life. This paper presents LiquidSense, a liquid-level sensing system that is low-cost, high accuracy, widely applicable to different daily liquids and containers, and can be easily integrated with existing smart home networks. LiquidSense uses an existing home WiFi network and a low-cost transducer that attached to the container to sense the resonance of the container for liquid level detection. In particular, our system mounts a low-cost transducer on the surface of the container and emits a well-designed chirp signal to make the container resonant, which introduces subtle changes to the home WiFi signals. By analyzing the subtle phase changes of the WiFi signals, LiquidSense extracts the resonance frequency as a feature for liquid level detection. Our system constructs prediction models for both continuous and discrete predictions using curve fitting and SVM respectively. We evaluate LiquidSense in home environments with containers of three different materials and six types of liquids. Results show that LiquidSense achieves an overall accuracy of 97% for continuous prediction and an overall F-score of 0.968 for discrete prediction. Results also show that our system has a large coverage in a home environment and works well under non-line-of-sight (NLOS) scenarios.      
### 63.On the Impact of the Capacity Drop Phenomenon for Freeway Traffic Flow Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.10347.pdf)
>  Capacity drop is an empirically observed phenomenon in vehicular traffic flow on freeways whereby, after a critical density is reached, a state of congestion sets in, but the freeway does not become decongested again until the density drops well below the critical density. This introduces a hysteresis effect so that it is easier to enter the congested state than to leave it. However, many existing first-order models of traffic flow, particularly those used for control design, ignore capacity drop, leading to suboptimal controllers. In this paper, we consider a cell transmission model of traffic flow that incorporates capacity drop to study the problem of optimal freeway ramp metering. We show that, if capacity drop is ignored in the control design, then the resulting controller, obtained via a convex program, may be significantly suboptimal. We then propose an alternative model predictive controller that accounts for capacity drop via a mixed integer linear program and show that, for sufficiently large rollout horizon, this controller is optimal. We also compare these approaches to a heuristic hand-crafted controller that is viewed as a modification of an integral feedback controller to account for capacity drop. This heuristic controller outperforms the controller that ignores capacity drop but underperforms compared to the proposed alternative model predictive controller. These results suggest that it is generally important to include capacity drop in the controller design process, and we demonstrate this insight on several case studies.      
### 64.GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage  [ :arrow_down: ](https://arxiv.org/pdf/2106.10277.pdf)
>  In this paper, we introduce a new acoustic leakage dataset of gas pipelines, called as GPLA-12, which has 12 categories over 684 training/testing acoustic signals. Unlike massive image and voice datasets, there have relatively few acoustic signal datasets, especially for engineering fault detection. In order to enhance the development of fault diagnosis, we collect acoustic leakage signals on the basis of an intact gas pipe system with external artificial leakages, and then preprocess the collected data with structured tailoring which are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning dataset for time-series tasks and classifications. To further understand the dataset, we train both shadow and deep learning algorithms to observe the performance. The dataset as well as the pretrained models have been released at both www.daip.club and <a class="link-external link-http" href="http://github.com/Deep-AI-Application-DAIP" rel="external noopener nofollow">this http URL</a>      
### 65.Attention-based Neural Network for Driving Environment Complexity Perception  [ :arrow_down: ](https://arxiv.org/pdf/2106.11277.pdf)
>  Environment perception is crucial for autonomous vehicle (AV) safety. Most existing AV perception algorithms have not studied the surrounding environment complexity and failed to include the environment complexity parameter. This paper proposes a novel attention-based neural network model to predict the complexity level of the surrounding driving environment. The proposed model takes naturalistic driving videos and corresponding vehicle dynamics parameters as input. It consists of a Yolo-v3 object detection algorithm, a heat map generation algorithm, CNN-based feature extractors, and attention-based feature extractors for both video and time-series vehicle dynamics data inputs to extract features. The output from the proposed algorithm is a surrounding environment complexity parameter. The Berkeley DeepDrive dataset (BDD Dataset) and subjectively labeled surrounding environment complexity levels are used for model training and validation to evaluate the algorithm. The proposed attention-based network achieves 91.22% average classification accuracy to classify the surrounding environment complexity. It proves that the environment complexity level can be accurately predicted and applied for future AVs' environment perception studies.      
### 66.Reliability and Validity of Image-Based and Self-Reported Skin Phenotype Metrics  [ :arrow_down: ](https://arxiv.org/pdf/2106.11240.pdf)
>  With increasing adoption of face recognition systems, it is important to ensure adequate performance of these technologies across demographic groups. Recently, phenotypes such as skin-tone, have been proposed as superior alternatives to traditional race categories when exploring performance differentials. However, there is little consensus regarding how to appropriately measure skin-tone in evaluations of biometric performance or in AI more broadly. In this study, we explore the relationship between face-area-lightness-measures (FALMs) estimated from images and ground-truth skin readings collected using a device designed to measure human skin. FALMs estimated from different images of the same individual varied significantly relative to ground-truth FALM. This variation was only reduced by greater control of acquisition (camera, background, and environment). Next, we compare ground-truth FALM to Fitzpatrick Skin Types (FST) categories obtained using the standard, in-person, medical survey and show FST is poorly predictive of skin-tone. Finally, we show how noisy estimation of FALM leads to errors selecting explanatory factors for demographic differentials. These results demonstrate that measures of skin-tone for biometric performance evaluations must come from objective, characterized, and controlled sources. Further, despite this being a currently practiced approach, estimating FST categories and FALMs from uncontrolled imagery does not provide an appropriate measure of skin-tone.      
### 67.Affinity Mixup for Weakly Supervised Sound Event Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.11233.pdf)
>  The weakly supervised sound event detection problem is the task of predicting the presence of sound events and their corresponding starting and ending points in a weakly labeled dataset. A weak dataset associates each training sample (a short recording) to one or more present sources. Networks that solely rely on convolutional and recurrent layers cannot directly relate multiple frames in a recording. Motivated by attention and graph neural networks, we introduce the concept of an affinity mixup to incorporate time-level similarities and make a connection between frames. This regularization technique mixes up features in different layers using an adaptive affinity matrix. Our proposed affinity mixup network improves over state-of-the-art techniques event-F1 scores by $8.2\%$.      
### 68.Deep Neural Network-Based Blind Multiple User Detection for Grant-free Multi-User Shared Access  [ :arrow_down: ](https://arxiv.org/pdf/2106.11204.pdf)
>  Multi-user shared access (MUSA) is introduced as advanced code domain non-orthogonal complex spreading sequences to support a massive number of machine-type communications (MTC) devices. In this paper, we propose a novel deep neural network (DNN)-based multiple user detection (MUD) for grant-free MUSA systems. The DNN-based MUD model determines the structure of the sensing matrix, randomly distributed noise, and inter-device interference during the training phase of the model by several hidden nodes, neuron activation units, and a fit loss function. The thoroughly learned DNN model is capable of distinguishing the active devices of the received signal without any a priori knowledge of the device sparsity level and the channel state information. Our numerical evaluation shows that with a higher percentage of active devices, the DNN-MUD achieves a significantly increased probability of detection compared to the conventional approaches.      
### 69.Classification of Documents Extracted from Images with Optical Character Recognition Methods  [ :arrow_down: ](https://arxiv.org/pdf/2106.11125.pdf)
>  Over the past decade, machine learning methods have given us driverless cars, voice recognition, effective web search, and a much better understanding of the human genome. Machine learning is so common today that it is used dozens of times a day, possibly unknowingly. Trying to teach a machine some processes or some situations can make them predict some results that are difficult to predict by the human brain. These methods also help us do some operations that are often impossible or difficult to do with human activities in a short time. For these reasons, machine learning is so important today. In this study, two different machine learning methods were combined. In order to solve a real-world problem, the manuscript documents were first transferred to the computer and then classified. We used three basic methods to realize the whole process. Handwriting or printed documents have been digitalized by a scanner or digital camera. These documents have been processed with two different Optical Character Recognition (OCR) operation. After that generated texts are classified by using Naive Bayes algorithm. All project was programmed in Microsoft Visual Studio 12 platform on Windows operating system. C# programming language was used for all parts of the study. Also, some prepared codes and DLLs were used.      
### 70.EML Online Speech Activity Detection for the Fearless Steps Challenge Phase-III  [ :arrow_down: ](https://arxiv.org/pdf/2106.11075.pdf)
>  Speech Activity Detection (SAD), locating speech segments within an audio recording, is a main part of most speech technology applications. Robust SAD is usually more difficult in noisy conditions with varying signal-to-noise ratios (SNR). The Fearless Steps challenge has recently provided such data from the NASA Apollo-11 mission for different speech processing tasks including SAD. Most audio recordings are degraded by different kinds and levels of noise varying within and between channels. This paper describes the EML online algorithm for the most recent phase of this challenge. The proposed algorithm can be trained both in a supervised and unsupervised manner and assigns speech and non-speech labels at runtime approximately every 0.1 sec. The experimental results show a competitive accuracy on both development and evaluation datasets with a real-time factor of about 0.002 using a single CPU machine.      
### 71.Paradigm selection for Data Fusion of SAR and Multispectral Sentinel data applied to Land-Cover Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.11056.pdf)
>  Data fusion is a well-known technique, becoming more and more popular in the Artificial Intelligence for Earth Observation (AI4EO) domain mainly due to its ability of reinforcing AI4EO applications by combining multiple data sources and thus bringing better results. On the other hand, like other methods for satellite data analysis, data fusion itself is also benefiting and evolving thanks to the integration of Artificial Intelligence (AI). In this letter, four data fusion paradigms, based on Convolutional Neural Networks (CNNs), are analyzed and implemented. The goals are to provide a systematic procedure for choosing the best data fusion framework, resulting in the best classification results, once the basic structure for the CNN has been defined, and to help interested researchers in their work when data fusion applied to remote sensing is involved. The procedure has been validated for land-cover classification but it can be transferred to other cases.      
### 72.Hard Choices in Artificial Intelligence  [ :arrow_down: ](https://arxiv.org/pdf/2106.11022.pdf)
>  As AI systems are integrated into high stakes social domains, researchers now examine how to design and operate them in a safe and ethical manner. However, the criteria for identifying and diagnosing safety risks in complex social contexts remain unclear and contested. In this paper, we examine the vagueness in debates about the safety and ethical behavior of AI systems. We show how this vagueness cannot be resolved through mathematical formalism alone, instead requiring deliberation about the politics of development as well as the context of deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness in terms of distinct design challenges at key stages in AI system development. The resulting framework of Hard Choices in Artificial Intelligence (HCAI) empowers developers by 1) identifying points of overlap between design decisions and major sociotechnical challenges; 2) motivating the creation of stakeholder feedback channels so that safety issues can be exhaustively addressed. As such, HCAI contributes to a timely debate about the status of AI development in democratic societies, arguing that deliberation should be the goal of AI Safety, not just the procedure by which it is ensured.      
### 73.Polynomial Input-to-state Stability of Infinite-dimensional Linear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.10933.pdf)
>  We introduce a notion of polynomial input-to-state stability for infinite-dimensional linear systems. This notion comes from polynomial stability of $C_0$-semigroups. We obtain sufficient conditions for polynomial input-to-state stability, by restricting the range of an input operator. Necessary conditions for polynomial input-to-state stability and an attractivity property related to polynomial input-to-state stability are also investigated.      
### 74.Unsupervised Deep Learning by Injecting Low-Rank and Sparse Priors  [ :arrow_down: ](https://arxiv.org/pdf/2106.10923.pdf)
>  What if deep neural networks can learn from sparsity-inducing priors? When the networks are designed by combining layer modules (CNN, RNN, etc), engineers less exploit the inductive bias, i.e., existing well-known rules or prior knowledge, other than annotated training data sets. We focus on employing sparsity-inducing priors in deep learning to encourage the network to concisely capture the nature of high-dimensional data in an unsupervised way. In order to use non-differentiable sparsity-inducing norms as loss functions, we plug their proximal mappings into the automatic differentiation framework. We demonstrate unsupervised learning of U-Net for background subtraction using low-rank and sparse priors. The U-Net can learn moving objects in a training sequence without any annotation, and successfully detect the foreground objects in test sequences.      
### 75.Performance Evaluation of Cooperative NOMA-based Improved Hybrid SWIPT Protocol  [ :arrow_down: ](https://arxiv.org/pdf/2106.10799.pdf)
>  This study proposes the integration of a cooperative non-orthogonal multiple access (CNOMA) and improved hybrid simultaneous wireless information and power transfer (IHS SWIPT) protocol (termed as CNOMA-IHS) to enhance the spectral efficiency (SE) of a downlink (DL) CNOMA communication system. CNOMA-IHS scheme can enhance the ergodic sum capacity (ESC) and energy efficiency (EE) of DL CNOMA by transferring additional symbols towards the users and energize the relay operation as well without any additional resources (e.g., time slot/frequency/code). The analytical and simulation results indicate that the proposed CNOMA-IHS scheme outperforms other existing SWIPT-based schemes (e.g., CNOMA with hybrid SWIPT, CNOMA with power-splitting SWIPT, wireless-powered CNOMA, CNOMA with time switching SWIPT, and orthogonal multiple access with IHS SWIPT) in terms of the ESC. Moreover, the CNOMA-IHS scheme also enhances EE compared with other conventional TS-SWIPT-based schemes, which is also illustrated by the simulation results. In addition, the proposed CNOMA-IHS scheme with the considered EE optimization technique outplayed the proposed CNOMA-IHS scheme without EE optimization and other existing TS-SWIPT-based schemes in terms of EE.      
### 76.Transfer Bayesian Meta-learning via Weighted Free Energy Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.10711.pdf)
>  Meta-learning optimizes the hyperparameters of a training procedure, such as its initialization, kernel, or learning rate, based on data sampled from a number of auxiliary tasks. A key underlying assumption is that the auxiliary tasks, known as meta-training tasks, share the same generating distribution as the tasks to be encountered at deployment time, known as meta-test tasks. This may, however, not be the case when the test environment differ from the meta-training conditions. To address shifts in task generating distribution between meta-training and meta-testing phases, this paper introduces weighted free energy minimization (WFEM) for transfer meta-learning. We instantiate the proposed approach for non-parametric Bayesian regression and classification via Gaussian Processes (GPs). The method is validated on a toy sinusoidal regression problem, as well as on classification using miniImagenet and CUB data sets, through comparison with standard meta-learning of GP priors as implemented by PACOH.      
### 77.Spatial Covariance Matrix Reconstruction for DOA Estimation in Hybrid Massive MIMO Systems with Multiple Radio Frequency Chains  [ :arrow_down: ](https://arxiv.org/pdf/2106.10709.pdf)
>  Multiple signal classification (MUSIC) has been widely applied in multiple-input multiple-output (MIMO) receivers for direction-of-arrival (DOA) estimation. To reduce the cost of radio frequency (RF) chains operating at millimeter-wave bands, hybrid analog-digital structure has been adopted in massive MIMO transceivers. In this situation, the received signals at the antennas are unavailable to the digital receiver, and as a consequence, the spatial covariance matrix (SCM), which is essential in MUSIC algorithm, cannot be obtained using traditional sample average approach. Based on our previous work, we propose a novel algorithm for SCM reconstruction in hybrid massive MIMO systems with multiple RF chains. By switching the analog beamformers to a group of predetermined DOAs, SCM can be reconstructed through the solutions of a set of linear equations. In addition, based on insightful analysis on that linear equations, a low-complexity algorithm, as well as a careful selection of the predetermined DOAs, will be also presented in this paper. Simulation results show that the proposed algorithms can reconstruct the SCM accurately so that MUSIC algorithm can be well used for DOA estimation in hybrid massive MIMO systems with multiple RF chains.      
### 78.Feedback Nash Equilibria in Differential Games with Impulse Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.10706.pdf)
>  We study a class of deterministic finite-horizon two-player nonzero-sum differential games where players are endowed with different kinds of controls. We assume that Player 1 uses piecewise-continuous controls, while Player 2 uses impulse controls. For this class of games, we seek to derive conditions for the existence of feedback Nash equilibrium strategies for the players. More specifically, we provide a verification theorem for identifying such equilibrium strategies, using the Hamilton-Jacobi-Bellman (HJB) equations for Player 1 and the quasi-variational inequalities (QVIs) for Player 2. Further, we show that the equilibrium number of interventions by Player 2 is upper bounded. Furthermore, we specialize the obtained results to a scalar two-player linear-quadratic differential game. In this game, Player 1's objective is to drive the state variable towards a specific target value, and Player 2 has a similar objective with a different target value. We provide, for the first time, an analytical characterization of the feedback Nash equilibrium in a linear-quadratic differential game with impulse control. We illustrate our results using numerical experiments.      
### 79.Hole Detection and Healing in Hybrid Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10659.pdf)
>  Although monitoring and covering are fundamental goals of a wireless sensor network (WSN), the accidental death of sensors or the running out of their energy would result in holes in the WSN. Such holes have the potential to disrupt the primary functions of WSNs. This paper investigates the hole detection and healing problems in hybrid WSNs with non-identical sensor sensing ranges. In particular, we aim to propose centralized algorithms for detecting holes in a given region and maximizing the area covered by a WSN in the presence of environmental obstacles. To precisely identify the boundary of the holes, we use an additively weighted Voronoi diagram and a polynomial-time algorithm.Furthermore, since this problem is known to be computationally difficult, we propose a centralized greedy 1/2-approximation algorithm to maximize the area covered by sensors. Finally, we implement the algorithms and run simulations to show that our approximation algorithm efficiently covers the holes by moving the mobile sensors.      
### 80.More than Encoder: Introducing Transformer Decoder to Upsample  [ :arrow_down: ](https://arxiv.org/pdf/2106.10637.pdf)
>  General segmentation models downsample images and then upsample to restore resolution for pixel level prediction. In such schema, upsample technique is vital in maintaining information for better performance. In this paper, we present a new upsample approach, Attention Upsample (AU), that could serve as general upsample method and be incorporated into any segmentation model that possesses lateral connections. AU leverages pixel-level attention to model long range dependency and global information for better reconstruction. It consists of Attention Decoder (AD) and bilinear upsample as residual connection to complement the upsampled features. AD adopts the idea of decoder from transformer which upsamples features conditioned on local and detailed information from contracting path. Moreover, considering the extensive memory and computation cost of pixel-level attention, we further propose to use window attention scheme to restrict attention computation in local windows instead of global range. Incorporating window attention, we denote our decoder as Window Attention Decoder (WAD) and our upsample method as Window Attention Upsample (WAU). We test our method on classic U-Net structure with lateral connection to deliver information from contracting path and achieve state-of-the-arts performance on Synapse (80.30 DSC and 23.12 HD) and MSD Brain (74.75 DSC) datasets.      
### 81.Low-Power Multi-Camera Object Re-Identification using Hierarchical Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10588.pdf)
>  Low-power computer vision on embedded devices has many applications. This paper describes a low-power technique for the object re-identification (reID) problem: matching a query image against a gallery of previously seen images. State-of-the-art techniques rely on large, computationally-intensive Deep Neural Networks (DNNs). We propose a novel hierarchical DNN architecture that uses attribute labels in the training dataset to perform efficient object reID. At each node in the hierarchy, a small DNN identifies a different attribute of the query image. The small DNN at each leaf node is specialized to re-identify a subset of the gallery: only the images with the attributes identified along the path from the root to a leaf. Thus, a query image is re-identified accurately after processing with a few small DNNs. We compare our method with state-of-the-art object reID techniques. With a 4% loss in accuracy, our approach realizes significant resource savings: 74% less memory, 72% fewer operations, and 67% lower query latency, yielding 65% less energy consumption.      
### 82.Coded Faster-than-Nyquist Signaling for Short Packet Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.10574.pdf)
>  Ultra-reliable low-latency communication (URLLC) requires short packets of data transmission. It is known that when the packet length becomes short, the achievable rate is subject to a penalty when compared to the channel capacity. In this paper, we propose to use faster-than-Nyquist (FTN) signaling to compensate for the achievable rate loss of short packet communications. We investigate the performance of a combination of a low complexity detector of FTN signaling used with nonbinary low-density parity-check (NB-LDPC) codes that is suitable for low-latency and short block length requirements of URLLC systems. Our investigation shows that such combination of low-complexity FTN signaling detection and NB-LDPC codes outperforms the use of close-to-optimal FTN signaling detectors with LDPC codes in terms of error rate performance and also has a considerably lower computational complexity.      
### 83.Graph Neural Networks for Learning Real-Time Prices in Electricity Market  [ :arrow_down: ](https://arxiv.org/pdf/2106.10529.pdf)
>  Solving the optimal power flow (OPF) problem in real-time electricity market improves the efficiency and reliability in the integration of low-carbon energy resources into the power grids. To address the scalability and adaptivity issues of existing end-to-end OPF learning solutions, we propose a new graph neural network (GNN) framework for predicting the electricity market prices from solving OPFs. The proposed GNN-for-OPF framework innovatively exploits the locality property of prices and introduces physics-aware regularization, while attaining reduced model complexity and fast adaptivity to varying grid topology. Numerical tests have validated the learning efficiency and adaptivity improvements of our proposed method over existing approaches.      
### 84.Stability of Graph Convolutional Neural Networks to Stochastic Perturbations  [ :arrow_down: ](https://arxiv.org/pdf/2106.10526.pdf)
>  Graph convolutional neural networks (GCNNs) are nonlinear processing tools to learn representations from network data. A key property of GCNNs is their stability to graph perturbations. Current analysis considers deterministic perturbations but fails to provide relevant insights when topological changes are random. This paper investigates the stability of GCNNs to stochastic graph perturbations induced by link losses. In particular, it proves the expected output difference between the GCNN over random perturbed graphs and the GCNN over the nominal graph is upper bounded by a factor that is linear in the link loss probability. We perform the stability analysis in the graph spectral domain such that the result holds uniformly for any graph. This result also shows the role of the nonlinearity and the architecture width and depth, and allows identifying handle to improve the GCNN robustness. Numerical simulations on source localization and robot swarm control corroborate our theoretical findings.      
### 85.Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.10497.pdf)
>  We study predictive control in a setting where the dynamics are time-varying and linear, and the costs are time-varying and well-conditioned. At each time step, the controller receives the exact predictions of costs, dynamics, and disturbances for the future $k$ time steps. We show that when the prediction window $k$ is sufficiently large, predictive control is input-to-state stable and achieves a dynamic regret of $O(\lambda^k T)$, where $\lambda &lt; 1$ is a positive constant. This is the first dynamic regret bound on the predictive control of linear time-varying systems. Under more assumptions on the terminal costs, we also show that predictive control obtains the first competitive bound for the control of linear time-varying systems: $1 + O(\lambda^k)$. Our results are derived using a novel proof framework based on a perturbation bound that characterizes how a small change to the system parameters impacts the optimal trajectory.      
### 86.Advances in Speech Vocoding for Text-to-Speech with Continuous Parameters  [ :arrow_down: ](https://arxiv.org/pdf/2106.10481.pdf)
>  Vocoders received renewed attention as main components in statistical parametric text-to-speech (TTS) synthesis and speech transformation systems. Even though there are vocoding techniques give almost accepted synthesized speech, their high computational complexity and irregular structures are still considered challenging concerns, which yield a variety of voice quality degradation. Therefore, this paper presents new techniques in a continuous vocoder, that is all features are continuous and presents a flexible speech synthesis system. First, a new continuous noise masking based on the phase distortion is proposed to eliminate the perceptual impact of the residual noise and letting an accurate reconstruction of noise characteristics. Second, we addressed the need of neural sequence to sequence modeling approach for the task of TTS based on recurrent networks. Bidirectional long short-term memory (LSTM) and gated recurrent unit (GRU) are studied and applied to model continuous parameters for more natural-sounding like a human. The evaluation results proved that the proposed model achieves the state-of-the-art performance of the speech synthesis compared with the other traditional methods.      
### 87.On the Ergodic Capacity of Reconfigurable Intelligent Surface (RIS)-Aided MIMO Channels  [ :arrow_down: ](https://arxiv.org/pdf/2106.10444.pdf)
>  Reconfigurable intelligent surfaces (RISs) have emerged as a promising technique to enhance the system spectral efficiency. This letter investigates the ergodic channel capacity (ECC) of an RIS-aided multiple-input multiple-output channel under the assumption that the transmitter-RIS, RIS-receiver, and transmitter-receiver channels contain deterministic line-of-sight paths. Novel expressions are derived to characterize the upper and lower bounds of the ECC. To unveil more system insights, asymptotic analyses are performed to the system ECC in the limit of large signal-to-noise ratio (SNR) and number of reflecting elements (REs). Theoretical analyses suggest that the RIS's deployment can shape the ECC curve by influencing its high-SNR power offset and the ECC can get improved by increasing the number of REs.      
### 88.ML and MAP Device Activity Detections for Grant-Free Massive Access in Multi-Cell Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.10438.pdf)
>  Device activity detection is one main challenge in grant-free massive access, which is recently proposed to support massive machine-type communications (mMTC). Existing solutions for device activity detection fail to consider inter-cell interference generated by massive IoT devices or important prior information on device activities and inter-cell interference. In this paper, given different numbers of observations and network parameters, we consider both non-cooperative device activity detection and cooperative device activity detection in a multi-cell network, consisting of many access points (APs) and IoT devices. Under each activity detection mechanism, we consider the joint maximum likelihood (ML) estimation and joint maximum a posterior probability (MAP) estimation of both device activities and interference powers, utilizing tools from probability, stochastic geometry, and optimization. Each estimation problem is a challenging non-convex problem, and a coordinate descent algorithm is proposed to obtain a stationary point. Each proposed joint ML estimation extends the existing one for a single-cell network by considering the estimation of interference powers, together with the estimation of device activities. Each proposed joint MAP estimation further enhances the corresponding joint ML estimation by exploiting prior distributions of device activities and interference powers. The proposed joint ML estimation and joint MAP estimation under cooperative detection outperform the respective ones under non-cooperative detection at the costs of increasing backhaul burden, knowledge of network parameters, and computational complexities.      
### 89.Neural Network Facial Authentication for Public Electric Vehicle Charging Station  [ :arrow_down: ](https://arxiv.org/pdf/2106.10432.pdf)
>  This study is to investigate and compare the facial recognition accuracy performance of Dlib ResNet against a K-Nearest Neighbour (KNN) classifier. Particularly when used against a dataset from an Asian ethnicity as Dlib ResNet was reported to have an accuracy deficiency when it comes to Asian faces. The comparisons are both implemented on the facial vectors extracted using the Histogram of Oriented Gradients (HOG) method and use the same dataset for a fair comparison. Authentication of a user by facial recognition in an electric vehicle (EV) charging station demonstrates a practical use case for such an authentication system.      
### 90.Multi-Contextual Design of Convolutional Neural Network for Steganalysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.10430.pdf)
>  In recent times, deep learning-based steganalysis classifiers became popular due to their state-of-the-art performance. Most deep steganalysis classifiers usually extract noise residuals using high-pass filters as preprocessing steps and feed them to their deep model for classification. It is observed that recent steganographic embedding does not always restrict their embedding in the high-frequency zone; instead, they distribute it as per embedding policy. Therefore, besides noise residual, learning the embedding zone is another challenging task. In this work, unlike the conventional approaches, the proposed model first extracts the noise residual using learned denoising kernels to boost the signal-to-noise ratio. After preprocessing, the sparse noise residuals are fed to a novel Multi-Contextual Convolutional Neural Network (M-CNET) that uses heterogeneous context size to learn the sparse and low-amplitude representation of noise residuals. The model performance is further improved by incorporating the Self-Attention module to focus on the areas prone to steganalytic embedding. A set of comprehensive experiments is performed to show the proposed scheme's efficacy over the prior arts. Besides, an ablation study is given to justify the contribution of various modules of the proposed architecture.      
### 91.Algorithm Unrolling for Massive Access via Deep Neural Network with Theoretical Guarantee  [ :arrow_down: ](https://arxiv.org/pdf/2106.10426.pdf)
>  Massive access is a critical design challenge of Internet of Things (IoT) networks. In this paper, we consider the grant-free uplink transmission of an IoT network with a multiple-antenna base station (BS) and a large number of single-antenna IoT devices. Taking into account the sporadic nature of IoT devices, we formulate the joint activity detection and channel estimation (JADCE) problem as a group-sparse matrix estimation problem. This problem can be solved by applying the existing compressed sensing techniques, which however either suffer from high computational complexities or lack of algorithm robustness. To this end, we propose a novel algorithm unrolling framework based on the deep neural network to simultaneously achieve low computational complexity and high robustness for solving the JADCE problem. Specifically, we map the original iterative shrinkage thresholding algorithm (ISTA) into an unrolled recurrent neural network (RNN), thereby improving the convergence rate and computational efficiency through end-to-end training. Moreover, the proposed algorithm unrolling approach inherits the structure and domain knowledge of the ISTA, thereby maintaining the algorithm robustness, which can handle non-Gaussian preamble sequence matrix in massive access. With rigorous theoretical analysis, we further simplify the unrolled network structure by reducing the redundant training parameters. Furthermore, we prove that the simplified unrolled deep neural network structures enjoy a linear convergence rate. Extensive simulations based on various preamble signatures show that the proposed unrolled networks outperform the existing methods in terms of the convergence rate, robustness and estimation accuracy.      
### 92.Joint Speed Control and Energy Replenishment Optimization for UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.10423.pdf)
>  Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a prominent application due to its flexibility, mobility, and low operational cost. However, under the dynamic and uncertainty of IoT data collection and energy replenishment processes, optimizing the performance for UAV collectors is a very challenging task. Thus, this paper introduces a novel framework that jointly optimizes the flying speed and energy replenishment for each UAV to significantly improve the data collection performance. Specifically, we first develop a Markov decision process to help the UAV automatically and dynamically make optimal decisions under the dynamics and uncertainties of the environment. We then propose a highly-effective reinforcement learning algorithm leveraging deep Q-learning, double deep Q-learning, and a deep dueling neural network architecture to quickly obtain the UAV's optimal policy. The core ideas of this algorithm are to estimate the state values and action advantages separately and simultaneously and to employ double estimators for estimating the action values. Thus, these proposed techniques can stabilize the learning process and effectively address the overestimation problem of conventional Q-learning algorithms. To further reduce the learning time as well as significantly improve learning quality, we develop advanced transfer learning techniques to allow UAVs to ``share'' and ``transfer'' learning knowledge. Extensive simulations demonstrate that our proposed solution can improve the average data collection performance of the system up to 200% compared with those of current methods.      
### 93.When Efficiency meets Equity in Congestion Pricing and Revenue Refunding Schemes  [ :arrow_down: ](https://arxiv.org/pdf/2106.10407.pdf)
>  Congestion pricing has long been hailed as a means to mitigate traffic congestion; however, its practical adoption has been limited due to the resulting social inequity issue, e.g., low-income users are priced out off certain roads. This issue has spurred interest in the design of equitable mechanisms that aim to refund the collected toll revenues as lump-sum transfers to users. Although revenue refunding has been extensively studied, there has been no thorough characterization of how such schemes can be designed to simultaneously achieve system efficiency and equity objectives. <br>In this work, we bridge this gap through the study of congestion pricing and revenue refunding (CPRR) schemes in non-atomic congestion games. We first develop CPRR schemes, which in comparison to the untolled case, simultaneously (i) increase system efficiency and (ii) decrease wealth inequality, while being (iii) user-favorable: irrespective of their initial wealth or values-of-time (which may differ across users) users would experience a lower travel cost after the implementation of the proposed scheme. We then characterize the set of optimal user-favorable CPRR schemes that simultaneously maximize system efficiency and minimize wealth inequality. These results assume a well-studied behavior model of users minimizing a linear function of their travel times and tolls, without considering refunds. We also study a more complex behavior model wherein users are influenced by and react to the amount of refund that they receive. Although, in general, the two models can result in different outcomes in terms of system efficiency and wealth inequality, we establish that those outcomes coincide when the aforementioned optimal CPRR scheme is implemented. Overall, our work demonstrates that through appropriate refunding policies we can achieve system efficiency while reducing wealth inequality.      
### 94.Improving robustness of one-shot voice conversion with deep discriminative speaker encoder  [ :arrow_down: ](https://arxiv.org/pdf/2106.10406.pdf)
>  One-shot voice conversion has received significant attention since only one utterance from source speaker and target speaker respectively is required. Moreover, source speaker and target speaker do not need to be seen during training. However, available one-shot voice conversion approaches are not stable for unseen speakers as the speaker embedding extracted from one utterance of an unseen speaker is not reliable. In this paper, we propose a deep discriminative speaker encoder to extract speaker embedding from one utterance more effectively. Specifically, the speaker encoder first integrates residual network and squeeze-and-excitation network to extract discriminative speaker information in frame level by modeling frame-wise and channel-wise interdependence in features. Then attention mechanism is introduced to further emphasize speaker related information via assigning different weights to frame level speaker information. Finally a statistic pooling layer is used to aggregate weighted frame level speaker information to form utterance level speaker embedding. The experimental results demonstrate that our proposed speaker encoder can improve the robustness of one-shot voice conversion for unseen speakers and outperforms baseline systems in terms of speech quality and speaker similarity.      
### 95.High Relative Degree Control Barrier Functions Under Input Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2106.10345.pdf)
>  This paper presents methodologies for ensuring forward invariance of sublevel sets of constraint functions with high-relative-degree with respect to the system dynamics and in the presence of input constraints. We show that such constraint functions can be converted into special Zeroing Control Barrier Functions (ZCBFs), which, by construction, generate sufficient conditions for rendering the state always inside a sublevel set of the constraint function in the presence of input constraints. We present a general form for one such ZCBF, as well as a special case applicable to a specific class of systems. We conclude with a comparison of system trajectories under the two ZCBFs developed and prior literature, and a case study for an asteroid observation problem using quadratic-program based controllers to enforce the ZCBF condition.      

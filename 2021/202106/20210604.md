# ArXiv eess --Fri, 4 Jun 2021
### 1.Real-time Grid and DER Co-simulation Platform for Validating Large-scale DER Control Schemes  [ :arrow_down: ](https://arxiv.org/pdf/2106.01993.pdf)
>  Distributed energy resources (DERs) such as responsive loads and energy storage systems are valuable resources available to grid operators for balancing supply-demand mismatches via load coordination. However, consumer acceptance of load coordination schemes depends on ensuring quality of service (QoS), which embodies device-level constraints. Since each device has its own internal energy state, the effect of QoS on the fleet can be cast as fleet-wide energy limits within which the aggregate "state of charge" (SoC) must be actively maintained. This requires coordination of DERs that is cognizant of the SoC, responsive to grid conditions, and depends on fast communication networks. To that effect, this paper presents a novel real-time grid-and-DER co-simulation platform for validating advanced DER coordination schemes and characterizing the capability of such a DER fleet. In particular, we present how the co-simulation platform is suitable for: i) testing real-time performance of a large fleet of DERs in delivering advanced grid services, including frequency regulation; ii) online state estimation to characterize the corresponding SoC of a large fleet of DERs; and iii) incorporating practical limitations of DERs and communications and analyzing the effects on fleet-wide performance. To illustrate these benefits of the presented grid-DER co-simulation platform, we employ the advanced DER coordination scheme called packetized energy management (PEM), which is a novel device-driven, asynchronous, and randomizing control paradigm for DERs. A fleet of thousands of PEM-enabled DERs are then added to a realistic and dynamical model of the Vermont transmission system to complete validation of the co-simulation platform.      
### 2.An Improved Model for Voicing Silent Speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.01933.pdf)
>  In this paper, we present an improved model for voicing silent speech, where audio is synthesized from facial electromyography (EMG) signals. To give our model greater flexibility to learn its own input features, we directly use EMG signals as input in the place of hand-designed features used by prior work. Our model uses convolutional layers to extract features from the signals and Transformer layers to propagate information across longer distances. To provide better signal for learning, we also introduce an auxiliary task of predicting phoneme labels in addition to predicting speech audio features. On an open vocabulary intelligibility evaluation, our model improves the state of the art for this task by an absolute 25.8%.      
### 3.Highly Accelerated EPI with Wave Encoding and Multi-shot Simultaneous Multi-Slice Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2106.01918.pdf)
>  We introduce wave encoded acquisition and reconstruction techniques for highly accelerated echo planar imaging (EPI) with reduced g-factor penalty and image artifacts. Wave-EPI involves playing sinusoidal gradients during the EPI readout while employing interslice shifts as in blipped-CAIPI acquisitions. This spreads the aliasing in all spatial directions, thereby taking better advantage of 3D coil sensitivity profiles. The amount of voxel spreading that can be achieved by the wave gradients during the short EPI readout period is constrained by the slew rate of the gradient coils and peripheral nerve stimulation (PNS) monitor. We propose to use a half-cycle sinusoidal gradient to increase the amount of voxel spreading that can be achieved while respecting the slew and stimulation constraints. Extending wave-EPI to multi-shot acquisition minimizes geometric distortion and voxel blurring at high in-plane resolution, while structured low-rank regularization mitigates shot-to-shot phase variations without additional navigators. We propose to use different point spread functions (PSFs) for the k-space lines with positive and negative polarities, which are calibrated with a FLEET-based reference scan and allow for addressing gradient imperfections. Wave-EPI provided whole-brain single-shot gradient echo (GE) and multi-shot spin echo (SE) EPI acquisitions at high acceleration factors and was combined with g-Slider slab encoding to boost the SNR level in 1mm isotropic diffusion imaging. Relative to blipped-CAIPI, wave-EPI reduced average and maximum g-factors by up to 1.21- and 1.37-fold, respectively. In conclusion, wave-EPI allows highly accelerated single- and multi-shot EPI with reduced g-factor and artifacts and may facilitate clinical and neuroscientific applications of EPI by improving the spatial and temporal resolution in functional and diffusion imaging.      
### 4.Pathology-Aware Generative Adversarial Networks for Medical Image Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.01915.pdf)
>  Convolutional Neural Networks (CNNs) can play a key role in Medical Image Analysis under large-scale annotated datasets. However, preparing such massive dataset is demanding. In this context, Generative Adversarial Networks (GANs) can generate realistic but novel samples, and thus effectively cover the real image distribution. In terms of interpolation, the GAN-based medical image augmentation is reliable because medical modalities can display the human body's strong anatomical consistency at fixed position while clearly reflecting inter-subject variability; thus, we propose to use noise-to-image GANs (e.g., random noise samples to diverse pathological images) for (i) medical Data Augmentation (DA) and (ii) physician training. Regarding the DA, the GAN-generated images can improve Computer-Aided Diagnosis based on supervised learning. For the physician training, the GANs can display novel desired pathological images and help train medical trainees despite infrastructural/legal constraints. This thesis contains four GAN projects aiming to present such novel applications' clinical relevance in collaboration with physicians. Whereas the methods are more generally applicable, this thesis only explores a few oncological applications.      
### 5.Robotic Inspection and 3D GPR-based Reconstruction for Underground Utilities  [ :arrow_down: ](https://arxiv.org/pdf/2106.01907.pdf)
>  Ground Penetrating Radar (GPR) is an effective non-destructive evaluation (NDE) device for inspecting and surveying subsurface objects (i.e., rebars, utility pipes) in complex environments. However, the current practice for GPR data collection requires a human inspector to move a GPR cart along pre-marked grid lines and record the GPR data in both X and Y directions for post-processing by 3D GPR imaging software. It is time-consuming and tedious work to survey a large area. Furthermore, identifying the subsurface targets depends on the knowledge of an experienced engineer, who has to make manual and subjective interpretation that limits the GPR applications, especially in large-scale scenarios. In addition, the current GPR imaging technology is not intuitive, and not for normal users to understand, and not friendly to visualize. To address the above challenges, this paper presents a novel robotic system to collect GPR data, interpret GPR data, localize the underground utilities, reconstruct and visualize the underground objects' dense point cloud model in a user-friendly manner. This system is composed of three modules: 1) a vision-aided Omni-directional robotic data collection platform, which enables the GPR antenna to scan the target area freely with an arbitrary trajectory while using a visual-inertial-based positioning module tags the GPR measurements with positioning information; 2) a deep neural network (DNN) migration module to interpret the raw GPR B-scan image into a cross-section of object model; 3) a DNN-based 3D reconstruction method, i.e., GPRNet, to generate underground utility model represented as fine 3D point cloud. Comparative studies on synthetic and field GPR raw data with various incompleteness and noise are performed.      
### 6.Joint Multi-Channel Dereverberation and Noise Reduction Using a Unified Convolutional Beamformer With Sparse Priors  [ :arrow_down: ](https://arxiv.org/pdf/2106.01902.pdf)
>  Recently, the convolutional weighted power minimization distortionless response (WPD) beamformer was proposed, which unifies multi-channel weighted prediction error dereverberation and minimum power distortionless response beamforming. To optimize the convolutional filter, the desired speech component is modeled with a time-varying Gaussian model, which promotes the sparsity of the desired speech component in the short-time Fourier transform domain compared to the noisy microphone signals. In this paper we generalize the convolutional WPD beamformer by using an lp-norm cost function, introducing an adjustable shape parameter which enables to control the sparsity of the desired speech component. Experiments based on the REVERB challenge dataset show that the proposed method outperforms the conventional convolutional WPD beamformer in terms of objective speech quality metrics.      
### 7.Denoising and Optical and SAR Image Classifications Based on Feature Extraction and Sparse Representation  [ :arrow_down: ](https://arxiv.org/pdf/2106.01896.pdf)
>  Optical image data have been used by the Remote Sensing workforce to study land use and cover since such data is easily interpretable. Synthetic Aperture Radar (SAR) has the characteristic of obtaining images during all-day, all-weather and provides object information that is different from visible and infrared sensors. However, SAR images have more speckle noise and fewer dimensions. This paper presents a method for denoising, feature extraction and compares classifications of Optical and SAR images. The image was denoised using K-Singular Value Decomposition (K-SVD) algorithm. A method to map the extraordinary goal signatures to be had withinside the SAR or Optical image using support vector machine (SVM) through offering given the enter facts to the supervised classifier. Initially, the Gray Level Histogram (GLH) and Gray Level Co-occurrence Matrix (GLCM) are used for feature extraction. Secondly, the extracted feature vectors from the first step were combined using correlation analysis to reduce the dimensionality of the feature spaces. Thirdly, the Classification of SAR images was done in Sparse Representations Classification (SRC). The above-mentioned classifications techniques were developed and performance parameters are accuracy and Kappa Coefficient calculated using MATLAB 2018a.      
### 8.Three-agent Time-constrained Cooperative Pursuit-Evasion  [ :arrow_down: ](https://arxiv.org/pdf/2106.01895.pdf)
>  This paper considers a pursuit-evasion scenario among three agents -- an evader, a pursuer, and a defender. We design cooperative guidance laws for the evader and the defender team to safeguard the evader from an attacking pursuer. Unlike differential games, optimal control formulations, and other heuristic methods, we propose a novel perspective on designing effective nonlinear feedback control laws for the evader-defender team using a time-constrained guidance approach. The evader lures the pursuer on the collision course by offering itself as bait. At the same time, the defender protects the evader from the pursuer by exercising control over the engagement duration. Depending on the nature of the mission, the defender may choose to take an aggressive or defensive stance. Such consideration widens the applicability of the proposed methods in various three-agent motion planning scenarios such as aircraft defense, asset guarding, search and rescue, surveillance, and secure transportation. We use a fixed-time sliding mode control strategy to design the control laws for the evader-defender team and a nonlinear finite-time disturbance observer to estimate the pursuer's maneuver. Finally, we present simulations to demonstrate favorable performance under various engagement geometries, thus vindicating the efficacy of the proposed designs.      
### 9.Worst-Case Pointing Performance Analysis for Large Flexible Spacecraft  [ :arrow_down: ](https://arxiv.org/pdf/2106.01893.pdf)
>  This paper presents a tool, PELIB, developed in MATLAB /SIMULINK environment to perform pointing performance analysis based on European pointing standards. PELIB is designed as an extension of the Satellite Dynamics Toolbox (SDT), which derives the Linear Fractional Transformation (LFT) models of flexible space structures. The addition of PELIB will allow the users of SDT to perform pointing performance analysis of real mission scenarios in the same environment used for control synthesis. PELIB offers as well the possibility to take into account uncertainties in the system. This feature represents an enhancement to the current verification tools available in the European space industry community by providing the worst-case pointing budget. The capabilities of PELIB were demonstrated in a case study involving a spacecraft model with two flexible solar arrays. Several error sources, as well as uncertain parameters, were included in this model. The nominal performance has been investigated using PELIB and compared with the current European reference tool. The worst-case performance is also investigated with the new feature of PELIB to obtain the worst-case performance budget      
### 10.Separated-Spectral-Distribution Estimation Based on Bayesian Inference with Single RGB Camera  [ :arrow_down: ](https://arxiv.org/pdf/2106.01861.pdf)
>  In this paper, we propose a novel method for separately estimating spectral distributions from images captured by a typical RGB camera. The proposed method allows us to separately estimate a spectral distribution of illumination, reflectance, or camera sensitivity, while recent hyperspectral cameras are limited to capturing a joint spectral distribution from a scene. In addition, the use of Bayesian inference makes it possible to take into account prior information of both spectral distributions and image noise as probability distributions. As a result, the proposed method can estimate spectral distributions in a unified way, and it can enhance the robustness of the estimation against noise, which conventional spectral-distribution estimation methods cannot. The use of Bayesian inference also enables us to obtain the confidence of estimation results. In an experiment, the proposed method is shown not only to outperform conventional estimation methods in terms of RMSE but also to be robust against noise.      
### 11.Noisy Labels are Treasure: Mean-Teacher-Assisted Confident Learning for Hepatic Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.01860.pdf)
>  Manually segmenting the hepatic vessels from Computer Tomography (CT) is far more expertise-demanding and laborious than other structures due to the low-contrast and complex morphology of vessels, resulting in the extreme lack of high-quality labeled data. Without sufficient high-quality annotations, the usual data-driven learning-based approaches struggle with deficient training. On the other hand, directly introducing additional data with low-quality annotations may confuse the network, leading to undesirable performance degradation. To address this issue, we propose a novel mean-teacher-assisted confident learning framework to robustly exploit the noisy labeled data for the challenging hepatic vessel segmentation task. Specifically, with the adapted confident learning assisted by a third party, i.e., the weight-averaged teacher model, the noisy labels in the additional low-quality dataset can be transformed from "encumbrance" to "treasure" via progressive pixel-wise soft-correction, thus providing productive guidance. Extensive experiments using two public datasets demonstrate the superiority of the proposed framework as well as the effectiveness of each component.      
### 12.Deep Learning Based Analysis of Prostate Cancer from MP-MRI  [ :arrow_down: ](https://arxiv.org/pdf/2106.01835.pdf)
>  The diagnosis of prostate cancer faces a problem with overdiagnosis that leads to damaging side effects due to unnecessary treatment. Research has shown that the use of multi-parametric magnetic resonance images to conduct biopsies can drastically help to mitigate the overdiagnosis, thus reducing the side effects on healthy patients. This study aims to investigate the use of deep learning techniques to explore computer-aid diagnosis based on MRI as input. Several diagnosis problems ranging from classification of lesions as being clinically significant or not to the detection and segmentation of lesions are addressed with deep learning based approaches. <br>This thesis tackled two main problems regarding the diagnosis of prostate cancer. Firstly, XmasNet was used to conduct two large experiments on the classification of lesions. Secondly, detection and segmentation experiments were conducted, first on the prostate and afterward on the prostate cancer lesions. The former experiments explored the lesions through a two-dimensional space, while the latter explored models to work with three-dimensional inputs. For this task, the 3D models explored were the 3D U-Net and a pretrained 3D ResNet-18. A rigorous analysis of all these problems was conducted with a total of two networks, two cropping techniques, two resampling techniques, two crop sizes, five input sizes and data augmentations experimented for lesion classification. While for segmentation two models, two input sizes and data augmentations were experimented. However, while the binary classification of the clinical significance of lesions and the detection and segmentation of the prostate already achieve the desired results (0.870 AUC and 0.915 dice score respectively), the classification of the PIRADS score and the segmentation of lesions still have a large margin to improve (0.664 accuracy and 0.690 dice score respectively).      
### 13.Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on Whole-body Micro-CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2106.01830.pdf)
>  Machine Learning-based fast and quantitative automated screening plays a key role in analyzing human bones on Computed Tomography (CT) scans. However, despite the requirement in drug safety assessment, such research is rare on animal fetus micro-CT scans due to its laborious data collection and annotation. Therefore, we propose various bone feature engineering techniques to thoroughly automate the skeletal localization/labeling/abnormality detection of rat fetuses on whole-body micro-CT scans with minimum effort. Despite limited training data of 49 fetuses, in skeletal labeling and abnormality detection, we achieve accuracy of 0.900 and 0.810, respectively.      
### 14.Identification of physical networks through structured polynomial models  [ :arrow_down: ](https://arxiv.org/pdf/2106.01813.pdf)
>  Physical dynamic networks most commonly consist of interconnections of physical components that can be described by diffusive couplings. These diffusive couplings imply that the cause-effect relationships in the interconnections are symmetric and therefore physical dynamic networks can be represented by undirected graphs. This paper shows how (prediction error) identification methods developed for polynomial linear time-invariant systems can be configured to consistently identify the parameters and the interconnection structure of (undirected) physical networks. Further, a multi-step least squares (convex) optimization algorithm is developed to solve the nonconvex optimization problem that results from the identification method.      
### 15.An objective evaluation of the effects of recording conditions and speaker characteristics in multi-speaker deep neural speech synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.01812.pdf)
>  Multi-speaker spoken datasets enable the creation of text-to-speech synthesis (TTS) systems which can output several voice identities. The multi-speaker (MSPK) scenario also enables the use of fewer training samples per speaker. However, in the resulting acoustic model, not all speakers exhibit the same synthetic quality, and some of the voice identities cannot be used at all. <br>In this paper we evaluate the influence of the recording conditions, speaker gender, and speaker particularities over the quality of the synthesised output of a deep neural TTS architecture, namely Tacotron2. The evaluation is possible due to the use of a large Romanian parallel spoken corpus containing over 81 hours of data. Within this setup, we also evaluate the influence of different types of text representations: orthographic, phonetic, and phonetic extended with syllable boundaries and lexical stress markings. <br>We evaluate the results of the MSPK system using the objective measures of equal error rate (EER) and word error rate (WER), and also look into the distances between natural and synthesised t-SNE projections of the embeddings computed by an accurate speaker verification network. The results show that there is indeed a large correlation between the recording conditions and the speaker's synthetic voice quality. The speaker gender does not influence the output, and that extending the input text representation with syllable boundaries and lexical stress information does not equally enhance the generated audio across all speaker identities. The visualisation of the t-SNE projections of the natural and synthesised speaker embeddings show that the acoustic model shifts some of the speakers' neural representation, but not all of them. As a result, these speakers have lower performances of the output speech.      
### 16.An Information-oriented Model of Multi-Scale (Feedback) Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.01801.pdf)
>  Multi-scale structures are prevalent in both natural and artificial systems, as they can handle increasing complexity. Several terms are employed almost interchangeably across various application domains to refer to the multi-scale concept - e.g., hierarchy, holarchy, multi-level, multi-layer, nested, embedded, micro-macro or coarse graining. While the concrete meanings behind these terms may differ slightly, several core commonalities persist across all cases. In this position paper we aim to highlight these common features of the multi-scale concept, as a preliminary basis for a generic theory of multi-scale systems. We discuss the concepts of scale and multi-scale systems in general, and then of multi-scale feedback systems in particular, focusing on the role played by information in such systems. Our long-term objective is to develop a general theory of multi-scale feedback systems, applicable across all domains dealing with complex systems.      
### 17.Speaker verification-derived loss and data augmentation for DNN-based multispeaker speech synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.01789.pdf)
>  Building multispeaker neural network-based text-to-speech synthesis systems commonly relies on the availability of large amounts of high quality recordings from each speaker and conditioning the training process on the speaker's identity or on a learned representation of it. However, when little data is available from each speaker, or the number of speakers is limited, the multispeaker TTS can be hard to train and will result in poor speaker similarity and naturalness. <br>In order to address this issue, we explore two directions: forcing the network to learn a better speaker identity representation by appending an additional loss term; and augmenting the input data pertaining to each speaker using waveform manipulation methods. We show that both methods are efficient when evaluated with both objective and subjective measures. The additional loss term aids the speaker similarity, while the data augmentation improves the intelligibility of the multispeaker TTS system.      
### 18.Advances in Classifying the Stages of Diabetic Retinopathy Using Convolutional Neural Networks in Low Memory Edge Devices  [ :arrow_down: ](https://arxiv.org/pdf/2106.01739.pdf)
>  Diabetic Retinopathy (DR) is a severe complication that may lead to retinal vascular damage and is one of the leading causes of vision impairment and blindness. DR broadly is classified into two stages - non-proliferative (NPDR), where there are almost no symptoms, except a few microaneurysms, and proliferative (PDR) involving a huge number of microaneurysms and hemorrhages, soft and hard exudates, neo-vascularization, macular ischemia or a combination of these, making it easier to detect. More specifically, DR is usually classified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is most severe. This paper firstly presents a discussion on the risk factors of the disease, then surveys the recent literature on the topic followed by examining certain techniques which were found to be highly effective in improving the prognosis accuracy. Finally, a convolutional neural network model is proposed to detect all the stages of DR on a low-memory edge microcontroller. The model has a size of just 5.9 MB, accuracy and F1 score both of 94% and an inference speed of about 20 frames per second.      
### 19.A Novel SEPIC-Ćuk Based High Gain Solar Micro-Inverter for Grid Integration  [ :arrow_down: ](https://arxiv.org/pdf/2106.01733.pdf)
>  Solar micro-inverters are becoming increasingly popular as they are modular, and they posses the capability of extracting maximum available power from the individual photovoltaic (PV) modules of a solar array. For realizing micro-inverters single stage transformer-less topologies are preferred as they offer better power evacuation efficacy. A SEPIC-Ćuk based transformer-less micro-inverter, having only one high frequency switch and four line frequency switches, is proposed in this paper. The proposed converter can be employed to interface a 35 V PV module to a 220 V single phase ac grid. As a very high gain is required to be achieved for the converter, it is made to operate in discontinuous conduction mode (DCM) for all possible operating conditions. Since the ground of the each PV modules is connected to the ground of the utility, there is no possibility of leakage current flow between the module and the utility. Detailed simulation studies are carried out to ascertain the efficacy of the proposed micro-inverter. A laboratory prototype of the inverter is fabricated, and detailed experimental studies are carried out to confirm the viability of the proposed scheme.      
### 20.Fast improvement of TEM image with low-dose electrons by deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.01718.pdf)
>  Low-electron-dose observation is indispensable for observing various samples using a transmission electron microscope; consequently, image processing has been used to improve transmission electron microscopy (TEM) images. To apply such image processing to in situ observations, we here apply a convolutional neural network to TEM imaging. Using a dataset that includes short-exposure images and long-exposure images, we develop a pipeline for processed short-exposure images, based on end-to-end training. The quality of images acquired with a total dose of approximately 5 e- per pixel becomes comparable to that of images acquired with a total dose of approximately 1000 e- per pixel. Because the conversion time is approximately 8 ms, in situ observation at 125 fps is possible. This imaging technique enables in situ observation of electron-beam-sensitive specimens.      
### 21.Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis  [ :arrow_down: ](https://arxiv.org/pdf/2106.01700.pdf)
>  Objective is to assess the ability of texture features for detecting radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view radiographs. We used lateral view knee radiographs from MOST public use datasets (n = 5507 knees). Patellar region-of-interest (ROI) was automatically detected using landmark detection tool (BoneFinder). Hand-crafted features, based on LocalBinary Patterns (LBP), were then extracted to describe the patellar texture. First, a machine learning model (Gradient Boosting Machine) was trained to detect radiographic PFOA from the LBP features. Furthermore, we used end-to-end trained deep convolutional neural networks (CNNs) directly on the texture patches for detecting the PFOA. The proposed classification models were eventually compared with more conventional reference models that use clinical assessments and participant characteristics such as age, sex, body mass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL) grade. Atlas-guided visual assessment of PFOA status by expert readers provided in the MOST public use datasets was used as a classification outcome for the models. Performance of prediction models was assessed using the area under the receiver operating characteristic curve (ROC AUC), the area under the precision-recall (PR) curve-average precision (AP)-, and Brier score in the stratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had PFOA. AUC and AP for the strongest reference model including age, sex, BMI, WOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487, respectively. Textural ROI classification using CNN significantly improved the prediction performance (ROC AUC= 0.889, AP= 0.714). We present the first study that analyses patellar bone texture for diagnosing PFOA. Our results demonstrates the potential of using texture features of patella to predict PFOA.      
### 22.Timing Configurations Affect the Macro-Properties of Multi-Scale Feedback Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.01651.pdf)
>  Multi-scale feedback systems, where information cycles through micro- and macro-scales leading to adaptation, are ubiquitous across domains, from animal societies and human organisations to electric grids and neural networks. Studies on the effects of timing on system properties are often domain specific. The Multi-Scale Abstraction Feedbacks (MSAF) design pattern aims to generalise the description and understanding of multi-scale systems where feedback occurs across scales. We expand on MSAF to include timing considerations. We then apply these considerations to two models: a hierarchical oscillator (HO) and a hierarchical cellular automata (HCA). Results show how (i) different timing configurations significantly affect system macro-properties and (ii) different regions of time configurations can lead to the same macro-properties. These results contribute to theory, while also providing useful insights for designing and controlling such systems.      
### 23.Three-dimensional Epanechnikov mixture regression in image coding  [ :arrow_down: ](https://arxiv.org/pdf/2106.01643.pdf)
>  Kernel methods have been studied extensively in recent years. We propose a three-dimensional (3-D) Epanechnikov Mixture Regression (EMR) based on our Epanechnikov Kernel (EK) and realize a complete framework for image coding. In our research, we deduce the covariance-matrix form of 3-D Epanechnikov kernels and their correlated statistics to obtain the Epanechnikov mixture models. To apply our theories to image coding, we propose the 3-D EMR which can better model an image in smaller blocks compared with the conventional Gaussian Mixture Regression (GMR). The regressions are all based on our improved Expectation-Maximization (EM) algorithm with mean square error optimization. Finally, we design an Adaptive Mode Selection (AMS) algorithm to realize the best model pattern combination for coding. Our recovered image has clear outlines and superior coding efficiency compared to JPEG below 0.25bpp. Our work realizes an unprecedented theory application by: (1) enriching the theory of Epanechnikov kernel,(2) improving the EM algorithm using MSE optimization, (3) exploiting the EMR and its application in image coding, and (4) AMS optimal modeling combined with Gaussian and Epanechnikov kernel.      
### 24.An Information Theoretic approach to identify Dominant Voltage Influencers for Unbalanced Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.01587.pdf)
>  Smart distribution grid with multiple renewable energy sources can experience random voltage fluctuations due to variable generation, which may result in voltage violations. Traditional voltage control algorithms are inadequate to handle fast voltage variations. Therefore, new dynamic control methods are being developed that can significantly benefit from the knowledge of dominant voltage influencer (DVI) nodes. DVI nodes for a particular node of interest refer to nodes that have a relatively high impact on the voltage fluctuations at that node. Conventional power flow-based algorithms to identify DVI nodes are computationally complex, which limits their use in real-time applications. This paper proposes a novel information theoretic voltage influencing score (VIS) that quantifies the voltage influencing capacity of nodes with DERs/active loads in a three phase unbalanced distribution system. VIS is then employed to rank the nodes and identify the DVI set. VIS is derived analytically in a computationally efficient manner and its efficacy to identify DVI nodes is validated using the IEEE 37-node test system. It is shown through experiments that KL divergence and Bhattacharyya distance are effective indicators of DVI nodes with an identifying accuracy of more than 90%. The computation burden is also reduced by an order of 5, thus providing the foundation for efficient voltage control.      
### 25.Waveform Design for Joint Sensing and Communications in the Terahertz Band  [ :arrow_down: ](https://arxiv.org/pdf/2106.01549.pdf)
>  The convergence of radar sensing and communication applications in the terahertz (THz) band has been envisioned as a promising technology, since it incorporates terabit-per-second (Tbps) data transmission and mm-level radar sensing in a spectrum- and cost-efficient manner, by sharing both the frequency and hardware resources. However, the joint THz radar and communication (JRC) system faces considerable challenges, due to the peculiarities of the THz channel and front ends. To this end, the waveform design for THz-JRC systems with ultra-broad bandwidth is investigated in this paper. Firstly, by considering THz-JRC systems based on the co-existence concept, where both functions operate in a time-domain duplex (TDD) manner, a novel multi-subband quasi-perfect (MS-QP) sequence, composed of multiple Zadoff-Chu (ZC) perfect subsequences on different subbands, is proposed for target sensing, which achieves accurate target ranging and velocity estimation, whilst only requiring cost-efficient low-rate analog-to-digital converters (A/Ds) for sequence detection. Furthermore, the root index of each ZC subsequence of the MS-QP sequence is designed to eliminate the influence of doppler shift on the THz radar sensing. Finally, a data-embedded MS-QP (DE-MS-QP) waveform is constructed through time-domain extension of the MS-QP sequence, generating null frequency points on each subband for data transmission. Unlike the THz-JRC system in TDD manner, the proposed DE-MS-QP waveform enables simultaneous interference-free sensing and communication, whilst inheriting all the merits from MS-QP sequences. Numerical results validate the superiority of the proposed waveforms in terms of sensing performance, hardware cost and flexible resource allocation over their conventional counterparts.      
### 26.Granger Causality from Quantized Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2106.01513.pdf)
>  An approach is proposed for inferring Granger causality between jointly stationary, Gaussian signals from quantized data. First, a necessary and sufficient rank criterion for the equality of two conditional Gaussian distributions is proved. Assuming a partial finite-order Markov property, conditions are then derived under which Granger causality between them can be reliably inferred from the second order moments of the quantized processes. A necessary and sufficient condition is proposed for Granger causality inference under binary quantization. Furthermore, sufficient conditions are introduced to infer Granger causality between jointly Gaussian signals through measurements quantized via non-uniform, uniform or high resolution quantizers. This approach does not require the statistics of the underlying Gaussian signals to be estimated, or a system model to be identified. No assumptions are made on the identifiability of the jointly Gaussian random processes through the quantized observations. The effectiveness of the proposed method is illustrated by simulation results.      
### 27.IoT Solutions with Multi-Sensor Fusion and Signal-Image Encoding for Secure Data Transfer and Decision Making  [ :arrow_down: ](https://arxiv.org/pdf/2106.01497.pdf)
>  Deployment of Internet of Things (IoT) devices and Data Fusion techniques have gained popularity in public and government domains. This usually requires capturing and consolidating data from multiple sources. As datasets do not necessarily originate from identical sensors, fused data typically results in a complex data problem. Because military is investigating how heterogeneous IoT devices can aid processes and tasks, we investigate a multi-sensor approach. Moreover, we propose a signal to image encoding approach to transform information (signal) to integrate (fuse) data from IoT wearable devices to an image which is invertible and easier to visualize supporting decision making. Furthermore, we investigate the challenge of enabling an intelligent identification and detection operation and demonstrate the feasibility of the proposed Deep Learning and Anomaly Detection models that can support future application that utilizes hand gesture data from wearable devices.      
### 28.Comprehensive Energy Footprint Benchmarking Algorithm for Electrified Powertrains  [ :arrow_down: ](https://arxiv.org/pdf/2106.01459.pdf)
>  Autonomy and electrification in automotive control systems have made modern-day powertrains one of the most complex cyber-physical systems. This paper presents a benchmark algorithm to quantify the performance of complex automotive systems exhibiting mechanical, electrical, and thermal interactions at various time-scales. Traditionally Dynamic Programming has been used for benchmarking the performance, however, it fails to deliver results for system with higher number of states and control lever due to curse of dimensionality. We propose "PS3", a three-step algorithm for mixed-integer nonlinear optimal control problems with application to powertrain energy management. PS3 uses pseudo-spectral collocation theory for highly accurate modeling of dynamics. Based on the validated powertrain component models, we have addressed simultaneous optimization of electrical (SOC), vehicular (eco-driving) and thermal (after-treatment and battery temperatures) dynamics along with an integer (gear and engine on/off) control and its corresponding (dwell-time) constraints. PS3 is used to solve such large-scale powertrain problems having fast and slow dynamic states, discontinuous behaviors, non-differentiable and linearly interpolated 1-D and 2-D maps, as well as combinatorial constraints. Five case study powertrain control problems are given to benchmark the accuracy and computational effort against Dynamic Programming. Our analysis shows that this algorithm does not scale computational burden as Dynamic Programming does, and can handle highly complex interactions that occur in modern-day powertrains, without compromising nonlinear and complex plant modeling.      
### 29.Real-Time COVID-19 Diagnosis from X-Ray Images Using Deep CNN and Extreme Learning Machines Stabilized by Chimp Optimization Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2106.01435.pdf)
>  Real-time detection of COVID-19 using radiological images has gained priority due to the increasing demand for fast diagnosis of COVID-19 cases. This paper introduces a novel two-phase approach for classifying chest X-ray images. Deep Learning (DL) methods fail to cover these aspects since training and fine-tuning the model's parameters consume much time. In this approach, the first phase comes to train a deep CNN working as a feature extractor, and the second phase comes to use Extreme Learning Machines (ELMs) for real-time detection. The main drawback of ELMs is to meet the need of a large number of hidden-layer nodes to gain a reliable and accurate detector in applying image processing since the detective performance remarkably depends on the setting of initial weights and biases. Therefore, this paper uses Chimp Optimization Algorithm (ChOA) to improve results and increase the reliability of the network while maintaining real-time capability. The designed detector is to be benchmarked on the COVID-Xray-5k and COVIDetectioNet datasets, and the results are verified by comparing it with the classic DCNN, Genetic Algorithm optimized ELM (GA-ELM), Cuckoo Search optimized ELM (CS-ELM), and Whale Optimization Algorithm optimized ELM (WOA-ELM). The proposed approach outperforms other comparative benchmarks with 98.25% and 99.11% as ultimate accuracy on the COVID-Xray-5k and COVIDetectioNet datasets, respectively, and it led relative error to reduce as the amount of 1.75% and 1.01% as compared to a convolutional CNN. More importantly, the time needed for training deep ChOA-ELM is only 0.9474 milliseconds, and the overall testing time for 3100 images is 2.937 seconds.      
### 30.Dual Script E2E framework for Multilingual and Code-Switching ASR  [ :arrow_down: ](https://arxiv.org/pdf/2106.01400.pdf)
>  India is home to multiple languages, and training automatic speech recognition (ASR) systems for languages is challenging. Over time, each language has adopted words from other languages, such as English, leading to code-mixing. Most Indian languages also have their own unique scripts, which poses a major limitation in training multilingual and code-switching ASR systems. <br>Inspired by results in text-to-speech synthesis, in this work, we use an in-house rule-based phoneme-level common label set (CLS) representation to train multilingual and code-switching ASR for Indian languages. We propose two end-to-end (E2E) ASR systems. In the first system, the E2E model is trained on the CLS representation, and we use a novel data-driven back-end to recover the native language script. In the second system, we propose a modification to the E2E model, wherein the CLS representation and the native language characters are used simultaneously for training. We show our results on the multilingual and code-switching tasks of the Indic ASR Challenge 2021. Our best results achieve 6% and 5% improvement (approx) in word error rate over the baseline system for the multilingual and code-switching tasks, respectively, on the challenge development data.      
### 31.Formally Verified Next-Generation Airborne Collision Avoidance Games in ACAS X  [ :arrow_down: ](https://arxiv.org/pdf/2106.02030.pdf)
>  The design of aircraft collision avoidance algorithms is a subtle but important challenge that merits the need for provable safety guarantees. Obtaining such guarantees is nontrivial given the unpredictability of the interplay of the intruder aircraft decisions, the ownship pilot reactions, and the subtlety of the continuous motion dynamics of aircraft. Existing collision avoidance systems, such as TCAS and the Next-Generation Airborne Collision Avoidance System ACAS X, have been analyzed assuming severe restrictions on the intruder's flight maneuvers, limiting their safety guarantees in real-world scenarios where the intruder may also be changing its course. This work takes a conceptually significant and practically relevant departure from existing ACAS X models by generalizing them to hybrid games with first-class representations of the ownship and intruder decisions coming from two independent players. By proving the existence of winning strategies for the resulting Adversarial ACAS X in differential game logic, collision-freedom is established for the rich encounters of ownship and intruder aircraft with independent decisions along differential equations for flight paths with evolving vertical/horizontal velocities. We present three classes of models of increasing complexity: single-advisory infinite-time models, bounded time models, and infinite time, multi-advisory models. Within each class of models, we identify symbolic conditions and prove that there then always is a possible ownship maneuver that will prevent a collision between the two aircraft.      
### 32.Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for End Usability  [ :arrow_down: ](https://arxiv.org/pdf/2106.02016.pdf)
>  Recent advances in supervised, semi-supervised and self-supervised deep learning algorithms have shown significant improvement in the performance of automatic speech recognition(ASR) systems. The state-of-the-art systems have achieved a word error rate (WER) less than 5%. However, in the past, researchers have argued the non-suitability of the WER metric for the evaluation of ASR systems for downstream tasks such as spoken language understanding (SLU) and information retrieval. The reason is that the WER works at the surface level and does not include any syntactic and semantic knowledge.The current work proposes Semantic-WER (SWER), a metric to evaluate the ASR transcripts for downstream applications in general. The SWER can be easily customized for any down-stream task.      
### 33.Unified Performance Analysis of Reconfigurable Intelligent Surface Empowered Free Space Optical Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.02000.pdf)
>  Reconfigurable intelligent surface (RIS) is an excellent use case for line-of-sight (LOS) based technologies such as free-space optical (FSO) communications. In this paper, we analyze the performance of RIS-empowered FSO (RISE-FSO) systems by unifying Fisher-Snedecor (F), Gamma-Gamma (GG), and Malaga (M) distributions for atmospheric turbulence with zero-boresight pointing errors over deterministic as well as random path-loss in foggy conditions with heterodyne detection (HD) and intensity modulation/direct detection (IM/DD) methods. By deriving the probability density function (PDF) and cumulative distribution function (CDF) of the direct-link (DL) with the statistical effect of atmospheric turbulence, pointing errors, and random fog, we develop exact expressions of PDF and CDF of the resultant channel for the RISE-FSO system. Using the derived statistical results, we present exact expressions of outage probability, average bit-error-rate (BER), ergodic capacity, and moments of signal-to-noise ratio (SNR) for both DL-FSO and RISE-FSO systems. We also develop an asymptotic analysis of the outage probability and average BER and derive the diversity order of the considered systems. We validate the analytical expressions using Monte-Carlo simulations and demonstrate the performance scaling of the FSO system with the number of RIS elements for various turbulence channels, detection techniques, and weather conditions.      
### 34.LyricJam: A system for generating lyrics for live instrumental music  [ :arrow_down: ](https://arxiv.org/pdf/2106.01960.pdf)
>  We describe a real-time system that receives a live audio stream from a jam session and generates lyric lines that are congruent with the live music being played. Two novel approaches are proposed to align the learned latent spaces of audio and text representations that allow the system to generate novel lyric lines matching live instrumental music. One approach is based on adversarial alignment of latent representations of audio and lyrics, while the other approach learns to transfer the topology from the music latent space to the lyric latent space. A user study with music artists using the system showed that the system was useful not only in lyric composition, but also encouraged the artists to improvise and find new musical expressions. Another user study demonstrated that users preferred the lines generated using the proposed methods to the lines generated by a baseline model.      
### 35.Short-term Maintenance Planning of Autonomous Trucks for Minimizing Economic Risk  [ :arrow_down: ](https://arxiv.org/pdf/2106.01871.pdf)
>  New autonomous driving technologies are emerging every day and some of them have been commercially applied in the real world. While benefiting from these technologies, autonomous trucks are facing new challenges in short-term maintenance planning, which directly influences the truck operator's profit. In this paper, we implement a vehicle health management system by addressing the maintenance planning issues of autonomous trucks on a transport mission. We also present a maintenance planning model using a risk-based decision-making method, which identifies the maintenance decision with minimal economic risk of the truck company. Both availability losses and maintenance costs are considered when evaluating the economic risk. We demonstrate the proposed model by numerical experiments illustrating real-world scenarios. In the experiments, compared to three baseline methods, the expected economic risk of the proposed method is reduced by up to $47\%$. We also conduct sensitivity analyses of different model parameters. The analyses show that the economic risk significantly decreases when the estimation accuracy of remaining useful life, the maximal allowed time of delivery delay before order cancellation, or the number of workshops increases. The experiment results contribute to identifying future research and development attentions of autonomous trucks from an economic perspective.      
### 36.Heart Sound Classification Considering Additive Noise and Convolutional Distortion  [ :arrow_down: ](https://arxiv.org/pdf/2106.01865.pdf)
>  Cardiac auscultation is an essential point-of-care method used for the early diagnosis of heart diseases. Automatic analysis of heart sounds for abnormality detection is faced with the challenges of additive noise and sensor-dependent degradation. This paper aims to develop methods to address the cardiac abnormality detection problem when both types of distortions are present in the cardiac auscultation sound. We first mathematically analyze the effect of additive and convolutional noise on short-term filterbank-based features and a Convolutional Neural Network (CNN) layer. Based on the analysis, we propose a combination of linear and logarithmic spectrogram-image features. These 2D features are provided as input to a residual CNN network (ResNet) for heart sound abnormality detection. Experimental validation is performed on an open-access heart sound abnormality detection dataset involving noisy recordings obtained from multiple stethoscope sensors. The proposed method achieves significantly improved results compared to the conventional approaches, with an area under the ROC (receiver operating characteristics) curve (AUC) of 91.36%, F-1 score of 84.09%, and Macc (mean of sensitivity and specificity) of 85.08%. We also show that the proposed method shows the best mean accuracy across different source domains including stethoscope and noise variability, demonstrating its effectiveness in different recording conditions. The proposed combination of linear and logarithmic features along with the ResNet classifier effectively minimizes the impact of background noise and sensor variability for classifying phonocardiogram (PCG) signals. The proposed method paves the way towards developing computer-aided cardiac auscultation systems in noisy environments using low-cost stethoscopes.      
### 37.Robust Reference-based Super-Resolution via C2-Matching  [ :arrow_down: ](https://arxiv.org/pdf/2106.01863.pdf)
>  Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising paradigm to enhance a low-resolution (LR) input image by introducing an additional high-resolution (HR) reference image. Existing Ref-SR methods mostly rely on implicit correspondence matching to borrow HR textures from reference images to compensate for the information loss in input images. However, performing local transfer is difficult because of two gaps between input and reference images: the transformation gap (e.g. scale and rotation) and the resolution gap (e.g. HR and LR). To tackle these challenges, we propose C2-Matching in this work, which produces explicit robust matching crossing transformation and resolution. 1) For the transformation gap, we propose a contrastive correspondence network, which learns transformation-robust correspondences using augmented views of the input image. 2) For the resolution gap, we adopt a teacher-student correlation distillation, which distills knowledge from the easier HR-HR matching to guide the more ambiguous LR-HR matching. 3) Finally, we design a dynamic aggregation module to address the potential misalignment issue. In addition, to faithfully evaluate the performance of Ref-SR under a realistic setting, we contribute the Webly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario. Extensive experiments demonstrate that our proposed C2-Matching significantly outperforms state of the arts by over 1dB on the standard CUFED5 benchmark. Notably, it also shows great generalizability on WR-SR dataset as well as robustness across large scale and rotation transformations.      
### 38.A Comparative Study of Convolutional Neural Networks for the Detection of Strong Gravitational Lensing  [ :arrow_down: ](https://arxiv.org/pdf/2106.01754.pdf)
>  As we enter the era of large-scale imaging surveys with the up-coming telescopes such as LSST and SKA, it is envisaged that the number of known strong gravitational lensing systems will increase dramatically. However, these events are still very rare and require the efficient processing of millions of images. In order to tackle this image processing problem, we present Machine Learning techniques and apply them to the Gravitational Lens Finding Challenge. The Convolutional Neural Networks (CNNs) presented have been re-implemented within a new modular, and extendable framework, LEXACTUM. We report an Area Under the Curve (AUC) of 0.9343 and 0.9870, and an execution time of 0.0061s and 0.0594s per image, for the Space and Ground datasets respectively, showing that the results obtained by CNNs are very competitive with conventional methods (such as visual inspection and arc finders) for detecting gravitational lenses.      
### 39.Lymph Node Graph Neural Networks for Cancer Metastasis Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2106.01711.pdf)
>  Predicting outcomes, such as survival or metastasis for individual cancer patients is a crucial component of precision oncology. Machine learning (ML) offers a promising way to exploit rich multi-modal data, including clinical information and imaging to learn predictors of disease trajectory and help inform clinical decision making. In this paper, we present a novel graph-based approach to incorporate imaging characteristics of existing cancer spread to local lymph nodes (LNs) as well as their connectivity patterns in a prognostic ML model. We trained an edge-gated Graph Convolutional Network (Gated-GCN) to accurately predict the risk of distant metastasis (DM) by propagating information across the LN graph with the aid of soft edge attention mechanism. In a cohort of 1570 head and neck cancer patients, the Gated-GCN achieves AUROC of 0.757 for 2-year DM classification and $C$-index of 0.725 for lifetime DM risk prediction, outperforming current prognostic factors as well as previous approaches based on aggregated LN features. We also explored the importance of graph structure and individual lymph nodes through ablation experiments and interpretability studies, highlighting the importance of considering individual LN characteristics as well as the relationships between regions of cancer spread.      
### 40.Language Independent Speech Emotion and Non-invasive Early Detection of Neurocognitive Disorder  [ :arrow_down: ](https://arxiv.org/pdf/2106.01684.pdf)
>  Emotions(like fear,anger,sadness,happiness etc.) are the fundamental features of human behavior and governs his/her mental health. The subtlety of emotional fluctuations can be examined through perturbation in conversations or speech. Analysis of emotional state of a person from acoustical features of speech signal leads to discovery of vital cues determining his or her mental health. Hence, it's an important field of research in the area of Human Computer Interaction(HCI). In a recent work we have shown that how the contrast in Hurst-Exponent calculated from the non-stationary and nonlinear aspects of "angry" and "sad" speech(spoken in English language) recordings in the Toronto-Emotional-Speech-Set(TESS) can be used for early detection and diagnosis of Alzheimer's Disease. In this work we have extended the work and extracted Hurst-exponent for the speech-signals of similar emotions but spoken in German language. It has been observed that the Hurst-exponent efficiently segregates the contrasting emotions of "anger" and "sadness" in the speech spoken in German language, in similar fashion it has been doing for English speech. Hence it can be concluded that the Hurst-exponent can differentiate among speech spoken out of different emotions in language-independent manner. We propose algorithm for a language-independent application for early non-invasive detection of various severe neurocognitive-disorders like Alzheimer's Disease, MND(motor-neuron-disorder), ASD(autism-spectrum-disorder), depression, suicidal-tendency etc. which is not possible with the state of the art medical science.      
### 41.ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.01621.pdf)
>  We present a new architecture of convolutional neural networks (CNNs) based on ResNet for audio pattern recognition tasks. The main modification is introducing a new hyper-parameter for decreasing temporal sizes of tensors with increased stride sizes which we call "the decreasing temporal size parameter". Optimal values of this parameter decrease the number of multi-adds that make the system faster. This approach not only decreases computational complexity but it can save and even increase (for the AudioSet dataset) the performance for audio pattern recognition tasks. This observation can be confirmed by experiments on three datasets: the AudioSet dataset, the ESC-50 dataset, and RAVDESS. Our best system achieves the state-of-the-art performance on the AudioSet dataset with mAP of 0.450. We also transfer a model pre-trained on the AudioSet dataset to the ESC-50 dataset and RAVDESS and obtain the state-of-the-art results with accuracies of 0.961 and 0.748, respectively. We call our system "ERANN" (Efficient Residual Audio Neural Network).      
### 42.Comparing Acoustic-based Approaches for Alzheimer's Disease Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.01555.pdf)
>  In this paper, we study the performance and generalizability of three approaches for AD detection from speech on the recent ADReSSo challenge dataset: 1) using conventional acoustic features 2) using novel pre-trained acoustic embeddings 3) combining acoustic features and embeddings. We find that while feature-based approaches have a higher precision, classification approaches relying on the combination of embeddings and features prove to have a higher, and more balanced performance across multiple metrics of performance. Our best model, using such a combined approach, outperforms the acoustic baseline in the challenge by 2.8\%.      
### 43.DeepCompress: Efficient Point Cloud Geometry Compression  [ :arrow_down: ](https://arxiv.org/pdf/2106.01504.pdf)
>  Point clouds are a basic data type that is increasingly of interest as 3D content becomes more ubiquitous. Applications using point clouds include virtual, augmented, and mixed reality and autonomous driving. We propose a more efficient deep learning-based encoder architecture for point clouds compression that incorporates principles from established 3D object detection and image compression architectures. Through an ablation study, we show that incorporating the learned activation function from Computational Efficient Neural Image Compression (CENIC) and designing more parameter-efficient convolutional blocks yields dramatic gains in efficiency and performance. Our proposed architecture incorporates Generalized Divisive Normalization activations and propose a spatially separable InceptionV4-inspired block. We then evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized Full Bodies dataset to evaluate our model's performance. Our proposed modifications outperform the baseline approaches by a small margin in terms of Bjontegard delta rate and PSNR values, yet reduces necessary encoder convolution operations by 8 percent and reduces total encoder parameters by 20 percent. Our proposed architecture, when considered on its own, has a small penalty of 0.02 percent in Chamfer's Distance and 0.32 percent increased bit rate in Point to Plane Distance for the same peak signal-to-noise ratio.      
### 44.NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and Results  [ :arrow_down: ](https://arxiv.org/pdf/2106.01439.pdf)
>  This paper reviews the first challenge on high-dynamic range (HDR) imaging that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop, held in conjunction with CVPR 2021. This manuscript focuses on the newly introduced dataset, the proposed methods and their results. The challenge aims at estimating a HDR image from one or multiple respective low-dynamic range (LDR) observations, which might suffer from under- or over-exposed regions and different sources of noise. The challenge is composed by two tracks: In Track 1 only a single LDR image is provided as input, whereas in Track 2 three differently-exposed LDR images with inter-frame motion are available. In both tracks, the ultimate goal is to achieve the best objective HDR reconstruction in terms of PSNR with respect to a ground-truth image, evaluated both directly and with a canonical tonemapping operation.      
### 45.A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2106.01415.pdf)
>  We propose a new paradigm for maintaining speaker identity in dysarthric voice conversion (DVC). The poor quality of dysarthric speech can be greatly improved by statistical VC, but as the normal speech utterances of a dysarthria patient are nearly impossible to collect, previous work failed to recover the individuality of the patient. In light of this, we suggest a novel, two-stage approach for DVC, which is highly flexible in that no normal speech of the patient is required. First, a powerful parallel sequence-to-sequence model converts the input dysarthric speech into a normal speech of a reference speaker as an intermediate product, and a nonparallel, frame-wise VC model realized with a variational autoencoder then converts the speaker identity of the reference speech back to that of the patient while assumed to be capable of preserving the enhanced quality. We investigate several design options. Experimental evaluation results demonstrate the potential of our approach to improving the quality of the dysarthric speech while maintaining the speaker identity.      

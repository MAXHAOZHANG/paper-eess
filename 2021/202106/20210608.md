# ArXiv eess --Tue, 8 Jun 2021
### 1.Pointwise visual field estimation from optical coherence tomography in glaucoma: a structure-function analysis using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.03793.pdf)
>  Background/Aims: Standard Automated Perimetry (SAP) is the gold standard to monitor visual field (VF) loss in glaucoma management, but is prone to intra-subject variability. We developed and validated a deep learning (DL) regression model that estimates pointwise and overall VF loss from unsegmented optical coherence tomography (OCT) scans. Methods: Eight DL regression models were trained with various retinal imaging modalities: circumpapillary OCT at 3.5mm, 4.1mm, 4.7mm diameter, and scanning laser ophthalmoscopy (SLO) en face images to estimate mean deviation (MD) and 52 threshold values. This retrospective study used data from patients who underwent a complete glaucoma examination, including a reliable Humphrey Field Analyzer (HFA) 24-2 SITA Standard VF exam and a SPECTRALIS OCT scan using the Glaucoma Module Premium Edition. Results: A total of 1378 matched OCT-VF pairs of 496 patients (863 eyes) were included for training and evaluation of the DL models. Average sample MD was -7.53dB (from -33.8dB to +2.0dB). For 52 VF threshold values estimation, the circumpapillary OCT scan with the largest radius (4.7mm) achieved the best performance among all individual models (Pearson r=0.77, 95% CI=[0.72-0.82]). For MD, prediction averaging of OCT-trained models (3.5mm, 4.1mm, 4.7mm) resulted in a Pearson r of 0.78 [0.73-0.83] on the validation set and comparable performance on the test set (Pearson r=0.79 [0.75-0.82]). Conclusion: DL on unsegmented OCT scans accurately predicts pointwise and mean deviation of 24-2 VF in glaucoma patients. Automated VF from unsegmented OCT could be a solution for patients unable to produce reliable perimetry results.      
### 2.Deep Neural Network-based Enhancement for Image and Video Streaming Systems: A Survey and Future Directions  [ :arrow_down: ](https://arxiv.org/pdf/2106.03727.pdf)
>  Internet-enabled smartphones and ultra-wide displays are transforming a variety of visual apps spanning from on-demand movies and 360Â° videos to video-conferencing and live streaming. However, robustly delivering visual content under fluctuating networking conditions on devices of diverse capabilities remains an open problem. In recent years, advances in the field of deep learning on tasks such as super-resolution and image enhancement have led to unprecedented performance in generating high-quality images from low-quality ones, a process we refer to as neural enhancement. In this paper, we survey state-of-the-art content delivery systems that employ neural enhancement as a key component in achieving both fast response time and high visual quality. We first present the components and architecture of existing content delivery systems, highlighting their challenges and motivating the use of neural enhancement models as a countermeasure. We then cover the deployment challenges of these models and analyze existing systems and their design decisions in efficiently overcoming these technical challenges. Additionally, we underline the key trends and common approaches across systems that target diverse use-cases. Finally, we present promising future directions based on the latest insights from deep learning research to further boost the quality of experience of content delivery systems.      
### 3.Synthesis of standard 12-lead electrocardiograms using two dimensional generative adversarial network  [ :arrow_down: ](https://arxiv.org/pdf/2106.03701.pdf)
>  This paper proposes a two-dimensional (2D) bidirectional long short-term memory generative adversarial network (GAN) to produce synthetic standard 12-lead ECGs corresponding to four types of signals: left ventricular hypertrophy (LVH), left branch bundle block (LBBB), acute myocardial infarction (ACUTMI), and Normal. It uses a fully automatic end-to-end process to generate and verify the synthetic ECGs that does not require any visual inspection. The proposed model is able to produce synthetic standard 12-lead ECG signals with success rates of 98% for LVH, 93% for LBBB, 79% for ACUTMI, and 59% for Normal. Statistical evaluation of the data confirms that the synthetic ECGs are not biased towards or overfitted to the training ECGs, and span a wide range of morphological features. This study demonstrates that it is feasible to use a 2D GAN to produce standard 12-lead ECGs suitable to augment artificially a diverse database of real ECGs, thus providing a possible solution to the demand for extensive ECG datasets.      
### 4.Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2106.03686.pdf)
>  We address the detection of material defects, which are inside a layered material structure using compressive sensing based multiple-output (MIMO) wireless radar. Here, the strong clutter due to the reflection of the layered structure's surface often makes the detection of the defects challenging. Thus, sophisticated signal separation methods are required for improved defect detection. In many scenarios, the number of defects that we are interested in is limited and the signaling response of the layered structure can be modeled as a low-rank structure. Therefore, we propose joint rank and sparsity minimization for defect detection. In particular, we propose a non-convex approach based on the iteratively reweighted nuclear and $\ell_1-$norm (a double-reweighted approach) to obtain a higher accuracy compared to the conventional nuclear norm and $\ell_1-$norm minimization. To this end, an iterative algorithm is designed to estimate the low-rank and sparse contributions. Further, we propose deep learning to learn the parameters of the algorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of convergence of the algorithm. Our numerical results show that the proposed approach outperforms the conventional approaches in terms of mean square errors of the recovered low-rank and sparse components and the speed of convergence.      
### 5.Unsupervised Clustered Federated Learning in Complex Multi-source Acoustic Environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.03671.pdf)
>  In this paper we introduce a realistic and challenging, multi-source and multi-room acoustic environment and an improved algorithm for the estimation of source-dominated microphone clusters in acoustic sensor networks. Our proposed clustering method is based on a single microphone per node and on unsupervised clustered federated learning which employs a light-weight autoencoder model. We present an improved clustering control strategy that takes into account the variability of the acoustic scene and allows the estimation of a dynamic range of clusters using reduced amounts of training data. The proposed approach is optimized using clustering-based measures and validated via a network-wide classification task.      
### 6.Minimum Norm Method for Linear and Planar Sparse Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2106.03666.pdf)
>  Coprime and nested arrays are sparse arrays with enhanced degrees of freedom, which can be exploited in direction of arrival estimation using algorithms such as product processing, min processing, and MUSIC. This paper applies the minimum norm method for direction of arrival estimation. Comparison of the root mean squared errors and probabilities of resolution of the minimum norm method with MUSIC for a given linear coprime or nested array demonstrates the superiority of the minimum norm method. Specifically, minimum norm method exhibits lower mean squared error, narrower peaks at the locations of the true sources, and a lower noise floor in the spatial spectral estimate. This work also formulates two different minimum norm methods for planar sparse arrays: direct and linear. Comparison of the linear minimum norm method with the linear MUSIC for planar arrays also demonstrates higher accuracy of the minimum norm method.      
### 7.Product Processing for Tapered Sparse Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2106.03653.pdf)
>  The product processor output has recently been introduced as a spatial power spectral density estimate, unifying product arrays such as coprime arrays, nested arrays, and standard uniform line arrays. The expected value and covariance function of this estimate for a white Gaussian process was derived in previous work over these various array configurations. However, this prior work used a uniform taper in all cases. In this paper, we show that when product arrays are windowed with non-uniform tapers, the expected value of the product processor output is the convolution of the true spatial power spectral density with the spatial Fourier transform of the difference coarray. This expected value makes a Fourier transform pair with a spatial autocorrelation estimate obtained by windowing the true autocorrelation function. We also derive the covariance function of the product processor output with non-uniform tapers, and compare these derived statistics for the aforementioned array geometries. Also, in prior work, the moments were provided only for linear arrays; this paper extends the estimation results to multidimensional arrays.      
### 8.Absolute Eigenvalues-Based Covariance Matrix Estimation for a Sparse Array  [ :arrow_down: ](https://arxiv.org/pdf/2106.03642.pdf)
>  The ensemble covariance matrix of a wide sense stationary signal spatially sampled by a full linear array is positive semi-definite and Toeplitz. However, the direct augmented covariance matrix of an augmentable sparse array is Toeplitz but not positive semi-definite, resulting in negative eigenvalues that pose inherent challenges in its applications, including model order estimation and source localization. The positive eigenvalues-based covariance matrix for augmentable sparse arrays is robust but the matrix is unobtainable when all noise eigenvalues of the direct augmented matrix are negative, which is a possible case. To address this problem, we propose a robust covariance matrix for augmentable sparse arrays that leverages both positive and negative noise eigenvalues. The proposed covariance matrix estimate can be used in conjunction with subspace based algorithms and adaptive beamformers to yield accurate signal direction estimates.      
### 9.Multi-agent Battery Storage Management using MPC-based Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.03541.pdf)
>  In this paper, we present the use of Model Predictive Control (MPC) based on Reinforcement Learning (RL) to find the optimal policy for a multi-agent battery storage system. A time-varying prediction of the power price and production-demand uncertainty are considered. We focus on optimizing an economic objective cost while avoiding very low or very high state of charge, which can damage the battery. We consider the bounded power provided by the main grid and the constraints on the power input and state of each agent. A parametrized MPC-scheme is used as a function approximator for the deterministic policy gradient method and RL optimizes the closed-loop performance by updating the parameters. Simulation results demonstrate that the proposed method is able to tackle the constraints and deliver the optimal policy.      
### 10.Performance assessment of Synchronous Condensers vs Voltage Source Converters providing grid-forming functions  [ :arrow_down: ](https://arxiv.org/pdf/2106.03536.pdf)
>  Having sufficient grid-forming sources is one of the necessary conditions to guarantee the stability in a power system hosting a very large share of inverter-based generation. The grid-forming function has been historically fulfilled by synchronous machines. However, with the appropriate control, it can also be provided by voltage source converters (VSC). This work presents a comparison between two technologies with grid-forming capability: the VSC with a grid-forming control coupled with an adequate energy storage system, and the synchronous condensers (SC). Both devices are compared regarding their inertial response, as well as their contribution to the system strength and short-circuit current for an equivalent capacity expressed in terms of apparent power and inertial reserve. Their behaviour following grid disturbances is assessed through time-domain simulations based on detailed electromagnetic transient (EMT) models. The results show that both devices achieve similar performance in the time-scale of seconds. For shorter time-windows, however, they present a different behavior: the SC ensures a better stiffness in the first tens of ms following the disturbance, while the VSC offers a faster resynchronization.      
### 11.Closed-Loop Wireless Power Transfer with Adaptive Waveform and Beamforming: Design, Prototype, and Experiment  [ :arrow_down: ](https://arxiv.org/pdf/2106.03519.pdf)
>  In this paper, we design, prototype, and experiment a closed-loop radiative wireless power transfer (WPT) system with adaptive waveform and beamforming using limited feedback. Spatial and frequency domains are exploited by jointly utilizing multi-sine waveform and multi-antenna beamforming at the transmitter in WPT system to adapt to the multipath fading channel and boost the output dc power. A closed-loop architecture based on a codebook design and a low complexity over-the-air limited feedback using an IEEE 802.15.4 RF interface is proposed. The codebook consists of multiple codewords where each codeword represents particular waveform and beamforming. The transmitter sweeps through the codebook and then the receiver feeds back the index of the optimal codeword, so that the waveform and beamforming can be adapted to the multipath fading channel to maximize the output dc power without requiring explicit channel estimation and the knowledge of accurate Channel State Information. The proposed closed-loop WPT with adaptive waveform and beamforming using limited feedback is prototyped using a Software Defined Radio equipment and measured in a real indoor environment. The measurement results show that the proposed closed-loop WPT with adaptive waveform and beamforming can increase the output dc power by up to 14.7 dB compared with the conventional single-tone and single-antenna WPT system.      
### 12.Task-driven Semantic Coding via Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.03511.pdf)
>  Task-driven semantic video/image coding has drawn considerable attention with the development of intelligent media applications, such as license plate detection, face detection, and medical diagnosis, which focuses on maintaining the semantic information of videos/images. Deep neural network (DNN)-based codecs have been studied for this purpose due to their inherent end-to-end optimization mechanism. However, the traditional hybrid coding framework cannot be optimized in an end-to-end manner, which makes task-driven semantic fidelity metric unable to be automatically integrated into the rate-distortion optimization process. Therefore, it is still attractive and challenging to implement task-driven semantic coding with the traditional hybrid coding framework, which should still be widely used in practical industry for a long time. To solve this challenge, we design semantic maps for different tasks to extract the pixelwise semantic fidelity for videos/images. Instead of directly integrating the semantic fidelity metric into traditional hybrid coding framework, we implement task-driven semantic coding by implementing semantic bit allocation based on reinforcement learning (RL). We formulate the semantic bit allocation problem as a Markov decision process (MDP) and utilize one RL agent to automatically determine the quantization parameters (QPs) for different coding units (CUs) according to the task-driven semantic fidelity metric. Extensive experiments on different tasks, such as classification, detection and segmentation, have demonstrated the superior performance of our approach by achieving an average bitrate saving of 34.39% to 52.62% over the High Efficiency Video Coding (H.265/HEVC) anchor under equivalent task-related semantic fidelity.      
### 13.Set-Estimation based Networked Model Predictive Control for Energy Management of Faulty Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2106.03501.pdf)
>  This paper addresses the issue of power flow control for partially faulty microgrids. In microgrid control systems, faults may occur in both electrical and communication layers. This may have severe effects on the operation of microgrids. In addition, disturbances always coexist with faults in microgrids, which may further deteriorate system performance. To address the faults and disturbances simultaneously, a model predictive control (MPC) method based on set-membership estimation (SME) that transmits information via a communication network is proposed. When electrical devices are nonfunctional or communication failures occur, the corresponding system states will become unavailable. To this end, the SME method is employed to estimate the states with the existence of unknown-but-bounded process and measurement disturbances. The networked MPC method is designed to schedule the power dispatch by using the forecasts of photovoltaic (PV) generation and load demand. With these two methods, the fault-tolerant control can be achieved. Further, a deviation compensation method is proposed to compensate for the forecast errors. The effectiveness of the proposed control strategy is demonstrated through wireless communication tests using Raspberry Pis.      
### 14.Configuring an Intelligent Reflecting Surface for Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.03497.pdf)
>  The IEEE Signal Processing Society is proud to announce the eighth edition of the Signal Processing Cup: an exciting challenge to control a wireless propagation environment using an intelligent reflecting surface. <br>An intelligent reflecting surface is a two-dimensional array of metamaterial whose interaction with electromagnetic waves can be controlled, e.g., by tuning the impedance variations over the surface. These surfaces might be used in the sixth generation (6G) mobile technology to direct wireless signals from a transmitter towards a receiver, to raise the communication performance. The goal of the challenge is to characterize the behavior of an intelligent reflecting surface based on received signals from an over-the-air signaling phase and develop a control algorithm to configure the surface to aid wireless communications.      
### 15.Weakly-supervised word-level pronunciation error detection in non-native English speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.03494.pdf)
>  We propose a weakly-supervised model for word-level mispronunciation detection in non-native (L2) English speech. To train this model, phonetically transcribed L2 speech is not required and we only need to mark mispronounced words. The lack of phonetic transcriptions for L2 speech means that the model has to learn only from a weak signal of word-level mispronunciations. Because of that and due to the limited amount of mispronounced L2 speech, the model is more likely to overfit. To limit this risk, we train it in a multi-task setup. In the first task, we estimate the probabilities of word-level mispronunciation. For the second task, we use a phoneme recognizer trained on phonetically transcribed L1 speech that is easily accessible and can be automatically annotated. Compared to state-of-the-art approaches, we improve the accuracy of detecting word-level pronunciation errors in AUC metric by 30% on the GUT Isle Corpus of L2 Polish speakers, and by 21.5% on the Isle Corpus of L2 German and Italian speakers.      
### 16.Knowledge-aware Deep Framework for Collaborative Skin Lesion Segmentation and Melanoma Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.03455.pdf)
>  Deep learning techniques have shown their superior performance in dermatologist clinical inspection. Nevertheless, melanoma diagnosis is still a challenging task due to the difficulty of incorporating the useful dermatologist clinical knowledge into the learning process. In this paper, we propose a novel knowledge-aware deep framework that incorporates some clinical knowledge into collaborative learning of two important melanoma diagnosis tasks, i.e., skin lesion segmentation and melanoma recognition. Specifically, to exploit the knowledge of morphological expressions of the lesion region and also the periphery region for melanoma identification, a lesion-based pooling and shape extraction (LPSE) scheme is designed, which transfers the structure information obtained from skin lesion segmentation into melanoma recognition. Meanwhile, to pass the skin lesion diagnosis knowledge from melanoma recognition to skin lesion segmentation, an effective diagnosis guided feature fusion (DGFF) strategy is designed. Moreover, we propose a recursive mutual learning mechanism that further promotes the inter-task cooperation, and thus iteratively improves the joint learning capability of the model for both skin lesion segmentation and melanoma recognition. Experimental results on two publicly available skin lesion datasets show the effectiveness of the proposed method for melanoma analysis.      
### 17.Data Augmentation Methods for End-to-end Speech Recognition on Distant-Talk Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2106.03419.pdf)
>  Although end-to-end automatic speech recognition (E2E ASR) has achieved great performance in tasks that have numerous paired data, it is still challenging to make E2E ASR robust against noisy and low-resource conditions. In this study, we investigated data augmentation methods for E2E ASR in distant-talk scenarios. E2E ASR models are trained on the series of CHiME challenge datasets, which are suitable tasks for studying robustness against noisy and spontaneous speech. We propose to use three augmentation methods and thier combinations: 1) data augmentation using text-to-speech (TTS) data, 2) cycle-consistent generative adversarial network (Cycle-GAN) augmentation trained to map two different audio characteristics, the one of clean speech and of noisy recordings, to match the testing condition, and 3) pseudo-label augmentation provided by the pretrained ASR module for smoothing label distributions. Experimental results using the CHiME-6/CHiME-4 datasets show that each augmentation method individually improves the accuracy on top of the conventional SpecAugment; further improvements are obtained by combining these approaches. We achieved 4.3\% word error rate (WER) reduction, which was more significant than that of the SpecAugment, when we combine all three augmentations for the CHiME-6 task.      
### 18.Effect of Adaptive and Fixed Shared Steering Control on Distracted Driver Behavior  [ :arrow_down: ](https://arxiv.org/pdf/2106.03364.pdf)
>  Driver distraction is a well-known cause for traffic collisions worldwide. Studies have indicated that shared steering control, which actively provides haptic guidance torque on the steering wheel, effectively improves the performance of distracted drivers. Recently, adaptive shared steering control based on the physiological status of the driver has been developed, although its effect on distracted driver behavior remains unclear. To this end, a high-fidelity driving simulator experiment was conducted involving 18 participants performing double lane changes. The experimental conditions comprised two driver states: attentive and distracted. Under each condition, evaluations were performed on three types of haptic guidance: none (manual), fixed authority, and adaptive authority based on feedback from the forearm surface electromyography of the driver. Evaluation results indicated that, for both attentive and distracted drivers, haptic guidance with adaptive authority yielded lower driver workload and reduced lane departure risk than manual driving and fixed authority. Moreover, there was a tendency for distracted drivers to reduce grip strength on the steering wheel to follow the haptic guidance with fixed authority, resulting in a relatively shorter double lane change duration.      
### 19.Improved Method for Dealing with Discontinuities in Power System Transient Simulation Based on Frequency Response Optimized Integrators Considering Second Order Derivative  [ :arrow_down: ](https://arxiv.org/pdf/2106.03329.pdf)
>  Potential disagreement in the result induced by discontinuities is revealed in this paper between a novel power system transient simulation scheme using numerical integrators considering second order derivative and conventional ones using numerical integrators considering first order derivative. The disagreement is due to the formula of the different numerical integrators. An improved method for dealing with discontinuities in the novel transient simulation scheme is proposed to resolve the disagreement. The effectiveness of the improved method is demonstrated and verified via numerical case studies. Although the disagreement is studied on and the improved method is proposed for a particular transient simulation scheme, similar conclusions also apply to other ones using numerical integrators considering high order derivative.      
### 20.Data-Driven Adaptive Network Slicing for Multi-Tenant Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.03282.pdf)
>  Network slicing to support multi-tenancy plays a key role in improving the performance of 5G networks. In this paper, we propose a two time-scale framework for the reservation-based network slicing in the backhaul and Radio Access Network (RAN). In the proposed two time-scale scheme, a subset of network slices is activated via a novel sparse optimization framework in the long time-scale with the goal of maximizing the expected utilities of tenants while in the short time-scale the activated slices are reconfigured according to the time-varying user traffic and channel states. Specifically, using the statistics from users and channels and also considering the expected utility from serving users of a slice and the reconfiguration cost, we formulate a sparse optimization problem to update the configuration of a slice resources such that the maximum isolation of reserved resources is enforced. The formulated optimization problems for long and short time-scales are non-convex and difficult to solve. We use the $\ell_q$-norm, $0&lt;q&lt;1$, and group LASSO regularizations to iteratively find convex approximations of the optimization problems. We propose a Frank-Wolfe algorithm to iteratively solve approximated problems in long time-scales. To cope with the dynamical nature of traffic variations, we propose a fast, distributed algorithm to solve the approximated optimization problems in short time-scales. Simulation results demonstrate the performance of our approaches relative to optimal solutions and the existing state of the art method.      
### 21.Power System Transient Modeling and Simulation using Integrated Circuit  [ :arrow_down: ](https://arxiv.org/pdf/2106.03254.pdf)
>  Transient stability analysis (TSA) plays an important role in power system analysis to investigate the stability of power system. Traditionally, transient stability analysis methods have been developed using time domain simulation by means of numerical integration method. In this paper, a new approach is proposed to model power systems as an integrated circuit and simulate the power system dynamic behavior by integrated circuit simulator. The proposed method modeled power grid, generator, governor, and exciter with high fidelity. The power system dynamic simulation accuracy and efficiency of the proposed approach are verified and demonstrated by case study on an IEEE standard system.      
### 22.Verification in the Loop: Correct-by-Construction Control Learning with Reach-avoid Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2106.03245.pdf)
>  In the current control design of safety-critical autonomous systems, formal verification techniques are typically applied after the controller is designed to evaluate whether the required properties (e.g., safety) are satisfied. However, due to the increasing system complexity and the fundamental hardness of designing a controller with formal guarantees, such an open-loop process of design-then-verify often results in many iterations and fails to provide the necessary guarantees. In this paper, we propose a correct-by-construction control learning framework that integrates the verification into the control design process in a closed-loop manner, i.e., design-while-verify. Specifically, we leverage the verification results (computed reachable set of the system state) to construct feedback metrics for control learning, which measure how likely the current design of control parameters can meet the required reach-avoid property for safety and goal-reaching. We formulate an optimization problem based on such metrics for tuning the controller parameters, and develop an approximated gradient descent algorithm with a difference method to solve the optimization problem and learn the controller. The learned controller is formally guaranteed to meet the required reach-avoid property. By treating verifiability as a first-class objective and effectively leveraging the verification results during the control learning process, our approach can significantly improve the chance of finding a control design with formal property guarantees. This is demonstrated via a set of experiments on both linear and non-linear systems that use model-based or neural network based controllers.      
### 23.Constrained Ellipse Fitting for Efficient Parameter Mapping with Phase-cycled bSSFP MRI  [ :arrow_down: ](https://arxiv.org/pdf/2106.03239.pdf)
>  Balanced steady-state free precession (bSSFP) imaging enables high scan efficiency in MRI, but differs from conventional sequences in terms of elevated sensitivity to main field inhomogeneity and nonstandard T2/T1-weighted tissue contrast. To address these limitations, multiple bSSFP images of the same anatomy are commonly acquired with a set of different RF phase-cycling increments. Joint processing of phase-cycled acquisitions serves to mitigate sensitivity to field inhomogeneity. Recently phase-cycled bSSFP acquisitions were also leveraged to estimate relaxation parameters based on explicit signal models. While effective, these model-based methods often involve a large number of acquisitions (N~10-16), degrading scan efficiency. Here, we propose a new constrained ellipse fitting method (CELF) for parameter estimation with improved efficiency and accuracy in phase-cycled bSSFP MRI. CELF is based on the elliptical signal model framework for complex bSSFP signals; and it introduces geometrical constraints on ellipse properties to improve estimation efficiency, and dictionary-based identification to improve estimation accuracy. Simulated, phantom and in vivo experiments demonstrate that the proposed method enables enhanced parameter estimation with as few as N=4 acquisitions, thus it holds great potential for improving utility of bSSFP-based parametric mapping.      
### 24.Deep Learning-based Type Identification of Volumetric MRI Sequences  [ :arrow_down: ](https://arxiv.org/pdf/2106.03208.pdf)
>  The analysis of Magnetic Resonance Imaging (MRI) sequences enables clinical professionals to monitor the progression of a brain tumor. As the interest for automatizing brain volume MRI analysis increases, it becomes convenient to have each sequence well identified. However, the unstandardized naming of MRI sequences makes their identification difficult for automated systems, as well as makes it difficult for researches to generate or use datasets for machine learning research. In the face of that, we propose a system for identifying types of brain MRI sequences based on deep learning. By training a Convolutional Neural Network (CNN) based on 18-layer ResNet architecture, our system can classify a volumetric brain MRI as a FLAIR, T1, T1c or T2 sequence, or whether it does not belong to any of these classes. The network was evaluated on publicly available datasets comprising both, pre-processed (BraTS dataset) and non-pre-processed (TCGA-GBM dataset), image types with diverse acquisition protocols, requiring only a few slices of the volume for training. Our system can classify among sequence types with an accuracy of 96.81%.      
### 25.Mathematical Vocoder Algorithm : Modified Spectral Inversion for Efficient Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.03167.pdf)
>  In this work, we propose a new mathematical vocoder algorithm(modified spectral inversion) that generates a waveform from acoustic features without phase estimation. The main benefit of using our proposed method is that it excludes the training stage of the neural vocoder from the end-to-end speech synthesis model. Our implementation can synthesize high fidelity speech at approximately 20 Mhz on CPU and 59.6MHz on GPU. This is 909 and 2,702 times faster compared to real-time. Since the proposed methodology is not a data-driven method, it is applicable to unseen voices and multiple languages without any additional work. The proposed method is expected to adapt for researching on neural network models capable of synthesizing speech at the studio recording level.      
### 26.Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation  [ :arrow_down: ](https://arxiv.org/pdf/2106.03153.pdf)
>  With rapid progress in neural text-to-speech (TTS) models, personalized speech generation is now in high demand for many applications. For practical applicability, a TTS model should generate high-quality speech with only a few audio samples from the given speaker, that are also short in length. However, existing methods either require to fine-tune the model or achieve low adaptation quality without fine-tuning. In this work, we propose StyleSpeech, a new TTS model which not only synthesizes high-quality speech but also effectively adapts to new speakers. Specifically, we propose Style-Adaptive Layer Normalization (SALN) which aligns gain and bias of the text input according to the style extracted from a reference speech audio. With SALN, our model effectively synthesizes speech in the style of the target speaker even from single speech audio. Furthermore, to enhance StyleSpeech's adaptation to speech from new speakers, we extend it to Meta-StyleSpeech by introducing two discriminators trained with style prototypes, and performing episodic training. The experimental results show that our models generate high-quality speech which accurately follows the speaker's voice with single short-duration (1-3 sec) speech audio, significantly outperforming baselines.      
### 27.3D UAV Trajectory and Data Collection Optimisation via Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.03129.pdf)
>  Unmanned aerial vehicles (UAVs) are now beginning to be deployed for enhancing the network performance and coverage in wireless communication. However, due to the limitation of their on-board power and flight time, it is challenging to obtain an optimal resource allocation scheme for the UAV-assisted Internet of Things (IoT). In this paper, we design a new UAV-assisted IoT systems relying on the shortest flight path of the UAVs while maximising the amount of data collected from IoT devices. Then, a deep reinforcement learning-based technique is conceived for finding the optimal trajectory and throughput in a specific coverage area. After training, the UAV has the ability to autonomously collect all the data from user nodes at a significant total sum-rate improvement while minimising the associated resources used. Numerical results are provided to highlight how our techniques strike a balance between the throughput attained, trajectory, and the time spent. More explicitly, we characterise the attainable performance in terms of the UAV trajectory, the expected reward and the total sum-rate.      
### 28.Deep Unsupervised Learning for Joint Antenna Selection and Hybrid Beamforming  [ :arrow_down: ](https://arxiv.org/pdf/2106.03127.pdf)
>  In this paper, we consider a massive multiple-input-multiple-output (MIMO) downlink system that improves the hardware efficiency by dynamically selecting the antenna subarray and utilizing 1-bit phase shifters for hybrid beamforming. To maximize the spectral efficiency, we propose a novel deep unsupervised learning-based approach that avoids the computationally prohibitive process of acquiring training labels. The proposed design has its input as the channel matrix and consists of two convolutional neural networks (CNNs). To enable unsupervised training, the problem constraints are embedded in the neural networks: the first CNN adopts deep probabilistic sampling, while the second CNN features a quantization layer designed for 1-bit phase shifters. The two networks can be trained jointly without labels by sharing an unsupervised loss function. We next propose a phased training approach to promote the convergence of the proposed networks. Simulation results demonstrate the advantage of the proposed approach over conventional optimization-based algorithms in terms of both achieved rate and computational complexity.      
### 29.Improving Channel Decorrelation for Multi-Channel Target Speech Extraction  [ :arrow_down: ](https://arxiv.org/pdf/2106.03113.pdf)
>  Target speech extraction has attracted widespread attention. When microphone arrays are available, the additional spatial information can be helpful in extracting the target speech. We have recently proposed a channel decorrelation (CD) mechanism to extract the inter-channel differential information to enhance the reference channel encoder representation. Although the proposed mechanism has shown promising results for extracting the target speech from mixtures, the extraction performance is still limited by the nature of the original decorrelation theory. In this paper, we propose two methods to broaden the horizon of the original channel decorrelation, by replacing the original softmax-based inter-channel similarity between encoder representations, using an unrolled probability and a normalized cosine-based similarity at the dimensional-level. Moreover, new combination strategies of the CD-based spatial information and target speaker adaptation of parallel encoder outputs are also investigated. Experiments on the reverberant WSJ0 2-mix show that the improved CD can result in more discriminative differential information and the new adaptation strategy is also very effective to improve the target speech extraction.      
### 30.Efficient Secure State Estimation against Sparse Integrity Attack for System with Non-derogatory Dynamics  [ :arrow_down: ](https://arxiv.org/pdf/2106.03066.pdf)
>  We consider the problem of estimating the state of a time-invariant linear Gaussian system in the presence of integrity attacks. The attacker can compromise $p$ out of $m$ sensors, the set of which is fixed over time and unknown to the system operator, and manipulate the measurements arbitrarily. Under the assumption that all the unstable eigenvalues of system matrix $A$ have geometric multiplicity 1 (unstable part of $A$ is non-derogatory), we propose a secure estimation scheme that is resilient to integrity attack as long as the system is $2p$-sparse detectable, which is proved to be the fundamental limit of secure dynamic estimation. In the absence of attack, the proposed estimation coincides with Kalman estimation with a certain probability that can be adjusted to trade-off between performance with and without attack. Furthermore, the detectability condition checking in the designing phase and the estimation computing in the online operating phase are both computationally efficient. A numerical example is provided to corroborate the results and illustrate the performance of the proposed estimator.      
### 31.Brain Age Estimation From MRI Using Cascade Networks with Ranking Loss  [ :arrow_down: ](https://arxiv.org/pdf/2106.03052.pdf)
>  Chronological age of healthy people is able to be predicted accurately using deep neural networks from neuroimaging data, and the predicted brain age could serve as a biomarker for detecting aging-related diseases. In this paper, a novel 3D convolutional network, called two-stage-age-network (TSAN), is proposed to estimate brain age from T1-weighted MRI data. Compared with existing methods, TSAN has the following improvements. First, TSAN uses a two-stage cascade network architecture, where the first-stage network estimates a rough brain age, then the second-stage network estimates the brain age more accurately from the discretized brain age by the first-stage network. Second, to our knowledge, TSAN is the first work to apply novel ranking losses in brain age estimation, together with the traditional mean square error (MSE) loss. Third, densely connected paths are used to combine feature maps with different scales. The experiments with $6586$ MRIs showed that TSAN could provide accurate brain age estimation, yielding mean absolute error (MAE) of $2.428$ and Pearson's correlation coefficient (PCC) of $0.985$, between the estimated and chronological ages. Furthermore, using the brain age gap between brain age and chronological age as a biomarker, Alzheimer's disease (AD) and Mild Cognitive Impairment (MCI) can be distinguished from healthy control (HC) subjects by support vector machine (SVM). Classification AUC in AD/HC and MCI/HC was $0.904$ and $0.823$, respectively. It showed that brain age gap is an effective biomarker associated with risk of dementia, and has potential for early-stage dementia risk screening. The codes and trained models have been released on GitHub: <a class="link-external link-https" href="https://github.com/Milan-BUAA/TSAN-brain-age-estimation" rel="external noopener nofollow">this https URL</a>.      
### 32.RTNeural: Fast Neural Inferencing for Real-Time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.03037.pdf)
>  RTNeural is a neural inferencing library written in C++. RTNeural is designed to be used in systems with hard real-time constraints, with additional emphasis on speed, flexibility, size, and convenience. The motivation and design of the library are described, as well as real-world use-cases, and performance comparisons with other neural inferencing libraries.      
### 33.Machine Learning Based Anxiety Detection in Older Adults using Wristband Sensors and Context Feature  [ :arrow_down: ](https://arxiv.org/pdf/2106.03019.pdf)
>  This paper explores a novel method for anxiety detection in older adults using simple wristband sensors such as Electrodermal Activity (EDA) and Photoplethysmogram (PPG) and a context-based feature. The proposed method for anxiety detection combines features from a single physiological signal with an experimental context-based feature to improve the performance of the anxiety detection model. The experimental data for this work is obtained from a year-long experiment on 41 healthy older adults (26 females and 15 males) in the age range 60-80 with mean age 73.36+-5.25 during a Trier Social Stress Test (TSST) protocol. The anxiety level ground truth was obtained from State-Trait Anxiety Inventory (STAI), which is regarded as the gold standard to measure perceived anxiety. EDA and Blood Volume Pulse (BVP) signals were recorded using a wrist-worn EDA and PPG sensor respectively. 47 features were computed from EDA and BVP signal, out of which a final set of 24 significantly correlated features were selected for analysis. The phases of the experimental study are encoded as unique integers to generate the context feature vector. A combination of features from a single sensor with the context feature vector is used for training a machine learning model to distinguish between anxious and not-anxious states. Results and analysis showed that the EDA and BVP machine learning models that combined the context feature along with the physiological features achieved 3.37% and 6.41% higher accuracy respectively than the models that used only physiological features. Further, end-to-end processing of EDA and BVP signals was simulated for real-time anxiety level detection. This work demonstrates the practicality of the proposed anxiety detection method in facilitating long-term monitoring of anxiety in older adults using low-cost consumer devices.      
### 34.Deep Source-Channel Coding for Sentence Semantic Transmission with HARQ  [ :arrow_down: ](https://arxiv.org/pdf/2106.03009.pdf)
>  Recently, semantic communication has been brought to the forefront because of its great success in deep learning (DL), especially Transformer. Even if semantic communication has been successfully applied in the sentence transmission to reduce semantic errors, existing architecture is usually fixed in the codeword length and is inefficient and inflexible for the varying sentence length. In this paper, we exploit hybrid automatic repeat request (HARQ) to reduce semantic transmission error further. We first combine semantic coding (SC) with Reed Solomon (RS) channel coding and HARQ, called SC-RS-HARQ, which exploits the superiority of the SC and the reliability of the conventional methods successfully. Although the SC-RS-HARQ is easily applied in the existing HARQ systems, we also develop an end-to-end architecture, called SCHARQ, to pursue the performance further. Numerical results demonstrate that SCHARQ significantly reduces the required number of bits for sentence semantic transmission and sentence error rate. Finally, we attempt to replace error detection from cyclic redundancy check to a similarity detection network called Sim32 to allow the receiver to reserve the wrong sentences with similar semantic information and to save transmission resources.      
### 35.Controller Synthesis for Omega-Regular and Steady-State Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2106.02951.pdf)
>  Given a Markov decision process (MDP) and a linear-time ($\omega$-regular or LTL) specification, the controller synthesis problem aims to compute the optimal policy that satisfies the specification. More recently, problems that reason over the asymptotic behavior of systems have been proposed through the lens of steady-state planning. This entails finding a control policy for an MDP such that the Markov chain induced by the solution policy satisfies a given set of constraints on its steady-state distribution. This paper studies a generalization of the controller synthesis problem for a linear-time specification under steady-state constraints on the asymptotic behavior. We present an algorithm to find a deterministic policy satisfying $\omega$-regular and steady-state constraints by characterizing the solutions as an integer linear program, and experimentally evaluate our approach.      
### 36.Hierarchical Temperature Imaging Using Pseudo-Inversed Convolutional Neural Network Aided TDLAS Tomography  [ :arrow_down: ](https://arxiv.org/pdf/2106.02901.pdf)
>  As an in situ combustion diagnostic tool, Tunable Diode Laser Absorption Spectroscopy (TDLAS) tomography has been widely used for imaging of two-dimensional temperature distributions in reactive flows. Compared with the computational tomographic algorithms, Convolutional Neural Networks (CNNs) have been proofed to be more robust and accurate for image reconstruction, particularly in case of limited access of laser beams in the Region of Interest (RoI). In practice, flame in the RoI that requires to be reconstructed with good spatial resolution is commonly surrounded by low-temperature background. Although the background is not of high interest, spectroscopic absorption still exists due to heat dissipation and gas convection. Therefore, we propose a Pseudo-Inversed CNN (PI-CNN) for hierarchical temperature imaging that (a) uses efficiently the training and learning resources for temperature imaging in the RoI with good spatial resolution, and (b) reconstructs the less spatially resolved background temperature by adequately addressing the integrity of the spectroscopic absorption model. In comparison with the traditional CNN, the newly introduced pseudo inversion of the RoI sensitivity matrix is more penetrating for revealing the inherent correlation between the projection data and the RoI to be reconstructed, thus prioritising the temperature imaging in the RoI with high accuracy and high computational efficiency. In this paper, the proposed algorithm was validated by both numerical simulation and lab-scale experiment, indicating good agreement between the phantoms and the high-fidelity reconstructions.      
### 37.Human Listening and Live Captioning: Multi-Task Training for Speech Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.02896.pdf)
>  With the surge of online meetings, it has become more critical than ever to provide high-quality speech audio and live captioning under various noise conditions. However, most monaural speech enhancement (SE) models introduce processing artifacts and thus degrade the performance of downstream tasks, including automatic speech recognition (ASR). This paper proposes a multi-task training framework to make the SE models unharmful to ASR. Because most ASR training samples do not have corresponding clean signal references, we alternately perform two model update steps called SE-step and ASR-step. The SE-step uses clean and noisy signal pairs and a signal-based loss function. The ASR-step applies a pre-trained ASR model to training signals enhanced with the SE model. A cross-entropy loss between the ASR output and reference transcriptions is calculated to update the SE model parameters. Experimental results with realistic large-scale settings using ASR models trained on 75,000-hour data show that the proposed framework improves the word error rate for the SE output by 11.82% with little compromise in the SE quality. Performance analysis is also carried out by changing the ASR model, the data used for the ASR-step, and the schedule of the two update steps.      
### 38.A Deep Variational Bayesian Framework for Blind Image Deblurring  [ :arrow_down: ](https://arxiv.org/pdf/2106.02884.pdf)
>  Blind image deblurring is an important yet very challenging problem in low-level vision. Traditional optimization based methods generally formulate this task as a maximum-a-posteriori estimation or variational inference problem, whose performance highly relies on the handcraft priors for both the latent image and the blur kernel. In contrast, recent deep learning methods generally learn, from a large collection of training images, deep neural networks (DNNs) directly mapping the blurry image to the clean one or to the blur kernel, paying less attention to the physical degradation process of the blurry image. In this paper, we present a deep variational Bayesian framework for blind image deblurring. Under this framework, the posterior of the latent clean image and blur kernel can be jointly estimated in an amortized inference fashion with DNNs, and the involved inference DNNs can be trained by fully considering the physical blur model, together with the supervision of data driven priors for the clean image and blur kernel, which is naturally led to by the evidence lower bound objective. Comprehensive experiments are conducted to substantiate the effectiveness of the proposed framework. The results show that it can not only achieve a promising performance with relatively simple networks, but also enhance the performance of existing DNNs for deblurring.      
### 39.Wideband Channel Estimation for IRS-Aided Systems in the Face of Beam Squint  [ :arrow_down: ](https://arxiv.org/pdf/2106.02883.pdf)
>  Intelligent reflecting surfaces (IRSs) improve both the bandwidth and energy efficiency of wideband communication systems by using low-cost passive elements for reflecting the impinging signals with adjustable phase shifts. To realize the full potential of IRS-aided systems, having accurate channel state information (CSI) is indispensable, but it is challenging to acquire, since these passive devices cannot carry out transmit/receive signal processing. The existing channel estimation methods conceived for wideband IRS-aided communication systems only consider the channel's frequency selectivity, but ignore the effect of beam squint, despite its severe performance degradation. Hence we fill this gap and conceive wideband channel estimation for IRS-aided communication systems by explicitly taking the effect of beam squint into consideration. We demonstrate that the mutual correlation function between the spatial steering vectors and the cascaded two-hop channel reflected by the IRS has two peaks, which leads to a pair of estimated angles for a single propagation path, due to the effect of beam squint. One of these two estimated angles is the frequency-independent `actual angle', while the other one is the frequency-dependent `false angle'. To reduce the influence of false angles on channel estimation, we propose a twin-stage orthogonal matching pursuit (TS-OMP) algorithm.      
### 40.Consensus Analysis over Clustered Networks of Multi-Agent Systems under External Disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2106.02865.pdf)
>  This paper studies a consensus problem of multi-agent systems subjected to external disturbances over the clustered network. It considers that the agents are divided into several clusters. They are almost all the time isolated one from another, which has a directed spanning tree. The goal of agents achieves a common value. To support interaction between clusters with a minimum exchange of information, we consider that each cluster has an agent, who can exchange information to any agents outside of its cluster at some discrete instants of time. Our main contribution proposes a consensus protocol, which takes into account the continuous-time communications among agents inside the clusters and discrete-time communication information across clusters. Accordingly, the consensus and the robust $\mathcal{H}_{\infty}$ consensus over the clustered network are respectively analyzed. Thanks to results from matrix theory and algebraic graph theory, we show that the proposed control protocols can solve the problems mentioned above. Finally, a numerical example is given to show the effectiveness of the proposed theoretical results.      
### 41.Multi-armed Bandit Algorithms on System-on-Chip: Go Frequentist or Bayesian?  [ :arrow_down: ](https://arxiv.org/pdf/2106.02855.pdf)
>  Multi-armed Bandit (MAB) algorithms identify the best arm among multiple arms via exploration-exploitation trade-off without prior knowledge of arm statistics. Their usefulness in wireless radio, IoT, and robotics demand deployment on edge devices, and hence, a mapping on system-on-chip (SoC) is desired. Theoretically, the Bayesian approach-based Thompson Sampling (TS) algorithm offers better performance than the frequentist approach-based Upper Confidence Bound (UCB) algorithm. However, TS is not synthesizable due to Beta function. We address this problem by approximating it via a pseudo-random number generator-based approach and efficiently realize the TS algorithm on Zynq SoC. In practice, the type of arms distribution (e.g., Bernoulli, Gaussian, etc.) is unknown and hence, a single algorithm may not be optimal. We propose a reconfigurable and intelligent MAB (RI-MAB) framework. Here, intelligence enables the identification of appropriate MAB algorithms for a given environment, and reconfigurability allows on-the-fly switching between algorithms on the SoC. This eliminates the need for parallel implementation of algorithms resulting in huge savings in resources and power consumption. We analyze the functional correctness, area, power, and execution time of the proposed and existing architectures for various arm distributions, word-length, and hardware-software co-design approaches. We demonstrate the superiority of the RI-MAB over TS and UCB only architectures.      
### 42.Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.02830.pdf)
>  Text-to-speech (TTS) synthesis is the process of producing synthesized speech from text or phoneme input. Traditional TTS models contain multiple processing steps and require external aligners, which provide attention alignments of phoneme-to-frame sequences. As the complexity increases and efficiency decreases with every additional step, there is expanding demand in modern synthesis pipelines for end-to-end TTS with efficient internal aligners. In this work, we propose an end-to-end text-to-waveform network with a novel reinforcement learning based duration search method. Our proposed generator is feed-forward and the aligner trains the agent to make optimal duration predictions by receiving active feedback from actions taken to maximize cumulative reward. We demonstrate accurate alignments of phoneme-to-frame sequence generated from trained agents enhance fidelity and naturalness of synthesized audio. Experimental results also show the superiority of our proposed model compared to other state-of-the-art TTS models with internal and external aligners.      
### 43.$\mathcal{H}_2/\mathcal{H}_{-}$ Distributed Fault Detection and Isolation for Heterogeneous Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.02822.pdf)
>  The paper deals with the problem of distributed fault detection and isolation (FDI) for a group of heterogeneous multi-agent systems. The developed formation for the FDI is taken into account as a distributed observer design methodology, where the interaction between the agent and its neighbors is described as a vector of distributed relative output measurements. Based on two performance indexes $\mathcal{H}_2$ and $\mathcal{H}_{-}$, sufficient conditions are given to ensure the residual signals robust to the disturbances and sensitive with respect to the fault signals. In addition, we show that by using our proposed approach, each agent is able to estimate both its own states and states of its nearest neighbors in the presence of disturbances and faults. Finally, numerical simulations are provided to demonstrate the effectiveness of the theoretically analyzed results.      
### 44.Full-Dimensional Rate Enhancement for UAV-Enabled Communications via Intelligent Omni-Surface  [ :arrow_down: ](https://arxiv.org/pdf/2106.02811.pdf)
>  This paper investigates the achievable rate maximization problem of a downlink unmanned aerial vehicle (UAV)-enabled communication system aided by an intelligent omni-surface (IOS). Different from the state-of-the-art reconfigurable intelligent surface (RIS) that only reflects incident signals, the IOS can simultaneously reflect and transmit the signals, thereby providing full-dimensional rate enhancement. To tackle such a problem, we formulate it by jointly optimizing the IOS's phase shift and the UAV trajectory. Although it is difficult to solve it optimally due to its non-convexity, we propose an efficient iterative algorithm to obtain a high-quality suboptimal solution. Simulation results show that the IOS-assisted UAV communications can achieve more significant improvement in achievable rates than other benchmark schemes.      
### 45.An Attribute-Aligned Strategy for Learning Speech Representation  [ :arrow_down: ](https://arxiv.org/pdf/2106.02810.pdf)
>  Advancement in speech technology has brought convenience to our life. However, the concern is on the rise as speech signal contains multiple personal attributes, which would lead to either sensitive information leakage or bias toward decision. In this work, we propose an attribute-aligned learning strategy to derive speech representation that can flexibly address these issues by attribute-selection mechanism. Specifically, we propose a layered-representation variational autoencoder (LR-VAE), which factorizes speech representation into attribute-sensitive nodes, to derive an identity-free representation for speech emotion recognition (SER), and an emotionless representation for speaker verification (SV). Our proposed method achieves competitive performances on identity-free SER and a better performance on emotionless SV, comparing to the current state-of-the-art method of using adversarial learning applied on a large emotion corpora, the MSP-Podcast. Also, our proposed learning strategy reduces the model and training process needed to achieve multiple privacy-preserving tasks.      
### 46.AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images  [ :arrow_down: ](https://arxiv.org/pdf/2106.02800.pdf)
>  Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time retinal images with high resolution down to 2 $\mu m$. This technique enables detection of the morphologies of individual microaneurysms (MAs), which are one of the earliest signs of diabetic retinopathy (DR), a frequent complication of diabetes that can lead to visual impairment and blindness. In contrast to previous automatic models developed for MA detection on standard fundus photographs, currently there is no high throughput image protocol available for automatic analysis of AOSLO photographs. To address this urgency, we introduce AOSLO-net, a deep neural network framework with customized training policy, including preprocessing, data augmentation and transfer learning, to automatically segment MAs from AOSLO images. We evaluate the performance of AOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and segmentation, leading to correct MA morphological classification, while outperforming the state-of-the-art both in accuracy and cost.      
### 47.MPC-based Realtime Power System Control with DNN-based Prediction/Sensitivity-Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2106.02794.pdf)
>  This paper presents a model predictive control (MPC)-based online real-time adaptive control scheme for emergency voltage control in power systems. Despite tremendous success in various applications, real-time implementation of MPC for control in power systems has not been successful due to its online computational burden for large-sized systems that takes more time than available between the two control decisions. This long-standing problem is addressed here by developing a novel MPC-based adaptive control framework which (i) adapts the nominal offline computed control, by successive control corrections, at each control decision point using the latest measurements, (ii) utilizes data-driven approach for prediction of voltage trajectory and its sensitivity with respect to control using trained deep neural networks (DNNs). In addition, a realistic coordination scheme among control inputs of static var compensators (SVC), load-shedding (LS), and load tap-changers (LTC) is presented with a goal of maintaining bus voltages within a predefined permissible range, where the delayed effect of LTC action is also incorporated in a novel way. The performance of the proposed scheme is validated for IEEE 9-bus as well as 39-bus systems, with $\pm 20\%$ variations in nominal loading conditions. We also show that the proposed new scheme speeds up the online computation by a factor of 20 bringing it down to under one-tenth the control interval, making the MPC-based power system control practically feasible.      
### 48.Do You Listen with One or Two Microphones? A Unified ASR Model for Single and Multi-Channel Audio  [ :arrow_down: ](https://arxiv.org/pdf/2106.02750.pdf)
>  Automatic speech recognition (ASR) models are typically designed to operate on a single input data type, e.g. a single or multi-channel audio streamed from a device. This design decision assumes the \textit{primary} input data source does not change and if an additional (\textit{auxiliary}) data source is occasionally available, it cannot be used. An ASR model that operates on both primary and auxiliary data can achieve better accuracy compared to a primary-only solution; and a model that can serve both \textit{primary-only} (PO) and \textit{primary-plus-auxiliary} (PPA) modes is highly desirable. In this work, we propose a unified ASR model that can serve both modes. We demonstrate its efficacy in a realistic scenario where a set of devices typically stream a single primary audio channel, and two additional auxiliary channels \textit{only when} upload bandwidth allows it. The architecture enables a unique methodology that uses both types of input audio during training time. Our proposed approach achieves up to 12.5\% relative word-error-rate reduction (WERR) compared to a PO baseline, and up to 16.0\% relative WERR in low-SNR conditions. The unique training methodology achieves up to 2.5\% relative WERR compared to a PPA baseline.      
### 49.Real Time Video based Heart and Respiration Rate Monitoring  [ :arrow_down: ](https://arxiv.org/pdf/2106.02669.pdf)
>  In recent years, research about monitoring vital signs by smartphones grows significantly. There are some special sensors like Electrocardiogram (ECG) and Photoplethysmographic (PPG) to detect heart rate (HR) and respiration rate (RR). Smartphone cameras also can measure HR by detecting and processing imaging Photoplethysmographic (iPPG) signals from the video of a user's face. Indeed, the variation in the intensity of the green channel can be measured by the iPPG signals of the video. This study aimed to provide a method to extract heart rate and respiration rate using the video of individuals' faces. The proposed method is based on measuring fluctuations in the Hue, and can therefore extract both HR and RR from the video of a user's face. The proposed method is evaluated by performing on 25 healthy individuals. For each subject, 20 seconds video of his/her face is recorded. Results show that the proposed approach of measuring iPPG using Hue gives more accurate rates than the Green channel.      
### 50.Singular Dynamic Mode Decompositions  [ :arrow_down: ](https://arxiv.org/pdf/2106.02639.pdf)
>  This manuscript is aimed at addressing several long standing limitations of dynamic mode decompositions in the application of Koopman analysis. Principle among these limitations are the convergence of associated Dynamic Mode Decomposition algorithms and the existence of Koopman modes. To address these limitations, two major modifications are made, where Koopman operators are removed from the analysis in light of Liouville operators (known as Koopman generators in special cases), and these operators are shown to be compact for certain pairs of Hilbert spaces selected separately as the domain and range of the operator. While eigenfunctions are discarded in this analysis, a viable reconstruction algorithm is still demonstrated, and the sacrifice of eigenfunctions realizes the theoretical goals of DMD analysis that have yet to be achieved in other contexts. The manuscript concludes with the description of a Dynamic Mode Decomposition algorithm that converges when a dense collection of occupation kernels, arising from the data, are leveraged in the analysis.      
### 51.Tunable Trajectory Planner Using G3 Curves  [ :arrow_down: ](https://arxiv.org/pdf/2106.03836.pdf)
>  Trajectory planning is commonly used as part of a local planner in autonomous driving. This paper considers the problem of planning a continuous-curvature-rate trajectory between fixed start and goal states that minimizes a tunable trade-off between passenger comfort and travel time. The problem is an instance of infinite dimensional optimization over two continuous functions: a path, and a velocity profile. We propose a simplification of this problem that facilitates the discretization of both functions. This paper also proposes a method to quickly generate minimal-length paths between start and goal states based on a single tuning parameter: the second derivative of curvature. Furthermore, we discretize the set of velocity profiles along a given path into a selection of acceleration way-points along the path. Gradient-descent is then employed to minimize cost over feasible choices of the second derivative of curvature, and acceleration way-points, resulting in a method that repeatedly solves the path and velocity profiles in an iterative fashion. Numerical examples are provided to illustrate the benefits of the proposed methods.      
### 52.Energy and Age Pareto Optimal Trajectories in UAV-assisted Wireless Data Collection  [ :arrow_down: ](https://arxiv.org/pdf/2106.03822.pdf)
>  This paper studies an unmanned aerial vehicle (UAV)-assisted wireless network, where a UAV is dispatched to gather information from ground sensor nodes (SN) and transfer the collected data to the depot. The information freshness is captured by the age of information (AoI) metric, whilst the energy consumption of the UAV is seen as another performance criterion. Most importantly, the AoI and energy efficiency are inherently competing metrics, since decreasing the AoI requires the UAV returning to the depot more frequently, leading to a higher energy consumption. To this end, we design UAV paths that optimize these two competing metrics and reveal the Pareto frontier. To formulate this problem, a multi-objective mixed integer linear programming (MILP) is proposed with a flow-based constraint set and we apply Bender's decomposition on the proposed formulation. The overall outcome shows that the proposed method allows deriving non-dominated solutions for decision making for UAV based wireless data collection. Numerical results are provided to corroborate our study by presenting the Pareto front of the two objectives and the effect on the UAV trajectory.      
### 53.Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-based Multimodal Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2106.03821.pdf)
>  It is now well established from a variety of studies that there is a significant benefit from combining video and audio data in detecting active speakers. However, either of the modalities can potentially mislead audiovisual fusion by inducing unreliable or deceptive information. This paper outlines active speaker detection as a multi-objective learning problem to leverage best of each modalities using a novel self-attention, uncertainty-based multimodal fusion scheme. Results obtained show that the proposed multi-objective learning architecture outperforms traditional approaches in improving both mAP and AUC scores. We further demonstrate that our fusion strategy surpasses, in active speaker detection, other modality fusion methods reported in various disciplines. We finally show that the proposed method significantly improves the state-of-the-art on the AVA-ActiveSpeaker dataset.      
### 54.High Resolution Solar Image Generation using Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.03814.pdf)
>  We applied Deep Learning algorithm known as Generative Adversarial Networks (GANs) to perform solar image-to-image translation. That is, from Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager(HMI) line of sight magnetogram images to SDO/Atmospheric Imaging Assembly(AIA) 0304-Ã images. The Ultraviolet(UV)/Extreme Ultraviolet(EUV) observations like the SDO/AIA0304-Ã images were only made available to scientists in the late 1990s even though the magenetic field observations like the SDO/HMI have been available since the 1970s. Therefore by leveraging Deep Learning algorithms like GANs we can give scientists access to complete datasets for analysis. For generating high resolution solar images we use the Pix2PixHD and Pix2Pix algorithms. The Pix2PixHD algorithm was specifically designed for high resolution image generation tasks, and the Pix2Pix algorithm is by far the most widely used image to image translation algorithm. For training and testing we used the data for the year 2012, 2013 and 2014. The results show that our deep learning models are capable of generating high resolution(1024 x 1024 pixels) AIA0304 images from HMI magnetograms. Specifically, the pixel-to-pixel Pearson Correlation Coefficient of the images generated by Pix2PixHD and original images is as high as 0.99. The number is 0.962 if Pix2Pix is used to generate images. The results we get for our Pix2PixHD model is better than the results obtained by previous works done by others to generate AIA0304 images. Thus, we can use these models to generate AIA0304 images when the AIA0304 data is not available which can be used for understanding space weather and giving researchers the capability to predict solar events such as Solar Flares and Coronal Mass Ejections. As far as we know, our work is the first attempt to leverage Pix2PixHD algorithm for SDO/HMI to SDO/AIA0304 image-to-image translation.      
### 55.Learning Stochastic Optimal Policies via Gradient Descent  [ :arrow_down: ](https://arxiv.org/pdf/2106.03780.pdf)
>  We systematically develop a learning-based treatment of stochastic optimal control (SOC), relying on direct optimization of parametric control policies. We propose a derivation of adjoint sensitivity results for stochastic differential equations through direct application of variational calculus. Then, given an objective function for a predetermined task specifying the desiderata for the controller, we optimize their parameters via iterative gradient descent methods. In doing so, we extend the range of applicability of classical SOC techniques, often requiring strict assumptions on the functional form of system and control. We verify the performance of the proposed approach on a continuous-time, finite horizon portfolio optimization with proportional transaction costs.      
### 56.Increase and Conquer: Training Graph Neural Networks on Growing Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2106.03693.pdf)
>  Graph neural networks (GNNs) use graph convolutions to exploit network invariances and learn meaningful features from network data. However, on large-scale graphs convolutions incur in high computational cost, leading to scalability limitations. Leveraging the graphon -- the limit object of a graph -- in this paper we consider the problem of learning a graphon neural network (WNN) -- the limit object of a GNN -- by training GNNs on graphs sampled Bernoulli from the graphon. Under smoothness conditions, we show that: (i) the expected distance between the learning steps on the GNN and on the WNN decreases asymptotically with the size of the graph, and (ii) when training on a sequence of growing graphs, gradient descent follows the learning direction of the WNN. Inspired by these results, we propose a novel algorithm to learn GNNs on large-scale graphs that, starting from a moderate number of nodes, successively increases the size of the graph during training. This algorithm is benchmarked on both a recommendation system and a decentralized control problem where it is shown to retain comparable performance, to its large-scale counterpart, at a reduced computational cost.      
### 57.Towards a Multi-purpose Robotic Nursing Assistant  [ :arrow_down: ](https://arxiv.org/pdf/2106.03683.pdf)
>  Robotic nursing aid is one of the heavily researched areas in robotics nowadays. Several robotic assistants exist that only focus on a specific function related to nurses assistance or functions related to patient aid. There is a need for a unified system that not only performs tasks that would assist nurses and reduce their burden but also perform tasks that help a patient. In recent times, due to the COVID-19 pandemic, there is also an increase in the need for robotic assistants that have teleoperation capabilities to provide better protection against the virus spread. To address these requirements, we propose a novel Multi-purpose Intelligent Nurse Aid (MINA) robotic system that is capable of providing walking assistance to the patients and perform teleoperation tasks with an easy-to-use and intuitive Graphical User Interface (GUI). This paper also presents preliminary results from the walking assistant task that improves upon the current state-of-the-art methods and shows the developed GUI for teleoperation.      
### 58.Recovery Analysis for Plug-and-Play Priors using the Restricted Eigenvalue Condition  [ :arrow_down: ](https://arxiv.org/pdf/2106.03668.pdf)
>  The plug-and-play priors (PnP) and regularization by denoising (RED) methods have become widely used for solving inverse problems by leveraging pre-trained deep denoisers as image priors. While the empirical imaging performance and the theoretical convergence properties of these algorithms have been widely investigated, their recovery properties have not previously been theoretically analyzed. We address this gap by showing how to establish theoretical recovery guarantees for PnP/RED by assuming that the solution of these methods lies near the fixed-points of a deep neural network. We also present numerical results comparing the recovery performance of PnP/RED in compressive sensing against that of recent compressive sensing algorithms based on generative models. Our numerical results suggest that PnP with a pre-trained artifact removal network provides significantly better results compared to the existing state-of-the-art methods.      
### 59.Optimal Transmit Power and Antenna Selection to Achieve Energy Efficient and Low Complexity in fifth generation Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.03664.pdf)
>  This paper investigates joint antenna selection and optimal transmit power in multi cell massive multiple input multiple output systems. The pilot interference and activated transmit antenna selection plays an essential role in maximizing energy efficiency. We derived the closed-form of maximal energy efficiency with complete knowledge of large-scale fading with maximum ratio transmission while accounting for channel estimation and eliminated pilot contamination when the antennas approach infinity. We investigated joint optimal antenna selection and optimal transmit power under minimized reuse of pilot sequences based on a novel iterative low-complexity algorithm for Lagrange multiplayer and Newton methods. The two scenarios of achievable high data rate and total transmit power allocation are critical to the performance maximal energy efficiency. We propose new power consumption for each antenna based on the transmit power amplifier and circuit power consumption to analyze exact power consumption. The simulation results show that maximal energy efficiency could be achieved using the iterative low complexity algorithm based on the reasonable maximum transmit power when the noise power was less than the power received pilot. The proposed low complexity iterative algorithm offers maximum energy efficiency by repeating a minimized pilot signal until the optimal antenna selection and transmission power are achieved.      
### 60.SNR optimization of multi-span fiber optic communication systems employing EDFAs with non-flat gain and noise figure  [ :arrow_down: ](https://arxiv.org/pdf/2106.03639.pdf)
>  Throughput optimization of optical communication systems is a key challenge for current optical networks. The use of gain-flattening filters (GFFs) simplifies the problem at the cost of insertion loss, higher power consumption and potentially poorer performance. In this work, we propose a component wise model of a multi-span transmission system for signal-to-noise (SNR) optimization. A machine-learning based model is trained for the gain and noise figure spectral profile of a C-band amplifier without a GFF. The model is combined with the Gaussian noise model for nonlinearities in optical fibers including stimulated Raman scattering and the implementation penalty spectral profile measured in back-to-back in order to predict the SNR in each channel of a multi-span wavelength division multiplexed system. All basic components in the system model are differentiable and allow for the gradient descent-based optimization of a system of arbitrary configuration in terms of number of spans and length per span. When the input power profile is optimized for flat and maximized received SNR per channel, the minimum performance in an arbitrary 3-span experimental system is improved by up to 8 dB w.r.t. a system with flat input power profile. An SNR flatness down to 1.2 dB is simultaneously achieved. The model and optimization methods are used to optimize the performance of an example core network, and 0.2 dB of gain is shown w.r.t. solutions that do not take into account nonlinearities. The method is also shown to be beneficial for systems with ideal gain flattening, achieving up to 0.3 dB of gain w.r.t. a flat input power profile.      
### 61.Beamforming and Transmit Power Design for Intelligent Reconfigurable Surface-aided Secure Spatial Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2106.03616.pdf)
>  Intelligent reflecting surface (IRS) is a promising solution to build a programmable wireless environment for future communication systems, in which the reflector elements steer the incident signal in fully customizable ways by passive beamforming. In this paper, an IRS-aided secure spatial modulation (SM) is proposed, where the IRS perform passive beamforming and information transfer simultaneously by adjusting the on-off states of the reflecting elements. We formulate an optimization problem to maximize the average secrecy rate (SR) by jointly optimizing the passive beamforming at IRS and the transmit power at transmitter under the consideration that the direct pathes channels from transmitter to receivers are obstructed by obstacles. As the expression of SR is complex, we derive a newly fitting expression (NASR) for the expression of traditional approximate SR (TASR), which has simpler closed-form and more convenient for subsequent optimization. Based on the above two fitting expressions, three beamforming methods, called maximizing NASR via successive convex approximation (Max-NASR-SCA), maximizing NASR via dual ascent (Max-NASR-DA) and maximizing TASR via semi-definite relaxation (Max-TASR-SDR) are proposed to improve the SR performance. Additionally, two transmit power design (TPD) methods are proposed based on the above two approximate SR expressions, called Max-NASR-TPD and Max-TASR-TPD. Simulation results show that the proposed Max-NASR-DA and Max-NASR-SCA IRS beamformers harvest substantial SR performance gains over Max-TASR-SDR. For TPD, the proposed Max-NASR-TPD performs better than Max-TASR-TPD. Particularly, the Max-NASR-TPD has a closed-form solution.      
### 62.Free-Choice Nets With Home Clusters Are Lucent  [ :arrow_down: ](https://arxiv.org/pdf/2106.03554.pdf)
>  A marked Petri net is lucent if there are no two different reachable markings enabling the same set of transitions, i.e., states are fully characterized by the transitions they enable. Characterizing the class of systems that are lucent is a foundational and also challenging question. However, little research has been done on the topic. In this paper, it is shown that all free-choice nets having a home cluster are lucent. These nets have a so-called home marking such that it is always possible to reach this marking again. Such a home marking can serve as a regeneration point or as an end-point. The result is highly relevant because in many applications, we want the system to be lucent and many well-behaved process models fall into the class identified in this paper. Unlike previous work, we do not require the marked Petri net to be live and strongly connected. Most of the analysis techniques for free-choice nets are tailored towards well-formed nets. The approach presented in this paper provides a novel perspective enabling new analysis techniques for free-choice nets that do not need to be well-formed. Therefore, we can also model systems and processes that are terminating and/or have an initialization phase.      
### 63.Empirical Bayesian Independent Deeply Learned Matrix Analysis For Multichannel Audio Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2106.03492.pdf)
>  Independent deeply learned matrix analysis (IDLMA) is one of the state-of-the-art supervised multichannel audio source separation methods. It blindly estimates the demixing filters on the basis of source independence, using the source model estimated by the deep neural network (DNN). However, since the ratios of the source to interferer signals vary widely among time-frequency (TF) slots, it is difficult to obtain reliable estimated power spectrograms of sources at all TF slots. In this paper, we propose an IDLMA extension, empirical Bayesian IDLMA (EB-IDLMA), by introducing a prior distribution of source power spectrograms and treating the source power spectrograms as latent random variables. This treatment allows us to implicitly consider the reliability of the estimated source power spectrograms for the estimation of demixing filters through the hyperparameters of the prior distribution estimated by the DNN. Experimental evaluations show the effectiveness of EB-IDLMA and the importance of introducing the reliability of the estimated source power spectrograms.      
### 64.Subject Independent Emotion Recognition using EEG Signals Employing Attention Driven Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.03461.pdf)
>  Electroencephalogram (EEG) based emotional analysis has been employed in medical science, security and human-computer interaction with good success. In the recent past, deep learning-based approaches have significantly improved the classification accuracy when compared to classical signal processing and machine learning based frameworks. But most of them were subject-dependent studies which were not able to generalize on the subject-independent tasks due to the inter-subject variability in EEG. In this work, a novel deep learning framework capable of doing subject-independent emotion recognition is presented, consisting of two parts. First, an unsupervised Long Short-Term Memory (LSTM) with channel-attention autoencoder is proposed for getting a correlated lower dimensional latent space representation of the EEG data for each subject. Secondly, a convolutional neural network (CNN) with attention framework, which takes the first component as input, is presented for performing the task of subject-independent emotion recognition. With the attention mechanism, the proposed approach could highlight the channel of interest as well as the temporal localization of the EEG signal, which contributes to the emotion under consideration as validated by the results. The proposed approach has been validated using various widely employed datasets for EEG signals including DEAP dataset, SEED dataset and CHB-MIT dataset. With proposed methodology, average subject independent accuracies of 65.9%, 69.5% for valence and arousal classification in the DEAP dataset, 76.7% for positive-negative classification in SEED dataset is obtained and further for the CHB-MIT dataset average subject independent accuracies of 69.1%, 67.6%, 72.3% for Pre-Ictal Vs Ictal, Inter-Ictal Vs Ictal, Pre-Ictal Vs Inter-Ictal classification is obtained.      
### 65.Real-time Identification and Tuning of Multirotors Based on Deep Neural Networks for Accurate Trajectory Tracking Under Wind Disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2106.03459.pdf)
>  High performance trajectory tracking for multirotor Unmanned Aerial Vehicles (UAVs) is a fast growing research area due to the increase in popularity and demand. In many applications, the multirotor UAV dynamics would change in-flight resulting in performance degradation, or even instability, such that the control system is required to adapt its parameters to the new dynamics. In this paper, we developed a real-time identification approach based on Deep Neural Networks (DNNs) and the Modified Relay Feedback Test (MRFT) to optimally tune PID controllers suitable for aggressive trajectory tracking. We also propose a feedback linearization technique along with additional feedforward terms to achieve high trajectory tracking performance. In addition, we investigate and analyze different PID configurations for position controllers to maximize the tracking performance in the presence of wind disturbance and system parameter changes, and provide a systematic design methodology to trade-off performance for robustness. We prove the effectiveness and applicability of our developed approach through a set of experiments where accurate trajectory tracking is maintained despite significant changes to the UAV aerodynamic characteristics and the application of external wind. We demonstrate low discrepancy between simulation and experimental results which proves the potential of using the suggested approach for planning and fault detection tasks. The achieved tracking results on figure-eight trajectory is on par with the state-of-the-art.      
### 66.Dynamic Portfolio Cuts: A Spectral Approach to Graph-Theoretic Diversification  [ :arrow_down: ](https://arxiv.org/pdf/2106.03417.pdf)
>  Stock market returns are typically analyzed using standard regression, yet they reside on irregular domains which is a natural scenario for graph signal processing. To this end, we consider a market graph as an intuitive way to represent the relationships between financial assets. Traditional methods for estimating asset-return covariance operate under the assumption of statistical time-invariance, and are thus unable to appropriately infer the underlying true structure of the market graph. This work introduces a class of graph spectral estimators which cater for the nonstationarity inherent to asset price movements, and serve as a basis to represent the time-varying interactions between assets through a dynamic spectral market graph. Such an account of the time-varying nature of the asset-return covariance allows us to introduce the notion of dynamic spectral portfolio cuts, whereby the graph is partitioned into time-evolving clusters, allowing for online and robust asset allocation. The advantages of the proposed framework over traditional methods are demonstrated through numerical case studies using real-world price data.      
### 67.On the Skew-Symmetric Binary Sequences and the Merit Factor Problem  [ :arrow_down: ](https://arxiv.org/pdf/2106.03377.pdf)
>  The merit factor problem is of practical importance to manifold domains, such as digital communications engineering, radars, system modulation, system testing, information theory, physics, chemistry. However, the merit factor problem is referenced as one of the most difficult optimization problems and it was further conjectured that stochastic search procedures will not yield merit factors higher than 5 for long binary sequences (sequences with lengths greater than 200). Some useful mathematical properties related to the flip operation of the skew-symmetric binary sequences are presented in this work. By exploiting those properties, the memory complexity of state-of-the-art stochastic merit factor optimization algorithms could be reduced from $O(n^2)$ to $O(n)$. As a proof of concept, a lightweight stochastic algorithm was constructed, which can optimize pseudo-randomly generated skew-symmetric binary sequences with long lengths (up to ${10}^5+1$) to skew-symmetric binary sequences with a merit factor greater than 5. An approximation of the required time is also provided. The numerical experiments suggest that the algorithm is universal and could be applied to skew-symmetric binary sequences with arbitrary lengths.      
### 68.Routing optimization on power packet dispatching system based on energy loss minimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.03325.pdf)
>  Power packet dispatching system has been proposed for smart power management in the form of discretized packet. In this paper, we discuss the routing optimization of power packets on the network of power routers. We propose a cost metric for the power packet delivery by circuit analysis of the router network. Using the metric, we formulate the optimization problem as a general shortest path problem from a source node to a load node. The result of numerical simulations shows that the proposed algorithm can allocate distributed power sources to load demands and identify the optimal path for the power delivery.      
### 69.Terrain Adaptive Gait Transitioning for a Quadruped Robot using Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.03307.pdf)
>  Legged robots can traverse challenging terrain, use perception to plan their safe foothold positions, and navigate the environment. Such unique mobility capabilities make these platforms a perfect candidate for scenarios such as search and rescue, inspection, and exploration tasks. While traversing through such terrains, the robot's instability is a significant concern. Many times the robot needs to switch gaits depending on its environment. Due to the complex dynamics of quadruped robots, classical PID control fails to provide high stability. Thus, there is a need for advanced control methods like the Model Predictive Control (MPC) which uses the system model and the nature of the terrain in order to predict the stable body pose of the robot. The controller also provides correction to any external disturbances that result in a change in the desired behavior of the robot. The MPC controller is designed in MATLAB, for full body torque control. The controller performance was verified on Boston Dynamics Spot in Webots simulator. The robot is able to provide correction for external perturbations up to 150 N and also resist falls till 80 cm.      
### 70.Robust Implicit Networks via Non-Euclidean Contractions  [ :arrow_down: ](https://arxiv.org/pdf/2106.03194.pdf)
>  Implicit neural networks, a.k.a., deep equilibrium networks, are a class of implicit-depth learning models where function evaluation is performed by solving a fixed point equation. They generalize classic feedforward models and are equivalent to infinite-depth weight-tied feedforward networks. While implicit models show improved accuracy and significant reduction in memory consumption, they can suffer from ill-posedness and convergence instability. <br>This paper provides a new framework to design well-posed and robust implicit neural networks based upon contraction theory for the non-Euclidean norm $\ell_\infty$. Our framework includes (i) a novel condition for well-posedness based on one-sided Lipschitz constants, (ii) an average iteration for computing fixed-points, and (iii) explicit estimates on input-output Lipschitz constants. Additionally, we design a training problem with the well-posedness condition and the average iteration as constraints and, to achieve robust models, with the input-output Lipschitz constant as a regularizer. Our $\ell_\infty$ well-posedness condition leads to a larger polytopic training search space than existing conditions and our average iteration enjoys accelerated convergence. Finally, we perform several numerical experiments for function estimation and digit classification through the MNIST data set. Our numerical results demonstrate improved accuracy and robustness of the implicit models with smaller input-output Lipschitz bounds.      
### 71.Using GANs to Augment Data for Cloud Image Segmentation Task  [ :arrow_down: ](https://arxiv.org/pdf/2106.03064.pdf)
>  While cloud/sky image segmentation has extensive real-world applications, a large amount of labelled data is needed to train a highly accurate models to perform the task. Scarcity of such volumes of cloud/sky images with corresponding ground-truth binary maps makes it highly difficult to train such complex image segmentation models. In this paper, we demonstrate the effectiveness of using Generative Adversarial Networks (GANs) to generate data to augment the training set in order to increase the prediction accuracy of image segmentation model. We further present a way to estimate ground-truth binary maps for the GAN-generated images to facilitate their effective use as augmented images. Finally, we validate our work with different statistical techniques.      
### 72.ScheduleNet: Learn to solve multi-agent scheduling problems with reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.03051.pdf)
>  We propose ScheduleNet, a RL-based real-time scheduler, that can solve various types of multi-agent scheduling problems. We formulate these problems as a semi-MDP with episodic reward (makespan) and learn ScheduleNet, a decentralized decision-making policy that can effectively coordinate multiple agents to complete tasks. The decision making procedure of ScheduleNet includes: (1) representing the state of a scheduling problem with the agent-task graph, (2) extracting node embeddings for agent and tasks nodes, the important relational information among agents and tasks, by employing the type-aware graph attention (TGA), and (3) computing the assignment probability with the computed node embeddings. We validate the effectiveness of ScheduleNet as a general learning-based scheduler for solving various types of multi-agent scheduling tasks, including multiple salesman traveling problem (mTSP) and job shop scheduling problem (JSP).      
### 73.Joint Design for Simultaneously Transmitting And Reflecting (STAR) RIS Assisted NOMA Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.03001.pdf)
>  Different from traditional reflection-only reconfigurable intelligent surfaces (RISs), simultaneously transmitting and reflecting RISs (STAR-RISs) represent a novel technology, which extends the \textit{half-space} coverage to \textit{full-space} coverage by simultaneously transmitting and reflecting incident signals. STAR-RISs provide new degrees-of-freedom (DoF) for manipulating signal propagation. Motivated by the above, a novel STAR-RIS assisted non-orthogonal multiple access (NOMA) (STAR-RIS-NOMA) system is proposed in this paper. Our objective is to maximize the achievable sum rate by jointly optimizing the decoding order, power allocation coefficients, active beamforming, and transmission and reflection beamforming. However, the formulated problem is non-convex with intricately coupled variables. To tackle this challenge, a suboptimal two-layer iterative algorithm is proposed. Specifically, in the inner-layer iteration, for a given decoding order, the power allocation coefficients, active beamforming, transmission and reflection beamforming are optimized alternatingly. For the outer-layer iteration, the decoding order of NOMA users in each cluster is updated with the solutions obtained from the inner-layer iteration. Moreover, an efficient decoding order determination scheme is proposed based on the equivalent-combined channel gains. Simulation results are provided to demonstrate that the proposed STAR-RSI-NOMA system, aided by our proposed algorithm, outperforms conventional RIS-NOMA and RIS assisted orthogonal multiple access (RIS-OMA) systems.      
### 74.About Digital Communication Methods for Visible Light Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.02996.pdf)
>  The visible light communication (VLC) by LED is one of the important communication methods because LED can work as high speed and VLC sends the information by high flushing LED. We use the pulse wave modulation for the VLC with LED because LED can be controlled easily by the microcontroller, which has the digital output pins. At the pulse wave modulation, deciding the high and low voltage by the middle voltage when the receiving signal level is amplified is equal to deciding it by the threshold voltage without amplification. In this paper, we proposed two methods that adjust the threshold value using counting the slot number and measuring the signal level. The number of signal slots is constant per one symbol when we use Pulse Position Modulation (PPM). If the number of received signal slots per one symbol time is less than the theoretical value, that means the threshold value is higher than the optimal value. If it is more than the theoretical value, that means the threshold value is lower. So, we can adjust the threshold value using the number of received signal slots. At the second proposed method, the average received signal level is not equal to the signal level because there is a ratio between the number of high slots and low slots. So, we can calculate the threshold value from the average received signal level and the slot ratio. We show these performances as real experiments.      
### 75.Distributed Task Allocation in Homogeneous Swarms Using Language Measure Theory  [ :arrow_down: ](https://arxiv.org/pdf/2106.02992.pdf)
>  In this paper, we present algorithms for synthesizing controllers to distribute a group (possibly swarms) of homogeneous robots (agents) over heterogeneous tasks which are operated in parallel. We present algorithms as well as analysis for global and local-feedback-based controller for the swarms. Using ergodicity property of irreducible Markov chains, we design a controller for global swarm control. Furthermore, to provide some degree of autonomy to the agents, we augment this global controller by a local feedback-based controller using Language measure theory. We provide analysis of the proposed algorithms to show their correctness. Numerical experiments are shown to illustrate the performance of the proposed algorithms.      
### 76.Lightweight Dual-channel Target Speaker Separation for Mobile Voice Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.02934.pdf)
>  Nowadays, there is a strong need to deploy the target speaker separation (TSS) model on mobile devices with a limitation of the model size and computational complexity. To better perform TSS for mobile voice communication, we first make a dual-channel dataset based on a specific scenario, LibriPhone. Specifically, to better mimic the real-case scenario, instead of simulating from the single-channel dataset, LibriPhone is made by simultaneously replaying pairs of utterances from LibriSpeech by two professional artificial heads and recording by two built-in microphones of the mobile. Then, we propose a lightweight time-frequency domain separation model, LSTM-Former, which is based on the LSTM framework with source-to-noise ratio (SI-SNR) loss. For the experiments on Libri-Phone, we explore the dual-channel LSTMFormer model and a single-channel version by a random single channel of Libri-Phone. Experimental result shows that the dual-channel LSTM-Former outperforms the single-channel LSTMFormer with relative 25% improvement. This work provides a feasible solution for the TSS task on mobile devices, playing back and recording multiple data sources in real application scenarios for getting dual-channel real data can assist the lightweight model to achieve higher performance.      
### 77.A Framework for Dynamic Optimal Next-Hop Selection and RF Interface Setting in IoT with the Same Source Requests  [ :arrow_down: ](https://arxiv.org/pdf/2106.02927.pdf)
>  Various applications of machines in Internet of Things (IoT) require different bandwidths. Each machine may choose its RF interface, according to required bandwidth for sending its data. We propose an optimal next-hop selection framework with dynamic RF interface settings for sources with same requested bandwidth. This framework enables machines to optimally select network devices with different RF equipment. In this way, the efficiency and correct use of RF network resources can be improved. The simulations show that, the average data rate of sources improved between 11.1% to 117% and the average unmatched source improved between 1.9% and 5.3%.      
### 78.Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping  [ :arrow_down: ](https://arxiv.org/pdf/2106.02892.pdf)
>  Graph neural networks (GNNs) are processing architectures that exploit graph structural information to model representations from network data. Despite their success, GNNs suffer from sub-optimal generalization performance given limited training data, referred to as over-fitting. This paper proposes Topology Adaptive Edge Dropping (TADropEdge) method as an adaptive data augmentation technique to improve generalization performance and learn robust GNN models. We start by explicitly analyzing how random edge dropping increases the data diversity during training, while indicating i.i.d. edge dropping does not account for graph structural information and could result in noisy augmented data degrading performance. To overcome this issue, we consider graph connectivity as the key property that captures graph topology. TADropEdge incorporates this factor into random edge dropping such that the edge-dropped subgraphs maintain similar topology as the underlying graph, yielding more satisfactory data augmentation. In particular, TADropEdge first leverages the graph spectrum to assign proper weights to graph edges, which represent their criticality for establishing the graph connectivity. It then normalizes the edge weights and drops graph edges adaptively based on their normalized weights. Besides improving generalization performance, TADropEdge reduces variance for efficient training and can be applied as a generic method modular to different GNN models. Intensive experiments on real-life and synthetic datasets corroborate theory and verify the effectiveness of the proposed method.      
### 79.Antenna Array Diagnosis for Millimeter-Wave MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.02862.pdf)
>  The densely packed antennas of millimeter-Wave (mmWave) MIMO systems are often blocked by the rain, snow, dust and even by fingers, which will change the channel's characteristics and degrades the system's performance. In order to solve this problem, we propose a cross-entropy inspired antenna array diagnosis detection (CE-AAD) technique by exploiting the correlations of adjacent antennas, when blockages occur at the transmitter. Then, we extend the proposed CE-AAD algorithm to the case, where blockages occur at transmitter and receiver simultaneously. Our simulation results show that the proposed CE-AAD algorithm outperforms its traditional counterparts.      
### 80.Trajectory Optimization of Chance-Constrained Nonlinear Stochastic Systems for Motion Planning and Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.02801.pdf)
>  We present gPC-SCP: Generalized Polynomial Chaos-based Sequential Convex Programming method to compute a sub-optimal solution for a continuous-time chance-constrained stochastic nonlinear optimal control problem (SNOC) problem. The approach enables motion planning and control of robotic systems under uncertainty. The proposed method involves two steps. The first step is to derive a deterministic nonlinear optimal control problem (DNOC) with convex constraints that are surrogate to the SNOC by using gPC expansion and the distributionally-robust convex subset of the chance constraints. The second step is to solve the DNOC problem using sequential convex programming (SCP) for trajectory generation and control. We prove that in the unconstrained case, the optimal value of the DNOC converges to that of SNOC asymptotically and that any feasible solution of the constrained DNOC is a feasible solution of the chance-constrained SNOC. We derive a stable stochastic model predictive controller using the gPC-SCP for tracking a trajectory in the presence of uncertainty. We empirically demonstrate the efficacy of the gPC-SCP method for the following three test cases: 1) collision checking under uncertainty in actuation, 2) collision checking with stochastic obstacle model, and 3) safe trajectory tracking under uncertainty in the dynamics and obstacle location by using a receding horizon control approach. We validate the effectiveness of the gPC-SCP method on the robotic spacecraft testbed.      
### 81.Subgroup Fairness in Two-Sided Markets  [ :arrow_down: ](https://arxiv.org/pdf/2106.02702.pdf)
>  It is well known that two-sided markets are unfair in a number of ways. For instance, female workers at Uber earn less than their male colleagues per mile driven. Similar observations have been made for other minority subgroups in other two-sided markets. Here, we suggest a novel market-clearing mechanism for two-sided markets, which promotes equalisation of the pay per hour worked across multiple subgroups, as well as within each subgroup. In the process, we introduce a novel notion of subgroup fairness (which we call Inter-fairness), which can be combined with other notions of fairness within each subgroup (called Intra-fairness), and the utility for the customers (Customer-Care) in the objective of the market-clearing problem. While the novel non-linear terms in the objective complicate market clearing by making the problem non-convex, we show that a certain non-convex augmented Lagrangian relaxation can be approximated to any precision in time polynomial in the number of market participants using semi-definite programming. This makes it possible to implement the market-clearing mechanism efficiently. On the example of driver-ride assignment in an Uber-like system, we demonstrate the efficacy and scalability of the approach, and trade-offs between Inter- and Intra-fairness.      
### 82.Robust Resource Allocation for Multi-Antenna URLLC-OFDMA Systems in a Smart Factory  [ :arrow_down: ](https://arxiv.org/pdf/2106.02670.pdf)
>  In this paper, we investigate the worst-case robust beamforming design and resource block (RB) assignment problem for total transmit power minimization of the central controller while guaranteeing each robot's transmission with target number of data bits and within required ultra-low latency and extremely high reliability. By using the property of the independence of each robot's beamformer design, we can obtain the equivalent power control design form of the original beamforming design. The binary RB mapping indicators are transformed into continuous ones with additional $\ell_0$-norm constraints to promote sparsity on each RB. A novel non-convex penalty (NCP) approach is applied to solve such $\ell_0$-norm constraints. Numerical results demonstrate the superiority of the NCP approach to the well-known reweighted $\ell_1$ method in terms of the optimized power consumption, convergence rate and robustness to channel realizations. Also, the impacts of latency, reliability, number of transmit antennas and channel uncertainty on the system performance are revealed.      

# ArXiv eess --Mon, 28 Jun 2021
### 1.A Time-domain Approach to the Design of Coupled-Resonator Microstrip Filters  [ :arrow_down: ](https://arxiv.org/pdf/2106.13737.pdf)
>  Coupled-resonator microstrip filters are among the most versatile filter topologies. A known design approach uses full-wave electromagnetic simulations to determine the coupling coefficient between resonators as a function of their relative position. This could be done using time-domain simulations using a fast Fourier transform (FFT) to extract the couplings from the S parameters obtained from time-domain signals. However, this approach has a poor performance in terms of resolution and specially for weak couplings, leading to unreasonably long simulation times. To overcome this, we introduce a technique to obtain the couplings directly from time signals, without moving to the frequency domain. This procedure works for strong and weak couplings, with much shorter simulation times and a reduced simulation domain over the FFT approach. This technique is used to design coupled resonator filter efficiently from time domain simulations. We implement this procedure using the finite-difference time-domain framework using an open source solver and discuss our implementation. We show that its results are very similar to previously published ones obtained from frequency domain simulations, even in the case of very weak couplings. Finally, we design and measure a filter to show the good performance of the proposed approach.      
### 2.Cybersecurity Challenges in Distributed Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.13712.pdf)
>  Cyber-physical systems are becoming core of the most modern systems consisting control, data sharing and real-time monitoring. While centralized control technique has been implemented in the past, recent innovation in distributed control schemes makes it attractive due to various reasons. One of them is the use of state-of-the-art communication protocols that makes the system more robust toward extreme conditions and ensures observability. Thus, as an application of cyber-physical systems, distributed control architectures are prone to various cyber-vulnerability which makes cybersecurity research critical in this application domain. This paper reviews recent researches of distributed control architectures, their cyber-vulnerabilities, and reported mitigation schemes. Finally, some research needs are addressed.      
### 3.A Fast Graph Kernel Based Classification Method for Wireless Link Scheduling on Riemannian Manifold  [ :arrow_down: ](https://arxiv.org/pdf/2106.13707.pdf)
>  In this paper, we propose a novel graph kernel method for the wireless link scheduling problem in device-to-device (D2D) networks on Riemannian manifold. The link scheduling problem can be considered as a binary classification problem since each D2D pair can only hold the state active or inactive. Our goal is to learn a novel metric that facilitates the design of an efficient but less computationally demanding machine learning (ML) solution for the binary classification task of link scheduling problem that requires no channel state information (CSI) and a fewer number of training samples as opposed to other benchmark ML algorithms. To this aim, we first represent the wireless D2D network as a graph and model the features of each D2D pair, including its communication and interference links, as regularized (i.e., positively-shifted) Laplacian matrices which are symmetric positive definite (SPD) one. By doing so, we represent the feature information of each D2D pair as a point on the SPD manifold, and we analyze the topology through Riemannian geometry. We compute the Riemannian metric, e.g., Log-Euclidean metric (LEM), which are suitable distance measures between the regularized Laplacian matrices. The LEM is then utilized to define a positive definite graph kernel for the binary classification of the link scheduling decisions. Simulation results demonstrate that the proposed graph Kernel-based method is computationally less demanding and achieves a sum rate of more than 95% of benchmark algorithm FPLinQ [1] for 10 D2D pairs without using CSI and less than a hundred training network layouts.      
### 4.Semantic annotation for computational pathology: Multidisciplinary experience and best practice recommendations  [ :arrow_down: ](https://arxiv.org/pdf/2106.13689.pdf)
>  Recent advances in whole slide imaging (WSI) technology have led to the development of a myriad of computer vision and artificial intelligence (AI) based diagnostic, prognostic, and predictive algorithms. Computational Pathology (CPath) offers an integrated solution to utilize information embedded in pathology WSIs beyond what we obtain through visual assessment. For automated analysis of WSIs and validation of machine learning (ML) models, annotations at the slide, tissue and cellular levels are required. The annotation of important visual constructs in pathology images is an important component of CPath projects. Improper annotations can result in algorithms which are hard to interpret and can potentially produce inaccurate and inconsistent results. Despite the crucial role of annotations in CPath projects, there are no well-defined guidelines or best practices on how annotations should be carried out. In this paper, we address this shortcoming by presenting the experience and best practices acquired during the execution of a large-scale annotation exercise involving a multidisciplinary team of pathologists, ML experts and researchers as part of the Pathology image data Lake for Analytics, Knowledge and Education (PathLAKE) consortium. We present a real-world case study along with examples of different types of annotations, diagnostic algorithm, annotation data dictionary and annotation constructs. The analyses reported in this work highlight best practice recommendations that can be used as annotation guidelines over the lifecycle of a CPath project.      
### 5.Video-Streaming Biomedical Implants using Ultrasonic Waves for Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.13655.pdf)
>  The use of wireless implanted medical devices (IMDs) is growing because they facilitate continuous monitoring of patients during normal activities, simplify medical procedures required for data retrieval and reduce the likelihood of infection associated with trailing wires. However, most of the state-of-the-art IMDs are passive and offline devices. One of the key obstacles to an active and online IMD is the infeasibility of real-time, high-quality video broadcast from the IMD. Such broadcast would help develop innovative devices such as a video-streaming capsule endoscopy (CE) pill with therapeutic intervention capabilities. State-of-the-art IMDs employ radio-frequency electromagnetic waves for information transmission. However, high attenuation of RF-EM waves in tissues and federal restrictions on the transmit power and operable bandwidth lead to fundamental performance constraints for IMDs employing RF links, and prevent achieving high data rates that could accomodate video broadcast. In this work, ultrasonic waves were used for video transmission and broadcast through biological tissues. The proposed proof-of-concept system was tested on a porcine intestine ex vivo and a rabbit in vivo. It was demonstrated that using a millimeter-sized, implanted biocompatible transducer operating at 1.1-1.2 MHz, it was possible to transmit endoscopic video with high resolution (1280 pixels by 720 pixels) through porcine intestine wrapped with bacon, and to broadcast standard definition (640 pixels by 480 pixels) video near real-time through rabbit abdomen in vivo. A media repository that includes experimental demonstrations and media files accompanies this paper. The accompanying media repository can be found at this link: <a class="link-external link-https" href="https://bit.ly/3wuc7tk" rel="external noopener nofollow">this https URL</a>.      
### 6.The Effect of Ground Truth Accuracy on the Evaluation of Localization Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13614.pdf)
>  The ability to accurately evaluate the performance of location determination systems is crucial for many applications. Typically, the performance of such systems is obtained by comparing ground truth locations with estimated locations. However, these ground truth locations are usually obtained by clicking on a map or using other worldwide available technologies like GPS. This introduces ground truth errors that are due to the marking process, map distortions, or inherent GPS inaccuracy. <br>In this paper, we present a theoretical framework for analyzing the effect of ground truth errors on the evaluation of localization systems. Based on that, we design two algorithms for computing the real algorithmic error from the validation error and marking/map ground truth errors, respectively. We further establish bounds on different performance metrics. <br>Validation of our theoretical assumptions and analysis using real data collected in a typical environment shows the ability of our theoretical framework to correct the estimated error of a localization algorithm in the presence of ground truth errors. Specifically, our marking error algorithm matches the real error CDF within 4%, and our map error algorithm provides a more accurate estimate of the median/tail error by 150%/72% when the map is shifted by 6m.      
### 7.A Novel Self-Learning Framework for Bladder Cancer Grading Using Histopathological Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.13559.pdf)
>  Recently, bladder cancer has been significantly increased in terms of incidence and mortality. Currently, two subtypes are known based on tumour growth: non-muscle invasive (NMIBC) and muscle-invasive bladder cancer (MIBC). In this work, we focus on the MIBC subtype because it is of the worst prognosis and can spread to adjacent organs. We present a self-learning framework to grade bladder cancer from histological images stained via immunohistochemical techniques. Specifically, we propose a novel Deep Convolutional Embedded Attention Clustering (DCEAC) which allows classifying histological patches into different severity levels of the disease, according to the patterns established in the literature. The proposed DCEAC model follows a two-step fully unsupervised learning methodology to discern between non-tumour, mild and infiltrative patterns from high-resolution samples of 512x512 pixels. Our system outperforms previous clustering-based methods by including a convolutional attention module, which allows refining the features of the latent space before the classification stage. The proposed network exceeds state-of-the-art approaches by 2-3% across different metrics, achieving a final average accuracy of 0.9034 in a multi-class scenario. Furthermore, the reported class activation maps evidence that our model is able to learn by itself the same patterns that clinicians consider relevant, without incurring prior annotation steps. This fact supposes a breakthrough in muscle-invasive bladder cancer grading which bridges the gap with respect to train the model on labelled data.      
### 8.Effects of current limit for grid forming converters on transient stability: analysis and solution  [ :arrow_down: ](https://arxiv.org/pdf/2106.13555.pdf)
>  Grid forming control applied to power converters that interface storage or renewable generation to the power grid, has been identified as a potential solution to facilitate a substantial share of converter-based renewable generation in the power system. Analyzing the response of grid forming converters (GFC) for large frequency, phase, and voltage events, particularly when the GFC enters the current limit operation, is very important for system stability, but studies on this have been limited. This paper presents a quantitative and illustrative analysis of the impact of the current limit in GFC on the transient stability of a system comprising of GFC. Furthermore, a solution based on virtual active power is proposed to improve the transient stability margin of the GFC when the GFC enters the current limit. Finally, the analysis and the proposed method to enhance the transient stability are verified by Power hardware in the loop (PHIL) experimental tests.      
### 9.Circumpapillary OCT-Focused Hybrid Learning for Glaucoma Grading Using Tailored Prototypical Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.13551.pdf)
>  Glaucoma is one of the leading causes of blindness worldwide and Optical Coherence Tomography (OCT) is the quintessential imaging technique for its detection. Unlike most of the state-of-the-art studies focused on glaucoma detection, in this paper, we propose, for the first time, a novel framework for glaucoma grading using raw circumpapillary B-scans. In particular, we set out a new OCT-based hybrid network which combines hand-driven and deep learning algorithms. An OCT-specific descriptor is proposed to extract hand-crafted features related to the retinal nerve fibre layer (RNFL). In parallel, an innovative CNN is developed using skip-connections to include tailored residual and attention modules to refine the automatic features of the latent space. The proposed architecture is used as a backbone to conduct a novel few-shot learning based on static and dynamic prototypical networks. The k-shot paradigm is redefined giving rise to a supervised end-to-end system which provides substantial improvements discriminating between healthy, early and advanced glaucoma samples. The training and evaluation processes of the dynamic prototypical network are addressed from two fused databases acquired via Heidelberg Spectralis system. Validation and testing results reach a categorical accuracy of 0.9459 and 0.8788 for glaucoma grading, respectively. Besides, the high performance reported by the proposed model for glaucoma detection deserves a special mention. The findings from the class activation maps are directly in line with the clinicians' opinion since the heatmaps pointed out the RNFL as the most relevant structure for glaucoma diagnosis.      
### 10.An Error-Based Approximation Sensing Circuit for Event-Triggered, Low Power Wearable Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2106.13545.pdf)
>  Event-based sensors have the potential to optimize energy consumption at every stage in the signal processing pipeline, including data acquisition, transmission, processing and storage. However, almost all state-of-the-art systems are still built upon the classical Nyquist-based periodic signal acquisition. In this work, we design and validate the Polygonal Approximation Sampler (PAS), a novel circuit to implement a general-purpose event-based sampler using a polygonal approximation algorithm as the underlying sampling trigger. The circuit can be dynamically reconfigured to produce a coarse or a detailed reconstruction of the analog input, by adjusting the error threshold of the approximation. The proposed circuit is designed at the Register Transfer Level and processes each input sample received from the ADC in a single clock cycle. The PAS has been tested with three different types of archetypal signals captured by wearable devices (electrocardiogram, accelerometer and respiration data) and compared with a standard periodic ADC. These tests show that single-channel signals, with slow variations and constant segments (like the used single-lead ECG and the respiration signals) take great advantage from the used sampling technique, reducing the amount of data used up to 99% without significant performance degradation. At the same time, multi-channel signals (like the six-dimensional accelerometer signal) can still benefit from the designed circuit, achieving a reduction factor up to 80% with minor performance degradation. These results open the door to new types of wearable sensors with reduced size and higher battery lifetime.      
### 11.Compactification of the Rigid Motions Group in Image Processing  [ :arrow_down: ](https://arxiv.org/pdf/2106.13505.pdf)
>  Image processing problems in general, and in particular in the field of single-particle cryo-electron microscopy, often require considering images up to their rotations and translations. Such problems were tackled successfully when considering images up to rotations only, using quantities which are invariant to the action of rotations on images. Extending these methods to cases where translations are involved is more complicated. Here we present a computationally feasible and theoretically sound approximate invariant to the action of rotations and translations on images. It allows one to approximately reduce image processing problems to similar problems over the sphere, a compact domain acted on by the group of 3D rotations, a compact group. We show that this invariant is induced by a family of mappings deforming, and thereby compactifying, the group structure of rotations and translations of the plane, i.e., the group of rigid motions, into the group of 3D rotations. Furthermore, we demonstrate its viability in two image processing tasks: multi-reference alignment and classification. To our knowledge, this is the first instance of a quantity that is either exactly or approximately invariant to rotations and translations of images that both rests on a sound theoretical foundation and also applicable in practice.      
### 12.Online Self-Attentive Gated RNNs for Real-Time Speaker Separation  [ :arrow_down: ](https://arxiv.org/pdf/2106.13493.pdf)
>  Deep neural networks have recently shown great success in the task of blind source separation, both under monaural and binaural settings. Although these methods were shown to produce high-quality separations, they were mainly applied under offline settings, in which the model has access to the full input signal while separating the signal. In this study, we convert a non-causal state-of-the-art separation model into a causal and real-time model and evaluate its performance under both online and offline settings. We compare the performance of the proposed model to several baseline methods under anechoic, noisy, and noisy-reverberant recording conditions while exploring both monaural and binaural inputs and outputs. Our findings shed light on the relative difference between causal and non-causal models when performing separation. Our stateful implementation for online separation leads to a minor drop in performance compared to the offline model; 0.8dB for monaural inputs and 0.3dB for binaural inputs while reaching a real-time factor of 0.65. Samples can be found under the following link: <a class="link-external link-https" href="https://kwanum.github.io/sagrnnc-stream-results/" rel="external noopener nofollow">this https URL</a>.      
### 13.Resonant Beam Communications with Echo Interference Elimination  [ :arrow_down: ](https://arxiv.org/pdf/2106.13480.pdf)
>  Resonant beam communications (RBCom) is capable of providing wide bandwidth when using light as the carrier. Besides, the RBCom system possesses the characteristics of mobility, high signal-to-noise ratio (SNR), and multiplexing. Nevertheless, the channel of the RBCom system is distinct from other light communication technologies due to the echo interference issue. In this paper, we reveal the mechanism of the echo interference and propose the method to eliminate the interference. Moreover, we present an exemplary design based on frequency shifting and optical filtering, along with its mathematic model and performance analysis. The numerical evaluation shows that the channel capacity is greater than 15 bit/s/Hz.      
### 14.Detectability Conditions and State Estimation for Linear Time-Varying and Nonlinear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13461.pdf)
>  This work proposes a detectability condition for linear time-varying systems based on the exponential dichotomy spectrum. The condition guarantees the existence of an observer, whose gain is determined only by the unstable modes of the system. This allows for an observer design with low computational complexity compared to classical estimation approaches. An extension of this observer design to a class of nonlinear systems is proposed and local convergence of the corresponding estimation error dynamics is proven. Numerical results show the efficacy of the proposed observer design technique.      
### 15.A Computationally Efficient Hamilton-Jacobi-based Formula for State-Constrained Optimal Control Problems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13440.pdf)
>  This paper investigates a Hamilton-Jacobi (HJ) analysis to solve finite-horizon optimal control problems for high-dimensional systems. Although grid-based methods, such as the level-set method [1], numerically solve a general class of HJ partial differential equations, the computational complexity is exponential in the dimension of the continuous state. To manage this computational complexity, methods based on Lax-Hopf theory have been developed for the state-unconstrained optimal control problem under certain assumptions, such as affine dynamics and state-independent stage cost. Based on the Lax formula [2], this paper proposes an HJ formula for the state-constrained optimal control problem for nonlinear systems. We call this formula \textit{the generalized Lax formula} for the optimal control problem. The HJ formula provides both the optimal cost and an optimal control signal. We also provide an efficient computational method for a class of problems for which the dynamics is affine in the state, and for which the stage and terminal cost, as well as the state constraints, are convex in the state. This class of problems does not require affine dynamics and convex stage cost in the control. This paper also provides three practical examples.      
### 16.Distributed Nash Equilibrium Seeking Algorithm Design for Multi-Cluster Games with High-Order Players  [ :arrow_down: ](https://arxiv.org/pdf/2106.13369.pdf)
>  In this paper, a multi-cluster game with high-order players is investigated. Different from the well-known multi-cluster games, the dynamics of players are taken into account in our problem. Due to the high-order dynamics of players, existing algorithms for multi-cluster games cannot solve the problem. For purpose of seeking the Nash equilibrium of the game, we design a distributed algorithm based on gradient descent and state feedback, where a distributed estimator is embedded for the players to estimate the decisions of other players. Furthermore, we analyze the exponential convergence of the algorithm via variational analysis and Lyapunov stability theory. Finally, a numerical simulation verifies the effectiveness of our method.      
### 17.FOVQA: Blind Foveated Video Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2106.13328.pdf)
>  Previous blind or No Reference (NR) video quality assessment (VQA) models largely rely on features drawn from natural scene statistics (NSS), but under the assumption that the image statistics are stationary in the spatial domain. Several of these models are quite successful on standard pictures. However, in Virtual Reality (VR) applications, foveated video compression is regaining attention, and the concept of space-variant quality assessment is of interest, given the availability of increasingly high spatial and temporal resolution contents and practical ways of measuring gaze direction. Distortions from foveated video compression increase with increased eccentricity, implying that the natural scene statistics are space-variant. Towards advancing the development of foveated compression / streaming algorithms, we have devised a no-reference (NR) foveated video quality assessment model, called FOVQA, which is based on new models of space-variant natural scene statistics (NSS) and natural video statistics (NVS). Specifically, we deploy a space-variant generalized Gaussian distribution (SV-GGD) model and a space-variant asynchronous generalized Gaussian distribution (SV-AGGD) model of mean subtracted contrast normalized (MSCN) coefficients and products of neighboring MSCN coefficients, respectively. We devise a foveated video quality predictor that extracts radial basis features, and other features that capture perceptually annoying rapid quality fall-offs. We find that FOVQA achieves state-of-the-art (SOTA) performance on the new 2D LIVE-FBT-FCVR database, as compared with other leading FIQA / VQA models. we have made our implementation of FOVQA available at: <a class="link-external link-http" href="http://live.ece.utexas.edu/research/Quality/FOVQA.zip" rel="external noopener nofollow">this http URL</a>.      
### 18.Generalized Unsupervised Clustering of Hyperspectral Images of Geological Targets in the Near Infrared  [ :arrow_down: ](https://arxiv.org/pdf/2106.13315.pdf)
>  The application of infrared hyperspectral imagery to geological problems is becoming more popular as data become more accessible and cost-effective. Clustering and classifying spectrally similar materials is often a first step in applications ranging from economic mineral exploration on Earth to planetary exploration on Mars. Semi-manual classification guided by expertly developed spectral parameters can be time consuming and biased, while supervised methods require abundant labeled data and can be difficult to generalize. Here we develop a fully unsupervised workflow for feature extraction and clustering informed by both expert spectral geologist input and quantitative metrics. Our pipeline uses a lightweight autoencoder followed by Gaussian mixture modeling to map the spectral diversity within any image. We validate the performance of our pipeline at submillimeter-scale with expert-labelled data from the Oman ophiolite drill core and evaluate performance at meters-scale with partially classified orbital data of Jezero Crater on Mars (the landing site for the Perseverance rover). We additionally examine the effects of various preprocessing techniques used in traditional analysis of hyperspectral imagery. This pipeline provides a fast and accurate clustering map of similar geological materials and consistently identifies and separates major mineral classes in both laboratory imagery and remote sensing imagery. We refer to our pipeline as "Generalized Pipeline for Spectroscopic Unsupervised clustering of Minerals (GyPSUM)."      
### 19.Coordinated Scheduling of Electric Vehicles Within Zero Carbon Emission Hybrid AC/DC Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2106.13291.pdf)
>  Microgrids with AC/DC architecture benefit from advantages of both AC and DC power. In this paper, daily operation problem for a zero-carbon AC/DC microgrid in presence of electric vehicles (EVs) is considered. In this framework, EVs' batteries are mobile energy storage systems, which allow desirable operation of the microgrid during peak demand hours. This study shows in absence of storage system, EVs' batteries can be properly managed to satisfy the system requirements. In the case studies, several sensitivity analyses based on variations in battery degradation costs, solar irradiance, and inverter capacity are investigated.      
### 20.The H2-optimal Control Problem of CSVIU Systems: Discounted, Counter-discounted and Long-run Solutions -- Part II: Optimal Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.13806.pdf)
>  The paper deals with stochastic control problems associated with $H_2$ performance indices such as energy or power norms or energy measurements when norms are not defined. They apply to a class of systems for which a stochastic process conveys the underlying uncertainties, known as CSVIU (Control and State Variation Increase Uncertainty). These indices allow various emphases from focusing on the transient behavior with the discounted norm to stricter conditions on stability, steady-state mean-square error and convergence rate, using the optimal overtaking criterion -- the long-run average power control stands as a midpoint in this respect. A critical advance regards the explicit form of the optimal control law, expressed in two equivalent forms. One takes a perturbed affine Riccati-like form of feedback solution; the other comes from a generalized normal equation that arises from the nondifferentiable local optimal problem. They are equivalent, but the latter allows for a search method to attain the optimal law. A detectability notion and a Riccati solution grant stochastic stability from the behavior of the norms. The energy overtaking criterion requires a further constraint on a matrix spectral radius. With these findings, the paper revisits the emerging of the inaction solution, a prominent feature of CSVIU models to deal with the uncertainty inherent to poorly known models. Besides, it provides the optimal solution and the tools to pursue it.      
### 21.The H2-optimal Control Problem of CSVIU Systems: Discounted, Counter-discounted and Long-Run Solutions -- Part I: The Norm  [ :arrow_down: ](https://arxiv.org/pdf/2106.13801.pdf)
>  The paper deals with the H2-norm and associated energy or power measurements for a class of processes known as CSVIU (Control and State Variation Increase Uncertainty). These are system models for which a stochastic process conveys the underlying uncertainties, and are able to give rise to cautious controls. The paper delves into the non-controlled version and fundamental system and norms notions associated with stochastic stability and mean-square convergence. One pillar of the study is the connection between the finiteness of one of these norms or a limited energy measurement growth with the corresponding stochastic stability notions. A detectability concept ties these notions, and the analysis of linear-positive operators plays a fundamental role. The introduction of various H2-norms and energy measurement performance criteria allows one to span the focus from transient to long-run behavior. As the discount parameter turns into a counter-discount, the criteria enforce stricter requirements on the second-moment steady state errors and on the exponential convergence rate. A tidy connection among this H2-performance measures cast employs a unifying vanishing discount reasoning.      
### 22.Voice Activity Detection for Transient Noisy Environment Based on Diffusion Nets  [ :arrow_down: ](https://arxiv.org/pdf/2106.13763.pdf)
>  We address voice activity detection in acoustic environments of transients and stationary noises, which often occur in real life scenarios. We exploit unique spatial patterns of speech and non-speech audio frames by independently learning their underlying geometric structure. This process is done through a deep encoder-decoder based neural network architecture. This structure involves an encoder that maps spectral features with temporal information to their low-dimensional representations, which are generated by applying the diffusion maps method. The encoder feeds a decoder that maps the embedded data back into the high-dimensional space. A deep neural network, which is trained to separate speech from non-speech frames, is obtained by concatenating the decoder to the encoder, resembling the known Diffusion nets architecture. Experimental results show enhanced performance compared to competing voice activity detection methods. The improvement is achieved in both accuracy, robustness and generalization ability. Our model performs in a real-time manner and can be integrated into audio-based communication systems. We also present a batch algorithm which obtains an even higher accuracy for off-line applications.      
### 23.Nonlinear Acoustic Echo Cancellation with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.13754.pdf)
>  We propose a nonlinear acoustic echo cancellation system, which aims to model the echo path from the far-end signal to the near-end microphone in two parts. Inspired by the physical behavior of modern hands-free devices, we first introduce a novel neural network architecture that is specifically designed to model the nonlinear distortions these devices induce between receiving and playing the far-end signal. To account for variations between devices, we construct this network with trainable memory length and nonlinear activation functions that are not parameterized in advance, but are rather optimized during the training stage using the training data. Second, the network is succeeded by a standard adaptive linear filter that constantly tracks the echo path between the loudspeaker output and the microphone. During training, the network and filter are jointly optimized to learn the network parameters. This system requires 17 thousand parameters that consume 500 Million floating-point operations per second and 40 Kilo-bytes of memory. It also satisfies hands-free communication timing requirements on a standard neural processor, which renders it adequate for embedding on hands-free communication devices. Using 280 hours of real and synthetic data, experiments show advantageous performance compared to competing methods.      
### 24.Cross-Modal Knowledge Distillation Method for Automatic Cued Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.13686.pdf)
>  Cued Speech (CS) is a visual communication system for the deaf or hearing impaired people. It combines lip movements with hand cues to obtain a complete phonetic repertoire. Current deep learning based methods on automatic CS recognition suffer from a common problem, which is the data scarcity. Until now, there are only two public single speaker datasets for French (238 sentences) and British English (97 sentences). In this work, we propose a cross-modal knowledge distillation method with teacher-student structure, which transfers audio speech information to CS to overcome the limited data problem. Firstly, we pretrain a teacher model for CS recognition with a large amount of open source audio speech data, and simultaneously pretrain the feature extractors for lips and hands using CS data. Then, we distill the knowledge from teacher model to the student model with frame-level and sequence-level distillation strategies. Importantly, for frame-level, we exploit multi-task learning to weigh losses automatically, to obtain the balance coefficient. Besides, we establish a five-speaker British English CS dataset for the first time. The proposed method is evaluated on French and British English CS datasets, showing superior CS recognition performance to the state-of-the-art (SOTA) by a large margin.      
### 25.Multi-player Multi-armed Bandits with Collision-Dependent Reward Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2106.13669.pdf)
>  We study a new stochastic multi-player multi-armed bandits (MP-MAB) problem, where the reward distribution changes if a collision occurs on the arm. Existing literature always assumes a zero reward for involved players if collision happens, but for applications such as cognitive radio, the more realistic scenario is that collision reduces the mean reward but not necessarily to zero. We focus on the more practical no-sensing setting where players do not perceive collisions directly, and propose the Error-Correction Collision Communication (EC3) algorithm that models implicit communication as a reliable communication over noisy channel problem, for which random coding error exponent is used to establish the optimal regret that no communication protocol can beat. Finally, optimizing the tradeoff between code length and decoding error rate leads to a regret that approaches the centralized MP-MAB regret, which represents a natural lower bound. Experiments with practical error-correction codes on both synthetic and real-world datasets demonstrate the superiority of EC3. In particular, the results show that the choice of coding schemes has a profound impact on the regret performance.      
### 26.Transient Stability Analysis with Physics-Informed Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.13638.pdf)
>  Solving the ordinary differential equations that govern the power system is an indispensable part in transient stability analysis. However, the traditionally applied methods either carry a significant computational burden, require model simplifications, or use overly conservative surrogate models. Neural networks can circumvent these limitations but are faced with high demands on the used datasets. Furthermore, they are agnostic to the underlying governing equations. Physics-informed neural network tackle this problem and we explore their advantages and challenges in this paper. We illustrate the findings on the Kundur two-area system and highlight possible pathways forward in developing this method further.      
### 27.Boundary Output Feedback Stabilization of Reaction-Diffusion PDEs with Delayed Boundary Measurement  [ :arrow_down: ](https://arxiv.org/pdf/2106.13637.pdf)
>  This paper addresses the boundary output feedback stabilization of general 1-D reaction-diffusion PDEs with delayed boundary measurement. The output takes the form of a either Dirichlet or Neumann trace. The output delay can be arbitrarily large. The control strategy is composed of a finite-dimensional observer that is used to observe a delayed version of the first modes of the PDE and a predictor component which is employed to obtain the control input to be applied at current time. For any given value of the output delay, we assess the stability of the resulting closed-loop system provided the order of the observer is selected large enough. Taking advantage of this result, we discuss the extension of the control strategy to the case of simultaneous input and output delays.      
### 28.$\mathcal{N}$IPM-HLSP: An Efficient Interior-Point Method for Hierarchical Least-Squares Programs  [ :arrow_down: ](https://arxiv.org/pdf/2106.13602.pdf)
>  Hierarchical least-squares programs with linear constraints (HLSP) are a type of optimization problem very common in robotics. Each priority level contains an objective in least-squares form which is subject to the linear constraints of the higher priority hierarchy levels. Active-set methods (ASM) are a popular choice for solving them. However, they can perform poorly in terms of computational time if there are large changes of the active set. We therefore propose a computationally efficient primal-dual interior-point method (IPM) for HLSP's which is able to maintain constant numbers of solver iterations in these situations. We base our IPM on the null-space method which requires only a single decomposition per Newton iteration instead of two as it is the case for other IPM solvers. After a priority level has converged we compose a set of active constraints judging upon the dual and project lower priority levels into their null-space. We show that the IPM-HLSP can be expressed in least-squares form which avoids the formation of the quadratic Karush-Kuhn-Tucker (KKT) Hessian. Due to our choice of the null-space basis the IPM-HLSP is as fast as the state-of-the-art ASM-HLSP solver for equality only problems.      
### 29.A Method of Predicting Powder Flowability for Selective Laser Sintering  [ :arrow_down: ](https://arxiv.org/pdf/2106.13568.pdf)
>  This work investigates a method for pre-screening material systems for Selective Laser Sintering (SLS) using a combination of Revolution Powder Analysis (RPA) and machine learning. To develop this method, nylon was mixed with alumina or carbon fibers in different wt.% to form material systems with varying flowability. The materials were measured in a custom RPA device and the results compared with as-spread layer density and surface roughness. Machine learning was used to attempt classification of all powders for each method. Ultimately, it was found that the RPA method is able to reliably classify powders based on their flowability, but as-spread layer density and surface roughness were not able to be classified.      
### 30.Beam Alignment in mmWave User-Centric Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13538.pdf)
>  The problem of beam alignment (BA) in a cell-free massive multiple-input multiple-output (CF-mMIMO) system operating at millimeter wave (mmWaves) carrier frequencies is considered in this paper. Two estimation algorithms are proposed, in association with a protocol that permits simultaneous estimation, on a shared set of frequencies, for each user equipment (UE), of the direction of arrival and departure of the radio waves associated to the strongest propagation paths from each of the surrounding access points (APs), so that UE-AP association can take place. The proposed procedure relies on the existence of a reliable control channel at sub-6 GHz frequency, so as to enable exchange of estimated values between the UEs and the network, and assumes that APs can be identifies based on the prior knowledge of the orthogonal channels and transmit beamforming codebook. A strategy for assigning codebook entries to the several APs is also proposed, with the aim of minimizing the mutual interference between APs that are assigned the same entry. Numerical results show the effectiveness of the proposed detection strategy, thus enabling one shot fast BA for CF-mMIMO systems.      
### 31.Deep Residual Echo Suppression with A Tunable Tradeoff Between Signal Distortion and Echo Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2106.13531.pdf)
>  In this paper, we propose a residual echo suppression method using a UNet neural network that directly maps the outputs of a linear acoustic echo canceler to the desired signal in the spectral domain. This system embeds a design parameter that allows a tunable tradeoff between the desired-signal distortion and residual echo suppression in double-talk scenarios. The system employs 136 thousand parameters, and requires 1.6 Giga floating-point operations per second and 10 Mega-bytes of memory. The implementation satisfies both the timing requirements of the AEC challenge and the computational and memory limitations of on-device applications. Experiments are conducted with 161~h of data from the AEC challenge database and from real independent recordings. We demonstrate the performance of the proposed system in real-life conditions and compare it with two competing methods regarding echo suppression and desired-signal distortion, generalization to various environments, and robustness to high echo levels.      
### 32.Navigating A Mobile Robot Using Switching Distributed Sensor Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.13529.pdf)
>  This paper proposes a method to navigate a mobile robot by estimating its state over a number of distributed sensor networks (DSNs) such that it can successively accomplish a sequence of tasks, i.e., its state enters each targeted set and stays inside no less than the desired time, under a resource-aware, time-efficient, and computation- and communication-constrained setting.We propose a new robot state estimation and navigation architecture, which integrates an event-triggered task-switching feedback controller for the robot and a two-time-scale distributed state estimator for each sensor. The architecture has three major advantages over existing approaches: First, in each task only one DSN is active for sensing and estimating the robot state, and for different tasks the robot can switch the active DSN by taking resource saving and system performance into account; Second, the robot only needs to communicate with one active sensor at each time to obtain its state information from the active DSN; Third, no online optimization is required. With the controller, the robot is able to accomplish a task by following a reference trajectory and switch to the next task when an event-triggered condition is fulfilled. With the estimator, each active sensor is able to estimate the robot state. Under proper conditions, we prove that the state estimation error and the trajectory tracking deviation are upper bounded by two time-varying sequences respectively, which play an essential role in the event-triggered condition. Furthermore, we find a sufficient condition for accomplishing a task and provide an upper bound of running time for the task. Numerical simulations of an indoor robot's localization and navigation are provided to validate the proposed architecture.      
### 33.Phoneme-aware and Channel-wise Attentive Learning for Text DependentSpeaker Verification  [ :arrow_down: ](https://arxiv.org/pdf/2106.13514.pdf)
>  This paper proposes a multi-task learning network with phoneme-aware and channel-wise attentive learning strategies for text-dependent Speaker Verification (SV). In the proposed structure, the frame-level multi-task learning along with the segment-level adversarial learning is adopted for speaker embedding extraction. The phoneme-aware attentive pooling is exploited on frame-level features in the main network for speaker classifier, with the corresponding posterior probability for the phoneme distribution in the auxiliary subnet. Further, the introduction of Squeeze and Excitation (SE-block) performs dynamic channel-wise feature recalibration, which improves the representational ability. The proposed method exploits speaker idiosyncrasies associated with pass-phrases, and is further improved by the phoneme-aware attentive pooling and SE-block from temporal and channel-wise aspects, respectively. The experiments conducted on RSR2015 Part 1 database confirm that the proposed system achieves outstanding results for textdependent SV.      
### 34.Evaluation of Deep-Learning-Based Voice Activity Detectors and Room Impulse Response Models in Reverberant Environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.13511.pdf)
>  State-of-the-art deep-learning-based voice activity detectors (VADs) are often trained with anechoic data. However, real acoustic environments are generally reverberant, which causes the performance to significantly deteriorate. To mitigate this mismatch between training data and real data, we simulate an augmented training set that contains nearly five million utterances. This extension comprises of anechoic utterances and their reverberant modifications, generated by convolutions of the anechoic utterances with a variety of room impulse responses (RIRs). We consider five different models to generate RIRs, and five different VADs that are trained with the augmented training set. We test all trained systems in three different real reverberant environments. Experimental results show $20\%$ increase on average in accuracy, precision and recall for all detectors and response models, compared to anechoic training. Furthermore, one of the RIR models consistently yields better performance than the other models, for all the tested VADs. Additionally, one of the VADs consistently outperformed the other VADs in all experiments.      
### 35.Pilot Contamination Elimination for Channel Estimation with Complete Knowledge of Large-Scale Fading in Downlink Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13507.pdf)
>  Massive multiple-input multiple-output is a very important technology for future fifth-generation systems. However, massive massive multiple input multiple output systems are still limited because of pilot contamination, impacting the data rate due to the non-orthogonality of pilot sequences transmitted by users in the same cell to the neighboring cells. We propose a channel estimation with complete knowledge of large-scale fading by using an orthogonal pilot reuse sequence to eliminate PC in edge users with poor channel quality based on the estimation of large-scale fading and performance analysis of maximum ratio transmission and zero forcing precoding methods. We derived the lower bounds on the achievable downlink DR and signal-to-interference noise ratio based on assigning PRS to a user grouping that mitigated this problem when the number of antenna elements approaches infinity The simulation results showed that a high DR can be achieved due to better channel estimation and reduced performance loss      
### 36.Data-based Design of Inferential Sensors for Petrochemical Industry  [ :arrow_down: ](https://arxiv.org/pdf/2106.13503.pdf)
>  Inferential (or soft) sensors are used in industry to infer the values of imprecisely and rarely measured (or completely unmeasured) variables from variables measured online (e.g., pressures, temperatures). The main challenge, akin to classical model overfitting, in designing an effective inferential sensor is the selection of a correct structure of the sensor. The sensor structure is represented by the number of inputs to the sensor, which correspond to the variables measured online and their (simple) combinations. This work is focused on the design of inferential sensors for product composition of an industrial distillation column in two oil refinery units, a Fluid Catalytic Cracking unit and a Vacuum Gasoil Hydrogenation unit. As the first design step, we use several well-known data pre-treatment (gross error detection) methods and compare the ability of these approaches to indicate systematic errors and outliers in the available industrial data. We then study effectiveness of various methods for design of the inferential sensors taking into account the complexity and accuracy of the resulting model. The effectiveness analysis indicates that the improvements achieved over the current inferential sensors are up to 19 %.      
### 37.Non-Parametric Neuro-Adaptive Control Subject to Task Specifications  [ :arrow_down: ](https://arxiv.org/pdf/2106.13498.pdf)
>  We develop a learning-based algorithm for the control of robotic systems governed by unknown, nonlinear dynamics to satisfy tasks expressed as signal temporal logic specifications. Most existing algorithms either assume certain parametric forms for the dynamic terms or resort to unnecessarily large control inputs (e.g., using reciprocal functions) in order to provide theoretical guarantees. The proposed algorithm avoids the aforementioned drawbacks by innovatively integrating neural network-based learning with adaptive control. More specifically, the algorithm learns a controller, represented as a neural network, using training data that correspond to a collection of different tasks and robot parameters. It then incorporates this neural network into an online closed-loop adaptive control mechanism in such a way that the resulting behavior satisfies a user-defined task. The proposed algorithm does not use any information on the unknown dynamic terms or any approximation schemes. We provide formal theoretical guarantees on the satisfaction of the task and we demonstrate the effectiveness of the algorithm in a virtual simulator using a 6-DOF robotic manipulator.      
### 38.Preliminary study on using vector quantization latent spaces for TTS/VC systems with consistent performance  [ :arrow_down: ](https://arxiv.org/pdf/2106.13479.pdf)
>  Generally speaking, the main objective when training a neural speech synthesis system is to synthesize natural and expressive speech from the output layer of the neural network without much attention given to the hidden layers. However, by learning useful latent representation, the system can be used for many more practical scenarios. In this paper, we investigate the use of quantized vectors to model the latent linguistic embedding and compare it with the continuous counterpart. By enforcing different policies over the latent spaces in the training, we are able to obtain a latent linguistic embedding that takes on different properties while having a similar performance in terms of quality and speaker similarity. Our experiments show that the voice cloning system built with vector quantization has only a small degradation in terms of perceptive evaluations, but has a discrete latent space that is useful for reducing the representation bit-rate, which is desirable for data transferring, or limiting the information leaking, which is important for speaker anonymization and other tasks of that nature.      
### 39.An Edge Computing Paradigm for Massive IoT Connectivity over High-Altitude Platform Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.13476.pdf)
>  With the advent of the Internet-of-Things (IoT) era, the ever-increasing number of devices and emerging applications have triggered the need for ubiquitous connectivity and more efficient computing paradigms. These stringent demands have posed significant challenges to the current wireless networks and their computing architectures. In this article, we propose a high-altitude platform (HAP) network-enabled edge computing paradigm to tackle the key issues of massive IoT connectivity. Specifically, we first provide a comprehensive overview of the recent advances in non-terrestrial network-based edge computing architectures. Then, the limitations of the existing solutions are further summarized from the perspectives of the network architecture, random access procedure, and multiple access techniques. To overcome the limitations, we propose a HAP-enabled aerial cell-free massive multiple-input multiple-output network to realize the edge computing paradigm, where multiple HAPs cooperate via the edge servers to serve IoT devices. For the case of a massive number of devices, we further adopt a grant-free massive access scheme to guarantee low-latency and high-efficiency massive IoT connectivity to the network. Besides, a case study is provided to demonstrate the effectiveness of the proposed solution. Finally, to shed light on the future research directions of HAP network-enabled edge computing paradigms, the key challenges and open issues are discussed.      
### 40.A hybrid model-based and learning-based approach for classification using limited number of training samples  [ :arrow_down: ](https://arxiv.org/pdf/2106.13436.pdf)
>  The fundamental task of classification given a limited number of training data samples is considered for physical systems with known parametric statistical models. The standalone learning-based and statistical model-based classifiers face major challenges towards the fulfillment of the classification task using a small training set. Specifically, classifiers that solely rely on the physics-based statistical models usually suffer from their inability to properly tune the underlying unobservable parameters, which leads to a mismatched representation of the system's behaviors. Learning-based classifiers, on the other hand, typically rely on a large number of training data from the underlying physical process, which might not be feasible in most practical scenarios. In this paper, a hybrid classification method -- termed HyPhyLearn -- is proposed that exploits both the physics-based statistical models and the learning-based classifiers. The proposed solution is based on the conjecture that HyPhyLearn would alleviate the challenges associated with the individual approaches of learning-based and statistical model-based classifiers by fusing their respective strengths. The proposed hybrid approach first estimates the unobservable model parameters using the available (suboptimal) statistical estimation procedures, and subsequently use the physics-based statistical models to generate synthetic data. Then, the training data samples are incorporated with the synthetic data in a learning-based classifier that is based on domain-adversarial training of neural networks. Specifically, in order to address the mismatch problem, the classifier learns a mapping from the training data and the synthetic data to a common feature space. Simultaneously, the classifier is trained to find discriminative features within this space in order to fulfill the classification task.      
### 41.Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2106.13419.pdf)
>  Recent studies have shown that neural vocoders based on generative adversarial network (GAN) can generate audios with high quality. While GAN based neural vocoders have shown to be computationally much more efficient than those based on autoregressive predictions, the real-time generation of the highest quality audio on CPU is still a very challenging task. One major computation of all GAN-based neural vocoders comes from the stacked upsampling layers, which were designed to match the length of the waveform's length of output and temporal resolution. Meanwhile, the computational complexity of upsampling networks is closely correlated with the numbers of samples generated for each window. To reduce the computation of upsampling layers, we propose a new GAN based neural vocoder called Basis-MelGAN where the raw audio samples are decomposed with a learned basis and their associated weights. As the prediction targets of Basis-MelGAN are the weight values associated with each learned basis instead of the raw audio samples, the upsampling layers in Basis-MelGAN can be designed with much simpler networks. Compared with other GAN based neural vocoders, the proposed Basis-MelGAN could produce comparable high-quality audio but significantly reduced computational complexity from HiFi-GAN V1's 17.74 GFLOPs to 7.95 GFLOPs.      
### 42.Countering Adversarial Examples: Combining Input Transformation and Noisy Training  [ :arrow_down: ](https://arxiv.org/pdf/2106.13394.pdf)
>  Recent studies have shown that neural network (NN) based image classifiers are highly vulnerable to adversarial examples, which poses a threat to security-sensitive image recognition task. Prior work has shown that JPEG compression can combat the drop in classification accuracy on adversarial examples to some extent. But, as the compression ratio increases, traditional JPEG compression is insufficient to defend those attacks but can cause an abrupt accuracy decline to the benign images. In this paper, with the aim of fully filtering the adversarial perturbations, we firstly make modifications to traditional JPEG compression algorithm which becomes more favorable for NN. Specifically, based on an analysis of the frequency coefficient, we design a NN-favored quantization table for compression. Considering compression as a data augmentation strategy, we then combine our model-agnostic preprocess with noisy training. We fine-tune the pre-trained model by training with images encoded at different compression levels, thus generating multiple classifiers. Finally, since lower (higher) compression ratio can remove both perturbations and original features slightly (aggressively), we use these trained multiple models for model ensemble. The majority vote of the ensemble of models is adopted as final predictions. Experiments results show our method can improve defense efficiency while maintaining original accuracy.      
### 43.Scalable Perception-Action-Communication Loops with Convolutional and Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.13358.pdf)
>  In this paper, we present a perception-action-communication loop design using Vision-based Graph Aggregation and Inference (VGAI). This multi-agent decentralized learning-to-control framework maps raw visual observations to agent actions, aided by local communication among neighboring agents. Our framework is implemented by a cascade of a convolutional and a graph neural network (CNN / GNN), addressing agent-level visual perception and feature learning, as well as swarm-level communication, local information aggregation and agent action inference, respectively. By jointly training the CNN and GNN, image features and communication messages are learned in conjunction to better address the specific task. We use imitation learning to train the VGAI controller in an offline phase, relying on a centralized expert controller. This results in a learned VGAI controller that can be deployed in a distributed manner for online execution. Additionally, the controller exhibits good scaling properties, with training in smaller teams and application in larger teams. Through a multi-agent flocking application, we demonstrate that VGAI yields performance comparable to or better than other decentralized controllers, using only the visual input modality and without accessing precise location or motion state information.      
### 44.Distributed IDA-PBC for a Class of Nonholonomic Mechanical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.13338.pdf)
>  Nonholonomic mechanical systems encompass a large class of practically interesting robotic structures, such as wheeled mobile robots, space manipulators, and multi-fingered robot hands. However, few results exist on the cooperative control of such systems in a generic, distributed approach. In this work we extend a recently developed distributed Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) method to such systems. More specifically, relying on port-Hamiltonian system modelling for networks of mechanical systems, we propose a full-state stabilization control law for a class of nonholonomic systems within the framework of distributed IDA-PBC. This enables the cooperative control of heterogeneous, underactuated and nonholonomic systems with a unified control law. This control law primarily relies on the notion of Passive Configuration Decomposition (PCD) and a novel, non-smooth desired potential energy function proposed here. A low-level collision avoidance protocol is also implemented in order to achieve dynamic inter-agent collision avoidance, enhancing the practical relevance of this work. Theoretical results are tested in different simulation scenarios in order to highlight the applicability of the derived method.      
### 45.Adaptive Imaging of Arbitrary Thermal Source Distributions with Near Quantum-Limited Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.13332.pdf)
>  We demonstrate an approach to obtaining near quantum limited far-field imaging resolution of thermal, incoherent sources with arbitrary distributions. Our method assumes no prior knowledge of the source distribution, but rather uses an adaptive approach to imaging via spatial-mode demultiplexing that iteratively updates both the form of the spatial imaging modes and the estimate of the source distribution. The optimal imaging modes are determined by minimizing the estimated Cramér-Rao bound over the manifold of all possible sets of orthogonal modes. We have observed through Monte Carlo simulations that the manifold-optimized spatial mode demultiplexing measurement consistently outperforms standard imaging techniques in the resolution and precision of source reconstructions, and approaches the quantum limits as set by the quantum Cramér-Rao bound. The adaptive framework presented here allows for a consistent approach to achieving near quantum-limited imaging resolution of arbitrarily distributed thermal sources.      
### 46.Factor Graphs for Heterogeneous Bayesian Decentralized Data Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2106.13285.pdf)
>  This paper explores the use of factor graphs as an inference and analysis tool for Bayesian peer-to-peer decentralized data fusion. We propose a framework by which agents can each use local factor graphs to represent relevant partitions of a complex global joint probability distribution, thus allowing them to avoid reasoning over the entirety of a more complex model and saving communication as well as computation cost. This allows heterogeneous multi-robot systems to cooperate on a variety of real world, task oriented missions, where scalability and modularity are key. To develop the initial theory and analyze the limits of this approach, we focus our attention on static linear Gaussian systems in tree-structured networks and use Channel Filters (also represented by factor graphs) to explicitly track common information. We discuss how this representation can be used to describe various multi-robot applications and to design and analyze new heterogeneous data fusion algorithms. We validate our method in simulations of a multi-agent multi-target tracking and cooperative multi-agent mapping problems, and discuss the computation and communication gains of this approach.      
### 47.Deep Learning for High-Impedance Fault Detection: Convolutional Autoencoders  [ :arrow_down: ](https://arxiv.org/pdf/2106.13276.pdf)
>  High-impedance faults (HIF) are difficult to detect because of their low current amplitude and highly diverse characteristics. In recent years, machine learning (ML) has been gaining popularity in HIF detection because ML techniques learn patterns from data and successfully detect HIFs. However, as these methods are based on supervised learning, they fail to reliably detect any scenario, fault or non-fault, not present in the training data. Consequently, this paper takes advantage of unsupervised learning and proposes a convolutional autoencoder framework for HIF detection (CAE-HIFD). Contrary to the conventional autoencoders that learn from normal behavior, the convolutional autoencoder (CAE) in CAE-HIFD learns only from the HIF signals eliminating the need for presence of diverse non-HIF scenarios in the CAE training. CAE distinguishes HIFs from non-HIF operating conditions by employing cross-correlation. To discriminate HIFs from transient disturbances such as capacitor or load switching, CAE-HIFD uses kurtosis, a statistical measure of the probability distribution shape. The performance evaluation studies conducted using the IEEE 13-node test feeder indicate that the CAE-HIFD reliably detects HIFs, outperforms the state-of-the-art HIF detection techniques, and is robust against noise.      
### 48.Iterative LP-based Methods for the Multiperiod Optimal Electricity and Gas Flow Problem  [ :arrow_down: ](https://arxiv.org/pdf/2106.13240.pdf)
>  In light of the increasing coupling between electricity and gas networks, this paper introduces two novel iterative methods for efficiently solving the multiperiod optimal electricity and gas flow (MOEGF) problem. The first is an iterative MILP-based method and the second is an iterative LP-based method with an elaborate procedure for ensuring an integral solution. The convergence of the two approaches is founded on two key features. The first is a penalty term with a single, automatically tuned, parameter for controlling the step size of the gas network iterates. The second is a sequence of supporting hyperplanes together with an increasing number of carefully constructed halfspaces for controlling the convergence of the electricity network iterates. Moreover, the two proposed algorithms use as a warm start the solution from a novel polyhedral relaxation of the MOEGF problem, for a noticeable improvement in computation time as compared to a cold start. Unlike the first method, which invokes a branch-and-bound algorithm to find an integral solution, the second method implements an elaborate steering procedure that guides the continuous variables to take integral values at the solution. Numerical evaluation demonstrates that the two proposed methods can converge to high-quality feasible solutions in computation times at least two orders of magnitude faster than both a state-of-the-art nonlinear branch-and-bound (NLBB) MINLP solver and a mixed-integer convex programming (MICP) relaxation of the MOEGF problem. The experimental setup consists of five test cases, three of which involve the real electricity and gas transmission networks of the state of Victoria with actual linepack and demand profiles.      

# ArXiv eess --Tue, 15 Jun 2021
### 1.Grasping force estimation using state-space model and Kalman filter  [ :arrow_down: ](https://arxiv.org/pdf/2106.07639.pdf)
>  The grip force required to handle an object depends on it mass and the friction between the skin and the object. The control of grip force in myoelectric prosthesis is crucial for handling objects adequately. The current paper proposes a method for improving the estimation of grip force in myoelectric prosthesis based on surface myoelectric (sEMG) recordings. For this purpose, we develop an approach based on multivariable system identification in the state-space (SS) and continuous force estimation with Kalman filter (KF). The sEMG recordings of ten healthy individuals performing a grip task were used as data set for model identification. The root mean square (RMS), the mean absolute value (MAV), and the waveform length (WL) extracted from the sEMG signals were used at the model's input and the measured grasping force was the output. The performance of the proposed method was evaluated using the normalized root-mean-squared-error (NRMSE) and the square of Pearson's correlation coefficient ($ R^2 $). In this study, the CC and NRMSE values were 0.92$ \pm $ 0.0319 and 0.723$ \pm $ 0.0563, respectively. The performance of the system was superior to results obtained with a recurrent nonlinear autoregressive exogenous (NARX)-based neural network and the multi-layer perceptron (MLP) network. The results confirmed that the method is an excellent tool for real-time applications with hand prostheses.      
### 2.Recursive Refinement Network for Deformable Lung Registration between Exhale and Inhale CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2106.07608.pdf)
>  Unsupervised learning-based medical image registration approaches have witnessed rapid development in recent years. We propose to revisit a commonly ignored while simple and well-established principle: recursive refinement of deformation vector fields across scales. We introduce a recursive refinement network (RRN) for unsupervised medical image registration, to extract multi-scale features, construct normalized local cost correlation volume and recursively refine volumetric deformation vector fields. RRN achieves state of the art performance for 3D registration of expiratory-inspiratory pairs of CT lung scans. On DirLab COPDGene dataset, RRN returns an average Target Registration Error (TRE) of 0.83 mm, which corresponds to a 13% error reduction from the best result presented in the leaderboard. In addition to comparison with conventional methods, RRN leads to 89% error reduction compared to deep-learning-based peer approaches.      
### 3.Distribution level battery storage valuation framework  [ :arrow_down: ](https://arxiv.org/pdf/2106.07590.pdf)
>  The growing demand for electricity in emerging markets and developing economies such as India is causing loading and congestion problems on distribution networks, particularly in urban locations. Electric utilities in these regions face unique constraints regarding raising capital required to upgrade their congested networks. Battery storage has emerged as a non-wire alternative to feeder-level upgrades. This article presents a valuation framework by optimally sizing and placing battery storage on the distribution network. We evaluate the value of storage using a real options analysis through a Markov Chain Monte Carlo to identify the least-cost network upgrade strategy, given demand growth uncertainty. When applied to urban distribution network feeders typical of those found in congested cities in India, the approach highlights the economic value of network investment deferrals by making use of battery storage. We find that storage costs below 261 USD/kWh justify investments in distribution level storage and storage as a non-wire alternative only makes sense on moderately loaded feeders where storage charging is still feasible without violating network thermal capacity limits.      
### 4.Scenarios of future Indian electricity demand accounting for space cooling and electric vehicle adoption  [ :arrow_down: ](https://arxiv.org/pdf/2106.07588.pdf)
>  India is expected to witness rapid growth in electricity use over the next two decades. Here, we introduce a custom regression model to project electricity consumption in India over the coming decades, which includes a bottom-up estimate of electricity consumption for two major growth drivers, air conditioning, and vehicle electrification. The model projections are available at a customizable level of spatial aggregation at an hourly temporal resolution, which makes them useful as inputs to long-term electricity infrastructure planning studies. The approach is used to develop electricity consumption data sets spanning various technology adoption and growth scenarios up to the year 2050 in five-year increments. The aim of the data is to provide a range of scenarios for India's demand growth given new technology adoption. With long-term hourly demand projections serving as an essential input for electricity infrastructure modeling, this data publication enables further work on energy efficiency, generation, and transmission expansion planning for a fast-growing and increasingly important region from a global climate mitigation perspective.      
### 5.Dual-Path Filter Network: Speaker-Aware Modeling for Speech Separation  [ :arrow_down: ](https://arxiv.org/pdf/2106.07579.pdf)
>  Speech separation has been extensively studied to deal with the cocktail party problem in recent years. All related approaches can be divided into two categories: time-frequency domain methods and time domain methods. In addition, some methods try to generate speaker vectors to support source separation. In this study, we propose a new model called dual-path filter network (DPFN). Our model focuses on the post-processing of speech separation to improve speech separation performance. DPFN is composed of two parts: the speaker module and the separation module. First, the speaker module infers the identities of the speakers. Then, the separation module uses the speakers' information to extract the voices of individual speakers from the mixture. DPFN constructed based on DPRNN-TasNet is not only superior to DPRNN-TasNet, but also avoids the problem of permutation-invariant training (PIT).      
### 6.A scalable multi-step least squares method for network identification with unknown disturbance topology  [ :arrow_down: ](https://arxiv.org/pdf/2106.07548.pdf)
>  Identification methods for dynamic networks typically require prior knowledge of the network and disturbance topology, and often rely on solving poorly scalable non-convex optimization problems. While methods for estimating network topology are available in the literature, less attention has been paid to estimating the disturbance topology, i.e., the (spatial) noise correlation structure and the noise rank. In this work we present an identification method for dynamic networks, in which an estimation of the disturbance topology precedes the identification of the full dynamic network with known network topology. To this end we extend the multi-step Sequential Linear Regression and Weighted Null Space Fitting methods to deal with reduced rank noise, and use these methods to estimate the disturbance topology and the network dynamics. As a result, we provide a multi-step least squares algorithm with parallel computation capabilities and that rely only on explicit analytical solutions, thereby avoiding the usual non-convex optimizations involved. Consequently we consistently estimate dynamic networks of Box Jenkins model structure, while keeping the computational burden low. We provide a consistency proof that includes path-based data informativity conditions for allocation of excitation signals in the experimental design. Numerical simulations performed on a dynamic network with reduced rank noise clearly illustrate the potential of this method.      
### 7.Posterior Temperature Optimization in Variational Inference  [ :arrow_down: ](https://arxiv.org/pdf/2106.07533.pdf)
>  Cold posteriors have been reported to perform better in practice in the context of Bayesian deep learning (Wenzel2020 et al., 2020). In variational inference, it is common to employ only a partially tempered posterior by scaling the complexity term in the log-evidence lower bound (ELBO). In this work, we first derive the ELBO for a fully tempered posterior in mean-field variational inference and subsequently use Bayesian optimization to automatically find the optimal posterior temperature. Choosing an appropriate posterior temperature leads to better predictive performance and improved uncertainty calibration, which we demonstrate for the task of denoising medical X-ray images.      
### 8.MIA-COV19D: COVID-19 Detection through 3-D Chest CT Image Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.07524.pdf)
>  Early and reliable COVID-19 diagnosis based on chest 3-D CT scans can assist medical specialists in vital circumstances. Deep learning methodologies constitute a main approach for chest CT scan analysis and disease prediction. However, large annotated databases are necessary for developing deep learning models that are able to provide COVID-19 diagnosis across various medical environments in different countries. Due to privacy issues, publicly available COVID-19 CT datasets are highly difficult to obtain, which hinders the research and development of AI-enabled diagnosis methods of COVID-19 based on CT scans. In this paper we present the COV19-CT-DB database which is annotated for COVID-19, consisting of about 5,000 3-D CT scans, We have split the database in training, validation and test datasets. The former two datasets can be used for training and validation of machine learning models, while the latter will be used for evaluation of the developed models. We also present a deep learning approach, based on a CNN-RNN network and report its performance on the COVID19-CT-DB database.      
### 9.Resilient and Distributed Discrete Optimal Transport with Deceptive Adversary: A Game-Theoretic Approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.07455.pdf)
>  Optimal transport (OT) is a framework that can be used to guide the optimal allocation of a limited amount of resources. The classical OT paradigm does not consider malicious attacks in its formulation and thus the designed transport plan lacks resiliency to an adversary. To address this concern, we establish an OT framework that explicitly accounts for the adversarial and stealthy manipulation of participating nodes in the network during the transport strategy design. Specifically, we propose a game-theoretic approach to capture the strategic interactions between the transport planner and the deceptive attacker. We analyze the properties of the established two-person zero-sum game thoroughly. We further develop a fully distributed algorithm to compute the optimal resilient transport strategies, and show the convergence of the algorithm to a saddle-point equilibrium. Finally, we demonstrate the effectiveness of the designed algorithm using case studies.      
### 10.Recurrent Inference Machines as inverse problem solvers for MR relaxometry  [ :arrow_down: ](https://arxiv.org/pdf/2106.07379.pdf)
>  In this paper, we propose the use of Recurrent Inference Machines (RIMs) to perform T1 and T2 mapping. The RIM is a neural network framework that learns an iterative inference process based on the signal model, similar to conventional statistical methods for quantitative MRI (QMRI), such as the Maximum Likelihood Estimator (MLE). This framework combines the advantages of both data-driven and model-based methods, and, we hypothesize, is a promising tool for QMRI. Previously, RIMs were used to solve linear inverse reconstruction problems. Here, we show that they can also be used to optimize non-linear problems and estimate relaxometry maps with high precision and accuracy. The developed RIM framework is evaluated in terms of accuracy and precision and compared to an MLE method and an implementation of the ResNet. The results show that the RIM improves the quality of estimates compared to the other techniques in Monte Carlo experiments with simulated data, test-retest analysis of a system phantom, and in-vivo scans. Additionally, inference with the RIM is 150 times faster than the MLE, and robustness to (slight) variations of scanning parameters is demonstrated. Hence, the RIM is a promising and flexible method for QMRI. Coupled with an open-source training data generation tool, it presents a compelling alternative to previous methods.      
### 11.Speech Disorder Classification Using Extended Factorized Hierarchical Variational Auto-encoders  [ :arrow_down: ](https://arxiv.org/pdf/2106.07337.pdf)
>  Objective speech disorder classification for speakers with communication difficulty is desirable for diagnosis and administering therapy. With the current state of speech technology, it is evident to propose neural networks for this application. But neural network model training is hampered by a lack of labeled disordered speech data. In this research, we apply an extended version of Factorized Hierarchical Variational Auto-encoders (FHVAE) for representation learning on disordered speech. The FHVAE model extracts both content-related and sequence-related latent variables from speech data, and we utilize the extracted variables to explore how disorder type information is represented in the latent variables. For better classification performance, the latent variables are aggregated at the word and sentence level. We show that an extension of the FHVAE model succeeds in the better disentanglement of the content-related and sequence-related related representations, but both representations are still required for best results on disorder type classification.      
### 12.A Multi Polarization Square Patch Antenna with a Reconfigurable Feeding Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.07291.pdf)
>  A multi-polarization square patch antenna with a reconfigurable feeding network is presented in this paper. The reconfigurable feeding network of this antenna is implemented on an FR-4 substrate by a Wilkinson power divider and a branch line coupler which perform amplitude distribution in the feeding network. Besides, two switching circuits which consist of one PIN diode (BAR63-02w) and its DC biasing circuit manage the RF signal flow on this feeding network. These switching circuits control the phase of the RF signal applied to the square patch, so it can provide linear polarization, left-hand and right-hand circular polarization at 2.45 GHz which has many applications in wireless networks. The simulated and measured results are presented which illuminate acceptable axial ratio bandwidth (ARBW) for both right-hand and left-hand circular polarization in (2.38-2.48 GHz) and minimum -10 dB return loss at 2.45 GHz.      
### 13.Design and Experimental Assessment of Detection Schemes for Air Interface Attacks in Adverse Scenarios  [ :arrow_down: ](https://arxiv.org/pdf/2106.07199.pdf)
>  In this letter, we propose three schemes designed to detect attacks over the air interface in cellular networks. These decision rules rely on the generalized likelihood ratio test, and are fed by data that can be acquired using common off-the-shelf receivers. In addition to more classical (barrage/smart) noise jamming attacks, we further assess the capability of the proposed schemes to detect the stealthy activation of a rogue base station. The evaluation is carried out through an experimentation of a LTE system concretely reproduced using Software-Defined Radios. Illustrative examples confirm that the proposed schemes can effectively detect air interface threats with high probability.      
### 14.Selective Hearing through Lip-reading  [ :arrow_down: ](https://arxiv.org/pdf/2106.07150.pdf)
>  Speaker extraction algorithm emulates human's ability of selective attention to extract the target speaker's speech from a multi-talker scenario. It requires an auxiliary stimulus to form the top-down attention towards the target speaker. It has been well studied to use a reference speech as the auxiliary stimulus. Visual cues also serve as an informative reference for human listening. They are particularly useful in the presence of acoustic noise and interference speakers. We believe that the temporal synchronization between speech and its accompanying lip motion is a direct and dominant audio-visual cue. In this work, we aim to emulate human's ability of visual attention for speaker extraction based on speech-lip synchronization. We propose a self-supervised pre-training strategy, to exploit the speech-lip synchronization in a multi-talker scenario. We transfer the knowledge from the pre-trained model to a speaker extraction network. We show that the proposed speaker extraction network outperforms various competitive baselines in terms of signal quality and perceptual evaluation, achieving state-of-the-art performance.      
### 15.Few-shot learning of new sound classes for target sound extraction  [ :arrow_down: ](https://arxiv.org/pdf/2106.07144.pdf)
>  Target sound extraction consists of extracting the sound of a target acoustic event (AE) class from a mixture of AE sounds. It can be realized using a neural network that extracts the target sound conditioned on a 1-hot vector that represents the desired AE class. With this approach, embedding vectors associated with the AE classes are directly optimized for the extraction of sound classes seen during training. However, it is not easy to extend this framework to new AE classes, i.e. unseen during training. Recently, speech, music, or AE sound extraction based on enrollment audio of the desired sound offers the potential of extracting any target sound in a mixture given only a short audio signal of a similar sound. In this work, we propose combining 1-hot- and enrollment-based target sound extraction, allowing optimal performance for seen AE classes and simple extension to new classes. In experiments with synthesized sound mixtures generated with the Freesound Dataset (FSD) datasets, we demonstrate the benefit of the combined framework for both seen and new AE classes. Besides, we also propose adapting the embedding vectors obtained from a few enrollment audio samples (few-shot) to further improve performance on new classes.      
### 16.Pointwise Feasibility of Gaussian Process-based Safety-Critical Control under Model Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2106.07108.pdf)
>  Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs) are popular tools for enforcing safety and stability of a controlled system, respectively. They are commonly utilized to build constraints that can be incorporated in a min-norm quadratic program (CBF-CLF-QP) which solves for a safety-critical control input. However, since these constraints rely on a model of the system, when this model is inaccurate the guarantees of safety and stability can be easily lost. In this paper, we present a Gaussian Process (GP)-based approach to tackle the problem of model uncertainty in safety-critical controllers that use CBFs and CLFs. The considered model uncertainty is affected by both state and control input. We derive probabilistic bounds on the effects that such model uncertainty has on the dynamics of the CBF and CLF. Then, we use these bounds to build safety and stability chance constraints that can be incorporated in a min-norm convex optimization program, called GP-CBF-CLF-SOCP. As the main theoretical result of the paper, we present necessary and sufficient conditions for pointwise feasibility of the proposed optimization problem. We believe that these conditions could serve as a starting point towards understanding what are the minimal requirements on the distribution of data collected from the real system in order to guarantee safety. Finally, we validate the proposed framework with numerical simulations of an adaptive cruise controller for an automotive system.      
### 17.Enhanced Hyperspectral Image Super-Resolution via RGB Fusion and TV-TV Minimization  [ :arrow_down: ](https://arxiv.org/pdf/2106.07066.pdf)
>  Hyperspectral (HS) images contain detailed spectral information that has proven crucial in applications like remote sensing, surveillance, and astronomy. However, because of hardware limitations of HS cameras, the captured images have low spatial resolution. To improve them, the low-resolution hyperspectral images are fused with conventional high-resolution RGB images via a technique known as fusion based HS image super-resolution. Currently, the best performance in this task is achieved by deep learning (DL) methods. Such methods, however, cannot guarantee that the input measurements are satisfied in the recovered image, since the learned parameters by the network are applied to every test image. Conversely, model-based algorithms can typically guarantee such measurement consistency. Inspired by these observations, we propose a framework that integrates learning and model based methods. Experimental results show that our method produces images of superior spatial and spectral resolution compared to the current leading methods, whether model- or DL-based.      
### 18.Multi-RIS Discrete-Phase Encoding for Interpath-Interference-Free Channel Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2106.07065.pdf)
>  Reconfigurable intelligent surfaces (RISs) are one of the foremost technological enablers of future wireless systems. They improve communication and localization by providing a strong non-line-of-sight path to the receiver. In this paper, we propose a pilot transmission method to enable the receiver to separate signals arriving from different RISs and from the uncontrolled multipath. This facilitates channel estimation and localization, as the channel or its geometric parameters can be estimated for each path separately. Our method is based on designing temporal phase profiles that are orthogonal across RISs without affecting the RIS beamforming capabilities. We take into consideration the limited resolution of the RIS phase shifters and show that in the presence of this practical limitation, orthogonal phase profiles can be designed based on Butson-type Hadamard matrices. For a localization scenario, we show that with our proposed method the estimator can attain the theoretical lower bound even with one-bit RIS phase resolution.      
### 19.Ultrasound Classification of Breast Masses Using a Comprehensive Nakagami Imaging and Machine Learning Framework  [ :arrow_down: ](https://arxiv.org/pdf/2106.07048.pdf)
>  Ultrasound imaging is establishing itself as a popular screening technique for breast cancer due to its non-invasive nature. In this study, we have utilized statistical parameters from the well-known Nakagami distribution to construct several different types of Nakagami and derived Nakagami parametric images from ultrasound B-mode scans, and investigated their potential to improve the non-invasive identification of breast cancer. The dataset we used contains 130 biopsy-proven patients consisting of 104 benign and 26 malignant cases. For each of these patients, we generated seven types of Nakagami and derived Nakagami images from basic and as well as derived parameters of the Nakagami distribution through a sliding-window technique. To determine the suitable window size for image generation, we conducted an empirical analysis using three windows of width 0.2 mm and lengths 0.1875 mm, 0.45 mm and 0.75mm. From each patient image, we extracted a total of 72 features that consisted of morphometric, elemental and hybrid features. Feature selection using Recursive Feature Elimination with Cross Validation (RFE-CV) was performed to find the optimum subset of features for the best classification performance. Incorporating the selected subset of features with the Support Vector Machine (SVM) classifier, and by tuning the decision threshold, we obtained a maximum classification accuracy of 93.08% and an Area Under the Curve (AUC) of 0.9712, along with a False Negative Rate of 0%, and a very low False Positive Rate of 8.65%. Our results indicate that the high accuracy of such a procedure may assist in the diagnostic process associated with detection of breast cancer, as well as help to reduce false positive diagnosis.      
### 20.Robust Speed Control Methodology for Variable Speed Wind Turbines  [ :arrow_down: ](https://arxiv.org/pdf/2106.07022.pdf)
>  Improving wind turbine efficiency is essential for reducing the costs of energy production. The highly nonlinear dynamics of the wind turbines and their uncertain operating conditions have posed many challenges for their control methods. In this work, a robust control strategy based on sliding mode and adaptive fuzzy disturbance observer is proposed for speed tracking in a variable speed wind turbine. First, the nonlinear mathematical model that describes the dynamics of the variable speed wind turbine is derived. This nonlinear model is then used to derive the control methodology and to find stability and robustness conditions. The control approach is designed to track the optimal wind speed that causes maximum energy extraction. The stability condition was verified using the Lyapunov stability theory. A simulation study was conducted to verify the method, and a comparative analysis was used to measure its effectiveness. The results showed a high tracking ability and robustness of the developed methodology. Moreover, higher power extraction was observed when compared to a classical control method.      
### 21.WASE: Learning When to Attend for Speaker Extraction in Cocktail Party Environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.07016.pdf)
>  In the speaker extraction problem, it is found that additional information from the target speaker contributes to the tracking and extraction of the target speaker, which includes voiceprint, lip movement, facial expression, and spatial information. However, no one cares for the cue of sound onset, which has been emphasized in the auditory scene analysis and psychology. Inspired by it, we explicitly modeled the onset cue and verified the effectiveness in the speaker extraction task. We further extended to the onset/offset cues and got performance improvement. From the perspective of tasks, our onset/offset-based model completes the composite task, a complementary combination of speaker extraction and speaker-dependent voice activity detection. We also combined voiceprint with onset/offset cues. Voiceprint models voice characteristics of the target while onset/offset models the start/end information of the speech. From the perspective of auditory scene analysis, the combination of two perception cues can promote the integrity of the auditory object. The experiment results are also close to state-of-the-art performance, using nearly half of the parameters. We hope that this work will inspire communities of speech processing and psychology, and contribute to communication between them. Our code will be available in <a class="link-external link-https" href="https://github.com/aispeech-lab/wase/" rel="external noopener nofollow">this https URL</a>.      
### 22.Towards Fast Region Adaptive Ultrasound Beamformer for Plane Wave Imaging Using Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.07006.pdf)
>  Automatic learning algorithms for improving the image quality of diagnostic B-mode ultrasound (US) images have been gaining popularity in the recent past. In this work, a novel convolutional neural network (CNN) is trained using time of flight corrected in-vivo receiver data of plane wave transmit to produce corresponding high-quality minimum variance distortion less response (MVDR) beamformed image. A comprehensive performance comparison in terms of qualitative and quantitative measures for fully connected neural network (FCNN), the proposed CNN architecture, MVDR and Delay and Sum (DAS) using the dataset from Plane wave Imaging Challenge in Ultrasound (PICMUS) is also reported in this work. The CNN architecture could leverage the spatial information and will be more region adaptive during the beamforming process. This is evident from the improvement seen over the baseline FCNN approach and conventional MVDR beamformer, both in resolution and contrast with an improvement of 6 dB in CNR using only zero-angle transmission over the baseline. With the observed reduction in the requirement of number of angles to produce similar image metrics would prove advantageous in providing a possibility for higher frame rates.      
### 23.A Dataset of Dynamic Reverberant Sound Scenes with Directional Interferers for Sound Event Localization and Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.06999.pdf)
>  This report presents the dataset and baseline of Task 3 of the DCASE2021 Challenge on Sound Event Localization and Detection (SELD). The dataset is based on emulation of real recordings of static or moving sound events under real conditions of reverberation and ambient noise, using spatial room impulse responses captured in a variety of rooms and delivered in two spatial formats. The acoustical synthesis remains the same as in the previous iteration of the challenge, however the new dataset brings more challenging conditions of polyphony and overlapping instances of the same class. The most important difference of the new dataset is the introduction of directional interferers, meaning sound events that are localized in space but do not belong to the target classes to be detected and are not annotated. Since such interfering events are expected in every real-world scenario of SELD, the new dataset aims to promote systems that deal with this condition effectively. A modified SELDnet baseline employing the recent ACCDOA representation for SELD problems accompanies the dataset and is described herein. To investigate the individual and combined effects of ambient noise, interferers, and reverberation, we study the performance of the baseline on different versions of the dataset excluding or including combinations of these factors. The results indicate that by far the most detrimental effects are caused by directional interferers.      
### 24.Learning the Imaging Landmarks: Unsupervised Key point Detection in Lung Ultrasound Videos  [ :arrow_down: ](https://arxiv.org/pdf/2106.06987.pdf)
>  Lung ultrasound (LUS) is an increasingly popular diagnostic imaging modality for continuous and periodic monitoring of lung infection, given its advantages of non-invasiveness, non-ionizing nature, portability and easy disinfection. The major landmarks assessed by clinicians for triaging using LUS are pleura, A and B lines. There have been many efforts for the automatic detection of these landmarks. However, restricting to a few pre-defined landmarks may not reveal the actual imaging biomarkers particularly in case of new pathologies like COVID-19. Rather, the identification of key landmarks should be driven by data given the availability of a plethora of neural network algorithms. This work is a first of its kind attempt towards unsupervised detection of the key LUS landmarks in LUS videos of COVID-19 subjects during various stages of infection. We adapted the relatively newer approach of transporter neural networks to automatically mark and track pleura, A and B lines based on their periodic motion and relatively stable appearance in the videos. Initial results on unsupervised pleura detection show an accuracy of 91.8% employing 1081 LUS video frames.      
### 25.An Approach Towards Physics Informed Lung Ultrasound Image Scoring Neural Network for Diagnostic Assistance in COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2106.06980.pdf)
>  Ultrasound is fast becoming an inevitable diagnostic tool for regular and continuous monitoring of the lung with the recent outbreak of COVID-19. In this work, a novel approach is presented to extract acoustic propagation-based features to automatically highlight the region below pleura, which is an important landmark in lung ultrasound (LUS). Subsequently, a multichannel input formed by using the acoustic physics-based feature maps is fused to train a neural network, referred to as LUSNet, to classify the LUS images into five classes of varying severity of lung infection to track the progression of COVID-19. In order to ensure that the proposed approach is agnostic to the type of acquisition, the LUSNet, which consists of a U-net architecture is trained in an unsupervised manner with the acoustic feature maps to ensure that the encoder-decoder architecture is learning features in the pleural region of interest. A novel combination of the U-net output and the U-net encoder output is employed for the classification of severity of infection in the lung. A detailed analysis of the proposed approach on LUS images over the infection to full recovery period of ten confirmed COVID-19 subjects shows an average five-fold cross-validation accuracy, sensitivity, and specificity of 97%, 93%, and 98% respectively over 5000 frames of COVID-19 videos. The analysis also shows that, when the input dataset is limited and diverse as in the case of COVID-19 pandemic, an aided effort of combining acoustic propagation-based features along with the gray scale images, as proposed in this work, improves the performance of the neural network significantly and also aids the labelling and triaging process.      
### 26.Optimal Sensor Precision for Multi-Rate Sensing for Bounded Estimation Error  [ :arrow_down: ](https://arxiv.org/pdf/2106.06906.pdf)
>  We address the problem of determining optimal sensor precisions for estimating the states of linear time-varying discrete-time stochastic dynamical systems, with guaranteed bounds on the estimation errors. This is performed in the Kalman filtering framework, where the sensor precisions are treated as variables. They are determined by solving a constrained convex optimization problem, which guarantees the specified upper bound on the posterior error variance. Optimal sensor precisions are determined by minimizing the l1 norm, which promotes sparseness in the solution and indirectly addresses the sensor selection problem. The theory is applied to realistic flight mechanics and astrodynamics problems to highlight its engineering value. These examples demonstrate the application of the presented theory to a) determine redundant sensing architectures for linear time invariant systems, b) accurately estimate states with low-cost sensors, and c) optimally schedule sensors for linear time-varying systems.      
### 27.Improving weakly supervised sound event detection with self-supervised auxiliary tasks  [ :arrow_down: ](https://arxiv.org/pdf/2106.06858.pdf)
>  While multitask and transfer learning has shown to improve the performance of neural networks in limited data settings, they require pretraining of the model on large datasets beforehand. In this paper, we focus on improving the performance of weakly supervised sound event detection in low data and noisy settings simultaneously without requiring any pretraining task. To that extent, we propose a shared encoder architecture with sound event detection as a primary task and an additional secondary decoder for a self-supervised auxiliary task. We empirically evaluate the proposed framework for weakly supervised sound event detection on a remix dataset of the DCASE 2019 task 1 acoustic scene data with DCASE 2018 Task 2 sounds event data under 0, 10 and 20 dB SNR. To ensure we retain the localisation information of multiple sound events, we propose a two-step attention pooling mechanism that provides a time-frequency localisation of multiple audio events in the clip. The proposed framework with two-step attention outperforms existing benchmark models by 22.3%, 12.8%, 5.9% on 0, 10 and 20 dB SNR respectively. We carry out an ablation study to determine the contribution of the auxiliary task and two-step attention pooling to the SED performance improvement.      
### 28.A Wideband Sliding Correlation Channel Sounder in 65 nm CMOS: Evaluation Board Performance  [ :arrow_down: ](https://arxiv.org/pdf/2106.06855.pdf)
>  Emerging applications such as wireless sensing, position location, robotics, and many more are driven by the ultra-wide bandwidths available at millimeter-wave (mmWave) and Terahertz (THz) frequencies. The characterization and efficient utilization of wireless channels at these extremely high frequencies require detailed knowledge of the radio propagation characteristics of the channels. Such knowledge is developed through empirical observations of operating conditions using wireless transceivers that measure the impulse response through channel sounding. Today, cutting-edge channel sounders rely on several bulky RF hardware components with complicated interconnections, large parasitics, and sub-GHz RF bandwidth. This paper presents a compact sliding correlation-based channel sounder baseband built on a monolithic integrated circuit (IC) using 65 nm CMOS, implemented as an evaluation board achieving a 2 GHz RF bandwidth. The IC is the worlds first gigabit-per-second channel sounder baseband implemented in low-cost CMOS. The presented single-board system can be employed at both the transmit and receive baseband to study multipath characteristics and path loss. Thus, the singleboard implementation provides an inexpensive and compact solution for sliding correlation-based channel sounding with 1 ns multipath delay resolution.      
### 29.Geodesic Density Regression for Correcting 4DCT Pulmonary Respiratory Motion Artifacts  [ :arrow_down: ](https://arxiv.org/pdf/2106.06853.pdf)
>  Pulmonary respiratory motion artifacts are common in four-dimensional computed tomography (4DCT) of lungs and are caused by missing, duplicated, and misaligned image data. This paper presents a geodesic density regression (GDR) algorithm to correct motion artifacts in 4DCT by correcting artifacts in one breathing phase with artifact-free data from corresponding regions of other breathing phases. The GDR algorithm estimates an artifact-free lung template image and a smooth, dense, 4D (space plus time) vector field that deforms the template image to each breathing phase to produce an artifact-free 4DCT scan. Correspondences are estimated by accounting for the local tissue density change associated with air entering and leaving the lungs, and using binary artifact masks to exclude regions with artifacts from image regression. The artifact-free lung template image is generated by mapping the artifact-free regions of each phase volume to a common reference coordinate system using the estimated correspondences and then averaging. This procedure generates a fixed view of the lung with an improved signal-to-noise ratio. The GDR algorithm was evaluated and compared to a state-of-the-art geodesic intensity regression (GIR) algorithm using simulated CT time-series and 4DCT scans with clinically observed motion artifacts. The simulation shows that the GDR algorithm has achieved significantly more accurate Jacobian images and sharper template images, and is less sensitive to data dropout than the GIR algorithm. We also demonstrate that the GDR algorithm is more effective than the GIR algorithm for removing clinically observed motion artifacts in treatment planning 4DCT scans. Our code is freely available at <a class="link-external link-https" href="https://github.com/Wei-Shao-Reg/GDR" rel="external noopener nofollow">this https URL</a>.      
### 30.System Identification and Model-based Robust Nonlinear Disturbance Rejection Control  [ :arrow_down: ](https://arxiv.org/pdf/2106.06816.pdf)
>  The robust disturbance rejection controller has been the subject of intensive research due to its undeniable importance for automation. Modern control theory tends to use model-based approaches versus model-free approaches, especially when it comes to highly modern applications. The backbone of the dissertation is based on the systematic modeling of dynamic systems and the development of advanced control methods. Accordingly, the dissertation begins with the investigation of nonlinearities in dynamic systems. The extension of classic subspace algorithms for linear systems in the frequency domain is tackled using the new local polynomial approach. Next, the problem of disturbance control is addressed, namely modeling of uncertainties and non-modeled high-order dynamics, fragility of the controller and observer systems, and the non-linearities are analyzed separately.      
### 31.On the Enabling of Multi-user Communications with Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2106.06789.pdf)
>  Reconfigurable Intelligent Surface (RIS) composed of programmable actuators is a promising technology, thanks to its capability in manipulating Electromagnetic (EM) wavefronts. In particular, RISs have the potential to provide significant performance improvements for wireless networks. However, to do so, a proper configuration of the reflection coefficients of the unit cells in the RIS is required. RISs are sophisticated platforms so the design and fabrication complexity might be uneconomical for single-user scenarios while a RIS that can service multi-users justifies the costs. For the first time, we propose an efficient reconfiguration technique providing the multi-beam radiation pattern. Thanks to the analytical model the reconfiguration profile is at hand compared to time-consuming optimization techniques. The outcome can pave the wave for commercial use of multi-user communication beyond 5G networks. We analyze the performance of our proposed RIS technology for indoor and outdoor scenarios, given the broadcast mode of operation. The aforesaid scenarios encompass some of the most challenging scenarios that wireless networks encounter. We show that our proposed technique provisions sufficient gains in the observed channel capacity when the users are close to the RIS in the indoor office environment scenario. Further, we report more than one order of magnitude increase in the system throughput given the outdoor environment. The results prove that RIS with the ability to communicate with multiple users can empower wireless networks with great capacity.      
### 32.Residual Networks based Distortion Classification and Ranking for Laparoscopic Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2106.06784.pdf)
>  Laparoscopic images and videos are often affected by different types of distortion like noise, smoke, blur and nonuniform illumination. Automatic detection of these distortions, followed generally by application of appropriate image quality enhancement methods, is critical to avoid errors during surgery. In this context, a crucial step involves an objective assessment of the image quality, which is a two-fold problem requiring both the classification of the distortion type affecting the image and the estimation of the severity level of that distortion. Unlike existing image quality measures which focus mainly on estimating a quality score, we propose in this paper to formulate the image quality assessment task as a multi-label classification problem taking into account both the type as well as the severity level (or rank) of distortions. Here, this problem is then solved by resorting to a deep neural networks based approach. The obtained results on a laparoscopic image dataset show the efficiency of the proposed approach.      
### 33.A piecewise ellipsoidal reachable set estimation method for continuous bimodal piecewise affine systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.06776.pdf)
>  In this work, the issue of estimation of reachable sets in continuous bimodal piecewise affine systems is studied. A new method is proposed, in the framework of ellipsoidal bounding, using piecewise quadratic Lyapunov functions. Although bimodal piecewise affine systems can be seen as a special class of affine hybrid systems, reachability methods developed for affine hybrid systems might be inappropriately complex for bimodal dynamics. This work goes in the direction of exploiting the dynamical structure of the system to propose a simpler approach. More specifically, because of the piecewise nature of the Lyapunov function, we first derive conditions to ensure that a given quadratic function is positive on half spaces. Then, we exploit the property of bimodal piecewise quadratic functions being continuous on a given hyperplane. Finally, linear matrix characterizations of the estimate of the reachable set are derived.      
### 34.AI Enlightens Wireless Communication: Analyses, Solutions and Opportunities on CSI Feedback  [ :arrow_down: ](https://arxiv.org/pdf/2106.06759.pdf)
>  In this paper, we give a systematic description of the 1st Wireless Communication Artificial Intelligence (AI) Competition (WAIC) which is hosted by IMT-2020(5G) Promotion Group 5G+AI Work Group. Firstly, the framework of full channel state information (F-CSI) feedback problem and its corresponding channel dataset are provided. Then the enhancing schemes for DL-based F-CSI feedback including i) channel data analysis and preprocessing, ii) neural network design and iii) quantization enhancement are elaborated. The final competition results composed of different enhancing schemes are presented. Based on the valuable experience of 1st WAIC, we also list some challenges and potential study areas for the design of AI-based wireless communication systems.      
### 35.Interference Mitigation for FMCW Radar With Sparse and Low-Rank Hankel Matrix Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2106.06748.pdf)
>  In this paper, the interference mitigation for Frequency Modulated Continuous Wave (FMCW) radar system with a dechirping receiver is investigated. After dechirping operation, the scattered signals from targets result in beat signals, i.e., the sum of complex exponentials while the interferences lead to chirp-like short pulses. Taking advantage of these different time and frequency features between the useful signals and the interferences, the interference mitigation is formulated as an optimization problem: a sparse and low-rank decomposition of a Hankel matrix constructed by lifting the measurements. Then, an iterative optimization algorithm is proposed to tackle it by exploiting the Alternating Direction of Multipliers (ADMM) scheme. Compared to the existing methods, the proposed approach does not need to detect the interference and also improves the estimation accuracy of the separated useful signals. Both numerical simulations with point-like targets and experiment results with distributed targets (i.e., raindrops) are presented to demonstrate and verify its performance. The results show that the proposed approach is generally applicable for interference mitigation in both stationary and moving target scenarios.      
### 36.Hippocampus segmentation in magnetic resonance images of Alzheimer's patients using Deep machine learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.06743.pdf)
>  Background: Alzheimers disease is a progressive neurodegenerative disorder and the main cause of dementia in aging. Hippocampus is prone to changes in the early stages of Alzheimers disease. Detection and observation of the hippocampus changes using magnetic resonance imaging (MRI) before the onset of Alzheimers disease leads to the faster preventive and therapeutic measures. Objective: The aim of this study was the segmentation of the hippocampus in magnetic resonance (MR) images of Alzheimers patients using deep machine learning method. Methods: U-Net architecture of convolutional neural network was proposed to segment the hippocampus in the real MRI data. The MR images of the 100 and 35 patients available in Alzheimers disease Neuroimaging Initiative (ADNI) dataset, was used for the train and test of the model, respectively. The performance of the proposed method was compared with manual segmentation by measuring the similarity metrics. Results: The desired segmentation achieved after 10 iterations. A Dice similarity coefficient (DSC) = 92.3%, sensitivity = 96.5%, positive predicted value (PPV) = 90.4%, and Intersection over Union (IoU) value for the train 92.94 and test 92.93 sets were obtained which are acceptable. Conclusion: The proposed approach is promising and can be extended in the prognosis of Alzheimers disease by the prediction of the hippocampus volume changes in the early stage of the disease.      
### 37.Rapid COVID-19 Risk Screening by Eye-region Manifestations  [ :arrow_down: ](https://arxiv.org/pdf/2106.06664.pdf)
>  It is still nontrivial to develop a new fast COVID-19 screening method with the easier access and lower cost, due to the technical and cost limitations of the current testing methods in the medical resource-poor districts. On the other hand, there are more and more ocular manifestations that have been reported in the COVID-19 patients as growing clinical evidence[1]. This inspired this project. We have conducted the joint clinical research since January 2021 at the ShiJiaZhuang City, Heibei province, China, which approved by the ethics committee of The fifth hospital of ShiJiaZhuang of Hebei Medical University. We undertake several blind tests of COVID-19 patients by Union Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China. Meantime as an important part of the ongoing globally COVID-19 eye test program by AIMOMICS since February 2020, we propose a new fast screening method of analyzing the eye-region images, captured by common CCD and CMOS cameras. This could reliably make a rapid risk screening of COVID-19 with the sustainable stable high performance in different countries and races. Our model for COVID-19 rapid prescreening have the merits of the lower cost, fully self-performed, non-invasive, importantly real-time, and thus enables the continuous health surveillance. We further implement it as the open accessible APIs, and provide public service to the world. Our pilot experiments show that our model is ready to be usable to all kinds of surveillance scenarios, such as infrared temperature measurement device at airports and stations, or directly pushing to the target people groups smartphones as a packaged application.      
### 38.Least Squares Optimal Density Compensation for the Gridding Non-uniform Discrete Fourier Transform  [ :arrow_down: ](https://arxiv.org/pdf/2106.06660.pdf)
>  The Gridding algorithm has shown great utility for reconstructing images from non-uniformly spaced samples in the Fourier domain in several imaging modalities. Due to the non-uniform spacing, some correction for the variable density of the samples must be made. Existing methods for generating density compensation values are either sub-optimal or only consider a finite set of points (a set of measure 0) in the optimization. This manuscript presents the first density compensation algorithm for a general trajectory that takes into account the point spread function over a set of non-zero measure. We show that the images reconstructed with Gridding using the density compensation values of this method are of superior quality when compared to density compensation weights determined in other ways. Results are shown with a numerical phantom and with magnetic resonance images of the abdomen and the knee.      
### 39.Analog Seizure Detection for Implanted Responsive Neurostimulation  [ :arrow_down: ](https://arxiv.org/pdf/2106.06590.pdf)
>  Epilepsy can be treated with medication, however, $30\%$ of epileptic patients are still drug resistive. Devices like responsive neurostimluation systems are implanted in select patients who may not be amenable to surgical resection. However, state-of-the-art devices suffer from low accuracy and high sensitivity. We propose a novel patient-specific seizure detection system based on naïve Bayesian inference using Müller C-elements. The system improves upon the current leading neurostimulation device, NeuroPace's RNS by implementing analog signal processing for feature extraction, minimizing the power consumption compared to the digital counterpart. <br>Preliminary simulations were performed in MATLAB, demonstrating that through integrating multiple channels and features, up to $98\%$ detection accuracy for individual patients can be achieved. Similarly, power calculations were performed, demonstrating that the system uses $6.5 \mu W$ per channel, which when compared to the state-of-the-art NeuroPace system would increase battery life by up to $50 \%$.      
### 40.Scalable and accurate multi-GPU based image reconstruction of large-scale ptychography data  [ :arrow_down: ](https://arxiv.org/pdf/2106.07575.pdf)
>  While the advances in synchrotron light sources, together with the development of focusing optics and detectors, allow nanoscale ptychographic imaging of materials and biological specimens, the corresponding experiments can yield terabyte-scale large volumes of data that can impose a heavy burden on the computing platform. While Graphical Processing Units (GPUs) provide high performance for such large-scale ptychography datasets, a single GPU is typically insufficient for analysis and reconstruction. Several existing works have considered leveraging multiple GPUs to accelerate the ptychographic reconstruction. However, they utilize only Message Passing Interface (MPI) to handle the communications between GPUs. It poses inefficiency for the configuration that has multiple GPUs in a single node, especially while processing a single large projection, since it provides no optimizations to handle the heterogeneous GPU interconnections containing both low-speed links, e.g., PCIe, and high-speed links, e.g., NVLink. In this paper, we provide a multi-GPU implementation that can effectively solve large-scale ptychographic reconstruction problem with optimized performance on intra-node multi-GPU. We focus on the conventional maximum-likelihood reconstruction problem using conjugate-gradient (CG) for the solution and propose a novel hybrid parallelization model to address the performance bottlenecks in CG solver. Accordingly, we develop a tool called PtyGer (Ptychographic GPU(multiple)-based reconstruction), implementing our hybrid parallelization model design. The comprehensive evaluation verifies that PtyGer can fully preserve the original algorithm's accuracy while achieving outstanding intra-node GPU scalability.      
### 41.An optimized Capsule-LSTM model for facial expression recognition with video sequences  [ :arrow_down: ](https://arxiv.org/pdf/2106.07564.pdf)
>  To overcome the limitations of convolutional neural network in the process of facial expression recognition, a facial expression recognition model Capsule-LSTM based on video frame sequence is proposed. This model is composed of three networks includingcapsule encoders, capsule decoders and LSTM network. The capsule encoder extracts the spatial information of facial expressions in video frames. Capsule decoder reconstructs the images to optimize the network. LSTM extracts the temporal information between video frames and analyzes the differences in expression changes between frames. The experimental results from the MMI dataset show that the Capsule-LSTM model proposed in this paper can effectively improve the accuracy of video expression recognition.      
### 42.BPLF: A Bi-Parallel Linear Flow Model for Facial Expression Generation from Emotion Set Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.07563.pdf)
>  The flow-based generative model is a deep learning generative model, which obtains the ability to generate data by explicitly learning the data distribution. Theoretically its ability to restore data is stronger than other generative models. However, its implementation has many limitations, including limited model design, too many model parameters and tedious calculation. In this paper, a bi-parallel linear flow model for facial emotion generation from emotion set images is constructed, and a series of improvements have been made in terms of the expression ability of the model and the convergence speed in training. The model is mainly composed of several coupling layers superimposed to form a multi-scale structure, in which each coupling layer contains 1*1 reversible convolution and linear operation modules. Furthermore, this paper sorted out the current public data set of facial emotion images, made a new emotion data, and verified the model through this data set. The experimental results show that, under the traditional convolutional neural network, the 3-layer 3*3 convolution kernel is more conducive to extracte the features of the face images. The introduction of principal component decomposition can improve the convergence speed of the model.      
### 43.Dataset for eye-tracking tasks  [ :arrow_down: ](https://arxiv.org/pdf/2106.07554.pdf)
>  In recent years many different deep neural networks were developed, but due to a large number of layers in deep networks, their training requires a long time and a large number of datasets. Today is popular to use trained deep neural networks for various tasks, even for simple ones in which such deep networks are not required. The well-known deep networks such as YoloV3, SSD, etc. are intended for tracking and monitoring various objects, therefore their weights are heavy and the overall accuracy for a specific task is low. Eye-tracking tasks need to detect only one object - an iris in a given area. Therefore, it is logical to use a neural network only for this task. But the problem is the lack of suitable datasets for training the model. In the manuscript, we presented a dataset that is suitable for training custom models of convolutional neural networks for eye-tracking tasks. Using data set data, each user can independently pre-train the convolutional neural network models for eye-tracking tasks. This dataset contains annotated 10,000 eye images in an extension of 416 by 416 pixels. The table with annotation information shows the coordinates and radius of the eye for each image. This manuscript can be considered as a guide for the preparation of datasets for eye-tracking devices      
### 44.Machine Learning Based Prediction of Future Stress Events in a Driving Scenario  [ :arrow_down: ](https://arxiv.org/pdf/2106.07542.pdf)
>  This paper presents a model for predicting a driver's stress level up to one minute in advance. Successfully predicting future stress would allow stress mitigation to begin before the subject becomes stressed, reducing or possibly avoiding the performance penalties of stress. The proposed model takes features extracted from Galvanic Skin Response (GSR) signals on the foot and hand and Respiration and Electrocardiogram (ECG) signals from the chest of the driver. The data used to train the model was retrieved from an existing database and then processed to create statistical and frequency features. A total of 42 features were extracted from the data and then expanded into a total of 252 features by grouping the data and taking six statistical measurements of each group for each feature. A Random Forest Classifier was trained and evaluated using a leave-one-subject-out testing approach. The model achieved 94% average accuracy on the test data. Results indicate that the model performs well and could be used as part of a vehicle stress prevention system.      
### 45.Resilient Control of Platooning Networked Robitic Systems via Dynamic Watermarking  [ :arrow_down: ](https://arxiv.org/pdf/2106.07541.pdf)
>  Networked robotic systems, such as connected vehicle platoons, can improve the safety and efficiency of transportation networks by allowing for high-speed coordination. To enable such coordination, these systems rely on networked communications. This can make them susceptible to cyber attacks. Though security methods such as encryption or specially designed network topologies can increase the difficulty of successfully executing such an attack, these techniques are unable to guarantee secure communication against an attacker. More troublingly, these security methods are unable to ensure that individual agents are able to detect attacks that alter the content of specific messages. To ensure resilient behavior under such attacks, this paper formulates a networked linear time-varying version of dynamic watermarking in which each agent generates and adds a private excitation to the input of its corresponding robotic subsystem. This paper demonstrates that such a method can enable each agent in a networked robotic system to detect cyber attacks. By altering measurements sent between vehicles, this paper illustrates that an attacker can create unstable behavior within a platoon. By utilizing the dynamic watermarking method proposed in this paper, the attack is detected, allowing the vehicles in the platoon to gracefully degrade to a non-communicative control strategy that maintains safety across a variety of scenarios.      
### 46.Signal processing on simplicial complexes  [ :arrow_down: ](https://arxiv.org/pdf/2106.07471.pdf)
>  Higher-order networks have so far been considered primarily in the context of studying the structure of complex systems, i.e., the higher-order or multi-way relations connecting the constituent entities. More recently, a number of studies have considered dynamical processes that explicitly ac- count for such higher-order dependencies, e.g., in the context of epidemic spreading processes or opinion formation. In this chapter, we focus on a closely related, but distinct third perspective: how can we use higher-order relationships to process signals and data supported on higher-order network structures. In particular, we survey how ideas from signal processing of data supported on regular domains, such as time series or images, can be extended to graphs and simplicial complexes. We discuss Fourier analysis, signal denois- ing, signal interpolation, and nonlinear processing through neural networks based on simplicial complexes. Key to our developments is the Hodge Laplacian matrix, a multi-relational operator that leverages the special structure of simplicial complexes and generalizes desirable properties of the Laplacian matrix in graph signal processing.      
### 47.HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units  [ :arrow_down: ](https://arxiv.org/pdf/2106.07447.pdf)
>  Self-supervised approaches for speech representation learning are challenged by three unique problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon of input sound units during the pre-training phase, and (3) sound units have variable lengths with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine-tuning subsets. Using a 1B parameter model, HuBERT shows up to 19% and 13% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.      
### 48.Low cost cloud based remote microscopy for biological sciences  [ :arrow_down: ](https://arxiv.org/pdf/2106.07419.pdf)
>  A low cost remote imaging platform for biological applications was developed. The "Picroscope" is a device that allows the user to perform longitudinal imaging studies on multi-well cell culture plates. Here we present the network architecture and software used to facilitate communication between modules within the device as well as external cloud services. A web based console was created to control the device and view experiment results. Post processing tools were developed to analyze captured data in the cloud. The result is a platform for controlling biological experiments from outside the lab.      
### 49.Online Estimation of Resource Overload Risk in 5G Multi-Tenancy Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.07417.pdf)
>  The technology of network slicing, as the most characteristic feature of the fifth generation (5G) wireless networks, manages the resources and network functions in heterogeneous and logically isolated slices on the top of a shared physical infrastructure, where every slice can be independently customized to fulfill the specific requirements of its devoted service type. It enables a new paradigm of multi-tenancy networking, where the network slices can be leased by the mobile network operator (MNO) to tenants in form of public cloud computing service, known as Slice-asa- Service (SlaaS). Similar to classical cloud computing scenarios, SlaaS benefits from overbooking its resources to numerous tenants, taking advantage of the resource elasticity and diversity, at a price of risking overloading network resources and violating the service-level agreements (SLAs), which stipulate the quality of service (QoS) that shall be guaranteed to the network slices. Thus, it becomes a critical challenge to the MNOs, accurately estimating the resource overload risk - especially under the sophisticated network dynamics - for monitoring and enhancing the reliability of SlaaS business.      
### 50.An SMT Based Compositional Model to Solve a Conflict-Free Electric Vehicle Routing Problem  [ :arrow_down: ](https://arxiv.org/pdf/2106.07387.pdf)
>  The Vehicle Routing Problem (VRP) is the combinatorial optimization problem of designing routes for vehicles to visit customers in such a fashion that a cost function, typically the number of vehicles, or the total travelled distance is minimized. The problem finds applications in industrial scenarios, for example where Automated Guided Vehicles run through the plant to deliver components from the warehouse. This specific problem, henceforth called the Electric Conflict-Free Vehicle Routing Problem (CF-EVRP), involves constraints such as limited operating range of the vehicles, time windows on the delivery to the customers, and limited capacity on the number of vehicles the road segments can accommodate at the same time. Such a complex system results in a large model that cannot easily be solved to optimality in reasonable time. We therefore developed a compositional model that breaks down the problem into smaller and simpler sub-problems and provides sub-optimal, feasible solutions to the original problem. The algorithm exploits the strengths of SMT solvers, which proved in our previous work to be an efficient approach to deal with scheduling problems. Compared to a monolithic model for the CF-EVRP, written in the SMT standard language and solved using a state-of-the-art SMT solver the compositional model was found to be significantly faster.      
### 51.Probabilistic Forecasting of Imbalance Prices in the Belgian Context  [ :arrow_down: ](https://arxiv.org/pdf/2106.07361.pdf)
>  Forecasting imbalance prices is essential for strategic participation in the short-term energy markets. A novel two-step probabilistic approach is proposed, with a particular focus on the Belgian case. The first step consists of computing the net regulation volume state transition probabilities. It is modeled as a matrix computed using historical data. This matrix is then used to infer the imbalance prices since the net regulation volume can be related to the level of reserves activated and the corresponding marginal prices for each activation level are published by the Belgian Transmission System Operator one day before electricity delivery. This approach is compared to a deterministic model, a multi-layer perceptron, and a widely used probabilistic technique, Gaussian Processes.      
### 52.Dynamic Based Estimator for UAVs with Real-time Identification Using DNN and the Modified Relay Feedback Test  [ :arrow_down: ](https://arxiv.org/pdf/2106.07299.pdf)
>  Control performance of Unmanned Aerial Vehicles (UAVs) is directly affected by their ability to estimate their states accurately. With the increasing popularity of autonomous UAV solutions in real world applications, it is imperative to develop robust adaptive estimators that can ameliorate sensor noises in low-cost UAVs. Utilizing the knowledge of UAV dynamics in estimation can provide significant advantages, but remains challenging due to the complex and expensive pre-flight experiments required to obtain UAV dynamic parameters. In this paper, we propose two decoupled dynamic model based Extended Kalman Filters for UAVs, that provide high rate estimates for position, and velocity of rotational and translational states, as well as filtered inertial acceleration. The dynamic model parameters are estimated online using the Deep Neural Network and Modified Relay Feedback Test (DNN-MRFT) framework, without requiring any prior knowledge of the UAV physical parameters. The designed filters with real-time identified process model parameters are tested experimentally and showed two advantages. Firstly, smooth and lag-free estimates of the UAV rotational speed and inertial acceleration are obtained, and used to improve the closed loop system performance, reducing the controller action by over 6 %. Secondly, the proposed approach enabled the UAV to track aggressive trajectories with low rate position measurements, a task usually infeasible under those conditions. The experimental data shows that we achieved estimation performance matching other methods that requires full knowledge of the UAV parameters.      
### 53.Compressed Gradient Tracking for Decentralized Optimization Over General Directed Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.07243.pdf)
>  In this paper, we propose two communication-efficient algorithms for decentralized optimization over a multi-agent network with general directed network topology. In the first part, we consider a novel communication-efficient gradient tracking based method, termed Compressed Push-Pull (CPP), which combines the Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence for strongly convex and smooth objective functions. In the second part, we propose a broadcast-like version of CPP (B-CPP), which also achieves linear convergence rate under the same conditions for the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.      
### 54.Crowdsourcing via Annotator Co-occurrence Imputation and Provable Symmetric Nonnegative Matrix Factorization  [ :arrow_down: ](https://arxiv.org/pdf/2106.07193.pdf)
>  Unsupervised learning of the Dawid-Skene (D&amp;S) model from noisy, incomplete and crowdsourced annotations has been a long-standing challenge, and is a critical step towards reliably labeling massive data. A recent work takes a coupled nonnegative matrix factorization (CNMF) perspective, and shows appealing features: It ensures the identifiability of the D\&amp;S model and enjoys low sample complexity, as only the estimates of the co-occurrences of annotator labels are involved. However, the identifiability holds only when certain somewhat restrictive conditions are met in the context of crowdsourcing. Optimizing the CNMF criterion is also costly -- and convergence assurances are elusive. This work recasts the pairwise co-occurrence based D&amp;S model learning problem as a symmetric NMF (SymNMF) problem -- which offers enhanced identifiability relative to CNMF. In practice, the SymNMF model is often (largely) incomplete, due to the lack of co-labeled items by some annotators. Two lightweight algorithms are proposed for co-occurrence imputation. Then, a low-complexity shifted rectified linear unit (ReLU)-empowered SymNMF algorithm is proposed to identify the D&amp;S model. Various performance characterizations (e.g., missing co-occurrence recoverability, stability, and convergence) and evaluations are also presented.      
### 55.Multiple scattering ambisonics: three-dimensional sound foeld estimation using interacting spheres  [ :arrow_down: ](https://arxiv.org/pdf/2106.07157.pdf)
>  Rigid spherical microphone arrays (RSMAs) have been widely used in ambisonics sound field recording. While it is desired to combine the information captured by a grid of densely arranged RSMAs for expanding the area of accurate reconstruction, or sweet-spots, this is not trivial due to inter-array interference. Here we propose multiple scattering ambisonics, a method for three-dimensional ambisonics sound field recording using multiple acoustically interacting RSMAs. Numerical experiments demonstrate the sweet-spot expansion realized by the proposed method. The proposed method can be used with existing RSMAs as building blocks and opens possibilities including higher degrees-of-freedom spatial audio.      
### 56.Security Analysis of Camera-LiDAR Semantic-Level Fusion Against Black-Box Attacks on Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2106.07098.pdf)
>  To enable safe and reliable decision-making, autonomous vehicles (AVs) feed sensor data to perception algorithms to understand the environment. Sensor fusion, and particularly semantic fusion, with multi-frame tracking is becoming increasingly popular for detecting 3D objects. Recently, it was shown that LiDAR-based perception built on deep neural networks is vulnerable to LiDAR spoofing attacks. Thus, in this work, we perform the first analysis of camera-LiDAR fusion under spoofing attacks and the first security analysis of semantic fusion in any AV context. We find first that fusion is more successful than existing defenses at guarding against naive spoofing. However, we then define the frustum attack as a new class of attacks on AVs and find that semantic camera-LiDAR fusion exhibits widespread vulnerability to frustum attacks with between 70% and 90% success against target models. Importantly, the attacker needs less than 20 random spoof points on average for successful attacks - an order of magnitude less than established maximum capability. Finally, we are the first to analyze the longitudinal impact of perception attacks by showing the impact of multi-frame attacks.      
### 57.DP-NormFedAvg: Normalizing Client Updates for Privacy-Preserving Federated Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.07094.pdf)
>  In this paper, we focus on facilitating differentially private quantized communication between the clients and server in federated learning (FL). Towards this end, we propose to have the clients send a \textit{private quantized} version of only the \textit{unit vector} along the change in their local parameters to the server, \textit{completely throwing away the magnitude information}. We call this algorithm \texttt{DP-NormFedAvg} and show that it has the same order-wise convergence rate as \texttt{FedAvg} on smooth quasar-convex functions (an important class of non-convex functions for modeling optimization of deep neural networks), thereby establishing that discarding the magnitude information is not detrimental from an optimization point of view. We also introduce QTDL, a new differentially private quantization mechanism for unit-norm vectors, which we use in \texttt{DP-NormFedAvg}. QTDL employs \textit{discrete} noise having a Laplacian-like distribution on a \textit{finite support} to provide privacy. We show that under a growth-condition assumption on the per-sample client losses, the extra per-coordinate communication cost in each round incurred due to privacy by our method is $\mathcal{O}(1)$ with respect to the model dimension, which is an improvement over prior work. Finally, we show the efficacy of our proposed method with experiments on fully-connected neural networks trained on CIFAR-10 and Fashion-MNIST.      
### 58.Decentralized Inertial Best-Response with Voluntary and Limited Communication in Random Communication Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.07079.pdf)
>  Multiple autonomous agents interact over a random communication network to maximize their individual utility functions which depend on the actions of other agents. We consider decentralized best-response with inertia type algorithms in which agents form beliefs about the future actions of other players based on local information, and take an action that maximizes their expected utility computed with respect to these beliefs or continue to take their previous action. We show convergence of these types of algorithms to a Nash equilibrium in weakly acyclic games under the condition that the belief update and information exchange protocols successfully learn the actions of other players with positive probability in finite time given a static environment, i.e., when other agents' actions do not change. We design a decentralized fictitious play algorithm with voluntary and limited communication (DFP-VL) protocols that satisfy this condition. In the voluntary communication protocol, each agent decides whom to exchange information with by assessing the novelty of its information and the potential effect of its information on others' assessments of their utility functions. The limited communication protocol entails agents sending only their most frequent action to agents that they decide to communicate with. Numerical experiments on a target assignment game demonstrate that the voluntary and limited communication protocol can more than halve the number of communication attempts while retaining the same convergence rate as DFP in which agents constantly attempt to communicate.      
### 59.Risk Assessment of Stealthy Attacks on Uncertain Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.07071.pdf)
>  In this article, we address the problem of risk assessment of stealthy attacks on uncertain control systems. Considering data injection attacks that aim at maximizing impact while remaining undetected, we use the recently proposed output-to-output gain to characterize the risk associated with the impact of attacks in two setups: A full system knowledge attacker and a limited system knowledge attacker. The risk in each setup is formulated using a well-established risk metric, namely the Value-at-Risk and the maximum expected loss, respectively. Under these setups, the risk assessment problem corresponds to an untractable infinite non-convex optimization problem. To address this limitation, we adopt the framework of scenario-based optimization to approximate the infinite non-convex optimization problem by a sampled non-convex optimization problem. Then, based on the framework of dissipative system theory and S-procedure, the sampled non-convex risk assessment problem is formulated as an equivalent convex semi-definite program. Additionally, we derive the necessary and sufficient conditions for the risk to be bounded. Finally, we illustrate the results through numerical simulation of a hydro-turbine power system.      
### 60.Convex Sparse Blind Deconvolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.07053.pdf)
>  In the blind deconvolution problem, we observe the convolution of an unknown filter and unknown signal and attempt to reconstruct the filter and signal. The problem seems impossible in general, since there are seemingly many more unknowns than knowns . Nevertheless, this problem arises in many application fields; and empirically, some of these fields have had success using heuristic methods -- even economically very important ones, in wireless communications and oil exploration. Today's fashionable heuristic formulations pose non-convex optimization problems which are then attacked heuristically as well. The fact that blind deconvolution can be solved under some repeatable and naturally-occurring circumstances poses a theoretical puzzle. <br>To bridge the gulf between reported successes and theory's limited understanding, we exhibit a convex optimization problem that -- assuming signal sparsity -- can convert a crude approximation to the true filter into a high-accuracy recovery of the true filter. Our proposed formulation is based on L1 minimization of inverse filter outputs. We give sharp guarantees on performance of the minimizer assuming sparsity of signal, showing that our proposal precisely recovers the true inverse filter, up to shift and rescaling. There is a sparsity/initial accuracy tradeoff: the less accurate the initial approximation, the greater we rely on sparsity to enable exact recovery. To our knowledge this is the first reported tradeoff of this kind. We consider it surprising that this tradeoff is independent of dimension. <br>We also develop finite-$N$ guarantees, for highly accurate reconstruction under $N\geq O(k \log(k) )$ with high probability. We further show stable approximation when the true inverse filter is infinitely long and extend our guarantees to the case where the observations are contaminated by stochastic or adversarial noise.      
### 61.Cross-sentence Neural Language Models for Conversational Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.06922.pdf)
>  An important research direction in automatic speech recognition (ASR) has centered around the development of effective methods to rerank the output hypotheses of an ASR system with more sophisticated language models (LMs) for further gains. A current mainstream school of thoughts for ASR N-best hypothesis reranking is to employ a recurrent neural network (RNN)-based LM or its variants, with performance superiority over the conventional n-gram LMs across a range of ASR tasks. In real scenarios such as a long conversation, a sequence of consecutive sentences may jointly contain ample cues of conversation-level information such as topical coherence, lexical entrainment and adjacency pairs, which however remains to be underexplored. In view of this, we first formulate ASR N-best reranking as a prediction problem, putting forward an effective cross-sentence neural LM approach that reranks the ASR N-best hypotheses of an upcoming sentence by taking into consideration the word usage in its precedent sentences. Furthermore, we also explore to extract task-specific global topical information of the cross-sentence history in an unsupervised manner for better ASR performance. Extensive experiments conducted on the AMI conversational benchmark corpus indicate the effectiveness and feasibility of our methods in comparison to several state-of-the-art reranking methods.      
### 62.GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio  [ :arrow_down: ](https://arxiv.org/pdf/2106.06909.pdf)
>  This paper introduces GigaSpeech, an evolving, multi-domain English speech recognition corpus with 10,000 hours of high quality labeled audio suitable for supervised training, and 40,000 hours of total audio suitable for semi-supervised and unsupervised training. Around 40,000 hours of transcribed audio is first collected from audiobooks, podcasts and YouTube, covering both read and spontaneous speaking styles, and a variety of topics, such as arts, science, sports, etc. A new forced alignment and segmentation pipeline is proposed to create sentence segments suitable for speech recognition training, and to filter out segments with low-quality transcription. For system training, GigaSpeech provides five subsets of different sizes, 10h, 250h, 1000h, 2500h, and 10000h. For our 10,000-hour XL training subset, we cap the word error rate at 4% during the filtering/validation stage, and for all our other smaller training subsets, we cap it at 0%. The DEV and TEST evaluation sets, on the other hand, are re-processed by professional human transcribers to ensure high transcription quality. Baseline systems are provided for popular speech recognition toolkits, namely Athena, ESPnet, Kaldi and Pika.      
### 63.INADVERT: An Interactive and Adaptive Counterdeception Platform for Attention Enhancement and Phishing Prevention  [ :arrow_down: ](https://arxiv.org/pdf/2106.06907.pdf)
>  Deceptive attacks exploiting the innate and the acquired vulnerabilities of human users have posed severe threats to information and infrastructure security. This work proposes INADVERT, a systematic solution that generates interactive visual aids in real-time to prevent users from inadvertence and counter visual-deception attacks. Based on the eye-tracking outcomes and proper data compression, the INADVERT platform automatically adapts the visual aids to the user's varying attention status captured by the gaze location and duration. We extract system-level metrics to evaluate the user's average attention level and characterize the magnitude and frequency of the user's mind-wandering behaviors. These metrics contribute to an adaptive enhancement of the user's attention through reinforcement learning. To determine the optimal hyper-parameters in the attention enhancement mechanism, we develop an algorithm based on Bayesian optimization to efficiently update the design of the INADVERT platform and maximize the accuracy of the users' phishing recognition.      
### 64.Hyperspectral and Multispectral Classification for Coastal Wetland Using Depthwise Feature Interaction Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.06896.pdf)
>  The monitoring of coastal wetlands is of great importance to the protection of marine and terrestrial ecosystems. However, due to the complex environment, severe vegetation mixture, and difficulty of access, it is impossible to accurately classify coastal wetlands and identify their species with traditional classifiers. Despite the integration of multisource remote sensing data for performance enhancement, there are still challenges with acquiring and exploiting the complementary merits from multisource data. In this paper, the Deepwise Feature Interaction Network (DFINet) is proposed for wetland classification. A depthwise cross attention module is designed to extract self-correlation and cross-correlation from multisource feature pairs. In this way, meaningful complementary information is emphasized for classification. DFINet is optimized by coordinating consistency loss, discrimination loss, and classification loss. Accordingly, DFINet reaches the standard solution-space under the regularity of loss functions, while the spatial consistency and feature discrimination are preserved. Comprehensive experimental results on two hyperspectral and multispectral wetland datasets demonstrate that the proposed DFINet outperforms other competitive methods in terms of overall accuracy.      
### 65.Harmonization with Flow-based Causal Inference  [ :arrow_down: ](https://arxiv.org/pdf/2106.06845.pdf)
>  Heterogeneity in medical data, e.g., from data collected at different sites and with different protocols in a clinical study, is a fundamental hurdle for accurate prediction using machine learning models, as such models often fail to generalize well. This paper presents a normalizing-flow-based method to perform counterfactual inference upon a structural causal model (SCM) to harmonize such data. We formulate a causal model for observed effects (brain magnetic resonance imaging data) that result from known confounders (site, gender and age) and exogenous noise variables. Our method exploits the bijection induced by flow for harmonization. We can infer the posterior of exogenous variables, intervene on observations, and draw samples from the resultant SCM to obtain counterfactuals. We evaluate on multiple, large, real-world medical datasets to observe that this method leads to better cross-domain generalization compared to state-of-the-art algorithms. Further experiments that evaluate the quality of confounder-independent data generated by our model using regression and classification tasks are provided.      
### 66.Model-free Reinforcement Learning for Branching Markov Decision Processes  [ :arrow_down: ](https://arxiv.org/pdf/2106.06777.pdf)
>  We study reinforcement learning for the optimal control of Branching Markov Decision Processes (BMDPs), a natural extension of (multitype) Branching Markov Chains (BMCs). The state of a (discrete-time) BMCs is a collection of entities of various types that, while spawning other entities, generate a payoff. In comparison with BMCs, where the evolution of a each entity of the same type follows the same probabilistic pattern, BMDPs allow an external controller to pick from a range of options. This permits us to study the best/worst behaviour of the system. We generalise model-free reinforcement learning techniques to compute an optimal control strategy of an unknown BMDP in the limit. We present results of an implementation that demonstrate the practicality of the approach.      
### 67.Markov Decision Processes with Long-Term Average Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2106.06680.pdf)
>  We consider the problem of constrained Markov Decision Process (CMDP) where an agent interacts with a unichain Markov Decision Process. At every interaction, the agent obtains a reward. Further, there are $K$ cost functions. The agent aims to maximize the long-term average reward while simultaneously keeping the $K$ long-term average costs lower than a certain threshold. In this paper, we propose CMDP-PSRL, a posterior sampling based algorithm using which the agent can learn optimal policies to interact with the CMDP. Further, for MDP with $S$ states, $A$ actions, and diameter $D$, we prove that following CMDP-PSRL algorithm, the agent can bound the regret of not accumulating rewards from optimal policy by $\Tilde{O}(poly(DSA)\sqrt{T})$. Further, we show that the violations for any of the $K$ constraints is also bounded by $\Tilde{O}(poly(DSA)\sqrt{T})$. To the best of our knowledge, this is the first work which obtains a $\Tilde{O}(\sqrt{T})$ regret bounds for ergodic MDPs with long-term average constraints.      
### 68.iThing: Designing Next-Generation Things with Battery Health Self-Monitoring Capabilities for Sustainable IoT in Smart Cities  [ :arrow_down: ](https://arxiv.org/pdf/2106.06678.pdf)
>  An accurate and reliable technique for predicting Remaining Useful Life (RUL) for battery cells proves helpful in battery-operated IoT devices, especially in remotely operated sensor nodes. Data-driven methods have proved to be the most effective methods until now. These IoT devices have low computational capabilities to save costs, but Data-Driven battery health techniques often require a comparatively large amount of computational power to predict SOH and RUL due to most methods being feature-heavy. This issue calls for ways to predict RUL with the least amount of calculations and memory. This paper proposes an effective and novel peak extraction method to reduce computation and memory needs and provide accurate prediction methods using the least number of features while performing all calculations on-board. The model can self-sustain, requires minimal external interference, and hence operate remotely much longer. Experimental results prove the accuracy and reliability of this method. The Absolute Error (AE), Relative error (RE), and Root Mean Square Error (RMSE) are calculated to compare effectiveness. The training of the GPR model takes less than 2 seconds, and the correlation between SOH from peak extraction and RUL is 0.97.      
### 69.Spatially Scalable Lossy Coded Caching  [ :arrow_down: ](https://arxiv.org/pdf/2106.06646.pdf)
>  We apply the coded caching scheme proposed by Maddah-Ali and Niesen to a multipoint multicasting video paradigm. Partially caching the video files on the wireless devices provides an opportunity to decrease data traffic load in peak hours via sending multicast coded messages to users. In this paper, we propose a two-hop wireless network for video multicasting, where the common coded multicast message is transmitted through different single antenna Edge Nodes (ENs) to multiple antenna users. Each user can decide to decode any EN by using a zero forcing receiver. Motivated by Scalable Video Coding (SVC), we consider successive refinement source coding in order to provide a ``softer'' tradeoff between the number of decoded ENs and the source distortion at each user receiver. The resulting coding scheme can be seen as the concatenation of Maddah-Ali and Niesen coded caching for each source-coded layer, and multiple description coding. Using stochastic geometry, we investigate the tradeoff between delivery time and per-user average source distortion. The proposed system is spatially scalable in the sense that, for given users' and ENs' spatial density, the achieved distortion-delivery time performance is independent of the coverage area (for in the limit of large area).      
### 70.Verified Synthesis of Optimal Safety Controllers for Human-Robot Collaboration  [ :arrow_down: ](https://arxiv.org/pdf/2106.06604.pdf)
>  We present a tool-supported approach for the synthesis, verification and validation of the control software responsible for the safety of the human-robot interaction in manufacturing processes that use collaborative robots. In human-robot collaboration, software-based safety controllers are used to improve operational safety, e.g., by triggering shutdown mechanisms or emergency stops to avoid accidents. Complex robotic tasks and increasingly close human-robot interaction pose new challenges to controller developers and certification authorities. Key among these challenges is the need to assure the correctness of safety controllers under explicit (and preferably weak) assumptions. Our controller synthesis, verification and validation approach is informed by the process, risk analysis, and relevant safety regulations for the target application. Controllers are selected from a design space of feasible controllers according to a set of optimality criteria, are formally verified against correctness criteria, and are translated into executable code and validated in a digital twin. The resulting controller can detect the occurrence of hazards, move the process into a safe state, and, in certain circumstances, return the process to an operational state from which it can resume its original task. We show the effectiveness of our software engineering approach through a case study involving the development of a safety controller for a manufacturing work cell equipped with a collaborative robot.      
### 71.Leveraging Pre-trained Language Model for Speech Sentiment Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.06598.pdf)
>  In this paper, we explore the use of pre-trained language models to learn sentiment information of written texts for speech sentiment analysis. First, we investigate how useful a pre-trained language model would be in a 2-step pipeline approach employing Automatic Speech Recognition (ASR) and transcripts-based sentiment analysis separately. Second, we propose a pseudo label-based semi-supervised training strategy using a language model on an end-to-end speech sentiment approach to take advantage of a large, but unlabeled speech dataset for training. Although spoken and written texts have different linguistic characteristics, they can complement each other in understanding sentiment. Therefore, the proposed system can not only model acoustic characteristics to bear sentiment-specific information in speech signals, but learn latent information to carry sentiments in the text representation. In these experiments, we demonstrate the proposed approaches improve F1 scores consistently compared to systems without a language model. Moreover, we also show that the proposed framework can reduce 65% of human supervision by leveraging a large amount of data without human sentiment annotation and boost performance in a low-resource condition where the human sentiment annotation is not available enough.      

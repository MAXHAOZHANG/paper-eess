# ArXiv eess --Wed, 9 Jun 2021
### 1.Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions  [ :arrow_down: ](https://arxiv.org/pdf/2106.04492.pdf)
>  We present the task description and discussion on the results of the DCASE 2021 Challenge Task 2. Last year, we organized unsupervised anomalous sound detection (ASD) task; identifying whether the given sound is normal or anomalous without anomalous training data. In this year, we organize an advanced unsupervised ASD task under domain-shift conditions which focuses on the inevitable problem for the practical use of ASD systems. The main challenge of this task is to detect unknown anomalous sounds where the acoustic characteristics of the training and testing samples are different, i.e. domain-shifted. This problem is frequently occurs due to changes in seasons, manufactured products, and/or environmental noise. After the challenge submission deadline, we will add challenge results and analysis of the submissions.      
### 2.PolypGen: A multi-center polyp detection and segmentation dataset for generalisability assessment  [ :arrow_down: ](https://arxiv.org/pdf/2106.04463.pdf)
>  Polyps in the colon are widely known as cancer precursors identified by colonoscopy either related to diagnostic work-up for symptoms, colorectal cancer screening or systematic surveillance of certain diseases. Whilst most polyps are benign, the number, size and the surface structure of the polyp are tightly linked to the risk of colon cancer. There exists a high missed detection rate and incomplete removal of colon polyps due to the variable nature, difficulties to delineate the abnormality, high recurrence rates and the anatomical topography of the colon. In the past, several methods have been built to automate polyp detection and segmentation. However, the key issue of most methods is that they have not been tested rigorously on a large multi-center purpose-built dataset. Thus, these methods may not generalise to different population datasets as they overfit to a specific population and endoscopic surveillance. To this extent, we have curated a dataset from 6 different centers incorporating more than 300 patients. The dataset includes both single frame and sequence data with 3446 annotated polyp labels with precise delineation of polyp boundaries verified by six senior gastroenterologists. To our knowledge, this is the most comprehensive detection and pixel-level segmentation dataset curated by a team of computational scientists and expert gastroenterologists. This dataset has been originated as the part of the Endocv2021 challenge aimed at addressing generalisability in polyp detection and segmentation. In this paper, we provide comprehensive insight into data construction and annotation strategies, annotation quality assurance and technical validation for our extended EndoCV2021 dataset which we refer to as PolypGen.      
### 3.An Analysis on Rate-Splitting Multiple Access for IRS Aided 6G Communication  [ :arrow_down: ](https://arxiv.org/pdf/2106.04418.pdf)
>  Integrating intelligent reflecting surface (IRS) and Rate-Splitting Multiple Access (RSMA) is an effective solution to improve the spectral/energy efficiency in next-generation (beyond 5G (B5G) and 6G) wireless networks. In this paper, we investigate a rate-splitting (RS)-based transmission technique for an IRS-aided communication network involving both near and cell-edge users. In particular, we derive a new architecture called IRS-RS that leverages the interplay between RS and IRS, with an aim to maximize the weighted sum-rate (WSR) of users by selecting the reflecting coefficients at the IRS and designing beamformers at the BS under the constraints of power at the base station (BS), quality of service (QoS) at each user and finite resolution at the IRS. To solve the non-convex WSR maximization problem, we propose an alternating algorithm and compare its performance with baseline non-orthogonal multiple access (NOMA) based transmission for an IRS-aided communication network for both perfect and imperfect CSIT cases. Through numerical results, it is shown that the proposed IRS-RS architecture yields better QoS with respect to the cell-edge users when compared to IRS-NOMA transmission scheme.      
### 4.Secure Dual-Functional Radar-Communication System via Exploiting Known Interference in the Presence of Clutter  [ :arrow_down: ](https://arxiv.org/pdf/2106.04386.pdf)
>  This paper addresses the problem that designing the transmit waveform and receive beamformer aims to maximize the receive radar SINR for secure dual-functional radar-communication (DFRC) systems, where the undesired multi-user interference (MUI) is transformed to useful power. In this system, the DFRC base station (BS) serves communication users (CUs) and detects the target simultaneously, where the radar target is regarded to be malicious since it might eavesdrop the transmitted information from BS to CUs. Inspired by the constructive interference (CI) approach, the phases of received signals at CUs are rotated into the relaxed decision region, and the undesired MUI is designed to contribute in useful power. Then, the convex approximation method (SCA) is adopted to tackle the optimization problem. Finally, numerical results are given to validate the effectiveness of the proposed method, which shows that it is viable to ensure the communication data secure adopting the techniques that we propose.      
### 5.Computer-Assisted Analysis of Biomedical Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.04381.pdf)
>  Nowadays, the amount of heterogeneous biomedical data is increasing more and more thanks to novel sensing techniques and high-throughput technologies. In reference to biomedical image analysis, the advances in image acquisition modalities and high-throughput imaging experiments are creating new challenges. This huge information ensemble could overwhelm the analytic capabilities needed by physicians in their daily decision-making tasks as well as by biologists investigating complex biochemical systems. In particular, quantitative imaging methods convey scientifically and clinically relevant information in prediction, prognosis or treatment response assessment, by also considering radiomics approaches. Therefore, the computational analysis of medical and biological images plays a key role in radiology and laboratory applications. In this regard, frameworks based on advanced Machine Learning and Computational Intelligence can significantly improve traditional Image Processing and Pattern Recognition approaches. However, conventional Artificial Intelligence techniques must be tailored to address the unique challenges concerning biomedical imaging data. This thesis aims at proposing novel and advanced computer-assisted methods for biomedical image analysis, also as an instrument in the development of Clinical Decision Support Systems, by always keeping in mind the clinical feasibility of the developed solutions. In conclusion, the ultimate goal of these research studies is to gain clinically and biologically useful insights that can guide differential diagnosis and therapies, leading towards biomedical data integration for personalized medicine. As a matter of fact, the proposed computer-assisted bioimage analysis methods can be beneficial for the definition of imaging biomarkers, as well as for quantitative medicine and biology.      
### 6.Sequence Alignment Algorithm for Statistical Similarity Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2106.04349.pdf)
>  This paper presents a new approach to statistical similarity assessment based on sequence alignment. The algorithm performs mutual matching of two random sequences by successively searching for common elements and by applying sequence breaks to matchless elements in the function of exponential cost. As a result, sequences varying significantly generate a high-cost alignment, while for low-cost sequences the introduced interruptions allow inferring the nature of sequences dependence. The most important advantage of the algorithm is an easy interpretation of the obtained results based on two parameters: stretch ratio and stretch cost. The operation of the method has been simulation tested and verified with the use of real data obtained from hardware random number generators. The proposed solution ensures simple implementation enabling the integration of hardware solutions, and operation based on only two sequences of any length predisposes the method to online testing.      
### 7.Revealing drivers and risks for power grid frequency stability with explainable AI  [ :arrow_down: ](https://arxiv.org/pdf/2106.04341.pdf)
>  Stable operation of the electrical power system requires the power grid frequency to stay within strict operational limits. With millions of consumers and thousands of generators connected to a power grid, detailed human-build models can no longer capture the full dynamics of this complex system. Modern machine learning algorithms provide a powerful alternative for system modelling and prediction, but the intrinsic black-box character of many models impedes scientific insights and poses severe security risks. Here, we show how eXplainable AI (XAI) alleviates these problems by revealing critical dependencies and influences on the power grid frequency. We accurately predict frequency stability indicators (such as RoCoF and Nadir) for three major European synchronous areas and identify key features that determine the power grid stability. Load ramps, specific generation ramps but also prices and forecast errors are central to understand and stabilize the power grid.      
### 8.Speech BERT Embedding For Improving Prosody in Neural TTS  [ :arrow_down: ](https://arxiv.org/pdf/2106.04312.pdf)
>  This paper presents a speech BERT model to extract embedded prosody information in speech segments for improving the prosody of synthesized speech in neural text-to-speech (TTS). As a pre-trained model, it can learn prosody attributes from a large amount of speech data, which can utilize more data than the original training data used by the target TTS. The embedding is extracted from the previous segment of a fixed length in the proposed BERT. The extracted embedding is then used together with the mel-spectrogram to predict the following segment in the TTS decoder. Experimental results obtained by the Transformer TTS show that the proposed BERT can extract fine-grained, segment-level prosody, which is complementary to utterance-level prosody to improve the final prosody of the TTS speech. The objective distortions measured on a single speaker TTS are reduced between the generated speech and original recordings. Subjective listening tests also show that the proposed approach is favorably preferred over the TTS without the BERT prosody embedding module, for both in-domain and out-of-domain applications. For Microsoft professional, single/multiple speakers and the LJ Speaker in the public database, subjective preference is similarly confirmed with the new BERT prosody embedding. TTS demo audio samples are in <a class="link-external link-https" href="https://judy44chen.github.io/TTSSpeechBERT/" rel="external noopener nofollow">this https URL</a>.      
### 9.Principled Data Completion of Network Constraints for Day Ahead Auctions in Power Markets  [ :arrow_down: ](https://arxiv.org/pdf/2106.04310.pdf)
>  Network constraints play a key role in the price finding mechanism for European Power Markets, but historical data is very sparse and usually insufficient for many quantitative applications. We reconstruct the constraints data, known as the Power Transmission Distribution Factors (PTDFs) and Remaining Available Margins (RAMs), by first recovering the underlying time dependent signals known as the Generation Shift Keys (GSKs) and Phase Angles (PAs), and the electricity grid characteristics, via a mathematical optimisation problem. This is solved by exploiting marginal convexity in certain subspaces via alternating minimisation. The GSKs and PAs are then mapped to the PTDFs and RAMs, using the grid structure. Our reconstruction achieves good in-sample and out-of-sample relative errors for the PTDFs and RAMs. We further show that our model outperforms the naive approach, and that the reconstructed GSKs and PAs recover specific structure.      
### 10.Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans  [ :arrow_down: ](https://arxiv.org/pdf/2106.04281.pdf)
>  Non-destructive testing is a set of techniques for defect detection in materials. While the set of imaging techniques are manifold, ultrasonic imaging is the one used the most. The analysis is mainly performed by human inspectors manually analyzing recorded images. The low number of defects in real ultrasonic inspections and legal issues considering data from such inspections make it difficult to obtain proper results from automatic ultrasonic image (B-scan) analysis. In this paper, we present a novel deep learning Generative Adversarial Network model for generating ultrasonic B-scans with defects in distinct locations. Furthermore, we show that generated B-scans can be used for synthetic data augmentation, and can improve the performance of deep convolutional neural object detection networks. Our novel method is demonstrated on a dataset of almost 4000 B-scans with more than 6000 annotated defects. Defect detection performance when training on real data yielded average precision of 71%. By training only on generated data the results increased to 72.1%, and by mixing generated and real data we achieve 75.7% average precision. We believe that synthetic data generation can generalize to other challenges with limited datasets and could be used for training human personnel.      
### 11.Constructing invariant tori using guaranteed Euler method  [ :arrow_down: ](https://arxiv.org/pdf/2106.04251.pdf)
>  We show here how, using Euler's integration method and an associated function bounding the error in function of time, one can generate structures closely surrounding the invariant tori of dynamical systems. Such structures are constructed from a finite number of balls of $\mathbb{R}^n$ and encompass the deformations of the tori when small perturbations of the flow of the system occur.      
### 12.Fast voltage boosters to improve transient stability of power systems with 100% of grid-forming VSC-based generation  [ :arrow_down: ](https://arxiv.org/pdf/2106.04182.pdf)
>  Grid-forming voltage source converter (GF-VSC) has been identified as the key technology for the operation of future converter-dominated power systems. Among many other issues, transient stability of this type of power systems remains an open topic of research because it is still a key limiting factor for stressed power systems. Previous studies have proposed control strategies for GF-VSC to improve transient stability of this type of systems by suitable current-limitation algorithms and/or control of active-power injections. As an alternative, this paper proposes two fast voltage boosters to improve transient stability of power systems with 100% of GF-VSC-based generation with virtual synchronous machine (VSM). One control strategy uses local measurements, whereas the other one uses global measurements of the frequency of the centre of inertia (COI). Both strategies improve transient stability of this type of systems significantly. The advantage of using fast voltage boosters for this purpose is that the set points linked to frequency/active-power injection (i.e set points linked to the primary energy source of the VSCs) will not be modified. Furthermore, strategies such as current-limitation, active-power control and fast voltage controllers for transient stability improvement are compatible and complementary.      
### 13.EnMcGAN: Adversarial Ensemble Learning for 3D Complete Renal Structures Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.04130.pdf)
>  3D complete renal structures(CRS) segmentation targets on segmenting the kidneys, tumors, renal arteries and veins in one inference. Once successful, it will provide preoperative plans and intraoperative guidance for laparoscopic partial nephrectomy(LPN), playing a key role in the renal cancer treatment. However, no success has been reported in 3D CRS segmentation due to the complex shapes of renal structures, low contrast and large anatomical variation. In this study, we utilize the adversarial ensemble learning and propose Ensemble Multi-condition GAN(EnMcGAN) for 3D CRS segmentation for the first time. Its contribution is three-fold. 1)Inspired by windowing, we propose the multi-windowing committee which divides CTA image into multiple narrow windows with different window centers and widths enhancing the contrast for salient boundaries and soft tissues. And then, it builds an ensemble segmentation model on these narrow windows to fuse the segmentation superiorities and improve whole segmentation quality. 2)We propose the multi-condition GAN which equips the segmentation model with multiple discriminators to encourage the segmented structures meeting their real shape conditions, thus improving the shape feature extraction ability. 3)We propose the adversarial weighted ensemble module which uses the trained discriminators to evaluate the quality of segmented structures, and normalizes these evaluation scores for the ensemble weights directed at the input image, thus enhancing the ensemble results. 122 patients are enrolled in this study and the mean Dice coefficient of the renal structures achieves 84.6%. Extensive experiments with promising results on renal structures reveal powerful segmentation accuracy and great clinical significance in renal cancer treatment.      
### 14.Personalized PercepNet: Real-time, Low-complexity Target Voice Separation and Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.04129.pdf)
>  The presence of multiple talkers in the surrounding environment poses a difficult challenge for real-time speech communication systems considering the constraints on network size and complexity. In this paper, we present Personalized PercepNet, a real-time speech enhancement model that separates a target speaker from a noisy multi-talker mixture without compromising on complexity of the recently proposed PercepNet. To enable speaker-dependent speech enhancement, we first show how we can train a perceptually motivated speaker embedder network to produce a representative embedding vector for the given speaker. Personalized PercepNet uses the target speaker embedding as additional information to pick out and enhance only the target speaker while suppressing all other competing sounds. Our experiments show that the proposed model significantly outperforms PercepNet and other baselines, both in terms of objective speech enhancement metrics and human opinion scores.      
### 15.Probabilistic Scan Matching: Bayesian Pose Estimation from Point Clouds  [ :arrow_down: ](https://arxiv.org/pdf/2106.04099.pdf)
>  Estimating position and orientation change of a mobile platform from two consecutive point clouds provided by a high-resolution sensor is a key problem in autonomous navigation. In particular, scan matching algorithms aim to find the translation and rotation of the platform such that the two point clouds coincide. The association of measurements in point cloud one with measurements in point cloud two is a problem inherent to scan matching. Existing methods perform non-probabilistic data association, i.e., they assume a single association hypothesis. This leads to overconfident pose estimates and reduced estimation accuracy in ambiguous environments. Our probabilistic scan matching approach addresses this issue by considering all association hypotheses with their respective likelihoods. We formulate a holistic Bayesian estimation problem for both data association and pose estimation and present the corresponding joint factor graph. Near-optimum maximum a posteriori (MAP) estimates of the sensor pose are computed by performing iterative message passing on the factor graph. Our numerical study shows performance improvements compared to non-probabilistic scan matching methods that are based on the normal distributions transform (NDT) and implicit moving least squares (IMLS).      
### 16.Online Learning Robust Control of Nonlinear Dynamical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.04092.pdf)
>  In this work we address the problem of the online robust control of nonlinear dynamical systems perturbed by disturbance. We study the problem of attenuation of the total cost over a duration $T$ in response to the disturbances. We consider the setting where the cost function (at a particular time) is a general continuous function and adversarial, the disturbance is adversarial and bounded at any point of time. Our goal is to design a controller that can learn and adapt to achieve a certain level of attenuation. We analyse two cases (i) when the system is known and (ii) when the system is unknown. We measure the performance of the controller by the deviation of the controller's cost for a sequence of cost functions with respect to an attenuation $\gamma$, $R^p_t$. We propose an online controller and present guarantees for the metric $R^p_t$ when the maximum possible attenuation is given by $\overline{\gamma}$, which is a system constant. We show that when the controller has preview of the cost functions and the disturbances for a short duration of time and the system is known $R^p_T(\gamma) = O(1)$ when $\gamma \geq \gamma_c$, where $\gamma_c = \mathcal{O}(\overline{\gamma})$. We then show that when the system is unknown the proposed controller with a preview of the cost functions and the disturbances for a short horizon achieves $R^p_T(\gamma) = \mathcal{O}(N) + \mathcal{O}(1) + \mathcal{O}((T-N)g(N))$, when $\gamma \geq \gamma_c$, where $g(N)$ is the accuracy of a given nonlinear estimator and $N$ is the duration of the initial estimation period. We also characterize the lower bound on the required prediction horizon for these guarantees to hold in terms of the system constants.      
### 17.End-to-End Speaker Diarization Conditioned on Speech Activity and Overlap Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.04078.pdf)
>  In this paper, we present a conditional multitask learning method for end-to-end neural speaker diarization (EEND). The EEND system has shown promising performance compared with traditional clustering-based methods, especially in the case of overlapping speech. In this paper, to further improve the performance of the EEND system, we propose a novel multitask learning framework that solves speaker diarization and a desired subtask while explicitly considering the task dependency. We optimize speaker diarization conditioned on speech activity and overlap detection that are subtasks of speaker diarization, based on the probabilistic chain rule. Experimental results show that our proposed method can leverage a subtask to effectively model speaker diarization, and outperforms conventional EEND systems in terms of diarization error rate.      
### 18.Joint Channel Estimation and Mixed-ADCs Allocation for Massive MIMO via Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.04047.pdf)
>  Millimeter wave (mmWave) multi-user massive multi-input multi-output (MIMO) is a promising technique for the next generation communication systems. However, the hardware cost and power consumption grow significantly as the number of radio frequency (RF) components increases, which hampers the deployment of practical massive MIMO systems. To address this issue and further facilitate the commercialization of massive MIMO, mixed analog-to-digital converters (ADCs) architecture has been considered, where parts of conventionally assumed full-resolution ADCs are replaced by one-bit ADCs. In this paper, we first propose a deep learning-based (DL) joint pilot design and channel estimation method for mixed-ADCs mmWave massive MIMO. Specifically, we devise a pilot design neural network whose weights directly represent the optimized pilots, and develop a Runge-Kutta model-driven densely connected network as the channel estimator. Instead of randomly assigning the mixed-ADCs, we then design a novel antenna selection network for mixed-ADCs allocation to further improve the channel estimation accuracy. Moreover, we adopt an autoencoder-inspired end-to-end architecture to jointly optimize the pilot design, channel estimation and mixed-ADCs allocation networks. Simulation results show that the proposed DL-based methods have advantages over the traditional channel estimators as well as the state-of-the-art networks.      
### 19.Balancing Asymptotic and Transient Efficiency Guarantees in Set Covering Games  [ :arrow_down: ](https://arxiv.org/pdf/2106.04031.pdf)
>  Game theoretic approaches have gained traction as a robust methodology for designing distributed local algorithms that induce a desired overall system configuration in a multi-agent setting. However, much of the emphasis in these approaches is on providing asymptotic guarantees on the performance of network of agents, and there is a gap in the study of efficiency guarantees along transients of these distributed algorithms. Therefore, in this paper, we study the transient efficiency guarantees of a natural game-theoretic algorithm in the class of set covering games, which have been used to model a variety of applications. Our main results characterize the optimal utility design that maximizes the guaranteed efficiency along the transient of the natural dynamics. Furthermore, we characterize the Pareto-optimal frontier with regards to guaranteed efficiency in the transient and the asymptote under a class of game-theoretic designs. Surprisingly, we show that there exists an extreme trade-off between the long-term and short-term guarantees in that an asymptotically optimal game-theoretic design can perform arbitrarily bad in the transient.      
### 20.A Nonlinear Observability Analysis of Ambient Wind Estimation with Uncalibrated Sensors, Inspired by Insect Neural Encoding  [ :arrow_down: ](https://arxiv.org/pdf/2106.03974.pdf)
>  Estimating the direction of ambient fluid flow is key for many flying or swimming animals and robots, but can only be accomplished through indirect measurements and active control. Recent work with tethered flying insects indicates that their sensory representation of orientation, apparent flow, direction of movement, and control is represented by a 2-dimensional angular encoding in the central brain. This representation simplifies sensory integration by projecting the direction (but not scale) of measurements with different units onto a universal polar coordinate frame. To align these angular measurements with one another and the motor system does, however, require a calibration of angular gain and offset for each sensor. This calibration could change with time due to changes in the environment or physical structure. The circumstances under which small robots and animals with angular sensors and changing calibrations could self-calibrate and estimate the direction of ambient fluid flow while moving remains an open question. Here, a methodical nonlinear observability analysis is presented to address this. The analysis shows that it is mathematically feasible to continuously estimate flow direction and perform regular self-calibrations by adopting frequent changes in course (or active prevention thereof) and orientation, and requires fusion and temporal differentiation of three sensory measurements: apparent flow, orientation (or its derivative), and direction of motion (or its derivative). These conclusions are consistent with the zigzagging trajectories exhibited by many plume tracking organisms, suggesting that perhaps flow estimation is a secondary driver of their trajectory structure.      
### 21.AutoPtosis  [ :arrow_down: ](https://arxiv.org/pdf/2106.03905.pdf)
>  Blepharoptosis, or ptosis as it is more commonly referred to, is a condition of the eyelid where the upper eyelid droops. The current diagnosis for ptosis involves cumbersome manual measurements that are time-consuming and prone to human error. In this paper, we present AutoPtosis, an artificial intelligence based system with interpretable results for rapid diagnosis of ptosis. We utilize a diverse dataset collected at the University of Illinois Hospital and Health to successfully develop a robust deep learning model for prediction and also develop a clinically inspired model that calculates the marginal reflex distance and iris ratio. AutoPtosis achieved 95.5% accuracy on physician verified data that had an equal class balance. The proposed algorithm can help in the rapid and timely diagnosis of ptosis, significantly reduce the burden on the healthcare system, and save the patients and clinics valuable resources.      
### 22.KIGLIS: Smart Networks for Smart Cities  [ :arrow_down: ](https://arxiv.org/pdf/2106.04549.pdf)
>  Smart cities will be characterized by a variety of intelligent and networked services, each with specific requirements for the underlying network infrastructure. While smart city architectures and services have been studied extensively, little attention has been paid to the network technology. The KIGLIS research project, consisting of a consortium of companies, universities and research institutions, focuses on artificial intelligence for optimizing fiber-optic networks of a smart city, with a special focus on future mobility applications, such as automated driving. In this paper, we present early results on our process of collecting smart city requirements for communication networks, which will lead towards reference infrastructure and architecture solutions. Finally, we suggest directions in which artificial intelligence will improve smart city networks.      
### 23.Random Forest classifier for EEG-based seizure prediction  [ :arrow_down: ](https://arxiv.org/pdf/2106.04510.pdf)
>  Epileptic seizure prediction has gained considerable interest in the computational Epilepsy research community. This paper presents a Machine Learning based method for epileptic seizure prediction which outperforms state-of-the art methods. We compute a probability for a given epoch, of being pre-ictal against interictal using the Random Forest classifier and introduce new concepts to enhance the robustness of the algorithm to false alarms. We assessed our method on 20 patients of the benchmark scalp EEG CHB-MIT dataset for a seizure prediction horizon (SPH) of 5 minutes and a seizure occurrence period (SOP) of 30 minutes. Our approach achieves a sensitivity of 82.07 % and a low false positive rate (FPR) of 0.0799 /h. We also tested our approach on intracranial EEG recordings.      
### 24.Interpreting Deep Learning based Cerebral Palsy Prediction with Channel Attention  [ :arrow_down: ](https://arxiv.org/pdf/2106.04471.pdf)
>  Early prediction of cerebral palsy is essential as it leads to early treatment and monitoring. Deep learning has shown promising results in biomedical engineering thanks to its capacity of modelling complicated data with its non-linear architecture. However, due to their complex structure, deep learning models are generally not interpretable by humans, making it difficult for clinicians to rely on the findings. In this paper, we propose a channel attention module for deep learning models to predict cerebral palsy from infants' body movements, which highlights the key features (i.e. body joints) the model identifies as important, thereby indicating why certain diagnostic results are found. To highlight the capacity of the deep network in modelling input features, we utilize raw joint positions instead of hand-crafted features. We validate our system with a real-world infant movement dataset. Our proposed channel attention module enables the visualization of the vital joints to this disease that the network considers. Our system achieves 91.67% accuracy, suppressing other state-of-the-art deep learning methods.      
### 25.3KG: Contrastive Learning of 12-Lead Electrocardiograms using Physiologically-Inspired Augmentations  [ :arrow_down: ](https://arxiv.org/pdf/2106.04452.pdf)
>  Self-supervised contrastive learning approaches leverage modality-specific context or invariances to pretrain models using unlabeled data. While contrastive learning has demonstrated promising on results in the image domain, there has been limited work on determining how to exploit modality-specific invariances in biosignals such as the electrocardiogram. In this work, we propose 3KG, a method to generate positive pairs for contrastive learning using physiologically-inspired 3D augmentations of the 12-lead electrocardiogram. We evaluate representation quality by fine-tuning a linear layer for the downstream task of 24-class diagnosis on the PhysioNet 2020 challenge training data, and find that models trained with physiologically-inspired augmentations both outperform and complement standard time-series augmentations. Our best performing strategy, which incorporates spatial rotation, spatial scaling, and time masking, achieves a performance increase of 0.16, .086, and .046 in mean AUROC over a randomly initialized baseline at 1%, 10%, and 100% label fractions respectively. Additionally, we show that the strength of spatial augmentations does not significantly affect the quality of the learned representations. Finally, we investigate the clinical relevance of how physiologically-inspired augmentations affect the performance of our classifier on different disease subgroupings. As expert annotations are often expensive and scarce for medical contexts, our approach highlights the potential of machine learning to tackle medical problems with large quantities of unlabeled biosignal data by exploiting their unique biological properties.      
### 26.Computation Offloading at Field Level: Motivation and Break-Even Point Calculation  [ :arrow_down: ](https://arxiv.org/pdf/2106.04449.pdf)
>  Smart manufacturing has the objective of creating highly flexible and resource optimized industrial plants. Furthermore, the improvement of product quality is another important target. These requirements implicate more complex control algo-rithms. Processing these algorithms may exceed the capabilities of resource constrained devices, such as programmable logic controllers (PLCs). In this case, the necessity for computation offloading is given. Due to the fact that industrial plants are currently designed for a life-cycle-time of more than ten years, in a realistic smart manufacturing scenario, these devices have to be considered. Therefore, we investigate the impact of complex algorithms on conventional PLCs by simulating them with a load generator. In addition, we propose a realistic factory scenario including benchmarks for both wireline and wireless communication systems. Thus, their round-trip time (RTT) is measured with and without additional load on the network. With the help of these investigations, break-even points for the application of computation offloading of two typical PLCs of Siemens S7 series can be calculated.      
### 27.On the relation between statistical learning and perceptual distances  [ :arrow_down: ](https://arxiv.org/pdf/2106.04427.pdf)
>  It has been demonstrated many times that the behavior of the human visual system is connected to the statistics of natural images. Since machine learning relies on the statistics of training data as well, the above connection has interesting implications when using perceptual distances (which mimic the behavior of the human visual system) as a loss function. In this paper, we aim to unravel the non-trivial relationship between the probability distribution of the data, perceptual distances, and unsupervised machine learning. To this end, we show that perceptual sensitivity is correlated with the probability of an image in its close neighborhood. We also explore the relation between distances induced by autoencoders and the probability distribution of the data used for training them, as well as how these induced distances are correlated with human perception. Finally, we discuss why perceptual distances might not lead to noticeable gains in performance over standard Euclidean distances in common image processing tasks except when data is scarce and the perceptual distance provides regularization.      
### 28.PANACEA cough sound-based diagnosis of COVID-19 for the DiCOVA 2021 Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2106.04423.pdf)
>  The COVID-19 pandemic has led to the saturation of public health services worldwide. In this scenario, the early diagnosis of SARS-Cov-2 infections can help to stop or slow the spread of the virus and to manage the demand upon health services. This is especially important when resources are also being stretched by heightened demand linked to other seasonal diseases, such as the flu. In this context, the organisers of the DiCOVA 2021 challenge have collected a database with the aim of diagnosing COVID-19 through the use of coughing audio samples. This work presents the details of the automatic system for COVID-19 detection from cough recordings presented by team PANACEA. This team consists of researchers from two European academic institutions and one company: EURECOM (France), University of Granada (Spain), and Biometric Vox S.L. (Spain). We developed several systems based on established signal processing and machine learning methods. Our best system employs a Teager energy operator cepstral coefficients (TECCs) based frontend and Light gradient boosting machine (LightGBM) backend. The AUC obtained by this system on the test set is 76.31% which corresponds to a 10% improvement over the official baseline.      
### 29.Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.04392.pdf)
>  Deep neural networks have been shown as a class of useful tools for addressing signal recognition issues in recent years, especially for identifying the nonlinear feature structures of signals. However, this power of most deep learning techniques heavily relies on an abundant amount of training data, so the performance of classic neural nets decreases sharply when the number of training data samples is small or unseen data are presented in the testing phase. This calls for an advanced strategy, i.e., model-agnostic meta-learning (MAML), which is able to capture the invariant representation of the data samples or signals. In this paper, inspired by the special structure of the signal, i.e., real and imaginary parts consisted in practical time-series signals, we propose a Complex-valued Attentional MEta Learner (CAMEL) for the problem of few-shot signal recognition by leveraging attention and meta-learning in the complex domain. To the best of our knowledge, this is also the first complex-valued MAML that can find the first-order stationary points of general nonconvex problems with theoretical convergence guarantees. Extensive experiments results showcase the superiority of the proposed CAMEL compared with the state-of-the-art methods.      
### 30.Proof methods for robust low-rank matrix recovery  [ :arrow_down: ](https://arxiv.org/pdf/2106.04382.pdf)
>  Low-rank matrix recovery problems arise naturally as mathematical formulations of various inverse problems, such as matrix completion, blind deconvolution, and phase retrieval. Over the last two decades, a number of works have rigorously analyzed the reconstruction performance for such scenarios, giving rise to a rather general understanding of the potential and the limitations of low-rank matrix models in sensing problems. In this article, we compare the two main proof techniques that have been paving the way to a rigorous analysis, discuss their potential and limitations, and survey their successful applications. On the one hand, we review approaches based on descent cone analysis, showing that they often lead to strong guarantees even in the presence of adversarial noise, but face limitations when it comes to structured observations. On the other hand, we discuss techniques using approximate dual certificates and the golfing scheme, which are often better suited to deal with practical measurement structures, but sometimes lead to weaker guarantees. Lastly, we review recent progress towards analyzing descent cones also for structured scenarios -- exploiting the idea of splitting the cones into multiple parts that are analyzed via different techniques.      
### 31.An Intelligent Hybrid Model for Identity Document Classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.04345.pdf)
>  Digitization, i.e., the process of converting information into a digital format, may provide various opportunities (e.g., increase in productivity, disaster recovery, and environmentally friendly solutions) and challenges for businesses. In this context, one of the main challenges would be to accurately classify numerous scanned documents uploaded every day by customers as usual business processes. For example, processes in banking (e.g., applying for loans) or the Government Registry of BDM (Births, Deaths, and Marriages) applications may involve uploading several documents such as a driver's license and passport. There are not many studies available to address the challenge as an application of image classification. Although some studies are available which used various methods, a more accurate model is still required. The current study has proposed a robust fusion model to define the type of identity documents accurately. The proposed approach is based on two different methods in which images are classified based on their visual features and text features. A novel model based on statistics and regression has been proposed to calculate the confidence level for the feature-based classifier. A fuzzy-mean fusion model has been proposed to combine the classifier results based on their confidence score. The proposed approach has been implemented using Python and experimentally validated on synthetic and real-world datasets. The performance of the proposed model is evaluated using the Receiver Operating Characteristic (ROC) curve analysis.      
### 32.Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2106.04306.pdf)
>  While classic control theory offers state of the art solutions in many problem scenarios, it is often desired to improve beyond the structure of such solutions and surpass their limitations. To this end, \emph{\gls{rpl}} offers a formulation to improve existing controllers with reinforcement learning (RL) by learning an additive "residual" to the output of a given controller. However, the applicability of such an approach highly depends on the structure of the controller. Often, internal feedback signals of the controller limit an RL algorithm to adequately change the policy and, hence, learn the task. We propose a new formulation that addresses these limitations by also modifying the feedback signals to the controller with an RL policy and show superior performance of our approach on a contact-rich peg-insertion task under position and orientation uncertainty. In addition, we use a recent impedance control architecture as control framework and show the difficulties of standard RPL. Furthermore, we introduce an adaptive curriculum for the given task to gradually increase the task difficulty in terms of position and orientation uncertainty. A video showing the results can be found at <a class="link-external link-https" href="https://youtu.be/SAZm_Krze7U" rel="external noopener nofollow">this https URL</a> .      
### 33.Unsupervised Word Segmentation from Discrete Speech Units in Low-Resource Settings  [ :arrow_down: ](https://arxiv.org/pdf/2106.04298.pdf)
>  When documenting oral-languages, Unsupervised Word Segmentation (UWS) from speech is a useful, yet challenging, task. It can be performed from phonetic transcriptions, or in the absence of these, from the output of unsupervised speech discretization models. These discretization models are trained using raw speech only, producing discrete speech units which can be applied for downstream (text-based) tasks. In this paper we compare five of these models: three Bayesian and two neural approaches, with regards to the exploitability of the produced units for UWS. Two UWS models are experimented with and we report results for Finnish, Hungarian, Mboshi, Romanian and Russian in a low-resource setting (using only 5k sentences). Our results suggest that neural models for speech discretization are difficult to exploit in our setting, and that it might be necessary to adapt them to limit sequence length. We obtain our best UWS results by using the SHMM and H-SHMM Bayesian models, which produce high quality, yet compressed, discrete representations of the input speech signal.      
### 34.NWT: Towards natural audio-to-video generation with representation learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.04283.pdf)
>  In this work we introduce NWT, an expressive speech-to-video model. Unlike approaches that use domain-specific intermediate representations such as pose keypoints, NWT learns its own latent representations, with minimal assumptions about the audio and video content. To this end, we propose a novel discrete variational autoencoder with adversarial loss, dVAE-Adv, which learns a new discrete latent representation we call Memcodes. Memcodes are straightforward to implement, require no additional loss terms, are stable to train compared with other approaches, and show evidence of interpretability. To predict on the Memcode space, we use an autoregressive encoder-decoder model conditioned on audio. Additionally, our model can control latent attributes in the generated video that are not annotated in the data. We train NWT on clips from HBO's Last Week Tonight with John Oliver. NWT consistently scores above other approaches in Mean Opinion Score (MOS) on tests of overall video naturalness, facial naturalness and expressiveness, and lipsync quality. This work sets a strong baseline for generalized audio-to-video synthesis. Samples are available at <a class="link-external link-https" href="https://next-week-tonight.github.io/NWT/" rel="external noopener nofollow">this https URL</a>.      
### 35.Optimizing a Binary Intelligent Reflecting Surface for OFDM Communications under Mutual Coupling  [ :arrow_down: ](https://arxiv.org/pdf/2106.04280.pdf)
>  An intelligent reflecting surface (IRS) can greatly improve the channel quality over a frequency-flat channel, if it is configured to reflect the incident signal as a beam towards the receiver. However, the fundamental limitations of the IRS technology become apparent over practical frequency-selective channels, where the same configuration must be used over the entire bandwidth. In this paper, we consider a wideband orthogonal frequency-division multiplexing (OFDM) system that is supported by a fairly realistic IRS setup with two unbalanced states per element and also mutual coupling. We describe the simulation setup considered in the IEEE Signal Processing Cup 2021, propose a low-complexity solution for channel estimation and IRS configuration, and evaluate it on that setup.      
### 36.Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.04275.pdf)
>  End-to-end speech recognition generally uses hand-engineered acoustic features as input and excludes the feature extraction module from its joint optimization. To extract learnable and adaptive features and mitigate information loss, we propose a new encoder that adopts globally attentive locally recurrent (GALR) networks and directly takes raw waveform as input. We observe improved ASR performance and robustness by applying GALR on different window lengths to aggregate fine-grain temporal information into multi-scale acoustic features. Experiments are conducted on a benchmark dataset AISHELL-2 and two large-scale Mandarin speech corpus of 5,000 hours and 21,000 hours. With faster speed and comparable model size, our proposed multi-scale GALR waveform encoder achieved consistent character error rate reductions (CERRs) from 7.9% to 28.1% relative over strong baselines, including Conformer and TDNN-Conformer. In particular, our approach demonstrated notable robustness than the traditional handcrafted features and outperformed the baseline MFCC-based TDNN-Conformer model by a 15.2% CERR on a music-mixed real-world speech test set.      
### 37.Converged Reconfigurable Intelligent Surface and Mobile Edge Computing for Space Information Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.04248.pdf)
>  Space information networks (SIN) are facing an ever-increasing thirst for high-speed and high-capacity seamless data transmission due to the integration of ground, air, and space communications. However, this imposes a new paradigm on the architecture design of the integrated SIN. Recently, reconfigurable intelligent surfaces (RISs) and mobile edge computing (MEC) are the most promising techniques, conceived to improve communication and computation capability by reconfiguring the wireless propagation environment and offloading. Hence, converging RISs and MEC in SIN is becoming an effort to reap the double benefits of computation and communication. In this article, we propose an RIS-assisted collaborative MEC architecture for SIN and discuss its implementation. Then we present its potential benefits, major challenges, and feasible applications. Subsequently, we study different cases to evaluate the system data rate and latency. Finally, we conclude with a list of open issues in this research area.      
### 38.Outage Performance of Multi-UAV Relaying-based Imperfect Hardware Hybrid Satellite-Terrestrial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.04223.pdf)
>  In this paper, we consider an imperfect hardware hybrid satellite-terrestrial network (HSTN) where the satellite communication with a ground user equipment (UE) is aided by the multiple amplify-and-forward (AF) three-dimensional ($3$D) mobile unmanned aerial vehicle (UAV) relays. Herein, we consider that all transceiver nodes are corrupted by the radio frequency hardware impairments (RFHI). Further, a stochastic mixed mobility (MM) model is employed to characterize the instantaneous location of $3$D mobile UAV relays in a cylindrical cell with UE lying at its center on ground plane. Taking into account the aggregate RFHI model for satellite and UAV relay transceivers and the random $3$D distances-based path loss for UAV relay-UE links, we investigate the outage probability (OP) and corresponding asymptotic outage behaviour of the system under an opportunistic relay selection scheme in a unified form for shadowed-Rician satellite links' channels and Nakagami-\emph{m} as well as Rician terrestrial links' channels. We corroborate theoretical analysis by simulations.      
### 39.Contention-based Grant-free Transmission with Extremely Sparse Orthogonal Pilot Scheme  [ :arrow_down: ](https://arxiv.org/pdf/2106.04172.pdf)
>  Due to the limited number of traditional orthogonal pilots, pilot collision will severely degrade the performance of contention-based grant-free transmission. To alleviate the pilot collision and exploit the spatial degree of freedom as much as possible, an extremely sparse orthogonal pilot scheme is proposed for uplink grant-free transmission. The proposed sparse pilot is used to perform active user detection and estimate the spatial channel. Then, inter-user interference suppression is performed by spatially combining the received data symbols using the estimated spatial channel. After that, the estimation and compensation of wireless channel and time/frequency offset are performed utilizing the geometric characteristics of combined data symbols. The task of pilot is much lightened, so that the extremely sparse orthogonal pilot can occupy minimized resources, and the number of orthogonal pilots can be increased significantly, which greatly reduces the probability of pilot collision. The numerical results show that the proposed extremely sparse orthogonal pilot scheme significantly improves the performance in high-overloading grant-free scenario.      
### 40.Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions  [ :arrow_down: ](https://arxiv.org/pdf/2106.04165.pdf)
>  Effective control and prediction of dynamical systems often require appropriate handling of continuous-time and discrete, event-triggered processes. Stochastic hybrid systems (SHSs), common across engineering domains, provide a formalism for dynamical systems subject to discrete, possibly stochastic, state jumps and multi-modal continuous-time flows. Despite the versatility and importance of SHSs across applications, a general procedure for the explicit learning of both discrete events and multi-mode continuous dynamics remains an open problem. This work introduces Neural Hybrid Automata (NHAs), a recipe for learning SHS dynamics without a priori knowledge on the number of modes and inter-modal transition dynamics. NHAs provide a systematic inference method based on normalizing flows, neural differential equations and self-supervision. We showcase NHAs on several tasks, including mode recovery and flow learning in systems with stochastic transitions, and end-to-end learning of hierarchical robot controllers.      
### 41.Broadcasted Residual Learning for Efficient Keyword Spotting  [ :arrow_down: ](https://arxiv.org/pdf/2106.04140.pdf)
>  Keyword spotting is an important research field because it plays a key role in device wake-up and user interaction on smart devices. However, it is challenging to minimize errors while operating efficiently in devices with limited resources such as mobile phones. We present a broadcasted residual learning method to achieve high accuracy with small model size and computational load. Our method configures most of the residual functions as 1D temporal convolution while still allows 2D convolution together using a broadcasted-residual connection that expands temporal output to frequency-temporal dimension. This residual mapping enables the network to effectively represent useful audio features with much less computation than conventional convolutional neural networks. We also propose a novel network architecture, Broadcasting-residual network (BC-ResNet), based on broadcasted residual learning and describe how to scale up the model according to the target device's resources. BC-ResNets achieve state-of-the-art 98.0% and 98.7% top-1 accuracy on Google speech command datasets v1 and v2, respectively, and consistently outperform previous approaches, using fewer computations and parameters.      
### 42.Efficient Speech Emotion Recognition Using Multi-Scale CNN and Attention  [ :arrow_down: ](https://arxiv.org/pdf/2106.04133.pdf)
>  Emotion recognition from speech is a challenging task. Re-cent advances in deep learning have led bi-directional recur-rent neural network (Bi-RNN) and attention mechanism as astandard method for speech emotion recognition, extractingand attending multi-modal features - audio and text, and thenfusing them for downstream emotion classification tasks. Inthis paper, we propose a simple yet efficient neural networkarchitecture to exploit both acoustic and lexical informationfrom speech. The proposed framework using multi-scale con-volutional layers (MSCNN) to obtain both audio and text hid-den representations. Then, a statistical pooling unit (SPU)is used to further extract the features in each modality. Be-sides, an attention module can be built on top of the MSCNN-SPU (audio) and MSCNN (text) to further improve the perfor-mance. Extensive experiments show that the proposed modeloutperforms previous state-of-the-art methods on IEMOCAPdataset with four emotion categories (i.e., angry, happy, sadand neutral) in both weighted accuracy (WA) and unweightedaccuracy (UA), with an improvement of 5.0% and 5.2% respectively under the ASR setting.      
### 43.Design of Low-Artifact Interpolation Kernels by Means of Computer Algebra  [ :arrow_down: ](https://arxiv.org/pdf/2106.04104.pdf)
>  We present a number of new piecewise-polynomial kernels for image interpolation. The kernels are constructed by optimizing a measure of interpolation quality based on the magnitude of anisotropic artifacts. The kernel design process is performed symbolically using Mathematica computer algebra system. Experimental evaluation involving 14 image quality assessment methods demonstrates that our results compare favorably with the existing linear interpolators.      
### 44.A Sequence Selection Bound for the Capacity of the Nonlinear Fiber Channel  [ :arrow_down: ](https://arxiv.org/pdf/2106.04097.pdf)
>  A novel technique to optimize the input distribution and compute a lower bound for the capacity of the nonlinear optical fiber channel is proposed. The technique improves previous bounds obtained with the additive white Gaussian noise decoding metric.      
### 45.Variational AutoEncoder for Reference based Image Super-Resolution  [ :arrow_down: ](https://arxiv.org/pdf/2106.04090.pdf)
>  In this paper, we propose a novel reference based image super-resolution approach via Variational AutoEncoder (RefVAE). Existing state-of-the-art methods mainly focus on single image super-resolution which cannot perform well on large upsampling factors, e.g., 8$\times$. We propose a reference based image super-resolution, for which any arbitrary image can act as a reference for super-resolution. Even using random map or low-resolution image itself, the proposed RefVAE can transfer the knowledge from the reference to the super-resolved images. Depending upon different references, the proposed method can generate different versions of super-resolved images from a hidden super-resolution space. Besides using different datasets for some standard evaluations with PSNR and SSIM, we also took part in the NTIRE2021 SR Space challenge and have provided results of the randomness evaluation of our approach. Compared to other state-of-the-art methods, our approach achieves higher diverse scores.      
### 46.Dilated Convolution based CSI Feedback Compression for Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.04043.pdf)
>  Although the frequency-division duplex (FDD) massive multiple-input multiple-output (MIMO) system can offer high spectral and energy efficiency, it requires to feedback the downlink channel state information (CSI) from users to the base station (BS), in order to fulfill the precoding design at the BS. However, the large dimension of CSI matrices in the massive MIMO system makes the CSI feedback very challenging, and it is urgent to compress the feedback CSI. To this end, this paper proposes a novel dilated convolution based CSI feedback network, namely DCRNet. Specifically, the dilated convolutions are used to enhance the receptive field (RF) of the proposed DCRNet without increasing the convolution size. Moreover, advanced encoder and decoder blocks are designed to improve the reconstruction performance and reduce computational complexity as well. Numerical results are presented to show the superiority of the proposed DCRNet over the conventional networks. In particular, the proposed DCRNet can achieve almost the state-of-the-arts (SOTA) performance with much lower floating point operations (FLOPs). The open source code and checkpoint of this work are available at <a class="link-external link-https" href="https://github.com/recusant7/DCRNet" rel="external noopener nofollow">this https URL</a>.      
### 47.Online Algorithms for Network Robustness under Connectivity Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2106.04037.pdf)
>  In this paper, we present algorithms for designing networks that are robust to node failures with minimal or limited number of links. We present algorithms for both the static network setting and the dynamic network setting; setting where new nodes can arrive in the future. For the static setting, we present algorithms for constructing the optimal network in terms of the number of links used for a given node size and the number of nodes that can fail. We then consider the dynamic setting where it is disruptive to remove any of the older links. For this setting, we present online algorithms for two cases: (i) when the number of nodes that can fail remains constant and (ii) when only the proportion of the nodes that can fail remains constant. We show that the proposed algorithm for the first case saves nearly $3/4$th of the total possible links at any point of time. We then present algorithms for various levels of the fraction of the nodes that can fail and characterize their link usage. We show that when $1/2$ the number of nodes can fail at any point of time, the proposed algorithm saves nearly $1/2$ of the total possible links at any point of time. We show that when the number of nodes that can fail is limited to the fraction $1/(2m)$ ($m \in \mathbb{N}$), the proposed algorithm saves nearly as much as $(1-1/2m)$ of the total possible links at any point of time. We also show that when the number of nodes that can fail at any point of time is $1/2$ of the number of nodes plus $n$, $n \in \mathbb{N}$, the number of links saved by the proposed algorithm reduces only linearly in $n$. We conjecture that the saving ratio achieved by the algorithms we present is optimal for the dynamic setting.      
### 48.Mission Level Uncertainty in Multi-Agent Resource Allocation  [ :arrow_down: ](https://arxiv.org/pdf/2106.04029.pdf)
>  In recent years, a significant research effort has been devoted to the design of distributed protocols for the control of multi-agent systems, as the scale and limited communication bandwidth characteristic of such systems render centralized control impossible. Given the strict operating conditions, it is unlikely that every agent in a multi-agent system will have local information that is consistent with the true system state. Yet, the majority of works in the literature assume that agents share perfect knowledge of their environment. This paper focuses on understanding the impact that inconsistencies in agents' local information can have on the performance of multi-agent systems. More specifically, we consider the design of multi-agent operations under a game theoretic lens where individual agents are assigned utilities that guide their local decision making. We provide a tractable procedure for designing utilities that optimize the efficiency of the resulting collective behavior (i.e., price of anarchy) for classes of set covering games where the extent of the information inconsistencies is known. In the setting where the extent of the informational inconsistencies is not known, we show -- perhaps surprisingly -- that underestimating the level of uncertainty leads to better price of anarchy than overestimating it.      
### 49.Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks  [ :arrow_down: ](https://arxiv.org/pdf/2106.04026.pdf)
>  Brain-computer interface (BCI) is used for communication between humans and devices by recognizing status and intention of humans. Communication between humans and a drone using electroencephalogram (EEG) signals is one of the most challenging issues in the BCI domain. In particular, the control of drone swarms (the direction and formation) has more advantages compared to the control of a drone. The visual imagery (VI) paradigm is that subjects visually imagine specific objects or scenes. Reduction of the variability among EEG signals of subjects is essential for practical BCI-based systems. In this study, we proposed the subepoch-wise feature encoder (SEFE) to improve the performances in the subject-independent tasks by using the VI dataset. This study is the first attempt to demonstrate the possibility of generalization among subjects in the VI-based BCI. We used the leave-one-subject-out cross-validation for evaluating the performances. We obtained higher performances when including our proposed module than excluding our proposed module. The DeepConvNet with SEFE showed the highest performance of 0.72 among six different decoding models. Hence, we demonstrated the feasibility of decoding the VI dataset in the subject-independent task with robust performances by using our proposed module.      
### 50.Byakto Speech: Real-time long speech synthesis with convolutional neural network: Transfer learning from English to Bangla  [ :arrow_down: ](https://arxiv.org/pdf/2106.03937.pdf)
>  Speech synthesis is one of the challenging tasks to automate by deep learning, also being a low-resource language there are very few attempts at Bangla speech synthesis. Most of the existing works can't work with anything other than simple Bangla characters script, very short sentences, etc. This work attempts to solve these problems by introducing Byakta, the first-ever open-source deep learning-based bilingual (Bangla and English) text to a speech synthesis system. A speech recognition model-based automated scoring metric was also proposed to evaluate the performance of a TTS model. We also introduce a test benchmark dataset for Bangla speech synthesis models for evaluating speech quality. The TTS is available at <a class="link-external link-https" href="https://github.com/zabir-nabil/bangla-tts" rel="external noopener nofollow">this https URL</a>      
### 51.How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild  [ :arrow_down: ](https://arxiv.org/pdf/2106.03932.pdf)
>  Successful active speaker detection requires a three-stage pipeline: (i) audio-visual encoding for all speakers in the clip, (ii) inter-speaker relation modeling between a reference speaker and the background speakers within each frame, and (iii) temporal modeling for the reference speaker. Each stage of this pipeline plays an important role for the final performance of the created architecture. Based on a series of controlled experiments, this work presents several practical guidelines for audio-visual active speaker detection. Correspondingly, we present a new architecture called ASDNet, which achieves a new state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5% outperforming the second best with a large margin of 4.7%. Our code and pretrained models are publicly available.      
### 52.PILOT: Introducing Transformers for Probabilistic Sound Event Localization  [ :arrow_down: ](https://arxiv.org/pdf/2106.03903.pdf)
>  Sound event localization aims at estimating the positions of sound sources in the environment with respect to an acoustic receiver (e.g. a microphone array). Recent advances in this domain most prominently focused on utilizing deep recurrent neural networks. Inspired by the success of transformer architectures as a suitable alternative to classical recurrent neural networks, this paper introduces a novel transformer-based sound event localization framework, where temporal dependencies in the received multi-channel audio signals are captured via self-attention mechanisms. Additionally, the estimated sound event positions are represented as multivariate Gaussian variables, yielding an additional notion of uncertainty, which many previously proposed deep learning-based systems designed for this application do not provide. The framework is evaluated on three publicly available multi-source sound event localization datasets and compared against state-of-the-art methods in terms of localization error and event detection accuracy. It outperforms all competing systems on all datasets with statistical significant differences in performance.      
### 53.SIGTYP 2021 Shared Task: Robust Spoken Language Identification  [ :arrow_down: ](https://arxiv.org/pdf/2106.03895.pdf)
>  While language identification is a fundamental speech and language processing task, for many languages and language families it remains a challenging task. For many low-resource and endangered languages this is in part due to resource availability: where larger datasets exist, they may be single-speaker or have different domains than desired application scenarios, demanding a need for domain and speaker-invariant language identification systems. This year's shared task on robust spoken language identification sought to investigate just this scenario: systems were to be trained on largely single-speaker speech from one domain, but evaluated on data in other domains recorded from speakers under different recording circumstances, mimicking realistic low-resource scenarios. We see that domain and speaker mismatch proves very challenging for current methods which can perform above 95% accuracy in-domain, which domain adaptation can address to some degree, but that these conditions merit further investigation to make spoken language identification accessible in many scenarios.      
### 54.Impact of data-splits on generalization: Identifying COVID-19 from cough and context  [ :arrow_down: ](https://arxiv.org/pdf/2106.03851.pdf)
>  Rapidly scaling screening, testing and quarantine has shown to be an effective strategy to combat the COVID-19 pandemic. We consider the application of deep learning techniques to distinguish individuals with COVID from non-COVID by using data acquirable from a phone. Using cough and context (symptoms and meta-data) represent such a promising approach. Several independent works in this direction have shown promising results. However, none of them report performance across clinically relevant data splits. Specifically, the performance where the development and test sets are split in time (retrospective validation) and across sites (broad validation). Although there is meaningful generalization across these splits the performance significantly varies (up to 0.1 AUC score). In addition, we study the performance of symptomatic and asymptomatic individuals across these three splits. Finally, we show that our model focuses on meaningful features of the input, cough bouts for cough and relevant symptoms for context. The code and checkpoints are available at <a class="link-external link-https" href="https://github.com/WadhwaniAI/cough-against-covid" rel="external noopener nofollow">this https URL</a>      

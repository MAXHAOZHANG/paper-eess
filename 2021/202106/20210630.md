# ArXiv eess --Wed, 30 Jun 2021
### 1.A Mixed-Supervision Multilevel GAN Framework for Image Quality Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.15575.pdf)
>  Deep neural networks for image quality enhancement typically need large quantities of highly-curated training data comprising pairs of low-quality images and their corresponding high-quality images. While high-quality image acquisition is typically expensive and time-consuming, medium-quality images are faster to acquire, at lower equipment costs, and available in larger quantities. Thus, we propose a novel generative adversarial network (GAN) that can leverage training data at multiple levels of quality (e.g., high and medium quality) to improve performance while limiting costs of data curation. We apply our mixed-supervision GAN to (i) super-resolve histopathology images and (ii) enhance laparoscopy images by combining super-resolution and surgical smoke removal. Results on large clinical and pre-clinical datasets show the benefits of our mixed-supervision GAN over the state of the art.      
### 2.A Survey on Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.15561.pdf)
>  Text to speech (TTS), or speech synthesis, which aims to synthesize intelligible and natural speech given text, is a hot research topic in speech, language, and machine learning communities and has broad applications in the industry. As the development of deep learning and artificial intelligence, neural network-based TTS has significantly improved the quality of synthesized speech in recent years. In this paper, we conduct a comprehensive survey on neural TTS, aiming to provide a good understanding of current research and future trends. We focus on the key components in neural TTS, including text analysis, acoustic models and vocoders, and several advanced topics, including fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc. We further summarize resources related to TTS (e.g., datasets, opensource implementations) and discuss future research directions. This survey can serve both academic researchers and industry practitioners working on TTS.      
### 3.HJB Based Optimal Safe Control using Control Barrier Functions  [ :arrow_down: ](https://arxiv.org/pdf/2106.15560.pdf)
>  This work proposes an optimal safe controller minimizing an infinite horizon cost functional subject to control barrier functions (CBFs) safety conditions. The constrained optimal control problem is reformulated as a minimization problem of the Hamilton-Jacobi-Bellman (HJB) equation subjected to the safety constraints. By solving the optimization problem, we are able to construct a closed form solution that satisfies optimality and safety conditions. The proposed solution is shown to be continuous and thus it renders the safe set forward invariant while minimizing the given cost. As a consequence, optimal stabilizability and safety objectives are achieved simultaneously. To synthesize the optimal safe controller, we present a modified Galerkin successive approximation (GSA) approach which guarantees an optimal safe solution given a stabilizing safe initialization. The proposed algorithm is implemented on a constrained system to show its efficacy.      
### 4.Model-Centric Volumetric Point Cloud Attributes  [ :arrow_down: ](https://arxiv.org/pdf/2106.15539.pdf)
>  Point clouds have recently gained interest, especially for real-time applications and for 3D-scanned material, such as is used in autonomous driving, architecture, and engineering, to model real estate for renovation or display. Point clouds are associated with geometry information and attributes such as color. Be the color unique or direction-dependent (in the case of plenoptic point clouds), it reflects the colors observed by cameras displaced around the object. Hence, not only are the viewing references assumed, but the illumination spectrum and illumination geometry is also implicit. We propose a model-centric description of the 3D object, that is independent of the illumination and of the position of the cameras. We want to be able to describe the objects themselves such that, at a later stage, the rendering of the model may decide where to place illumination, from which it may calculate the image viewed by a given camera. We want to be able to describe transparent or translucid objects, mirrors, fishbowls, fog and smoke. Volumetric clouds may allow us to describe the air, however ``empty'', and introduce air particles, in a manner independent of the viewer position. For that, we rely on some eletromagnetic properties to arrive at seven attributes per voxel that would describe the material and its color or transparency. Three attributes are for the transmissivity of each color, three are for the attenuation of each color, and another attribute is for diffuseness. These attributes give information about the object to the renderer, with whom lies the decision on how to render and depict each object.      
### 5.Measurement-Based Parameter Identification of DC-DC Converters with Adaptive Approximate Bayesian Computation  [ :arrow_down: ](https://arxiv.org/pdf/2106.15538.pdf)
>  The recent advances in power plants and energy resources have extended the applications of DC-DC converters in the power systems (especially in the context of DC micro-grids). Parameter identification can extract the parameters of the converters and generate accurate discrete simulation models. In this paper, we propose a measurement-based converter parameter calibration method by an adaptive Approximate Bayesian Computation with sequential Monte Carlo sampler (ABC SMC), which estimates the parameters related to passive and parasitic components. At first, we propose to find suitable prior distribution for the parameter which we don't know the prior information about them. With having prior distributions, we can use the ABC SMC to find the exact values of the parameters of the converter. We chose the distance function carefully and based on the simulations we assigned the best method for the threshold sequencing. For improving the computationally of the algorithm, we propose an adaptive weight that helps the algorithm to find the optimal values with fewer simulations. The effectiveness of the proposed method is validated for a DC-DC buck converter. The results show that the proposed approach can accurately and efficiently estimate the posterior distributions of the buck parameters subject to gross errors in the prior distributions of the parameters. The proposed algorithm can also be applied to other parameter identifications and optimization applications such as rectifiers, filters, or power supplies, among others.      
### 6.Partially Coherent Radar Unties Range Resolution from Bandwidth Limitations  [ :arrow_down: ](https://arxiv.org/pdf/2106.15525.pdf)
>  It is widely believed that range resolution, the ability to distinguish between two closely situated targets, depends inversely on the bandwidth of the transmitted radar signal. Here we demonstrate a different type of ranging system, which possesses superior range resolution that is almost completely free of bandwidth limitations. By sweeping over the coherence length of the transmitted signal, the partially coherent radar experimentally demonstrates an improvement of over an order of magnitude in resolving targets, compared to standard coherent radars with the same bandwidth.. A theoretical framework is developed to show that the resolution could be further improved without a bound, revealing a tradeoff between bandwidth and sweep time. This concept offers solutions to problems which require high range resolution and accuracy but available bandwidth is limited, as is the case for the autonomous car industry, optical imaging, and astronomy to name just few.      
### 7.Random Access Procedure over Non-Terrestrial Networks: From Theory to Practice  [ :arrow_down: ](https://arxiv.org/pdf/2106.15439.pdf)
>  Non-terrestrial Networks (NTNs) have become an appealing concept over the last few years and they are foreseen as a cornerstone for the next generations of mobile communication systems. Despite opening up new market opportunities and use cases for the future, the novel impairments caused by the signal propagation over the NTN channel compromises several procedures of the current cellular standards. One of the first and most important procedures impacted is the random access (RA) procedure, which is mainly utilized for achieving uplink synchronization among users in several standards, such as the fourth and fifth generation of mobile communication (4 &amp; 5G) and narrowband internet of things (NB-IoT). In this work, we analyse the challenges imposed by the considerably increased delay in the communication link on the RA procedure and propose new solutions to overcome those challenges. A trade-off analysis of various solutions is provided taking into account also the already existing ones in the literature. In order to broaden the scope of applicability, we keep the analysis general targeting 4G, 5G and NB-IoT systems since the RA procedure is quasi-identical among these technologies. Last but not least, we go one step further and validate our techniques in an experimental setup, consisting of a user and a base station implemented in open air interface (OAI), and an NTN channel implemented in hardware that emulates the signal propagation delay. The laboratory test-bed built in this work, not only enables us to validate various solutions, but also plays a crucial role in identifying novel challenges not previously treated in the literature. Finally, an important key performance indicator (KPI) of the RA procedure over NTN is shown, which is the time that a single user requires to establish a connection with the base station.      
### 8.PDL Impact on Linearly Coded Digital Phase Conjugation Techniques in CO-OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15405.pdf)
>  We investigate the impact of polarization-dependent loss (PDL) on the linearly coded digital phase conjugation (DPC) techniques in coherent optical orthogonal frequency division multiplexing (CO-OFDM) superchannel systems. We consider two DPC approaches: one uses orthogonal polarizations to transmit the linearly coded signal and its phase conjugate, while the other uses two orthogonal time slots of the same polarization. We compare the performances of these DPC approaches by considering both aligned- and statistical-PDL models. The investigation with aligned-PDL model indicates that the latter approach is more tolerant to PDL-induced distortions when compared to the former. Furthermore, the study using statistical-PDL model shows that the outage probability of the latter approach tends to zero at a root mean square PDL value of 3.6 dB. On the other hand, the former shows an outage probability of 0.63 for the same PDL value.      
### 9.Bi-static Radar Cross Section Test Method by Using Historic Marconi Set-up and Time Gating  [ :arrow_down: ](https://arxiv.org/pdf/2106.15404.pdf)
>  In this paper, a low-cost, simple and reliable bi-static Radar Cross Section (RCS) measurement method making use a historic Marconi set-up is presented. It uses a transmitting (Tx) antenna (located at a constant position, at a reference angle of {\theta} = 0o) and a receiver (Rx) antenna (mounted on a moveable arm calibrated in the azimuthal direction with an accuracy of 0.1o). A time gating method is used to extract the information from the reflection in the time domain; applying time filter allows removing the antenna side lobe effects and other ambient noise. In this method, the Rx antenna (on the movable arm) is used to measure the reflected field in the angular range from 1o to 90o of reflection from the structure (printed PCB) and from the reference configuration represented by a ground (GND) plane of the same dimension. The time gating method is then applied to each pair of PCB / GND measurements to extract the bi-static RCS pattern of the structure at a given frequency. Here comparison of measurement results carried out at 18 GHz and 32 GHz with simulation indicates the successful performance of the proposed method. It can be used as a low-cost, reliable and available option in future measurement and scientific research.      
### 10.Two-Stage Self-Supervised Cycle-Consistency Network for Reconstruction of Thin-Slice MR Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.15395.pdf)
>  The thick-slice magnetic resonance (MR) images are often structurally blurred in coronal and sagittal views, which causes harm to diagnosis and image post-processing. Deep learning (DL) has shown great potential to re-construct the high-resolution (HR) thin-slice MR images from those low-resolution (LR) cases, which we refer to as the slice interpolation task in this work. However, since it is generally difficult to sample abundant paired LR-HR MR images, the classical fully supervised DL-based models cannot be effectively trained to get robust performance. To this end, we propose a novel Two-stage Self-supervised Cycle-consistency Network (TSCNet) for MR slice interpolation, in which a two-stage self-supervised learning (SSL) strategy is developed for unsupervised DL network training. The paired LR-HR images are synthesized along the sagittal and coronal directions of input LR images for network pretraining in the first-stage SSL, and then a cyclic in-terpolation procedure based on triplet axial slices is designed in the second-stage SSL for further refinement. More training samples with rich contexts along all directions are exploited as guidance to guarantee the improved in-terpolation performance. Moreover, a new cycle-consistency constraint is proposed to supervise this cyclic procedure, which encourages the network to reconstruct more realistic HR images. The experimental results on a real MRI dataset indicate that TSCNet achieves superior performance over the conventional and other SSL-based algorithms, and obtains competitive quali-tative and quantitative results compared with the fully supervised algorithm.      
### 11.Polynomial-Time Algorithms for Structurally Observable Graphs by Controlling Minimal Vertices  [ :arrow_down: ](https://arxiv.org/pdf/2106.15374.pdf)
>  The aim of this paper is to characterize an important class of marked digraphs, called structurally observable graphs (SOGs), and to solve two minimum realization problems. To begin with, by exploring structural observability of large-scale Boolean networks (LSBNs), an underlying type of SOGs is provided based on a recent observability criterion of conjunctive BNs. Besides, SOGs are also proved to have important applicability to structural observability of general discrete-time systems. Further, two minimum realization strategies are considered to induce an SOG from an arbitrarily given digraph by marking and controlling the minimal vertices, respectively. It indicates that one can induce an observable system by means of adding the minimal sensors or modifying the adjacency relation of minimal vertices. Finally, the structural observability of finite-field networks, and the minimum pinned node theorem for Boolean networks are displayed as application and simulation. The most salient superiority is that the designed algorithms are polynomial time and avoid exhaustive brute-force searches. It means that our results can be applied to deal with the observability of large-scale systems (particularly, LSBNs), whose observability analysis and the minimum controlled node theorem are known as intractable problems.      
### 12.Patient-independent Schizophrenia Relapse Prediction Using Mobile Sensor based Daily Behavioral Rhythm Changes  [ :arrow_down: ](https://arxiv.org/pdf/2106.15353.pdf)
>  A schizophrenia relapse has severe consequences for a patient's health, work, and sometimes even life safety. If an oncoming relapse can be predicted on time, for example by detecting early behavioral changes in patients, then interventions could be provided to prevent the relapse. In this work, we investigated a machine learning based schizophrenia relapse prediction model using mobile sensing data to characterize behavioral features. A patient-independent model providing sequential predictions, closely representing the clinical deployment scenario for relapse prediction, was evaluated. The model uses the mobile sensing data from the recent four weeks to predict an oncoming relapse in the next week. We used the behavioral rhythm features extracted from daily templates of mobile sensing data, self-reported symptoms collected via EMA (Ecological Momentary Assessment), and demographics to compare different classifiers for the relapse prediction. Naive Bayes based model gave the best results with an F2 score of 0.083 when evaluated in a dataset consisting of 63 schizophrenia patients, each monitored for up to a year. The obtained F2 score, though low, is better than the baseline performance of random classification (F2 score of 0.02 $\pm$ 0.024). Thus, mobile sensing has predictive value for detecting an oncoming relapse and needs further investigation to improve the current performance. Towards that end, further feature engineering and model personalization based on the behavioral idiosyncrasies of a patient could be helpful.      
### 13.Short-Term Load Forecasting for Smart HomeAppliances with Sequence to Sequence Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.15348.pdf)
>  Appliance-level load forecasting plays a critical role in residential energy management, besides having significant importance for ancillary services performed by the utilities. In this paper, we propose to use an LSTM-based sequence-to-sequence (seq2seq) learning model that can capture the load profiles of appliances. We use a real dataset collected fromfour residential buildings and compare our proposed schemewith three other techniques, namely VARMA, Dilated One Dimensional Convolutional Neural Network, and an LSTM model.The results show that the proposed LSTM-based seq2seq model outperforms other techniques in terms of prediction error in most cases.      
### 14.Deep Random Projection Outlyingness for Unsupervised Anomaly Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.15307.pdf)
>  Random projection is a common technique for designing algorithms in a variety of areas, including information retrieval, compressive sensing and measuring of outlyingness. In this work, the original random projection outlyingness measure is modified and associated with a neural network to obtain an unsupervised anomaly detection method able to handle multimodal normality. Theoretical and experimental arguments are presented to justify the choices of the anomaly score estimator, the dimensions of the random projections, and the number of such projections. The contribution of adapted dropouts is investigated, along with the affine stability of the proposed method. The performance of the proposed neural network approach is comparable to a state-of-the-art anomaly detection method. Experiments conducted on the MNIST, Fashion-MNIST and CIFAR-10 datasets show the relevance of the proposed approach, and suggest a possible extension to a semi-supervised setup.      
### 15.On the impact of numerology in NR V2X Mode 2 with sensing and no-sensing resource selection  [ :arrow_down: ](https://arxiv.org/pdf/2106.15303.pdf)
>  In this paper, we use a New Radio (NR) Vehicular-to-everything (V2X) standard compliant simulator based on ns-3, to study the impact of NR numerologies on the end-to-end performance. In particular, we focus on NR V2X Mode 2, used for autonomous resource selection in out-of-coverage communications, and consider the two key procedures defined in 3GPP: sensing and non-sensing based resource selection. We pay particular attention to the interplay between the operational numerology and the resource selection window length, a key parameter of NR V2X Mode 2. The results in a standard-compliant, end-to-end simulation platform show that in all cases, for basic service messages, a higher numerology is beneficial because of different reasons, depending on the way the resource selection window length is established.      
### 16.On Complex Conjugate Pair Sums and Complex Conjugate Subspaces  [ :arrow_down: ](https://arxiv.org/pdf/2106.15300.pdf)
>  In this letter, we study a few properties of Complex Conjugate Pair Sums (CCPSs) and Complex Conjugate Subspaces (CCSs). Initially, we consider an LTI system whose impulse response is one period data of CCPS. For a given input x(n), we prove that the output of this system is equivalent to computing the first order derivative of x(n). Further, with some constraints on the impulse response, the system output is also equivalent to the second order derivative. With this, we show that a fine edge detection in an image can be achieved using CCPSs as impulse response over Ramanujan Sums (RSs). Later computation of projection for CCS is studied. Here the projection matrix has a circulant structure, which makes the computation of projections easier. Finally, we prove that CCS is shift-invariant and closed under the operation of circular cross-correlation.      
### 17.Using a Drone Sounder to Measure Channels for Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15276.pdf)
>  Measurements of the propagation channel form the basis of all realistic system performance evaluations, as foundation of statistical channel models or to verify ray tracing. This is also true for the analysis of cell-free massive multi-input multi-output (CF-mMIMO) systems in real-world environments. However, such experimental data are difficult to obtain, due to the complexity and expense of deploying tens or hundreds of channel sounder nodes across the wide area a CF-mMIMO system is expected to cover, especially when different configurations and number of antennas are to be explored. In this paper, we provide a novel method to measure channels for CF-mMIMO systems using a channel sounder based on a drone, also known as a small unmanned aerial vehicle (UAV). Such a method is efficient, flexible, simple, and low-cost, capturing channel data from thousands of different access point (AP) locations within minutes. In addition, we provide sample 3.5 GHz measurement results analyzing deployment strategies for APs and make the data open source, so they may be used for various other studies.      
### 18.A Study of Ultrawideband (UWB) Antenna Design for Cognitive Radio Applications  [ :arrow_down: ](https://arxiv.org/pdf/2106.15272.pdf)
>  Cognitive radio is rapidly shaping the future of wireless communications. Research on antenna design is very critical for the implementation of cognitive radio. A special antenna is required in cognitive radio for sensing and communicating. For the purpose of spectrum sensing, an Ultrawideband (UWB) antenna is being considered as a potential candidate by many experts. This paper provides a detailed discussion of the existing UWB spectrum sensing antenna designs for cognitive radio system. Simulation results for a promising cognitive radio antenna which provides a reconfigurable function in the range of 5-6 GHz have also been presented and shown to match closely with the measured results.      
### 19.Improvement of Bi-directional Communications using Solar Powered Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2106.15269.pdf)
>  Recently, there has been a flurry of research on the use of Reconfigurable Intelligent Surfaces (RIS) in wireless networks to create dynamic radio environments. In this paper, we investigate the use of an RIS panel to improve bi-directional communications. Assuming that the RIS will be located on the facade of a building, we propose to connect it to a solar panel that harvests energy to be used to power the RIS panel's smart controller and reflecting elements. Therefore, we present a novel framework to optimally decide the transmit power of each user and the number of elements that will be used to reflect the signal of any two communicating pair in the system (user-user or base station-user). An optimization problem is formulated to jointly minimize a scalarized function of the energy of the communicating pair and the RIS panel and to find the optimal number of reflecting elements used by each user. Although the formulated problem is a mixed-integer non-linear problem, the optimal solution is found by linearizing the non-linear constraints. Besides, a more efficient close to the optimal solution is found using Bender decomposition. Simulation results show that the proposed model is capable of delivering the minimum rate of each user even if line-of-sight communication is not achievable.      
### 20.Frequency Reflection Modulation for Reconfigurable Intelligent Surface Aided OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15265.pdf)
>  Reconfigurable intelligent surface (RIS) based reflection modulation has been considered as a promising information delivery mechanism, and has the potential to realize passive information transfer of a RIS without consuming any additional radio frequency chain and time/frequency/energy resources. The existing on-off reflection modulation (ORM) schemes are based on manipulating the ``on/off'' states of RIS elements, which may lead to the degradation of RIS reflection efficiency. This paper proposes a frequency reflection modulation (FRM) method for RIS-aided OFDM systems. The FRM-OFDM scheme modulates the frequency of the incident electromagnetic waves, and the RIS information is embedded in the frequency-hoping states of RIS elements. Unlike the ORM-OFDM scheme, the FRM-OFDM scheme can achieve higher reflection efficiency, since the latter does not turn off any reflection element in reflection modulation. We propose a block coordinate descent (BCD) algorithm to maximize the user achievable rate for the FRM-OFDM system by jointly optimizing the phase shift of the RIS and the power allocation at the transmitter. Further, we design a bilinear message passing (BMP) algorithm for the bilinear recovery of both the user symbols and the RIS data. Numerical simulations have verified the efficiency of the designed BCD algorithm for system optimization and the BMP algorithm for signal detection, as well as the superiority of the proposed FRM-OFDM scheme over the ORM-OFDM scheme.      
### 21.Dynamic Response and Stability Margin Improvement of Wireless Power Receiver Systems via Right-Half-Plane Zero Elimination  [ :arrow_down: ](https://arxiv.org/pdf/2106.15264.pdf)
>  The series-series compensation topology is widely adopted in many wireless power transfer applications. For such systems, their wireless power receiver part typically involves a DC-DC converter with front-stage full-bridge diode rectifier, to process the high-frequency transmitted AC power into a DC output voltage for the load. It is recently reported that the current source nature of the series-series compensation will introduce right-half-plane (RHP) zeros into the small-signal transfer functions of the DC-DC converter of the wireless power receiver, which will severely affect the stability and dynamic response of the system. To resolve this issue, in this paper, it is proposed to adopt a different rectifier configuration for the system such that the input current to the DC-DC converter becomes controllable to eliminate the presence of RHP zeros of the small-signal transfer functions of the system. This rectifier can be applied to different wireless power receivers using the buck, buck-boost, or boost converters. As compared with the original wireless power receivers, the modified ones feature minimum-phase characteristics and hence ease the design of compensator. Theoretical and experimental results are provided. The comparative experimental results verify the elimination of the RHP zero, improved dynamic responses of reference tracking and against load disturbances, and a larger stability margin.      
### 22.Achieved Throughput of Hovering UAV-Based Optical Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2106.15263.pdf)
>  Recently, free-space optical (FSO) communication systems have obtained a wide range of applications for communications between unmanned aerial vehicles (UAVs) because they offer several advantages with respect to the traditional RF communication systems. To investigate the performance of UAV-based FSO systems in terms of achievable data rates, we derive the exact closed-form expression for the mean achievable rates of UAV-to-UAV transmission. Our results may serve to investigate the interaction between different FSO system parameters and the average data rates achieved by UAV-based optical wireless communications.      
### 23.Exploiting a Supervised Index for High-accuracy Parameter Estimation in Low SNR  [ :arrow_down: ](https://arxiv.org/pdf/2106.15220.pdf)
>  Performance of parameter estimation is one of the most important issues in array signal processing. The root mean square error, probability of success, resolution probabilities, and computational complexity are frequently used indexes for evaluating the performance of the parameter estimation methods. However, a common characteristic of these indexes is that they are unsupervised indexes, and are passively used for evaluating the estimation results. In other words, these indexes cannot participate in the design of estimation methods. It seems that exploiting a validity supervised index for the parameter estimation that can guide the design of the methods will be an interesting and meaningful work. In this study, we exploit an index to build a supervised learning model of the parameter estimation. With the developed model we refine the signal subspace so as to enhance the performance of the parameter estimation method. The main characteristic of the proposed model is a circularly applied feedback of the estimated parameter for refining the estimated subspace. It is a closed loop and supervised method not reported before. This research opens a specific way for improving the performance of the parameter estimation by a supervised index. However, the proposed method is still unsatisfying in some scopes of signal-to-noise ratio (SNR). We believe that exploiting a validity index for the parameter estimation in array signal processing is still a general and interesting problem.      
### 24.N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.15205.pdf)
>  Recently, end-to-end Korean singing voice systems have been designed to generate realistic singing voices. However, these systems still suffer from a lack of robustness in terms of pronunciation accuracy. In this paper, we propose N-Singer, a non-autoregressive Korean singing voice system, to synthesize accurate and pronounced Korean singing voices in parallel. N-Singer consists of a Transformer-based mel-generator, a convolutional network-based postnet, and voicing-aware discriminators. It can contribute in the following ways. First, for accurate pronunciation, N-Singer separately models linguistic and pitch information without other acoustic features. Second, to achieve improved mel-spectrograms, N-Singer uses a combination of Transformer-based modules and convolutional network-based modules. Third, in adversarial training, voicing-aware conditional discriminators are used to capture the harmonic features of voiced segments and noise components of unvoiced segments. The experimental results prove that N-Singer can synthesize a natural singing voice in parallel with a more accurate pronunciation than the baseline model.      
### 25.Predictive Control based on Equivalent Dynamic Linearization Model  [ :arrow_down: ](https://arxiv.org/pdf/2106.15191.pdf)
>  Based on equivalent-dynamic-linearization model (EDLM), we propose a kind of model predictive control (MPC) for single-input and single-output (SISO) nonlinear or linear systems. After compensating the EDLM with disturbance for multiple-input and multiple-output nonlinear or linear systems, the MPC compensated with disturbance is proposed to address the disturbance rejection problem. The system performance analysis results are much clear compared with the system stability analyses on MPC in current works. And this may help the engineers understand how to design, analyze and apply the controller in practical.      
### 26.DCASE 2021 Task 3: Spectrotemporally-aligned Features for Polyphonic Sound Event Localization and Detection  [ :arrow_down: ](https://arxiv.org/pdf/2106.15190.pdf)
>  Sound event localization and detection consists of two subtasks which are sound event detection and direction-of-arrival estimation. While sound event detection mainly relies on time-frequency patterns to distinguish different sound classes, direction-of-arrival estimation uses magnitude or phase differences between microphones to estimate source directions. Therefore, it is often difficult to jointly train these two subtasks simultaneously. We propose a novel feature called spatial cue-augmented log-spectrogram (SALSA) with exact time-frequency mapping between the signal power and the source direction-of-arrival. The feature includes multichannel log-spectrograms stacked along with the estimated direct-to-reverberant ratio and a normalized version of the principal eigenvector of the spatial covariance matrix at each time-frequency bin on the spectrograms. Experimental results on the DCASE 2021 dataset for sound event localization and detection with directional interference showed that the deep learning-based models trained on this new feature outperformed the DCASE challenge baseline by a large margin. We combined several models with slightly different architectures that were trained on the new feature to further improve the system performances for the DCASE sound event localization and detection challenge.      
### 27.Non-Point Visible Light Transmitter Localization based on Monocular Camera  [ :arrow_down: ](https://arxiv.org/pdf/2106.15161.pdf)
>  Many algorithms for visible light positioning (VLP) localization do not consider the shapes of the transmitters, which leads to the impracticality of the algorithm and the low localization accuracy. Therefore, this paper proposes a novel VLP algorithm and addresses the problems in terms of practicality and complexity by using one non-point transmitter based on a monocular. Because the shape of the transmitter is considered, the proposed algorithm is easy for practice and has wide applicability. Besides, it decreases the computation for simple geometric model and expands the coverage for there is a greater chance of receiving signals from one light than that of receiving signals from multiple lights.      
### 28.GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.15153.pdf)
>  Recent advances in neural multi-speaker text-to-speech (TTS) models have enabled the generation of reasonably good speech quality with a single model and made it possible to synthesize the speech of a speaker with limited training data. Fine-tuning to the target speaker data with the multi-speaker model can achieve better quality, however, there still exists a gap compared to the real speech sample and the model depends on the speaker. In this work, we propose GANSpeech, which is a high-fidelity multi-speaker TTS model that adopts the adversarial training method to a non-autoregressive multi-speaker TTS model. In addition, we propose simple but efficient automatic scaling methods for feature matching loss used in adversarial training. In the subjective listening tests, GANSpeech significantly outperformed the baseline multi-speaker FastSpeech and FastSpeech2 models, and showed a better MOS score than the speaker-specific fine-tuned FastSpeech2.      
### 29.Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.15144.pdf)
>  In this paper, we propose methods for improving the modeling performance of a Transformer-based non-autoregressive text-to-speech (TNA-TTS) model. Although the text encoder and audio decoder handle different types and lengths of data (i.e., text and audio), the TNA-TTS models are not designed considering these variations. Therefore, to improve the modeling performance of the TNA-TTS model we propose a hierarchical Transformer structure-based text encoder and audio decoder that are designed to accommodate the characteristics of each module. For the text encoder, we constrain each self-attention layer so the encoder focuses on a text sequence from the local to the global scope. Conversely, the audio decoder constrains its self-attention layers to focus in the reverse direction, i.e., from global to local scope. Additionally, we further improve the pitch modeling accuracy of the audio decoder by providing sentence and word-level pitch as conditions. Various objective and subjective evaluations verified that the proposed method outperformed the baseline TNA-TTS.      
### 30.Analysis and Control of a Planar Quadrotor  [ :arrow_down: ](https://arxiv.org/pdf/2106.15134.pdf)
>  In this paper, we model the planar motion of a quadcopter, and develop a linear model of the same. We perform stability analysis of the open loop system and develop a PD controller for its position control. We compare the closed loop response between the linear and non linear systems using the controller developed for the linear system. We also perform stability analysis for the linear and non linear systems, and compare the PD controller with modern deep neural methods based on reinforcement learning actor-critic networks.      
### 31.FastPitchFormant: Source-filter based Decomposed Modeling for Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.15123.pdf)
>  Methods for modeling and controlling prosody with acoustic features have been proposed for neural text-to-speech (TTS) models. Prosodic speech can be generated by conditioning acoustic features. However, synthesized speech with a large pitch-shift scale suffers from audio quality degradation, and speaker characteristics deformation. To address this problem, we propose a feed-forward Transformer based TTS model that is designed based on the source-filter theory. This model, called FastPitchFormant, has a unique structure that handles text and acoustic features in parallel. With modeling each feature separately, the tendency that the model learns the relationship between two features can be mitigated.      
### 32.IREM: High-Resolution Magnetic Resonance (MR) Image Reconstruction via Implicit Neural Representation  [ :arrow_down: ](https://arxiv.org/pdf/2106.15097.pdf)
>  For collecting high-quality high-resolution (HR) MR image, we propose a novel image reconstruction network named IREM, which is trained on multiple low-resolution (LR) MR images and achieve an arbitrary up-sampling rate for HR image reconstruction. In this work, we suppose the desired HR image as an implicit continuous function of the 3D image spatial coordinate and the thick-slice LR images as several sparse discrete samplings of this function. Then the super-resolution (SR) task is to learn the continuous volumetric function from a limited observations using an fully-connected neural network combined with Fourier feature positional encoding. By simply minimizing the error between the network prediction and the acquired LR image intensity across each imaging plane, IREM is trained to represent a continuous model of the observed tissue anatomy. Experimental results indicate that IREM succeeds in representing high frequency image feature, and in real scene data collection, IREM reduces scan time and achieves high-quality high-resolution MR imaging in terms of SNR and local image detail.      
### 33.Cascaded Composite Turbulence and Misalignment: Statistical Characterization and Applications to Reconfigurable Intelligent Surface-Empowered Wireless Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15082.pdf)
>  Reconfigurable intelligent surfaces (RISs) empowered high-frequency (HF) wireless systems are expected to become the supporting pillar for several reliability and data rate hungry applications. Such systems are, however, sensitive to misalignment and atmospheric phenomena including turbulence. Most of the existing studies on the performance assessment of RIS-empowered wireless systems ignore the impact of the aforementioned phenomena. Motivated by this, the current contribution presents a theoretical framework for analyzing the performance of multi-RIS empowered HF wireless systems. More specifically, we statistically characterize the cascaded composite turbulence and misalignment channels in terms of probability density and cumulative distribution functions. Building upon the derived analytical expressions, we present novel closed-form formulas that quantify the joint impact of turbulence and misalignment on the outage performance for two scenarios of high interest namely cascaded multi-RIS-empowered free space optics (FSO) and terahertz (THz) wireless systems. In addition, we provide an insightful outage probability upper-bound for a third scenario that considers parallel multi-RIS-empowered FSO systems. Our results highlight the importance of accurately modeling both turbulence and misalignment when assessing the performance of such systems.      
### 34.Doppler Biomotion Detections Immune to Unavoidable DC Offsets  [ :arrow_down: ](https://arxiv.org/pdf/2106.15054.pdf)
>  In the past decades, continuous Doppler radar sensor-based bio-signal detections have attracted many research interests. A typical example is the Doppler heartbeat detection. While significant progresses have been achieved, reliable, accurate demodulation of bio-signals in the presence of unavoidable DC offsets remains a technical challenge. Aiming to overcome this difficulty, we propose in this paper a novel demodulation algorithm that does not need to trace and eliminate dynamic DC offsets based on approximating segmented arcs in a quadrature constellation of sampling data to directional chords. Assisted by the principal component analysis, such chords and their directions can be deterministically determined. Simulations and experimental validations showed fully recovery of micron-level pendulum movements and strongly noised human heartbeats, verifying the effectiveness and accuracy of the proposed approach.      
### 35.Regression analysis of distributional data through Multi-Marginal Optimal transport  [ :arrow_down: ](https://arxiv.org/pdf/2106.15031.pdf)
>  We formulate and solve a regression problem with time-stamped distributional data. Distributions are considered as points in the Wasserstein space of probability measures, metrized by the 2-Wasserstein metric, and may represent images, power spectra, point clouds of particles, and so on. The regression seeks a curve in the Wasserstein space that passes closest to the dataset. Our regression problem allows utilizing general curves in a Euclidean setting (linear, quadratic, sinusoidal, and so on), lifted to corresponding measure-valued curves in the Wasserstein space. It can be cast as a multi-marginal optimal transport problem that allows efficient computation. Illustrative academic examples are presented.      
### 36.Federated Dynamic Spectrum Access  [ :arrow_down: ](https://arxiv.org/pdf/2106.14976.pdf)
>  Due to the growing volume of data traffic produced by the surge of Internet of Things (IoT) devices, the demand for radio spectrum resources is approaching their limitation defined by Federal Communications Commission (FCC). To this end, Dynamic Spectrum Access (DSA) is considered as a promising technology to handle this spectrum scarcity. However, standard DSA techniques often rely on analytical modeling wireless networks, making its application intractable in under-measured network environments. Therefore, utilizing neural networks to approximate the network dynamics is an alternative approach. In this article, we introduce a Federated Learning (FL) based framework for the task of DSA, where FL is a distributive machine learning framework that can reserve the privacy of network terminals under heterogeneous data distributions. We discuss the opportunities, challenges, and opening problems of this framework. To evaluate its feasibility, we implement a Multi-Agent Reinforcement Learning (MARL)-based FL as a realization associated with its initial evaluation results.      
### 37.Data augmentation for deep learning based accelerated MRI reconstruction with limited data  [ :arrow_down: ](https://arxiv.org/pdf/2106.14947.pdf)
>  Deep neural networks have emerged as very successful tools for image restoration and reconstruction tasks. These networks are often trained end-to-end to directly reconstruct an image from a noisy or corrupted measurement of that image. To achieve state-of-the-art performance, training on large and diverse sets of images is considered critical. However, it is often difficult and/or expensive to collect large amounts of training images. Inspired by the success of Data Augmentation (DA) for classification problems, in this paper, we propose a pipeline for data augmentation for accelerated MRI reconstruction and study its effectiveness at reducing the required training data in a variety of settings. Our DA pipeline, MRAugment, is specifically designed to utilize the invariances present in medical imaging measurements as naive DA strategies that neglect the physics of the problem fail. Through extensive studies on multiple datasets we demonstrate that in the low-data regime DA prevents overfitting and can match or even surpass the state of the art while using significantly fewer training data, whereas in the high-data regime it has diminishing returns. Furthermore, our findings show that DA can improve the robustness of the model against various shifts in the test distribution.      
### 38.Caching and Computation Offloading in High Altitude Platform Station (HAPS) Assisted Intelligent Transportation Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.14928.pdf)
>  Edge intelligence, which is a new paradigm to accelerate artificial intelligence (AI) applications by leveraging computing resources on the network edge, can be used to improve intelligent transportation systems (ITS). However, due to physical limitations and energy-supply constraints, the computing powers of edge equipment are usually limited. High altitude platform station (HAPS) computing can be considered as a promising extension of edge computing. HAPS is deployed in the stratosphere to provide wide coverage and strong computational capabilities. It is suitable to coordinate terrestrial resources and store the fundamental data associated with ITS-based applications. In this work, three computing layers,i.e., vehicles, terrestrial network edges, and HAPS, are integrated to build a computation framework for ITS, where the HAPS data library stores the fundamental data needed for the applications. In addition, the caching technique is introduced for network edges to store some of the fundamental data from the HAPS so that large propagation delays can be reduced. We aim to minimize the delay of the system by optimizing computation offloading and caching decisions as well as bandwidth and computing resource allocations. The simulation results highlight the benefits of HAPS computing for mitigating delays and the significance of caching at network edges.      
### 39.Multimodal Approaches for Indoor Localization for Ambient Assisted Living in Smart Homes  [ :arrow_down: ](https://arxiv.org/pdf/2106.15606.pdf)
>  This work makes multiple scientific contributions to the field of Indoor Localization for Ambient Assisted Living in Smart Homes. First, it presents a Big-Data driven methodology that studies the multimodal components of user interactions and analyzes the data from Bluetooth Low Energy (BLE) beacons and BLE scanners to detect a user's indoor location in a specific activity-based zone during Activities of Daily Living. Second, it introduces a context independent approach that can interpret the accelerometer and gyroscope data from diverse behavioral patterns to detect the zone-based indoor location of a user in any Internet of Things (IoT)-based environment. These two approaches achieved performance accuracies of 81.36% and 81.13%, respectively, when tested on a dataset. Third, it presents a methodology to detect the spatial coordinates of a user's indoor position that outperforms all similar works in this field, as per the associated root mean squared error - one of the performance evaluation metrics in ISO/IEC18305:2016- an international standard for testing Localization and Tracking Systems. Finally, it presents a comprehensive comparative study that includes Random Forest, Artificial Neural Network, Decision Tree, Support Vector Machine, k-NN, Gradient Boosted Trees, Deep Learning, and Linear Regression, to address the challenge of identifying the optimal machine learning approach for Indoor Localization.      
### 40.Uncertainty-Guided Progressive GANs for Medical Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2106.15542.pdf)
>  Image-to-image translation plays a vital role in tackling various medical imaging tasks such as attenuation correction, motion correction, undersampled reconstruction, and denoising. Generative adversarial networks have been shown to achieve the state-of-the-art in generating high fidelity images for these tasks. However, the state-of-the-art GAN-based frameworks do not estimate the uncertainty in the predictions made by the network that is essential for making informed medical decisions and subsequent revision by medical experts and has recently been shown to improve the performance and interpretability of the model. In this work, we propose an uncertainty-guided progressive learning scheme for image-to-image translation. By incorporating aleatoric uncertainty as attention maps for GANs trained in a progressive manner, we generate images of increasing fidelity progressively. We demonstrate the efficacy of our model on three challenging medical image translation tasks, including PET to CT translation, undersampled MRI reconstruction, and MRI motion artefact correction. Our model generalizes well in three different tasks and improves performance over state of the art under full-supervision and weak-supervision with limited data. Code is released here: <a class="link-external link-https" href="https://github.com/ExplainableML/UncerGuidedI2I" rel="external noopener nofollow">this https URL</a>      
### 41.Sounds of COVID-19: exploring realistic performance of audio-based digital testing  [ :arrow_down: ](https://arxiv.org/pdf/2106.15523.pdf)
>  Researchers have been battling with the question of how we can identify Coronavirus disease (COVID-19) cases efficiently, affordably and at scale. Recent work has shown how audio based approaches, which collect respiratory audio data (cough, breathing and voice) can be used for testing, however there is a lack of exploration of how biases and methodological decisions impact these tools' performance in practice. In this paper, we explore the realistic performance of audio-based digital testing of COVID-19. To investigate this, we collected a large crowdsourced respiratory audio dataset through a mobile app, alongside recent COVID-19 test result and symptoms intended as a ground truth. Within the collected dataset, we selected 5,240 samples from 2,478 participants and split them into different participant-independent sets for model development and validation. Among these, we controlled for potential confounding factors (such as demographics and language). The unbiased model takes features extracted from breathing, coughs, and voice signals as predictors and yields an AUC-ROC of 0.71 (95\% CI: 0.65$-$0.77). We further explore different unbalanced distributions to show how biases and participant splits affect performance. Finally, we discuss how the realistic model presented could be integrated in clinical practice to realize continuous, ubiquitous, sustainable and affordable testing at population scale.      
### 42.Optimization Techniques in Reconfigurable Intelligent Surface Aided Networks  [ :arrow_down: ](https://arxiv.org/pdf/2106.15458.pdf)
>  Reconfigurable intelligent surface (RIS)-aided networks have been investigated for the purpose of improving the system performance. However, the introduced unit modulus phase shifts and coupling characteristic bring enormous challenges to the optimization in the RIS-aided networks. Many efforts have been made to jointly optimize phase shift vector and other parameters. This article intends to survey the latest research results about the optimization in RIS-aided networks. A taxonomy is devised to categorize the existing literatures based on optimization types, phase shift form, and decoupling methods. Furthermore, in alternating optimization framework, we introduce in detail how to exploit the aforementioned technologies flexibly. It is known that most works could not guarantee a stationary point. To overcome this problem, we propose a unified framework for the optimization problem of RIS-aided networks with continuous phase shifts to find a stationary point. Finally, key challenges are outlined to provide guidelines for the domain researchers and designers to explore more efficient optimization frameworks, and then open issues are discussed.      
### 43.An Efficient Batch Constrained Bayesian Optimization Approach for Analog Circuit Synthesis via Multi-objective Acquisition Ensemble  [ :arrow_down: ](https://arxiv.org/pdf/2106.15412.pdf)
>  Bayesian optimization is a promising methodology for analog circuit synthesis. However, the sequential nature of the Bayesian optimization framework significantly limits its ability to fully utilize real-world computational resources. In this paper, we propose an efficient parallelizable Bayesian optimization algorithm via Multi-objective ACquisition function Ensemble (MACE) to further accelerate the optimization procedure. By sampling query points from the Pareto front of the probability of improvement (PI), expected improvement (EI) and lower confidence bound (LCB), we combine the benefits of state-of-the-art acquisition functions to achieve a delicate tradeoff between exploration and exploitation for the unconstrained optimization problem. Based on this batch design, we further adjust the algorithm for the constrained optimization problem. By dividing the optimization procedure into two stages and first focusing on finding an initial feasible point, we manage to gain more information about the valid region and can better avoid sampling around the infeasible area. After achieving the first feasible point, we favor the feasible region by adopting a specially designed penalization term to the acquisition function ensemble. The experimental results quantitatively demonstrate that our proposed algorithm can reduce the overall simulation time by up to 74 times compared to differential evolution (DE) for the unconstrained optimization problem when the batch size is 15. For the constrained optimization problem, our proposed algorithm can speed up the optimization process by up to 15 times compared to the weighted expected improvement based Bayesian optimization (WEIBO) approach, when the batch size is 15.      
### 44.Improvements in Micro-CT Method for Characterizing X-ray Monocapillary Optics  [ :arrow_down: ](https://arxiv.org/pdf/2106.15410.pdf)
>  Accurate characterization of the inner surface of X-ray monocapillary optics (XMCO) is of great significance in X-ray optics research. Compared with other characterization methods, the micro computed tomography (micro-CT) method has its unique advantages but also has some disadvantages, such as a long scanning time, long image reconstruction time, and inconvenient scanning process. In this paper, sparse sampling was proposed to shorten the scanning time, GPU acceleration technology was used to improve the speed of image reconstruction, and a simple geometric calibration algorithm was proposed to avoid the calibration phantom and simplify the scanning process. These methodologies will popularize the use of the micro-CT method in XMCO characterization.      
### 45.LB-CNN: An Open Source Framework for Fast Training of Light Binary Convolutional Neural Networks using Chainer and Cupy  [ :arrow_down: ](https://arxiv.org/pdf/2106.15350.pdf)
>  Light binary convolutional neural networks (LB-CNN) are particularly useful when implemented in low-energy computing platforms as required in many industrial applications. Herein, a framework for optimizing compact LB-CNN is introduced and its effectiveness is evaluated. The framework is freely available and may run on free-access cloud platforms, thus requiring no major investments. The optimized model is saved in the standardized .h5 format and can be used as input to specialized tools for further deployment into specific technologies, thus enabling the rapid development of various intelligent image sensors. The main ingredient in accelerating the optimization of our model, particularly the selection of binary convolution kernels, is the Chainer/Cupy machine learning library offering significant speed-ups for training the output layer as an extreme-learning machine. Additional training of the output layer using Keras/Tensorflow is included, as it allows an increase in accuracy. Results for widely used datasets including MNIST, GTSRB, ORL, VGG show very good compromise between accuracy and complexity. Particularly, for face recognition problems a carefully optimized LB-CNN model provides up to 100% accuracies. Such TinyML solutions are well suited for industrial applications requiring image recognition with low energy consumption.      
### 46.Where is the disease? Semi-supervised pseudo-normality synthesis from an abnormal image  [ :arrow_down: ](https://arxiv.org/pdf/2106.15345.pdf)
>  Pseudo-normality synthesis, which computationally generates a pseudo-normal image from an abnormal one (e.g., with lesions), is critical in many perspectives, from lesion detection, data augmentation to clinical surgery suggestion. However, it is challenging to generate high-quality pseudo-normal images in the absence of the lesion information. Thus, expensive lesion segmentation data have been introduced to provide lesion information for the generative models and improve the quality of the synthetic images. In this paper, we aim to alleviate the need of a large amount of lesion segmentation data when generating pseudo-normal images. We propose a Semi-supervised Medical Image generative LEarning network (SMILE) which not only utilizes limited medical images with segmentation masks, but also leverages massive medical images without segmentation masks to generate realistic pseudo-normal images. Extensive experiments show that our model outperforms the best state-of-the-art model by up to 6% for data augmentation task and 3% in generating high-quality images. Moreover, the proposed semi-supervised learning achieves comparable medical image synthesis quality with supervised learning model, using only 50 of segmentation data.      
### 47.Image Inpainting Using Wasserstein Generative Adversarial Imputation Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.15341.pdf)
>  Image inpainting is one of the important tasks in computer vision which focuses on the reconstruction of missing regions in an image. The aim of this paper is to introduce an image inpainting model based on Wasserstein Generative Adversarial Imputation Network. The generator network of the model uses building blocks of convolutional layers with different dilation rates, together with skip connections that help the model reproduce fine details of the output. This combination yields a universal imputation model that is able to handle various scenarios of missingness with sufficient quality. To show this experimentally, the model is simultaneously trained to deal with three scenarios given by missing pixels at random, missing various smaller square regions, and one missing square placed in the center of the image. It turns out that our model achieves high-quality inpainting results on all scenarios. Performance is evaluated using peak signal-to-noise ratio and structural similarity index on two real-world benchmark datasets, CelebA faces and Paris StreetView. The results of our model are compared to biharmonic imputation and to some of the other state-of-the-art image inpainting methods.      
### 48.Improved Padding in CNNs for Quantitative Susceptibility Mapping  [ :arrow_down: ](https://arxiv.org/pdf/2106.15331.pdf)
>  Recently, deep learning methods have been proposed for quantitative susceptibility mapping (QSM) data processing: background field removal, field-to-source inversion, and single-step QSM reconstruction. However, the conventional padding mechanism used in convolutional neural networks (CNNs) can introduce spatial artifacts, especially in QSM background field removal and single-step QSM which requires inference from total fields with extreme large values at the edge boundaries of volume of interest. To address this issue, we propose an improved padding technique which utilizes the neighboring valid voxels to estimate the invalid voxels of feature maps at volume boundaries in the neural networks. Studies using simulated and in-vivo data show that the proposed padding greatly improves estimation accuracy and reduces artifacts in the results in the tasks of background field removal, field-to-source inversion, and single-step QSM reconstruction.      
### 49.Artificial Intelligence in Minimally Invasive Interventional Treatment  [ :arrow_down: ](https://arxiv.org/pdf/2106.15306.pdf)
>  Minimally invasive image guided treatment procedures often employ advanced image processing algorithms. The recent developments of artificial intelligence algorithms harbor potential to further enhance this domain. In this article we explore several application areas within the minimally invasive treatment space and discuss the deployment of artificial intelligence within these areas.      
### 50.Evaluating Deep Neural Networks for Image Document Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.15286.pdf)
>  This work evaluates six state-of-the-art deep neural network (DNN) architectures applied to the problem of enhancing camera-captured document images. The results from each network were evaluated both qualitatively and quantitatively using Image Quality Assessment (IQA) metrics, and also compared with an existing approach based on traditional computer vision techniques. The best performing architectures generally produced good enhancement compared to the existing algorithm, showing that it is possible to use DNNs for document image enhancement. Furthermore, the best performing architectures could work as a baseline for future investigations on document enhancement using deep learning techniques. The main contributions of this paper are: a baseline of deep learning techniques that can be further improved to provide better results, and a evaluation methodology using IQA metrics for quantitatively comparing the produced images from the neural networks to a ground truth.      
### 51.Similarity Embedding Networks for Robust Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2106.15283.pdf)
>  Deep learning models for human activity recognition (HAR) based on sensor data have been heavily studied recently. However, the generalization ability of deep models on complex real-world HAR data is limited by the availability of high-quality labeled activity data, which are hard to obtain. In this paper, we design a similarity embedding neural network that maps input sensor signals onto real vectors through carefully designed convolutional and LSTM layers. The embedding network is trained with a pairwise similarity loss, encouraging the clustering of samples from the same class in the embedded real space, and can be effectively trained on a small dataset and even on a noisy dataset with mislabeled samples. Based on the learned embeddings, we further propose both nonparametric and parametric approaches for activity recognition. Extensive evaluation based on two public datasets has shown that the proposed similarity embedding network significantly outperforms state-of-the-art deep models on HAR classification tasks, is robust to mislabeled samples in the training set, and can also be used to effectively denoise a noisy dataset.      
### 52.On-board Volcanic Eruption Detection through CNNs and Satellite Multispectral Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2106.15281.pdf)
>  In recent years, the growth of Machine Learning algorithms in a variety of different applications has raised numerous studies on the applicability of these algorithms in real scenarios. Among all, one of the hardest scenarios, due to its physical requirements, is the aerospace one. In this context, the authors of this work aim to propose a first prototype and a study of feasibility for an AI model to be 'loaded' on board. As a case study, the authors decided to investigate the detection of volcanic eruptions as a method to swiftly produce alerts. Two Convolutional Neural Networks have been proposed and created, also showing how to correctly implement them on real hardware and how the complexity of a CNN can be adapted to fit computational requirements.      
### 53.Model Predictive Control for Trajectory Tracking on Differentiable Manifolds  [ :arrow_down: ](https://arxiv.org/pdf/2106.15233.pdf)
>  We consider the problem of bridging the gap between geometric tracking control theory and implementation of model predictive control (MPC) for robotic systems operating on manifolds. We propose a generic on-manifold MPC formulation based on a canonical representation of the system evolving on manifolds. Then, we present a method that solves the on-manifold MPC formulation by linearizing the system along the trajectory under tracking. There are two main advantages of the proposed scheme. The first is that the linearized system leads to an equivalent error system represented by a set of minimal parameters without any singularity. Secondly, the process of system modeling, error-system derivation, linearization and control has the manifold constraints completely decoupled from the system descriptions, enabling the development of a symbolic MPC framework that naturally encapsulates the manifold constraints. In this framework, users need only to supply system-specific descriptions without dealing with the manifold constraints. We implement this framework and test it on a quadrotor unmanned aerial vehicle (UAV) operating on $SO(3) \times \mathbb{R}^n$ and an unmanned ground vehicle (UGV) moving on a curved surface. Real-world experiments show that the proposed framework and implementation achieve high tracking performance and computational efficiency even in highly aggressive aerobatic quadrotor maneuvers.      
### 54.End-to-end Waveform Learning Through Joint Optimization of Pulse and Constellation Shaping  [ :arrow_down: ](https://arxiv.org/pdf/2106.15158.pdf)
>  As communication systems are foreseen to enable new services such as joint communication and sensing and utilize parts of the sub-THz spectrum, the design of novel waveforms that can support these emerging applications becomes increasingly challenging. We present in this work an end-to-end learning approach to design waveforms through joint learning of pulse shaping and constellation geometry, together with a neural network (NN)-based receiver. Optimization is performed to maximize an achievable information rate, while satisfying constraints on out-of-band emission and power envelope. Our results show that the proposed approach enables up to orders of magnitude smaller adjacent channel leakage ratios (ACLRs) with peak-to-average power ratios (PAPRs) competitive with traditional filters, without significant loss of information rate on an additive white Gaussian noise (AWGN) channel, and no additional complexity at the transmitter.      
### 55.The Effect of Sensor Fusion on Data-Driven Learning of Koopman Operators  [ :arrow_down: ](https://arxiv.org/pdf/2106.15091.pdf)
>  Dictionary methods for system identification typically rely on one set of measurements to learn governing dynamics of a system. In this paper, we investigate how fusion of output measurements with state measurements affects the dictionary selection process in Koopman operator learning problems. While prior methods use dynamical conjugacy to show a direct link between Koopman eigenfunctions in two distinct data spaces (measurement channels), we explore the specific case where output measurements are nonlinear, non-invertible functions of the system state. This setup reflects the measurement constraints of many classes of physical systems, e.g., biological measurement data, where one type of measurement does not directly transform to another. We propose output constrained Koopman operators (OC-KOs) as a new framework to fuse two measurement sets. We show that OC-KOs are effective for sensor fusion by proving that when learning a Koopman operator, output measurement functions serve to constrain the space of potential Koopman observables and their eigenfunctions. Further, low-dimensional output measurements can be embedded to inform selection of Koopman dictionary functions for high-dimensional models. We propose two algorithms to identify OC-KO representations directly from data: a direct optimization method that uses state and output data simultaneously and a sequential optimization method. We prove a theorem to show that the solution spaces of the two optimization problems are equivalent. We illustrate these findings with a theoretical example and two numerical simulations.      
### 56.Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding  [ :arrow_down: ](https://arxiv.org/pdf/2106.15065.pdf)
>  Decomposable tasks are complex and comprise of a hierarchy of sub-tasks. Spoken intent prediction, for example, combines automatic speech recognition and natural language understanding. Existing benchmarks, however, typically hold out examples for only the surface-level sub-task. As a result, models with similar performance on these benchmarks may have unobserved performance differences on the other sub-tasks. To allow insightful comparisons between competitive end-to-end architectures, we propose a framework to construct robust test sets using coordinate ascent over sub-task specific utility functions. Given a dataset for a decomposable task, our method optimally creates a test set for each sub-task to individually assess sub-components of the end-to-end model. Using spoken language understanding as a case study, we generate new splits for the Fluent Speech Commands and Snips SmartLights datasets. Each split has two test sets: one with held-out utterances assessing natural language understanding abilities, and one with held-out speakers to test speech processing skills. Our splits identify performance gaps up to 10% between end-to-end systems that were within 1% of each other on the original test sets. These performance gaps allow more realistic and actionable comparisons between different architectures, driving future model development. We release our splits and tools for the community.      
### 57.Hamilton-Jacobi Equations for Two Classes of State-Constrained Zero-Sum Games  [ :arrow_down: ](https://arxiv.org/pdf/2106.15006.pdf)
>  This paper presents Hamilton-Jacobi (HJ) formulations for two classes of two-player zero-sum games: one with a maximum cost value over time, and one with a minimum cost value over time. In the zero-sum game setting, player A minimizes the given cost while satisfying state constraints, and player B wants to prevent player A's success. For each class of problems, this paper presents two HJ equations: one for time-varying dynamics, cost, and state constraint; the other for time-invariant dynamics, cost, and state constraint. Utilizing the HJ equations, the optimal control for each player is analyzed, and a numerical algorithm is presented to compute the solution to the HJ equations. A two-dimensional water system is introduced as an example to demonstrate the proposed HJ framework.      
### 58.Online Estimation and Coverage Control with Heterogeneous Sensing Information  [ :arrow_down: ](https://arxiv.org/pdf/2106.14984.pdf)
>  Heterogeneous multi-robot sensing systems are able to characterize physical processes more comprehensively than homogeneous systems. Access to multiple modalities of sensory data allow such systems to fuse information between complementary sources and learn richer representations of a phenomenon of interest. Often, these data are correlated but vary in fidelity, i.e., accuracy (bias) and precision (noise). Low-fidelity data may be more plentiful, while high-fidelity data may be more trustworthy. In this paper, we address the problem of multi-robot online estimation and coverage control by combining low- and high-fidelity data to learn and cover a sensory function of interest. We propose two algorithms for this task of heterogeneous learning and coverage -- namely Stochastic Sequencing of Multi-fidelity Learning and Coverage (SMLC) and Deterministic Sequencing of Multi-fidelity Learning and Coverage (DMLC) -- and prove that they converge asymptotically. In addition, we demonstrate the empirical efficacy of SMLC and DMLC through numerical simulations.      
### 59.Chaos Engineering for Enhanced Resilience of Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.14962.pdf)
>  Cyber-physical systems (CPS) incorporate the complex and large-scale engineered systems behind critical infrastructure operations, such as water distribution networks, energy delivery systems, healthcare services, manufacturing systems, and transportation networks. Industrial CPS in particular need to simultaneously satisfy requirements of available, secure, safe and reliable system operation against diverse threats, in an adaptive and sustainable way. These adverse events can be of accidental or malicious nature and may include natural disasters, hardware or software faults, cyberattacks, or even infrastructure design and implementation faults. They may drastically affect the results of CPS algorithms and mechanisms, and subsequently the operations of industrial control systems (ICS) deployed in those critical infrastructures. Such a demanding combination of properties and threats calls for resilience-enhancement methodologies and techniques, working in real-time operation. However, the analysis of CPS resilience is a difficult task as it involves evaluation of various interdependent layers with heterogeneous computing equipment, physical components, network technologies, and data analytics. In this paper, we apply the principles of chaos engineering (CE) to industrial CPS, in order to demonstrate the benefits of such practices on system resilience. The systemic uncertainty of adverse events can be tamed by applying runtime CE-based analyses to CPS in production, in order to predict environment changes and thus apply mitigation measures limiting the range and severity of the event, and minimizing its blast radius.      
### 60.A novel approach to photon transfer conversion gain estimation  [ :arrow_down: ](https://arxiv.org/pdf/2106.14958.pdf)
>  Nonuniformities in the imaging characteristics of modern image sensors are a primary factor in the push to develop a pixel-level generalization of the photon transfer characterization method. In this paper, we seek to develop a body of theoretical results leading toward a comprehensive approach for tackling the biggest obstacle in the way of this goal: a means of pixel-level conversion gain estimation. This is accomplished by developing an estimator for the reciprocal-difference of normal variances and then using this to construct a novel estimator of the conversion gain. The first two moments of this estimator are derived and used to construct exact and approximate confidence intervals for its absolute relative bias and absolute coefficient of variation, respectively. A means of approximating and computing optimal sample sizes are also discussed and used to demonstrate the process of pixel-level conversion gain estimation for a real image sensor.      
### 61.Design for a blind stereoscopic picture taker  [ :arrow_down: ](https://arxiv.org/pdf/2106.14949.pdf)
>  An Schematical Design for an Autonomous Picture taker used for obtaining Point clouds from pictures taken inside a House. In this case we are proposing the use of an equation programmed inside an embedded system that will be tracking the points inside a room and then, open the space between two cameras of same type in order to take pictures that later will be used to create the cloud points for the mathematical model that the latter user will apply to that pictures.      
### 62.Robust Control for a Class of Nonlinearly Coupled Hierarchical Systems with Actuator Faults  [ :arrow_down: ](https://arxiv.org/pdf/2106.14944.pdf)
>  This paper proposes an approach to addresses the control challenges posed by a fault-induced uncertainty in both the dynamics and control input effectiveness of a class of hierarchical nonlinear systems in which the high-level dynamics is nonlinearly coupled with a multi-agent low-level dynamics. The high-level dynamics has a multiplicative uncertainty in the control input effectiveness and is subjected to an exogenous disturbance input. On the other hand, the low-level system is subjected to actuator faults causing a time-varying multiplicative uncertainty in the dynamical model and associated control effectiveness. Moreover, the nonlinear coupling between the high-level and the low-level dynamics makes the problem even more challenging. To address this problem, an online parameter estimation algorithm is designed, coupled with an adaptive splitting mechanism which automatically distributes the control action among low level multi-agent systems. A nonlinear $\mathcal{L}_2$-gain-based controller, and then a state-feedback controller are designed in the high-level, and the low-level, respectively, to recover the system from faults with high performance in the transient response, and reject the exogenous disturbance. The resulting analysis guarantees a robust tracking of the high-level reference command signal.      

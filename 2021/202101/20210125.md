# ArXiv eess --Mon, 25 Jan 2021
### 1.Automatic Cerebral Vessel Extraction in TOF-MRA Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09253.pdf)
>  Deep learning approaches may help radiologists in the early diagnosis and timely treatment of cerebrovascular diseases. Accurate cerebral vessel segmentation of Time-of-Flight Magnetic Resonance Angiographs (TOF-MRAs) is an essential step in this process. This study investigates deep learning approaches for automatic, fast and accurate cerebrovascular segmentation for TOF-MRAs. The performance of several data augmentation and selection methods for training a 2D and 3D U-Net for vessel segmentation was investigated in five experiments: a) without augmentation, b) Gaussian blur, c) rotation and flipping, d) Gaussian blur, rotation and flipping and e) different input patch sizes. All experiments were performed by patch-training both a 2D and 3D U-Net and predicted on a test set of MRAs. Ground truth was manually defined using an interactive threshold and region growing method. The performance was evaluated using the Dice Similarity Coefficient (DSC), Modified Hausdorff Distance and Volumetric Similarity, between the predicted images and the interactively defined ground truth. The segmentation performance of all trained networks on the test set was found to be good, with DSC scores ranging from 0.72 to 0.83. Both the 2D and 3D U-Net had the best segmentation performance with Gaussian blur, rotation and flipping compared to other experiments without augmentation or only one of those augmentation techniques. Additionally, training on larger patches or slices gave optimal segmentation results. In conclusion, vessel segmentation can be optimally performed on TOF-MRAs using a trained 3D U-Net on larger patches, where data augmentation including Gaussian blur, rotation and flipping was performed on the training data.      
### 2.Towards efficient models for real-time deep noise suppression  [ :arrow_down: ](https://arxiv.org/pdf/2101.09249.pdf)
>  With recent research advancements, deep learning models are becoming attractive and powerful choices for speech enhancement in real-time applications. While state-of-the-art models can achieve outstanding results in terms of speech quality and background noise reduction, the main challenge is to obtain compact enough models, which are resource efficient during inference time. An important but often neglected aspect for data-driven methods is that results can be only convincing when tested on real-world data and evaluated with useful metrics. In this work, we investigate reasonably small recurrent and convolutional-recurrent network architectures for speech enhancement, trained on a large dataset considering also reverberation. We show interesting tradeoffs between computational complexity and the achievable speech quality, measured on real recordings using a highly accurate MOS estimator. It is shown that the achievable speech quality is a function of network complexity, and show which models have better tradeoffs.      
### 3.A comparison of three heart rate detection algorithms over ballistocardiogram signals  [ :arrow_down: ](https://arxiv.org/pdf/2101.09144.pdf)
>  Heart rate (HR) detection from ballistocardiogram (BCG) signals is challenging for various reasons. For example, BCG signals' morphology can vary between and within-subjects. Also, it differs from one sensor to another. Hence, it is essential to evaluate HR detection algorithms across different datasets and under different experimental setups. This paper investigated the suitability of three algorithms (i.e., MODWT-MRA, CWT, and template matching) for HR detection across three independent BCG datasets. The first two datasets (Datset1 and DataSet2) were obtained using a microbend fiber optic (MFOS) sensor, while the last one (DataSet3) was obtained using a fiber Bragg grating (FBG) sensor. DataSet1 was collected from 10 OSA patients during an in-lab PSG study, Datset2 was obtained from 50 subjects in a sitting position, and DataSet3 was gathered from 10 subjects in a sleeping position. The CWT with derivative of Gaussian (Gaus2) provided superior results than the MODWT-MAR, CWT (frequency B-spline-Fbsp-2-1-1), and CWT (Shannon-Shan1.5-1.0) for DataSet1 and DataSet2. That said, a BCG template was constructed from DataSet1. Then, it was applied for HR detection across DataSet2. The template matching method achieved slightly superior results than CWT-Gaus2 for DataSet2. Furthermore, it has proved useful for HR detection across DataSet3 despite that BCG signals were obtained from a different sensor and under different conditions. Overall, the time required to analyze a 30-second BCG signal was in a millisecond resolution for the three proposed methods. The MODWT-MRA had the highest performance, with an average time of 4.92 ms.      
### 4.Traffic Flow Estimation using LTE Radio Frequency Counters and Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09143.pdf)
>  As the demand for vehicles continues to outpace construction of new roads, it becomes imperative we implement strategies that improve utilization of existing transport infrastructure. Traffic sensors form a crucial part of many such strategies, giving us valuable insights into road utilization. However, due to cost and lead time associated with installation and maintenance of traffic sensors, municipalities and traffic authorities look toward cheaper and more scalable alternatives. Due to their ubiquitous nature and wide global deployment, cellular networks offer one such alternative. In this paper we present a novel method for traffic flow estimation using standardized LTE/4G radio frequency performance measurement counters. The problem is cast as a supervised regression task using both classical and deep learning methods. We further apply transfer learning to compensate that many locations lack traffic sensor data that could be used for training. We show that our approach benefits from applying transfer learning to generalize the solution not only in time but also in space (i.e., various parts of the city). The results are very promising and, unlike competing solutions, our approach utilizes aggregate LTE radio frequency counter data that is inherently privacy-preserving, readily available, and scales globally without any additional network impact.      
### 5.Multi-hop RIS-Empowered Terahertz Communications: A DRL-based Hybrid Beamforming Design  [ :arrow_down: ](https://arxiv.org/pdf/2101.09137.pdf)
>  Wireless communication in the TeraHertz band (0.1--10 THz) is envisioned as one of the key enabling technologies for the future sixth generation (6G) wireless communication systems scaled up beyond massive multiple input multiple output (Massive-MIMO) technology. However, very high propagation attenuations and molecular absorptions of THz frequencies often limit the signal transmission distance and coverage range. Benefited from the recent breakthrough on the reconfigurable intelligent surfaces (RIS) for realizing smart radio propagation environment, we propose a novel hybrid beamforming scheme for the multi-hop RIS-assisted communication networks to improve the coverage range at THz-band frequencies. Particularly, multiple passive and controllable RISs are deployed to assist the transmissions between the base station (BS) and multiple single-antenna users. We investigate the joint design of digital beamforming matrix at the BS and analog beamforming matrices at the RISs, by leveraging the recent advances in deep reinforcement learning (DRL) to combat the propagation loss. To improve the convergence of the proposed DRL-based algorithm, two algorithms are then designed to initialize the digital beamforming and the analog beamforming matrices utilizing the alternating optimization technique. Simulation results show that our proposed scheme is able to improve 50\% more coverage range of THz communications compared with the benchmarks. Furthermore, it is also shown that our proposed DRL-based method is a state-of-the-art method to solve the NP-hard beamforming problem, especially when the signals at RIS-assisted THz communication networks experience multiple hops.      
### 6.A Universal Deep Learning Framework for Real-Time Denoising of Ultrasound Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.09122.pdf)
>  Ultrasound images are widespread in medical diagnosis for muscle-skeletal, cardiac, and obstetrical diseases, due to the efficiency and non-invasiveness of the acquisition methodology. However, ultrasound acquisition introduces a speckle noise in the signal, that corrupts the resulting image and affects further processing operations, and the visual analysis that medical experts conduct to estimate patient diseases. Our main goal is to define a universal deep learning framework for real-time denoising of ultrasound images. We analyse and compare state-of-the-art methods for the smoothing of ultrasound images (e.g., spectral, low-rank, and deep learning denoising algorithms), in order to select the best one in terms of accuracy, preservation of anatomical features, and computational cost. Then, we propose a tuned version of the selected state-of-the-art denoising methods (e.g., WNNM), to improve the quality of the denoised images, and extend its applicability to ultrasound images. To handle large data sets of ultrasound images with respect to applications and industrial requirements, we introduce a denoising framework that exploits deep learning and HPC tools, and allows us to replicate the results of state-of-the-art denoising methods in a real-time execution.      
### 7.B-DRRN: A Block Information Constrained Deep Recursive Residual Network for Video Compression Artifacts Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2101.09021.pdf)
>  Although the video compression ratio nowadays becomes higher, the video coders such as H.264/AVC, H.265/HEVC, H.266/VVC always suffer from the video artifacts. In this paper, we design a neural network to enhance the quality of the compressed frame by leveraging the block information, called B-DRRN (Deep Recursive Residual Network with Block information). Firstly, an extra network branch is designed for leveraging the block information of the coding unit (CU). Moreover, to avoid a great increase in the network size, Recursive Residual structure and sharing weight techniques are applied. We also conduct a new large-scale dataset with 209,152 training samples. Experimental results show that the proposed B-DRRN can reduce 6.16% BD-rate compared to the HEVC standard. After efficiently adding an extra network branch, this work can improve the performance of the main network without increasing any memory for storing.      
### 8.Automatic Volumetric Segmentation of Additive Manufacturing Defects with 3D U-Net  [ :arrow_down: ](https://arxiv.org/pdf/2101.08993.pdf)
>  Segmentation of additive manufacturing (AM) defects in X-ray Computed Tomography (XCT) images is challenging, due to the poor contrast, small sizes and variation in appearance of defects. Automatic segmentation can, however, provide quality control for additive manufacturing. Over recent years, three-dimensional convolutional neural networks (3D CNNs) have performed well in the volumetric segmentation of medical images. In this work, we leverage techniques from the medical imaging domain and propose training a 3D U-Net model to automatically segment defects in XCT images of AM samples. This work not only contributes to the use of machine learning for AM defect detection but also demonstrates for the first time 3D volumetric segmentation in AM. We train and test with three variants of the 3D U-Net on an AM dataset, achieving a mean intersection of union (IOU) value of 88.4%.      
### 9.Progressive Image Super-Resolution via Neural Differential Equation  [ :arrow_down: ](https://arxiv.org/pdf/2101.08987.pdf)
>  We propose a new approach for the image super-resolution (SR) task that progressively restores a high-resolution (HR) image from an input low-resolution (LR) image on the basis of a neural ordinary differential equation. In particular, we newly formulate the SR problem as an initial value problem, where the initial value is the input LR image. Unlike conventional progressive SR methods that perform gradual updates using straightforward iterative mechanisms, our SR process is formulated in a concrete manner based on explicit modeling with a much clearer understanding. Our method can be easily implemented using conventional neural networks for image restoration. Moreover, the proposed method can super-resolve an image with arbitrary scale factors on continuous domain, and achieves superior SR performance over state-of-the-art SR methods.      
### 10.Efficient Near-Field Imaging Using Cylindrical MIMO Arrays  [ :arrow_down: ](https://arxiv.org/pdf/2101.08982.pdf)
>  Multiple-input multiple-output (MIMO) array based millimeter-wave (MMW) imaging has a tangible prospect in applications of concealed weapons detection. A near-field imaging algorithm based on wavenumber domain processing is proposed for a cylindrical MIMO array scheme with uniformly spaced transmit and receive antennas over both the vertical and horizontal-arc directions. The spectrum aliasing associated with the proposed MIMO array is analyzed through a zero-filling discrete-time Fourier transform. The analysis shows that an undersampled array can be used in recovering the MMW image by a wavenumber domain algorithm. The requirements for the antenna inter-element spacing of the MIMO array are delineated. Numerical simulations as well as comparisons with the backprojection (BP) algorithm are provided to demonstrate the effectiveness of the proposed method.      
### 11.Snapshot Hyperspectral Imaging Based on Weighted High-order Singular Value Regularization  [ :arrow_down: ](https://arxiv.org/pdf/2101.08923.pdf)
>  Snapshot hyperspectral imaging can capture the 3D hyperspectral image (HSI) with a single 2D measurement and has attracted increasing attention recently. Recovering the underlying HSI from the compressive measurement is an ill-posed problem and exploiting the image prior is essential for solving this ill-posed problem. However, existing reconstruction methods always start from modeling image prior with the 1D vector or 2D matrix and cannot fully exploit the structurally spectral-spatial nature in 3D HSI, thus leading to a poor fidelity. In this paper, we propose an effective high-order tensor optimization based method to boost the reconstruction fidelity for snapshot hyperspectral imaging. We first build high-order tensors by exploiting the spatial-spectral correlation in HSI. Then, we propose a weight high-order singular value regularization (WHOSVR) based low-rank tensor recovery model to characterize the structure prior of HSI. By integrating the structure prior in WHOSVR with the system imaging process, we develop an optimization framework for HSI reconstruction, which is finally solved via the alternating minimization algorithm. Extensive experiments implemented on two representative systems demonstrate that our method outperforms state-of-the-art methods.      
### 12.Understanding the Tradeoffs in Client-Side Privacy for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.08919.pdf)
>  Existing approaches to ensuring privacy of user speech data primarily focus on server-side approaches. While improving server-side privacy reduces certain security concerns, users still do not retain control over whether privacy is ensured on the client-side. In this paper, we define, evaluate, and explore techniques for client-side privacy in speech recognition, where the goal is to preserve privacy on raw speech data before leaving the client's device. We first formalize several tradeoffs in ensuring client-side privacy between performance, compute requirements, and privacy. Using our tradeoff analysis, we perform a large-scale empirical study on existing approaches and find that they fall short on at least one metric. Our results call for more research in this crucial area as a step towards safer real-world deployment of speech recognition systems at scale across mobile devices.      
### 13.Single Neuron Segmentation using Graph-based Global Reasoning with Auxiliary Skeleton Loss from 3D Optical Microscope Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.08910.pdf)
>  One of the critical steps in improving accurate single neuron reconstruction from three-dimensional (3D) optical microscope images is the neuronal structure segmentation. However, they are always hard to segment due to the lack in quality. Despite a series of attempts to apply convolutional neural networks (CNNs) on this task, noise and disconnected gaps are still challenging to alleviate with the neglect of the non-local features of graph-like tubular neural structures. Hence, we present an end-to-end segmentation network by jointly considering the local appearance and the global geometry traits through graph reasoning and a skeleton-based auxiliary loss. The evaluation results on the Janelia dataset from the BigNeuron project demonstrate that our proposed method exceeds the counterpart algorithms in performance.      
### 14.Adversarial Attacks and Defenses for Speaker Identification Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.08909.pdf)
>  Research in automatic speaker recognition (SR) has been undertaken for several decades, reaching great performance. However, researchers discovered potential loopholes in these technologies like spoofing attacks. Quite recently, a new genre of attack, termed adversarial attacks, has been proved to be fatal in computer vision and it is vital to study their effects on SR systems. This paper examines how state-of-the-art speaker identification (SID) systems are vulnerable to adversarial attacks and how to defend against them. We investigated adversarial attacks common in the literature like fast gradient sign method (FGSM), iterative-FGSM / basic iterative method (BIM) and Carlini-Wagner (CW). Furthermore, we propose four pre-processing defenses against these attacks - randomized smoothing, DefenseGAN, variational autoencoder (VAE) and WaveGAN vocoder. We found that SID is extremely vulnerable under Iterative FGSM and CW attacks. Randomized smoothing defense robustified the system for imperceptible BIM and CW attacks recovering classification accuracies ~97%. Defenses based on generative models (DefenseGAN, VAE and WaveGAN) project adversarial examples (outside manifold) back into the clean manifold. In the case that attacker cannot adapt the attack to the defense (black-box defense), WaveGAN performed the best, being close to clean condition (Accuracy&gt;97%). However, if the attack is adapted to the defense - assuming the attacker has access to the defense model (white-box defense), VAE and WaveGAN protection dropped significantly-50% and 37% accuracy for CW attack. To counteract this,we combined randomized smoothing with VAE or WaveGAN. We found that smoothing followed by WaveGAN vocoder was the most effective defense overall. As a black-box defense, it provides 93% average accuracy. As white-box defense, accuracy only degraded for iterative attacks with perceptible perturbations (L&gt;=0.01).      
### 15.A Self-Updating K-Contingency List for Smart Grid System  [ :arrow_down: ](https://arxiv.org/pdf/2101.08896.pdf)
>  A reliable decision making by the operator in a smart grid is contingent upon correct analysis of intra-and-interdependencies between its entities and also on accurate identification of the most critical entities at a given point of time. A measurement based self-updating contingency list can provide real-time information to the operator about current system condition which can help the operator to take the required action. In this paper, the underlying intra-and-interdependencies between entities for a given power-communication network is captured using a dependency model called Modified Implicative Interdependency Model (MIIM) [1]. Given an integer K, the event-driven self-updating contingency list problem gives the list of K-most critical entities, failure of which maximizes the network damage at the current time. Owing to the problem being NP complete, a fast heuristic method to generate a real-time contingency list using system measurements is provided here. The validation of the work is done by comparing the contingency list obtained for different K values using the MIIM model on a smart grid of IEEE 14-Bus system with that obtained by simulating the smart grid using a co-simulation system formed by MATPOWER and Java Network Simulator (JNS). The results also indicate that the network damage predicted by both the ILP based solution [2] and the proposed heuristic solution using MIIM are more realistic compared to that obtained using another dependency model called Implicative Interdependency Model (IIM) [3].      
### 16.Analyzing Epistemic and Aleatoric Uncertainty for Drusen Segmentation in Optical Coherence Tomography Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.08888.pdf)
>  Age-related macular degeneration (AMD) is one of the leading causes of permanent vision loss in people aged over 60 years. Accurate segmentation of biomarkers such as drusen that points to the early stages of AMD is crucial in preventing further vision impairment. However, segmenting drusen is extremely challenging due to their varied sizes and appearances, low contrast and noise resemblance. Most existing literature, therefore, have focused on size estimation of drusen using classification, leaving the challenge of accurate segmentation less tackled. Additionally, obtaining the pixel-wise annotations is extremely costly and such labels can often be noisy, suffering from inter-observer and intra-observer variability. Quantification of uncertainty associated with segmentation tasks offers principled measures to inspect the segmentation output. Realizing its utility in identifying erroneous segmentation and the potential applications in clinical decision making, here we develop a U-Net based drusen segmentation model and quantify the segmentation uncertainty. We investigate epistemic uncertainty capturing the model confidence and aleatoric uncertainty capturing the data uncertainty. We present segmentation results and show how uncertainty can help formulate robust evaluation strategies. We visually inspect the pixel-wise uncertainty and segmentation results on test images. We finally analyze the correlation between segmentation uncertainty and accuracy. Our results demonstrate the utility of leveraging uncertainties in developing and explaining segmentation models for medical image analysis.      
### 17.Compositional Construction of Abstractions for Infinite Networks of Discrete-Time Switched Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.08873.pdf)
>  In this paper, we develop a compositional scheme for the construction of continuous approximations for interconnections of infinitely many discrete-time switched systems. An approximation (also known as abstraction) is itself a continuous-space system, which can be used as a replacement of the original (also known as concrete) system in a controller design process. Having designed a controller for the abstract system, it is refined to a more detailed one for the concrete system. We use the notion of so-called simulation functions to quantify the mismatch between the original system and its approximation. In particular, each subsystem in the concrete network and its corresponding one in the abstract network are related through a notion of local simulation functions. We show that if the local simulation functions satisfy certain small-gain type conditions developed for a network containing infinitely many subsystems, then the aggregation of the individual simulation functions provides an overall simulation function quantifying the error between the overall abstraction network and the concrete one. In addition, we show that our methodology results in a scale-free compositional approach for any finite-but-arbitrarily large networks obtained from truncation of an infinite network. We provide a systematic approach to construct local abstractions and simulation functions for networks of linear switched systems. The required conditions are expressed in terms of linear matrix inequalities that can be efficiently computed. We illustrate the effectiveness of our approach through an application to AC islanded microgirds.      
### 18.Distributed Receding Horizon Control of Autonomous Convoy with Self-Interested Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2101.08858.pdf)
>  This paper considers the problem of controlling a convoy of autonomous vehicles to be deployed on automated highways. The individual behavior of an autonomous vehicle as an intelligent self-interested decision-maker can be analyzed under a non-cooperative differential game model of the convoy. The receding horizon Nash equilibrium of the linear-quadratic differential game provides a distributed state-feedback control strategy for the convoy. This approach suffers a fundamental issue that neither the existence nor the uniqueness of a Nash equilibrium is guaranteed, so the convoy control. We present a relative dynamics based model of the convoy that carries all the features of the individual dynamics based game model. We show that the relative dynamics model guarantees the existence of the convoy control as well as the asymptotic stability of the closed-loop system. Simulations illustrate the effectiveness of the presented convoy control scheme.      
### 19.Unsupervised Pixel-wise Hyperspectral Anomaly Detection via Autoencoding Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.08827.pdf)
>  We propose a completely unsupervised pixel-wise anomaly detection method for hyperspectral images. The proposed method consists of three steps called data preparation, reconstruction, and detection. In the data preparation step, we apply a background purification to train the deep network in an unsupervised manner. In the reconstruction step, we propose to use three different deep autoencoding adversarial network (AEAN) models including 1D-AEAN, 2D-AEAN, and 3D-AEAN which are developed for working on spectral, spatial, and joint spectral-spatial domains, respectively. The goal of the AEAN models is to generate synthesized hyperspectral images (HSIs) which are close to real ones. A reconstruction error map (REM) is calculated between the original and the synthesized image pixels. In the detection step, we propose to use a WRX-based detector in which the pixel weights are obtained according to REM. We compare our proposed method with the classical RX, WRX, support vector data description-based (SVDD), collaborative representation-based detector (CRD), adaptive weight deep belief network (AW-DBN) detector and deep autoencoder anomaly detection (DAEAD) method on real hyperspectral datasets. The experimental results show that the proposed approach outperforms other detectors in the benchmark.      
### 20.Exact and Heuristic Methods with Warm-start for Embedded Mixed-Integer Quadratic Programming Based on Accelerated Dual Gradient Projection  [ :arrow_down: ](https://arxiv.org/pdf/2101.09264.pdf)
>  Small-scale Mixed-Integer Quadratic Programming (MIQP) problems often arise in embedded control and estimation applications. Driven by the need for algorithmic simplicity to target computing platforms with limited memory and computing resources, this paper proposes a few approaches to solving MIQPs, either to optimality or suboptimally. We specialize an existing Accelerated Dual Gradient Projection (GPAD) algorithm to effectively solve the Quadratic Programming (QP) relaxation that arise during Branch and Bound (B&amp;B) and propose a generic framework to warm-start the binary variables which reduces the number of QP relaxations. Moreover, in order to find an integer feasible combination of the binary variables upfront, two heuristic approaches are presented: ($i$) without using B&amp;B, and ($ii$) using B&amp;B with a significantly reduced number of QP relaxations. Both heuristic approaches return an integer feasible solution that may be suboptimal but involve a much reduced computation effort. Such a feasible solution can be either implemented directly or used to set an initial upper bound on the optimal cost in B&amp;B. Through different hybrid control and estimation examples involving binary decision variables, we show that the performance of the proposed methods, although very simple to code, is comparable to that of state-of-the-art MIQP solvers.      
### 21.Unequal Error Protection Achieves Threshold Gains on BEC and BSC via Higher Fidelity Messages  [ :arrow_down: ](https://arxiv.org/pdf/2101.09238.pdf)
>  Because of their capacity-approaching performance, graph-based codes have a wide range of applications, including communications and storage. In these codes, unequal error protection (UEP) can offer performance gains with limited rate loss. Recent empirical results in magnetic recording (MR) systems show that extra protection for the parity bits of a low-density parity-check (LDPC) code via constrained coding results in significant density gains. In particular, when UEP is applied via more reliable parity bits, higher fidelity messages of parity bits are spread to all bits by message passing algorithm, enabling performance gains. Threshold analysis is a tool to measure the effectiveness of a graph-based code or coding scheme. In this paper, we provide a theoretical analysis of this UEP idea using extrinsic information transfer (EXIT) charts in the binary erasure channel (BEC) and the binary symmetric channel (BSC). We use EXIT functions to investigate the effect of change in mutual information of parity bits on the overall coding scheme. We propose a setup in which parity bits of a repeat-accumulate (RA) LDPC code have lower erasure or crossover probabilities than input information bits. We derive the a-priori and extrinsic mutual information functions for check nodes and variable nodes of the code. After applying our UEP setup to the information functions, we formulate a linear programming problem to find the optimal degree distribution that maximizes the code rate under the decoding convergence constraint. Results show that UEP via higher fidelity parity bits achieves up to about $17\%$ and $28\%$ threshold gains on BEC and BSC, respectively.      
### 22.Continual Learning of Generative Models with Limited Data: From Wasserstein-1 Barycenter to Adaptive Coalescence  [ :arrow_down: ](https://arxiv.org/pdf/2101.09225.pdf)
>  Learning generative models is challenging for a network edge node with limited data and computing power. Since tasks in similar environments share model similarity, it is plausible to leverage pre-trained generative models from the cloud or other edge nodes. Appealing to optimal transport theory tailored towards Wasserstein-1 generative adversarial networks (WGAN), this study aims to develop a framework which systematically optimizes continual learning of generative models using local data at the edge node while exploiting adaptive coalescence of pre-trained generative models. Specifically, by treating the knowledge transfer from other nodes as Wasserstein balls centered around their pre-trained models, continual learning of generative models is cast as a constrained optimization problem, which is further reduced to a Wasserstein-1 barycenter problem. A two-stage approach is devised accordingly: 1) The barycenters among the pre-trained models are computed offline, where displacement interpolation is used as the theoretic foundation for finding adaptive barycenters via a "recursive" WGAN configuration; 2) the barycenter computed offline is used as meta-model initialization for continual learning and then fast adaptation is carried out to find the generative model using the local samples at the target edge node. Finally, a weight ternarization method, based on joint optimization of weights and threshold for quantization, is developed to compress the generative model further.      
### 23.X-ray Scatter Estimation Using Deep Splines  [ :arrow_down: ](https://arxiv.org/pdf/2101.09177.pdf)
>  Algorithmic X-ray scatter compensation is a desirable technique in flat-panel X-ray imaging and cone-beam computed tomography. State-of-the-art U-net based image translation approaches yielded promising results. As there are no physics constraints applied to the output of the U-Net, it cannot be ruled out that it yields spurious results. Unfortunately, those may be misleading in the context of medical imaging. To overcome this problem, we propose to embed B-splines as a known operator into neural networks. This inherently limits their predictions to well-behaved and smooth functions. In a study using synthetic head and thorax data as well as real thorax phantom data, we found that our approach performed on par with U-net when comparing both algorithms based on quantitative performance metrics. However, our approach not only reduces runtime and parameter complexity, but we also found it much more robust to unseen noise levels. While the U-net responded with visible artifacts, our approach preserved the X-ray signal's frequency characteristics.      
### 24.Virtual laser scanning with HELIOS++: A novel take on ray tracing-based simulation of topographic 3D laser scanning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09154.pdf)
>  Topographic laser scanning is a remote sensing method to create detailed 3D point cloud representations of the Earth's surface. Since data acquisition is expensive, simulations can complement real data given certain premises are available: i) a model of 3D scene and scanner, ii) a model of the beam-scene interaction, simplified to a computationally feasible while physically realistic level, and iii) an application for which simulated data is fit for use. A number of laser scanning simulators for different purposes exist, which we enrich by presenting HELIOS++. HELIOS++ is an open-source simulation framework for terrestrial static, mobile, UAV-based and airborne laser scanning implemented in C++. The HELIOS++ concept provides a flexible solution for the trade-off between physical accuracy (realism) and computational complexity (runtime, memory footprint), as well as ease of use and of configuration. Unique features of HELIOS++ include the availability of Python bindings (pyhelios) for controlling simulations, and a range of model types for 3D scene representation. HELIOS++ further allows the simulation of beam divergence using a subsampling strategy, and is able to create full-waveform outputs as a basis for detailed analysis. As generation and analysis of waveforms can strongly impact runtimes, the user may set the level of detail for the subsampling, or optionally disable full-waveform output altogether. A detailed assessment of computational considerations and a comparison of HELIOS++ to its predecessor, HELIOS, reveal reduced runtimes by up to 83 %. At the same time, memory requirements are reduced by up to 94 %, allowing for much larger (i.e. more complex) 3D scenes to be loaded into memory and hence to be virtually acquired by laser scanning simulation.      
### 25.Intelligent Reflecting Surface Enhanced Multi-UAV NOMA Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.09145.pdf)
>  Intelligent reflecting surface (IRS) enhanced multi-unmanned aerial vehicle (UAV) non-orthogonal multiple access (NOMA) networks are investigated. A new transmission framework is proposed, where multiple UAV-mounted base stations employ NOMA to serve multiple groups of ground users with the aid of an IRS. The three-dimensional (3D) placement and transmit power of UAVs, the reflection matrix of the IRS, and the NOMA decoding orders among users are jointly optimized for maximization of the sum rate of considered networks. To tackle the formulated mixed-integer non-convex optimization problem with coupled variables, a block coordinate descent (BCD)-based iterative algorithm is developed. Specifically, the original problem is decomposed into three subproblems, which are alternatingly solved by exploiting the penalty method and the successive convex approximation technique. The proposed BCD-based algorithm is demonstrated to be able to obtain a stationary point of the original problem with polynomial time complexity. Numerical results show that: 1) the proposed NOMA-IRS scheme for multi-UAV networks achieves a higher sum rate compared to the benchmark schemes, i.e., orthogonal multiple access (OMA)-IRS and NOMA without IRS; 2) the use of IRS is capable of providing performance gain for multi-UAV networks by both enhancing channel qualities of UAVs to their served users and mitigating the inter-UAV interference; and 3) optimizing the UAV placement can make the sum rate gain brought by NOMA more distinct due to the flexible decoding order design.      
### 26.Deep Inverse Design of Reconfigurable Metasurfaces for Future Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.09131.pdf)
>  Reconfigurable intelligent surfaces (RIS) have recently received significant attention as building blocks for smart radio environments and adaptable wireless channels. By altering the space- and time-varying electromagnetic (EM) properties, the RIS transforms the inherently stochastic nature of the wireless environment into a programmable propagation channel. Conventionally, designing RIS to yield the desired EM response requires trial-and-error by iteratively investigating a large possibility of various geometries and materials through thousands of full-wave EM simulations. In this context, deep learning (DL) techniques are proving critical in reducing the computational cost and time of RIS inverse design. Instead of explicitly solving Maxwell's equations, DL models learn physics-based relationships through supervised training data. Further, generative adversarial networks are shown to synthesize novel RIS designs not previously seen in the literature. This article provides a synopsis of DL techniques for inverse RIS design and optimization to yield targeted EM response necessary for future wireless networks.      
### 27.Exploiting Beam Search Confidence for Energy-Efficient Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.09083.pdf)
>  With computers getting more and more powerful and integrated in our daily lives, the focus is increasingly shifting towards more human-friendly interfaces, making Automatic Speech Recognition (ASR) a central player as the ideal means of interaction with machines. Consequently, interest in speech technology has grown in the last few years, with more systems being proposed and higher accuracy levels being achieved, even surpassing \textit{Human Accuracy}. While ASR systems become increasingly powerful, the computational complexity also increases, and the hardware support have to keep pace. In this paper, we propose a technique to improve the energy-efficiency and performance of ASR systems, focusing on low-power hardware for edge devices. We focus on optimizing the DNN-based Acoustic Model evaluation, as we have observed it to be the main bottleneck in state-of-the-art ASR systems, by leveraging run-time information from the Beam Search. By doing so, we reduce energy and execution time of the acoustic model evaluation by 25.6% and 25.9%, respectively, with negligible accuracy loss.      
### 28.WIP: Distance Estimation for Contact Tracing -- A Measurement Study of BLE and UWB Traces  [ :arrow_down: ](https://arxiv.org/pdf/2101.09075.pdf)
>  Mobile contact tracing apps are -- in principle -- a perfect aid to condemn the human-to-human spread of an infectious disease such as COVID-19 due to the wide use of smartphones worldwide. Yet, the unknown accuracy of contact estimation by wireless technologies hinders the broad use. We address this challenge by conducting a measurement study with a custom testbed to show the benefits and limitations of Bluetooth Low Energy (BLE) in comparison to distance estimation by ultra-wideband (UWB). Our results confirm that BLE-based distance estimation is not sufficient in real scenarios where smartphones are shielded heavily by the users' bodies. Yet, multi-path signal propagation reduces the effect of body shielding. Finally, we demonstrate that UWB is more robust to the environment than BLE.      
### 29.DSAL: Deeply Supervised Active Learning from Strong and Weak Labelers for Biomedical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.09057.pdf)
>  Image segmentation is one of the most essential biomedical image processing problems for different imaging modalities, including microscopy and X-ray in the Internet-of-Medical-Things (IoMT) domain. However, annotating biomedical images is knowledge-driven, time-consuming, and labor-intensive, making it difficult to obtain abundant labels with limited costs. Active learning strategies come into ease the burden of human annotation, which queries only a subset of training data for annotation. Despite receiving attention, most of active learning methods generally still require huge computational costs and utilize unlabeled data inefficiently. They also tend to ignore the intermediate knowledge within networks. In this work, we propose a deep active semi-supervised learning framework, DSAL, combining active learning and semi-supervised learning strategies. In DSAL, a new criterion based on deep supervision mechanism is proposed to select informative samples with high uncertainties and low uncertainties for strong labelers and weak labelers respectively. The internal criterion leverages the disagreement of intermediate features within the deep learning network for active sample selection, which subsequently reduces the computational costs. We use the proposed criteria to select samples for strong and weak labelers to produce oracle labels and pseudo labels simultaneously at each active learning iteration in an ensemble learning manner, which can be examined with IoMT Platform. Extensive experiments on multiple medical image datasets demonstrate the superiority of the proposed method over state-of-the-art active learning methods.      
### 30.Linear Regression with Distributed Learning: A Generalization Error Perspective  [ :arrow_down: ](https://arxiv.org/pdf/2101.09001.pdf)
>  Distributed learning provides an attractive framework for scaling the learning task by sharing the computational load over multiple nodes in a network. Here, we investigate the performance of distributed learning for large-scale linear regression where the model parameters, i.e., the unknowns, are distributed over the network. We adopt a statistical learning approach. In contrast to works that focus on the performance on the training data, we focus on the generalization error, i.e., the performance on unseen data. We provide high-probability bounds on the generalization error for both isotropic and correlated Gaussian data as well as sub-gaussian data. These results reveal the dependence of the generalization performance on the partitioning of the model over the network. In particular, our results show that the generalization error of the distributed solution can be substantially higher than that of the centralized solution even when the error on the training data is at the same level for both the centralized and distributed approaches. Our numerical results illustrate the performance with both real-world image data as well as synthetic data.      
### 31.CSI-Based Localization with CNNs Exploiting Phase Information  [ :arrow_down: ](https://arxiv.org/pdf/2101.08983.pdf)
>  In this paper we study the use of the Channel State Information (CSI) as fingerprint inputs of a Convolutional Neural Network (CNN) for localization. We examine whether the CSI can be used as a distinct fingerprint corresponding to a single position by considering the inconsistencies with its raw phase that cause the CSI to be unreliable. We propose two methods to produce reliable fingerprints including the phase information. Furthermore, we examine the structure of the CNN and more specifically the impact of pooling on the positioning performance, and show that pooling over the subcarriers can be more beneficial than over the antennas.      
### 32.AS-Net: Fast Photoacoustic Reconstruction with Multi-feature Fusion from Sparse Data  [ :arrow_down: ](https://arxiv.org/pdf/2101.08934.pdf)
>  Photoacoustic (PA) imaging is a biomedical imaging modality capable of acquiring high contrast images of optical absorption at depths much greater than traditional optical imaging techniques. However, practical instrumentation and geometry limit the number of available acoustic sensors surrounding the imaging target, which results in sparsity of sensor data. Conventional PA image reconstruction methods give severe artifacts when they are applied directly to these sparse data. In this paper, we first employ a novel signal processing method to make sparse PA raw data more suitable for the neural network, and concurrently speeding up image reconstruction. Then we propose Attention Steered Network (AS-Net) for PA reconstruction with multi-feature fusion. AS-Net is validated on different datasets, including simulated photoacoustic data from fundus vasculature phantoms and real data from in vivo fish and mice imaging experiments. Notably, the method is also able to eliminate some artifacts present in the ground-truth for in vivo data. Results demonstrated that our method provides superior reconstructions at a faster speed.      
### 33.Performance Analysis for Cache-enabled Cellular Networks with Cooperative Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2101.08918.pdf)
>  The large amount of deployed smart devices put tremendous traffic pressure on networks. Caching at the edge has been widely studied as a promising technique to solve this problem. To further improve the successful transmission probability (STP) of cache-enabled cellular networks (CEN), we combine the cooperative transmission technique with CEN and propose a novel transmission scheme. Local channel state information (CSI) is introduced at each cooperative base station (BS) to enhance the strength of the signal received by the user. A tight approximation for the STP of this scheme is derived using tools from stochastic geometry. The optimal content placement strategy of this scheme is obtained using a numerical method to maximize the STP. Simulation results demonstrate the optimal strategy achieves significant gains in STP over several comparative baselines with the proposed scheme.      
### 34.A co-Design approach to develop a smart cooking appliance. Applying a Domain Specific Language for a community supported appliance  [ :arrow_down: ](https://arxiv.org/pdf/2101.08886.pdf)
>  Our environment, whether at work, in public spaces, or at home, is becoming more connected, and increasingly responsive. Meal preparation even when it involves simply heating ready-made food can be perceived as a complex process for people with disabilities. This research aimed to prototype, using a co-Design approach a Community Supported Appliance (CSA) by developing a Domain Specific Language (DSL), precisely created for a semi-automated cooking process. The DSL was shaped and expressed in the idiom of the users and allowed the CSA to support independence for users while performing daily cooking activities.      
### 35.Centralized Collision-free Polynomial Trajectories and Goal Assignment for Aerial Swarms  [ :arrow_down: ](https://arxiv.org/pdf/2101.08829.pdf)
>  Computationally tractable methods are developed for centralized goal assignment and planning of collision-free polynomial-in-time trajectories for systems of multiple aerial robots. The method first assigns robots to goals to minimize total time-in-motion based on initial trajectories. By coupling the assignment and trajectory generation, the initial motion plans tend to require only limited collision resolution. The plans are then refined by checking for potential collisions and resolving them using either start time delays or altitude assignment. Numerical experiments using both methods show significant reductions in the total time required for agents to arrive at goals with only modest additional computational effort in comparison to state-of-the-art prior work, enabling planning for thousands of agents.      

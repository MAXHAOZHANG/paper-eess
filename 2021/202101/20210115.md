# ArXiv eess --Fri, 15 Jan 2021
### 1.Adaptive Frequency Response Reserve based on Real-time System Inertia  [ :arrow_down: ](https://arxiv.org/pdf/2101.05717.pdf)
>  To ensure adequate and economic reserve for primary frequency response in the current and future power system, this paper proposes real-time frequency response reserve (FRR) requirement based on system inertia. This minimum FRR will help power system operators adjust the current frequency response requirement and accommodate more renewable generations while achieving a saving of both energy and facility costs. Most importantly, the ability to adaptively vary the FRR will provide the additional agility, resiliency, and reliability to the grid.      
### 2.EmoCat: Language-agnostic Emotional Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2101.05695.pdf)
>  Emotional voice conversion models adapt the emotion in speech without changing the speaker identity or linguistic content. They are less data hungry than text-to-speech models and allow to generate large amounts of emotional data for downstream tasks. In this work we propose EmoCat, a language-agnostic emotional voice conversion model. It achieves high-quality emotion conversion in German with less than 45 minutes of German emotional recordings by exploiting large amounts of emotional data in US English. EmoCat is an encoder-decoder model based on CopyCat, a voice conversion system which transfers prosody. We use adversarial training to remove emotion leakage from the encoder to the decoder. The adversarial training is improved by a novel contribution to gradient reversal to truly reverse gradients. This allows to remove only the leaking information and to converge to better optima with higher conversion performance. Evaluations show that Emocat can convert to different emotions but misses on emotion intensity compared to the recordings, especially for very expressive emotions. EmoCat is able to achieve audio quality on par with the recordings for five out of six tested emotion intensities.      
### 3.Calibration based Minimalistic Multi-Exposure Digital Sensor Camera Robust Linear High Dynamic Range Enhancement Technique Demonstration  [ :arrow_down: ](https://arxiv.org/pdf/2101.05603.pdf)
>  Demonstrated for a digital image sensor based camera is a calibration target optimized method for finding the Camera Response Function (CRF). The proposed method uses localized known target zone pixel outputs spatial averaging and histogram analysis for saturated pixel detection. Using the proposed CRF generation method with a 87 dB High Dynamic Range (HDR) silicon CMOS image sensor camera viewing a 90 dB HDR calibration target, experimentally produced is a non-linear CRF with a limited 40 dB linear CRF zone. Next, a 78 dB test target is deployed to test the camera with this measured CRF and its restricted 40 dB zone. By engaging the proposed minimal exposures, weighting free, multi-exposure imaging method with 2 images, demonstrated is a highly robust recovery of the test target. In addition, the 78 dB test target recovery with 16 individual DR value patches stays robust over a factor of 20 change in test target illumination lighting. In comparison, a non-robust test target image recovery is produced by 5 leading prior-art multi-exposure HDR recovery algorithms using 16 images having 16 different exposure times, with each consecutive image having a sensor dwell time increasing by a factor of 2. Further validation of the proposed HDR image recovery method is provided using two additional experiments, the first using a 78 dB calibrated target combined with a natural indoor scene to form a hybrid design target and a second experiment using an uncalibrated indoor natural scene. The proposed technique applies to all digital image sensor based cameras having exposure time and illumination controls. In addition, the proposed methods apply to various sensor technologies, spectral bands, and imaging applications.      
### 4.Fast offline Transformer-based end-to-end automatic speech recognition for real-world applications  [ :arrow_down: ](https://arxiv.org/pdf/2101.05600.pdf)
>  Many real-world applications require to convert speech files into text with high accuracy with limited resources. This paper proposes a method to recognize large speech database fast using the Transformer-based end-to-end model. Transfomers have improved the state-of-the-art performance in many fields as well as speech recognition. But it is not easy to be used for long sequences. In this paper, various techniques to speed up the recognition of real-world speeches are proposed and tested including parallelizing the recognition using batched beam search, detecting end-of-speech based on connectionist temporal classification (CTC), restricting CTC prefix score and splitting long speeches into short segments. Experiments are conducted with real-world Korean speech recognition task. Experimental results with an 8-hour test corpus show that the proposed system can convert speeches into text in less than 3 minutes with 10.73% character error rate which is 27.1% relatively low compared to conventional DNN-HMM based recognition system.      
### 5.Dynamic network analysis of a target defense differential game with limited observations  [ :arrow_down: ](https://arxiv.org/pdf/2101.05592.pdf)
>  In this paper, we study a Target-Attacker-Defender (TAD) differential game involving one attacker and one target, both with unlimited visibility range, and multiple defenders with limited visibility capabilities. We assume that the target and attacker are unaware of defenders' visibility constraints which results in a dynamic game with asymmetric information. We seek to obtain the strategies that are likely to be used by the players. The visibility constraints of the defenders induce a visibility network which encapsulates the visibility information during the evolution of the game. Based on this observation, we introduce network adapted feedback or implementable strategies for the defenders. We construct a class of parametric performance indices for which the defenders' strategies along with standard feedback Nash strategies of the attacker and target provides a network adapted feedback Nash equilibrium. We introduce a consistency criterion for selecting a subset (or refinement) of network adapted feedback Nash strategies, and provide an optimization based approach for computing them. Finally, we illustrate our results with numerical experiments.      
### 6.Design of false data injection attack on distributed process estimation  [ :arrow_down: ](https://arxiv.org/pdf/2101.05567.pdf)
>  Herein, design of false data injection attack on a distributed cyber-physical system is considered. A stochastic process with linear dynamics and Gaussian noise is measured by multiple agent nodes, each equipped with multiple sensors. The agent nodes form a multi-hop network among themselves. Each agent node computes an estimate of the process by using its sensor observation and messages obtained from neighboring nodes, via Kalman-consensus filtering. An external attacker, capable of arbitrarily manipulating the sensor observations of some or all agent nodes, injects errors into those sensor observations. The goal of the attacker is to steer the estimates at the agent nodes as close as possible to a pre-specified value, while respecting a constraint on the attack detection probability. To this end, a constrained optimization problem is formulated to find the optimal parameter values of a certain class of linear attacks. The parameters of linear attack are learnt on-line via a combination of stochastic approximation based update of a Lagrange multiplier, and an optimization technique involving either the Karush-Kuhn-Tucker (KKT) conditions or online stochastic gradient descent. The problem turns out to be convex for some special cases. Desired convergence of the proposed algorithms are proved by exploiting the convexity and properties of stochastic approximation algorithms. Finally, numerical results demonstrate the efficacy of the attack.      
### 7.Optimal Energy Shaping via Neural Approximators  [ :arrow_down: ](https://arxiv.org/pdf/2101.05537.pdf)
>  We introduce optimal energy shaping as an enhancement of classical passivity-based control methods. A promising feature of passivity theory, alongside stability, has traditionally been claimed to be intuitive performance tuning along the execution of a given task. However, a systematic approach to adjust performance within a passive control framework has yet to be developed, as each method relies on few and problem-specific practical insights. Here, we cast the classic energy-shaping control design process in an optimal control framework; once a task-dependent performance metric is defined, an optimal solution is systematically obtained through an iterative procedure relying on neural networks and gradient-based optimization. The proposed method is validated on state-regulation tasks.      
### 8.An evaluation of word-level confidence estimation for end-to-end automatic speech recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.05525.pdf)
>  Quantifying the confidence (or conversely the uncertainty) of a prediction is a highly desirable trait of an automatic system, as it improves the robustness and usefulness in downstream tasks. In this paper we investigate confidence estimation for end-to-end automatic speech recognition (ASR). Previous work has addressed confidence measures for lattice-based ASR, while current machine learning research mostly focuses on confidence measures for unstructured deep learning. However, as the ASR systems are increasingly being built upon deep end-to-end methods, there is little work that tries to develop confidence measures in this context. We fill this gap by providing an extensive benchmark of popular confidence methods on four well-known speech datasets. There are two challenges we overcome in adapting existing methods: working on structured data (sequences) and obtaining confidences at a coarser level than the predictions (words instead of tokens). Our results suggest that a strong baseline can be obtained by scaling the logits by a learnt temperature, followed by estimating the confidence as the negative entropy of the predictive distribution and, finally, sum pooling to aggregate at word level.      
### 9.Speaker activity driven neural speech extraction  [ :arrow_down: ](https://arxiv.org/pdf/2101.05516.pdf)
>  Target speech extraction, which extracts the speech of a target speaker in a mixture given auxiliary speaker clues, has recently received increased interest. Various clues have been investigated such as pre-recorded enrollment utterances, direction information, or video of the target speaker. In this paper, we explore the use of speaker activity information as an auxiliary clue for single-channel neural network-based speech extraction. We propose a speaker activity driven speech extraction neural network (ADEnet) and show that it can achieve performance levels competitive with enrollment-based approaches, without the need for pre-recordings. We further demonstrate the potential of the proposed approach for processing meeting-like recordings, where speaker activity obtained from a diarization system is used as a speaker clue for ADEnet. We show that this simple yet practical approach can successfully extract speakers after diarization, which leads to improved ASR performance when using a single microphone, especially in high overlapping conditions, with a relative word error rate reduction of up to 25 %.      
### 10.Automated Model Design and Benchmarking of 3D Deep Learning Models for COVID-19 Detection with Chest CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2101.05442.pdf)
>  The COVID-19 pandemic has spread globally for several months. Because its transmissibility and high pathogenicity seriously threaten people's lives, it is crucial to accurately and quickly detect COVID-19 infection. Many recent studies have shown that deep learning (DL) based solutions can help detect COVID-19 based on chest CT scans. However, most existing work focuses on 2D datasets, which may result in low quality models as the real CT scans are 3D images. Besides, the reported results span a broad spectrum on different datasets with a relatively unfair comparison. In this paper, we first use three state-of-the-art 3D models (ResNet3D101, DenseNet3D121, and MC3\_18) to establish the baseline performance on the three publicly available chest CT scan datasets. Then we propose a differentiable neural architecture search (DNAS) framework to automatically search for the 3D DL models for 3D chest CT scans classification with the Gumbel Softmax technique to improve the searching efficiency. We further exploit the Class Activation Mapping (CAM) technique on our models to provide the interpretability of the results. The experimental results show that our automatically searched models (CovidNet3D) outperform the baseline human-designed models on the three datasets with tens of times smaller model size and higher accuracy. Furthermore, the results also verify that CAM can be well applied in CovidNet3D for COVID-19 datasets to provide interpretability for medical diagnosis.      
### 11.Dual-cycle Constrained Bijective VAE-GAN For Tagged-to-Cine Magnetic Resonance Image Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2101.05439.pdf)
>  Tagged magnetic resonance imaging (MRI) is a widely used imaging technique for measuring tissue deformation in moving organs. Due to tagged MRI's intrinsic low anatomical resolution, another matching set of cine MRI with higher resolution is sometimes acquired in the same scanning session to facilitate tissue segmentation, thus adding extra time and cost. To mitigate this, in this work, we propose a novel dual-cycle constrained bijective VAE-GAN approach to carry out tagged-to-cine MR image synthesis. Our method is based on a variational autoencoder backbone with cycle reconstruction constrained adversarial training to yield accurate and realistic cine MR images given tagged MR images. Our framework has been trained, validated, and tested using 1,768, 416, and 1,560 subject-independent paired slices of tagged and cine MRI from twenty healthy subjects, respectively, demonstrating superior performance over the comparison methods. Our method can potentially be used to reduce the extra acquisition time and cost, while maintaining the same workflow for further motion analyses.      
### 12.A Critical Look at Coulomb Counting Towards Improving the Kalman Filter Based State of Charge Tracking Algorithms in Rechargeable Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2101.05435.pdf)
>  In this paper, we consider the problem of state of charge estimation for rechargeable batteries. Coulomb counting is one of the traditional approaches to state of charge estimation and it is considered reliable as long as the battery capacity and initial state of charge are known. However, the Coulomb counting method is susceptible to errors from several sources and the extent of these errors are not studied in the literature. In this paper, we formally derive and quantify the state of charge estimation error during Coulomb counting due to the following four types of error sources: (i) current measurement error; (ii) current integration approximation error; (iii) battery capacity uncertainty; and (iv) the timing oscillator error/drift. It is shown that the resulting state of charge error can either be of the time-cumulative or of state-of-charge-proportional type. Time-cumulative errors increase with time and has the potential to completely invalidate the state of charge estimation in the long run. State-of-charge-proportional errors increase with the accumulated state of charge and reach its worst value within one charge/discharge cycle. Simulation analyses are presented to demonstrate the extent of these errors under several realistic scenarios and the paper discusses approaches to reduce the time-cumulative and state of charge-proportional errors.      
### 13.A Unified Conditional Disentanglement Framework for Multimodal Brain MR Image Translation  [ :arrow_down: ](https://arxiv.org/pdf/2101.05434.pdf)
>  Multimodal MRI provides complementary and clinically relevant information to probe tissue condition and to characterize various diseases. However, it is often difficult to acquire sufficiently many modalities from the same subject due to limitations in study plans, while quantitative analysis is still demanded. In this work, we propose a unified conditional disentanglement framework to synthesize any arbitrary modality from an input modality. Our framework hinges on a cycle-constrained conditional adversarial training approach, where it can extract a modality-invariant anatomical feature with a modality-agnostic encoder and generate a target modality with a conditioned decoder. We validate our framework on four MRI modalities, including T1-weighted, T1 contrast enhanced, T2-weighted, and FLAIR MRI, from the BraTS'18 database, showing superior performance on synthesis quality over the comparison methods. In addition, we report results from experiments on a tumor segmentation task carried out with synthesized data.      
### 14.Non-Parametric Quickest Detection of a Change in the Mean of an Observation Sequence  [ :arrow_down: ](https://arxiv.org/pdf/2101.05423.pdf)
>  We study the problem of quickest detection of a change in the mean of an observation sequence, under the assumption that both the pre- and post-change distributions have bounded support. We first study the case where the pre-change distribution is known, and then study the extension where only the mean and variance of the pre-change distribution are known. In both cases, no knowledge of the post-change distribution is assumed other than that it has bounded support. For the case where the pre-change distribution is known, we derive a test that asymptotically minimizes the worst-case detection delay over all post-change distributions, as the false alarm rate goes to zero. We then study the limiting form of the optimal test as the gap between the pre- and post-change means goes to zero, which we call the Mean-Change Test (MCT). We show that the MCT can be designed with only knowledge of the mean and variance of the pre-change distribution. We validate our analysis through numerical results for detecting a change in the mean of a beta distribution. We also demonstrate the use of the MCT for pandemic monitoring.      
### 15.Verification and Reachability Analysis of Fractional-Order Differential Equations Using Interval Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.05414.pdf)
>  Interval approaches for the reachability analysis of initial value problems for sets of classical ordinary differential equations have been investigated and implemented by many researchers during the last decades. However, there exist numerous applications in computational science and engineering, where continuous-time system dynamics cannot be described adequately by integer-order differential equations. Especially in cases in which long-term memory effects are observed, fractional-order system representations are promising to describe the dynamics, on the one hand, with sufficient accuracy and, on the other hand, to limit the number of required state variables and parameters to a reasonable amount. Real-life applications for such fractional-order models can, among others, be found in the field of electrochemistry, where methods for impedance spectroscopy are typically used to identify fractional-order models for the charging/discharging behavior of batteries or for the dynamic relation between voltage and current in fuel cell systems if operated in a non-stationary state. This paper aims at presenting an iterative method for reachability analysis of fractional-order systems that is based on an interval arithmetic extension of Mittag-Leffler functions. An illustrating example, inspired by a low-order model of battery systems concludes this contribution.      
### 16.Interval centred form for proving stability of non-linear discrete-time systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.05412.pdf)
>  In this paper, we propose a new approach to prove stability of non-linear discrete-time systems. After introducing the new concept of stability contractor, we show that the interval centred form plays a fundamental role in this context and makes it possible to easily prove asymptotic stability of a discrete system. Then, we illustrate the principle of our approach through theoretical examples. Finally, we provide two practical examples using our method : proving stability of a localisation system and that of the trajectory of a robot.      
### 17.A Multi-Stage Attentive Transfer Learning Framework for Improving COVID-19 Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2101.05410.pdf)
>  Computed tomography (CT) imaging is a promising approach to diagnosing the COVID-19. Machine learning methods can be employed to train models from labeled CT images and predict whether a case is positive or negative. However, there exists no publicly-available and large-scale CT data to train accurate models. In this work, we propose a multi-stage attentive transfer learning framework for improving COVID-19 diagnosis. Our proposed framework consists of three stages to train accurate diagnosis models through learning knowledge from multiple source tasks and data of different domains. Importantly, we propose a novel self-supervised learning method to learn multi-scale representations for lung CT images. Our method captures semantic information from the whole lung and highlights the functionality of each lung region for better representation learning. The method is then integrated to the last stage of the proposed transfer learning framework to reuse the complex patterns learned from the same CT images. We use a base model integrating self-attention (ATTNs) and convolutional operations. Experimental results show that networks with ATTNs induce greater performance improvement through transfer learning than networks without ATTNs. This indicates attention exhibits higher transferability than convolution. Our results also show that the proposed self-supervised learning method outperforms several baseline methods.      
### 18.A Deep Reinforcement Learning Framework for Eco-driving in Connected and Automated Hybrid Electric Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2101.05372.pdf)
>  Connected and Automated Vehicles (CAVs), in particular those with multiple power sources, have the potential to significantly reduce fuel consumption and travel time in real-world driving conditions. In particular, the Eco-driving problem seeks to design optimal speed and power usage profiles based upon look-ahead information from connectivity and advanced mapping features, to minimize the fuel consumption over a given itinerary. <br>Due to the complexity of the problem and the limited on-board computational capability, the real-time implementation of many existing methods that rely on online trajectory optimization becomes infeasible. In this work, the Eco-driving problem is formulated as a Partially Observable Markov Decision Process (POMDP), which is then solved with a state-of-art Deep Reinforcement Learning (DRL) Actor Critic algorithm, Proximal Policy Optimization. An Eco-driving simulation environment is developed for training and testing purposes. To benchmark the performance of the DRL controller, a baseline controller representing the human driver and the wait-and-see deterministic optimal solution are presented. With minimal on-board computational requirement and comparable travel time, the DRL controller reduces the fuel consumption by more than 17% by modulating the vehicle velocity over the route and performing energy-efficient approach and departure at signalized intersections when compared against a baseline controller.      
### 19.On the Identification of Electrical Equivalent Circuit Models Based on Noisy Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2101.05349.pdf)
>  Real-time identification of electrical equivalent circuit models is a critical requirement in many practical systems, such as batteries and electric motors. Significant work has been done in the past developing different types of algorithms for system identification using reduced equivalent circuit models. However, little work was done in analyzing the theoretical performance bounds of these approaches. Proper understanding of theoretical bounds will help in designing a system that is economical in cost and robust in performance. In this paper, we analyze the performance of a linear recursive least squares approach to equivalent circuit model identification and show that the least squares approach is both unbiased and efficient when the signal-to-noise ratio is high enough. However, we show that, when the signal-to-noise ratio is low - resembling the case in many practical applications - the least squares estimator becomes significantly biased. Consequently, we develop a parameter estimation approach based on total least squares method and show it to be asymptotically unbiased and efficient at practically low signal-to-noise ratio regions. Further, we develop a recursive implementation of the total least square algorithm and find it to be slow to converge; for this, we employ a Kalman filter to improve the convergence speed of the total least squares method. The resulting total Kalman filter is shown to be both unbiased and efficient in equivalent circuit model parameter identification. The performance of this filter is analyzed using real-world current profile under fluctuating signal-to-noise ratios. Finally, the applicability of the algorithms and analysis in this paper in identifying higher order electrical equivalent circuit models is explained.      
### 20.On the SIR Meta Distribution in Massive MTCNetworks with Scheduling and Data Aggregation  [ :arrow_down: ](https://arxiv.org/pdf/2101.05333.pdf)
>  Data aggregation is an efficient approach to handle the congestion introduced by a massive number of machine type devices (MTDs). The aggregators not only collect data but also implement scheduling mechanisms to cope with scarce network resources. We use the concept of meta distribution (MD) of the signal-to-interference ratio (SIR) to gain a complete understanding of the per-link reliability and describe the performance of two scheduling methods for data aggregation of machine type communication (MTC): random resource scheduling (RRS) and channel-aware resource scheduling (CRS). The results show the fraction of users in the network that achieves a target reliability, which is an important aspect to consider when designing wireless systems with stringent service requirements.      
### 21.Advancing Eosinophilic Esophagitis Diagnosis and Phenotype Assessment with Deep Learning Computer Vision  [ :arrow_down: ](https://arxiv.org/pdf/2101.05326.pdf)
>  Eosinophilic Esophagitis (EoE) is an inflammatory esophageal disease which is increasing in prevalence. The diagnostic gold-standard involves manual review of a patient's biopsy tissue sample by a clinical pathologist for the presence of 15 or greater eosinophils within a single high-power field (400x magnification). Diagnosing EoE can be a cumbersome process with added difficulty for assessing the severity and progression of disease. We propose an automated approach for quantifying eosinophils using deep image segmentation. A U-Net model and post-processing system are applied to generate eosinophil-based statistics that can diagnose EoE as well as describe disease severity and progression. These statistics are captured in biopsies at the initial EoE diagnosis and are then compared with patient metadata: clinical and treatment phenotypes. The goal is to find linkages that could potentially guide treatment plans for new patients at their initial disease diagnosis. A deep image classification model is further applied to discover features other than eosinophils that can be used to diagnose EoE. This is the first study to utilize a deep learning computer vision approach for EoE diagnosis and to provide an automated process for tracking disease severity and progression.      
### 22.Whispered and Lombard Neural Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2101.05313.pdf)
>  It is desirable for a text-to-speech system to take into account the environment where synthetic speech is presented, and provide appropriate context-dependent output to the user. In this paper, we present and compare various approaches for generating different speaking styles, namely, normal, Lombard, and whisper speech, using only limited data. The following systems are proposed and assessed: 1) Pre-training and fine-tuning a model for each style. 2) Lombard and whisper speech conversion through a signal processing based approach. 3) Multi-style generation using a single model based on a speaker verification model. Our mean opinion score and AB preference listening tests show that 1) we can generate high quality speech through the pre-training/fine-tuning approach for all speaking styles. 2) Although our speaker verification (SV) model is not explicitly trained to discriminate different speaking styles, and no Lombard and whisper voice is used for pre-training this system, the SV model can be used as a style encoder for generating different style embeddings as input for the Tacotron system. We also show that the resulting synthetic Lombard speech has a significant positive impact on intelligibility gain.      
### 23.DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows  [ :arrow_down: ](https://arxiv.org/pdf/2101.05796.pdf)
>  The difficulty of obtaining paired data remains a major bottleneck for learning image restoration and enhancement models for real-world applications. Current strategies aim to synthesize realistic training data by modeling noise and degradations that appear in real-world settings. We propose DeFlow, a method for learning stochastic image degradations from unpaired data. Our approach is based on a novel unpaired learning formulation for conditional normalizing flows. We model the degradation process in the latent space of a shared flow encoder-decoder network. This allows us to learn the conditional distribution of a noisy image given the clean input by solely minimizing the negative log-likelihood of the marginal distributions. We validate our DeFlow formulation on the task of joint image restoration and super-resolution. The models trained with the synthetic data generated by DeFlow outperform previous learnable approaches on all three datasets.      
### 24.Group Testing with a Graph Infection Spread Model  [ :arrow_down: ](https://arxiv.org/pdf/2101.05792.pdf)
>  We propose a novel infection spread model based on a random connection graph which represents connections between $n$ individuals. Infection spreads via connections between individuals and this results in a probabilistic cluster formation structure as well as a non-i.i.d. (correlated) infection status for individuals. We propose a class of two-step sampled group testing algorithms where we exploit the known probabilistic infection spread model. We investigate the metrics associated with two-step sampled group testing algorithms. To demonstrate our results, for analytically tractable exponentially split cluster formation trees, we calculate the required number of tests and the expected number of false classifications in terms of the system parameters, and identify the trade-off between them. For such exponentially split cluster formation trees, for zero-error construction, we prove that the required number of tests is $O(\log_2n)$. Thus, for such cluster formation trees, our algorithm outperforms any zero-error non-adaptive group test, binary splitting algorithm, and Hwang's generalized binary splitting algorithm. Our results imply that, by exploiting probabilistic information on the connections of individuals, group testing can be used to reduce the number of required tests significantly even when infection rate is high, contrasting the prevalent belief that group testing is useful only when infection rate is low.      
### 25.Rule-based Optimal Control for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2101.05709.pdf)
>  We develop optimal control strategies for Autonomous Vehicles (AVs) that are required to meet complex specifications imposed by traffic laws and cultural expectations of reasonable driving behavior. We formulate these specifications as rules, and specify their priorities by constructing a priority structure. We propose a recursive framework, in which the satisfaction of the rules in the priority structure are iteratively relaxed based on their priorities. Central to this framework is an optimal control problem, where convergence to desired states is achieved using Control Lyapunov Functions (CLFs), and safety is enforced through Control Barrier Functions (CBFs). We also show how the proposed framework can be used for after-the-fact, pass / fail evaluation of trajectories - a given trajectory is rejected if we can find a controller producing a trajectory that leads to less violation of the rule priority structure. We present case studies with multiple driving scenarios to demonstrate the effectiveness of the proposed framework.      
### 26.Generating coherent spontaneous speech and gesture from text  [ :arrow_down: ](https://arxiv.org/pdf/2101.05684.pdf)
>  Embodied human communication encompasses both verbal (speech) and non-verbal information (e.g., gesture and head movements). Recent advances in machine learning have substantially improved the technologies for generating synthetic versions of both of these types of data: On the speech side, text-to-speech systems are now able to generate highly convincing, spontaneous-sounding speech using unscripted speech audio as the source material. On the motion side, probabilistic motion-generation methods can now synthesise vivid and lifelike speech-driven 3D gesticulation. In this paper, we put these two state-of-the-art technologies together in a coherent fashion for the first time. Concretely, we demonstrate a proof-of-concept system trained on a single-speaker audio and motion-capture dataset, that is able to generate both speech and full-body gestures together from text input. In contrast to previous approaches for joint speech-and-gesture generation, we generate full-body gestures from speech synthesis trained on recordings of spontaneous speech from the same person as the motion-capture data. We illustrate our results by visualising gesture spaces and text-speech-gesture alignments, and through a demonstration video at <a class="link-external link-https" href="https://simonalexanderson.github.io/IVA2020" rel="external noopener nofollow">this https URL</a> .      
### 27.Continuous Deep Q-Learning with Simulator for Stabilization of Uncertain Discrete-Time Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.05640.pdf)
>  Applications of reinforcement learning (RL) to stabilization problems of real systems are restricted since an agent needs many experiences to learn an optimal policy and may determine dangerous actions during its exploration. If we know a mathematical model of a real system, a simulator is useful because it predicates behaviors of the real system using the mathematical model with a given system parameter vector. We can collect many experiences more efficiently than interactions with the real system. However, it is difficult to identify the system parameter vector accurately. If we have an identification error, experiences obtained by the simulator may degrade the performance of the learned policy. Thus, we propose a practical RL algorithm that consists of two stages. At the first stage, we choose multiple system parameter vectors. Then, we have a mathematical model for each system parameter vector, which is called a virtual system. We obtain optimal Q-functions for multiple virtual systems using the continuous deep Q-learning algorithm. At the second stage, we represent a Q-function for the real system by a linear approximated function whose basis functions are optimal Q-functions learned at the first stage. The agent learns the Q-function through interactions with the real system online. By numerical simulations, we show the usefulness of our proposed method.      
### 28.Parkinson's Disease Diagnosis Using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.05631.pdf)
>  Parkinson's Disease (PD) is a chronic, degenerative disorder which leads to a range of motor and cognitive symptoms. PD diagnosis is a challenging task since its symptoms are very similar to other diseases such as normal ageing and essential tremor. Much research has been applied to diagnosing this disease. This project aims to automate the PD diagnosis process using deep learning, Recursive Neural Networks (RNN) and Convolutional Neural Networks (CNN), to differentiate between healthy and PD patients. Besides that, since different datasets may capture different aspects of this disease, this project aims to explore which PD test is more effective in the discrimination process by analysing different imaging and movement datasets (notably cube and spiral pentagon datasets). In addition, this project evaluates which dataset type, imaging or time series, is more effective in diagnosing PD.      
### 29.Design of borehole resistivity measurement acquisition systems using deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.05623.pdf)
>  Borehole resistivity measurements recorded with logging-while-drilling (LWD) instruments are widely used for characterizing the earth's subsurface properties. They facilitate the extraction of natural resources such as oil and gas. LWD instruments require real-time inversions of electromagnetic measurements to estimate the electrical properties of the earth's subsurface near the well and possibly correct the well trajectory. Deep Neural Network (DNN)-based methods are suitable for the rapid inversion of borehole resistivity measurements as they approximate the forward and inverse problem offline during the training phase and they only require a fraction of a second for the evaluation (aka prediction). However, the inverse problem generally admits multiple solutions. DNNs with traditional loss functions based on data misfit are ill-equipped for solving an inverse problem. This can be partially overcome by adding regularization terms to a loss function specifically designed for encoder-decoder architectures. But adding regularization seriously limits the number of possible solutions to a set of a priori desirable physical solutions. To avoid this, we use a two-step loss function without any regularization. In addition, to guarantee an inverse solution, we need a carefully selected measurement acquisition system with a sufficient number of measurements. In this work, we propose a DNN-based iterative algorithm for designing such a measurement acquisition system. We illustrate our DNN-based iterative algorithm via several synthetic examples. Numerical results show that the obtained measurement acquisition system is sufficient to identify and characterize both resistive and conductive layers above and below the logging instrument. Numerical results are promising, although further improvements are required to make our method amenable for industrial purposes.      
### 30.Review on the Security Threats of Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2101.05614.pdf)
>  Internet of Things (IoT) is being considered as the growth engine for industrial revolution 4.0. The combination of IoT, cloud computing and healthcare can contribute in ensuring well-being of people. One important challenge of IoT network is maintaining privacy and to overcome security threats. This paper provides a systematic review of the security aspects of IoT. Firstly, the application of IoT in industrial and medical service scenarios are described, and the security threats are discussed for the different layers of IoT healthcare architecture. Secondly, different types of existing malware including spyware, viruses, worms, keyloggers, and trojan horses are described in the context of IoT. Thirdly, some of the recent malware attacks such as Mirai, echobot and reaper are discussed. Next, a comparative discussion is presented on the effectiveness of different machine learning algorithms in mitigating the security threats. It is found that the k-nearest neighbor (kNN) machine learning algorithm exhibits excellent accuracy in detecting malware. This paper also reviews different tools for ransomware detection, classification and analysis. Finally, a discussion is presented on the existing security issues, open challenges and possible future scopes in ensuring IoT security.      
### 31.Deep Cellular Recurrent Network for Efficient Analysis of Time-Series Data with Spatial Information  [ :arrow_down: ](https://arxiv.org/pdf/2101.05608.pdf)
>  Efficient processing of large-scale time series data is an intricate problem in machine learning. Conventional sensor signal processing pipelines with hand engineered feature extraction often involve huge computational cost with high dimensional data. Deep recurrent neural networks have shown promise in automated feature learning for improved time-series processing. However, generic deep recurrent models grow in scale and depth with increased complexity of the data. This is particularly challenging in presence of high dimensional data with temporal and spatial characteristics. Consequently, this work proposes a novel deep cellular recurrent neural network (DCRNN) architecture to efficiently process complex multi-dimensional time series data with spatial information. The cellular recurrent architecture in the proposed model allows for location-aware synchronous processing of time series data from spatially distributed sensor signal sources. Extensive trainable parameter sharing due to cellularity in the proposed architecture ensures efficiency in the use of recurrent processing units with high-dimensional inputs. This study also investigates the versatility of the proposed DCRNN model for classification of multi-class time series data from different application domains. Consequently, the proposed DCRNN architecture is evaluated using two time-series datasets: a multichannel scalp EEG dataset for seizure detection, and a machine fault detection dataset obtained in-house. The results suggest that the proposed architecture achieves state-of-the-art performance while utilizing substantially less trainable parameters when compared to comparable methods in the literature.      
### 32.On the design of terminal ingredients for data-driven MPC  [ :arrow_down: ](https://arxiv.org/pdf/2101.05573.pdf)
>  We present a model predictive control (MPC) scheme to control unknown linear time-invariant systems using only measured input-output data and no model knowledge. The scheme includes a terminal cost and a terminal set constraint on an extended state containing past input-output values. We provide an explicit design procedure for the corresponding terminal ingredients that only uses measured input-output data. Further, we prove that the MPC scheme based on these terminal ingredients exponentially stabilizes the desired setpoint in closed loop. Finally, we illustrate the advantages over existing methods with a numerical example.      
### 33.Cyber Taxi: A Taxonomy of Interactive Cyber Training and Education Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.05538.pdf)
>  The lack of guided exercises and practical opportunities to learn about cybersecurity in a practical way makes it difficult for security experts to improve their proficiency. Capture the Flag events and Cyber Ranges are ideal for cybersecurity training. Thereby, the participants usually compete in teams against each other, or have to defend themselves in a specific scenario. As organizers of yearly events, we present a taxonomy for interactive cyber training and education. The proposed taxonomy includes different factors of the technical setup, audience, training environment, and training setup. By the comprehensive taxonomy, different aspects of interactive training are considered. This can help trainings to improve and to be established successfully. The provided taxonomy is extendable and can be used in further application areas as research on new security technologies.      
### 34.Selective Deletion in a Blockchain  [ :arrow_down: ](https://arxiv.org/pdf/2101.05495.pdf)
>  The constantly growing size of blockchains becomes a challenge with the increasing usage. Especially the storage of unwanted data in a blockchain is an issue, because it cannot be removed naturally. In order to counteract this problem, we present the first concept for the selective deletion of single entries in a blockchain. For this purpose, the general consensus algorithm is extended by the functionality of regularly creating summary blocks. Previous data of the chain are summarized and stored again in a new block, leaving out unwanted information. With a shifting marker of the Genesis Block, data can be deleted from the beginning of a blockchain. In this way, the technology of the blockchain becomes fully transactional. The concept is independent of a specific block structure, network structure, or consensus algorithm. Moreover, this functionality can be adapted to current blockchains to solve multiple problems related to scalability. This approach enables the transfer of blockchain technology to further fields of application, among others in the area of Industry 4.0 and Product Life-cycle Management.      
### 35.WER-BERT: Automatic WER Estimation with BERT in a Balanced Ordinal Classification Paradigm  [ :arrow_down: ](https://arxiv.org/pdf/2101.05478.pdf)
>  Audio Speech Recognition (ASR) systems are evaluated using Word Error Rate (WER) which is calculated by comparing the number of errors between the ground truth and the ASR system's transcription. This calculation, however, requires manual transcription of the speech signal to obtain the ground truth. Since transcribing audio signals is a costly process, Automatic WER Evaluation (e-WER) methods have been developed which attempt to predict the WER of a Speech system by only relying on the transcription and the speech signal features. While WER is a continuous variable, previous works have shown that positing e-WER as a classification problem is more effective than regression. However, while converting to a classification setting, these approaches suffer from heavy class imbalance. In this paper, we propose a new balanced paradigm for e-WER in a classification setting. Within this paradigm, we also propose WER-BERT, a BERT based architecture with speech features for e-WER. Furthermore, we introduce a distance loss function to tackle the ordinal nature of e-WER classification. The proposed approach and paradigm are evaluated on the Librispeech dataset and a commercial (black box) ASR system, Google Cloud's Speech-to-Text API. The results and experiments demonstrate that WER-BERT establishes a new state-of-the-art in automatic WER estimation.      
### 36.Direct wavefront sensing from extended objects: a general sensor  [ :arrow_down: ](https://arxiv.org/pdf/2101.05445.pdf)
>  Wavefront sensing from an extended object is a challenging task since the phase to be sensed is disturbed by the phase generated from the structure of the extended object. To address this problem, a general wavefront sensor was proposed. The hardware of the sensor consists of a field lens, a collimating lens, a lenslet array, and a camera. The idea for its algorithm is to eliminate the phase caused by the extended object and reconstruct the point spread function through each lenslet. As a result, the scenario of wavefront sensing from an extended object has been converted to the conventional one from a point source. Numerical simulations and experiments both verify the feasibility and the accuracy of the proposed sensor.      
### 37.Unsupervised heart abnormality detection based on phonocardiogram analysis with Beta Variational Auto-Encoders  [ :arrow_down: ](https://arxiv.org/pdf/2101.05443.pdf)
>  Heart Sound (also known as phonocardiogram (PCG)) analysis is a popular way that detects cardiovascular diseases (CVDs). Most PCG analysis uses supervised way, which demands both normal and abnormal samples. This paper proposes a method of unsupervised PCG analysis that uses beta variational auto-encoder ($\beta-\text{VAE}$) to model the normal PCG signals. The best performed model reaches an AUC (Area Under Curve) value of 0.91 in ROC (Receiver Operating Characteristic) test for PCG signals collected from the same source. Unlike majority of $\beta-\text{VAE}$s that are used as generative models, the best-performed $\beta-\text{VAE}$ has a $\beta$ value smaller than 1. Further experiments then find that the introduction of a light weighted KL divergence between distribution of latent space and normal distribution improves the performance of anomaly PCG detection based on anomaly scores resulted by reconstruction loss. The fact suggests that anomaly score based on reconstruction loss may be better than anomaly scores based on latent vectors of samples      
### 38.Learning Safe Multi-Agent Control with Decentralized Neural Barrier Certificates  [ :arrow_down: ](https://arxiv.org/pdf/2101.05436.pdf)
>  We study the multi-agent safe control problem where agents should avoid collisions to static obstacles and collisions with each other while reaching their goals. Our core idea is to learn the multi-agent control policy jointly with learning the control barrier functions as safety certificates. We propose a novel joint-learning framework that can be implemented in a decentralized fashion, with generalization guarantees for certain function classes. Such a decentralized framework can adapt to an arbitrarily large number of agents. Building upon this framework, we further improve the scalability by incorporating neural network architectures that are invariant to the quantity and permutation of neighboring agents. In addition, we propose a new spontaneous policy refinement method to further enforce the certificate condition during testing. We provide extensive experiments to demonstrate that our method significantly outperforms other leading multi-agent control approaches in terms of maintaining safety and completing original tasks. Our approach also shows exceptional generalization capability in that the control policy can be trained with 8 agents in one scenario, while being used on other scenarios with up to 1024 agents in complex multi-agent environments and dynamics.      
### 39.Act to Reason: A Dynamic Game Theoretical Model of Driving  [ :arrow_down: ](https://arxiv.org/pdf/2101.05399.pdf)
>  The focus of this paper is to propose a driver model that incorporates human reasoning levels as actions during interactions with other drivers. Different from earlier work using game theoretical human reasoning levels, we propose a dynamic approach, where the actions are the levels themselves, instead of conventional driving actions such as accelerating or braking. This results in a dynamic behavior, where the agent adapts to its environment by exploiting different behavior models as available moves to choose from, depending on the requirements of the traffic situation. The bounded rationality assumption is preserved since the selectable strategies are designed by adhering to the fact that humans are cognitively limited in their understanding and decision making. Using a highway merging scenario, it is demonstrated that the proposed dynamic approach produces more realistic outcomes compared to the conventional method that employs fixed human reasoning levels.      
### 40.Uniform Error and Posterior Variance Bounds for Gaussian Process Regression with Application to Safe Control  [ :arrow_down: ](https://arxiv.org/pdf/2101.05328.pdf)
>  In application areas where data generation is expensive, Gaussian processes are a preferred supervised learning model due to their high data-efficiency. Particularly in model-based control, Gaussian processes allow the derivation of performance guarantees using probabilistic model error bounds. To make these approaches applicable in practice, two open challenges must be solved i) Existing error bounds rely on prior knowledge, which might not be available for many real-world tasks. (ii) The relationship between training data and the posterior variance, which mainly drives the error bound, is not well understood and prevents the asymptotic analysis. This article addresses these issues by presenting a novel uniform error bound using Lipschitz continuity and an analysis of the posterior variance function for a large class of kernels. Additionally, we show how these results can be used to guarantee safe control of an unknown dynamical system and provide numerical illustration examples.      
### 41.Learning and Fast Adaptation for Grid Emergency Control via Deep Meta Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.05317.pdf)
>  As power systems are undergoing a significant transformation with more uncertainties, less inertia and closer to operation limits, there is increasing risk of large outages. Thus, there is an imperative need to enhance grid emergency control to maintain system reliability and security. Towards this end, great progress has been made in developing deep reinforcement learning (DRL) based grid control solutions in recent years. However, existing DRL-based solutions have two main limitations: 1) they cannot handle well with a wide range of grid operation conditions, system parameters, and contingencies; 2) they generally lack the ability to fast adapt to new grid operation conditions, system parameters, and contingencies, limiting their applicability for real-world applications. In this paper, we mitigate these limitations by developing a novel deep meta reinforcement learning (DMRL) algorithm. The DMRL combines the meta strategy optimization together with DRL, and trains policies modulated by a latent space that can quickly adapt to new scenarios. We test the developed DMRL algorithm on the IEEE 300-bus system. We demonstrate fast adaptation of the meta-trained DRL polices with latent variables to new operating conditions and scenarios using the proposed method and achieve superior performance compared to the state-of-the-art DRL and model predictive control (MPC) methods.      

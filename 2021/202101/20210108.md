# ArXiv eess --Fri, 8 Jan 2021
### 1.Lossless Compression of Color images using Imperialist competitive algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2101.02678.pdf)
>  One of the most important reasons of the existence of different types of files with media (audio or video) content, is achieving compression and less size, while preserving quality. In terms of fast transportation of files between equipment and networks and decrease of the required storage space, compression have always been under attention and action. Considering what was mentioned, in general, the concept of compression can be divided into two classes of lossy and lossless. In the lossy method, a part of data is omitted, but in the lossless methods, no data is omitted for compression. At the end of this article, a lossless compression method is presented using Imperialist competitive algorithm for compression. The proposed algorithm tries to achieve a more optimized color for the image color-map, so that it increases the compression rate. The simulation results indicate that the proposed algorithm can perform the compression by 43 percent and show its superiority compared to other similar methods.      
### 2.28 GHz Indoor and Outdoor Propagation Analysis at a Regional Airport  [ :arrow_down: ](https://arxiv.org/pdf/2101.02599.pdf)
>  In the upcoming 5G communication, the millimeter-wave (mmWave) technology will play an important role due to its large bandwidth and high data rate. However, mmWave frequencies have higher free-space path loss (FSPL) in line-of-sight (LOS) propagation compared to the currently used sub-6 GHz frequencies. What is more, in non-line-of-sight (NLOS) propagation, the attenuation of mmWave is larger compared to the lower frequencies, which can seriously degrade the performance. It is therefore necessary to investigate mmWave propagation characteristics for a given deployment scenario to understand coverage and rate performance for that environment. In this paper, we focus on 28 GHz wideband mmWave signal propagation characteristics at Johnston Regional Airport (JNX), a local airport near Raleigh, NC. To collect data, we use an NI PXI based channel sounder at 28 GHz for indoor, outdoor, and indoor-to-outdoor scenarios. Results on LOS propagation, reflection, penetration, signal coverage, and multi-path components (MPCs) show a lower indoor FSPL, a richer scattering, and a better coverage compared to outdoor. We also observe high indoor-to-outdoor propagation losses.      
### 3.Monitoring of Railpad Long-term Condition in Turnouts Using Extreme Value Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2101.02567.pdf)
>  The railpad is a key element in railway infrastructures that plays an essential role in the train-track dynamics. Presence of worn or defective railpads along railway track may lead to large wheel/rail interaction forces, and a high rate of deterioration for track components. Despite the importance of railpad, the track infrastructure managers use no inspection tool for monitoring in-service railpads over time. In this paper, a novel data-driven monitoring tool for long-term performance analysis of in-service railpads is developed based on train-induced vibration data collected by a track-side measurement system. The monitoring tool consists of a method for track resonance frequencies estimation, a temperature-frequency model for describing railpad behavior with respect to ambient temperature, and a generalized likelihood ratio test based on the generalized extreme value distribution for detecting changes in the railpad status over time. To evaluate the performance of the proposed monitoring system, the status of railpads at four different locations along a railway turnout is monitored over a period of 18 months. It is shown that the monitoring system can successfully detect changes in railpad properties over the considered period.      
### 4.Attention-based multi-task learning for speech-enhancement and speaker-identification in multi-speaker dialogue scenario  [ :arrow_down: ](https://arxiv.org/pdf/2101.02550.pdf)
>  Multi-task learning (MTL) and the attention technique have been proven to effectively extract robust acoustic features for various speech-related applications in noisy environments. In this study, we integrated MTL and the attention-weighting mechanism and propose an attention-based MTL (ATM0 approach to realize a multi-model learning structure and to promote the speech enhancement (SE) and speaker identification (SI) systems simultaneously. There are three subsystems in the proposed ATM: SE, SI, and attention-Net (AttNet). In the proposed system, a long-short-term memory (LSTM) is used to perform SE, while a deep neural network (DNN) model is applied to construct SI and AttNet in ATM. The overall ATM system first extracts the representative features and then enhances the speech spectra in LSTM-SE and classifies speaker identity in DNN-SI. We conducted our experiment on Taiwan Mandarin hearing in noise test database. The evaluation results indicate that the proposed ATM system not only increases the quality and intelligibility of noisy speech input but also improves the accuracy of the SI system when compared to the conventional MTL approaches.      
### 5.Decision Support System for an Intelligent Operator of Utility Tunnel Boring Machines  [ :arrow_down: ](https://arxiv.org/pdf/2101.02463.pdf)
>  In tunnel construction projects, delays induce high costs. Thus, tunnel boring machines (TBM) operators aim for fast advance rates, without safety compromise, a difficult mission in uncertain ground environments. Finding the optimal control parameters based on the TBM sensors' measurements remains an open research question with large practical relevance. <br>In this paper, we propose an intelligent decision support system developed in three steps. First past projects performances are evaluated with an optimality score, taking into account the advance rate and the working pressure safety. Then, a deep learning model learns the mapping between the TBM measurements and this optimality score. Last, in real application, the model provides incremental recommendations to improve the optimality, taking into account the current setting and measurements of the TBM. <br>The proposed approach is evaluated on real micro-tunnelling project and demonstrates great promises for future projects.      
### 6.An Adaptive Multi-Agent Physical Layer Security Framework for Cognitive Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.02446.pdf)
>  Being capable of sensing and behavioral adaptation in line with their changing environments, cognitive cyber-physical systems (CCPSs) are the new form of applications in future wireless networks. With the advancement of the machine learning algorithms, the transmission scheme providing the best performance can be utilized to sustain a reliable network of CCPS agents equipped with self-decision mechanisms, where the interactions between each agent are modeled in terms of service quality, security, and cost dimensions. In this work, first, we provide network utility as a reliability metric, which is a weighted sum of the individual utility values of the CCPS agents. The individual utilities are calculated by mixing the quality of service (QoS), security, and cost dimensions with the proportions determined by the individualized user requirements. By changing the proportions, the CCPS network can be tuned for different applications of next-generation wireless networks. Then, we propose a secure transmission policy selection (STPS) mechanism that maximizes the network utility by using the Markov-decision process (MDP). In STPS, the CCPS network jointly selects the best performing physical layer security policy and the parameters of the selected secure transmission policy to adapt to the changing environmental effects. The proposed STPS is realized by reinforcement learning (RL), considering its real-time decision mechanism where agents can decide automatically the best utility providing policy in an altering environment.      
### 7.Weighted Truncated Nuclear Norm Regularization for Low-Rank Quaternion Matrix Completion  [ :arrow_down: ](https://arxiv.org/pdf/2101.02443.pdf)
>  In recent years, quaternion matrix completion (QMC) based on low-rank regularization has been gradually used in image de-noising and de-blurring.Unlike low-rank matrix completion (LRMC) which handles RGB images by recovering each color channel separately, the QMC models utilize the connection of three channels by processing them as a whole. Most of the existing quaternion-based methods formulate low-rank QMC (LRQMC) as a quaternion nuclear norm (a convex relaxation of the rank) minimization problem.The main limitation of these approaches is that the singular values being minimized simultaneously so that the low-rank property could not be approximated well and efficiently. To achieve a more accurate low-rank approximation, the matrix-based truncated nuclear norm has been proposed and also been proved to have the superiority. In this paper, we introduce a quaternion truncated nuclear norm (QTNN) for LRQMC and utilize the alternating direction method of multipliers (ADMM) to get the optimization.We further propose weights to the residual error quaternion matrix during the update process for accelerating the convergence of the QTNN method with admissible performance. The weighted method utilizes a concise gradient descent strategy which has a theoretical guarantee in optimization. The effectiveness of our method is illustrated by experiments on real visual datasets.      
### 8.An Adaptive All-Pass Filter for Time-Varying Delay Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2101.02406.pdf)
>  The focus of this paper is the estimation of a delay between two signals. Such a problem is common in signal processing and particularly challenging when the delay is non-stationary in nature. Our proposed solution is based on an all-pass filter framework comprising of two elements: a time delay is equivalent to all-pass filtering and an all-pass filter can be represented in terms of a ratio of a finite impulse response (FIR) filter and its time reversal. Using these elements, we propose an adaptive filtering algorithm with an LMS style update that estimates the FIR filter coefficients and the time delay. Specifically, at each time step, the algorithm updates the filter coefficients based on a gradient descent update and then extracts an estimate of the time delay from the filter. We validate our algorithm on synthetic data demonstrating that it is both accurate and capable of tracking time-varying delays.      
### 9.VHS to HDTV Video Translation using Multi-task Adversarial Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.02384.pdf)
>  There are large amount of valuable video archives in Video Home System (VHS) format. However, due to the analog nature, their quality is often poor. Compared to High-definition television (HDTV), VHS video not only has a dull color appearance but also has a lower resolution and often appears blurry. In this paper, we focus on the problem of translating VHS video to HDTV video and have developed a solution based on a novel unsupervised multi-task adversarial learning model. Inspired by the success of generative adversarial network (GAN) and CycleGAN, we employ cycle consistency loss, adversarial loss and perceptual loss together to learn a translation model. An important innovation of our work is the incorporation of super-resolution model and color transfer model that can solve unsupervised multi-task problem. To our knowledge, this is the first work that dedicated to the study of the relation between VHS and HDTV and the first computational solution to translate VHS to HDTV. We present experimental results to demonstrate the effectiveness of our solution qualitatively and quantitatively.      
### 10.Dual-Teacher++: Exploiting Intra-domain and Inter-domain Knowledge with Reliable Transfer for Cardiac Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.02375.pdf)
>  Annotation scarcity is a long-standing problem in medical image analysis area. To efficiently leverage limited annotations, abundant unlabeled data are additionally exploited in semi-supervised learning, while well-established cross-modality data are investigated in domain adaptation. In this paper, we aim to explore the feasibility of concurrently leveraging both unlabeled data and cross-modality data for annotation-efficient cardiac segmentation. To this end, we propose a cutting-edge semi-supervised domain adaptation framework, namely Dual-Teacher++. Besides directly learning from limited labeled target domain data (e.g., CT) via a student model adopted by previous literature, we design novel dual teacher models, including an inter-domain teacher model to explore cross-modality priors from source domain (e.g., MR) and an intra-domain teacher model to investigate the knowledge beneath unlabeled target domain. In this way, the dual teacher models would transfer acquired inter- and intra-domain knowledge to the student model for further integration and exploitation. Moreover, to encourage reliable dual-domain knowledge transfer, we enhance the inter-domain knowledge transfer on the samples with higher similarity to target domain after appearance alignment, and also strengthen intra-domain knowledge transfer of unlabeled target data with higher prediction confidence. In this way, the student model can obtain reliable dual-domain knowledge and yield improved performance on target domain data. We extensively evaluated the feasibility of our method on the MM-WHS 2017 challenge dataset. The experiments have demonstrated the superiority of our framework over other semi-supervised learning and domain adaptation methods. Moreover, our performance gains could be yielded in bidirections,i.e., adapting from MR to CT, and from CT to MR.      
### 11.Re-configurable Intelligent Surface-based VLC Receivers Using Tunable Liquid-crystals: The Concept  [ :arrow_down: ](https://arxiv.org/pdf/2101.02369.pdf)
>  Visible light communication (VLC) enables access to huge unlicensed bandwidth, a higher security level, and no radio frequency interference. With these advantages, VLC emerges as a complementary solution to radio frequency communications. VLC systems have primarily been designed for indoor scenarios with typical transmission distances between 2 and 5 m. Different designs would be required for larger distances. This paper proposes for the first time the use of a liquid crystal (LC)-based re-configurable intelligent surface (RIS) on improving the VLC signal detection and transmission range. An LC-based RIS presents multiple advantages, including the tunability of its photo-refractive parameters. Another advantage is its light amplification capabilities when under the influence of an externally applied field. In this paper, we analyze an LC-based RIS structure to amplify the detected light and improve the VLC signal detection and transmission range. Results show that mixing LC with 4 to 8 wt\% concentration of a dye such as the terthiophene (3T-2MB) improves the VLC transmission range of about 0.20 to 1.08 m. This improvement can reach 6.56 m if we combine 8 wt\% concentration of 3T-2MB and 0.1 wt\% concentration of trinitrofluorenone.      
### 12.Cross-domain Joint Dictionary Learning for ECG Inference from PPG  [ :arrow_down: ](https://arxiv.org/pdf/2101.02362.pdf)
>  The inverse problem of inferring electrocardiogram (ECG) from photoplethysmogram (PPG) is an emerging research direction that combines the easy measurability of PPG and the rich clinical knowledge of ECG for long-term continuous cardiac monitoring. The prior art for reconstruction using a universal basis has limited fidelity for uncommon ECG waveform shapes due to the lack of rich representative power. In this paper, we design two dictionary learning frameworks, the cross-domain joint dictionary learning (XDJDL) and the label-consistent XDJDL (LC-XDJDL), to further improve the ECG inference quality and enrich the PPG-based diagnosis knowledge. Building on the K-SVD technique, our proposed joint dictionary learning frameworks aim to maximize the expressive power by optimizing simultaneously a pair of signal dictionaries for PPG and ECG with the transforms to relate their sparse codes and disease information. The proposed models are evaluated with 34,000+ ECG/PPG cycle pairs containing a variety of ECG morphologies and cardiovascular diseases. We demonstrate both visually and quantitatively that our proposed frameworks can achieve better inference performance than previous methods, suggesting an encouraging potential for ECG screening using PPG based on the proactive learned PPG-ECG relationship.      
### 13.Joint User Activity and Data Detection in Grant-Free NOMA using Generative Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.02324.pdf)
>  Grant-free non-orthogonal multiple access (NOMA) is considered as one of the supporting technology for massive connectivity for future networks. In the grant-free NOMA systems with a massive number of users, user activity detection is of great importance. Existing multi-user detection (MUD) techniques rely on complicated update steps which may cause latency in signal detection. In this paper, we propose a generative neural network-based MUD (GenMUD) framework to utilize low-complexity neural networks, which are trained to reconstruct signals in a small fixed number of steps. By exploiting the uncorrelated user behaviours, we design a network architecture to achieve higher recovery accuracy with a low computational cost. Experimental results show significant performance gains in detection accuracy compared to conventional solutions under different channel conditions and user sparsity levels. We also provide a sparsity estimator through extensive experiments. Simulation results of the sparsity estimator showed high estimation accuracy, strong robustness to channel variations and neglectable impact on support detection accuracy.      
### 14.Integration of Renewable Generators in Synthetic Electric Grids for Dynamic Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.02319.pdf)
>  This paper presents a method to better integrate dynamic models for renewable resources into synthetic electric grids. An automated dynamic models assignment process is proposed for wind and solar generators. A realistic composition ratio for different types of wind turbine generators (WTG) is assigned to each wind generator. Statistics summarized from real electric grid data form the bases in assigning proper models with reasonable parameters to each WTG. A similar process is used to assign appropriate models and parameters to each photovoltaic (PV) generator. Multiple control strategies of the renewable resources are considered and tested in case studies. Two large-scale synthetic network test cases are used as examples of modeling the dynamics of renewable generators. Several transient stability metrics are adopted to assess the stability level after being subject to N-1 contingency event. Representative contingency events are given to demonstrate the performance of the synthetic renewable generator models.      
### 15.Review of Core Process Representation in Power System Operational Models: Gaps, Challenges, and Opportunities for Multisector Dynamics Research  [ :arrow_down: ](https://arxiv.org/pdf/2101.02303.pdf)
>  Power grid operations increasingly interact with environmental systems and human systems such as transportation, agriculture, the economy, and financial markets. Our objective is to discuss the modelling gaps and opportunities to advance the science for multisector adaptation and tradeoffs. We focus on power system operational models, which typically represent key physical and economic aspects of grid operations over days to a year and assume a fixed power grid infrastructure. Due to computational burden, models are typically customized to reflect regional resource opportunities, data availability, and applications of interest. While there are model intercomparison papers, there is however no model-agnostic characterization and systematic overview of the state-of-the-art process representations in operational power system models. To address our objective, we conceptualize power system operational models with four core processes: physical grid assets (generation, transmission, loads, and storage), model objectives and purpose, institutions and decision agents, and performance metrics. We taxonomize the representations of these core processes based on a review of 23 existing open-source and commercial models. As we acknowledge the computational burden of certain representations, we leverage this taxonomy to describe tradeoffs in process fidelity and tractability that have been adopted by the research community to address interactions between the power grid and hydrometeorological uncertainties, global change, and/or technological innovation. The core process taxonomy along with the existing computational tradeoffs are used to identify technical gaps and recommend future model development needs and research directions to better represent power grid operations as part of integrated multisector dynamics modeling and interdisciplinary research.      
### 16.Harvesting energy from a periodic heat bath  [ :arrow_down: ](https://arxiv.org/pdf/2101.02239.pdf)
>  The context of the present paper is stochastic thermodynamics - an approach to nonequilibrium thermodynamics rooted within the broader framework of stochastic control. In contrast to the classical paradigm of Carnot engines, we herein propose to consider thermodynamic processes with periodic continuously varying temperature of a heat bath and study questions of maximal power and efficiency for two idealized cases, overdamped (first-order) and underdamped (second-order) stochastic models. We highlight properties of optimal periodic control, derive and numerically validate approximate formulae for the optimal performance (power and efficiency).      
### 17.Zero-shot sim-to-real transfer of tactile control policies for aggressive swing-up manipulation  [ :arrow_down: ](https://arxiv.org/pdf/2101.02680.pdf)
>  This paper aims to show that robots equipped with a vision-based tactile sensor can perform dynamic manipulation tasks without prior knowledge of all the physical attributes of the objects to be manipulated. For this purpose, a robotic system is presented that is able to swing up poles of different masses, radii and lengths, to an angle of 180 degrees, while relying solely on the feedback provided by the tactile sensor. This is achieved by developing a novel simulator that accurately models the interaction of a pole with the soft sensor. A feedback policy that is conditioned on a sensory observation history, and which has no prior knowledge of the physical features of the pole, is then learned in the aforementioned simulation. When evaluated on the physical system, the policy is able to swing up a wide range of poles that differ significantly in their physical attributes without further adaptation. To the authors' knowledge, this is the first work where a feedback policy from high-dimensional tactile observations is used to control the swing-up manipulation of poles in closed-loop.      
### 18.Waveform and Beamforming Design for Intelligent Reflecting Surface Aided Wireless Power Transfer: Single-User and Multi-User Solutions  [ :arrow_down: ](https://arxiv.org/pdf/2101.02674.pdf)
>  In this paper, we study the waveform and passive beamforming design for intelligent reflecting surface (IRS)-aided wireless power transfer (WPT). Generalized multi-user and low complexity single-user algorithms are derived based on alternating optimization (AO) framework to maximize the weighted sum output DC current, subject to transmit power constraints and passive beamforming phases unit modulus constraints. The input signal waveform and IRS passive beamforming phase shifts are jointly designed as a function of users' individual frequency-selective channel state information (CSI). The energy harvester nonlinearity is explored and two IRS deployment schemes, namely frequency selective IRS (FS-IRS) and frequency flat IRS (FF-IRS), are modeled and analyzed. This paper highlights the fact that IRS can provide an extra passive beamforming gain on output DC power over conventional WPT designs and significantly influence the waveform design by leveraging the benefit of passive beamforming, frequency diversity and energy harvester nonlinearity. Even though FF-IRS exhibits lower output DC current than FS-IRS, it still achieves substantially increased DC power over conventional WPT designs. Performance evaluations confirm the significant benefits of a joint waveform and passive beamforming design accounting for the energy harvester nonlinearity to boost the performance of single-user and multi-user WPT system.      
### 19.Boundary Conditions for Linear Exit Time Gradient Trajectories Around Saddle Points: Analysis and Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2101.02625.pdf)
>  Gradient-related first-order methods have become the workhorse of large-scale numerical optimization problems. Many of these problems involve nonconvex objective functions with multiple saddle points, which necessitates an understanding of the behavior of discrete trajectories of first-order methods within the geometrical landscape of these functions. This paper concerns convergence of first-order discrete methods to a local minimum of nonconvex optimization problems that comprise strict saddle points within the geometrical landscape. To this end, it focuses on analysis of discrete gradient trajectories around saddle neighborhoods, derives sufficient conditions under which these trajectories can escape strict-saddle neighborhoods in linear time, explores the contractive and expansive dynamics of these trajectories in neighborhoods of strict-saddle points that are characterized by gradients of moderate magnitude, characterizes the non-curving nature of these trajectories, and highlights the inability of these trajectories to re-enter the neighborhoods around strict-saddle points after exiting them. Based on these insights and analyses, the paper then proposes a simple variant of the vanilla gradient descent algorithm, termed Curvature Conditioned Regularized Gradient Descent (CCRGD) algorithm, which utilizes a check for an initial boundary condition to ensure its trajectories can escape strict-saddle neighborhoods in linear time. Convergence analysis of the CCRGD algorithm, which includes its rate of convergence to a local minimum within a geometrical landscape that has a maximum number of strict-saddle points, is also presented in the paper. Numerical experiments are then provided on a test function as well as a low-rank matrix factorization problem to evaluate the efficacy of the proposed algorithm.      
### 20.Robust Machine Learning Systems: Challenges, Current Trends, Perspectives, and the Road Ahead  [ :arrow_down: ](https://arxiv.org/pdf/2101.02559.pdf)
>  Machine Learning (ML) techniques have been rapidly adopted by smart Cyber-Physical Systems (CPS) and Internet-of-Things (IoT) due to their powerful decision-making capabilities. However, they are vulnerable to various security and reliability threats, at both hardware and software levels, that compromise their accuracy. These threats get aggravated in emerging edge ML devices that have stringent constraints in terms of resources (e.g., compute, memory, power/energy), and that therefore cannot employ costly security and reliability measures. Security, reliability, and vulnerability mitigation techniques span from network security measures to hardware protection, with an increased interest towards formal verification of trained ML models. <br>This paper summarizes the prominent vulnerabilities of modern ML systems, highlights successful defenses and mitigation techniques against these vulnerabilities, both at the cloud (i.e., during the ML training phase) and edge (i.e., during the ML inference stage), discusses the implications of a resource-constrained design on the reliability and security of the system, identifies verification methodologies to ensure correct system behavior, and describes open research challenges for building secure and reliable ML systems at both the edge and the cloud.      
### 21.MRNet: a Multi-scale Residual Network for EEG-based Sleep Staging  [ :arrow_down: ](https://arxiv.org/pdf/2101.02538.pdf)
>  Sleep staging based on electroencephalogram (EEG) plays an important role in the clinical diagnosis and treatment of sleep disorders. In order to emancipate human experts from heavy labeling work, deep neural networks have been employed to formulate automated sleep staging systems recently. However, EEG signals lose considerable detailed information in network propagation, which affects the representation of deep features. To address this problem, we propose a new framework, called MRNet, for data-driven sleep staging by integrating a multi-scale feature fusion model and a Markov-based sequential correction algorithm. The backbone of MRNet is a residual block-based network, which performs as a feature extractor.Then the fusion model constructs a feature pyramid by concatenating the outputs from the different depths of the backbone, which can help the network better comprehend the signals in different scales. The Markov-based sequential correction algorithm is designed to reduce the output jitters generated by the classifier. The algorithm depends on a prior stage distribution associated with the sleep stage transition rule and the Markov chain. Experiment results demonstrate the competitive performance of our proposed approach on both accuracy and F1 score (e.g., 85.14% Acc and 78.91% F1 score on Sleep-EDFx, and 87.59% Acc and 79.62% F1 score on Sleep-EDF).      
### 22.MSED: a multi-modal sleep event detection model for clinical sleep analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.02530.pdf)
>  Study objective: Clinical sleep analysis require manual analysis of sleep patterns for correct diagnosis of sleep disorders. Several studies show significant variability in scoring discrete sleep events. We wished to investigate, whether an automatic method could be used for detection of arousals (Ar), leg movements (LM) and sleep disordered breathing (SDB) events, and if the joint detection of these events performed better than having three separate models. <br>Methods: We designed a single deep neural network architecture to jointly detect sleep events in a polysomnogram. We trained the model on 1653 recordings of individuals, and tested the optimized model on 1000 separate recordings. The performance of the model was quantified by F1, precision, and recall scores, and by correlating index values to clinical values using Pearson's correlation coefficient. <br>Results: F1 scores for the optimized model was 0.70, 0.63, and 0.62 for Ar, LM, and SDB, respectively. The performance was higher, when detecting events jointly compared to corresponding single-event models. Index values computed from detected events correlated well with manual annotations ($r^2$ = 0.73, $r^2$ = 0.77, $r^2$ = 0.78, respectively). <br>Conclusion: Detecting arousals, leg movements and sleep disordered breathing events jointly is possible, and the computed index values correlates well with human annotations.      
### 23.Distributed Quantum Computing and Network Control for Accelerated VQE  [ :arrow_down: ](https://arxiv.org/pdf/2101.02504.pdf)
>  Interconnecting small quantum computers will be essential in the future for creating large scale, robust quantum computers. Methods for distributing monolithic quantum algorithms efficiently are thus needed. In this work we consider an approach for distributing the accelerated variational quantum eigensolver (AVQE) algorithm over arbitrary sized - in terms of number of qubits - distributed quantum computers. We consider approaches for distributing qubit assignments of the Ansatz states required to estimate the expectation value of Hamiltonian operators in quantum chemistry in a parallelized computation and provide a systematic approach to generate distributed quantum circuits for distributed quantum computing. Moreover, we propose an architecture for a distributed quantum control system in the settings of centralized and decentralized network control.      
### 24.Active learning for object detection in high-resolution satellite images  [ :arrow_down: ](https://arxiv.org/pdf/2101.02480.pdf)
>  In machine learning, the term active learning regroups techniques that aim at selecting the most useful data to label from a large pool of unlabelled examples. While supervised deep learning techniques have shown to be increasingly efficient on many applications, they require a huge number of labelled examples to reach operational performances. Therefore, the labelling effort linked to the creation of the datasets required is also increasing. When working on defense-related remote sensing applications, labelling can be challenging due to the large areas covered and often requires military experts who are rare and whose time is primarily dedicated to operational needs. Limiting the labelling effort is thus of utmost importance. This study aims at reviewing the most relevant active learning techniques to be used for object detection on very high resolution imagery and shows an example of the value of such techniques on a relevant operational use case: aircraft detection.      
### 25.RobustSleepNet: Transfer learning for automated sleep staging at scale  [ :arrow_down: ](https://arxiv.org/pdf/2101.02452.pdf)
>  Sleep disorder diagnosis relies on the analysis of polysomnography (PSG) records. Sleep stages are systematically determined as a preliminary step of this examination. In practice, sleep stage classification relies on the visual inspection of 30-seconds epochs of polysomnography signals. Numerous automatic approaches have been developed to replace this tedious and expensive task. Although these methods demonstrated better performance than human sleep experts on specific datasets, they remain largely unused in sleep clinics. The main reason is that each sleep clinic uses a specific PSG montage that most automatic approaches are unable to handle out-of-the-box. Moreover, even when the PSG montage is compatible, publications have shown that automatic approaches perform poorly on unseen data with different demographics. To address these issues, we introduce RobustSleepNet, a deep learning model for automatic sleep stage classification able to handle arbitrary PSG montages. We trained and evaluated this model in a leave-one-out-dataset fashion on a large corpus of 8 heterogeneous sleep staging datasets to make it robust to demographic changes. When evaluated on an unseen dataset, RobustSleepNet reaches 97% of the F1 of a model trained specifically on this dataset. We then show that finetuning RobustSleepNet, using a part of the unseen dataset, increase the F1 by 2% when compared to a model trained specifically for this dataset. Hence, RobustSleepNet unlocks the possibility to perform high-quality out-of-the-box automatic sleep staging with any clinical setup. It can also be finetuned to reach a state-of-the-art level of performance on a specific population.      
### 26.Measurement of breast-tissue x-ray attenuation by spectral mammography: solid lesions  [ :arrow_down: ](https://arxiv.org/pdf/2101.02449.pdf)
>  Knowledge of x-ray attenuation is essential for developing and evaluating x-ray imaging technologies. For instance, techniques to distinguish between cysts and solid tumours at mammography screening would be highly desirable to reduce recalls, but the development requires knowledge of the x-ray attenuation for cysts and tumours. We have previously measured the attenuation of cyst fluid using photon-counting spectral mammography. Data on x-ray attenuation for solid breast lesions are available in the literature, but cover a relatively wide range, likely caused by natural spread between samples, random measurement errors, and different experimental conditions. In this study, we have adapted the previously developed spectral method to measure the linear attenuation of solid breast lesions. A total of 56 malignant and 5 benign lesions were included in the study. The samples were placed in a holder that allowed for thickness measurement. Spectral (energy-resolved) images of the samples were acquired and the image signal was mapped to equivalent thicknesses of two known reference materials, which can be used to derive the x-ray attenuation as a function of energy. The spread in equivalent material thicknesses was relatively large between samples, which is likely to be caused mainly by natural variation and only to a minor extent by random measurement errors and sample inhomogeneity. No significant difference in attenuation was found between benign and malignant solid lesions, or between different types of malignant lesions. The separation between cyst-fluid and tumour attenuation was, however, significant, which suggests it may be possible to distinguish cystic from solid breast lesions, and the results lay the groundwork for a clinical trial. [cropped]      
### 27.Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs  [ :arrow_down: ](https://arxiv.org/pdf/2101.02402.pdf)
>  To apply neural sequence models such as the Transformers to music generation tasks, one has to represent a piece of music by a sequence of tokens drawn from a finite set of pre-defined vocabulary. Such a vocabulary usually involves tokens of various types. For example, to describe a musical note, one needs separate tokens to indicate the note's pitch, duration, velocity (dynamics), and placement (onset time) along the time grid. While different types of tokens may possess different properties, existing models usually treat them equally, in the same way as modeling words in natural languages. In this paper, we present a conceptually different approach that explicitly takes into account the type of the tokens, such as note types and metric types. And, we propose a new Transformer decoder architecture that uses different feed-forward heads to model tokens of different types. With an expansion-compression trick, we convert a piece of music to a sequence of compound words by grouping neighboring tokens, greatly reducing the length of the token sequences. We show that the resulting model can be viewed as a learner over dynamic directed hypergraphs. And, we employ it to learn to compose expressive Pop piano music of full-song length (involving up to 10K individual tokens per song), both conditionally and unconditionally. Our experiment shows that, compared to state-of-the-art models, the proposed model converges 5--10 times faster at training (i.e., within a day on a single GPU with 11 GB memory), and with comparable quality in the generated music.      
### 28.COVID19-HPSMP: COVID-19 Adopted Hybrid and Parallel Deep Information Fusion Framework for Stock Price Movement Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2101.02287.pdf)
>  The novel of coronavirus (COVID-19) has suddenly and abruptly changed the world as we knew at the start of the 3rd decade of the 21st century. Particularly, COVID-19 pandemic has negatively affected financial econometrics and stock markets across the globe. Artificial Intelligence (AI) and Machine Learning (ML)-based prediction models, especially Deep Neural Network (DNN) architectures, have the potential to act as a key enabling factor to reduce the adverse effects of the COVID-19 pandemic and future possible ones on financial markets. In this regard, first, a unique COVID-19 related PRIce MOvement prediction (COVID19 PRIMO) dataset is introduced in this paper, which incorporates effects of social media trends related to COVID-19 on stock market price movements. Afterwards, a novel hybrid and parallel DNN-based framework is proposed that integrates different and diversified learning architectures. Referred to as the COVID-19 adopted Hybrid and Parallel deep fusion framework for Stock price Movement Prediction (COVID19-HPSMP), innovative fusion strategies are used to combine scattered social media news related to COVID-19 with historical mark data. The proposed COVID19-HPSMP consists of two parallel paths (hence hybrid), one based on Convolutional Neural Network (CNN) with Local/Global Attention modules, and one integrated CNN and Bi-directional Long Short term Memory (BLSTM) path. The two parallel paths are followed by a multilayer fusion layer acting as a fusion centre that combines localized features. Performance evaluations are performed based on the introduced COVID19 PRIMO dataset illustrating superior performance of the proposed framework.      
### 29.Fast Parallel Newton-Raphson Power Flow Solver for Large Number of System Calculations with CPU and GPU  [ :arrow_down: ](https://arxiv.org/pdf/2101.02270.pdf)
>  To analyze large sets of grid states, e.g. in time series calculations or parameter studies, large number of power flow calculations have to be performed, as well as evaluating the impact from uncertainties of the renewable energy e.g. wind and PV of power systems with Monte-Carlo simulation. For the application in real-time grid operation and in cases when computational time is critical, a novel approach on parallelization of Newton-Raphson power flow for many calculations on CPU and with GPU-acceleration is proposed. The result shows a speed-up of over x100 comparing to the open-source tool pandapower, when performing repetitive power flows of system with admittance matrix of the same sparsity pattern on both CPU and GPU. The speed-up relies on the optimized algorithm and parallelization strategy, which can reduce the repetitive work and saturate the high hardware performance of modern CPUs and GPUs well. This is achieved with the proposed batched sparse matrix operation and batched linear solver based on LU-refactorization. The batched linear solver shows a large performance improvement comparing to the state-of-art linear system solver KLU library and a better saturation of the GPU performance with small problem scale. Finally, the method of integrating the proposed solver into pandapower is presented, thus the parallel power flow solver with outstanding performance can be easily applied in challenging real-life grid operation and innovative researches e.g. data-driven machine learning studies.      
### 30.Enhanced IoV Security Network by Using Blockchain Governance Game  [ :arrow_down: ](https://arxiv.org/pdf/1904.11340.pdf)
>  This paper deals with the design of the secure network in an Enhanced Internet of Vehicles by using the Blockchain Governance Game (BGG). The BGG is a system model of a stochastic game to find best strategies towards preparation of preventing a network malfunction by an attacker and the paper applies this game model into the connected vehicle security. Analytically tractable results for decision-making parameters enable to predict the moment for safety operations and to deliver the optimal combination of the number of reserved nodes with the acceptance probability of backup nodes to protect a connected car. This research helps for whom considers the enhanced secure IoV architecture with the BGG within a decentralized network.      
### 31.Network Modeling of Short Over-Dispersed Spike-Counts: A Hierarchical Parametric Empirical Bayes Framework  [ :arrow_down: ](https://arxiv.org/pdf/1605.02869.pdf)
>  Accurate statistical models of neural spike responses can characterize the information carried by neural populations. Yet, challenges in recording at the level of individual neurons commonly results in relatively limited samples of spike counts, which can lead to model overfitting. Moreover, current models assume spike counts to be Poisson-distributed, which ignores the fact that many neurons demonstrate over-dispersed spiking behavior. The Negative Binomial Generalized Linear Model (NB-GLM) provides a powerful tool for modeling over-dispersed spike counts. However, maximum likelihood based standard NB-GLM leads to unstable and inaccurate parameter estimations. Thus, we propose a hierarchical parametric empirical Bayes method for estimating the parameters of the NB-GLM. Our method integrates Generalized Linear Models (GLMs) and empirical Bayes theory to: (1) effectively capture over-dispersion nature of spike counts from retinal ganglion neural responses; (2) significantly reduce mean square error of parameter estimations when compared to maximum likelihood based method for NB-GLMs; (3) provide an efficient alternative to fully Bayesian inference with low computational cost for hierarchical models; and (4) give insightful findings on both neural interactions and spiking behaviors of real retina cells. We apply our approach to study both simulated data and experimental neural data from the retina. The simulation results indicate the new framework can efficiently and accurately retrieve the weights of functional connections among neural populations and predict mean spike counts. The results from the retinal datasets demonstrate the proposed method outperforms both standard Poisson and Negative Binomial GLMs in terms of the predictive log-likelihood of held-out data.      

# ArXiv eess --Thu, 7 Jan 2021
### 1.Regularization-Agnostic Compressed Sensing MRI Reconstruction with Hypernetworks  [ :arrow_down: ](https://arxiv.org/pdf/2101.02194.pdf)
>  Reconstructing under-sampled k-space measurements in Compressed Sensing MRI (CS-MRI) is classically solved with regularized least-squares. Recently, deep learning has been used to amortize this optimization by training reconstruction networks on a dataset of under-sampled measurements. Here, a crucial design choice is the regularization function(s) and corresponding weight(s). In this paper, we explore a novel strategy of using a hypernetwork to generate the parameters of a separate reconstruction network as a function of the regularization weight(s), resulting in a regularization-agnostic reconstruction model. At test time, for a given under-sampled image, our model can rapidly compute reconstructions with different amounts of regularization. We analyze the variability of these reconstructions, especially in situations when the overall quality is similar. Finally, we propose and empirically demonstrate an efficient and data-driven way of maximizing reconstruction performance given limited hypernetwork capacity. Our code is publicly available at <a class="link-external link-https" href="https://github.com/alanqrwang/RegAgnosticCSMRI" rel="external noopener nofollow">this https URL</a>.      
### 2.Quick Annotator: an open-source digital pathology based rapid image annotation tool  [ :arrow_down: ](https://arxiv.org/pdf/2101.02183.pdf)
>  Image based biomarker discovery typically requires an accurate segmentation of histologic structures (e.g., cell nuclei, tubules, epithelial regions) in digital pathology Whole Slide Images (WSI). Unfortunately, annotating each structure of interest is laborious and often intractable even in moderately sized cohorts. Here, we present an open-source tool, Quick Annotator (QA), designed to improve annotation efficiency of histologic structures by orders of magnitude. While the user annotates regions of interest (ROI) via an intuitive web interface, a deep learning (DL) model is concurrently optimized using these annotations and applied to the ROI. The user iteratively reviews DL results to either (a) accept accurately annotated regions, or (b) correct erroneously segmented structures to improve subsequent model suggestions, before transitioning to other ROIs. We demonstrate the effectiveness of QA over comparable manual efforts via three use cases. These include annotating (a) 337,386 nuclei in 5 pancreatic WSIs, (b) 5,692 tubules in 10 colorectal WSIs, and (c) 14,187 regions of epithelium in 10 breast WSIs. Efficiency gains in terms of annotations per second of 102x, 9x, and 39x were respectively witnessed while retaining f-scores &gt;.95, suggesting QA may be a valuable tool for efficiently fully annotating WSIs employed in downstream biomarker studies.      
### 3.PowerDynamics.jl -- An experimentally validated open-source package for the dynamical analysis of power grids  [ :arrow_down: ](https://arxiv.org/pdf/2101.02103.pdf)
>  PowerDynamics.jl is a Julia package for time-domain modeling of power grids that is specifically designed for the stability analysis of systems with high shares of renewable energies. It makes use of Julia's state-of-the-art differential equation solvers and is highly performant even for systems with a large number of components. Further, it is compatible with Julia's machine learning libraries and allows for the utilization of these methods for dynamical optimization and parameter fitting. The package comes with a number of predefined models for synchronous machines, transmission lines and inverter systems. However, the strict open-source approach and a macro-based user-interface also allows for an easy implementation of custom-built models which makes it especially interesting for the design and testing of new control strategies for distributed generation units. This paper presents how the modeling concept, implemented component models and fault scenarios have been experimentally tested against measurements in the microgrid lab of TECNALIA.      
### 4.On-Sensor Inference for Uncertainty Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2101.02067.pdf)
>  This article presents an algorithm for reducing measurement uncertainty of one quantity when given measurements of two quantities with correlated noise. The algorithm assumes that the measurements of both physical quantities follow a Gaussian distribution and provides concrete justification that these assumptions are valid. When applied to humidity sensors, it provides reduced uncertainty in humidity estimates from correlated temperature and humidity measurements. In an experimental evaluation, the algorithm achieves uncertainty reduction of 4.2%. The algorithm incurs an execution time overhead of 1.4% when compared to the minimum algorithm required to measure and calculate the uncertainty. Detailed instruction-level emulation of a C-language implementation compiled to the RISC-V architecture shows that the uncertainty reduction program required 0.05% more instructions per iteration than the minimum operations required to calculate the uncertainty.      
### 5.Ensemble and Random Collaborative Representation-Based Anomaly Detector for Hyperspectral Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2101.01976.pdf)
>  In recent years, hyperspectral anomaly detection (HAD) has become an active topic and plays a significant role in military and civilian fields. As a classic HAD method, the collaboration representation-based detector (CRD) has attracted extensive attention and in-depth research. Despite the good performance of CRD method, its computational cost is too high for the widely demanded real-time applications. To alleviate this problem, a novel ensemble and random collaborative representation-based detector (ERCRD) is proposed for HAD. This approach comprises two main steps. Firstly, we propose a random background modeling to replace the sliding dual window strategy used in the original CRD method. Secondly, we can obtain multiple detection results through multiple random background modeling, and these results are further refined to final detection result through ensemble learning. Experiments on four real hyperspectral datasets exhibit the accuracy and efficiency of this proposed ERCRD method compared with ten state-of-the-art HAD methods.      
### 6.The 2020 Personalized Voice Trigger Challenge: Open Database, Evaluation Metrics and the Baseline Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.01935.pdf)
>  The 2020 Personalized Voice Trigger Challenge (PVTC2020) addresses two different research problems a unified setup: joint wake-up word detection with speaker verification on close-talking single microphone data and far-field multi-channel microphone array data. Specially, the second task poses an additional cross-channel matching challenge on top of the far-field condition. To simulate the real-life application scenario, the enrollment utterances are recorded from close-talking cell-phone only, while the test utterances are recorded from both the close-talking cell-phone and the far-field microphone arrays. This paper introduces our challenge setup and the released database as well as the evaluation metrics. In addition, we present a joint end-to-end neural network baseline system trained with the proposed database for speaker-dependent wake-up word detection. Results show that the cost calculated from the miss rate and the false alarm rate, can reach 0.37 in the close-talking single microphone task and 0.31 in the far-field microphone array task. The official website and the open-source baseline system have been released.      
### 7.A New Weighting Scheme for Fan-beam and Circle Cone-beam CT Reconstructions  [ :arrow_down: ](https://arxiv.org/pdf/2101.01886.pdf)
>  In this paper, we first present an arc based algorithm for fan-beam computed tomography (CT) reconstruction via applying Katsevich's helical CT formula to 2D fan-beam CT reconstruction. Then, we propose a new weighting function to deal with the redundant projection data. By extending the weighted arc based fan-beam algorithm to circle cone-beam geometry, we also obtain a new FDK-similar algorithm for circle cone-beam CT reconstruction. Experiments show that our methods can obtain higher PSNR and SSIM compared to the Parker-weighted conventional fan-beam algorithm and the FDK algorithm for super-short-scan trajectories.      
### 8.Biosensors and Machine Learning for Enhanced Detection, Stratification, and Classification of Cells: A Review  [ :arrow_down: ](https://arxiv.org/pdf/2101.01866.pdf)
>  Biological cells, by definition, are the basic units which contain the fundamental molecules of life of which all living things are composed. Understanding how they function and differentiating cells from one another therefore is of paramount importance for disease diagnostics as well as therapeutics. Sensors focusing on the detection and stratification of cells have gained popularity as technological advancements have allowed for the miniaturization of various components inching us closer to Point-of-Care (POC) solutions with each passing day. Furthermore, Machine Learning has allowed for enhancement in analytical capabilities of these various biosensing modalities, especially the challenging task of classification of cells into various categories using a data-driven approach rather than physics-driven. In this review, we provide an account of how Machine Learning has been applied explicitly to sensors that detect and classify cells. We also provide a comparison of how different sensing modalities and algorithms affect the classifier accuracy and the dataset size required.      
### 9.A Pilot Study of Smart Agricultural Irrigation using Unmanned Aerial Vehicles and IoT-Based Cloud System  [ :arrow_down: ](https://arxiv.org/pdf/2101.01851.pdf)
>  This article introduces a new mobile-based application of modern information and communication technology in agriculture based on Internet of Things (IoT), embedded systems and an unmanned aerial vehicle (UAV). The proposed agricultural monitoring system was designed and implemented using Arduino microcontroller boards, Wi-Fi modules, water pumps and electronic environmental sensors, namely temperature, humidity and soil moisture. The role of UAV in this study is to collect these environmental data from different regions of the farm. Then, the quantity of water irrigation is automatically computed for each region in the cloud. Moreover, the developed system can monitor the farm conditions including the water requirements remotely on Android mobile application to guide the farmers. The results of this study demonstrated that our proposed IoT-based embedded system can be effective to avoid unnecessary and wasted water irrigation within the framework of smart agriculture.      
### 10.On the Computational Complexity of the Secure State-Reconstruction Problem  [ :arrow_down: ](https://arxiv.org/pdf/2101.01827.pdf)
>  In this paper, we discuss the computational complexity of reconstructing the state of a linear system from sensor measurements that have been corrupted by an adversary. The first result establishes that the problem is, in general, NP-hard. We then introduce the notion of eigenvalue observability and show that the state can be reconstructed in polynomial time when each eigenvalue is observable by at least $2s+1$ sensors and at most $s$ sensors are corrupted by an adversary. However, there is a gap between eigenvalue observability and the possibility of reconstructing the state despite attacks - this gap has been characterized in the literature by the notion of sparse observability. To better understand this, we show that when the $\mathbf{A}$ matrix of the linear system has unitary geometric multiplicity, the gap disappears, i.e., eigenvalue observability coincides with sparse observability, and there exists a polynomial time algorithm to reconstruct the state provided the state can be reconstructed.      
### 11.Efficient Reachability Analysis of Closed-Loop Systems with Neural Network Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2101.01815.pdf)
>  Neural Networks (NNs) can provide major empirical performance improvements for robotic systems, but they also introduce challenges in formally analyzing those systems' safety properties. In particular, this work focuses on estimating the forward reachable set of closed-loop systems with NN controllers. Recent work provides bounds on these reachable sets, yet the computationally efficient approaches provide overly conservative bounds (thus cannot be used to verify useful properties), whereas tighter methods are too intensive for online computation. This work bridges the gap by formulating a convex optimization problem for reachability analysis for closed-loop systems with NN controllers. While the solutions are less tight than prior semidefinite program-based methods, they are substantially faster to compute, and some of the available computation time can be used to refine the bounds through input set partitioning, which more than overcomes the tightness gap. The proposed framework further considers systems with measurement and process noise, thus being applicable to realistic systems with uncertainty. Finally, numerical comparisons show $10\times$ reduction in conservatism in $\frac{1}{2}$ of the computation time compared to the state-of-the-art, and the ability to handle various sources of uncertainty is highlighted on a quadrotor model.      
### 12.Conceptual Design of LiFi Audio Transmission Using Pre-Programmed Modules  [ :arrow_down: ](https://arxiv.org/pdf/2101.01783.pdf)
>  We all know that Wi-Fi is presently the most commonly used technology for data transmission and connecting devices to the Internet, at the same time due to much reasonable concern, (such as Wi-Fi can be vulnerable when it comes to hacking, health concern, and low latency, etc.) the concept of Li-Fi is becoming very popular as a new way of data transmission that use light waves to transmit data rather than radio waves. Light-emitting diodes LED are used when transmitting the data in the visible light spectrum. Li-fi uses visible light communication and it has a promising future. Unlike Wi-fi, Li-Fi has low latency, high efficiency, accessible spectrum, and high data can be achieved. It is highly secured so the data cannot be hacked. In this paper, we design a concept of Li-fi audio signal transmission by reusing and repurposing pre-programmed modules to simplify and discuss visible light communication (VLC) in other to give a new researcher the idea on how the concept of LiFi and VLC. In addition to designing the concept we experiment to test the concept and we illustrated the result within this paper.      
### 13.A Review of Artificial Intelligence Technologies for Early Prediction of Alzheimer's Disease  [ :arrow_down: ](https://arxiv.org/pdf/2101.01781.pdf)
>  Alzheimer's Disease (AD) is a severe brain disorder, destroying memories and brain functions. AD causes chronically, progressively, and irreversibly cognitive declination and brain damages. The reliable and effective evaluation of early dementia has become essential research with medical imaging technologies and computer-aided algorithms. This trend has moved to modern Artificial Intelligence (AI) technologies motivated by deeplearning success in image classification and natural language processing. The purpose of this review is to provide an overview of the latest research involving deep-learning algorithms in evaluating the process of dementia, diagnosing the early stage of AD, and discussing an outlook for this research. This review introduces various applications of modern AI algorithms in AD diagnosis, including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Automatic Image Segmentation, Autoencoder, Graph CNN (GCN), Ensemble Learning, and Transfer Learning. The advantages and disadvantages of the proposed methods and their performance are discussed. The conclusion section summarizes the primary contributions and medical imaging preprocessing techniques applied in the reviewed research. Finally, we discuss the limitations and future outlooks.      
### 14.Federated Learning over Noisy Channels: Convergence Analysis and Design Examples  [ :arrow_down: ](https://arxiv.org/pdf/2101.02198.pdf)
>  Does Federated Learning (FL) work when both uplink and downlink communications have errors? How much communication noise can FL handle and what is its impact to the learning performance? This work is devoted to answering these practically important questions by explicitly incorporating both uplink and downlink noisy channels in the FL pipeline. We present several novel convergence analyses of FL over simultaneous uplink and downlink noisy communication channels, which encompass full and partial clients participation, direct model and model differential transmissions, and non-independent and identically distributed (IID) local datasets. These analyses characterize the sufficient conditions for FL over noisy channels to have the same convergence behavior as the ideal case of no communication error. More specifically, in order to maintain the O(1/T) convergence rate of FedAvg with perfect communications, the uplink and downlink signal-to-noise ratio (SNR) for direct model transmissions should be controlled such that they scale as O(t^2) where t is the index of communication rounds, but can stay constant for model differential transmissions. The key insight of these theoretical results is a "flying under the radar" principle - stochastic gradient descent (SGD) is an inherent noisy process and uplink/downlink communication noises can be tolerated as long as they do not dominate the time-varying SGD noise. We exemplify these theoretical findings with two widely adopted communication techniques - transmit power control and diversity combining - and further validating their performance advantages over the standard methods via extensive numerical experiments using several real-world FL tasks.      
### 15.Combining Deep Learning and Mathematical Morphology for Historical Map Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.02144.pdf)
>  The digitization of historical maps enables the study of ancient, fragile, unique, and hardly accessible information sources. Main map features can be retrieved and tracked through the time for subsequent thematic analysis. The goal of this work is the vectorization step, i.e., the extraction of vector shapes of the objects of interest from raster images of maps. We are particularly interested in closed shape detection such as buildings, building blocks, gardens, rivers, etc. in order to monitor their temporal evolution. Historical map images present significant pattern recognition challenges. The extraction of closed shapes by using traditional Mathematical Morphology (MM) is highly challenging due to the overlapping of multiple map features and texts. Moreover, state-of-the-art Convolutional Neural Networks (CNN) are perfectly designed for content image filtering but provide no guarantee about closed shape detection. Also, the lack of textural and color information of historical maps makes it hard for CNN to detect shapes that are represented by only their boundaries. Our contribution is a pipeline that combines the strengths of CNN (efficient edge detection and filtering) and MM (guaranteed extraction of closed shapes) in order to achieve such a task. The evaluation of our approach on a public dataset shows its effectiveness for extracting the closed boundaries of objects in historical maps.      
### 16.Investigating the efficacy of music version retrieval systems for setlist identification  [ :arrow_down: ](https://arxiv.org/pdf/2101.02098.pdf)
>  The setlist identification (SLI) task addresses a music recognition use case where the goal is to retrieve the metadata and timestamps for all the tracks played in live music events. Due to various musical and non-musical changes in live performances, developing automatic SLI systems is still a challenging task that, despite its industrial relevance, has been under-explored in the academic literature. In this paper, we propose an end-to-end workflow that identifies relevant metadata and timestamps of live music performances using a version identification system. We compare 3 of such systems to investigate their suitability for this particular task. For developing and evaluating SLI systems, we also contribute a new dataset that contains 99.5h of concerts with annotated metadata and timestamps, along with the corresponding reference set. The dataset is categorized by audio qualities and genres to analyze the performance of SLI systems in different use cases. Our approach can identify 68% of the annotated segments, with values ranging from 35% to 77% based on the genre. Finally, we evaluate our approach against a database of 56.8k songs to illustrate the effect of expanding the reference set, where we can still identify 56% of the annotated segments.      
### 17.Impact of Inter-Channel Interference on Shallow Underwater Acoustic OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.02089.pdf)
>  This paper investigates the impacts of Inter-Channel Interference (ICI) effects on a shallow underwater acoustic (UWA) orthogonal frequency-division multiplexing (OFDM) communication system. Considering both the turbulence of the water surface and the roughness of the bottom, a stochastic geometry-based channel model utilized for a wide-band transmission scenario has been exploited to derive a simulation model. Since the system bandwidth and the sub-carrier spacing is very limited in the range of a few kHz, the channel capacity of a UWA system is severely suffered by the ICI effect. For further investigation, we construct the signal-to-noise-plus-interference ratio (SINR) based on the simulation model, then evaluate the channel capacity. Numerical results show that the various factors of a UWA-OFDM system as subcarriers, bandwidth, and OFDM symbols affect the channel capacity under the different Doppler frequencies. Those observations give hints to select the good parameters for UWA-OFDM systems.      
### 18.A unified view for unsupervised representation learning with density ratio estimation: Maximization of mutual information, nonlinear ICA and nonlinear subspace estimation  [ :arrow_down: ](https://arxiv.org/pdf/2101.02083.pdf)
>  Unsupervised representation learning is one of the most important problems in machine learning. Recent promising methods are based on contrastive learning. However, contrastive learning often relies on heuristic ideas, and therefore it is not easy to understand what contrastive learning is doing. This paper emphasizes that density ratio estimation is a promising goal for unsupervised representation learning, and promotes understanding to contrastive learning. Our primal contribution is to theoretically show that density ratio estimation unifies three frameworks for unsupervised representation learning: Maximization of mutual information (MI), nonlinear independent component analysis (ICA) and a novel framework for estimation of a lower-dimensional nonlinear subspace proposed in this paper. This unified view clarifies under what conditions contrastive learning can be regarded as maximizing MI, performing nonlinear ICA or estimating the lower-dimensional nonlinear subspace in the proposed framework. Furthermore, we also make theoretical contributions in each of the three frameworks: We show that MI can be maximized through density ratio estimation under certain conditions, while our analysis for nonlinear ICA reveals a novel insight for recovery of the latent source components, which is clearly supported by numerical experiments. In addition, some theoretical conditions are also established to estimate a nonlinear subspace in the proposed framework. Based on the unified view, we propose two practical methods for unsupervised representation learning through density ratio estimation: The first method is an outlier-robust method for representation learning, while the second one is a sample-efficient nonlinear ICA method. Finally, we numerically demonstrate usefulness of the proposed methods in nonlinear ICA and through application to a downstream task for classification.      
### 19.Shallow-UWnet : Compressed Model for Underwater Image Enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2101.02073.pdf)
>  Over the past few decades, underwater image enhancement has attracted increasing amount of research effort due to its significance in underwater robotics and ocean engineering. Research has evolved from implementing physics-based solutions to using very deep CNNs and GANs. However, these state-of-art algorithms are computationally expensive and memory intensive. This hinders their deployment on portable devices for underwater exploration tasks. These models are trained on either synthetic or limited real world datasets making them less practical in real-world scenarios. In this paper we propose a shallow neural network architecture, \textbf{Shallow-UWnet} which maintains performance and has fewer parameters than the state-of-art models. We also demonstrated the generalization of our model by benchmarking its performance on combination of synthetic and real-world datasets.      
### 20.FDMA-CDMA Mode CAOS Camera Demonstration using UV to NIR Full Spectrum  [ :arrow_down: ](https://arxiv.org/pdf/2101.02061.pdf)
>  For the first time, the hybrid Frequency Division Multiple Access (FDMA) Code Division Multiple Access (CDMA) mode of the CAOS (i.e., Coded Access Optical Sensor) camera is demonstrated. The FDMA CDMA mode is a time frequency double signal encoding design for robust and faster linear High Dynamic Range (HDR) image irradiance extraction. Specifically, it simultaneously combines the strength of the FDMA-mode linear HDR Fast Fourier Transform (FFT) Digital Signal Processing (DSP) based spectrum analysis with the CDMA mode provided many simultaneous CAOS pixels high Signal to Noise Ratio (SNR) photo-detection. The FDMA CDMA mode with P FDMA channels provides a faster camera operation versus the linear HDR Frequency Modulation (FM) CDMA mode. Visible band imaging experiments using a Digital Micromirror Device (DMD) based CAOS camera demonstrate a P equal to 4 channels FDMA CDMA mode high quality image recovery of a calibrated 64 dB 6 patches HDR target versus the CDMA and FM CDMA CAOS modes that limit dynamic range and speed, respectively. Simultaneous dual image capture capability of the FDMA-CDMA mode is also demonstrated for the first time in Ultraviolet (UV) to Near Infrared (NIR) 350 to 1800 nm full spectrum using Silicon (Si) and Germanium (Ge) point photo-detectors.      
### 21.Cross-Validation and Uncertainty Determination for Randomized Neural Networks with Applications to Mobile Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2101.01990.pdf)
>  Randomized artificial neural networks such as extreme learning machines provide an attractive and efficient method for supervised learning under limited computing ressources and green machine learning. This especially applies when equipping mobile devices (sensors) with weak artificial intelligence. Results are discussed about supervised learning with such networks and regression methods in terms of consistency and bounds for the generalization and prediction error. Especially, some recent results are reviewed addressing learning with data sampled by moving sensors leading to non-stationary and dependent samples. <br>As randomized networks lead to random out-of-sample performance measures, we study a cross-validation approach to handle the randomness and make use of it to improve out-of-sample performance. Additionally, a computationally efficient approach to determine the resulting uncertainty in terms of a confidence interval for the mean out-of-sample prediction error is discussed based on two-stage estimation. The approach is applied to a prediction problem arising in vehicle integrated photovoltaics.      
### 22.Multichannel CRNN for Speaker Counting: an Analysis of Performance  [ :arrow_down: ](https://arxiv.org/pdf/2101.01977.pdf)
>  Speaker counting is the task of estimating the number of people that are simultaneously speaking in an audio recording. For several audio processing tasks such as speaker diarization, separation, localization and tracking, knowing the number of speakers at each timestep is a prerequisite, or at least it can be a strong advantage, in addition to enabling a low latency processing. In a previous work, we addressed the speaker counting problem with a multichannel convolutional recurrent neural network which produces an estimation at a short-term frame resolution. In this work, we show that, for a given frame, there is an optimal position in the input sequence for best prediction accuracy. We empirically demonstrate the link between that optimal position, the length of the input sequence and the size of the convolutional filters.      
### 23.WEST operation with real time feed back control based on wall component temperature toward machine protection in a steady state tungsten environment  [ :arrow_down: ](https://arxiv.org/pdf/2101.01914.pdf)
>  A real time Wall Monitoring System (WMS) is used on the WEST tokamak during the C4 experimental campaign. The WMS uses the wall surface temperatures from 6 fields of view of the Infrared viewing system. It extracts the raw digital data from selected areas, converts it to temperatures using the calibration and write it on the shared memory network being used by the Plasma Control System (PCS). The PCS feeds back to actuators, namely the injected power from 5 antennae's of the lower hybrid and ion cyclotron resonance radiofrequency (RF) heating systems. WMS activates feed back control 63 times during C4, which is 14% of the plasma discharges. It activates mainly as the result of a direct RF loss to the upper divertor pipes. The feedback control maintains the wall temperature within the operation envelope during 97% of the occurrences, while enabling plasma discharge continuation. The false positive rate establishes at 0.2%. WMS significantly facilitated the operation path to high power operation during C4, by managing the technical risks to critical wall components.      
### 24.Low-Complexity Interference Cancellation Algorithms for Detection in Media-based Modulated Uplink Massive-MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.01905.pdf)
>  Media-based modulation (MBM) is a novel modulation technique that can improve the spectral efficiency of the existing wireless systems. In MBM, multiple radio frequency (RF) mirrors are placed near the transmit antenna(s) and are switched ON/OFF to create different channel fade realizations. In such systems, additional information is conveyed through the ON/OFF status of RF mirrors along with conventional modulation symbols. A challenging task at the receiver is to detect the transmitted information symbols and extract the additional information from the channel fade realization used for transmission. In this paper, we consider a massive MIMO (mMIMO) system where each user relies on MBM for transmitting information to the base station, and investigate the problem of symbol detection at the base station. First, we propose a mirror activation pattern (MAP) selection based modified iterative sequential detection algorithm. With the proposed algorithm, the most favorable MAP is selected, followed by the detection of symbol corresponding to the selected MAP. Each solution is subjected to the reliability check before getting the update. Next, we introduce a $K$ favorable MAP search based iterative interference cancellation (KMAP-IIC) algorithm. In particular, a selection rule is introduced in KMAP-IIC for deciding the set of favorable MAPs over which iterative interference cancellation is performed, followed by a greedy update scheme for detecting the MBM symbols corresponding to each user. Simulation results show that the proposed detection algorithms exhibit superior performance-complexity trade-off over the existing detection techniques in MBM-mMIMO systems.      
### 25.Interspeech 2021 Deep Noise Suppression Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2101.01902.pdf)
>  The Deep Noise Suppression (DNS) challenge is designed to foster innovation in the area of noise suppression to achieve superior perceptual speech quality. We recently organized a DNS challenge special session at INTERSPEECH and ICASSP 2020. We open-sourced training and test datasets for the wideband scenario. We also open-sourced a subjective evaluation framework based on ITU-T standard P.808, which was also used to evaluate participants of the challenge. Many researchers from academia and industry made significant contributions to push the field forward, yet even the best noise suppressor was far from achieving superior speech quality in challenging scenarios. In this version of the challenge organized at INTERSPEECH 2021, we are expanding both our training and test datasets to accommodate full band scenarios. The two tracks in this challenge will focus on real-time denoising for (i) wide band, and(ii) full band scenarios. We are also making available a reliable non-intrusive objective speech quality metric called DNSMOS for the participants to use during their development phase.      
### 26.Generalized Necessary and Sufficient Robust Boundedness Results for Feedback Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.01900.pdf)
>  Classical conditions for ensuring the robust stability of a system in feedback with a nonlinearity include passivity, small gain, circle, and conicity theorems. We present a generalized and unified version of these results in an arbitrary semi-inner product space, which avoids many of the technicalities that arise when working in traditional extended spaces. Our general formulation clarifies when the sufficient conditions for robust stability are also necessary, and we show how to construct worst-case scenarios when the sufficient conditions fail to hold. Finally, we show how our general result can be specialized to recover a wide variety of existing results, and explain how properties such as boundedness, causality, linearity, and time-invariance emerge as a natural consequence.      
### 27.Performance Analysis and Optimization of Bidirectional Overlay Cognitive Radio Networks with Hybrid-SWIPT  [ :arrow_down: ](https://arxiv.org/pdf/2101.01897.pdf)
>  This paper considers a cooperative cognitive radio network with two primary users (PUs) and two secondary users (SUs) that enables two-way communications of primary and secondary systems in conjunction with non-linear energy harvesting based simultaneous wireless information and power transfer (SWIPT). With the considered network, SUs are able to realize their communications over the licensed spectrum while extending relay assistance to the PUs. The overall bidirectional end-to-end transmission takes place in four phases, which include both energy harvesting (EH) and information transfer. A non-linear energy harvester with a hybrid SWIPT scheme is adopted in which both power-splitting and time-switching EH techniques are used. The SUs aid in relay cooperation by performing an amplify-and-forward operation, whereas selection combining technique is adopted at the PUs to extract the intended signal from multiple received signals broadcasted by the SUs. Accurate outage probability expressions for the primary and secondary links are derived under the Nakagami-$m$ fading environment. Further, the system behavior is analyzed with respect to achievable system throughput and energy efficiency. Since the performance of the considered system is strongly affected by the spectrum sharing factor and hybrid SWIPT parameters, particle swarm optimization is implemented to optimize the system parameters so as to maximize the system throughput and energy efficiency. Simulation results are provided to corroborate the performance analysis and give useful insights into the system behavior concerning various system/channel parameters.      
### 28.3D Convolutional Selective Autoencoder For Instability Detection in Combustion Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.01877.pdf)
>  While analytical solutions of critical (phase) transitions in physical systems are abundant for simple nonlinear systems, such analysis remains intractable for real-life dynamical systems. A key example of such a physical system is thermoacoustic instability in combustion, where prediction or early detection of an onset of instability is a hard technical challenge, which needs to be addressed to build safer and more energy-efficient gas turbine engines powering aerospace and energy industries. The instabilities arising in combustion chambers of engines are mathematically too complex to model. To address this issue in a data-driven manner instead, we propose a novel deep learning architecture called 3D convolutional selective autoencoder (3D-CSAE) to detect the evolution of self-excited oscillations using spatiotemporal data, i.e., hi-speed videos taken from a swirl-stabilized combustor (laboratory surrogate of gas turbine engine combustor). 3D-CSAE consists of filters to learn, in a hierarchical fashion, the complex visual and dynamic features related to combustion instability. We train the 3D-CSAE on frames of videos obtained from a limited set of operating conditions. We select the 3D-CSAE hyper-parameters that are effective for characterizing hierarchical and multiscale instability structure evolution by utilizing the dynamic information available in the video. The proposed model clearly shows performance improvement in detecting the precursors of instability. The machine learning-driven results are verified with physics-based off-line measures. Advanced active control mechanisms can directly leverage the proposed online detection capability of 3D-CSAE to mitigate the adverse effects of combustion instabilities on the engine operating under various stringent requirements and conditions.      
### 29.Environment Transfer for Distributed Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.01863.pdf)
>  Collecting sufficient amount of data that can represent various acoustic environmental attributes is a critical problem for distributed acoustic machine learning. Several audio data augmentation techniques have been introduced to address this problem but they tend to remain in simple manipulation of existing data and are insufficient to cover the variability of the environments. We propose a method to extend a technique that has been used for transferring acoustic style textures between audio data. The method transfers audio signatures between environments for distributed acoustic data augmentation. This paper devises metrics to evaluate the generated acoustic data, based on classification accuracy and content preservation. A series of experiments were conducted using UrbanSound8K dataset and the results show that the proposed method generates better audio data with transferred environmental features while preserving content features.      
### 30.Hypothesis Stitcher for End-to-End Speaker-attributed ASR on Long-form Multi-talker Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2101.01853.pdf)
>  An end-to-end (E2E) speaker-attributed automatic speech recognition (SA-ASR) model was proposed recently to jointly perform speaker counting, speech recognition and speaker identification. The model achieved a low speaker-attributed word error rate (SA-WER) for monaural overlapped speech comprising an unknown number of speakers. However, the E2E modeling approach is susceptible to the mismatch between the training and testing conditions. It has yet to be investigated whether the E2E SA-ASR model works well for recordings that are much longer than samples seen during training. In this work, we first apply a known decoding technique that was developed to perform single-speaker ASR for long-form audio to our E2E SA-ASR task. Then, we propose a novel method using a sequence-to-sequence model, called hypothesis stitcher. The model takes multiple hypotheses obtained from short audio segments that are extracted from the original long-form input, and it then outputs a fused single hypothesis. We propose several architectural variations of the hypothesis stitcher model and compare them with the conventional decoding methods. Experiments using LibriSpeech and LibriCSS corpora show that the proposed method significantly improves SA-WER especially for long-form multi-talker recordings.      
### 31.Deep Learning for Fast and Reliable Initial Access in AI-Driven 6G mmWave Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.01847.pdf)
>  We present DeepIA, a deep neural network (DNN) framework for enabling fast and reliable initial access for AI-driven beyond 5G and 6G millimeter (mmWave) networks. DeepIA reduces the beam sweep time compared to a conventional exhaustive search-based IA process by utilizing only a subset of the available beams. DeepIA maps received signal strengths (RSSs) obtained from a subset of beams to the beam that is best oriented to the receiver. In both line of sight (LoS) and non-line of sight (NLoS) conditions, DeepIA reduces the IA time and outperforms the conventional IA's beam prediction accuracy. We show that the beam prediction accuracy of DeepIA saturates with the number of beams used for IA and depends on the particular selection of the beams. In LoS conditions, the selection of the beams is consequential and improves the accuracy by up to 70%. In NLoS situations, it improves accuracy by up to 35%. We find that, averaging multiple RSS snapshots further reduces the number of beams needed and achieves more than 95% accuracy in both LoS and NLoS conditions. Finally, we evaluate the beam prediction time of DeepIA through embedded hardware implementation and show the improvement over the conventional beam sweeping.      
### 32.Synergistic Multi-spectral CT Reconstruction with Directional Total Variation  [ :arrow_down: ](https://arxiv.org/pdf/2101.01834.pdf)
>  This work considers synergistic multi-spectral CT reconstruction where information from all available energy channels is combined to improve the reconstruction of each individual channel, we propose to fuse this available data (represented by a single sinogram) to obtain a polyenergetic image which keeps structural information shared by the energy channels with increased signal-to-noise-ratio. This new image is used as prior information during the minimization process through the directional total variation. We analyze the use of directional total variation within variational regularization and iterative regularization. Our numerical results on simulated and experimental data show significant improvements in terms of image quality and in computational speed.      
### 33.Large-Scale Extended Granger Causality for Classification of Marijuana Users From Functional MRI  [ :arrow_down: ](https://arxiv.org/pdf/2101.01832.pdf)
>  It has been shown in the literature that marijuana use is associated with changes in brain network connectivity. We propose large-scale Extended Granger Causality (lsXGC) and investigate whether it can capture such changes using resting-state fMRI. This method combines dimension reduction with source time-series augmentation and uses predictive time-series modeling for estimating directed causal relationships among fMRI time-series. It is a multivariate approach, since it is capable of identifying the interdependence of time-series in the presence of all other time-series of the underlying dynamic system. Here, we investigate whether this model can serve as a biomarker for classifying marijuana users from typical controls using 126 adult subjects with a childhood diagnosis of ADHD from the Addiction Connectome Preprocessed Initiative (ACPI) database. We use brain connections estimated by lsXGC as features for classification. After feature extraction, we perform feature selection by Kendall's-tau rank correlation coefficient followed by classification using a support vector machine. As a reference method, we compare our results with cross-correlation, which is typically used in the literature as a standard measure of functional connectivity. Within a cross-validation scheme of 100 different training/test (90%/10%) data splits, we obtain a mean accuracy range of [0.714, 0.985] and a mean Area Under the receiver operating characteristic Curve (AUC) range of [0.779, 0.999] across all tested numbers of features for lsXGC, which is significantly better than results obtained with cross-correlation, namely mean accuracy of [0.728, 0.912] and mean AUC of [0.825, 0.969]. Our results suggest the applicability of lsXGC as a potential biomarker for marijuana use.      

# ArXiv eess --Tue, 12 Jan 2021
### 1.Frequency Response Assessment of U.S. Power Grids in High PV Penetration  [ :arrow_down: ](https://arxiv.org/pdf/2101.04054.pdf)
>  Nonsynchronous generations such as photovoltaics (PVs) are expected to undermine bulk power systems (BPSs) frequency response at high penetration levels. Though the underlying mechanism has been relatively well understood, the accurate assessment and effective enhancement of the U.S. interconnections frequency response under extra-high PV penetration conditions remains an issue. In this paper, the industry-provided full-detail interconnection models were further validated by synchrophasor frequency measurements and realistically-projected PV geographic distribution information were used to develop extra-high PV penetration scenarios and dynamic models for the three main U.S. interconnections, including Eastern Interconnection (EI), Western Electricity Coordinating Council (WECC), and Electric Reliability Council of Texas (ERCOT). Up to 65% instantaneous PV and 15% wind penetration were simulated and the frequency response change trend of each U.S. interconnection due to the increasing PV penetration level were examined. Most importantly, the practical solutions to address the declining frequency response were discussed. This paper will provide valuable guidance for policy makers, utility operators and academic researchers not only in the U.S. but also other countries in the world.      
### 2.Optimize the Co-expansion of Generation and Transmission Considering Wind Power in the US Eastern Interconnection  [ :arrow_down: ](https://arxiv.org/pdf/2101.04048.pdf)
>  This paper studies the generation and transmission expansion co-optimization problem with a high wind power penetration rate in large-scale power grids. In this paper, generation and transmission expansion co-optimization is modeled as a mixed-integer programming (MIP) problem. A scenario creation method is proposed to capture the variation and correlation of both load and wind power across regions for large-scale power grids. Obtained scenarios that represent load and wind uncertainties can be easily introduced into the MIP problem and then solved to obtain the co-optimized generation and transmission expansion plan. Simulation results show that the proposed planning model and the scenario creation method can improve the expansion result significantly through modeling more detailed information of wind and load variation among regions in the US EI system. The improved expansion plan that combines generation and transmission will aid system planners and policy makers to maximize the social welfare in large-scale power grids.      
### 3.Covariance Estimation from Compressive Data Partitions using a Projected Gradient-based Algorithm  [ :arrow_down: ](https://arxiv.org/pdf/2101.04027.pdf)
>  Covariance matrix estimation techniques require high acquisition costs that challenge the sampling systems' storing and transmission capabilities. For this reason, various acquisition approaches have been developed to simultaneously sense and compress the relevant information of the signal using random projections. However, estimating the covariance matrix from the random projections is an ill-posed problem that requires further information about the data, such as sparsity, low rank, or stationary behavior. Furthermore, this approach fails using high compression ratios. Therefore, this paper proposes an algorithm based on the projected gradient method to recover a low-rank or Toeplitz approximation of the covariance matrix. The proposed algorithm divides the data into subsets projected onto different subspaces, assuming that each subset contains an approximation of the signal statistics, improving the inverse problem's condition. The error induced by this assumption is analytically derived along with the convergence guarantees of the proposed method. Extensive simulations show that the proposed algorithm can effectively recover the covariance matrix of hyperspectral images with high compression ratios (8-15% approx) in noisy scenarios. Additionally, simulations and theoretical results show that filtering the gradient reduces the estimator's error recovering up to twice the number of eigenvectors.      
### 4.Automatic Polyp Segmentation using Fully Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2101.04001.pdf)
>  Colorectal cancer is one of fatal cancer worldwide. Colonoscopy is the standard treatment for examination, localization, and removal of colorectal polyps. However, it has been shown that the miss-rate of colorectal polyps during colonoscopy is between 6 to 27%. The use of an automated, accurate, and real-time polyp segmentation during colonoscopy examinations can help the clinicians to eliminate missing lesions and prevent further progression of colorectal cancer. The ``Medico automatic polyp segmentation challenge'' provides an opportunity to study polyp segmentation and build a fast segmentation model. The challenge organizers provide a Kvasir-SEG dataset to train the model. Then it is tested on a separate unseen dataset to validate the efficiency and speed of the segmentation model. The experiments demonstrate that the model trained on the Kvasir-SEG dataset and tested on an unseen dataset achieves a dice coefficient of 0.7801, mIoU of 0.6847, recall of 0.8077, and precision of 0.8126, demonstrating the generalization ability of our model. The model has achieved 80.60 FPS on the unseen dataset with an image resolution of $512 \times 512$.      
### 5.Load Embeddings for Scalable AC-OPF Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.03973.pdf)
>  AC Optimal Power Flow (AC-OPF) is a fundamental building block in power system optimization. It is often solved repeatedly, especially in regions with large penetration of renewable generation, to avoid violating operational limits. Recent work has shown that deep learning can be effective in providing highly accurate approximations of AC-OPF. However, deep learning approaches may suffer from scalability issues, especially when applied to large realistic grids. This paper addresses these scalability limitations and proposes a load embedding scheme using a 3-step approach. The first step formulates the load embedding problem as a bilevel optimization model that can be solved using a penalty method. The second step learns the encoding optimization to quickly produce load embeddings for new OPF instances. The third step is a deep learning model that uses load embeddings to produce accurate AC-OPF approximations. The approach is evaluated experimentally on large-scale test cases from the NESTA library. The results demonstrate that the proposed approach produces an order of magnitude improvements in training convergence and prediction accuracy.      
### 6.A generalized efficiency mismatch attack to bypass detection-scrambling countermeasure  [ :arrow_down: ](https://arxiv.org/pdf/2101.03969.pdf)
>  The ability of an eavesdropper to compromise the security of a quantum communication system by changing the angle of the incoming light is well-known. Randomizing the role of the detectors has been proposed to be an efficient countermeasure to this type of attack. Here we show that the proposed countermeasure can be bypassed if the attack is generalized by including more attack variables. Using the experimental data from existing literature, we show how randomization effectively prevents the initial attack but fails to do so when Eve generalizes her attack strategy. Our result and methodology could be used to security-certify a free-space quantum communication receiver against all types of detector-efficiency-mismatch type attacks.      
### 7.Audiovisual Saliency Prediction in Uncategorized Video Sequences based on Audio-Video Correlation  [ :arrow_down: ](https://arxiv.org/pdf/2101.03966.pdf)
>  Substantial research has been done in saliency modeling to develop intelligent machines that can perceive and interpret their surroundings. But existing models treat videos as merely image sequences excluding any audio information, unable to cope with inherently varying content. Based on the hypothesis that an audiovisual saliency model will be an improvement over traditional saliency models for natural uncategorized videos, this work aims to provide a generic audio/video saliency model augmenting a visual saliency map with an audio saliency map computed by synchronizing low-level audio and visual features. The proposed model was evaluated using different criteria against eye fixations data for a publicly available DIEM video dataset. The results show that the model outperformed two state-of-the-art visual saliency models.      
### 8.Super-Resolution Time-Resolved Imaging using Computational Sensor Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2101.03949.pdf)
>  Imaging across both the full transverse spatial and temporal dimensions of a scene with high precision in all three coordinates is key to applications ranging from LIDAR to fluorescence lifetime imaging. However, compromises that sacrifice, for example, spatial resolution at the expense of temporal resolution are often required, in particular when the full 3-dimensional data cube is required in short acquisition times. We introduce a sensor fusion approach that combines data having low-spatial resolution but high temporal precision gathered with a single-photon-avalanche-diode (SPAD) array with set of data that has high spatial but no temporal resolution, such as that acquired with a standard CMOS camera. Our method, based on blurring the image on the SPAD array and computational sensor fusion, reconstructs time-resolved images at significantly higher spatial resolution than the SPAD input, upsampling numerical data by a factor 12x12, and demonstrating up to 4x4 upsampling of experimental data. We demonstrate the technique for both LIDAR applications and FLIM of fluorescent cancer cells. This technique paves the way to high spatial resolution SPAD imaging or, equivalently, FLIM imaging with conventional microscopes at frame rates accelerated by more than an order of magnitude.      
### 9.Nonlinearity Compensation and Link Margin Analysis of 112-Gbps Circular-Polarization Division Multiplexed Fiber Optic Communication System using a Digital Coherent Receiver over 800-km SSMF Link  [ :arrow_down: ](https://arxiv.org/pdf/2101.03942.pdf)
>  Nonlinear effects have been considered as the major limitations in coherent optical (CO) fiber transmission system. DSP based CO receiver with digital backpropagation (DBP) method has recently facilitated the compensation of fiber nonlinear impairments as well as compensating dispersion of optical fiber. In this paper, a comprehensive design is presented for circular-polarization division multiplexed (CPDM) 8-quadrature amplitude modulation (8-QAM) with DSP based CO receiver for the fiber optic communication (FOC) system to investigate the impact of nonlinearities. We have examined the performance of nonlinearity compensating DSP based CO receiver with DBP method and demonstrated that it can be effectively employed to mitigate the intrachannel nonlinearities in CPDM 8-QAM FOC system over 800-km SSMF link. By effectively compensating the fiber nonlinearities, we analyze the performance of bit error rate (BER), optical signal to noise ratio (OSNR), optimum launch power, and investigate the link margin by evaluating OSNR margin for a specific launch power. Moreover, a CPDM technique helps as a very suitable means of maximizing the link capacity as well as enhancing the spectral-efficiency (SE) of the FOC system.      
### 10.Deep Joint Source Channel Coding for WirelessImage Transmission with OFDM  [ :arrow_down: ](https://arxiv.org/pdf/2101.03909.pdf)
>  We present a deep learning based joint source channel coding (JSCC) scheme for wireless image transmission over multipath fading channels with non-linear signal clipping. The proposed encoder and decoder use convolutional neural networks (CNN) and directly map the source images to complex-valued baseband samples for orthogonal frequency division multiplexing (OFDM) transmission. The proposed model-driven machine learning approach eliminates the need for separate source and channel coding while integrating an OFDM datapath to cope with multipath fading channels. The end-to-end JSCC communication system combines trainable CNN layers with non-trainable but differentiable layers representing the multipath channel model and OFDM signal processing blocks. Our results show that injecting domain expert knowledge by incorporating OFDM baseband processing blocks into the machine learning framework significantly enhances the overall performance compared to an unstructured CNN. Our method outperforms conventional schemes that employ state-of-the-art but separate source and channel coding such as BPG and LDPC with OFDM. Moreover, our method is shown to be robust against non-linear signal clipping in OFDM for various channel conditions that do not match the model parameter used during the training.      
### 11.Identification of 27 cardiac abnormalities from multi-lead ECG signals: An ensembled Se-ResNet framework with Sign Loss function  [ :arrow_down: ](https://arxiv.org/pdf/2101.03895.pdf)
>  Cardiovascular disease is a major threat to health and one of the primary causes of death globally, where the cardiac abnormality is the most common type of cardiovascular disease. The early and accurate diagnosis of cardiac abnormalities will allow early treatment and intervention to prevent further progression of the disease. In accordance with the PhysioNet/Computing in Cardiology Challenge 2020, our objective is to develop an algorithm that automatically identifies 27 types of cardiac abnormality from 12-lead ECG recordings. We proposed an accurate and robust predictive framework that combines both deep neural networks and rule-based models to automatically classify multiple cardiac abnormalities. Our framework is able to identify 27 types of cardiac abnormalities presented in 12-lead ECG data. And our proposed Sign Loss makes the framework able to tackle the imbalanced dataset. Meanwhile, our framework was trained and verified on 6 datasets from different countries, and our proposed multi-source preprocessing methods are able to reduce the discrepancies of ECG datasets from different sources.      
### 12.A Comprehensive Survey of 6G Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.03889.pdf)
>  While fifth-generation (5G) communications are being rolled out worldwide, sixth-generation (6G) communications have attracted much attention from both the industry and the academia. Compared with 5G, 6G will have a wider frequency band, higher transmission rate, spectrum efficiency, greater connection capacity, shorter delay, wider coverage, and stronger anti-interference capability to satisfy various network requirements. In this paper, we present a survey of potential essential technologies in 6G. In particular, we will give an insightful understanding of the paradigms and applications of the future 6G wireless communications by introducing index modulation (IM), artificial intelligence (AI), intelligent reflecting surfaces (IRS), simultaneous wireless information and power transfer (SWIPT), space-air-ground-sea integrated network (SAGSIN), terahertz (THz), visible light communications (VLC), blockchain-enabled wireless network, holographic radio, full-duplex technology (FD), Cell-Free Massive MIMO (CFmMM), and security and privacy problems behind technologies mentioned above.      
### 13.FPGA prototyping of synchronized chaotic map for UAV secure communication  [ :arrow_down: ](https://arxiv.org/pdf/2101.03880.pdf)
>  We propose a design that uses the principle of chaos for UAV secure communication. A UAV identified as an aerial base station communicates with a ground base station over an RF channel. The communication units have dynamics based on the logistic map. The map is chaotic in the appropriate parameter space. Its states are non-periodic, broadband, and noise-like in the frequency domain. They are useful for spreading information during transmission, making it difficult for an eavesdropper to recover the modulated message since state prediction is ultimately impossible. To retrieve it, we propose a variable feedback controller. It asymptotically stabilizes the error dynamics when the information source is off. During transmission, the controller synchronizes the units such that the error contains signatures of the information signal. Therefore, the information signal is retrievable by a suitable detection mechanism. Security depends on the confidentiality of the map, the variable feedback controller, including its scale factor and bounded feedback gain, and the designer`s choice of invertible function for use in the scrambling and descrambling process. Also, the method is less prone to jamming attacks and multipath effects as the broadband spectrum can be used to randomly select RF channels. It uses only a few simple algorithms, including a correlation summation and a detection mechanism. The algorithms collect subsamples of the received signal sequences and averages over each subsample length. The method requires minimal programming efforts and low hardware resource utilization. It is energy-efficient, which is a vital consideration for any UAV security model. Moreover, we realize a prototype of the communication system on field-programmable gate arrays. We presented a digital design of the secure communication system involving the transmission of bitstreams between the ABS and GBS.      
### 14.Privacy-Preserving Transactive Energy Management for IoT-aided Smart Homes via Blockchain  [ :arrow_down: ](https://arxiv.org/pdf/2101.03840.pdf)
>  With the booming of smart grid, The ubiquitously deployed smart meters constitutes an energy internet of things. This paper develops a novel blockchain-based transactive energy management system for IoT-aided smart homes. We consider a holistic set of options for smart homes to participate in transactive energy. Smart homes can interact with the grid to perform vertical transactions, e.g., feeding in extra solar energy to the grid and providing demand response service to alleviate the grid load. Smart homes can also interact with peer users to perform horizontal transactions, e.g., peer-to-peer energy trading. However, conventional transactive energy management method suffers from the drawbacks of low efficiency, privacy leakage, and single-point failure. To address these challenges, we develop a privacy-preserving distributed algorithm that enables users to optimally manage their energy usages in parallel via the smart contract on the blockchain. Further, we design an efficient blockchain system tailored for IoT devices and develop the smart contract to support the holistic transactive energy management system. Finally, we evaluate the feasibility and performance of the blockchain-based transactive energy management system through extensive simulations and experiments. The results show that the blockchain-based transactive energy management system is feasible on practical IoT devices and reduces the overall cost by 25%.      
### 15.On the Search for Equilibrium Points of Switched Affine Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.03825.pdf)
>  One of the main aspects of switched affine systems that makes their stabilizability study intricate is the existence of (generally) infinitely many equilibrium points in the state space. Thus, prior to designing the switched control, the user must specify one of these equilibrium points to be the goal or reference. This can be a cumbersome task, especially if this goal is partially given or only defined as a set of constraints. To tackle this issue, in this paper we describe algorithms that can determine whether a given goal is an equilibrium point of the system and also jointly search for equilibrium points and design globally stabilizing switching functions.      
### 16.Analysis of skin lesion images with deep learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.03814.pdf)
>  Skin cancer is the most common cancer worldwide, with melanoma being the deadliest form. Dermoscopy is a skin imaging modality that has shown an improvement in the diagnosis of skin cancer compared to visual examination without support. We evaluate the current state of the art in the classification of dermoscopic images based on the ISIC-2019 Challenge for the classification of skin lesions and current literature. Various deep neural network architectures pre-trained on the ImageNet data set are adapted to a combined training data set comprised of publicly available dermoscopic and clinical images of skin lesions using transfer learning and model fine-tuning. The performance and applicability of these models for the detection of eight classes of skin lesions are examined. Real-time data augmentation, which uses random rotation, translation, shear, and zoom within specified bounds is used to increase the number of available training samples. Model predictions are multiplied by inverse class frequencies and normalized to better approximate actual probability distributions. Overall prediction accuracy is further increased by using the arithmetic mean of the predictions of several independently trained models. The best single model has been published as a web service.      
### 17.ITS and Real Time Cross Border Logistic Operations Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2101.03803.pdf)
>  Moving parcels from origin to destination should not require a lot of re-planning. However, the vast number of shipments and destinations, which need to be re-aligned in real-time due to various external factors makes the delivery process a complex issue to tackle. Anticipating the impact of external factors though can provide more robust logistic plans which are resilient to changes. The work described in this paper, was carried out in the EU-funded COG-LO project and addresses the issue of parcel delivery across the road network making use of context-awareness information as an input for the optimization operations. A positive impact derived from the implementation of these services is expected due to complex event detection, context awareness and decision support at both local and global level of logistics operations.      
### 18.Diagnosis of Intelligent Reflecting Surface in Millimeter-wave Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.03792.pdf)
>  Intelligent reflecting surface (IRS) is a promising technology for enhancing wireless communication systems, which adaptively configures massive passive reflecting elements to control wireless channel in a desirable way. Due to hardware characteristics and deploying environments, the IRS may be subject to reflecting element blockages and failures, and hence developing diagnostic techniques is of great significance to system monitoring and maintenance. In this paper, we develop diagnostic techniques for IRS systems to locate faulty reflecting elements and retrieve failure parameters. Three cases of the channel state information (CSI) availability are considered. In the first case where full CSI is available, a compressed sensing based diagnostic technique is proposed, which significantly reduces the required number of measurements. In the second case where only partial CSI is available, we jointly exploit the sparsity of the millimeter-wave channel and the failure, and adopt compressed sparse and low-rank matrix recovery algorithm to decouple channel and failure. In the third case where no CSI is available, a novel atomic norm is introduced as the sparsity-inducing norm of the cascaded channel, and the diagnosis problem is formulated as a joint sparse recovery problem. Finally, proposed diagnostic techniques are validated through numerical simulations.      
### 19.Optimized Multi-Level Prime Array Configurations  [ :arrow_down: ](https://arxiv.org/pdf/2101.03714.pdf)
>  Antenna arrays have many applications in direction-of-arrival (DOA) estimation. Sparse arrays such as nested arrays, super nested arrays, and coprime arrays have large degrees of freedom (DOFs). They can estimate large number of sources greater than the number of elements. They also have closed form expressions for antenna locations and the achievable DOFs. The multi-level prime array (MLPA) uses multiple uniform linear subarrays where the number of elements in the subarrays are pairwise coprime integers. The array achieves large DOFs and it has closed form expressions for the antenna locations and the required aperture size. For a given number of subarrays and total number of elements, there are different design alternatives. This paper finds the optimum number of elements within each subarray and the optimized ordered inter-element spacing. In almost all cases, we have found that a unique configuration jointly realizes the maximum number of unique lags and the maximum number of consecutive lags.      
### 20.Generalize Ultrasound Image Segmentation via Instant and Plug &amp; Play Style Transfer  [ :arrow_down: ](https://arxiv.org/pdf/2101.03711.pdf)
>  Deep segmentation models that generalize to images with unknown appearance are important for real-world medical image analysis. Retraining models leads to high latency and complex pipelines, which are impractical in clinical settings. The situation becomes more severe for ultrasound image analysis because of their large appearance shifts. In this paper, we propose a novel method for robust segmentation under unknown appearance shifts. Our contribution is three-fold. First, we advance a one-stage plug-and-play solution by embedding hierarchical style transfer units into a segmentation architecture. Our solution can remove appearance shifts and perform segmentation simultaneously. Second, we adopt Dynamic Instance Normalization to conduct precise and dynamic style transfer in a learnable manner, rather than previously fixed style normalization. Third, our solution is fast and lightweight for routine clinical adoption. Given 400*400 image input, our solution only needs an additional 0.2ms and 1.92M FLOPs to handle appearance shifts compared to the baseline pipeline. Extensive experiments are conducted on a large dataset from three vendors demonstrate our proposed method enhances the robustness of deep segmentation models.      
### 21.Online Learning of Interconnected Neural Networks for Optimal Control of an HVAC System  [ :arrow_down: ](https://arxiv.org/pdf/2101.03653.pdf)
>  Optimizing the operation of heating, ventilation, and air-conditioning (HVAC) systems is a challenging task, requiring the modeling of complex nonlinear relationships among HVAC load, indoor temperatures, and outdoor environments. This paper proposes a new strategy for optimal operation of an HVAC system in a commercial building. The system for indoor temperature control is divided into three sub-systems, each of which is modeled using an artificial neural network (ANN). The ANNs are then interconnected and integrated into an optimization problem for temperature set-point scheduling. The problem is reformulated to determine the optimal set-points using a deterministic search algorithm. After the optimal scheduling is initiated, the ANNs undergo online learning repeatedly, mitigating the overfitting. Case studies are performed to analyze the performance of the proposed strategy, compared to the strategies with a pre-determined temperature set-point, an ideal physics-based building model, and conventional ANN-based building models. The case study results confirm that the proposed strategy is effective in terms of the HVAC energy cost, practical applicability, and training data requirement.      
### 22.Learning Rotation Invariant Features for Cryogenic Electron Microscopy Image Reconstruction  [ :arrow_down: ](https://arxiv.org/pdf/2101.03549.pdf)
>  Cryo-Electron Microscopy (Cryo-EM) is a Nobel prize-winning technology for determining the 3D structure of particles at near-atomic resolution. A fundamental step in the recovering of the 3D single-particle structure is to align its 2D projections; thus, the construction of a canonical representation with a fixed rotation angle is required. Most approaches use discrete clustering which fails to capture the continuous nature of image rotation, others suffer from low-quality image reconstruction. We propose a novel method that leverages the recent development in the generative adversarial networks. We introduce an encoder-decoder with a rotation angle classifier. In addition, we utilize a discriminator on the decoder output to minimize the reconstruction error. We demonstrate our approach with the Cryo-EM 5HDB and the rotated MNIST datasets showing substantial improvement over recent methods.      
### 23.Channel Modeling and Signal Processing for Array-based Visible Light Communication System in Misalignment  [ :arrow_down: ](https://arxiv.org/pdf/2101.03548.pdf)
>  This paper proposes an indoor visible light communication (VLC) system with multiple transmitters and receivers. Due to diffusivity of LED light beams, photodiode receive signals from many directions. We use one concave and one convex lens as optical antenna, and obtain the optimal lens structure by optimizing which corresponds to the minimum condition number of channel gain matrix. In this way the light emitted by different LED can be separated well from each other then minimize signal interference. However, interference increases in the case of system deviation, so we explore the system mobility. Then subsequent signal processing is carried out, including signal combining and successive interference cancellation (SIC). We combine the same signal received by different receivers to improve signal to interference noise ratio (SINR). And SIC can effectively restore interference and eliminate its impact. The simulation results show that channel capacity can be increased by more than 5 times and up to 20 times under the condition of receiver and transmitter alignment. In the case of movement, channel capacity can also be increased by about 4 times on average. Moreover, the mobile range of system is also significantly expanded.      
### 24.Deep Ensemble Learning-based Approach to Real-time Power System State Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2101.03457.pdf)
>  Power system state estimation (PSSE) is commonly formulated as weighted least-square (WLS) algorithm and solved using iterative methods such as Gauss-Newton methods. However, iterative methods have become more sensitive to system operating conditions than ever before due to the deployment of intermittent renewable energy sources, low carbon technologies (e.g., electric vehicles), and demand response programs. Appropriate PSSE approaches are required to avoid pitfalls of the WLS-based PSSE computations for accurate prediction of operating conditions. This paper proposes a data-driven real-time PSSE using a deep ensemble learning algorithm. In the proposed approach, the ensemble learning setup is formulated with dense residual neural networks as base-learners and multivariate-linear regressor as meta-learner. Historical measurements and states are utilised to train and test the model. The trained model can be used in real-time to estimate power system states (voltage magnitudes and phase angles) using real-time measurements. Most of current data-driven PSSE methods assume the availability of a complete set of measurements, which may not be the case in real power system data-acquisition. This paper adopts multivariate linear regression to forecast system states for instants of missing measurements to assist the proposed PSSE technique. Case studies are performed on various IEEE standard benchmark systems to validate the proposed approach. The results show that the proposed approach outperforms existing data-driven PSSE methods techniques.      
### 25.DeepFilter: an ECG baseline wander removal filter using deep learning techniques  [ :arrow_down: ](https://arxiv.org/pdf/2101.03423.pdf)
>  According to the World Health Organization, around 36% of the annual deaths are associated with cardiovascular diseases and 90% of heart attacks are preventable. Electrocardiogram signal analysis in ambulatory electrocardiography, during an exercise stress test, and in resting conditions allows cardiovascular disease diagnosis. However, during the acquisition, there is a variety of noises that may damage the signal quality thereby compromising their diagnostic potential. The baseline wander is one of the most undesirable noises. In this work, we propose a novel algorithm for BLW noise filtering using deep learning techniques. The model performance was validated using the QT Database and the MIT-BIH Noise Stress Test Database from Physionet. In addition, several comparative experiments were performed against state-of-the-art methods using traditional filtering procedures as well as deep learning techniques. The proposed approach yields the best results on four similarity metrics: the sum of squared distance, maximum absolute square, percentage of root distance, and cosine similarity with 4.29 (6.35) au, 0.34 (0.25) au, 45.35 (29.69) au and, 91.46 (8.61) au, respectively. The source code of this work, containing our method and related implementations, is freely available on Github.      
### 26.Equalized Recovery State Estimators for Linear Systems with Delayed and Missing Observations  [ :arrow_down: ](https://arxiv.org/pdf/2101.03389.pdf)
>  This paper presents a dynamic state observer design for discrete-time linear time-varying systems that robustly achieves equalized recovery despite delayed or missing observations, where the set of all temporal patterns for the missing or delayed data is modeled by a finite-length language. By introducing a mapping of the language onto a reduced event-based language, we design a state estimator that adapts based on the history of available data at each step, and satisfies equalized recovery for all patterns in the reduced language. In contrast to existing equalized recovery estimators, the proposed design considers the equalized recovery level as a decision variable, which enables us to directly obtain the global minimum for the intermediate recovery level, resulting in improved estimation performance. Finally, we demonstrate the effectiveness of the proposed observer when compared to existing approaches using several illustrative examples.      
### 27.On the Implementation Complexity of Digital Full-Duplex Self-Interference Cancellation  [ :arrow_down: ](https://arxiv.org/pdf/2101.03380.pdf)
>  In-band full-duplex systems promise to further increase the throughput of wireless systems, by simultaneously transmitting and receiving on the same frequency band. However, concurrent transmission generates a strong self-interference signal at the receiver, which requires the use of cancellation techniques. A wide range of techniques for analog and digital self-interference cancellation have already been presented in the literature. However, their evaluation focuses on cases where the underlying physical parameters of the full-duplex system do not vary significantly. In this paper, we focus on adaptive digital cancellation, motivated by the fact that physical systems change over time. We examine some of the different cancellation methods in terms of their performance and implementation complexity, considering the cost of both cancellation and training. We then present a comparative analysis of all these methods to determine which perform better under different system performance requirements. We demonstrate that with a neural network approach, the reduction in arithmetic complexity for the same cancellation performance relative to a state-of-the-art polynomial model is several orders of magnitude.      
### 28.Integrating a joint Bayesian generative model in a discriminative learning framework for speaker verification  [ :arrow_down: ](https://arxiv.org/pdf/2101.03329.pdf)
>  The task for speaker verification (SV) is to decide an utterance is spoken by a target or imposter speaker. In most SV studies, a log-likelihood ratio (L_LLR) score is estimated based on a generative probability model on speaker features, and compared with a threshold for decision making. However, the generative model usually focuses on feature distributions and does not have the discriminative feature selection ability, which is easy to be distracted by nuisance features. The SV, as a hypothesis test, could be formulated as a binary classification task where a neural network (NN) based discriminative learning could be applied. Through discriminative learning, the nuisance features could be removed with the help of label supervision. However, the discriminative learning pays more attention to classification boundaries which is prone to overfitting to training data and yielding poor generalization on testing data. In this paper, we propose a hybrid learning framework, i.e., integrating a joint Bayesian (JB) generative model into a neural discriminative learning framework for SV. A Siamese NN is built with dense layers to approximate the mapping functions used in the SV pipeline with the JB model, and the L-LLR score estimated based on the JB model is connected to the distance metric in a pair-wised discriminative learning. By initializing the Siamese NN with the parameters learned from the JB model, we further train the model parameters with the pair-wised samples as a binary discrimination task. Moreover, direct evaluation metric in SV, i.e., minimum empirical Bayes risk, is designed and integrated as an objective function in the discriminative learning. We carried out SV experiments on speakers in the wild (SITW) and Voxceleb corpora. Experimental results showed that our proposed model improved the performance with a large margin compared with state-of-the-art models for SV.      
### 29.Channel Estimation for IRS-aided Multiuser Communications with Reduced Error Propagation  [ :arrow_down: ](https://arxiv.org/pdf/2101.03314.pdf)
>  Intelligent reflecting surface (IRS) has emerged as a promising paradigm to improve the capacity and reliability of a wireless communication system by smartly reconfiguring the wireless propagation environment. To achieve the promising gains of IRS, the acquisition of the channel state information (CSI) is essential, which however is practically difficult since the IRS does not employ any transmit/receive radio frequency (RF) chains in general and it has limited signal processing capability. In this paper, we study the uplink channel estimation problem for an IRS-aided multiuser single-input multi-output (SIMO) system, and propose a novel two-phase channel estimation (2PCE) strategy which can alleviate the negative effects caused by error propagation in the existing three-phase channel estimation approach, i.e., the channel estimation errors in previous phases will deteriorate the estimation performance in later phases, and enhance the channel estimation performance with the same amount of channel training overhead as in the existing approach. Moreover, the asymptotic mean squared error (MSE) of the 2PCE strategy is analyzed when the least-square (LS) channel estimation method is employed, and we show that the 2PCE strategy can outperform the existing approach. Finally, extensive simulation results are presented to validate the effectiveness of the 2PCE strategy.      
### 30.An Ultra Fast Low Power Convolutional Neural Network Image Sensor with Pixel-level Computing  [ :arrow_down: ](https://arxiv.org/pdf/2101.03308.pdf)
>  The separation of the data capture and analysis in modern vision systems has led to a massive amount of data transfer between the end devices and cloud computers, resulting in long latency, slow response, and high power consumption. Efficient hardware architectures are under focused development to enable Artificial Intelligence (AI) at the resource-limited end sensing devices. This paper proposes a Processing-In-Pixel (PIP) CMOS sensor architecture, which allows convolution operation before the column readout circuit to significantly improve the image reading speed with much lower power consumption. The simulation results show that the proposed architecture enables convolution operation (kernel size=3*3, stride=2, input channel=3, output channel=64) in a 1080P image sensor array with only 22.62 mW power consumption. In other words, the computational efficiency is 4.75 TOPS/w, which is about 3.6 times as higher as the state-of-the-art.      
### 31.Quantization optimized with respect to the Haar basis  [ :arrow_down: ](https://arxiv.org/pdf/2101.03304.pdf)
>  We propose a method of data quantization of finite discrete-time signals which optimizes the error estimate of low frequency Haar coefficients. We also discuss the error/noise bounds of this quantization in the Fourier space. Our result shows one can quantize any discrete-time analog signal with high precision at low frequencies. Our method is deterministic, and it employs no statistical arguments, nor any probabilistic assumptions.      
### 32.Incentive Design and Profit Sharing in Multi-modal Transportation Network  [ :arrow_down: ](https://arxiv.org/pdf/2101.03297.pdf)
>  We consider the situation where multiple transportation service providers cooperate to offer an integrated multi-modal platform to enhance the convenience to the passengers through ease in multi-modal journey planning, payment, and first and last mile connectivity. This market structure allows the multi-modal platform to coordinate profits across modes and also provide incentives to the passengers. Accordingly, in this paper, we use cooperative game theory coupled with the hyperpath-based stochastic user equilibrium framework to study such a market. We assume that the platform sets incentive (subsidy or tax) along every edge in the transportation network. We derive the continuity and monotonicity properties of the equilibrium flow with respect to the incentives along every edge. The optimal incentives that maximize the profit of the platform are obtained through a two time-scale stochastic approximation algorithm. We use the asymmetric Nash bargaining solution to design a fair profit sharing scheme among the service providers. We show that the profit for each service provider increases after cooperation on such a platform. We complement the theoretical results through two numerical simulations.      
### 33.End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effect of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2101.03244.pdf)
>  We present a novel multi-stage 3D computer-aided detection and diagnosis (CAD) model for automated localization of clinically significant prostate cancer (csPCa) in bi-parametric MR imaging (bpMRI). State-of-the-art attention mechanisms drive its detection network, which aims to accurately discriminate csPCa lesions from indolent cancer and the wide range of benign pathology that can afflict the prostate gland. In parallel, a decoupled residual classifier is used to achieve consistent false positive reduction, without sacrificing high detection sensitivity or computational efficiency. Furthermore, a probabilistic anatomical prior, which captures the spatial prevalence of csPCa and its zonal distinction, is computed and encoded into the CNN architecture to guide model generalization with domain-specific clinical knowledge. <br>For 486 institutional testing scans, the 3D CAD system achieves $83.69\pm5.22\%$ and $93.19\pm2.96\%$ detection sensitivity at 0.50 and 1.46 false positive(s) per patient, respectively, along with $0.882$ AUROC in patient-based diagnosis $-$significantly outperforming four baseline architectures (USEResNet, UNet++, nnU-Net, Attention U-Net). For 296 external testing scans, the ensembled CAD system shares moderate agreement with a consensus of expert radiologists ($76.69\%$; $kappa=0.511$) and independent pathologists ($81.08\%$; $kappa=0.559$); demonstrating a strong ability to localize histologically-confirmed malignancies and generalize beyond the radiologically-estimated annotations of the 1950 training-validation cases used in this study.      
### 34.Remote Pulse Estimation in the Presence of Face Masks  [ :arrow_down: ](https://arxiv.org/pdf/2101.04096.pdf)
>  Remote photoplethysmography (rPPG) is a known family of techniques for monitoring blood volume changes from a camera. It may be especially useful for widespread contact-less health monitoring when used to analyze face video from consumer-grade visible-light cameras. The COVID-19 pandemic has caused the widespread use of protective face masks to prevent virus transmission. We found that occlusions from face masks affect face video-based rPPG as the mean absolute error of blood volume estimation is nearly doubled when the face is partially occluded by protective masks. To our knowledge, this paper is the first to analyse the impact of face masks on the accuracy of blood volume pulse estimation and offers several novel elements: (a) two publicly available pulse estimation datasets acquired from 86 unmasked and 61 masked subjects, (b) evaluations of handcrafted algorithms and a 3D convolutional neural network trained on videos of full (unmasked) faces and synthetically generated masks, and (c) data augmentation method (a generator adding a synthetic mask to a face video). Our findings help identify how face masks degrade accuracy of face video analysis, and we discuss paths toward more robust pulse estimation in their presence. The datasets and source codes of all proposed methods are available along with this paper.      
### 35.Hardware-efficient megapixel per second coherent soliton microcomb ranging  [ :arrow_down: ](https://arxiv.org/pdf/2101.03952.pdf)
>  Laser based ranging (LiDAR) - already ubiquitously used in robotics, industrial monitoring, or geodesy - is a key sensor technology for future autonomous driving, and has been employed in nearly all successful implementations of autonomous vehicles to date. Coherent laser allows long-range detection, operates eye safe, is immune to crosstalk and yields simultaneous velocity and distance information. Yet for actual deployment in vehicles, video frame-rate requirements for object detection, classification and sensor fusion mandate megapixel per second measurement speed. Such pixel rates are not possible to attain with current coherent single laser-detector architectures at high definition range imagining, and make parallelization essential. A megapixel class coherent LiDAR has not been demonstrated, and is still impeded by the arduous requirements of large banks of detectors and digitizers on the receiver side, that need to be integrated on chip. Here we report hardware efficient coherent laser ranging at megapixel per second imaging rates. This is achieved using a novel concept for massively parallel coherent laser ranging that requires only a single laser and a single photoreceiver, yet achieves simultaneous recording of more than 64 channels with distance and velocity measurements each - attaining an unprecedented 5 megapixel per second rate. Heterodyning two offset chirped soliton microcombs on a single coherent receiver yields an interferogram containing both distance and velocity information of all particular channels, thereby alleviating the need to individually separate, detect and digitize distinct channels. The reported LiDAR implementation is hardware-efficient, compatible with photonic integration and demonstrates the significant advantages of acquisition speed, complexity and cost benefits afforded by the convergence of optical telecommunication and metrology technologies.      
### 36.Cycle Generative Adversarial Networks Algorithm With Style Transfer For Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2101.03921.pdf)
>  The biggest challenge faced by a Machine Learning Engineer is the lack of data they have, especially for 2-dimensional images. The image is processed to be trained into a Machine Learning model so that it can recognize patterns in the data and provide predictions. This research is intended to create a solution using the Cycle Generative Adversarial Networks (GANs) algorithm in overcoming the problem of lack of data. Then use Style Transfer to be able to generate a new image based on the given style. Based on the results of testing the resulting model has been carried out several improvements, previously the loss value of the photo generator: 3.1267, monet style generator: 3.2026, photo discriminator: 0.6325, and monet style discriminator: 0.6931 to photo generator: 2.3792, monet style generator: 2.7291, photo discriminator: 0.5956, and monet style discriminator: 0.4940. It is hoped that the research will make the application of this solution useful in the fields of Education, Arts, Information Technology, Medicine, Astronomy, Automotive and other important fields.      
### 37.On Interfacing the Brain with Quantum Computers: An Approach to Listen to the Logic of the Mind  [ :arrow_down: ](https://arxiv.org/pdf/2101.03887.pdf)
>  This chapter presents a quantum computing-based approach to study and harness neuronal correlates of mental activity for the development of Brain-Computer Interface (BCI) systems. It introduces the notion of a logic of the mind, where neurophysiological data are encoded as logical expressions representing mental activity. Effective logical expressions are likely to be extensive, involving dozens of variables. Large expressions require considerable computational power to be processed. This is problematic for BCI applications because they require fast reaction times to execute sequences of commands. Quantum computers hold much promise in terms of processing speed for some problems, including those involving logical expressions. Hence, we propose to use quantum computers to process the logic of the mind. The chapter begins with an introduction to BCI and the electroencephalogram, which is the neurophysiological signal that is normally used in BCI. Then, it briefly discusses how the EEG corresponds to mental states, followed by an introduction to the logic of the mind. After that, there is an overview of quantum computing, focusing on the basics deemed necessary to understand how it processes logical expressions. An example of a BCI system is presented. In a nutshell, the system reads the EEG and builds logical expressions, which are sent to a quantum computer to solve them. In turn, the system converts the results into sounds by means of a bespoke synthesiser. Essentially, the BCI here is a musical instrument controlled by the mind of the player. Our BCI is a proof-of-concept aimed at demonstrating how quantum computing may support the development of sophisticated BCI systems. The remaining of the chapter is devoted to technical and practical considerations on the limitations of current quantum computing hardware technology and scalability of the system.      
### 38.Transient Stability Analysis of Power Grids with Admissible and Maximal Robust Positively Invariant Sets  [ :arrow_down: ](https://arxiv.org/pdf/2101.03882.pdf)
>  The energy transition is causing many stability-related challenges for power systems. Transient stability refers to the ability of a power grid's bus angles to retain synchronism after the occurrence of a major fault. In this paper a set-based approach is presented to assess the transient stability of power systems. The approach is based on the theory of barriers, to obtain an exact description of the boundaries of admissible sets and maximal robust positively invariant sets, respectively. We decompose a power system into generator and load components, replace couplings with bounded disturbances and obtain the sets for each component separately. From this we deduce transient stability properties for the entire system. We demonstrate the results of our approach through an example of one machine connected to one load and a multi-machine system.      
### 39.The Degraded Discrete-Time Poisson Wiretap Channel  [ :arrow_down: ](https://arxiv.org/pdf/2101.03650.pdf)
>  This paper addresses the degraded discrete-time Poisson wiretap channel (DT--PWC) in an optical wireless communication system based on intensity modulation and direct detection. Subject to nonnegativity, peak- and average-intensity as well as bandwidth constraints, we study the secrecy-capacity-achieving input distribution of this wiretap channel and prove it to be unique and discrete with a finite number of mass points; one of them located at the origin. Furthermore, we establish that every point on the boundary of the rate-equivocation region of this wiretap channel is also obtained by a unique and discrete input distribution with finitely many mass points. In general, the number of mass points of the optimal distributions is greater than two. This is in contrast with the degraded continuous-time PWC when the signaling bandwidth is not restricted and where the secrecy capacity and the entire boundary of the rate-equivocation region are achieved by binary distributions. Furthermore, we extend our analysis to the case where only an average-intensity constraint is active. For this case, we find that the secrecy capacity and the entire boundary of the rate-equivocation region are attained by discrete distributions with countably \textit{infinite} number of mass points, but with finitely many mass points in any bounded interval.      
### 40.Confocal super-resolution microscopy based on a spatial mode sorter  [ :arrow_down: ](https://arxiv.org/pdf/2101.03649.pdf)
>  Spatial resolution is one of the most important specifications of an imaging system. Recent results in quantum parameter estimation theory reveal that an arbitrarily small distance between two incoherent point sources can always be efficiently determined through the use of a spatial mode sorter. However, extending this procedure to a general object consisting of many incoherent point sources remains challenging, due to the intrinsic complexity of multi-parameter estimation problems. Here, we generalize the Richardson-Lucy (RL) deconvolution algorithm to address this challenge. We simulate its application to an incoherent confocal microscope, with a Zernike spatial mode sorter replacing the pinhole used in a conventional confocal microscope. We test different spatially incoherent objects of arbitrary geometry, and we find that sorter-based microscopy can achieve more than 5-fold resolution enhancement over a diffraction-limited image. In addition, the resolution enhancement of sorter-based microscopy is on average over 30% higher than that of a conventional confocal microscope using the standard RL deconvolution algorithm. Our method could potentially be used in diverse applications such as fluorescent microscopy and astronomical imaging.      
### 41.Sum-Rate Maximization for UAV-assisted Visible Light Communications using NOMA: Swarm Intelligence meets Machine Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.03498.pdf)
>  As the integration of unmanned aerial vehicles (UAVs) into visible light communications (VLC) can offer many benefits for massive-connectivity applications and services in 5G and beyond, this work considers a UAV-assisted VLC using non-orthogonal multiple-access. More specifically, we formulate a joint problem of power allocation and UAV's placement to maximize the sum rate of all users, subject to constraints on power allocation, quality of service of users, and UAV's position. Since the problem is non-convex and NP-hard in general, it is difficult to be solved optimally. Moreover, the problem is not easy to be solved by conventional approaches, e.g., coordinate descent algorithms, due to channel modeling in VLC. Therefore, we propose using harris hawks optimization (HHO) algorithm to solve the formulated problem and obtain an efficient solution. We then use the HHO algorithm together with artificial neural networks to propose a design which can be used in real-time applications and avoid falling into the "local minima" trap in conventional trainers. Numerical results are provided to verify the effectiveness of the proposed algorithm and further demonstrate that the proposed algorithm/HHO trainer is superior to several alternative schemes and existing metaheuristic algorithms.      
### 42.Reinforcement Learning Enabled Automatic Impedance Control of a Robotic Knee Prosthesis to Mimic the Intact Knee Motion in a Co-Adapting Environment  [ :arrow_down: ](https://arxiv.org/pdf/2101.03487.pdf)
>  Automatically configuring a robotic prosthesis to fit its user's needs and physical conditions is a great technical challenge and a roadblock to the adoption of the technology. Previously, we have successfully developed reinforcement learning (RL) solutions toward addressing this issue. Yet, our designs were based on using a subjectively prescribed target motion profile for the robotic knee during level ground walking. This is not realistic for different users and for different locomotion tasks. In this study for the first time, we investigated the feasibility of RL enabled automatic configuration of impedance parameter settings for a robotic knee to mimic the intact knee motion in a co-adapting environment. We successfully achieved such tracking control by an online policy iteration. We demonstrated our results in both OpenSim simulations and two able-bodied (AB) subjects.      
### 43.Downlink SCMA Codebook Design with Low Error Rate by Maximizing Minimum Euclidean Distance of Superimposed Codewords  [ :arrow_down: ](https://arxiv.org/pdf/2101.03355.pdf)
>  Sparse code multiple access (SCMA), as a codebook-based non-orthogonal multiple access (NOMA) technique, has received research attention in recent years. The codebook design problem for SCMA has also been studied to some extent since codebook choices are highly related to the system's error rate performance. In this paper, we approach the downlink SCMA codebook design problem by formulating an optimization problem to maximize the minimum Euclidean distance (MED) of superimposed codewords under power constraints. While SCMA codebooks with a larger minimum Euclidean distance (MED) are expected to obtain a better BER performance, no optimal SCMA codebook in terms of MED maximization, to the authors' best knowledge, has been reported in the SCMA literature yet. In this paper, a new iterative algorithm based on alternating maximization with exact penalty is proposed for the MED maximization problem. The proposed algorithm, when supplied with appropriate initial points and parameters, achieves a set of codebooks of all users whose MED is larger than any previously reported results. A Lagrange dual problem is derived which provides an upper bound of MED of any set of codebooks. Even though there is still a nonzero gap between the achieved MED and the upper bound given by the dual problem, simulation results demonstrate clear advantages in error rate performances of the proposed set of codebooks over all existing ones. The correctness and accuracy of error curves in the simulation results are further confirmed by the coincidences with the theoretical upper bounds of error rates derived for any given set of codebooks.      
### 44.Drivers' skills and behavior vs. traffic at intersections  [ :arrow_down: ](https://arxiv.org/pdf/2101.03351.pdf)
>  The work is devoted to ways of modeling street traffic on a street layout without traffic lights of an established topology. The behavior of traffic participants takes into account the individual inclinations of drivers to creatively interpret traffic rules. Participant interactions describe game theory models that provide information for simulation algorithms based on cellular automata. Driver diversification comes down to two types often considered in such research: DE(fective)-agent and CO(operative)-agent. Various ways of using the description of traffic participants to examine the impact of behavior on street traffic dynamics were shown. Directions for the further detailed analysis were indicated, which requires basic research in the field of game theory models.      
### 45.Studies on Frequency Response Optimized Integrators Considering Second Order Derivative  [ :arrow_down: ](https://arxiv.org/pdf/2101.03266.pdf)
>  This paper presents comprehensive studies on frequency response optimized integrators considering second order derivative regarding their numerical error, numerical stability and transient performance. Frequency domain error analysis is conducted on these numerical integrators to reveal their accuracy. Numerical stability of the numerical integrators is investigated. Interesting new types of numerical stability are recognized. Transient performance of the numerical integrators is defined to qualitatively characterize their ability to track fast decaying transients. This property is related to unsatisfactory phenomena such as numerical oscillation which frequently appear in time domain simulation of circuits and systems. Transient performance analysis of the numerical integrators is provided. Theoretical observations from the analysis of the numerical integrators are verified via time domain case studies.      
### 46.Adaptive Learning in Two-Player Stackelberg Games with Application to Network Security  [ :arrow_down: ](https://arxiv.org/pdf/2101.03253.pdf)
>  We study a two-player Stackelberg game with incomplete information such that the follower's strategy belongs to a known family of parameterized functions with an unknown parameter vector. We design an adaptive learning approach to simultaneously estimate the unknown parameter and minimize the leader's cost, based on adaptive control techniques and hysteresis switching. Our approach guarantees that the leader's cost predicted using the parameter estimate becomes indistinguishable from its actual cost in finite time, up to a preselected, arbitrarily small error threshold. Also, the first-order necessary condition for optimality holds asymptotically for the predicted cost. Additionally, if a persistent excitation condition holds, then the parameter estimation error becomes bounded by a preselected, arbitrarily small threshold in finite time as well. For the case where there is a mismatch between the follower's strategy and the parameterized function that is known to the leader, our approach is able to guarantee the same convergence results for error thresholds larger than the size of the mismatch. The algorithms and the convergence results are illustrated via a simulation example in the domain of network security.      
### 47.Generation of Traffic Flows in Multi-Agent Traffic Simulation with Agent Behavior Model based on Deep Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.03230.pdf)
>  In multi-agent based traffic simulation, agents are always supposed to move following existing instructions, and mechanically and unnaturally imitate human behavior. The human drivers perform acceleration or deceleration irregularly all the time, which seems unnecessary in some conditions. For letting agents in traffic simulation behave more like humans and recognize other agents' behavior in complex conditions, we propose a unified mechanism for agents learn to decide various accelerations by using deep reinforcement learning based on a combination of regenerated visual images revealing some notable features, and numerical vectors containing some important data such as instantaneous speed. By handling batches of sequential data, agents are enabled to recognize surrounding agents' behavior and decide their own acceleration. In addition, we can generate a traffic flow behaving diversely to simulate the real traffic flow by using an architecture of fully decentralized training and fully centralized execution without violating Markov assumptions.      
### 48.Domain-aware Neural Language Models for Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.03229.pdf)
>  As voice assistants become more ubiquitous, they are increasingly expected to support and perform well on a wide variety of use-cases across different domains. We present a domain-aware rescoring framework suitable for achieving domain-adaptation during second-pass rescoring in production settings. In our framework, we fine-tune a domain-general neural language model on several domains, and use an LSTM-based domain classification model to select the appropriate domain-adapted model to use for second-pass rescoring. This domain-aware rescoring improves the word error rate by up to 2.4% and slot word error rate by up to 4.1% on three individual domains -- shopping, navigation, and music -- compared to domain general rescoring. These improvements are obtained while maintaining accuracy for the general use case.      
### 49.Deep Diffusion Processes for Active Learning of Hyperspectral Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.03197.pdf)
>  A method for active learning of hyperspectral images (HSI) is proposed, which combines deep learning with diffusion processes on graphs. A deep variational autoencoder extracts smoothed, denoised features from a high-dimensional HSI, which are then used to make labeling queries based on graph diffusion processes. The proposed method combines the robust representations of deep learning with the mathematical tractability of diffusion geometry, and leads to strong performance on real HSI.      

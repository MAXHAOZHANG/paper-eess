# ArXiv eess --Tue, 26 Jan 2021
### 1.Channel Estimation via Successive Denoising in MIMO OFDM Systems: A Reinforcement Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2101.10300.pdf)
>  Reliable communication through multiple-input multiple-output (MIMO) orthogonal frequency division multiplexing (OFDM) requires accurate channel estimation. Existing literature largely focuses on denoising methods for channel estimation that are dependent on either (i) channel analysis in the time-domain, and/or (ii) supervised learning techniques, requiring large pre-labeled datasets for training. To address these limitations, we present a frequency-domain denoising method based on the application of a reinforcement learning framework that does not need a priori channel knowledge and pre-labeled data. Our methodology includes a new successive channel denoising process based on channel curvature computation, for which we obtain a channel curvature magnitude threshold to identify unreliable channel estimates. Based on this process, we formulate the denoising mechanism as a Markov decision process, where we define the actions through a geometry-based channel estimation update, and the reward function based on a policy that reduces the MSE. We then resort to Q-learning to update the channel estimates over the time instances. Numerical results verify that our denoising algorithm can successfully mitigate noise in channel estimates. In particular, our algorithm provides a significant improvement over the practical least squares (LS) channel estimation method and provides performance that approaches that of the ideal linear minimum mean square error (LMMSE) with perfect knowledge of channel statistics.      
### 2.Generating Simulation-based Contacts matrices for Disease Transmission Modelling at Special Settings  [ :arrow_down: ](https://arxiv.org/pdf/2101.10224.pdf)
>  Since a significant amount of disease transmission occurs through human-to-human or social contacts, understanding who interacts with whom in time and space is essential for disease transmission modelling, prediction, and assessment of prevention strategies in different environments and special settings. Thus, measuring contact mixing patterns, often in form of contacts matrices has been a key component of heterogeneous disease transmission modelling research. Several data collection techniques estimate or calculate contacts matrices at different geographical scales and population mixes based on surveys and sensors. This paper presents a methodology for generating contacts matrices by using high fidelity simulations which mimic actual workflow and movements of individuals in time and space. Results of this study show that such simulations can be a feasible, flexible, and reasonable alternative method for estimating social contacts and generating contacts mixing matrices for various settings under different conditions.      
### 3.A two-step explainable approach for COVID-19 computer-aided diagnosis from chest x-ray images  [ :arrow_down: ](https://arxiv.org/pdf/2101.10223.pdf)
>  Early screening of patients is a critical issue in order to assess immediate and fast responses against the spread of COVID-19. The use of nasopharyngeal swabs has been considered the most viable approach; however, the result is not immediate or, in the case of fast exams, sufficiently accurate. Using Chest X-Ray (CXR) imaging for early screening potentially provides faster and more accurate response; however, diagnosing COVID from CXRs is hard and we should rely on deep learning support, whose decision process is, on the other hand, "black-boxed" and, for such reason, untrustworthy. We propose an explainable two-step diagnostic approach, where we first detect known pathologies (anomalies) in the lungs, on top of which we diagnose the illness. Our approach achieves promising performance in COVID detection, compatible with expert human radiologists. All of our experiments have been carried out bearing in mind that, especially for clinical applications, explainability plays a major role for building trust in machine learning algorithms.      
### 4.Back-Projection Pipeline  [ :arrow_down: ](https://arxiv.org/pdf/2101.10208.pdf)
>  We propose a simple extension of residual networks that works simultaneously in multiple resolutions. Our network design is inspired by the iterative back-projection algorithm but seeks the more difficult task of learning how to enhance images. Compared to similar approaches, we propose a novel solution to make back-projections run in multiple resolutions by using a data pipeline workflow. Features are updated at multiple scales in each layer of the network. The update dynamic through these layers includes interactions between different resolutions in a way that is causal in scale, and it is represented by a system of ODEs, as opposed to a single ODE in the case of ResNets. The system can be used as a generic multi-resolution approach to enhance images. We test it on several challenging tasks with special focus on super-resolution and raindrop removal. Our results are competitive with state-of-the-arts and show a strong ability of our system to learn both global and local image features.      
### 5.Optimal Placement of Detectors to Minimize Casualties on a Manmade Attack  [ :arrow_down: ](https://arxiv.org/pdf/2101.10184.pdf)
>  This study proposes a mathematical model to optimally locate a set of detectors in such a way that the expected number of casualties in a given threat area can be minimized. Detectors may not be perfectly reliable, which is often a function of how long an attacker would stay within the detectors effective detection radius. To accurately detect any threat event and to avoid any false alarm, we assume that a set of backup/secondary detectors are available to support the primary detectors. The problem is formulated as a nonlinear binary integer programming model and then solved as a linearized branch-and-bound algorithm. A number of sensitivity analyses are performed to illustrate the robustness of the model and to draw key managerial insights. Experimental results reveal that a two-layer detection will significantly minimize the expected number of casualties in a threat area over a one-layer detection problem.      
### 6.On w-Optimization of the Split Covariance Intersection Filter  [ :arrow_down: ](https://arxiv.org/pdf/2101.10159.pdf)
>  The split covariance intersection filter (split CIF) is a useful tool for general data fusion and has the potential to be applied in a variety of engineering tasks. An indispensable optimization step (referred to as w-optimization) involved in the split CIF concerns the performance and implementation efficiency of the Split CIF, but explanation on w-optimization is neglected in the paper [1] that provides a theoretical foundation for the Split CIF. This note complements [1] by providing a theoretical proof for the convexity of the w-optimization problem involved in the split CIF (convexity is always a desired property for optimization problems as it facilitates optimization considerably).      
### 7.Spatial Wideband Channel Estimation for MmWave Massive MIMO Systems with Hybrid Architectures and Low-Resolution ADCs  [ :arrow_down: ](https://arxiv.org/pdf/2101.10158.pdf)
>  In this paper, a channel estimator for wideband millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems with hybrid architectures and low-resolution analog-to-digital converters (ADCs) is proposed. To account for the propagation delay across the antenna array, which cannot be neglected in wideband mmWave massive MIMO systems, the discrete time channel that models the spatial wideband effect is developed. Also, the training signal design that addresses inter-frame, inter-user, and inter-symbol interferences is investigated when the spatial wideband effect is not negligible. To estimate the channel parameters over the continuum based on the maximum a posteriori (MAP) criterion, the Newtonized fully corrective forward greedy selection-cross validation-based (NFCFGS-CV-based) channel estimator is proposed. NFCFGS-CV is a gridless compressed sensing (CS) algorithm, whose termination condition is determined by the CV technique. The CV-based termination condition is proved to achieve the minimum squared error (SE). The simulation results show that NFCFGS-CV outperforms state-of-the-art on-grid CS-based channel estimators.      
### 8.Performance of Cell-Free MmWave Massive MIMO Systems with Fronthaul Compression and DAC Quantization  [ :arrow_down: ](https://arxiv.org/pdf/2101.10157.pdf)
>  In this paper, the zero-forcing (ZF) precoder with max-min power allocation is proposed for cell-free millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems using low-resolution digital-to-analog converters (DACs) with limited-capacity fronthaul links. The proposed power allocation aims to achieve max-min fairness on the achievable rate lower bounds of the users obtained by the additive quantization noise model (AQNM), which mimics the effect of low-resolution DACs. To solve the max-min power allocation problem, an alternating optimization (AO) method is proposed, which is guaranteed to converge because the global optima of the subproblems that constitute the original problem are attained at each AO iteration. The performance of cell-free and small-cell systems is explored in the simulation results, which suggest that not-too-small fronthaul capacity suffices for cell-free systems to outperform small-cell systems.      
### 9.Pricing Energy Storage in Real-time Market  [ :arrow_down: ](https://arxiv.org/pdf/2101.10151.pdf)
>  The problem of pricing utility-scale energy storage resources (ESRs) in the real-time electricity market is considered. Under a rolling-window dispatch model where the operator centrally dispatches generation and consumption under forecasting uncertainty, it is shown that almost all uniform pricing schemes, including the standard locational marginal pricing (LMP), result in lost opportunity costs that require out-of-the-market settlements. It is also shown that such settlements give rise to disincentives for generating firms and storage participants to bid truthfully, even when these market participants are rational price-takers in a competitive market. Temporal locational marginal pricing (TLMP) is proposed for ESRs as a generalization of LMP to an in-market discriminative form. TLMP is a sum of the system-wide energy price, LMP, and the individual state-of-charge price. It is shown that, under arbitrary forecasting errors, the rolling-window implementation of TLMP eliminates the lost opportunity costs and provides incentives to price-taking firms to bid truthfully with their marginal costs. Numerical examples show insights into the effects of uniform and non-uniform pricing mechanisms on dispatch following and truthful bidding incentives.      
### 10.Estimates for solutions of homogeneous time-delay systems: Comparison of Lyapunov-Krasovskii and Lyapunov-Razumikhin techniques  [ :arrow_down: ](https://arxiv.org/pdf/2101.10139.pdf)
>  In this contribution, the estimates for the response of time delay systems with nonlinear homogeneous right-hand side of degree strictly greater than one are constructed. The existing results obtained via the Lyapunov--Razumikhin approach are reminded. Their proofs, revisited in the appendix, lead to explicit expressions of the involved constants. Based on a recently introduced Lyapunov--Krasovskii functional and known estimates of the domain of attraction, we present new estimates of the system response. We compare both approaches and discuss the illustrative examples.      
### 11.Designing a Reliable Inland Waterway Transportation Network under Uncertainty  [ :arrow_down: ](https://arxiv.org/pdf/2101.10120.pdf)
>  Inland waterway transportation network significantly supports the overall freight transportation of the nation. In order to ensure efficient and timely commodity transportation through this network, this study aims at developing a reliable inland waterway transportation network considering the interactions between different transportation entities along with considering the uncertain commodity supply and unpredictable waterway conditions over time. A capacitated, multi-commodity, multi-period, stochastic, two-stage mixed-integer linear programming (MILP) model is proposed to capture this stochastic, time variant behavior of the water-depth along any link of the inland waterway under consideration. Additionally, we proposed a parallelized hybrid decomposition algorithm to solve the real-life test instances of this complex NP-hard problem. The proposed algorithm is capable of producing high quality solutions within a reasonable amount of time. Further, a case study is demonstrated for the Southeast region of the United States and a number of managerial insights are drawn that magnifies the impact of different key input parameters on the overall inland waterway transportation network under consideration.      
### 12.Beyond cost reduction: Improving the value of energy storage in electricity systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.10092.pdf)
>  An energy storage technology is valuable if it makes energy systems cheaper. Traditional ways to improve storage technologies are to reduce their costs; however, the cheapest energy storage is not always the most valuable in energy systems. This paper reviews techno-economic storage valuation methods and expands them by the new "market potential method" which derives a system-value by examining the capacities obtained from a long-term investment planning optimisation. We apply and compare this method to other cost metrics in a renewables-based European power system model, covering diverse energy storage technologies. We find that characteristics of high-cost hydrogen storage can be equally or even more valuable than low-cost hydrogen storage. Additionally, we show that modifying the freedom of storage sizing and component interactions can make the energy system 10% cheaper and impact the value of technologies. The results suggest to look beyond the pure cost reduction paradigm and focus on developing technologies with value approaches that can lead to cheaper electricity systems in future. One practical and useful value method to guide energy storage innovation could be the market potential method.      
### 13.A Continuation Method for Large-Scale Modeling and Control: from ODEs to PDE, a Round Trip  [ :arrow_down: ](https://arxiv.org/pdf/2101.10060.pdf)
>  In this paper we present a continuation method which transforms spatially distributed ODE systems into continuous PDE. We show that this continuation can be performed both for linear and nonlinear systems, including multidimensional, space- and time-varying systems. When applied to a large-scale network, the continuation provides a PDE describing evolution of continuous state approximation that respects the spatial structure of the original ODE. Our method is illustrated by multiple examples including transport equations, Kuramoto equations and heat diffusion equations. As a main example, we perform the continuation of a Newtonian system of interacting particles and obtain the Euler equations for compressible fluids, thereby providing an original alternative solution to Hilbert's 6th problem. Finally, we leverage our derivation of the Euler equations to control multiagent systems, designing a nonlinear control algorithm for robot formation based on its continuous approximation.      
### 14.Embedding-based Instance Segmentation of Microscopy Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.10033.pdf)
>  Automatic detection and segmentation of objects in microscopy images is important for many biological applications. In the domain of natural images, and in particular in the context of city street scenes, embedding-based instance segmentation leads to high-quality results. Inspired by this line of work, we introduce EmbedSeg, an end-to-end trainable deep learning method based on the work by Neven et al. While their approach embeds each pixel to the centroid of any given instance, in EmbedSeg, motivated by the complex shapes of biological objects, we propose to use the medoid instead. Additionally, we make use of a test-time augmentation scheme, and show that both suggested modifications improve the instance segmentation performance on biological microscopy datasets notably. We demonstrate that embedding-based instance segmentation achieves competitive results in comparison to state-of-the-art methods on diverse and biologically relevant microscopy datasets. Finally, we show that the overall pipeline has a small enough memory footprint to be used on virtually all CUDA enabled laptop hardware. Our open-source implementation is available at <a class="link-external link-http" href="http://github.com/juglab/EmbedSeg" rel="external noopener nofollow">this http URL</a>.      
### 15.Automatic Liver Segmentation from CT Images Using Deep Learning Algorithms: A Comparative Study  [ :arrow_down: ](https://arxiv.org/pdf/2101.09987.pdf)
>  Medical imaging has been employed to support medical diagnosis and treatment. It may also provide crucial information to surgeons to facilitate optimal surgical preplanning and perioperative management. Essentially, semi-automatic organ and tumor segmentation has been studied by many researchers. Recently, with the development of Deep Learning (DL) algorithms, automatic organ segmentation has been gathered lots of attention from the researchers. This paper addresses to propose the most efficient DL architectures for Liver segmentation by adapting and comparing state-of-the-art DL frameworks, studied in different disciplines. These frameworks are implemented and adapted into a Commercial software, 'LiverVision'. It is aimed to reveal the most effective and accurate DL architecture for fully automatic liver segmentation. Equal conditions were provided to all architectures in the experiments so as to measure the effectiveness of algorithms accuracy, and Dice coefficient metrics were also employed to support comparative analysis. Experimental results prove that 'U-Net' and 'SegNet' have been superior in line with the experiments conducted considering the concepts of time, cost, and effectiveness. Considering both architectures, 'SegNet' was observed to be more successful in eliminating false-positive values. Besides, it was seen that the accuracy metric used to measure effectiveness in image segmentation alone was not enough. Results reveal that DL algorithms are able to automate organ segmentation from DICOM images with high accuracy. This contribution is critical for surgical preplanning and motivates author to apply this approach to the different organs and field of medicine.      
### 16.3D U-Net for segmentation of COVID-19 associated pulmonary infiltrates using transfer learning: State-of-the-art results on affordable hardware  [ :arrow_down: ](https://arxiv.org/pdf/2101.09976.pdf)
>  Segmentation of pulmonary infiltrates can help assess severity of COVID-19, but manual segmentation is labor and time-intensive. Using neural networks to segment pulmonary infiltrates would enable automation of this task. However, training a 3D U-Net from computed tomography (CT) data is time- and resource-intensive. In this work, we therefore developed and tested a solution on how transfer learning can be used to train state-of-the-art segmentation models on limited hardware and in shorter time. We use the recently published RSNA International COVID-19 Open Radiology Database (RICORD) to train a fully three-dimensional U-Net architecture using an 18-layer 3D ResNet, pretrained on the Kinetics-400 dataset as encoder. The generalization of the model was then tested on two openly available datasets of patients with COVID-19, who received chest CTs (Corona Cases and MosMed datasets). Our model performed comparable to previously published 3D U-Net architectures, achieving a mean Dice score of 0.679 on the tuning dataset, 0.648 on the Coronacases dataset and 0.405 on the MosMed dataset. Notably, these results were achieved with shorter training time on a single GPU with less memory available than the GPUs used in previous studies.      
### 17.Unitary Approximate Message Passing for Sparse Bayesian Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09954.pdf)
>  Sparse Bayesian learning (SBL) can be implemented with low complexity based on the approximate message passing (AMP) algorithm. However, it is vulnerable to 'difficult' measurement matrices, which may cause AMP to diverge. Damped AMP has been used for SBL to alleviate the problem at the cost of reducing convergence speed. In this work, we propose a new SBL algorithm based on structured variational inference, leveraging AMP with a unitary transformation (UAMP). Both single measurement vector and multiple measurement vector problems are investigated. It is shown that, compared to state-of-the-art AMP-based SBL algorithms, the proposed UAMPSBL is more robust and efficient, leading to remarkably better performance.      
### 18.Blind Diagnosis for Millimeter-wave Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.09952.pdf)
>  Millimeter-wave (mmWave) massive multiple-input multiple-output (MIMO) systems rely on large-scale antenna arrays to combat large path-loss at mmWave band. Due to hardware characteristics and deploying environments, mmWave massive MIMO systems are vulnerable to antenna element blockages and failures, which necessitate diagnostic techniques to locate faulty antenna elements for calibration purposes. Current diagnostic techniques require full or partial knowledge of channel state information (CSI), which can be challenging to acquire in the presence of antenna failures. In this letter, we propose a blind diagnostic technique to identify faulty antenna elements in mmWave massive MIMO systems, which does not require any CSI knowledge. By jointly exploiting the sparsity of mmWave channel and failure, we first formulate the diagnosis problem as a joint sparse recovery problem. Then, the atomic norm is introduced to induce the sparsity of mmWave channel over continuous Fourier dictionary. An efficient algorithm based on alternating direction method of multipliers (ADMM) is proposed to solve the proposed problem. Finally, the performance of proposed technique is evaluated through numerical simulations.      
### 19.Fast &amp; Robust Image Interpolation using Gradient Graph Laplacian Regularizer  [ :arrow_down: ](https://arxiv.org/pdf/2101.09951.pdf)
>  In the graph signal processing (GSP) literature, it has been shown that signal-dependent graph Laplacian regularizer (GLR) can efficiently promote piecewise constant (PWC) signal reconstruction for various image restoration tasks. However, for planar image patches, like total variation (TV), GLR may suffer from the well-known "staircase" effect. To remedy this problem, we generalize GLR to gradient graph Laplacian regularizer (GGLR) that provably promotes piecewise planar (PWP) signal reconstruction for the image interpolation problem -- a 2D grid with randomly missing pixels that requires completion. Specifically, we first construct two higher-order gradient graphs to connect local horizontal and vertical gradients. Each local gradient is estimated using structure tensor, which is robust using known pixels in a small neighborhood, mitigating the problem of larger noise variance when computing gradient of gradients. Moreover, unlike total generalized variation (TGV), GGLR retains the quadratic form of GLR, leading to an unconstrained quadratic programming (QP) problem per iteration that can be solved quickly using conjugate gradient (CG). We derive the means-square-error minimizing weight parameter for GGLR, trading off bias and variance of the signal estimate. Experiments show that GGLR outperformed competing schemes in interpolation quality for severely damaged images at a reduced complexity.      
### 20.Asymptotic Assessment of Distribution Voltage Profile Using a Nonlinear ODE Model  [ :arrow_down: ](https://arxiv.org/pdf/2101.09945.pdf)
>  The promising increase of Electric Vehicles (EVs) in our society poses a challenging problem on the impact assessment of their charging/discharging to power distribution grids. This paper addresses the assessment problem in a framework of nonlinear differential equations. Specifically, we address the nonlinear ODE (Ordinary Differential Equation) model for representing the spatial profile of voltage phasor along a distribution feeder, which has been recently introduced in literature. The assessment problem is then formulated as a two-point boundary value problem of the nonlinear ODE model. In this paper we derive an asymptotic charcterisation of solutions of the problem through the standard regular perturbation method. This provides a mathematically-rigor and quantitative method for assessing how the charging/discharging of EVs affects the spatial profile of distribution voltage. Effectiveness of the asymptotic charcterisation is established with simulations of both simple and practical configurations of the power distribution grid.      
### 21.Supervised and Unsupervised Approaches for Controlling Narrow Lexical Focus in Sequence-to-Sequence Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2101.09940.pdf)
>  Although Sequence-to-Sequence (S2S) architectures have become state-of-the-art in speech synthesis, capable of generating outputs that approach the perceptual quality of natural samples, they are limited by a lack of flexibility when it comes to controlling the output. In this work we present a framework capable of controlling the prosodic output via a set of concise, interpretable, disentangled parameters. We apply this framework to the realization of emphatic lexical focus, proposing a variety of architectures designed to exploit different levels of supervision based on the availability of labeled resources. We evaluate these approaches via listening tests that demonstrate we are able to successfully realize controllable focus while maintaining the same, or higher, naturalness over an established baseline, and we explore how the different approaches compare when synthesizing in a target voice with or without labeled data.      
### 22.Active Attack Detection and Control in Constrained Cyber-Physical Systems Under Prevented Actuation Attack  [ :arrow_down: ](https://arxiv.org/pdf/2101.09885.pdf)
>  This paper proposes an active attack detection scheme for constrained cyber-physical systems. Despite passive approaches where the detection is based on the analysis of the input-output data, active approaches interact with the system by designing the control input so to improve detection. This paper focuses on the prevented actuation attack, where the attacker prevents the exchange of information between the controller and actuators. The proposed scheme consists of two units: 1) detection, and 2) control. The detection unit includes a set of parallel detectors, which are designed based on the multiple-model adaptive estimation approach to detect the attack and to identify the attacked actuator(s). For what regards the control unit, a constrained optimization approach is developed to determine the control input such that the control and detection aims are achieved. In the formulation of the detection and control objective functions, a probabilistic approach is used to reap the benefits of the \textit{a priori} information availability. The effectiveness of the proposed scheme is demonstrated through a simulation study on an irrigation channel.      
### 23.TSO-DSO Operational Planning Coordination through Surrogate Lagrangian Relaxation  [ :arrow_down: ](https://arxiv.org/pdf/2101.09877.pdf)
>  With the proliferation of distributed energy resources (DERs), located at the Distribution System Operator (DSO) level, uncertainties propagate from Transmission System Operator (TSO) to DSOs and vice versa. Therefore, to enable interoperability, while ensuring higher flexibility and cost-efficiency, both systems need to be efficiently coordinated to operate in sync. Moreover, because of the intermittency of renewable generation, voltages exhibit fluctuations thus necessitating the inclusion of AC power flow. Difficulties behind creating such TSO-DSO coordination include the combinatorial nature of the operational planning problem involved at the transmission level as well as the nonlinearity of AC power flow within both systems. These considerations significantly increase the complexity even under the deterministic setting. In this paper, a deterministic TSO-DSO operational planning coordination problem is considered and a novel decomposition and coordination approach is developed. Within the new method, the problem is decomposed into TSO and DSO subproblems, which are efficiently coordinated by updating Lagrangian multipliers. The nonlinearities at the TSO level caused by AC power flow constraints are resolved through a novel dynamic linearization. Numerical results based on the coordination of 118-bus TSO system with 32 DSO 34-bus systems indicate that both systems benefit from the coordination.      
### 24.A Data-Driven Modeling Framework of Time-Dependent Switched Dynamical Systems via Extreme Learning Machine  [ :arrow_down: ](https://arxiv.org/pdf/2101.09863.pdf)
>  In this work, a data-driven modeling framework of switched dynamical systems under time-dependent switching is proposed.} The learning technique utilized to model system dynamics is Extreme Learning Machine (ELM). First, \weiming{a method is developed for the detection of the switching occurrence events in the training data extracted from system traces. The training data thus can be segmented by the detected switching instants. Then, ELM is used to learn the system dynamics of subsystems. The learning process includes segmented trace data merging and subsystem dynamics modeling. Due to the specific learning structure of ELM, the modeling process is formulated as an iterative Least-Squares (LS) optimization problem. Finally, the switching sequence can be reconstructed based on the switching detection and segmented trace merging results. An example of the data-driven modeling DC-DC converter is presented to show the effectiveness of the developed approach.      
### 25.UAV-Assisted Over-the-Air Computation  [ :arrow_down: ](https://arxiv.org/pdf/2101.09856.pdf)
>  Over-the-air computation (AirComp) provides a promising way to support ultrafast aggregation of distributed data. However, its performance cannot be guaranteed in long-distance transmission due to the distortion induced by the channel fading and noise. To unleash the full potential of AirComp, this paper proposes to use a low-cost unmanned aerial vehicle (UAV) acting as a mobile base station to assist AirComp systems. Specifically, due to its controllable high-mobility and high-altitude, the UAV can move sufficiently close to the sensors to enable line-of-sight transmission and adaptively adjust all the links' distances, thereby enhancing the signal magnitude alignment and noise suppression. Our goal is to minimize the time-averaging mean-square error for AirComp by jointly optimizing the UAV trajectory, the scaling factor at the UAV, and the transmit power at the sensors, under constraints on the UAV's predetermined locations and flying speed, sensors' average and peak power limits. However, due to the highly coupled optimization variables and time-dependent constraints, the resulting problem is non-convex and challenging. We thus propose an efficient iterative algorithm by applying the block coordinate descent and successive convex optimization techniques. Simulation results verify the convergence of the proposed algorithm and demonstrate the performance gains and robustness of the proposed design compared with benchmarks.      
### 26.A new approach to extracting coronary arteries and detecting stenosis in invasive coronary angiograms  [ :arrow_down: ](https://arxiv.org/pdf/2101.09848.pdf)
>  In stable coronary artery disease (CAD), reduction in mortality and/or myocardial infarction with revascularization over medical therapy has not been reliably achieved. Coronary arteries are usually extracted to perform stenosis detection. We aim to develop an automatic algorithm by deep learning to extract coronary arteries from <a class="link-external link-http" href="http://ICAs.In" rel="external noopener nofollow">this http URL</a> this study, a multi-input and multi-scale (MIMS) U-Net with a two-stage recurrent training strategy was proposed for the automatic vessel segmentation. Incorporating features such as the Inception residual module with depth-wise separable convolutional layers, the proposed model generated a refined prediction map with the following two training stages: (i) Stage I coarsely segmented the major coronary arteries from pre-processed single-channel ICAs and generated the probability map of vessels; (ii) during the Stage II, a three-channel image consisting of the original preprocessed image, a generated probability map, and an edge-enhanced image generated from the preprocessed image was fed to the proposed MIMS U-Net to produce the final segmentation probability map. During the training stage, the probability maps were iteratively and recurrently updated by feeding into the neural network. After segmentation, an arterial stenosis detection algorithm was developed to extract vascular centerlines and calculate arterial diameters to evaluate stenotic level. Experimental results demonstrated that the proposed method achieved an average Dice score of 0.8329, an average sensitivity of 0.8281, and an average specificity of 0.9979 in our dataset with 294 ICAs obtained from 73 patient. Moreover, our stenosis detection algorithm achieved a true positive rate of 0.6668 and a positive predictive value of 0.7043.      
### 27.AQuA: Analytical Quality Assessment for Optimizing Video Analytics Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.09752.pdf)
>  Millions of cameras at edge are being deployed to power a variety of different deep learning applications. However, the frames captured by these cameras are not always pristine - they can be distorted due to lighting issues, sensor noise, compression etc. Such distortions not only deteriorate visual quality, they impact the accuracy of deep learning applications that process such video streams. In this work, we introduce AQuA, to protect application accuracy against such distorted frames by scoring the level of distortion in the frames. It takes into account the analytical quality of frames, not the visual quality, by learning a novel metric, classifier opinion score, and uses a lightweight, CNN-based, object-independent feature extractor. AQuA accurately scores distortion levels of frames and generalizes to multiple different deep learning applications. When used for filtering poor quality frames at edge, it reduces high-confidence errors for analytics applications by 17%. Through filtering, and due to its low overhead (14ms), AQuA can also reduce computation time and average bandwidth usage by 25%.      
### 28.Quantum Learning Based Nonrandom Superimposed Coding for Secure Wireless Access in 5G URLLC  [ :arrow_down: ](https://arxiv.org/pdf/2101.09712.pdf)
>  Secure wireless access in ultra-reliable low-latency communications (URLLC), which is a critical aspect of 5G security, has become increasingly important due to its potential support of grant-free configuration. In grant-free URLLC, precise allocation of different pilot resources to different users that share the same time-frequency resource is essential for the next generation NodeB (gNB) to exactly identify those users under access collision and to maintain precise channel estimation required for reliable data transmission. However, this process easily suffers from attacks on pilots. We in this paper propose a quantum learning based nonrandom superimposed coding method to encode and decode pilots on multidimensional resources, such that the uncertainty of attacks can be learned quickly and eliminated precisely. Particularly, multiuser pilots for uplink access are encoded as distinguishable subcarrier activation patterns (SAPs) and gNB decodes pilots of interest from observed SAPs, a superposition of SAPs from access users, by joint design of attack mode detection and user activity detection though a quantum learning network (QLN). We found that the uncertainty lies in the identification process of codeword digits from the attacker, which can be always modelled as a black-box model, resolved by a quantum learning algorithm and quantum circuit. Novel analytical closed-form expressions of failure probability are derived to characterize the reliability of this URLLC system with short packet transmission. Simulations how that our method can bring ultra-high reliability and low latency despite attacks on pilots.      
### 29.Two-step Machine Learning Approach for Channel Estimation with Mixed Resolution RF Chains  [ :arrow_down: ](https://arxiv.org/pdf/2101.09705.pdf)
>  Massive MIMO is one of the main features of 5G mobile radio systems. However, it often leads to high cost, size and power consumption. To overcome these issues, the use of constrained radio frequency (RF) frontends has been proposed, as well as novel precoders, e.g., a multi-antenna, greedy, iterative and quantized precoding algorithm (MAGIQ). Nevertheless, the best performance of MAGIQ assumes accurate channel knowledge per antenna element, for example, from uplink sounding reference signals. In this context, we propose an efficient uplink channel estimator by applying machine learning (ML) algorithms. In a first step a conditional generative adversarial network (cGAN) predicts the radio channels from a limited set of full resolution RF chains to the rest of the low resolution RF chain antenna elements. A long-short term memory (LSTM) neural network extracts further phase information from the low resolution RF chain antenna elements. Our results indicate that our proposed approach is competitive with traditional Unitary tensor-ESPRIT in scenarios with various closely spaced multipath components (MPCs).      
### 30.Towards Overfitting Avoidance: Tuning-free Tensor-aided Multi-user Channel Estimation for 3D Massive MIMO Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.09672.pdf)
>  Channel estimation has long been deemed as one of the most critical problems in three-dimensional (3D) massive multiple-input multiple-output (MIMO), which is recognized as the leading technology that enables 3D spatial signal processing in the fifth-generation (5G) wireless communications and beyond. Recently, by exploring the angular channel model and tensor decompositions, the accuracy of single-user channel estimation for 3D massive MIMO communications has been significantly improved given a limited number of pilot signals. However, these existing approaches cannot be straightforwardly extended to the multi-user channel estimation task, where the base station (BS) aims at acquiring the channels of multiple users at the same time. The difficulty is that the coupling among multiple users' channels makes the channel estimation deviate from widely-used tensor decompositions. It gives a non-standard tensor decomposition format that has not been well tackled. To overcome this challenge, besides directly fitting the new tensor model for channel estimation to the wireless data via block coordinate descent (BCD) method, which is prone to the overfitting of noises or requires regularization parameter tuning, we further propose a novel tuning-free channel estimation algorithm that can automatically control the channel model complexity and thus effectively avoid the overfitting. Numerical results are presented to demonstrate the excellent performance of the proposed algorithm in terms of both estimation accuracy and overfitting avoidance.      
### 31.SRAR-RISs: Simultaneous Reflecting and Refracting Reconfigurable Intelligent Surfaces  [ :arrow_down: ](https://arxiv.org/pdf/2101.09663.pdf)
>  In this letter, simultaneous reflecting and refracting reconfigurable intelligent surfaces (SRAR-RISs) are studied. Compared with RISs that only operate in the reflection mode, the coverage area of SRAR-RISs is extended via simultaneous reflection and refraction. We separately present a hardware model and channel models for the near-field region and the far-field region. The proposed channel models give closed-form expressions of the channel gains in terms of physical parameters of the SRAR-RIS and the geometrical information of the receivers. The differences between the far-field and the near-field channel models are revealed by analytical results and simulations.      
### 32.Cost-limited reachability: a new problem in reachability analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.09646.pdf)
>  In this paper, we generalize the definition of backward reachable tube. The classic definition of backward reachable tube is a set of system state that can be driven into the target set within a given time horizon. Sometimes, the concern of researchers is not only the time consumption, but some other forms of cost of driving the system state toward the target set. Under this background, the definition of cost-limited backward reachable tube is put forward in this paper, where the cost is the time integral of a running cost. And the running cost is a scalar function of system state and control input. A method to compute the cost-limited backward reachable tube is proposed. In this method, a cost-limited backward reachable tube is characterized by a non-zero level set of a value function, which is approximated using recursion and interpolation. At the end of this paper, some examples are taken to illustrate the validity and accuracy of the proposed method.      
### 33.Multi-intersection Traffic Optimisation: A Benchmark Dataset and a Strong Baseline  [ :arrow_down: ](https://arxiv.org/pdf/2101.09640.pdf)
>  The control of traffic signals is fundamental and critical to alleviate traffic congestion in urban areas. However, it is challenging since traffic dynamics are complicated in real situations. Because of the high complexity of modelling the optimisation problem, experimental settings of current works are often inconsistent. Moreover, it is not trivial to control multiple intersections properly in real complex traffic scenarios due to its vast state and action space. Failing to take intersection topology relations into account also results in inferior traffic condition. To address these issues, in this work we carefully design our settings and propose new data including both synthetic and real traffic data in more complex scenarios. Additionally, we propose a novel and strong baseline model based on deep reinforcement learning with the encoder-decoder structure: an edge-weighted graph convolutional encoder to excavate multi-intersection relations; and a unified structure decoder to jointly model multiple junctions in a comprehensive manner, which significantly reduces the number of the model parameters. By doing so, the proposed model is able to effectively deal with multi-intersection traffic optimisation problems. Models have been trained and tested on both synthetic and real maps and traffic data with the Simulation of Urban Mobility (SUMO) simulator. Experimental results show that the proposed model surpasses existing methods in the literature.      
### 34.Chance-Constrained Covariance Steering in a Gaussian Random Field via Successive Convex Programming  [ :arrow_down: ](https://arxiv.org/pdf/2101.09634.pdf)
>  The problem of optimizing affine feedback laws that explicitly steer the mean and covariance of an uncertain system state in the presence of a Gaussian random field is considered. Spatially-dependent disturbances are successively approximated with respect to a nominal trajectory by a sequence of jointly Gaussian random vectors. Sequential updates to the nominal control inputs are computed via convex optimization that includes the effect of affine state feedback, the perturbing effects of spatial disturbances, and chance constraints on the closed-loop state and control. The developed method is applied to solve for an affine feedback law to minimize the 99th percentile of $\Delta v$ required to complete an aerocapture mission around a planet with a randomly disturbed atmosphere.      
### 35.A Review of Speaker Diarization: Recent Advances with Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09624.pdf)
>  Speaker diarization is a task to label audio or video recordings with classes corresponding to speaker identity, or in short, a task to identify "who spoke when". In the early years, speaker diarization algorithms were developed for speech recognition on multi-speaker audio recordings to enable speaker adaptive processing, but also gained its own value as a stand-alone application over time to provide speaker-specific meta information for downstream tasks such as audio retrieval. More recently, with the rise of deep learning technology that has been a driving force to revolutionary changes in research and practices across speech application domains in the past decade, more rapid advancements have been made for speaker diarization. In this paper, we review not only the historical development of speaker diarization technology but also the recent advancements in neural speaker diarization approaches. We also discuss how speaker diarization systems have been integrated with speech recognition applications and how the recent surge of deep learning is leading the way of jointly modeling these two components to be complementary to each other. By considering such exciting technical trends, we believe that it is a valuable contribution to the community to provide a survey work by consolidating the recent developments with neural methods and thus facilitating further progress towards a more efficient speaker diarization.      
### 36.A Methodology for the Development of RL-Based Adaptive Traffic Signal Controllers  [ :arrow_down: ](https://arxiv.org/pdf/2101.09614.pdf)
>  This article proposes a methodology for the development of adaptive traffic signal controllers using reinforcement learning. Our methodology addresses the lack of standardization in the literature that renders the comparison of approaches in different works meaningless, due to differences in metrics, environments, and even experimental design and methodology. The proposed methodology thus comprises all the steps necessary to develop, deploy and evaluate an adaptive traffic signal controller -- from simulation setup to problem formulation and experimental design. We illustrate the proposed methodology in two simple scenarios, highlighting how its different steps address limitations found in the current literature.      
### 37.Communication-Efficient Variance-Reduced Decentralized Stochastic Optimization over Time-Varying Directed Graphs  [ :arrow_down: ](https://arxiv.org/pdf/2101.09583.pdf)
>  We consider decentralized optimization over time-varying directed networks. Network nodes can access only their local objectives, and aim to collaboratively minimize a global function by exchanging messages with their neighbors. Leveraging sparsification, gradient tracking and variance-reduction, we propose a novel communication-efficient decentralized optimization scheme that is suitable for resource-constrained time-varying directed networks. We prove that in the case of smooth and strongly-convex objective functions, the proposed scheme achieves an accelerated linear convergence rate. To our knowledge, this is the first decentralized optimization framework that achieves such a convergence rate and applies to settings requiring sparsified communication. Experimental results on both synthetic and real datasets verify the theoretical results and demonstrate efficacy of the proposed scheme.      
### 38.Stochastic Image Denoising by Sampling from the Posterior Distribution  [ :arrow_down: ](https://arxiv.org/pdf/2101.09552.pdf)
>  Image denoising is a well-known and well studied problem, commonly targeting a minimization of the mean squared error (MSE) between the outcome and the original image. Unfortunately, especially for severe noise levels, such Minimum MSE (MMSE) solutions may lead to blurry output images. In this work we propose a novel stochastic denoising approach that produces viable and high perceptual quality results, while maintaining a small MSE. Our method employs Langevin dynamics that relies on a repeated application of any given MMSE denoiser, obtaining the reconstructed image by effectively sampling from the posterior distribution. Due to its stochasticity, the proposed algorithm can produce a variety of high-quality outputs for a given noisy input, all shown to be legitimate denoising results. In addition, we present an extension of our algorithm for handling the inpainting problem, recovering missing pixels and removing noise from partially given noisy data.      
### 39.Microcontroller based bidirectional buck boost converter for photo voltaic power plant  [ :arrow_down: ](https://arxiv.org/pdf/2101.09474.pdf)
>  A common configuration for a stand-alone PV power system may consist of three converters: a buck converter for the PV panelto charge the battery, a boost converter for the battery to discharge to the load and one for the load voltage regulation. Such a systemrequires a coordinated control scheme for three converters which can be complicated. A simple structure for a stand-alone PV plantconsists of a PV array, a battery unit, and its associated bidirectional converter which is a combination of a buck and boost converter.When controlled properly the system can provide uninterrupted power to the load, despite the intermittent availability of sunlight. Inthis paper complete design of the converter is carried out and the simulation has been performed using Psim. From the simulation,the graphs are presented to show the converter working in buck mode and boost mode. Controller is designed to take care of modetransition, buck to boost and boost to buck mode automatically based on source voltage. Hardware implementation has been doneusing microcontroller (8051).      
### 40.Circumventing the resolution-time tradeoff in Ultrasound Localization Microscopy by Velocity Filtering  [ :arrow_down: ](https://arxiv.org/pdf/2101.09470.pdf)
>  Ultrasound Localization Microscopy (ULM) offers a cost-effective modality for microvascular imaging by using intravascular contrast agents (microbubbles). However, ULM has a fundamental trade-off between acquisition time and spatial resolution, which makes clinical translation challenging. In this paper, in order to circumvent the trade-off, we introduce a spatiotemporal filtering operation dubbed velocity filtering, which is capable of separating contrast agents into different groups based on their vector velocities thus reducing interference in the localization step, while simultaneously offering blood velocity mapping at super resolution, without tracking individual microbubbles. As side benefit, the velocity filter provides noise suppression before microbubble localization that could enable substantially increased penetration depth in tissue typically by 4cm or more. We provide a theoretical analysis of the performance of velocity filter. Numerical experiments confirm that the proposed velocity filter is able to separate the microbubbles with respect to the speed and direction of their motion. In combination with subsequent localization of microbubble centers, e.g. by matched filtering, the velocity filter improves the quality of the reconstructed vasculature significantly and provides blood flow information. Overall, the proposed imaging pipeline in this paper enables the use of higher concentrations of microbubbles while preserving spatial resolution, thus helping circumvent the trade-off between acquisition time and spatial resolution. Conveniently, because the velocity filtering operation can be implemented by fast Fourier transforms(FFTs) it admits fast, and potentially real-time realization. We believe that the proposed velocity filtering method has the potential to pave the way to clinical translation of ULM.      
### 41.Adaptively Sparse Regularization for Blind Image Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2101.09401.pdf)
>  Image quality is the basis of image communication and understanding tasks. Due to the blur and noise effects caused by imaging, transmission and other processes, the image quality is degraded. Blind image restoration is widely used to improve image quality, where the main goal is to faithfully estimate the blur kernel and the latent sharp image. In this study, based on experimental observation and research, an adaptively sparse regularized minimization method is originally proposed. The high-order gradients combine with low-order ones to form a hybrid regularization term, and an adaptive operator derived from the image entropy is introduced to maintain a good convergence. Extensive experiments were conducted on different blur kernels and images. Compared with existing state-of-the-art blind deblurring methods, our method demonstrates superiority on the recovery accuracy.      
### 42.SGD-Net: Efficient Model-Based Deep Learning with Theoretical Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2101.09379.pdf)
>  Deep unfolding networks have recently gained popularity in the context of solving imaging inverse problems. However, the computational and memory complexity of data-consistency layers within traditional deep unfolding networks scales with the number of measurements, limiting their applicability to large-scale imaging inverse problems. We propose SGD-Net as a new methodology for improving the efficiency of deep unfolding through stochastic approximations of the data-consistency layers. Our theoretical analysis shows that SGD-Net can be trained to approximate batch deep unfolding networks to an arbitrary precision. Our numerical results on intensity diffraction tomography and sparse-view computed tomography show that SGD-Net can match the performance of the batch network at a fraction of training and testing complexity.      
### 43.Pulse Index Modulation  [ :arrow_down: ](https://arxiv.org/pdf/2101.09340.pdf)
>  Emerging systems such as Internet-of-things (IoT) and machine-to-machine (M2M) communications have strict requirements on the power consumption of used equipments and associated complexity in the transceiver design. As a result, multiple-input multiple-output (MIMO) solutions might not be directly suitable for these system due to their high complexity, inter-antenna synchronization (IAS) requirement, and high inter-antenna interference (IAI) problems. In order to overcome these problems, we propose two novel index modulation (IM) schemes, namely pulse index modulation (PIM) and generalized PIM (GPIM) for single-input single-output (SISO) schemes. The proposed models use well-localized and orthogonal Hermite-Gaussian pulses for data transmission and provide high spectral efficiency owing to the Hermite-Gaussian pulse indices. Besides, it has been shown via analytical derivations and computer simulations that the proposed PIM and GPIM systems have better error performance and considerable signal-to-noise ratio (SNR) gain compared to existing spatial modulation (SM), quadrature SM (QSM), and traditional M-ary systems.      
### 44.Safe Learning Reference Governor for Constrained Systems with Application to Fuel Truck Rollover Avoidance  [ :arrow_down: ](https://arxiv.org/pdf/2101.09298.pdf)
>  This paper proposes a learning reference governor (LRG) approach to enforce state and control constraints in systems for which an accurate model is unavailable; and this approach enables the reference governor to gradually improve command tracking performance through learning while enforcing the constraints during learning and after learning is completed. The learning can be performed either on a black-box type model of the system or directly on the hardware. After introducing the LRG algorithm and outlining its theoretical properties, this paper investigates LRG application to fuel truck rollover avoidance. Through simulations based on a fuel truck model that accounts for liquid fuel sloshing effects, we show that the proposed LRG can effectively protect fuel trucks from rollover accidents under various operating conditions.      
### 45.MIMO-SAR: A Hierarchical High-resolution Imaging Algorithm for FMCW Automotive Radar  [ :arrow_down: ](https://arxiv.org/pdf/2101.09293.pdf)
>  Millimeter-wave radars are being increasingly integrated into commercial vehicles to support advanced driver-assistance system features. A key shortcoming for present-day vehicular radar imaging is poor azimuth resolution (for side-looking operation) due to the form factor limits on antenna size and placement. In this paper, we propose a solution via a new multiple-input and multiple-output synthetic aperture radar (MIMO-SAR) imaging technique, that applies coherent SAR principles to vehicular MIMO radar to improve the side-view (angular) resolution. The proposed 2-stage hierarchical MIMO-SAR processing workflow drastically reduces the computation load while preserving image resolution. To enable coherent processing over the synthetic aperture, we integrate a radar odometry algorithm that estimates the trajectory of ego-radar. The MIMO-SAR algorithm is validated by both simulations and real experiment data collected by a vehicle-mounted radar platform (see Fig. 1).      
### 46.Reconfigurable Intelligent Surface for Massive Connectivity  [ :arrow_down: ](https://arxiv.org/pdf/2101.10322.pdf)
>  With the rapid development of Internet of Things (IoT), massive machine-type communication has become a promising application scenario, where a large number of devices transmit sporadically to a base station (BS). Reconfigurable intelligent surface (RIS) has been recently proposed as an innovative new technology to achieve energy efficiency and coverage enhancement by establishing favorable signal propagation environments, thereby improving data transmission in massive connectivity. Nevertheless, the BS needs to detect active devices and estimate channels to support data transmission in RIS-assisted massive access systems, which yields unique challenges. This paper shall consider an RIS-assisted uplink IoT network and aims to solve the RIS-related activity detection and channel estimation problem, where the BS detects the active devices and estimates the separated channels of the RIS-to-device link and the RIS-to-BS link. Due to limited scattering between the RIS and the BS, we model the RIS-to-BS channel as a sparse channel. As a result, by simultaneously exploiting both the sparsity of sporadic transmission in massive connectivity and the RIS-to-BS channels, we formulate the RIS-related activity detection and channel estimation problem as a sparse matrix factorization problem. Furthermore, we develop an approximate message passing (AMP) based algorithm to solve the problem based on Bayesian inference framework and reduce the computational complexity by approximating the algorithm with the central limit theorem and Taylor series arguments. Finally, extensive numerical experiments are conducted to verify the effectiveness and improvements of the proposed algorithm.      
### 47.High-Quality Vocoding Design with Signal Processing for Speech Synthesis and Voice Conversion  [ :arrow_down: ](https://arxiv.org/pdf/2101.10278.pdf)
>  This Ph.D. thesis focuses on developing a system for high-quality speech synthesis and voice conversion. Vocoder-based speech analysis, manipulation, and synthesis plays a crucial role in various kinds of statistical parametric speech research. Although there are vocoding methods which yield close to natural synthesized speech, they are typically computationally expensive, and are thus not suitable for real-time implementation, especially in embedded environments. Therefore, there is a need for simple and computationally feasible digital signal processing algorithms for generating high-quality and natural-sounding synthesized speech. In this dissertation, I propose a solution to extract optimal acoustic features and a new waveform generator to achieve higher sound quality and conversion accuracy by applying advances in deep learning. The approach remains computationally efficient. This challenge resulted in five thesis groups, which are briefly summarized below.      
### 48.Novel Recording Studio Features for Music Information Retrieval  [ :arrow_down: ](https://arxiv.org/pdf/2101.10201.pdf)
>  In the recording studio, producers of Electronic Dance Music (EDM) spend more time creating, shaping, mixing and mastering sounds, than with compositional aspects or arrangement. They tune the sound by close listening and by leveraging audio metering and audio analysis tools, until they successfully creat the desired sound aesthetics. DJs of EDM tend to play sets of songs that meet their sound ideal. We therefore suggest using audio metering and monitoring tools from the recording studio to analyze EDM, instead of relying on conventional low-level audio features. We test our novel set of features by a simple classification task. We attribute songs to DJs who would play the specific song. This new set of features and the focus on DJ sets is targeted at EDM as it takes the producer and DJ culture into account. With simple dimensionality reduction and machine learning these features enable us to attribute a song to a DJ with an accuracy of 63%. The features from the audio metering and monitoring tools in the recording studio could serve for many applications in Music Information Retrieval, such as genre, style and era classification and music recommendation for both DJs and consumers of electronic dance music.      
### 49.Cyber-Physical Energy Systems Security: Threat Modeling, Risk Assessment, Resources, Metrics, and Case Studies  [ :arrow_down: ](https://arxiv.org/pdf/2101.10198.pdf)
>  Cyber-physical systems (CPS) are interconnected architectures that employ analog, digital, and communication resources for their interaction with the physical environment. CPS are the backbone of enterprise, industrial, and critical infrastructure. Thus, their vital importance, makes them prominent targets for malicious attacks aiming to disrupt their operations. Attacks targeting cyber-physical energy systems (CPES), given their mission-critical nature, can have disastrous consequences. The security of CPES can be enhanced leveraging testbed capabilities to replicate power systems operation, discover vulnerabilities, develop security countermeasures, and evaluate grid operation under fault-induced or maliciously constructed scenarios. In this paper, we provide a comprehensive overview of the CPS security landscape with emphasis on CPES. Specifically, we demonstrate a threat modeling methodology to accurately represent the CPS elements, their interdependencies, as well as the possible attack entry points and system vulnerabilities. Leveraging the threat model formulation, we present a CPS framework designed to delineate the hardware, software, and modeling resources required to simulate the CPS and construct high-fidelity models which can be used to evaluate the system's performance under adverse scenarios. The system performance is assessed using scenario-specific metrics, while risk assessment enables the system vulnerability prioritization factoring the impact on the system operation. The overarching framework for modeling, simulating, assessing, and mitigating attacks in a CPS is illustrated using four representative attack scenarios targeting CPES. The key objective of this paper is to demonstrate a step-by-step process that can be used to enact in-depth cybersecurity analyses, thus leading to more resilient and secure CPS.      
### 50.Traffic Reaction Model  [ :arrow_down: ](https://arxiv.org/pdf/2101.10190.pdf)
>  In this paper a novel non-negative finite volume discretization scheme is proposed for certain first order nonlinear partial differential equations describing conservation laws arising in traffic flow modelling. The spatially discretized model is shown to preserve several fundamentally important analytical properties of the conservation law (e.g., conservativeness, capacity) giving rise to a set of (second order) polynomial ODEs. Furthermore, it is shown that the discretized traffic flow model is formally kinetic and that it can be interpreted in a compartmental context. As a consequence, traffic networks can be represented as reaction graphs. It is shown that the model can be equipped with on- and off- ramps in a physically meaningful way, still preserving the advantageous properties of the discretization. Numerical case studies include empirical convergence tests, and the stability analysis presented in the paper paves the way to scalable observer and controller design.      
### 51.Dispersion and Filtering Properties of Rectangular Waveguides Loaded With Holey Structures  [ :arrow_down: ](https://arxiv.org/pdf/2101.10068.pdf)
>  This paper analyzes thoroughly the dispersion and filtering features of periodic holey waveguides in the millimeter-wave frequency range. Two structures are mainly studied depending on the glide and mirror symmetries of the holes. A parametric study of the dispersion characteristics of their unit cells is carried out. Glide-symmetric holey waveguides provide a higher propagation constant and a low dispersion over a wide frequency range regarding hollow waveguides. This property is particularly useful for the design of low-loss and low-dispersive phase shifters. We also demonstrate that glide-symmetric holey waveguides are less dispersive than waveguides loaded with glide-symmetric pins. Furthermore, we perform a Bloch analysis to compute the attenuation constants in holey waveguides with mirror and broken glide symmetries. Both configurations are demonstrated to be suitable for filter design. Finally, the simulation results are validated with two prototypes in gap-waveguide technology. The first one is a 180$^{o}$ phase shifter based on a glide-symmetric holey configuration that achieves a flat phase shift response over a wide frequency range (27.5\% frequency bandwidth). The second one is a filter based on a mirror-symmetric holey structure with 20-dB rejection from 63 GHz to 75 GHz.      
### 52.All-Optical Nonlinear Pre-Compensation of Long-Reach Unrepeatered Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.10064.pdf)
>  We numerically demonstrate an all-optical nonlinearity pre-compensation module for state-of-the-art long-reach Raman-amplified unrepeatered links. The compensator design is optimized in terms of propagation symmetry to maximize the performance gains under WDM transmission, achieving 4.0dB and 2.6dB of SNR improvement for 250-km and 350-km links.      
### 53.A Review of Graph Neural Networks and Their Applications in Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.10025.pdf)
>  Deep neural networks have revolutionized many machine learning tasks in power systems, ranging from pattern recognition to signal processing. The data in these tasks is typically represented in Euclidean domains. Nevertheless, there is an increasing number of applications in power systems, where data are collected from non-Euclidean domains and represented as the graph-structured data with high dimensional features and interdependency among nodes. The complexity of graph-structured data has brought significant challenges to the existing deep neural networks defined in Euclidean domains. Recently, many studies on extending deep neural networks for graph-structured data in power systems have emerged. In this paper, a comprehensive overview of graph neural networks (GNNs) in power systems is proposed. Specifically, several classical paradigms of GNNs structures (e.g., graph convolutional networks, graph recurrent neural networks, graph attention networks, graph generative networks, spatial-temporal graph convolutional networks, and hybrid forms of GNNs) are summarized, and key applications in power systems such as fault diagnosis, power prediction, power flow calculation, and data generation are reviewed in detail. Furthermore, main issues and some research trends about the applications of GNNs in power systems are discussed.      
### 54.Galaxy Image Restoration with Shape Constraint  [ :arrow_down: ](https://arxiv.org/pdf/2101.10021.pdf)
>  Images acquired with a telescope are blurred and corrupted by noise. The blurring is usually modeled by a convolution with the Point Spread Function and the noise by Additive Gaussian Noise. Recovering the observed image is an ill-posed inverse problem. Sparse deconvolution is well known to be an efficient deconvolution technique, leading to optimized pixel Mean Square Errors, but without any guarantee that the shapes of objects (e.g. galaxy images) contained in the data will be preserved. In this paper, we introduce a new shape constraint and exhibit its properties. By combining it with a standard sparse regularization in the wavelet domain, we introduce the Shape COnstraint REstoration algorithm (SCORE), which performs a standard sparse deconvolution, while preserving galaxy shapes. We show through numerical experiments that this new approach leads to a reduction of galaxy ellipticity measurement errors by at least 44%.      
### 55.Adaptive Scheduling for Machine Learning Tasks over Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.10007.pdf)
>  A key functionality of emerging connected autonomous systems such as smart transportation systems, smart cities, and the industrial Internet-of-Things, is the ability to process and learn from data collected at different physical locations. This is increasingly attracting attention under the terms of distributed learning and federated learning. However, in this setup data transfer takes place over communication resources that are shared among many users and tasks or subject to capacity constraints. This paper examines algorithms for efficiently allocating resources to linear regression tasks by exploiting the informativeness of the data. The algorithms developed enable adaptive scheduling of learning tasks with reliable performance guarantees.      
### 56.Turbulence-Resilient Coherent Free-Space Optical Communications using Automatic Power-Efficient Pilot-Assisted Optoelectronic Beam Mixing of Many Modes  [ :arrow_down: ](https://arxiv.org/pdf/2101.09967.pdf)
>  Atmospheric turbulence generally limits free-space optical (FSO) communications, and this problem is severely exacerbated when implementing highly sensitive and spectrally efficient coherent detection. Specifically, turbulence induces power coupling from the transmitted Gaussian mode to higher-order Laguerre-Gaussian (LG) modes, resulting in a significant decrease of the power that mixes with a single-mode local oscillator (LO). Instead, we transmit a frequency-offset Gaussian pilot tone along with the data signal, such that both experience similar turbulence and modal power coupling. Subsequently, the photodetector (PD) optoelectronically mixes all corresponding pairs of the beams' modes. During mixing, a conjugate of the turbulence experienced by the pilot tone is automatically generated and compensates the turbulence experienced by the data, and nearly all orders of the same corresponding modes efficiently mix. We demonstrate a 12-Gbit/s 16-quadrature-amplitude-modulation (16-QAM) polarization-multiplexed (PolM) FSO link that exhibits resilience to emulated turbulence. Experimental results for turbulence D/r_0~5.5 show up to ~20 dB reduction in the mixing power loss over a conventional coherent receiver. Therefore, our approach automatically recovers nearly all the captured data power to enable high-performance coherent FSO systems.      
### 57.Parametric Rectified Power Sigmoid Units: Learning Nonlinear Neural Transfer Analytical Forms  [ :arrow_down: ](https://arxiv.org/pdf/2101.09948.pdf)
>  The paper proposes representation functionals in a dual paradigm where learning jointly concerns both linear convolutional weights and parametric forms of nonlinear activation functions. The nonlinear forms proposed for performing the functional representation are associated with a new class of parametric neural transfer functions called rectified power sigmoid units. This class is constructed to integrate both advantages of sigmoid and rectified linear unit functions, in addition with rejecting the drawbacks of these functions. Moreover, the analytic form of this new neural class involves scale, shift and shape parameters so as to obtain a wide range of activation shapes, including the standard rectified linear unit as a limit case. Parameters of this neural transfer class are considered as learnable for the sake of discovering the complex shapes that can contribute in solving machine learning issues. Performance achieved by the joint learning of convolutional and rectified power sigmoid learnable parameters are shown outstanding in both shallow and deep learning frameworks. This class opens new prospects with respect to machine learning in the sense that learnable parameters are not only attached to linear transformations, but also to suitable nonlinear operators.      
### 58.Using Angle of Arrival for Improving Indoor Localization  [ :arrow_down: ](https://arxiv.org/pdf/2101.09904.pdf)
>  In this paper, we primarily explore the improvement of single stream audio systems using Angle of Arrival calculations in both simulation and real life gathered data. We wanted to learn how to discern the direction of an audio source from gathered signal data to ultimately incorporate into a multi modal security system. We focused on the MUSIC algorithm for the estimation of the angle of arrival but briefly experimented with other techniques such as Bartlett and Capo. We were able to implement our own MUSIC algorithm on stimulated data from Cornell. In addition, we demonstrated how we are able to calculate the angle of arrival over time in a real life scene. Finally, we are able to detect the direction of arrival for two separate and simultaneous audio sources in a real life scene. Eventually, we could incorporate this tracking into a multi modal system combined with video. Overall, we are able to produce compelling results for angle of arrival calculations that could be the stepping stones for a better system to detect events in a scene.      
### 59.Is Phase Shift Keying Optimal for Channels with Phase-Quantized Output?  [ :arrow_down: ](https://arxiv.org/pdf/2101.09896.pdf)
>  This paper establishes the capacity of AWGN channels with phase-quantized output. We show that a rotated $2^b$-phase shift keying scheme is the capacity-achieving input distribution for a complex AWGN channel with $b$-bit phase quantization. The result is then used to establish the expression for the channel capacity as a function of average power constraint $P$ and quantization bits $b$. The outage performance of phase-quantized system is also investigated for the case of Rayleigh fading. Our findings suggest the existence of a threshold in the rate $R$, above which the decay exponent of the outage probability changes abruptly. In fact, this threshold effect in the decay exponent causes $2^b$-PSK to have suboptimal outage performance at high SNR.      
### 60.ADMM-Based Parallel Optimization for Multi-Agent Collision-Free Model Predictive Control  [ :arrow_down: ](https://arxiv.org/pdf/2101.09894.pdf)
>  This paper investigates the multi-agent collision-free control problem for medium and large scale systems. For such multi-agent systems, it is the typical situation where conventional methods using either the usual centralized model predictive control (MPC), or even the distributed counterpart, would suffer from substantial difficulty in balancing optimality and computational efficiency. Additionally, the non-convex characteristics that invariably arise in such collision-free control and optimization problems render it difficult to effectively derive a reliable solution (and also to thoroughly analyze the associated convergence properties). To overcome these challenging issues, this work establishes a suitably novel parallel computation framework through an innovative mathematical problem formulation; and then with this framework and formulation, the alternating direction method of multipliers (ADMM) algorithm is presented to solve the sub-problems arising from the resulting parallel structure. Furthermore, an efficient and intuitive initialization procedure is developed to accelerate the optimization process, and the optimum is thus determined with significantly improved computational efficiency. As supported by rigorous proofs, the convergence of the proposed ADMM iterations for this non-convex optimization problem is analyzed and discussed in detail. Finally, a multi-agent system with a group of unmanned aerial vehicles (UAVs) serves as an illustrative example here to demonstrate the effectiveness and efficiency of the proposed approach.      
### 61.Domain-Dependent Speaker Diarization for the Third DIHARD Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2101.09884.pdf)
>  This report presents the system developed by the ABSP Laboratory team for the third DIHARD speech diarization challenge. Our main contribution in this work is to develop a simple and efficient solution for acoustic domain dependent speech diarization. We explore speaker embeddings for \emph{acoustic domain identification} (ADI) task. Our study reveals that i-vector based method achieves considerably better performance than x-vector based approach in the third DIHARD challenge dataset. Next, we integrate the ADI module with the diarization framework. The performance substantially improved over that of the baseline when we optimized the thresholds for agglomerative hierarchical clustering and the parameters for dimensionality reduction during scoring for individual acoustic domains. We achieved a relative improvement of $9.63\%$ and $10.64\%$ in DER for core and full conditions, respectively, for Track 1 of the DIHARD III evaluation set.      
### 62.Standalone Deployment of a Dynamic Drone Cell for Wireless Connectivity of Two Services  [ :arrow_down: ](https://arxiv.org/pdf/2101.09701.pdf)
>  We treat a setting in which two priority wireless service classes are offered in a given area by a drone small cell (DSC). Specifically, we consider broadband (BB) user with high priority and reliability requirements that coexists with random access machine-type-communications (MTC) devices. The drone serves both connectivity types with a combination of orthogonal slicing of the wireless resources and dynamic horizontal opportunistic positioning (D-HOP). We treat the D-HOP as a computational geometry function over stochastic BB user locations which requires careful adjustment in the deployment parameters to ensure MTC service at all times. Using an information theoretic approach, we optimize DSC deployment properties and radio resource allocation for the purpose of maximizing the average rate of BB users. While respecting the strict dual service requirements we analyze how system performance is affected by stochastic user positioning and density, topology, and reliability constraints combinations. The numerical results show that this approach outperforms static DSCs that fit the same coverage constraints, with outstanding performance in the urban setting.      
### 63.FlowReg: Fast Deformable Unsupervised Medical Image Registration using Optical Flow  [ :arrow_down: ](https://arxiv.org/pdf/2101.09639.pdf)
>  We propose FlowReg, a deep learning-based framework for unsupervised image registration for neuroimaging applications. The system is composed of two architectures that are trained sequentially: FlowReg-A which affinely corrects for gross differences between moving and fixed volumes in 3D followed by FlowReg-O which performs pixel-wise deformations on a slice-by-slice basis for fine tuning in 2D. The affine network regresses the 3D affine matrix based on a correlation loss function that enforces global similarity. The deformable network operates on 2D image slices based on the optical flow network FlowNet-Simple but with three loss components. The photometric loss minimizes pixel intensity differences differences, the smoothness loss encourages similar magnitudes between neighbouring vectors, and a correlation loss that is used to maintain the intensity similarity between fixed and moving image slices. The proposed method is compared to four open source registration techniques ANTs, Demons, SE, and Voxelmorph. In total, 4643 FLAIR MR imaging volumes are used from dementia and vascular disease cohorts, acquired from over 60 international centres with varying acquisition parameters. A battery of quantitative novel registration validation metrics are proposed that focus on the structural integrity of tissues, spatial alignment, and intensity similarity. Experimental results show FlowReg (FlowReg-A+O) performs better than iterative-based registration algorithms for intensity and spatial alignment metrics with a Pixelwise Agreement of 0.65, correlation coefficient of 0.80, and Mutual Information of 0.29. Among the deep learning frameworks, FlowReg-A or FlowReg-A+O provided the highest performance over all but one of the metrics. Results show that FlowReg is able to obtain high intensity and spatial similarity while maintaining the shape and structure of anatomy and pathology.      
### 64.Isogeometric Configuration Design Optimization of Three-dimensional Curved Beam Structures for Maximal Fundamental Frequency  [ :arrow_down: ](https://arxiv.org/pdf/2101.09566.pdf)
>  This paper presents a configuration design optimization method for three-dimensional curved beam built-up structures having maximized fundamental eigenfrequency. We develop the method of computation of design velocity field and optimal design of beam structures constrained on a curved surface, where both designs of the embedded beams and the curved surface are simultaneously varied during the optimal design process. A shear-deformable beam model is used in the response analyses of structural vibrations within an isogeometric framework using the NURBS basis functions. An analytical design sensitivity expression of repeated eigenvalues is derived. The developed method is demonstrated through several illustrative examples.      
### 65.Gaussian Process-Based Model Predictive Control for Overtaking  [ :arrow_down: ](https://arxiv.org/pdf/2101.09375.pdf)
>  This paper proposes a novel framework for addressing the challenge of autonomous overtaking and obstacle avoidance, which incorporates the overtaking path planning into Gaussian Process-based model predictive control (GPMPC). Compared with the conventional control strategies, this approach has two main advantages. Firstly, combining Gaussian Process (GP) regression with a nominal model allows for learning from model mismatch and unmodeled dynamics, which enhances a simple model and delivers significantly better results. Due to the approximation for propagating uncertainties, we can furthermore satisfy the constraints and thereby safety of the vehicle is ensured. Secondly, we convert the geometric relationship between the ego vehicle and other obstacle vehicles into the constraints. Without relying on a higherlevel path planner, this approach substantially reduces the computational burden. In addition, we transform the state constraints under the model predictive control (MPC) framework into a soft constraint and incorporate it as relaxed barrier function into the cost function, which makes the optimizer more efficient. Simulation results reveal the usefulness of the proposed approach.      
### 66.On Distributed Optimization in the Presence of Malicious Agents  [ :arrow_down: ](https://arxiv.org/pdf/2101.09347.pdf)
>  In this paper, we consider an unconstrained distributed optimization problem over a network of agents, in which some agents are adversarial. We solve the problem via gradient-based distributed optimization algorithm and characterize the effect of the adversarial agents on the convergence of the algorithm to the optimal solution. The attack model considered is such that agents locally perturb their iterates before broadcasting it to neighbors; and we analyze the case in which the adversarial agents cooperate in perturbing their estimates and the case where each adversarial agent acts independently. Based on the attack model adopted in the paper, we show that the solution converges to the neighborhood of the optimal solution and depends on the magnitude of the attack (perturbation) term. The analyses presented establishes conditions under which the malicious agents have enough information to obstruct convergence to the optimal solution by the non-adversarial agents.      
### 67.On the Local Linear Rate of Consensus on the Stiefel Manifold  [ :arrow_down: ](https://arxiv.org/pdf/2101.09346.pdf)
>  We study the convergence properties of Riemannian gradient method for solving the consensus problem (for an undirected connected graph) over the Stiefel manifold. The Stiefel manifold is a non-convex set and the standard notion of averaging in the Euclidean space does not work for this problem. We propose Distributed Riemannian Consensus on Stiefel Manifold (DRCS) and prove that it enjoys a local linear convergence rate to global consensus. More importantly, this local rate asymptotically scales with the second largest singular value of the communication matrix, which is on par with the well-known rate in the Euclidean space. To the best of our knowledge, this is the first work showing the equality of the two rates. The main technical challenges include (i) developing a Riemannian restricted secant inequality for convergence analysis, and (ii) to identify the conditions (e.g., suitable step-size and initialization) under which the algorithm always stays in the local region.      
### 68.Beurling-type density criteria for system identification  [ :arrow_down: ](https://arxiv.org/pdf/2101.09341.pdf)
>  This paper addresses the problem of identifying a linear time-varying (LTV) system characterized by a (possibly infinite) discrete set of delay-Doppler shifts without a lattice (or other geometry-discretizing) constraint on the support set. Concretely, we show that a class of such LTV systems is identifiable whenever the upper uniform Beurling density of the delay-Doppler support sets, measured uniformly over the class, is strictly less than 1/2. The proof of this result reveals an interesting relation between LTV system identification and interpolation in the Bargmann-Fock space. Moreover, we show that this density condition is also necessary for classes of systems invariant under time-frequency shifts and closed under a natural topology on the support sets. We furthermore show that identifiability guarantees robust recovery of the delay-Doppler support set, as well as the weights of the individual delay-Doppler shifts, both in the sense of asymptotically vanishing reconstruction error for vanishing measurement error.      
### 69.Robotic Knee Tracking Control to Mimic the Intact Human Knee Profile Based on Actor-critic Reinforcement Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.09334.pdf)
>  We address a state-of-the-art reinforcement learning (RL) control approach to automatically configure robotic prosthesis impedance parameters to enable end-to-end, continuous locomotion intended for transfemoral amputee subjects. Specifically, our actor-critic based RL provides tracking control of a robotic knee prosthesis to mimic the intact knee profile. This is a significant advance from our previous RL based automatic tuning of prosthesis control parameters which have centered on regulation control with a designer prescribed robotic knee profile as the target. In addition to presenting the complete tracking control algorithm based on direct heuristic dynamic programming (dHDP), we provide an analytical framework for the tracking controller with constrained inputs. We show that our proposed tracking control possesses several important properties, such as weight convergence of the learning networks, Bellman (sub)optimality of the cost-to-go value function and control input, and practical stability of the human-robot system under input constraint. We further provide a systematic simulation of the proposed tracking control using a realistic human-robot system simulator, the OpenSim, to emulate how the dHDP enables level ground walking, walking on different terrains and at different paces. These results show that our proposed dHDP based tracking control is not only theoretically suitable, but also practically useful.      
### 70.Rate of Prefix-free Codes in LQG Control Systems with Side Information  [ :arrow_down: ](https://arxiv.org/pdf/2101.09329.pdf)
>  In this work, we study LQG control systems where one of two feedback channels is discrete and incurs a communication cost, measured as time-averaged expected length of prefix-free codeword. This formulation to motivates a rate distortion problem, which we restrict to a particular policy space and express as a convex optimization. The optimization leads to a quantizer design and a subseqent achievability result.      

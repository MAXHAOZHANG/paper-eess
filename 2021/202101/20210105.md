# ArXiv eess --Tue, 5 Jan 2021
### 1.Deep Learning for Latent Events Forecasting in Twitter Aided Caching Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.01149.pdf)
>  A novel Twitter context aided content caching (TAC) framework is proposed for enhancing the caching efficiency by taking advantage of the legibility and massive volume of Twitter data. For the purpose of promoting the caching efficiency, three machine learning models are proposed to predict latent events and events popularity, utilizing collect Twitter data with geo-tags and geographic information of the adjacent base stations (BSs). Firstly, we propose a latent Dirichlet allocation (LDA) model for latent events forecasting taking advantage of the superiority of the LDA model in natural language processing (NLP). Then, we conceive long short-term memory (LSTM) with skip-gram embedding approach and LSTM with continuous skip-gram-Geo-aware embedding approach for the events popularity forecasting. Lastly, we associate the predicted latent events and the popularity of the events with the caching strategy. Extensive practical experiments demonstrate that: (1) The proposed TAC framework outperforms the conventional caching framework and is capable of being employed in practical applications thanks to the associating ability with public interests. (2) The proposed LDA approach conserves superiority for natural language processing (NLP) in Twitter data. (3) The perplexity of the proposed skip-gram-based LSTM is lower compared with the conventional LDA approach. (4) Evaluation of the model demonstrates that the hit rates of tweets of the model vary from 50% to 65% and the hit rate of the caching contents is up to approximately 75\% with smaller caching space compared to conventional algorithms.      
### 2.An Integrated Optimization Framework for Multi-Component Predictive Analytics in Wind Farm Operations &amp; Maintenance  [ :arrow_down: ](https://arxiv.org/pdf/2101.01084.pdf)
>  Recent years have seen an unprecedented growth in the use of sensor data to guide wind farm operations and maintenance. Emerging sensor-driven approaches typically focus on optimal maintenance procedures for single turbine systems, or model multiple turbines in wind farms as single component entities. In reality, turbines are composed of multiple components that dynamically interact throughout their lifetime. These interactions are central for realistic assessment and control of turbine failure risks. In this paper, an integrated framework that combines i) real-time degradation models used for predicting remaining life distribution of each component, with ii) mixed integer optimization models and solution algorithms used for identifying optimal wind farm maintenance and operations is proposed. Maintenance decisions identify optimal times to repair every component, which in turn, determine the failure risk of the turbines. More specifically, optimization models that characterize a turbine's failure time as the first time that one of its constituent components fail - a systems reliability concept called competing risk is developed. The resulting turbine failures impact the optimization of wind farm operations and revenue. Extensive experiments conducted for multiple wind farms with 300 wind turbines - 1200 components - showcases the performance of the proposed framework over conventional methods.      
### 3.Empirical Characterization of Air-to-ground Propagation at mm-Wave Frequencies in Dense Urban Environment  [ :arrow_down: ](https://arxiv.org/pdf/2101.01061.pdf)
>  In the present study, a measurement setup utilizing mm-wave transceivers with steerable directive antennas, mounted on both a customized UAV and a ground station has been used to study Air-to-Ground (A2G) radio links and, more generally, full-3D mm-wave propagation in urban environment. We evaluate the double-directional characteristics of the channel by rotating the antennas, deriving Power-Angle Profiles at both link ends. Preliminary results provide useful understanding of A2G propagation, e.g. the influence of the antenna tilt angles, or the mechanisms allowing for the signal to propagate from street canyons to the air.      
### 4.Underwater Image Enhancement based on Deep Learning and Image Formation Model  [ :arrow_down: ](https://arxiv.org/pdf/2101.00991.pdf)
>  Underwater robots play an important role in oceanic geological exploration, resource exploitation, ecological research, and other fields. However, the visual perception of underwater robots is affected by various environmental factors. The main challenge now is that images captured by underwater robots are color-distorted. The hue of underwater images tends to be close to green and blue. In addition, the contrast is low and the details are fuzzy. In this paper, a new underwater image enhancement method based on deep learning and image formation model is proposed. Experimental results show that the method proposed in this paper can eliminate the influence of underwater environmental factors, and the processed image has richer color, clearer details, and higher scores in PSNR and SSIM metrics. Moreover, it can help feature key-point point matching, get better results.      
### 5.Coherence and Concentration in Tightly-Connected Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.00981.pdf)
>  The ability to achieve coordinated behavior -- engineered or emergent -- on networked systems has attracted widespread interest over several fields. This interest has led to remarkable advances in developing a theoretical understanding of the conditions under which agents within a network can reach an agreement (consensus) or develop coordinated behavior, such as synchronization. However, much less understood is the phenomenon of network coherence. Network coherence generally refers to nodes' ability in a network to have a similar dynamic response despite heterogeneity in their individual behavior. In this paper, we develop a general framework to analyze and quantify the level of network coherence that a system exhibits by relating coherence with a low-rank property of the system. More precisely, for a networked system with linear dynamics and coupling, we show that, as the network connectivity grows, the system transfer matrix converges to a rank-one transfer matrix representing the coherent behavior. Interestingly, the non-zero eigenvalue of such a rank-one matrix is given by the harmonic mean of individual nodal dynamics, and we refer to it as the coherent dynamics. Our analysis unveils the frequency-dependent nature of coherence and a non-trivial interplay between dynamics and network topology. We further show that many networked systems can exhibit similar coherent behavior by establishing a concentration result in a setting with randomly chosen individual nodal dynamics.      
### 6.Towards Robust Data Hiding Against (JPEG) Compression: A Pseudo-Differentiable Deep Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2101.00973.pdf)
>  Data hiding is one widely used approach for protecting authentication and ownership. Most multimedia content like images and videos are transmitted or saved in the compressed form. This kind of lossy compression, such as JPEG, can destroy the hidden data, which raises the need of robust data hiding. It is still an open challenge to achieve the goal of data hiding that can be against these compressions. Recently, deep learning has shown large success in data hiding, while non-differentiability of JPEG makes it challenging to train a deep pipeline for improving robustness against lossy compression. The existing SOTA approaches replace the non-differentiable parts with differentiable modules that perform similar operations. Multiple limitations exist: (a) large engineering effort; (b) requiring a white-box knowledge of compression attacks; (c) only works for simple compression like JPEG. In this work, we propose a simple yet effective approach to address all the above limitations at once. Beyond JPEG, our approach has been shown to improve robustness against various image and video lossy compression algorithms.      
### 7.Relativistic Rocket Control (Relativistic Space-Travel Flight Control): Feedback Control of Relativistic Dynamics Propelled by Ejecting Mass  [ :arrow_down: ](https://arxiv.org/pdf/2101.00957.pdf)
>  In this short note, we investigate the feedback control of relativistic dynamics propelled by mass ejection, modeling, e.g., the relativistic rocket control or the relativistic (space-travel) flight control. As an extreme case, we also examine the control of relativistic photon rockets which are propelled by ejecting photons.      
### 8.Data-driven estimation of the maximum sampling interval: analysis and controller design for discrete-time systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.00903.pdf)
>  This article is concerned with data-driven analysis of discrete-time systems under aperiodic sampling, and in particular with a data-driven estimation of the maximum sampling interval (MSI). The MSI is relevant for analysis of and controller design for cyber-physical, embedded and networked systems, since it gives a limit on the time span between sampling instants such that stability is guaranteed. We propose tools to compute the MSI for a given controller and to design a controller with a preferably large MSI, both directly from a finite-length, noise-corrupted state-input trajectory of the system. We follow two distinct approaches for stability analysis, one taking a robust control perspective and the other a switched systems perspective on the aperiodically sampled system. In a numerical example and a subsequent discussion, we demonstrate the efficacy of our developed tools and compare the two approaches.      
### 9.A Mixed Integer Least-Squares Formulation of the GNSS Snapshot Positioning Problem  [ :arrow_down: ](https://arxiv.org/pdf/2101.00895.pdf)
>  This paper presents a formulation of Snapshot Positioning as a mixed-integer least-squares problem. In snapshot positioning one estimates a position from code-phase and possibly Doppler observations of a Global Navigation Satellite Systems (GNSS) without knowing the time of departure (time stamp) of the codes. Solving the problem allows a receiver to determine a fix from short radio-frequency snapshots missing the time-stamp information embedded in the GNSS data stream. This is used to reduced the time to first fix in some receivers, and it is used in certain wildlife trackers. This paper presents two new formulations of the problem and an algorithm that solves the resulting mixed-integer least-squares problems. We also show that the new formulations can produce fixes even with huge initial errors, much larger than permitted in Van Diggelen's widely-cited coarse-time navigation method.      
### 10.Symbolic Control for Stochastic Systems via Parity Games  [ :arrow_down: ](https://arxiv.org/pdf/2101.00834.pdf)
>  We consider the problem of computing the maximal probability of satisfying an $\omega$-regular specification for stochastic, continuous-state, nonlinear systems evolving in discrete time. The problem reduces, after automata-theoretic constructions, to finding the maximal probability of satisfying a parity condition on a (possibly hybrid) state space. While characterizing the exact satisfaction probability is open, we show that a lower bound on this probability can be obtained by (I) computing an under-approximation of the qualitative winning region, i.e., states from which the parity condition can be enforced almost surely, and (II) computing the maximal probability of reaching this qualitative winning region. The heart of our approach is a technique to symbolically compute the under-approximation of the qualitative winning region in step (I) via a finite-state abstraction of the original system as a $2\frac{1}{2}$-player parity game. Our abstraction procedure uses only the support of the probabilistic evolution; it does not use precise numerical transition probabilities. We prove that the winning set in the abstract $2\frac{1}{2}$-player game induces an under-approximation of the qualitative winning region in the original synthesis problem, along with a policy to solve it. By combining these contributions with (a) existing symbolic fixpoint algorithms to solve $2\frac{1}{2}$-player games and (b) existing techniques for reachability policy synthesis in stochastic nonlinear systems, we get an abstraction-based symbolic algorithm for finding a lower bound on the maximal satisfaction probability. We have implemented our approach and evaluated it on the nonlinear model of the perturbed Dubins vehicle.      
### 11.Single-shot fringe projection profilometry based on Deep Learning and Computer Graphics  [ :arrow_down: ](https://arxiv.org/pdf/2101.00814.pdf)
>  Multiple works have applied deep learning to fringe projection profilometry (FPP) in recent years. However, to obtain a large amount of data from actual systems for training is still a tricky problem, and moreover, the network design and optimization still worth exploring. In this paper, we introduce computer graphics to build virtual FPP systems in order to generate the desired datasets conveniently and simply. The way of constructing a virtual FPP system is described in detail firstly, and then some key factors to set the virtual FPP system much close to the reality are analyzed. With the aim of accurately estimating the depth image from only one fringe image, we also design a new loss function to enhance the quality of the overall and detailed information restored. And two representative networks, U-Net and pix2pix, are compared in multiple aspects. The real experiments prove the good accuracy and generalization of the network trained by the data from our virtual systems and the designed loss, implying the potential of our method for applications.      
### 12.A Reduced Codebook and Re-Interpolation Approach for Enhancing Quality in Chroma Subsampling  [ :arrow_down: ](https://arxiv.org/pdf/2101.00796.pdf)
>  Prior to encoding RGB full-color images or Bayer color filter array (CFA) images, chroma subsampling is a necessary and crucial step at the server side. In this paper, we first propose a flow diagram approach to analyze the coordinate-inconsistency (CI) problem and the upsampling process-inconsistency (UPI) problem existing in the traditional and state-of-the-art chroma subsampling methods under the current coding environment. In addition, we explain why the two problems degrade the quality of the reconstructed images. Next, we propose a reduced codebook and re-interpolation (RCRI) approach to solve the two problems for enhancing the quality of the reconstructed images. Based on the testing RGB full-color images and Bayer CFA images, the comprehensive experimental results demonstrated at least 1.4 dB and 2.4 dB quality improvement effects, respectively, of our RCRI approach against the CI and UPI problems for the traditional and state-of-the-art chroma subsampling methods.      
### 13.Optimal adaptive testing for epidemic control: combining molecular and serology tests  [ :arrow_down: ](https://arxiv.org/pdf/2101.00773.pdf)
>  The COVID-19 crisis highlighted the importance of non-medical interventions, such as testing and isolation of infected individuals, in the control of epidemics. Here, we show how to minimize testing needs while maintaining the number of infected individuals below a desired threshold. We find that the optimal policy is adaptive, with testing rates that depend on the epidemic state. Additionally, we show that such epidemic state is difficult to infer with molecular tests alone, which are highly sensitive but have a short detectability window. Instead, we propose the use of baseline serology testing, which is less sensitive but detects past infections, for the purpose of state estimation. Validation of such combined testing approach with a stochastic model of epidemics shows significant cost savings compared to non-adaptive testing strategies that are the current standard for COVID-19.      
### 14.Modeling RIS Empowered Outdoor-to-Indoor Communication in mmWave Cellular Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.00736.pdf)
>  With the increasing adoption of millimeter-waves (mmWave) over cellular networks, outdoor-to-indoor (O2I) communication has been one of the challenging research problems due to high penetration loss of buildings. To address this, we investigate the practicability of utilizing reconfigurable intelligent surfaces (RISs) for assisting such O2I communication. We propose a new notion of prefabricated RIS-empowered wall consisting of a large number of chipless radio frequency identification (RFID) sensors. Each sensor maintains its own bank of delay lines. These sensors which are built within the building walls can potentially be controlled by a main integrated circuit (IC) to regulate the phase of impinging signals. To evaluate our idea, we develop a thorough performance analysis of the RIS-based O2I communication in the mmWave network using stochastic-geometry tools for blockage models. Our analysis facilitates two closed-form approximations of the downlink signal-to-noise ratio (SNR) coverage probability for RIS-based O2I communication. We perform extensive simulations to evaluate the accuracy of the derived expressions, thus providing new observations and findings.      
### 15.Smart Black Box 2.0: Efficient High-bandwidth Driving Data Collection based on Video Anomalies  [ :arrow_down: ](https://arxiv.org/pdf/2101.00706.pdf)
>  Autonomous vehicles require fleet-wide data collection for continuous algorithm development and validation. The Smart Black Box (SBB) intelligent event data recorder has been proposed as a system for prioritized high-bandwidth data capture. This paper extends the SBB by applying anomaly detection and action detection methods for generalized event-of-interest (EOI) detection. An updated SBB pipeline is proposed for the real-time capture of driving video data. A video dataset is constructed to evaluate the SBB on real-world data for the first time. SBB performance is assessed by comparing the compression of normal and anomalous data and by comparing our prioritized data recording with a FIFO strategy. Results show that SBB data compression can increase the anomalous-to-normal storage ratio by ~100%, while the prioritized recording strategy saves ~25% fewer normal frames and ~50-100% more anomalous frames than a FIFO queue. We compare the real-world dataset SBB results to a baseline SBB given ground-truth anomaly labels and conclude that improved general EOI detection methods will greatly improve SBB performance.      
### 16.A Novel Multi-Stage Training Approach for Human Activity Recognition from Multimodal Wearable Sensor Data Using Deep Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2101.00702.pdf)
>  Deep neural network is an effective choice to automatically recognize human actions utilizing data from various wearable sensors. These networks automate the process of feature extraction relying completely on data. However, various noises in time series data with complex inter-modal relationships among sensors make this process more complicated. In this paper, we have proposed a novel multi-stage training approach that increases diversity in this feature extraction process to make accurate recognition of actions by combining varieties of features extracted from diverse perspectives. Initially, instead of using single type of transformation, numerous transformations are employed on time series data to obtain variegated representations of the features encoded in raw data. An efficient deep CNN architecture is proposed that can be individually trained to extract features from different transformed spaces. Later, these CNN feature extractors are merged into an optimal architecture finely tuned for optimizing diversified extracted features through a combined training stage or multiple sequential training stages. This approach offers the opportunity to explore the encoded features in raw sensor data utilizing multifarious observation windows with immense scope for efficient selection of features for final convergence. Extensive experimentations have been carried out in three publicly available datasets that provide outstanding performance consistently with average five-fold cross-validation accuracy of 99.29% on UCI HAR database, 99.02% on USC HAR database, and 97.21% on SKODA database outperforming other state-of-the-art approaches.      
### 17.CovTANet: A Hybrid Tri-level Attention Based Network for Lesion Segmentation, Diagnosis, and Severity Prediction of COVID-19 Chest CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2101.00691.pdf)
>  Rapid and precise diagnosis of COVID-19 is one of the major challenges faced by the global community to control the spread of this overgrowing pandemic. In this paper, a hybrid neural network is proposed, named CovTANet, to provide an end-to-end clinical diagnostic tool for early diagnosis, lesion segmentation, and severity prediction of COVID-19 utilizing chest computer tomography (CT) scans. A multi-phase optimization strategy is introduced for solving the challenges of complicated diagnosis at a very early stage of infection, where an efficient lesion segmentation network is optimized initially which is later integrated into a joint optimization framework for the diagnosis and severity prediction tasks providing feature enhancement of the infected regions. Moreover, for overcoming the challenges with diffused, blurred, and varying shaped edges of COVID lesions with novel and diverse characteristics, a novel segmentation network is introduced, namely Tri-level Attention-based Segmentation Network (TA-SegNet). This network has significantly reduced semantic gaps in subsequent encoding decoding stages, with immense parallelization of multi-scale features for faster convergence providing considerable performance improvement over traditional networks. Furthermore, a novel tri-level attention mechanism has been introduced, which is repeatedly utilized over the network, combining channel, spatial, and pixel attention schemes for faster and efficient generalization of contextual information embedded in the feature map through feature re-calibration and enhancement operations. Outstanding performances have been achieved in all three-tasks through extensive experimentation on a large publicly available dataset containing 1110 chest CT-volumes that signifies the effectiveness of the proposed scheme at the current stage of the pandemic.      
### 18.Multi-Party Dynamic State Estimation that Preserves Data and Model Privacy  [ :arrow_down: ](https://arxiv.org/pdf/2101.00666.pdf)
>  In this paper we focus on the dynamic state estimation which harnesses a vast amount of sensing data harvested by multiple parties and recognize that in many applications, to improve collaborations between parties, the estimation procedure must be designed with the awareness of protecting participants' data and model privacy, where the latter refers to the privacy of key parameters of observation models. We develop a state estimation paradigm for the scenario where multiple parties with data and model privacy concerns are involved. Multiple parties monitor a physical dynamic process by deploying their own sensor networks and update the state estimate according to the average state estimate of all the parties calculated by a cloud server and security module. The paradigm taps additively homomorphic encryption which enables the cloud server and security module to jointly fuse parties' data while preserving the data privacy. Meanwhile, all the parties collaboratively develop a stable (or optimal) fusion rule without divulging sensitive model information. For the proposed filtering paradigm, we analyze the stabilization and the optimality. First, to stabilize the multi-party state estimator while preserving observation model privacy, two stabilization design methods are proposed. For special scenarios, the parties directly design their estimator gains by the matrix norm relaxation. For general scenarios, after transforming the original design problem into a convex semi-definite programming problem, the parties collaboratively derive suitable estimator gains based on the ADMM. Second, an optimal collaborative gain design method with model privacy guarantees is provided, which results in the asymptotic MMSE state estimation. Finally, numerical examples are presented to illustrate our design and theoretical findings.      
### 19.A scheduling algorithm for networked control systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.00649.pdf)
>  This paper deals with the design of scheduling logics for Networked Control Systems (NCSs) whose shared communication networks have limited capacity. We assume that among \(N\) plants, only \(M\:(&lt; N)\) plants can communicate with their controllers at any time instant. We present an algorithm to allocate the network to the plants periodically such that stability of each plant is preserved. The main apparatus for our analysis is a switched systems representation of the individual plants in an NCS. We rely on multiple Lyapunov-like functions and graph-theoretic arguments to design our scheduling logics. The set of results presented in this paper is a continuous-time counterpart of the results proposed in [15]. We present a set of numerical experiments to demonstrate the performance of our techniques.      
### 20.In-Ear SpO2 for Classification of Cognitive Workload  [ :arrow_down: ](https://arxiv.org/pdf/2101.00647.pdf)
>  Classification of cognitive workload promises immense benefit in diverse areas ranging from driver safety to augmenting human capability through closed loop brain computer interface. The brain is the most metabolically active organ in the body and increases its metabolic activity and thus oxygen consumption with increasing cognitive demand. In this study, we explore the feasibility of in-ear SpO2 cognitive workload tracking. To this end, we preform cognitive workload assessment in 8 subjects, based on an N-back task, whereby the subjects are asked to count and remember the number of odd numbers displayed on a screen in 5 second windows. The 2 and 3-back tasks lead to either the lowest median absolute SpO2 or largest median decrease in SpO2 in all of the subjects, indicating a robust and measurable decrease in blood oxygen in response to increased cognitive workload. Using features derived from in-ear pulse oximetry, including SpO2, pulse rate and respiration rate, we were able to classify the 4 N-back task categories, over 5 second epochs, with a mean accuracy of 94.2%. Moreover, out of 21 total features, the 9 most important features for classification accuracy were all SpO2 related features. The findings suggest that in-ear SpO2 measurements provide valuable information for classification of cognitive workload over short time windows, which together with the small form factor promises a new avenue for real time cognitive workload tracking.      
### 21.Target Control of Asynchronous Boolean Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.00644.pdf)
>  We study the target control of asynchronous Boolean networks, to identify efficacious interventions that can drive the dynamics of a given Boolean network from any initial state to the desired target attractor. Based on the application time, the control can be realised with three types of perturbations, including instantaneous, temporary and permanent perturbations. We develop efficient methods to compute the target control for a given target attractor with three types of perturbations. We compare our methods with the stable motif-based control on a variety of real-life biological networks to evaluate their performance. We show that our methods scale well for large Boolean networks and they are able to identify a rich set of solutions with a small number of perturbations.      
### 22.Nonlinear Incremental Control for Flexible Aircraft Trajectory Tracking and Load Alleviation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00594.pdf)
>  This paper proposes a nonlinear control architecture for flexible aircraft simultaneous trajectory tracking and load alleviation. By exploiting the control redundancy, the gust and maneuver loads are alleviated without degrading the rigid-body command tracking performance. The proposed control architecture contains four cascaded control loops: position control, flight path control, attitude control, and optimal multi-objective wing control. Since the position kinematics are not influenced by model uncertainties, the nonlinear dynamic inversion control is applied. On the contrary, the flight path dynamics are perturbed by both model uncertainties and atmospheric disturbances; thus the incremental sliding mode control is adopted. Lyapunov-based analyses show that this method can simultaneously reduce the model dependency and the minimum possible gains of conventional sliding mode control methods. Moreover, the attitude dynamics are in the strict-feedback form; thus the incremental backstepping sliding mode control is applied. Furthermore, a novel load reference generator is designed to distinguish the necessary loads for performing maneuvers from the excessive loads. The load references are realized by the inner-loop optimal wing controller, while the excessive loads are naturalized by flaps without influencing the outer-loop tracking performance. The merits of the proposed control architecture are verified by trajectory tracking tasks and gust load alleviation tasks in spatial von Karman turbulence fields.      
### 23.RegNet: Self-Regulated Network for Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2101.00590.pdf)
>  The ResNet and its variants have achieved remarkable successes in various computer vision tasks. Despite its success in making gradient flow through building blocks, the simple shortcut connection mechanism limits the ability of re-exploring new potentially complementary features due to the additive function. To address this issue, in this paper, we propose to introduce a regulator module as a memory mechanism to extract complementary features, which are further fed to the ResNet. In particular, the regulator module is composed of convolutional RNNs (e.g., Convolutional LSTMs or Convolutional GRUs), which are shown to be good at extracting Spatio-temporal information. We named the new regulated networks as RegNet. The regulator module can be easily implemented and appended to any ResNet architecture. We also apply the regulator module for improving the Squeeze-and-Excitation ResNet to show the generalization ability of our method. Experimental results on three image classification datasets have demonstrated the promising performance of the proposed architecture compared with the standard ResNet, SE-ResNet, and other state-of-the-art architectures.      
### 24.Towards Annotation-free Instance Segmentation and Tracking with Adversarial Simulations  [ :arrow_down: ](https://arxiv.org/pdf/2101.00567.pdf)
>  Quantitative analysis of microscope videos often requires instance segmentation and tracking of cellular and subcellular objects. Traditional method is composed of two stages: (1) instance object segmentation of each frame, and (2) associate objects frame by frame. Recently, pixel embedding based deep learning approaches provide single stage holistic solutions to tackle instance segmentation and tracking simultaneously. However, the deep learning methods require consistent annotations not only spatially (for segmentation), but also temporally (for tracking). In computer vision, annotated training data with consistent segmentation and tracking is resource intensive, which can be more severe in microscopy imaging owing to (1) dense objects (e.g., overlapping or touching), and (2) high dynamics (e.g., irregular motion and mitosis). To alleviate the lack of such annotations in dynamics scenes, adversarial simulations have provided successful solutions in computer vision, such as using simulated environments (e.g., computer games) to train real-world self-driving systems. In this paper, we proposed an annotation-free synthetic instance segmentation and tracking (ASIST) method with adversarial simulation and single-stage pixel-embedding based learning. The contribution is three-fold: (1) the proposed method aggregates adversarial simulations and single-stage pixel-embedding based deep learning; (2) the method is assessed with both cellular (i.e., HeLa cells) and subcellular (i.e., microvilli) objects; and (3) to the best of our knowledge, this is the first study to explore annotation-free instance segmentation and tracking study for microscope videos. From the results, our ASIST method achieved promising results compared with fully supervised approaches.      
### 25.Airplane-Aided Integrated Next-Generation Networking  [ :arrow_down: ](https://arxiv.org/pdf/2101.00566.pdf)
>  A high-rate yet low-cost air-to-ground (A2G) communication backbone is conceived for integrating the space and terrestrial network by harnessing the opportunistic assistance of the passenger planes or high altitude platforms (HAPs) as mobile base stations (BSs) and millimetre wave communication. The airliners act as the network-provider for the terrestrial users while relying on satellite backhaul. A null-steered beamforming technique relying on a large-scale planar array is used for transmission by the airliner/HAP for achieving a high directional gain, hence minimizing the interference between the users. Furthermore, approximate spectral efficiency (SE) and area spectral efficiency (ASE) expressions are derived and quantified for diverse system parameters.      
### 26.Zero-dynamics Attack, Variations, and Countermeasures  [ :arrow_down: ](https://arxiv.org/pdf/2101.00556.pdf)
>  This chapter presents an overview on actuator attacks that exploit zero dynamics, and countermeasures against them. First, zero-dynamics attack is re-introduced based on a canonical representation called normal form. Then it is shown that the target dynamic system is at elevated risk if the associated zero dynamics is unstable. From there on, several questions are raised in series to ensure when the target system is immune to the attack of this kind. The first question is: Is the target system secure from zero-dynamics attack if it does not have any unstable zeros? An answer provided for this question is: No, the target system may still be at risk due to another attack surface emerging in the process of implementation. This is followed by a series of next questions, and in the course of providing answers, variants of the classic zero-dynamics attack are presented, from which the vulnerability of the target system is explored in depth. At the end, countermeasures are proposed to render the attack ineffective. Because it is known that the zero-dynamics in continuous-time systems cannot be modified by feedback, the main idea of the countermeasure is to relocate any unstable zero to a stable region in the stage of digital implementation through modified digital samplers and holders. Adversaries can still attack actuators, but due to the re-located zeros, they are of little use in damaging the target system.      
### 27.RV-GAN : Retinal Vessel Segmentation from Fundus Images using Multi-scale Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.00535.pdf)
>  Retinal vessel segmentation contributes significantly to the domain of retinal image analysis for the diagnosis of vision-threatening diseases. With existing techniques the generated segmentation result deteriorates when thresholded with higher confidence value. To alleviate from this, we propose RVGAN, a new multi-scale generative architecture for accurate retinal vessel segmentation. Our architecture uses two generators and two multi-scale autoencoder based discriminators, for better microvessel localization and segmentation. By combining reconstruction and weighted feature matching loss, our adversarial training scheme generates highly accurate pixel-wise segmentation of retinal vessels with threshold &gt;= 0.5. The architecture achieves AUC of 0.9887, 0.9814, and 0.9887 on three publicly available datasets, namely DRIVE, CHASE-DB1, and STARE, respectively. Additionally, RV-GAN outperforms other architectures in two additional relevant metrics, Mean-IOU and SSIM.      
### 28.Multi-stage Deep Layer Aggregation for Brain Tumor Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00490.pdf)
>  Gliomas are among the most aggressive and deadly brain tumors. This paper details the proposed Deep Neural Network architecture for brain tumor segmentation from Magnetic Resonance Images. The architecture consists of a cascade of three Deep Layer Aggregation neural networks, where each stage elaborates the response using the feature maps and the probabilities of the previous stage, and the MRI channels as inputs. The neuroimaging data are part of the publicly available Brain Tumor Segmentation (BraTS) 2020 challenge dataset, where we evaluated our proposal in the BraTS 2020 Validation and Test sets. In the Test set, the experimental results achieved a Dice score of 0.8858, 0.8297 and 0.7900, with an Hausdorff Distance of 5.32 mm, 22.32 mm and 20.44 mm for the whole tumor, core tumor and enhanced tumor, respectively.      
### 29.Combining unsupervised and supervised learning for predicting the final stroke lesion  [ :arrow_down: ](https://arxiv.org/pdf/2101.00489.pdf)
>  Predicting the final ischaemic stroke lesion provides crucial information regarding the volume of salvageable hypoperfused tissue, which helps physicians in the difficult decision-making process of treatment planning and intervention. Treatment selection is influenced by clinical diagnosis, which requires delineating the stroke lesion, as well as characterising cerebral blood flow dynamics using neuroimaging acquisitions. Nonetheless, predicting the final stroke lesion is an intricate task, due to the variability in lesion size, shape, location and the underlying cerebral haemodynamic processes that occur after the ischaemic stroke takes place. Moreover, since elapsed time between stroke and treatment is related to the loss of brain tissue, assessing and predicting the final stroke lesion needs to be performed in a short period of time, which makes the task even more complex. Therefore, there is a need for automatic methods that predict the final stroke lesion and support physicians in the treatment decision process. We propose a fully automatic deep learning method based on unsupervised and supervised learning to predict the final stroke lesion after 90 days. Our aim is to predict the final stroke lesion location and extent, taking into account the underlying cerebral blood flow dynamics that can influence the prediction. To achieve this, we propose a two-branch Restricted Boltzmann Machine, which provides specialized data-driven features from different sets of standard parametric Magnetic Resonance Imaging maps. These data-driven feature maps are then combined with the parametric Magnetic Resonance Imaging maps, and fed to a Convolutional and Recurrent Neural Network architecture. We evaluated our proposal on the publicly available ISLES 2017 testing dataset, reaching a Dice score of 0.38, Hausdorff Distance of 29.21 mm, and Average Symmetric Surface Distance of 5.52 mm.      
### 30.CryoNuSeg: A Dataset for Nuclei Instance Segmentation of Cryosectioned H&amp;E-Stained Histological Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.00442.pdf)
>  Nuclei instance segmentation plays an important role in the analysis of Hematoxylin and Eosin (H&amp;E)-stained images. While supervised deep learning (DL)-based approaches represent the state-of-the-art in automatic nuclei instance segmentation, annotated datasets are required to train these models. There are two main types of tissue processing protocols, namely formalin-fixed paraffin-embedded samples (FFPE) and frozen tissue samples (FS). Although FFPE-derived H&amp;E stained tissue sections are the most widely used samples, H&amp;E staining on frozen sections derived from FS samples is a relevant method in intra-operative surgical sessions as it can be performed fast. Due to differences in the protocols of these two types of samples, the derived images and in particular the nuclei appearance may be different in the acquired whole slide images. Analysis of FS-derived H&amp;E stained images can be more challenging as rapid preparation, staining, and scanning of FS sections may lead to deterioration in image quality. <br>In this paper, we introduce CryoNuSeg, the first fully annotated FS-derived cryosectioned and H&amp;E-stained nuclei instance segmentation dataset. The dataset contains images from 10 human organs that were not exploited in other publicly available datasets, and is provided with three manual mark-ups to allow measuring intra-observer and inter-observer variability. Moreover, we investigate the effects of tissue fixation/embedding protocol (i.e., FS or FFPE) on the automatic nuclei instance segmentation performance of one of the state-of-the-art DL approaches. We also create a baseline segmentation benchmark for the dataset that can be used in future research. <br>A step-by-step guide to generate the dataset as well as the full dataset and other detailed information are made available to fellow researchers at <a class="link-external link-https" href="https://github.com/masih4/CryoNuSeg" rel="external noopener nofollow">this https URL</a>.      
### 31.A Thickness Sensitive Vessel Extraction Framework for Retinal and Conjunctival Vascular Tortuosity Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.00435.pdf)
>  Systemic diseases such as diabetes, hypertension, atherosclerosis are among the leading causes of annual human mortality rate. It is suggested that retinal and conjunctival vascular tortuosity is a potential biomarker for such systemic diseases. Most importantly, it is observed that the tortuosity depends on the thickness of these vessels. Therefore, selective calculation of tortuosity within specific vessel thicknesses is required depending on the disease being analysed. In this paper, we propose a thickness sensitive vessel extraction framework that is primarily applicable for studies related to retinal and conjunctival vascular tortuosity. The framework uses a Convolutional Neural Network based on the IterNet architecture to obtain probability maps of the entire vasculature. They are then processed by a multi-scale vessel enhancement technique that exploits both fine and coarse structural vascular details of these probability maps in order to extract vessels of specified thicknesses. We evaluated the proposed framework on four datasets including DRIVE and SBVPI, and obtained Matthew's Correlation Coefficient values greater than 0.71 for all the datasets. In addition, the proposed framework was utilized to determine the association of diabetes with retinal and conjunctival vascular tortuosity. We observed that retinal vascular tortuosity (Eccentricity based Tortuosity Index) of the diabetic group was significantly higher (p &lt; .05) than that of the non-diabetic group and that conjunctival vascular tortuosity (Total Curvature normalized by Arc Length) of diabetic group was significantly lower (p &lt; .05) than that of the non-diabetic group. These observations were in agreement with the literature, strengthening the suitability of the proposed framework.      
### 32.Non-line-of-Sight Imaging via Neural Transient Fields  [ :arrow_down: ](https://arxiv.org/pdf/2101.00373.pdf)
>  We present a neural modeling framework for Non-Line-of-Sight (NLOS) imaging. Previous solutions have sought to explicitly recover the 3D geometry (e.g., as point clouds) or voxel density (e.g., within a pre-defined volume) of the hidden scene. In contrast, inspired by the recent Neural Radiance Field (NeRF) approach, we use a multi-layer perceptron (MLP) to represent the neural transient field or NeTF. However, NeTF measures the transient over spherical wavefronts rather than the radiance along lines. We therefore formulate a spherical volume NeTF reconstruction pipeline, applicable to both confocal and non-confocal setups. Compared with NeRF, NeTF samples a much sparser set of viewpoints (scanning spots) and the sampling is highly uneven. We thus introduce a Monte Carlo technique to improve the robustness in the reconstruction. Comprehensive experiments on synthetic and real datasets demonstrate NeTF provides higher quality reconstruction and preserves fine details largely missing in the state-of-the-art.      
### 33.Quaternion higher-order singular value decomposition and its applications in color image processing  [ :arrow_down: ](https://arxiv.org/pdf/2101.00364.pdf)
>  Higher-order singular value decomposition (HOSVD) is one of the most efficient tensor decomposition techniques. It has the salient ability to represent high_dimensional data and extract features. In more recent years, the quaternion has proven to be a very suitable tool for color pixel representation as it can well preserve cross-channel correlation of color channels. Motivated by the advantages of the HOSVD and the quaternion tool, in this paper, we generalize the HOSVD to the quaternion domain and define quaternion-based HOSVD (QHOSVD). Due to the non-commutability of quaternion multiplication, QHOSVD is not a trivial extension of the HOSVD. They have similar but different calculation procedures. The defined QHOSVD can be widely used in various visual data processing with color pixels. In this paper, we present two applications of the defined QHOSVD in color image processing: multi_focus color image fusion and color image denoising. The experimental results on the two applications respectively demonstrate the competitive performance of the proposed methods over some existing ones.      
### 34.Design of an Enhanced Reconfigurable Chaotic Oscillator using G4FET-NDR Based Discrete Map  [ :arrow_down: ](https://arxiv.org/pdf/2101.00334.pdf)
>  In this paper, a novel chaotic map is introduced usinga voltage controlled negative differential resistance (NDR) circuitcomposed of ann-channel and ap-channel silicon-on-insulator(SOI) four-gate transistor (G4FET). The multiple gates of theG4FET are leveraged to create a discrete chaotic map with threebifurcation parameters. The three tunable parameters are thegain of a transimpedance amplifier (TIA), top-gate voltage ofn-channel G4FET, and top-gate voltage ofp-channel G4FET. Twomethods are proposed for building chaotic oscillators using thisdiscrete map. The effect of altering bifurcation parameters onchaotic operation is illustrated using bifurcation diagrams andLyapunov exponent. A design methodology for building flexibleand reconfigurable logic gate is outlined and the consequentenhancement in functionality space caused by the existence ofthree independent bifurcation parameters is demonstrated andcompared with previous work.      
### 35.Deep Reinforcement Learning-based Anti-jamming Power Allocation in a Two-cell NOMA Network  [ :arrow_down: ](https://arxiv.org/pdf/2101.00270.pdf)
>  The performance of Non-orthogonal Multiple Access (NOMA) system dramatically decreases in the presence of inter-cell interference. This condition gets more challenging if a smart jammer is interacting in a network. In this paper, the NOMA power allocation of two independent Base Stations (BSs) against a smart jammer is, modeled as a sequential game. In this game, at first, each BS as a leader independently chooses its power allocation strategy. Then, the smart jammer as the follower selects its optimal strategy based on the strategies of the BSs. The solutions of this game are, derived under different conditions. Based on the game-theoretical analysis, three new schemes are proposed for anti-jamming NOMA power allocation in a two-cell scenario called a) Q-Learning based Unselfish (QLU) NOMA power allocation scheme, b) Deep Q-Learning based Unselfish (DQLU) NOMA power allocation scheme, and c) Hot Booting Deep Q-Learning based Unselfish (HBDQLU) NOMA power allocation scheme. In these methods the BSs do not coordinate with each other. But our analysis theoretically predicts that with high probability, the proposed methods will converge to the optimal strategy from the total network point of view. Simulation results show the convergence of the proposed schemes and also their outperformance with respect to the Q-Learning-based Selfish (QLS) NOMA power allocation method.      
### 36.Formation Flight Control of Multi-UAV System Using Neighbor-based Trajectory Generation Topology  [ :arrow_down: ](https://arxiv.org/pdf/2101.00264.pdf)
>  In this paper, a distributed formation flight control topology for Leader-Follower formation structure is presented. Such topology depends in the first place on online generation of the trajectories that should be followed by the agents in the formation. The trajectory of each agent is planned during execution depending on its neighbors and considering that the desired reference trajectory is only given to the leader. Simulation using MATLAB/SIMULINK is done on a formation of quadrotor UAVs to illustrate the proposed method. The topology shows very good results in achieving the formation and following the reference trajectory.      
### 37.Cutting-edge 3D Medical Image Segmentation Methods in 2020: Are Happy Families All Alike?  [ :arrow_down: ](https://arxiv.org/pdf/2101.00232.pdf)
>  Segmentation is one of the most important and popular tasks in medical image analysis, which plays a critical role in disease diagnosis, surgical planning, and prognosis evaluation. During the past five years, on the one hand, thousands of medical image segmentation methods have been proposed for various organs and lesions in different medical images, which become more and more challenging to fairly compare different methods. On the other hand, international segmentation challenges can provide a transparent platform to fairly evaluate and compare different methods. In this paper, we present a comprehensive review of the top methods in ten 3D medical image segmentation challenges during 2020, covering a variety of tasks and datasets. We also identify the "happy-families" practices in the cutting-edge segmentation methods, which are useful for developing powerful segmentation approaches. Finally, we discuss open research problems that should be addressed in the future. We also maintain a list of cutting-edge segmentation methods at \url{<a class="link-external link-https" href="https://github.com/JunMa11/SOTA-MedSeg" rel="external noopener nofollow">this https URL</a>}.      
### 38.Energy-Efficient Resource Allocation for 5G Cognitive Radio NOMA Using Game Theory  [ :arrow_down: ](https://arxiv.org/pdf/2101.00225.pdf)
>  Cognitive radio non-orthogonal multiple access (CR-NOMA) networks promise improved spectrum utilization and capacity in 5G networks. In this work, we aim to investigate efficient power allocation for the secondary users (SUs) in underlay CR-NOMA networks using a game-theoretic approach. We present a novel power allocation to CR-NOMA network from a game-theoretic perspective. First, we specify the utility function of the primary users (PUs) and SUs, and formulate the game as a non-cooperative game. Then, the existence and uniqueness of the Nash equilibrium (NE) are investigated. Finally, the sum utilities of SUs is maximized by optimal power allocation at the NE point. Simulation results provided that the proposed scheme outperforms the conventional method, providing up to 37.5\% increase in sum utilities of the SUs.      
### 39.Online Discriminative Graph Learning from Multi-Class Smooth Signals  [ :arrow_down: ](https://arxiv.org/pdf/2101.00184.pdf)
>  Graph signal processing (GSP) is a key tool for satisfying the growing demand for information processing over networks. However, the success of GSP in downstream learning and inference tasks is heavily dependent on the prior identification of the relational structures. Graphs are natural descriptors of the relationships between entities of complex environments. The underlying graph is not readily detectable in many cases and one has to infer the topology from the observed signals. Firstly, we address the problem of graph signal classification by proposing a novel framework for discriminative graph learning. To learn discriminative graphs, we invoke the assumption that signals belonging to each class are smooth with respect to the corresponding graph while maintaining non-smoothness with respect to the graphs corresponding to other classes. Secondly, we extend our work to tackle increasingly dynamic environments and real-time topology inference. We develop a proximal gradient (PG) method which can be adapted to situations where the data are acquired on-the-fly. Beyond discrimination, this is the first work that addresses the problem of dynamic graph learning from smooth signals where the sought network alters slowly. The validation of the proposed frameworks is comprehensively investigated using both synthetic and real data.      
### 40.ECG-Based Driver Stress Levels Detection System Using Hyperparameter Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2101.00165.pdf)
>  Stress and driving are a dangerous combination which can lead to crashes, as evidenced by the large number of road traffic crashes that involve stress. Motivated by the need to address the significant costs of driver stress, it is essential to build a practical system that can classify driver stress level with high accuracy. However, the performance of an accurate driving stress levels classification system depends on hyperparameter optimization choices such as data segmentation (windowing hyperparameters). The configuration setting of hyperparameters, which has an enormous impact on the system performance, are typically hand-tuned while evaluating the algorithm. This tuning process is time consuming and often depends on personal experience. There are also no generic optimal values for hyperparameters values. In this work, we propose a meta-heuristic approach to support automated hyperparameter optimization and provide a real-time driver stress detection system. This is the first systematic study of optimizing windowing hyperparameters based on Electrocardiogram (ECG) signal in the domain of driving safety. Our approach is to propose a framework based on Particle Swarm Optimization algorithm (PSO) to select an optimal/near optimal windowing hyperparameters values. The performance of the proposed framework is evaluated on two datasets: a public dataset (DRIVEDB dataset) and our collected dataset using an advanced simulator. DRIVEDB dataset was collected in a real time driving scenario, and our dataset was collected using an advanced driving simulator in the control environment. We demonstrate that optimising the windowing hyperparameters yields significant improvement in terms of accuracy. The most accurate built model applied to the public dataset and our dataset, based on the selected windowing hyperparameters, achieved 92.12% and 77.78% accuracy, respectively.      
### 41.Design of heterogeneous multi-agent system for distributed computation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00161.pdf)
>  A group behavior of a heterogeneous multi-agent system is studied which obeys an "average of individual vector fields" under strong couplings among the agents. Under stability of the averaged dynamics (not asking stability of individual agents), the behavior of heterogeneous multi-agent system can be estimated by the solution to the averaged dynamics. A following idea is to "design" individual agent's dynamics such that the averaged dynamics performs the desired task. A few applications are discussed including estimation of the number of agents in a network, distributed least-squares or median solver, distributed optimization, distributed state estimation, and robust synchronization of coupled oscillators. Since stability of the averaged dynamics makes the initial conditions forgotten as time goes on, these algorithms are initialization-free and suitable for plug-and-play operation. At last, nonlinear couplings are also considered, which potentially asserts that enforced synchronization gives rise to an emergent behavior of a heterogeneous multi-agent system.      
### 42.Multi-Grid Back-Projection Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.00150.pdf)
>  Multi-Grid Back-Projection (MGBP) is a fully-convolutional network architecture that can learn to restore images and videos with upscaling artifacts. Using the same strategy of multi-grid partial differential equation (PDE) solvers this multiscale architecture scales computational complexity efficiently with increasing output resolutions. The basic processing block is inspired in the iterative back-projection (IBP) algorithm and constitutes a type of cross-scale residual block with feedback from low resolution references. The architecture performs in par with state-of-the-arts alternatives for regression targets that aim to recover an exact copy of a high resolution image or video from which only a downscale image is known. A perceptual quality target aims to create more realistic outputs by introducing artificial changes that can be different from a high resolution original content as long as they are consistent with the low resolution input. For this target we propose a strategy using noise inputs in different resolution scales to control the amount of artificial details generated in the output. The noise input controls the amount of innovation that the network uses to create artificial realistic details. The effectiveness of this strategy is shown in benchmarks and it is explained as a particular strategy to traverse the perception-distortion plane.      
### 43.Coherent optical communications using coherence-cloned Kerr soliton microcombs  [ :arrow_down: ](https://arxiv.org/pdf/2101.00137.pdf)
>  Dissipative Kerr soliton microcomb has been recognized as a promising on-chip multi-wavelength laser source for fiber optical communications, as its comb lines possess frequency and phase stability far beyond independent lasers. In the scenarios of coherent optical transmission and interconnect, a highly beneficial but rarely explored target is to re-generate a Kerr soliton microcomb at the receiver side as local oscillators that conserve the frequency and phase property of the incoming data carriers, so that to enable coherent detection with minimized optical and electrical compensations. Here, by using the techniques of pump laser conveying and two-point locking, we implement re-generation of a Kerr soliton microcomb that faithfully clones the frequency and phase coherence of another microcomb sent from 50 km away. Moreover, leveraging the coherence-cloned soliton microcombs as carriers and local oscillators, we demonstrate terabit coherent data interconnect, wherein traditional digital processes for frequency offset estimation is totally dispensed with, and carrier phase estimation is substantially simplified via slowed-down phase estimation rate per channel and joint phase estimation among multiple channels. Our work reveals that, in addition to providing a multitude of laser tones, regulating the frequency and phase of Kerr soliton microcombs among transmitters and receivers can significantly improve coherent communication in terms of performance, power consumption, and simplicity.      
### 44.Audio Content Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2101.00132.pdf)
>  Preprint for a book chapter introducing Audio Content Analysis. With a focus on Music Information Retrieval systems, this chapter defines musical audio content, introduces the general process of audio content analysis, and surveys basic approaches to audio content analysis. The various tasks in Audio Content Analysis are categorized into three classes: music transcription, music performance analysis, and music identification and categorization. The examples for music transcription systems include music key detection, fundamental frequency detection, and music structure detection. Music performance analysis systems feature an overview of beat and tempo detection approaches as well as music performance assessment. The covered music classification systems are audio fingerprinting, music genre classification, and music emotion recognition. The chapter concludes with a discussion and current challenges in the field and a speculation on future perspectives.      
### 45.Energy Performance Analysis of Distributed Renewables: Pacific Northwest Smart Grid Demonstration  [ :arrow_down: ](https://arxiv.org/pdf/2101.00115.pdf)
>  The Pacific Northwest Smart Grid Demonstration was an electricity grid modernization project conducted in the Northwest U.S. This paper presents the analysis of renewable generation at the Renewable Energy Park located in the City of Ellensburg, WA. The community energy park concept is an intriguing model for community investment in renewable resources,but the lessons in this paper should be considered.      
### 46.A Zonal Volt/VAR Control Mechanism for High PV Penetration Distribution Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.00106.pdf)
>  This paper presents a zonal Volt/VAR control scheme that coordinates Photovoltaic (PV) inverters for providing voltage regulation on 3-phase unbalanced distribution feeders. Voltage sensitivity studies are conducted to uncover the dependency between nodal voltage changes and the reactive power injections at nodes with smart PV inverters. A fast incremental clustering method is developed to divide the distribution feeder into weakly coupled zones based on correlations of nodal voltage sensitivities. Because each zone is weakly coupled, voltage of each zone can be controlled independently. Thus, in each zone, a rule-based voltage controller will dispatch PV smart inverters to provide reactive power control for correcting the over/under voltages. An actual distribution feeder in North Carolina is used as a test bed. Simulation results show that the proposed zonal based Volt/VAR control mechanism can maintain the voltage in the distribution system within limits and solves faster than the centralized controller.      
### 47.Toward Reliable Designs of Data-Driven Reinforcement Learning Tracking Control for Euler-Lagrange Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.00068.pdf)
>  This paper addresses reinforcement learning based, direct signal tracking control with an objective of developing mathematically suitable and practically useful design approaches. Specifically, we aim to provide reliable and easy to implement designs in order to reach reproducible neural network-based solutions. Our proposed new design takes advantage of two control design frameworks: a reinforcement learning based, data-driven approach to provide the needed adaptation and (sub)optimality, and a backstepping based approach to provide closed-loop system stability framework. We develop this work based on an established direct heuristic dynamic programming (dHDP) learning paradigm to perform online learning and adaptation and a backstepping design for a class of important nonlinear dynamics described as Euler-Lagrange systems. We provide a theoretical guarantee for the stability of the overall dynamic system, weight convergence of the approximating nonlinear neural networks, and the Bellman (sub)optimality of the resulted control policy. We use simulations to demonstrate significantly improved design performance of the proposed approach over the original dHDP.      
### 48.Successive Null-Space Precoder Design for Downlink MU-MIMO with Rate Splitting and Single-Stage SIC  [ :arrow_down: ](https://arxiv.org/pdf/2101.01147.pdf)
>  In this paper, we consider the precoder design for an under-loaded or critically loaded downlink multi-user multiple-input multiple-output (MU-MIMO) communication system. We propose novel precoding and decoding schemes which enhance system performance based on rate splitting at the transmitter and single-stage successive interference cancellation at the receivers. The proposed successive null-space (SNS) precoding scheme utilizes linear combinations of the null-space basis vectors of the successively augmented MIMO channel matrices of the users as precoding vectors to adjust the inter-user-interference experienced by the receivers. We formulate a non-convex weighted sum rate (WSR) optimization problem, and solve it via successive convex approximation to obtain a suboptimal solution for the precoding vectors and the associated power allocation. Our simulation results reveal that the proposed SNS precoders outperform block diagonalization based linear and rate splitting designs, and in many cases, have a relatively small gap to the maximum sum rate achieved by dirty paper coding.      
### 49.High-bandwidth nonlinear control for soft actuators with recursive network models  [ :arrow_down: ](https://arxiv.org/pdf/2101.01139.pdf)
>  We present a high-bandwidth, lightweight, and nonlinear output tracking technique for soft actuators that combines parsimonious recursive layers for forward output predictions and online optimization using Newton-Raphson. This technique allows for reduced model sizes and increased control loop frequencies when compared with conventional RNN models. Experimental results of this controller prototype on a single soft actuator with soft positional sensors indicate effective tracking of referenced spatial trajectories and rejection of mechanical and electromagnetic disturbances. These are evidenced by root mean squared path tracking errors (RMSE) of 1.8mm using a fully connected (FC) substructure, 1.62mm using a gated recurrent unit (GRU) and 2.11mm using a long short term memory (LSTM) unit, all averaged over three tasks. Among these models, the highest flash memory requirement is 2.22kB enabling co-location of controller and actuator.      
### 50.Transformer for Image Quality Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2101.01097.pdf)
>  Transformer has become the new standard method in natural language processing (NLP), and it also attracts research interests in computer vision area. In this paper we investigate the application of Transformer in Image Quality (TRIQ) assessment. Following the original Transformer encoder employed in Vision Transformer (ViT), we propose an architecture of using a shallow Transformer encoder on the top of a feature map extracted by convolution neural networks (CNN). Adaptive positional embedding is employed in the Transformer encoder to handle images with arbitrary resolutions. Different settings of Transformer architectures have been investigated on publicly available image quality databases. We have found that the proposed TRIQ architecture achieves outstanding performance. The implementation of TRIQ is published on Github (<a class="link-external link-https" href="https://github.com/junyongyou/triq" rel="external noopener nofollow">this https URL</a>).      
### 51.Derivative-Free Policy Optimization for Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity  [ :arrow_down: ](https://arxiv.org/pdf/2101.01041.pdf)
>  Direct policy search serves as one of the workhorses in modern reinforcement learning (RL), and its applications in continuous control tasks have recently attracted increasing attention. In this work, we investigate the convergence theory of policy gradient (PG) methods for learning the linear risk-sensitive and robust controller. In particular, we develop PG methods that can be implemented in a derivative-free fashion by sampling system trajectories, and establish both global convergence and sample complexity results in the solutions of two fundamental settings in risk-sensitive and robust control: the finite-horizon linear exponential quadratic Gaussian, and the finite-horizon linear-quadratic disturbance attenuation problems. As a by-product, our results also provide the first sample complexity for the global convergence of PG methods on solving zero-sum linear-quadratic dynamic games, a nonconvex-nonconcave minimax optimization problem that serves as a baseline setting in multi-agent reinforcement learning (MARL) with continuous spaces. One feature of our algorithms is that during the learning phase, a certain level of robustness/risk-sensitivity of the controller is preserved, which we termed as the implicit regularization property, and is an essential requirement in safety-critical control systems.      
### 52.VIS30K: A Collection of Figures and Tables from {IEEE} Visualization Conference Publications  [ :arrow_down: ](https://arxiv.org/pdf/2101.01036.pdf)
>  We present the VIS30K dataset, a collection of 29,689 images that represents 30 years of figures and tables from each track of the IEEE Visualization conference series (Vis, SciVis, InfoVis, VAST). VIS30K's comprehensive coverage of the scientific literature in visualization not only reflects the progress of the field but also enables researchers to study the evolution of the state-of-the-art and to find relevant work based on graphical content. We describe the dataset and our semi-automatic collection process, which couples convolutional neural networks (CNN) with curation. Extracting figures and tables semi-automatically allows us to verify that no images are overlooked or extracted erroneously. To improve quality further, we engaged in a peer-search process for high-quality figures from early IEEE Visualization papers. With the resulting data, we also contribute VISImageNavigator (VIN, <a class="link-external link-http" href="http://visimagenavigator.github.io" rel="external noopener nofollow">this http URL</a>), a web-based tool that facilitates searching and exploring VIS30K by author names, paper keywords, title and abstract, and years.      
### 53.HyperMorph: Amortized Hyperparameter Learning for Image Registration  [ :arrow_down: ](https://arxiv.org/pdf/2101.01035.pdf)
>  We present HyperMorph, a learning-based strategy for deformable image registration that removes the need to tune important registration hyperparameters during training. Classical registration methods solve an optimization problem to find a set of spatial correspondences between two images, while learning-based methods leverage a training dataset to learn a function that generates these correspondences. The quality of the results for both types of techniques depends greatly on the choice of hyperparameters. Unfortunately, hyperparameter tuning is time-consuming and typically involves training many separate models with various hyperparameter values, potentially leading to suboptimal results. To address this inefficiency, we introduce amortized hyperparameter learning for image registration, a novel strategy to learn the effects of hyperparameters on deformation fields. The proposed framework learns a hypernetwork that takes in an input hyperparameter and modulates a registration network to produce the optimal deformation field for that hyperparameter value. In effect, this strategy trains a single, rich model that enables rapid, fine-grained discovery of hyperparameter values from a continuous interval at test-time. We demonstrate that this approach can be used to optimize multiple hyperparameters considerably faster than existing search strategies, leading to a reduced computational and human burden and increased flexibility. We also show that this has several important benefits, including increased robustness to initialization and the ability to rapidly identify optimal hyperparameter values specific to a registration task, dataset, or even a single anatomical region - all without retraining the HyperMorph model. Our code is publicly available at <a class="link-external link-http" href="http://voxelmorph.mit.edu" rel="external noopener nofollow">this http URL</a>.      
### 54.Guiding GANs: How to control non-conditional pre-trained GANs for conditional image generation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00990.pdf)
>  Generative Adversarial Networks (GANs) are an arrange of two neural networks -- the generator and the discriminator -- that are jointly trained to generate artificial data, such as images, from random inputs. The quality of these generated images has recently reached such levels that can often lead both machines and humans into mistaking fake for real examples. However, the process performed by the generator of the GAN has some limitations when we want to condition the network to generate images from subcategories of a specific class. Some recent approaches tackle this \textit{conditional generation} by introducing extra information prior to the training process, such as image semantic segmentation or textual descriptions. While successful, these techniques still require defining beforehand the desired subcategories and collecting large labeled image datasets representing them to train the GAN from scratch. In this paper we present a novel and alternative method for guiding generic non-conditional GANs to behave as conditional GANs. Instead of re-training the GAN, our approach adds into the mix an encoder network to generate the high-dimensional random input vectors that are fed to the generator network of a non-conditional GAN to make it generate images from a specific subcategory. In our experiments, when compared to training a conditional GAN from scratch, our guided GAN is able to generate artificial images of perceived quality comparable to that of non-conditional GANs after training the encoder on just a few hundreds of images, which substantially accelerates the process and enables adding new subcategories seamlessly.      
### 55.A downsampling strategy to assess the predictive value of radiomic features  [ :arrow_down: ](https://arxiv.org/pdf/2101.00950.pdf)
>  Many studies are devoted to the design of radiomic models for a prediction task. When no effective model is found, it is often difficult to know whether the radiomic features do not include information relevant to the task or because of insufficient data. We propose a downsampling method to answer that question when considering a classification task into two groups. Using two large patient cohorts, several experimental configurations involving different numbers of patients were created. Univariate or multivariate radiomic models were designed from each configuration. Their performance as reflected by the Youden index (YI) and Area Under the receiver operating characteristic Curve (AUC) was compared to the stable performance obtained with the highest number of patients. A downsampling method is described to predict the YI and AUC achievable with a large number of patients. Using the multivariate models involving machine learning, YI and AUC increased with the number of patients while they decreased for univariate models. The downsampling method better estimated YI and AUC obtained with the largest number of patients than the YI and AUC obtained using the number of available patients and identifies the lack of information relevant to the classification task when no such information exists.      
### 56.Shed Various Lights on a Low-Light Image: Multi-Level Enhancement Guided by Arbitrary References  [ :arrow_down: ](https://arxiv.org/pdf/2101.00813.pdf)
>  It is suggested that low-light image enhancement realizes one-to-many mapping since we have different definitions of NORMAL-light given application scenarios or users' aesthetic. However, most existing methods ignore subjectivity of the task, and simply produce one result with fixed brightness. This paper proposes a neural network for multi-level low-light image enhancement, which is user-friendly to meet various requirements by selecting different images as brightness reference. Inspired by style transfer, our method decomposes an image into two low-coupling feature components in the latent space, which allows the concatenation feasibility of the content components from low-light images and the luminance components from reference images. In such a way, the network learns to extract scene-invariant and brightness-specific information from a set of image pairs instead of learning brightness differences. Moreover, information except for the brightness is preserved to the greatest extent to alleviate color distortion. Extensive results show strong capacity and superiority of our network against existing methods.      
### 57.WearMask: Fast In-browser Face Mask Detection with Serverless Edge Computing for COVID-19  [ :arrow_down: ](https://arxiv.org/pdf/2101.00784.pdf)
>  The COVID-19 epidemic has been a significant healthcare challenge in the United States. According to the Centers for Disease Control and Prevention (CDC), COVID-19 infection is transmitted predominately by respiratory droplets generated when people breathe, talk, cough, or sneeze. Wearing a mask is the primary, effective, and convenient method of blocking 80% of all respiratory infections. Therefore, many face mask detection and monitoring systems have been developed to provide effective supervision for hospitals, airports, publication transportation, sports venues, and retail locations. However, the current commercial face mask detection systems are typically bundled with specific software or hardware, impeding public accessibility. In this paper, we propose an in-browser serverless edge-computing based face mask detection solution, called Web-based efficient AI recognition of masks (WearMask), which can be deployed on any common devices (e.g., cell phones, tablets, computers) that have internet connections using web browsers, without installing any software. The serverless edge-computing design minimizes the extra hardware costs (e.g., specific devices or cloud computing servers). The contribution of the proposed method is to provide a holistic edge-computing framework of integrating (1) deep learning models (YOLO), (2) high-performance neural network inference computing framework (NCNN), and (3) a stack-based virtual machine (WebAssembly). For end-users, our web-based solution has advantages of (1) serverless edge-computing design with minimal device limitation and privacy risk, (2) installation free deployment, (3) low computing requirements, and (4) high detection speed. Our WearMask application has been launched with public access at <a class="link-external link-http" href="http://facemask-detection.com" rel="external noopener nofollow">this http URL</a>.      
### 58.A novel policy for pre-trained Deep Reinforcement Learning for Speech Emotion Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.00738.pdf)
>  Reinforcement Learning (RL) is a semi-supervised learning paradigm which an agent learns by interacting with an environment. Deep learning in combination with RL provides an efficient method to learn how to interact with the environment is called Deep Reinforcement Learning (deep RL). Deep RL has gained tremendous success in gaming - such as AlphaGo, but its potential have rarely being explored for challenging tasks like Speech Emotion Recognition (SER). The deep RL being used for SER can potentially improve the performance of an automated call centre agent by dynamically learning emotional-aware response to customer queries. While the policy employed by the RL agent plays a major role in action selection, there is no current RL policy tailored for SER. In addition, extended learning period is a general challenge for deep RL which can impact the speed of learning for SER. Therefore, in this paper, we introduce a novel policy - "Zeta policy" which is tailored for SER and apply Pre-training in deep RL to achieve faster learning rate. Pre-training with cross dataset was also studied to discover the feasibility of pre-training the RL Agent with a similar dataset in a scenario of where no real environmental data is not available. IEMOCAP and SAVEE datasets were used for the evaluation with the problem being to recognize four emotions happy, sad, angry and neutral in the utterances provided. Experimental results show that the proposed "Zeta policy" performs better than existing policies. The results also support that pre-training can reduce the training time upon reducing the warm-up period and is robust to cross-corpus scenario.      
### 59.Adversarial Unsupervised Domain Adaptation for Harmonic-Percussive Source Separation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00701.pdf)
>  This paper addresses the problem of domain adaptation for the task of music source separation. Using datasets from two different domains, we compare the performance of a deep learning-based harmonic-percussive source separation model under different training scenarios, including supervised joint training using data from both domains and pre-training in one domain with fine-tuning in another. We propose an adversarial unsupervised domain adaptation approach suitable for the case where no labelled data (ground-truth source signals) from a target domain is available. By leveraging unlabelled data (only mixtures) from this domain, experiments show that our framework can improve separation performance on the new domain without losing any considerable performance on the original domain. The paper also introduces the Tap &amp; Fiddle dataset, a dataset containing recordings of Scandinavian fiddle tunes along with isolated tracks for 'foot-tapping' and 'violin'.      
### 60.An Evolution of CNN Object Classifiers on Low-Resolution Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.00686.pdf)
>  Object classification is a significant task in computer vision. It has become an effective research area as an important aspect of image processing and the building block of image localization, detection, and scene parsing. Object classification from low-quality images is difficult for the variance of object colors, aspect ratios, and cluttered backgrounds. The field of object classification has seen remarkable advancements, with the development of deep convolutional neural networks (DCNNs). Deep neural networks have been demonstrated as very powerful systems for facing the challenge of object classification from high-resolution images, but deploying such object classification networks on the embedded device remains challenging due to the high computational and memory requirements. Using high-quality images often causes high computational and memory complexity, whereas low-quality images can solve this issue. Hence, in this paper, we investigate an optimal architecture that accurately classifies low-quality images using DCNNs architectures. To validate different baselines on lowquality images, we perform experiments using webcam captured image datasets of 10 different objects. In this research work, we evaluate the proposed architecture by implementing popular CNN architectures. The experimental results validate that the MobileNet architecture delivers better than most of the available CNN architectures for low-resolution webcam image datasets.      
### 61.Privacy Preserving Domain Adaptation for Semantic Segmentation of Medical Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.00522.pdf)
>  Convolutional neural networks (CNNs) have led to significant improvements in tasks involving semantic segmentation of images. CNNs are vulnerable in the area of biomedical image segmentation because of distributional gap between two source and target domains with different data modalities which leads to domain shift. Domain shift makes data annotations in new modalities necessary because models must be retrained from scratch. Unsupervised domain adaptation (UDA) is proposed to adapt a model to new modalities using solely unlabeled target domain data. Common UDA algorithms require access to data points in the source domain which may not be feasible in medical imaging due to privacy concerns. In this work, we develop an algorithm for UDA in a privacy-constrained setting, where the source domain data is inaccessible. Our idea is based on encoding the information from the source samples into a prototypical distribution that is used as an intermediate distribution for aligning the target domain distribution with the source domain distribution. We demonstrate the effectiveness of our algorithm by comparing it to state-of-the-art medical image semantic segmentation approaches on two medical image semantic segmentation datasets.      
### 62.A General Deep Reinforcement Learning Framework for Grant-Free NOMA Optimization in mURLLC  [ :arrow_down: ](https://arxiv.org/pdf/2101.00515.pdf)
>  Grant-free non-orthogonal multiple access (GF-NOMA) is a potential technique to support massive Ultra-Reliable and Low-Latency Communication (mURLLC) service. However, the dynamic resource configuration in GF-NOMA systems is challenging due to the random traffics and collisions, which are unknown at the base station (BS). Meanwhile, joint consideration of the latency and reliability requirements makes the resource configuration of GF-NOMA for mURLLC more complex. To address this problem, we develop a general learning framework for signature-based GF-NOMA in mURLLC service taking into account the MA signature collision, and the UE detection as well as the data decoding procedures for the K-repetition GF scheme and the Proactive GF scheme. The goal of our learning framework is to maximize the long-term average number of successfully served users (UEs) under the latency constraint. We first perform a real-time repetition value configuration based on a double deep Q-Network (DDQN) and then propose a Cooperative Multi-Agent (CMA) learning technique based on the DQN to optimize the configuration of both the repetition values and the contention-transmission unit (CTU) numbers. Our results shown that the number of successfully served UEs achieved under the same latency constraint in our proposed learning framework is up to ten times for the K-repetition scheme, and two times for the Proactive scheme, more than those achieved in the system with fixed repetition values and CTU numbers, respectively. Importantly, our general learning framework can be used to optimize the resource configuration problems in all the signature-based GF-NOMA schemes.      
### 63.Smart Car Features using Embedded Systems and IoT  [ :arrow_down: ](https://arxiv.org/pdf/2101.00496.pdf)
>  There has been a tremendous rise in technological advances in the field of automobiles and autonomous vehicles. With the increase in the number of driven vehicles, the safety concerns with the same have also risen. The cases of accidents and life-threatening injuries have skyrocketed. It has become a necessity to provide adequate safety measures in automobiles. This project aims to develop a prototype for a smart vehicle system that provides real-time location of the vehicle on detection of a crash and alert the police station and relatives of the user, it has a panic button feature for a passenger's safety. We also demonstrate a mechanism for cabin monitoring and an interactive interface between a user and a car, where the user can inquire about the temperature, humidity, and other variables inside the car remotely by sending a text message to the GSM module which is present in the car. The GSM module connects to the Arduino, which fetches the readings from sensors attached to it and sends it back to the user through a text message. We show the integration of MQ3 Alcohol sensor with Arduino for drunk driving prevention.      
### 64.Non-conservative Design of Robust Tracking Controllers Based on Input-output Data  [ :arrow_down: ](https://arxiv.org/pdf/2101.00488.pdf)
>  This paper studies worst-case robust optimal tracking using noisy input-output data. We utilize behavioral system theory to represent system trajectories, while avoiding explicit system identification. We assume that the recent output data used in the data-dependent representation are noisy and we provide a non-conservative design procedure for robust control based on optimization with a linear cost and LMI constraints. Our methods rely on the parameterization of noise sequences compatible with the data-dependent system representation and on a suitable reformulation of the performance specification, which further enable the application of the S-lemma to derive an LMI optimization problem. The performance of the new controller is discussed through simulations.      
### 65.Securing Isosceles Triangular Formations under Heterogeneous Sensing and Mixed Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2101.00474.pdf)
>  This paper focuses on securing a triangular shape (up to translation) for a team of three mobile robots that uses heterogeneous sensing mechanism. Based on the available local information, each robot employs the popular gradient-based control law to attain the assigned individual task(s). In the current work, robots are assigned either distance and signed area task(s) or bearing task(s). We provide a sufficient condition on the gain ratio $R_{\text{Ad}}$ between the signed area and the distance control term such that the desired formation shape, an isosceles triangle, is reached from all feasible starting positions. Numerical simulations are provided to support the theoretical analyses.      
### 66.Learning-Based Distributed Random Access for Multi-Cell IoT Networks with NOMA  [ :arrow_down: ](https://arxiv.org/pdf/2101.00464.pdf)
>  Non-orthogonal multiple access (NOMA) is a key technology to enable massive machine type communications (mMTC) in 5G networks and beyond. In this paper, NOMA is applied to improve the random access efficiency in high-density spatially-distributed multi-cell wireless IoT networks, where IoT devices contend for accessing the shared wireless channel using an adaptive p-persistent slotted Aloha protocol. To enable a capacity-optimal network, a novel formulation of random channel access with NOMA is proposed, in which the transmission probability of each IoT device is tuned to maximize the geometric mean of users' expected capacity. It is shown that the network optimization objective is high dimensional and mathematically intractable, yet it admits favourable mathematical properties that enable the design of efficient learning-based algorithmic solutions. To this end, two algorithms, i.e., a centralized model-based algorithm and a scalable distributed model-free algorithm, are proposed to optimally tune the transmission probabilities of IoT devices to attain the maximum capacity. The convergence of the proposed algorithms to the optimal solution is further established based on convex optimization and game-theoretic analysis. Extensive simulations demonstrate the merits of the novel formulation and the efficacy of the proposed algorithms.      
### 67.Early Work on Efficient Patching for Coordinating Edge Applications  [ :arrow_down: ](https://arxiv.org/pdf/2101.00397.pdf)
>  Multiple applications running on Edge computers can be orchestrated to achieve the desired goal. Orchestration of applications is prominent when working with Internet of Things based applications, Autonomous driving and Autonomous Aerial vehicles. As the applications receive modified classifiers/code, there will be multiple applications that need to be updated. If all the classifiers are synchronously updated there would be increased throughput and bandwidth degradation. On the other hand, delaying updates of applications which need immediate update hinders performance and delays progress towards end goal. The updates of applications should be prioritized and updates should happen according to this priority. This paper explores the setup and benchmarks to understand the impact of updates when multiple applications working to achieve same objective are orchestrated with prioritized updates. We discuss methods to build a distributed, reliable and scalable system called "DSOC"(Docker Swarm Orchestration Component).      
### 68.VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00390.pdf)
>  We introduce VoxPopuli, a large-scale multilingual corpus providing 100K hours of unlabelled speech data in 23 languages. It is the largest open data to date for unsupervised representation learning as well as semi-supervised learning. VoxPopuli also contains 1.8K hours of transcribed speeches in 16 languages and their aligned oral interpretations into 5 other languages totaling 5.1K hours. We provide speech recognition baselines and validate the versatility of VoxPopuli unlabelled data in semi-supervised learning under challenging out-of-domain settings. We will release the corpus at <a class="link-external link-https" href="https://github.com/facebookresearch/voxpopuli" rel="external noopener nofollow">this https URL</a> under an open license.      
### 69.What all do audio transformer models hear? Probing Acoustic Representations for Language Delivery and its Structure  [ :arrow_down: ](https://arxiv.org/pdf/2101.00387.pdf)
>  In recent times, BERT based transformer models have become an inseparable part of the 'tech stack' of text processing models. Similar progress is being observed in the speech domain with a multitude of models observing state-of-the-art results by using audio transformer models to encode speech. This begs the question of what are these audio transformer models learning. Moreover, although the standard methodology is to choose the last layer embedding for any downstream task, but is it the optimal choice? We try to answer these questions for the two recent audio transformer models, Mockingjay and wave2vec2.0. We compare them on a comprehensive set of language delivery and structure features including audio, fluency and pronunciation features. Additionally, we probe the audio models' understanding of textual surface, syntax, and semantic features and compare them to BERT. We do this over exhaustive settings for native, non-native, synthetic, read and spontaneous speech datasets      
### 70.An Artificial Intelligence System for Combined Fruit Detection and Georeferencing, Using RTK-Based Perspective Projection in Drone Imagery  [ :arrow_down: ](https://arxiv.org/pdf/2101.00339.pdf)
>  This work presents an Artificial Intelligence (AI) system, based on the Faster Region-Based Convolution Neural Network (Faster R-CNN) framework, which detects and counts apples from oblique, aerial drone imagery of giant commercial orchards. To reduce computational cost, a novel precursory stage to the network is designed to preprocess raw imagery into cropped images of individual trees. Unique geospatial identifiers are allocated to these using the perspective projection model. This employs Real-Time Kinematic (RTK) data, Digital Terrain and Surface Models (DTM and DSM), as well as internal and external camera parameters. The bulk of experiments however focus on tuning hyperparameters in the detection network itself. Apples which are on trees and apples which are on the ground are treated as separate classes. A mean Average Precision (mAP) metric, calibrated by the size of the two classes, is devised to mitigate spurious results. Anchor box design is of key interest due to the scale of the apples. As such, a k-means clustering approach, never before seen in literature for Faster R-CNN, resulted in the most significant improvements to calibrated mAP. Other experiments showed that the maximum number of box proposals should be 225; the initial learning rate of 0.001 is best applied to the adaptive RMS Prop optimiser; and ResNet 101 is the ideal base feature extractor when considering mAP and, to a lesser extent, inference time. The amalgamation of the optimal hyperparameters leads to a model with a calibrated mAP of 0.7627.      
### 71.Biologically Inspired Hexagonal Deep Learning for Hexagonal Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2101.00337.pdf)
>  Whereas conventional state-of-the-art image processing systems of recording and output devices almost exclusively utilize square arranged methods, biological models, however, suggest an alternative, evolutionarily-based structure. Inspired by the human visual perception system, hexagonal image processing in the context of machine learning offers a number of key advantages that can benefit both researchers and users alike. The hexagonal deep learning framework Hexnet leveraged in this contribution serves therefore the generation of hexagonal images by utilizing hexagonal deep neural networks (H-DNN). As the results of our created test environment show, the proposed models can surpass current approaches of conventional image generation. While resulting in a reduction of the models' complexity in the form of trainable parameters, they furthermore allow an increase of test rates in comparison to their square counterparts.      
### 72.A Survey on Deep Reinforcement Learning for Audio-Based Applications  [ :arrow_down: ](https://arxiv.org/pdf/2101.00240.pdf)
>  Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising application in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together the research studies across different speech and music-related areas. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting challenges faced by audio-based DRL agents and highlighting open areas for future research and investigation.      
### 73.Sequential Convex Programming for Collaboration of Connected and Automated Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2101.00202.pdf)
>  This paper investigates the collaboration of multiple connected and automated vehicles (CAVs) in different scenarios. In general, the collaboration of CAVs can be formulated as a nonlinear and nonconvex model predictive control (MPC) problem. Most of the existing approaches available for utilization to solve such an optimization problem suffer from the drawback of considerable computational burden, which hinders the practical implementation in real time. This paper proposes the use of sequential convex programming (SCP), which is a powerful approach to solving the nonlinear and nonconvex MPC problem in real time. To appropriately deploy the methodology, as a first stage, SCP requires linearization and discretization when addressing the nonlinear dynamics of the system model adequately. Based on the linearization and discretization, the original MPC problem can be transformed into a quadratically constrained quadratic programming (QCQP) problem. Besides, SCP also involves convexification to handle the associated nonconvex constraints. Thus, the nonconvex QCQP can be reduced to a quadratic programming (QP) problem that can be solved rather quickly. Therefore, the computational efficiency is suitably improved despite the existence of nonlinear and nonconvex characteristics, whereby the implementation is realized in real time. Furthermore, simulation results in three different scenarios of autonomous driving are presented to validate the effectiveness and efficiency of our proposed approach.      
### 74.Semi-Definite Relaxation Based ADMM for Cooperative Planning and Control of Connected Autonomous Vehicles  [ :arrow_down: ](https://arxiv.org/pdf/2101.00201.pdf)
>  This paper investigates the cooperative planning and control problem for multiple connected autonomous vehicles (CAVs) in different scenarios. In the existing literature, most of the methods suffer from significant problems in computational efficiency. Besides, as the optimization problem is nonlinear and nonconvex, it typically poses great difficultly in determining the optimal solution. To address this issue, this work proposes a novel and completely parallel computation framework by leveraging the alternating direction method of multipliers (ADMM). The nonlinear and nonconvex optimization problem in the autonomous driving problem can be divided into two manageable subproblems; and the resulting subproblems can be solved by using effective optimization methods in a parallel framework. Here, the differential dynamic programming (DDP) algorithm is capable of addressing the nonlinearity of the system dynamics rather effectively; and the nonconvex coupling constraints with small dimensions can be approximated by invoking the notion of semi-definite relaxation (SDR), which can also be solved in a very short time. Due to the parallel computation and efficient relaxation of nonconvex constraints, our proposed approach effectively realizes real-time implementation and thus also extra assurance of driving safety is provided. In addition, two transportation scenarios for multiple CAVs are used to illustrate the effectiveness and efficiency of the proposed method.      
### 75.Generative Deep Learning for Virtuosic Classical Music: Generative Adversarial Networks as Renowned Composers  [ :arrow_down: ](https://arxiv.org/pdf/2101.00169.pdf)
>  Current AI-generated music lacks fundamental principles of good compositional techniques. By narrowing down implementation issues both programmatically and musically, we can create a better understanding of what parameters are necessary for a generated composition nearly indistinguishable from that of a master composer.      
### 76.Estimating Experimental Dispersion Curves from Steady-State Frequency Response Measurements  [ :arrow_down: ](https://arxiv.org/pdf/2101.00155.pdf)
>  Dispersion curves characterize the frequency dependence of the phase and the group velocities of propagating elastic waves. Many analytical and numerical techniques produce dispersion curves from physics-based models. However, it is often challenging to accurately model engineering structures with intricate geometric features and inhomogeneous material properties. For such cases, this paper proposes a novel method to estimate group velocities from experimental data-driven models. Experimental frequency response functions (FRFs) are used to develop data-driven models, {which are then used to estimate dispersion curves}. The advantages of this approach over other traditionally used transient techniques stem from the need to conduct only steady-state experiments. In comparison, transient experiments often need a higher-sampling rate for wave-propagation applications and are more susceptible to noise. <br>The vector-fitting (VF) algorithm is adopted to develop data-driven models from experimental in-plane and out-of-plane FRFs of a one-dimensional structure. The quality of the corresponding data-driven estimates is evaluated using an analytical Timoshenko beam as a baseline. The data-driven model (using the out-of-plane FRFs) estimates the anti-symmetric ($A_0$) group velocity with a maximum error of $4\%$ over a 40~kHz frequency band. In contrast, group velocities estimated from transient experiments resulted in a maximum error of $6\%$ over the same frequency band.      
### 77.$\mathcal{L}_1$ Adaptive Control for Switching Reference Systems: Application to Flight Control  [ :arrow_down: ](https://arxiv.org/pdf/2101.00134.pdf)
>  This paper presents a framework for the design and analysis of an $\mathcal{L}_1$ adaptive controller with a switching reference system. The use of a switching reference system allows the desired behavior to be scheduled across the operating envelope, which is often required in aerospace applications. The analysis uses a switched reference system that assumes perfect knowledge of uncertainties and uses a corresponding non-adaptive controller. Provided that this switched reference system is stable, it is shown that the closed-loop system with unknown parameters and disturbances and the $\mathcal{L}_1$ adaptive controller can behave arbitrarily close to this reference system. Simulations of the short period dynamics of a transport class aircraft during the approach phase illustrate the theoretical results.      
### 78.Verifying a Cruise Control System using Simulink and SpaceEx  [ :arrow_down: ](https://arxiv.org/pdf/2101.00102.pdf)
>  This article aims to provide a simple step-by-step guide highlighting the steps needed to verify a control system with formal verification tools. Starting from a description of the physical system and a control objective in natural language, we design the plant and the controller, we use Simulink for simulation and we employ a reachability analysis tool, SpaceEx, for formal verification.      
### 79.Analysis of a new chaotic system, electronic realization and use in navigation of differential drive mobile robot  [ :arrow_down: ](https://arxiv.org/pdf/2101.00095.pdf)
>  This paper presents a new chaotic system having four attractors, including two fixed point attractors and two symmetrical chaotic strange attractors. Dynamical properties of the system, viz. sensitive dependence on initial conditions, Lyapunov spectrum, strangeness measure, attraction basin, including the class and size of it, existence of strange attractor, bifurcation analysis, multistability, electronic circuit design, and hardware implementation, are rigorously treated. Numerical computations are used to compute the basin of attraction and show that the system has a far-reaching composite basin of attraction. Such a basin of attraction is vital for engineering applications. Moreover, a circuit model of the system is realized using analog electronic components. A procedure is detailed for converting the system parameters into corresponding electronic component values such as the circuital resistances while ensuring the dynamic ranges are bounded. Besides, the system is used as the source of control inputs for independent navigation of a differential drive mobile robot, which is subject to the Pfaffian velocity constraint. Due to the properties of sensitivity on initial conditions and topological mixing, the robot's path becomes unpredictable and guaranteed to scan the workspace, respectively.      
### 80.FGF-GAN: A Lightweight Generative Adversarial Network for Pansharpening via Fast Guided Filter  [ :arrow_down: ](https://arxiv.org/pdf/2101.00062.pdf)
>  Pansharpening is a widely used image enhancement technique for remote sensing. Its principle is to fuse the input high-resolution single-channel panchromatic (PAN) image and low-resolution multi-spectral image and to obtain a high-resolution multi-spectral (HRMS) image. The existing deep learning pansharpening method has two shortcomings. First, features of two input images need to be concatenated along the channel dimension to reconstruct the HRMS image, which makes the importance of PAN images not prominent, and also leads to high computational cost. Second, the implicit information of features is difficult to extract through the manually designed loss function. To this end, we propose a generative adversarial network via the fast guided filter (FGF) for pansharpening. In generator, traditional channel concatenation is replaced by FGF to better retain the spatial information while reducing the number of parameters. Meanwhile, the fusion objects can be highlighted by the spatial attention module. In addition, the latent information of features can be preserved effectively through adversarial training. Numerous experiments illustrate that our network generates high-quality HRMS images that can surpass existing methods, and with fewer parameters.      
### 81.Psychoacoustic Calibration of Loss Functions for Efficient End-to-End Neural Audio Coding  [ :arrow_down: ](https://arxiv.org/pdf/2101.00054.pdf)
>  Conventional audio coding technologies commonly leverage human perception of sound, or psychoacoustics, to reduce the bitrate while preserving the perceptual quality of the decoded audio signals. For neural audio codecs, however, the objective nature of the loss function usually leads to suboptimal sound quality as well as high run-time complexity due to the large model size. In this work, we present a psychoacoustic calibration scheme to re-define the loss functions of neural audio coding systems so that it can decode signals more perceptually similar to the reference, yet with a much lower model complexity. The proposed loss function incorporates the global masking threshold, allowing the reconstruction error that corresponds to inaudible artifacts. Experimental results show that the proposed model outperforms the baseline neural codec twice as large and consuming 23.4% more bits per second. With the proposed method, a lightweight neural codec, with only 0.9 million parameters, performs near-transparent audio coding comparable with the commercial MPEG-1 Audio Layer III codec at 112 kbps.      
### 82.Modified Gaussian Process Regression Models for Cyclic Capacity Prediction of Lithium-ion Batteries  [ :arrow_down: ](https://arxiv.org/pdf/2101.00035.pdf)
>  This paper presents the development of machine learning-enabled data-driven models for effective capacity predictions for lithium-ion batteries under different cyclic conditions. To achieve this, a model structure is first proposed with the considerations of battery ageing tendency and the corresponding operational temperature and depth-of-discharge. Then based on a systematic understanding of covariance functions within the Gaussian process regression, two related data-driven models are developed. Specifically, by modifying the isotropic squared exponential kernel with an automatic relevance determination structure, 'Model A' could extract the highly relevant input features for capacity predictions. Through coupling the Arrhenius law and a polynomial equation into a compositional kernel, 'Model B' is capable of considering the electrochemical and empirical knowledge of battery degradation. The developed models are validated and compared on the Nickel Manganese Cobalt Oxide (NMC) lithium-ion batteries with various cycling patterns. Experimental results demonstrate that the modified Gaussian process regression model considering the battery electrochemical and empirical ageing signature outperforms other counterparts and is able to achieve satisfactory results for both one-step and multi-step predictions. The proposed technique is promising for battery capacity predictions under various cycling cases.      
### 83.Explainability Matters: Backdoor Attacks on Medical Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2101.00008.pdf)
>  Deep neural networks have been shown to be vulnerable to backdoor attacks, which could be easily introduced to the training set prior to model training. Recent work has focused on investigating backdoor attacks on natural images or toy datasets. Consequently, the exact impact of backdoors is not yet fully understood in complex real-world applications, such as in medical imaging where misdiagnosis can be very costly. In this paper, we explore the impact of backdoor attacks on a multi-label disease classification task using chest radiography, with the assumption that the attacker can manipulate the training dataset to execute the attack. Extensive evaluation of a state-of-the-art architecture demonstrates that by introducing images with few-pixel perturbations into the training set, an attacker can execute the backdoor successfully without having to be involved with the training procedure. A simple 3$\times$3 pixel trigger can achieve up to 1.00 Area Under the Receiver Operating Characteristic (AUROC) curve on the set of infected images. In the set of clean images, the backdoored neural network could still achieve up to 0.85 AUROC, highlighting the stealthiness of the attack. As the use of deep learning based diagnostic systems proliferates in clinical practice, we also show how explainability is indispensable in this context, as it can identify spatially localized backdoors in inference time.      

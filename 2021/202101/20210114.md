# ArXiv eess --Thu, 14 Jan 2021
### 1.Big Self-Supervised Models Advance Medical Image Classification  [ :arrow_down: ](https://arxiv.org/pdf/2101.05224.pdf)
>  Self-supervised pretraining followed by supervised fine-tuning has seen success in image recognition, especially when labeled examples are scarce, but has received limited attention in medical image analysis. This paper studies the effectiveness of self-supervised learning as a pretraining strategy for medical image classification. We conduct experiments on two distinct tasks: dermatology skin condition classification from digital camera images and multi-label chest X-ray classification, and demonstrate that self-supervised learning on ImageNet, followed by additional self-supervised learning on unlabeled domain-specific medical images significantly improves the accuracy of medical image classifiers. We introduce a novel Multi-Instance Contrastive Learning (MICLe) method that uses multiple images of the underlying pathology per patient case, when available, to construct more informative positive pairs for self-supervised learning. Combining our contributions, we achieve an improvement of 6.7% in top-1 accuracy and an improvement of 1.1% in mean AUC on dermatology and chest X-ray classification respectively, outperforming strong supervised baselines pretrained on ImageNet. In addition, we show that big self-supervised models are robust to distribution shift and can learn efficiently with a small number of labeled medical images.      
### 2.A Two-Stage Wavelet Decomposition Method for Instantaneous Power Quality Indices Estimation Considering Interharmonics and Transient Disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2101.05220.pdf)
>  As the complexity increases in modern power systems, power quality analysis considering interharmonics has become a challenging and important task. This paper proposes a novel decomposition and estimation method for instantaneous power quality indices (PQIs) monitoring in single-phase and three-phase systems with interharmonics and transient disturbances. To separate the interharmonic components, a set of new scaling filter and wavelet filter with narrow transition bands are designed for the undecimated wavelet packet transform (UWPT). Further, a two-stage decomposition method for multi-tone voltage and current signals is proposed. The Hilbert transform (HT) is applied to calculate the instantaneous amplitude and phase of each frequency component, which accordingly allows the monitoring of different PQI parameters. Numerical tests are conducted to check the performance of the proposed method. The test results show that compared to other conventional approaches, instantaneous PQIs estimated by the proposed method present significant advances for tracking transitory changes in power systems, and could be considered as a helpful tool for high-accuracy PQ detections.      
### 3.Three Dimensional MR Image Synthesis with Progressive Generative Adversarial Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.05218.pdf)
>  Mainstream deep models for three-dimensional MRI synthesis are either cross-sectional or volumetric depending on the input. Cross-sectional models can decrease the model complexity, but they may lead to discontinuity artifacts. On the other hand, volumetric models can alleviate the discontinuity artifacts, but they might suffer from loss of spatial resolution due to increased model complexity coupled with scarce training data. To mitigate the limitations of both approaches, we propose a novel model that progressively recovers the target volume via simpler synthesis tasks across individual orientations.      
### 4.Similarity-based prediction for channel mapping and user positioning  [ :arrow_down: ](https://arxiv.org/pdf/2101.05217.pdf)
>  In a wireless network, gathering information at the base station about mobile users based only on uplink channel measurements is an interesting challenge. Indeed, accessing the users locations and predicting their downlink channels would be particularly useful in order to optimize the network efficiency. In this paper, a supervised machine learning approach addressing these tasks in an unified way is proposed. It relies on a labeled database that can be acquired in a simple way by the base station while operating. The proposed regression method can be seen as a computationally efficient two layers neural network initialized with a non-parametric estimator. It is illustrated on realistic channel data, both for the positioning and channel mapping tasks, achieving better results than previously proposed approaches, at a lower cost.      
### 5.Study on MCS Selection and Spectrum Allocation for URLLC Traffic under Delay and Reliability Constraint in 5G Network  [ :arrow_down: ](https://arxiv.org/pdf/2101.05215.pdf)
>  To support Ultra-Reliable and Low Latency Communications (URLLC) is an essential character of the 5th Generation (5G) communication system. Unlike the other two use cases defined in 5G, e.g. enhanced Mobile Broadband (eMBB) and massive Machine Type Communications (mMTC), URLLC traffic has strict delay and reliability requirement. In this paper, an analysis model for URLLC traffic is proposed from the generation of a URLLC traffic until its transmission over a wireless channel, where channel quality, coding scheme with finite coding length, modulation scheme and allocated spectrum resource are taken into consideration. Then, network calculus analysis is applied to derive the delay guarantee for periodical URLLC traffic. Based on the delay analysis, the admission region is found under certain delay and reliability requirement, which gives a lower bound on required spectrum resource. Theoretical results in the scenario of a 5G New Radio system are presented, where the SNR thresholds for adaptive modulation and coding scheme selection, transmission rate and delay, as well as admission region under different configurations are discussed. In addition, simulation results are obtained and compared with theoretical results, which validates that the admission region derived in this work provides a lower spectrum allocation bound.      
### 6.Millimeter-wave Multimode Circular Array for Spatially Encoded Beamforming in a Wide Coverage Area  [ :arrow_down: ](https://arxiv.org/pdf/2101.05213.pdf)
>  This paper summarizes an investigation around millimeter-wave (mmWave) multimode circular antenna array based beamformer capable of specially encoded data transmission in a wide coverage area. The circular antenna array is capable of an entire 360 deg. azimuth sector coverage where broadcast, uni-cast and multi-cast radio transmissions are possible. Orbital angular momentum (OAM) mode transmission along the elevation axis, i.e., perpendicular to the azimuth plane, can also be achieved. These two types of spatially encoded beamforming makes coverage in almost an entire hemisphere possible. The circular array is developed using twelve multilayer patch antennas with unique radiation performance aiding in both azimuth and elevation radiation. The proposed array architecture and its radiation performance makes it a good candidate for spatially encoded beamforming for mmWave 5G.      
### 7.Deep Learning Assisted Calibrated Beam Training for Millimeter-Wave Communication Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.05206.pdf)
>  Huge overhead of beam training poses a significant challenge in millimeter-wave (mmWave) wireless communications. To address this issue, a wide beam based training method is proposed to calibrate the narrow beam direction according to the channel power leakage in this paper. To handle the complex nonlinear properties of the channel power leakage, deep learning is utilized to predict the optimal narrow beam directly. Specifically, three deep learning assisted calibrated beam training schemes are proposed. First, Convolution Neural Network (CNN) is adopted to implement the prediction based on the instantaneous received signals of wide beam training. Besides, we propose to perform the additional narrow beam training based on the predicted probabilities for further beam direction calibrations. In the second scheme, in order to enhance the robustness to noise, Long-Short Term Memory (LSTM) Network is adopted to track the movement of users and calibrate the beam direction according to the received signals of prior beam training. To further reduce the overhead of wide beam training, an adaptive beam training strategy is proposed, where partial wide beams are selected to be trained based on the prior received signals. Furthermore, two criteria, namely optimal neighboring criterion (ONC) and maximum probability criterion (MPC), are designed for the selection. To handle mobile scenarios, auxiliary LSTM is introduced to calibrate the directions of the selected wide beams more precisely. Simulation results demonstrate that our proposed schemes achieve significantly higher beamforming gain with smaller beam training overhead compared with the conventional counterparts.      
### 8.Ambient PMU Data Based System Oscillation Analysis Using Multivariate Empirical Mode Decomposition  [ :arrow_down: ](https://arxiv.org/pdf/2101.05203.pdf)
>  Wide-area synchrophasor ambient measurements provide a valuable data source for real-time oscillation mode monitoring and analysis. This paper introduces a novel method for identifying inter-area oscillation modes using wide-area ambient measurements. Based on multivariate empirical mode decomposition (MEMD), which can analyze multi-channel non-stationary and nonlinear signals, the proposed method is capable of detecting the common oscillation mode that exists in multiple synchrophasor measurements at low amplitudes. Test results based on two real-world datasets validate the effectiveness of the proposed method.      
### 9.Optimisation of Spectral Wavelets for Persistence-based Graph Classification  [ :arrow_down: ](https://arxiv.org/pdf/2101.05201.pdf)
>  A graph's spectral wavelet signature determines a filtration, and consequently an associated set of extended persistence diagrams. We propose a framework that optimises the choice of wavelet for a dataset of graphs, such that their associated persistence diagrams capture features of the graphs that are best suited to a given data science problem. Since the spectral wavelet signature of a graph is derived from its Laplacian, our framework encodes geometric properties of graphs in their associated persistence diagrams and can be applied to graphs without a priori vertex features. We demonstrate how our framework can be coupled with different persistence diagram vectorisation methods for various supervised and unsupervised learning problems, such as graph classification and finding persistence maximising filtrations, respectively. To provide the underlying theoretical foundations, we extend the differentiability result for ordinary persistent homology to extended persistent homology.      
### 10.Use Energy Storage for Primary Frequency Control in Power Grids  [ :arrow_down: ](https://arxiv.org/pdf/2101.05165.pdf)
>  Frequency stability of power systems becomes more vulnerable with the increase of solar photovoltaic (PV). Energy storage provides an option to mitigate the impact of high PV penetration. Using the U.S. Eastern Interconnection (EI) and Texas Interconnection (ERCOT) power grid models, this paper investigates the capabilities of using energy storage to improve frequency response under high PV penetration. The study result helps to identify the potential and impact factors in utilizing energy storage to improve frequency response in high renewable penetration power grids.      
### 11.Neuro-Reachability of Networked Microgrids  [ :arrow_down: ](https://arxiv.org/pdf/2101.05159.pdf)
>  A neural ordinary differential equations network (ODE-Net)-enabled reachability method (Neuro-Reachability) is devised for the dynamic verification of networked microgrids (NMs) with unidentified subsystems and heterogeneous uncertainties. Three new contributions are presented: 1) An ODENet-enabled dynamic model discovery approach is devised to construct the data-driven state-space model which preserves the nonlinear and differential structure of the NMs system; 2) A physics-data-integrated (PDI) NMs model is established, which empowers various NM analytics; and 3) A conformance-empowered reachability analysis is developed to enhance the reliability of the PDI-driven dynamic verification. Extensive case studies demonstrate the efficacy of the ODE-Net-enabled method in microgrid dynamic model discovery, and the effectiveness of the Neuro-Reachability approach in verifying the NMs dynamics under multiple uncertainties and various operational scenarios.      
### 12.Self-Supervised Vessel Enhancement Using Flow-Based Consistencies  [ :arrow_down: ](https://arxiv.org/pdf/2101.05145.pdf)
>  Vessel segmenting is an essential task in many clinical applications. Although supervised methods have achieved state-of-art performance, acquiring expert annotation is laborious and mostly limited for two-dimensional datasets with a small sample size. On the contrary, unsupervised methods rely on handcrafted features to detect tube-like structures such as vessels. However, those methods require complex pipelines involving several hyper-parameters and design choices rendering the procedure sensitive, dataset-specific, and not generalizable. Also, unsupervised methods usually underperform supervised methods. We propose a self-supervised method with a limited number of hyper-parameters that is generalizable. Our method uses tube-like structure properties, such as connectivity, profile consistency, and bifurcation, to introduce inductive bias into a learning algorithm. To model those properties, we generate a vector field that we refer to as a flow. Our experiments on various datasets in 2D and 3D show that our method reduces the gap between supervised and unsupervised methods. Unlike generic self-supervised methods, the learned features are transferable for supervised approaches, which is essential when the number of annotated data is limited.      
### 13.VoxelHop: Successive Subspace Learning for ALS Disease Classification Using Structural MRI  [ :arrow_down: ](https://arxiv.org/pdf/2101.05131.pdf)
>  Deep learning has great potential for accurate detection and classification of diseases with medical imaging data, but the performance is often limited by the number of training datasets and memory requirements. In addition, many deep learning models are considered a "black-box," thereby often limiting their adoption in clinical applications. To address this, we present a successive subspace learning model, termed VoxelHop, for accurate classification of Amyotrophic Lateral Sclerosis (ALS) using T2-weighted structural MRI data. Compared with popular convolutional neural network (CNN) architectures, VoxelHop has modular and transparent structures with fewer parameters without any backpropagation, so it is well-suited to small dataset size and 3D imaging data. Our VoxelHop has four key components, including (1) sequential expansion of near-to-far neighborhood for multi-channel 3D data; (2) subspace approximation for unsupervised dimension reduction; (3) label-assisted regression for supervised dimension reduction; and (4) concatenation of features and classification between controls and patients. Our experimental results demonstrate that our framework using a total of 20 controls and 26 patients achieves an accuracy of 93.48$\%$ and an AUC score of 0.9394 in differentiating patients from controls, even with a relatively small number of datasets, showing its robustness and effectiveness. Our thorough evaluations also show its validity and superiority to the state-of-the-art 3D CNN classification methods. Our framework can easily be generalized to other classification tasks using different imaging modalities.      
### 14.DAEs for Linear Inverse Problems: Improved Recovery with Provable Guarantees  [ :arrow_down: ](https://arxiv.org/pdf/2101.05130.pdf)
>  Generative priors have been shown to provide improved results over sparsity priors in linear inverse problems. However, current state of the art methods suffer from one or more of the following drawbacks: (a) speed of recovery is slow; (b) reconstruction quality is deficient; (c) reconstruction quality is contingent on a computationally expensive process of tuning hyperparameters. In this work, we address these issues by utilizing Denoising Auto Encoders (DAEs) as priors and a projected gradient descent algorithm for recovering the original signal. We provide rigorous theoretical guarantees for our method and experimentally demonstrate its superiority over existing state of the art methods in compressive sensing, inpainting, and super-resolution. We find that our algorithm speeds up recovery by two orders of magnitude (over 100x), improves quality of reconstruction by an order of magnitude (over 10x), and does not require tuning hyperparameters.      
### 15.Self-Synchronising On-Off-Keying Visible Light Communication System For Intra and Inter-Vehicle Data Transmission  [ :arrow_down: ](https://arxiv.org/pdf/2101.05126.pdf)
>  Visible Light Communication (VLC) is a current technology which allows data to be transmitted by modulating information onto a light source. It has many advantages over traditional radio frequency communication and up to 10,000 times larger bandwidth. Existing research in visible light communication assumes a synchronised channel, however, this is not always easily achieved. In this paper, a novel synchronised intra and inter-vehicle VLC system is proposed to ensure reliable communication in both inter and intra-vehicle communication for Infotainment Systems (IS). The protocol achieves synchronisation at the symbol level using the transistor-transistor logic protocol and achieves frame synchronisations with markers. Consequently, the deployment of the protocol in both inter and intra-vehicle communication presents numerous advantages over existing data transmission processes. A practical application, where VLC is used for media streaming is also previewed. In addition, various regions of possible data transmission are determined with the intention to infer forward error correction schemes to ensure reliable communication.      
### 16.Beyond Procrustes: Balancing-Free Gradient Descent for Asymmetric Low-Rank Matrix Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2101.05113.pdf)
>  Low-rank matrix estimation plays a central role in various applications across science and engineering. Recently, nonconvex formulations based on matrix factorization are provably solved by simple gradient descent algorithms with strong computational and statistical guarantees. However, when the low-rank matrices are asymmetric, existing approaches rely on adding a regularization term to balance the scale of the two matrix factors which in practice can be removed safely without hurting the performance when initialized via the spectral method. In this paper, we provide a theoretical justification to this for the matrix sensing problem, which aims to recover a low-rank matrix from a small number of linear measurements. As long as the measurement ensemble satisfies the restricted isometry property, gradient descent -- in conjunction with spectral initialization -- converges linearly without the need of explicitly promoting balancedness of the factors; in fact, the factors stay balanced automatically throughout the execution of the algorithm. Our analysis is based on analyzing the evolution of a new distance metric that directly accounts for the ambiguity due to invertible transforms, and might be of independent interest.      
### 17.MRI Images, Brain Lesions and Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.05091.pdf)
>  Medical brain image analysis is a necessary step in the Computers Assisted /Aided Diagnosis (CAD) systems. Advancements in both hardware and software in the past few years have led to improved segmentation and classification of various diseases. In the present work, we review the published literature on systems and algorithms that allow for classification, identification, and detection of White Matter Hyperintensities (WMHs) of brain MRI images specifically in cases of ischemic stroke and demyelinating diseases. For the selection criteria, we used the bibliometric networks. Out of a total of 140 documents we selected 38 articles that deal with the main objectives of this study. Based on the analysis and discussion of the revised documents, there is constant growth in the research and proposal of new models of deep learning to achieve the highest accuracy and reliability of the segmentation of ischemic and demyelinating lesions. Models with indicators (Dice Score, DSC: 0.99) were found, however with little practical application due to the uses of small datasets and lack of reproducibility. Therefore, the main conclusion is to establish multidisciplinary research groups to overcome the gap between CAD developments and their complete utilization in the clinical environment.      
### 18.Secure Consensus with Distributed Detection via Two-hop Communication  [ :arrow_down: ](https://arxiv.org/pdf/2101.05087.pdf)
>  In this paper, we consider a multi-agent resilient consensus problem, where some of the nodes may behave maliciously. The approach is to equip all nodes with a scheme to detect neighboring nodes when they behave in an abnormal fashion. To this end, the nodes exchange not only their own states but also information regarding their neighbor nodes. Such two-hop communication has long been studied in fault-tolerant algorithms in computer science. We propose two distributed schemes for detection of malicious nodes and resilient consensus with different requirements on resources for communication and the structures of the networks. In particular, the detection schemes become effective under certain connectivity properties in the network so that the non-malicious nodes can share enough information about their neighbors. It is shown that the requirements are however less stringent than those for conventional algorithms. A numerical example is presented to demonstrate the performance of the proposed methods in wireless sensor networks.      
### 19.Real-time phase-retrieval and wavefront sensing enabled by an artificial neural network  [ :arrow_down: ](https://arxiv.org/pdf/2101.05082.pdf)
>  In this manuscript we demonstrate a method to reconstruct the wavefront of focused beams from a measured diffraction pattern behind a diffracting mask in real-time. The phase problem is solved by means of a neural network, which is trained with simulated data and verified with experimental data. The neural network allows live reconstructions within a few milliseconds, which previously with iterative phase retrieval took several seconds, thus allowing the adjustment of complex systems and correction by adaptive optics in real time. The neural network additionally outperforms iterative phase retrieval with high noise diffraction patterns.      
### 20.Detection and extraction of biological particles in a three-dimensional imaging of biological structures by TEM (Transmission Electron Microscopy)  [ :arrow_down: ](https://arxiv.org/pdf/2101.05062.pdf)
>  Cells segmentation shows rapid growth in biology. Indeed, using the classical segmentation methods only is not enough to segment this type of images. In this manuscript, we will present a new method of ribosomes segmentation. A pre-treatment phase will precedes the segmentation process and after that a post-processing will proceed.      
### 21.PID passivity-based control of power converters: Large-signal stability, robustness and performance  [ :arrow_down: ](https://arxiv.org/pdf/2101.05047.pdf)
>  We present a full review of PID passivity-based controllers (PBC) applied to power electronic converters, discussing limitations, unprecedented merits and potential improvements in terms of large-signal stability, robustness and performance. We provide four main contributions. First, we prove that, under perfect knowledge of the parameters, the controller ensures global exponential stability of the closed-loop system. Second, we analyze its robustness properties for a specific class of power converters, by establishing precise stability margins. Third, we propose a modification of the controller by introducing a leakage, in order to overcome some of the intrinsic performance and robustness limitations. Interestingly, such controller can be interpreted at steady-state as a droop between the input and the passive output. Fourth, we robustify the design against saturation of the control input via an appropriate monotone transformation of the controller. The obtained results are thoroughly discussed and validated by simulations on two relevant power applications: a dc/dc boost converter and an HVDC grid-connected voltage source converter.      
### 22.Analyzing and Mitigating the Impacts of GMD and EMP Events on the Electrical Grid with PowerModelsGMD.jl  [ :arrow_down: ](https://arxiv.org/pdf/2101.05042.pdf)
>  Geomagnetic disturbances and E3 high-altitude electromagnetic pulse events pose a substantial threat to the electrical grid by adversely impacting and damaging high-voltage transmission networks and equipment. To evaluate the risks and mitigate the potential effects of these hazards, this work proposes PowerModelsGMD.jl (abbr. PMsGMD). PMsGMD is an open-source Julia package that solves for quasi-dc line flow and ac power flow problems in a system subjected to geomagnetically induced currents. Unlike commercially available software solutions, it is extensible and applicable to a variety of problems. The flexibility of this framework is demonstrated by applying it to the problem of identifying mitigation strategies via line switching for a time-extended transformer heating problem. An overview of PMsGMD is presented in this paper: introduction to its design, validation of its implementation, demonstration of its performance and effectiveness, and a description of how it may be applied to aid system-operation decisions.      
### 23.An Integral Sliding-Mode Parallel Control Approach for General Nonlinear Systems via Piecewise Affine Linear Models  [ :arrow_down: ](https://arxiv.org/pdf/2101.05039.pdf)
>  The fundamental problem of stabilizing a general non-affine continuous-time nonlinear system is investigated via piecewise affine linear models (PALMs) in this paper. A novel integral sliding-mode parallel control (ISMPC) approach is developed, where an uncertain piecewise affine system (PWA) is constructed to model a non-affine continuous-time nonlinear system equivalently on a compact region containing the origin. A piecewise integral sliding-mode parallel controller is designed to globally stabilize the uncertain PWA and, consequently, to semi-globally stabilize the original nonlinear system. The proposed scheme enjoys two favorable features: i) some restrictions on the system input channel are eliminated, thus the developed method is more relaxed compared with the published approaches; and ii) it is convenient to be used to deal with both matched and unmatched uncertainties of the system. Moreover, we provide discussions about the universality analysis of the developed control strategy for two kinds of typical nonlinear systems. Simulation results from two numerical examples further demonstrate the performance of the developed control approach.      
### 24.A Lumen Segmentation Method in Ureteroscopy Images based on a Deep Residual U-Net architecture  [ :arrow_down: ](https://arxiv.org/pdf/2101.05021.pdf)
>  Ureteroscopy is becoming the first surgical treatment option for the majority of urinary affections. This procedure is performed using an endoscope which provides the surgeon with the visual information necessary to navigate inside the urinary tract. Having in mind the development of surgical assistance systems, that could enhance the performance of surgeon, the task of lumen segmentation is a fundamental part since this is the visual reference which marks the path that the endoscope should follow. This is something that has not been analyzed in ureteroscopy data before. However, this task presents several challenges given the image quality and the conditions itself of ureteroscopy procedures. In this paper, we study the implementation of a Deep Neural Network which exploits the advantage of residual units in an architecture based on U-Net. For the training of these networks, we analyze the use of two different color spaces: gray-scale and RGB data images. We found that training on gray-scale images gives the best results obtaining mean values of Dice Score, Precision, and Recall of 0.73, 0.58, and 0.92 respectively. The results obtained shows that the use of residual U-Net could be a suitable model for further development for a computer-aided system for navigation and guidance through the urinary system.      
### 25.Effective Low-Cost Time-Domain Audio Separation Using Globally Attentive Locally Recurrent Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.05014.pdf)
>  Recent research on the time-domain audio separation networks (TasNets) has brought great success to speech separation. Nevertheless, conventional TasNets struggle to satisfy the memory and latency constraints in industrial applications. In this regard, we design a low-cost high-performance architecture, namely, globally attentive locally recurrent (GALR) network. Alike the dual-path RNN (DPRNN), we first split a feature sequence into 2D segments and then process the sequence along both the intra- and inter-segment dimensions. Our main innovation lies in that, on top of features recurrently processed along the inter-segment dimensions, GALR applies a self-attention mechanism to the sequence along the inter-segment dimension, which aggregates context-aware information and also enables parallelization. Our experiments suggest that GALR is a notably more effective network than the prior work. On one hand, with only 1.5M parameters, it has achieved comparable separation performance at a much lower cost with 36.1% less runtime memory and 49.4% fewer computational operations, relative to the DPRNN. On the other hand, in a comparable model size with DPRNN, GALR has consistently outperformed DPRNN in three datasets, in particular, with a substantial margin of 2.4dB absolute improvement of SI-SNRi in the benchmark WSJ0-2mix task.      
### 26.Network Slicing for eMBB and mMTC with NOMA and Space Diversity Reception  [ :arrow_down: ](https://arxiv.org/pdf/2101.04983.pdf)
>  In this work we study the coexistence in the same Radio Access Network (RAN) of two generic services present in the Fifth Generation (5G) of wireless communication systems: enhanced Mobile BroadBand (eMBB) and massive Machine-Type Communications (mMTC). eMBB services are requested for applications that demand extremely high data rates and moderate requirements on latency and reliability, whereas mMTC enables applications for connecting a massive number of low-power and low-complexity devices. The coexistence of both services is enabled by means of network slicing and Non-Orthogonal Multiple Access (NOMA) with Successive Interference Cancellation (SIC) decoding. Under the orthogonal slicing, the radio resources are exclusively allocated to each service, while in the non-orthogonal slicing the traffics from both services overlap in the same radio resources. We evaluate the uplink performance of both services in a scenario with a multi-antenna Base Station (BS). Our simulation results show that the performance gains obtained through multiple receive antennas are more accentuated for the non-orthogonal slicing than for the orthogonal allocation of resources, such that the non-orthogonal slicing outperforms its orthogonal counterpart in terms of achievable data rates or number of connected devices as the number of receive antennas increases.      
### 27.Deep learning based prediction of Alzheimer's disease from magnetic resonance images  [ :arrow_down: ](https://arxiv.org/pdf/2101.04961.pdf)
>  Alzheimer's disease (AD) is an irreversible, progressive neuro degenerative disorder that slowly destroys memory and thinking skills and eventually, the ability to carry out the simplest tasks. In this paper, a deep neural network based prediction of AD from magnetic resonance images (MRI) is proposed. The state of the art image classification networks like VGG, residual networks (ResNet) etc. with transfer learning shows promising results. Performance of pre-trained versions of these networks are improved by transfer learning. ResNet based architecture with large number of layers is found to give the best result in terms of predicting different stages of the disease. The experiments are conducted on Kaggle dataset.      
### 28.Learning to be EXACT, Cell Detection for Asthma on Partially Annotated Whole Slide Images  [ :arrow_down: ](https://arxiv.org/pdf/2101.04943.pdf)
>  Asthma is a chronic inflammatory disorder of the lower respiratory tract and naturally occurs in humans and animals including horses. The annotation of an asthma microscopy whole slide image (WSI) is an extremely labour-intensive task due to the hundreds of thousands of cells per WSI. To overcome the limitation of annotating WSI incompletely, we developed a training pipeline which can train a deep learning-based object detection model with partially annotated WSIs and compensate class imbalances on the fly. With this approach we can freely sample from annotated WSIs areas and are not restricted to fully annotated extracted sub-images of the WSI as with classical approaches. We evaluated our pipeline in a cross-validation setup with a fixed training set using a dataset of six equine WSIs of which four are partially annotated and used for training, and two fully annotated WSI are used for validation and testing. Our WSI-based training approach outperformed classical sub-image-based training methods by up to 15\% $mAP$ and yielded human-like performance when compared to the annotations of ten trained pathologists.      
### 29.Short Circuit Current Constrained UC in High IBG-Penetrated Power Systems  [ :arrow_down: ](https://arxiv.org/pdf/2101.04918.pdf)
>  Inverter Based Generators (IBGs) have been increasing significantly in power systems. Due to the demanding thermal rating of Power Electronics (PE), their contribution to the system Short Circuit Current (SCC) is much less than that from the conventional Synchronous Generators (SGs) thus reducing the system strength and posing challenges to system protection and stability. This paper proposes a Unit Commitment (UC) model with SCC constraint in high IBG-penetrated systems to ensure minimum operation cost while maintaining the SCC level at each bus in the system. The SCC from synchronous generators as well as the IBGs are explicitly modeled in the formulation leading to an SCC constraint involving decision-dependent matrix inverse. This highly nonlinear constraint is further reformulated into linear form conservatively. The influence of the SCC constraint on the system operation and its interaction with the frequency regulation are demonstrated through simulations on IEEE 30- and 118-bus systems.      
### 30.A Data-driven Nonlinear Recharge Controller for Energy Storage in Frequency Regulation  [ :arrow_down: ](https://arxiv.org/pdf/2101.04858.pdf)
>  Battery energy storage boosts up the response speed of power system frequency regulation, but must be recharged carefully to minimize the distortion to the frequency regulation response. This paper proposes a nonlinear feedback controller to optimize the recharge for storage resources in frequency regulation. This controller is designed using a data-driven best-hindsight optimization framework, the resulting nonlinear recharge controller's gain depends on the storage state of charge as well as its power and energy rating. The developed controller is compared with two benchmark automatic generation control designs, one is a proportional-integral-based control from PJM Interconnection, the other one is based on linear-quadratic regulator. Simulation results using real area control error data from PJM Interconnection show the proposed controller achieves smaller deviations in both the area control error and the storage state of charge compared to the two benchmark controllers under various storage configurations.      
### 31.A reusable pipeline for large-scale fiber segmentation on unidirectional fiber beds using fully convolutional neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.04823.pdf)
>  Fiber-reinforced ceramic-matrix composites are advanced materials resistant to high temperatures, with application to aerospace engineering. Their analysis depends on the detection of embedded fibers, with semi-supervised techniques usually employed to separate fibers within the fiber beds. Here we present an open computational pipeline to detect fibers in ex-situ X-ray computed tomography fiber beds. To separate the fibers in these samples, we tested four different architectures of fully convolutional neural networks. When comparing our neural network approach to a semi-supervised one, we obtained Dice and Matthews coefficients greater than $92.28 \pm 9.65\%$, reaching up to $98.42 \pm 0.03 \%$, showing that the network results are close to the human-supervised ones in these fiber beds, in some cases separating fibers that human-curated algorithms could not find. The software we generated in this project is open source, released under a permissive license, and can be freely adapted and re-used in other domains. All data and instructions on how to download and use it are also available.      
### 32.Plug-and-Play Algorithms for Video Snapshot Compressive Imaging  [ :arrow_down: ](https://arxiv.org/pdf/2101.04822.pdf)
>  We consider the reconstruction problem of video snapshot compressive imaging (SCI), which captures high-speed videos using a low-speed 2D sensor (detector). The underlying principle of SCI is to modulate sequential high-speed frames with different masks and then these encoded frames are integrated into a snapshot on the sensor and thus the sensor can be of low-speed. On one hand, video SCI enjoys the advantages of low-bandwidth, low-power and low-cost. On the other hand, applying SCI to large-scale problems (HD or UHD videos) in our daily life is still challenging and one of the bottlenecks lies in the reconstruction algorithm. Exiting algorithms are either too slow (iterative optimization algorithms) or not flexible to the encoding process (deep learning based end-to-end networks). In this paper, we develop fast and flexible algorithms for SCI based on the plug-and-play (PnP) framework. In addition to the PnP-ADMM method, we further propose the PnP-GAP (generalized alternating projection) algorithm with a lower computational workload. We first employ the image deep denoising priors to show that PnP can recover a UHD color video with 30 frames from a snapshot measurement. Since videos have strong temporal correlation, by employing the video deep denoising priors, we achieve a significant improvement in the results. Furthermore, we extend the proposed PnP algorithms to the color SCI system using mosaic sensors, where each pixel only captures the red, green or blue channels. A joint reconstruction and demosaicing paradigm is developed for flexible and high quality reconstruction of color video SCI systems. Extensive results on both simulation and real datasets verify the superiority of our proposed algorithm.      
### 33.Generative Adversarial U-Net for Domain-free Medical Image Augmentation  [ :arrow_down: ](https://arxiv.org/pdf/2101.04793.pdf)
>  The shortage of annotated medical images is one of the biggest challenges in the field of medical image computing. Without a sufficient number of training samples, deep learning based models are very likely to suffer from over-fitting problem. The common solution is image manipulation such as image rotation, cropping, or resizing. Those methods can help relieve the over-fitting problem as more training samples are introduced. However, they do not really introduce new images with additional information and may lead to data leakage as the test set may contain similar samples which appear in the training set. To address this challenge, we propose to generate diverse images with generative adversarial network. In this paper, we develop a novel generative method named generative adversarial U-Net , which utilizes both generative adversarial network and U-Net. Different from existing approaches, our newly designed model is domain-free and generalizable to various medical images. Extensive experiments are conducted over eight diverse datasets including computed tomography (CT) scan, pathology, X-ray, etc. The visualization and quantitative results demonstrate the efficacy and good generalization of the proposed method on generating a wide array of high-quality medical images.      
### 34.Learning Efficient Representations for Keyword Spotting with Triplet Loss  [ :arrow_down: ](https://arxiv.org/pdf/2101.04792.pdf)
>  In the past few years, triplet loss-based metric embeddings have become a de-facto standard for several important computer vision problems, most notably, person reidentification. On the other hand, in the area of speech recognition the metric embeddings generated by the triplet loss are rarely used even for classification problems. We fill this gap showing that a combination of two representation learning techniques: a triplet loss-based embedding and a variant of kNN for classification instead of cross-entropy loss significantly (by 26% to 38%) improves the classification accuracy for convolutional networks on a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel phonetic similarity based triplet mining approach. We also match the current best published SOTA for Google Speech Commands dataset V2 10+2-class classification with an architecture that is about 6 times more compact and improve the current best published SOTA for 35-class classification on Google Speech Commands dataset V2 by over 40%.      
### 35.Stability and performance in MPC using a finite-tail cost  [ :arrow_down: ](https://arxiv.org/pdf/2101.04738.pdf)
>  In this paper, we provide a stability and performance analysis of model predictive control (MPC) schemes based on finite-tail costs. We study the MPC formulation originally proposed by Magni et al. (2001) wherein the standard terminal penalty is replaced by a finite-horizon cost of some stabilizing control law. In order to analyse the closed loop, we leverage the more recent technical machinery developed for MPC without terminal ingredients. For a specified set of initial conditions, we obtain sufficient conditions for stability and a performance bound in dependence of the prediction horizon and the extended horizon used for the terminal penalty. The main practical benefit of the considered finite-tail cost MPC formulation is the simpler offline design in combination with typically significantly less restrictive bounds on the prediction horizon to ensure stability. We demonstrate the benefits of the considered MPC formulation using the classical example of a four tank system.      
### 36.Model-Based Machine Learning for Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.04726.pdf)
>  We present an introduction to model-based machine learning for communication systems. We begin by reviewing existing strategies for combining model-based algorithms and machine learning from a high level perspective, and compare them to the conventional deep learning approach which utilizes established deep neural network (DNN) architectures trained in an end-to-end manner. Then, we focus on symbol detection, which is one of the fundamental tasks of communication receivers. We show how the different strategies of conventional deep architectures, deep unfolding, and DNN-aided hybrid algorithms, can be applied to this problem. The last two approaches constitute a middle ground between purely model-based and solely DNN-based receivers. By focusing on this specific task, we highlight the advantages and drawbacks of each strategy, and present guidelines to facilitate the design of future model-based deep learning systems for communications.      
### 37.Random Fourier Feature Based Deep Learning for Wireless Communications  [ :arrow_down: ](https://arxiv.org/pdf/2101.05254.pdf)
>  Deep-learning (DL) has emerged as a powerful machine-learning technique for several classic problems encountered in generic wireless communications. Specifically, random Fourier Features (RFF) based deep-learning has emerged as an attractive solution for several machine-learning problems; yet there is a lacuna of rigorous results to justify the viability of RFF based DL-algorithms in general. To address this gap, we attempt to analytically quantify the viability of RFF based DL. Precisely, in this paper, analytical proofs are presented demonstrating that RFF based DL architectures have lower approximation-error and probability of misclassification as compared to classical DL architectures. In addition, a new distribution-dependent RFF is proposed to facilitate DL architectures with low training-complexity. Through computer simulations, the practical application of the presented analytical results and the proposed distribution-dependent RFF, are depicted for various machine-learning problems encountered in next-generation communication systems such as: a) line of sight (LOS)/non-line of sight (NLOS) classification, and b) message-passing based detection of low-density parity check codes (LDPC) codes over nonlinear visible light communication (VLC) channels. Especially in the low training-data regime, the presented simulations show that significant performance gains are achieved when utilizing RFF maps of observations. Lastly, in all the presented simulations, it is observed that the proposed distribution-dependent RFFs significantly outperform RFFs, which make them useful for potential machine-learning/DL based applications in the context of next-generation communication systems.      
### 38.Robust CUR Decomposition: Theory and Imaging Applications  [ :arrow_down: ](https://arxiv.org/pdf/2101.05231.pdf)
>  This paper considers the use of Robust PCA in a CUR decomposition framework and applications thereof. Our main algorithms produce a robust version of column-row factorizations of matrices $\mathbf{D}=\mathbf{L}+\mathbf{S}$ where $\mathbf{L}$ is low-rank and $\mathbf{S}$ contains sparse outliers. These methods yield interpretable factorizations at low computational cost, and provide new CUR decompositions that are robust to sparse outliers, in contrast to previous methods. We consider two key imaging applications of Robust PCA: video foreground-background separation and face modeling. This paper examines the qualitative behavior of our Robust CUR decompositions on the benchmark videos and face datasets, and find that our method works as well as standard Robust PCA while being significantly faster. Additionally, we consider hybrid randomized and deterministic sampling methods which produce a compact CUR decomposition of a given matrix, and apply this to video sequences to produce canonical frames thereof.      
### 39.Automated 3D cephalometric landmark identification using computerized tomography  [ :arrow_down: ](https://arxiv.org/pdf/2101.05205.pdf)
>  Identification of 3D cephalometric landmarks that serve as proxy to the shape of human skull is the fundamental step in cephalometric analysis. Since manual landmarking from 3D computed tomography (CT) images is a cumbersome task even for the trained experts, automatic 3D landmark detection system is in a great need. Recently, automatic landmarking of 2D cephalograms using deep learning (DL) has achieved great success, but 3D landmarking for more than 80 landmarks has not yet reached a satisfactory level, because of the factors hindering machine learning such as the high dimensionality of the input data and limited amount of training data due to ethical restrictions on the use of medical data. This paper presents a semi-supervised DL method for 3D landmarking that takes advantage of anonymized landmark dataset with paired CT data being removed. The proposed method first detects a small number of easy-to-find reference landmarks, then uses them to provide a rough estimation of the entire landmarks by utilizing the low dimensional representation learned by variational autoencoder (VAE). Anonymized landmark dataset is used for training the VAE. Finally, coarse-to-fine detection is applied to the small bounding box provided by rough estimation, using separate strategies suitable for mandible and cranium. For mandibular landmarks, patch-based 3D CNN is applied to the segmented image of the mandible (separated from the maxilla), in order to capture 3D morphological features of mandible associated with the landmarks. We detect 6 landmarks around the condyle all at once, instead of one by one, because they are closely related to each other. For cranial landmarks, we again use VAE-based latent representation for more accurate annotation. In our experiment, the proposed method achieved an averaged 3D point-to-point error of 2.91 mm for 90 landmarks only with 15 paired training data.      
### 40.High-resolution agent-based modeling of COVID-19 spreading in a small town  [ :arrow_down: ](https://arxiv.org/pdf/2101.05171.pdf)
>  Amid the ongoing COVID-19 pandemic, public health authorities and the general population are striving to achieve a balance between safety and normalcy. Ever changing conditions call for the development of theory and simulation tools to finely describe multiple strata of society while supporting the evaluation of "what-if" scenarios. Particularly important is to assess the effectiveness of potential testing approaches and vaccination strategies. Here, an agent-based modeling platform is proposed to simulate the spreading of COVID-19 in small towns and cities, with a single-individual resolution. The platform is validated on real data from New Rochelle, NY -- one of the first outbreaks registered in the United States. Supported by expert knowledge and informed by reported data, the model incorporates detailed elements of the spreading within a statistically realistic population. Along with pertinent functionality such as testing, treatment, and vaccination options, the model accounts for the burden of other illnesses with symptoms similar to COVID-19. Unique to the model is the possibility to explore different testing approaches -- in hospitals or drive-through facilities -- and vaccination strategies that could prioritize vulnerable groups. Decision making by public authorities could benefit from the model, for its fine-grain resolution, open-source nature, and wide range of features.      
### 41.Comparative Analysis of Agent-Oriented Task Assignment and Path Planning Algorithms Applied to Drone Swarms  [ :arrow_down: ](https://arxiv.org/pdf/2101.05161.pdf)
>  Autonomous drone swarms are a burgeoning technology with significant applications in the field of mapping, inspection, transportation and monitoring. To complete a task, each drone has to accomplish a sub-goal within the context of the overall task at hand and navigate through the environment by avoiding collision with obstacles and with other agents in the environment. In this work, we choose the task of optimal coverage of an environment with drone swarms where the global knowledge of the goal states and its positions are known but not of the obstacles. The drones have to choose the Points of Interest (PoI) present in the environment to visit, along with the order to be visited to ensure fast coverage. We model this task in a simulation and use an agent-oriented approach to solve the problem. We evaluate different policy networks trained with reinforcement learning algorithms based on their effectiveness, i.e. time taken to map the area and efficiency, i.e. computational requirements. We couple the task assignment with path planning in an unique way for performing collision avoidance during navigation and compare a grid-based global planning algorithm, i.e. Wavefront and a gradient-based local planning algorithm, i.e. Potential Field. We also evaluate the Potential Field planning algorithm with different cost functions, propose a method to adaptively modify the velocity of the drone when using the Huber loss function to perform collision avoidance and observe its effect on the trajectory of the drones. We demonstrate our experiments in 2D and 3D simulations.      
### 42.Low Latency Scheduling Algorithms for Full-Duplex V2X Networks  [ :arrow_down: ](https://arxiv.org/pdf/2101.05127.pdf)
>  Vehicular communication systems have been an active subject of research for many years and are important technologies in the 5G and the post-5G era. One important use case is platooning which is seemingly the first step towards fully autonomous driving systems. Furthermore, a key performance parameter in all vehicular communication systems is the end-to-end packet latency. Towards this goal, full-duplex (FD) transceivers can potentially be an efficient and practical solution towards reducing the delay in platooning networks. In this paper, we study the delay performance of dynamic and TDMAbased scheduling algorithms and assess the effect of FD-enabled vehicles with imperfect self-interference cancellation (SIC). By simulations, we demonstrate the performance-complexity tradeoff of these algorithms and show that a TDMA centralized scheme with low-complexity and overhead can achieve comparable performance with a fully-dynamic, centralized algorithm.      
### 43.Formatting the Landscape: Spatial conditional GAN for varying population in satellite imagery  [ :arrow_down: ](https://arxiv.org/pdf/2101.05069.pdf)
>  Climate change is expected to reshuffle the settlement landscape: forcing people in affected areas to migrate, to change their lifeways, and continuing to affect demographic change throughout the world. Changes to the geographic distribution of population will have dramatic impacts on land use and land cover and thus constitute one of the major challenges of planning for climate change scenarios. In this paper, we explore a generative model framework for generating satellite imagery conditional on gridded population distributions. We make additions to the existing ALAE architecture, creating a spatially conditional version: SCALAE. This method allows us to explicitly disentangle population from the model's latent space and thus input custom population forecasts into the generated imagery. We postulate that such imagery could then be directly used for land cover and land use change estimation using existing frameworks, as well as for realistic visualisation of expected local change. We evaluate the model by comparing pixel and semantic reconstructions, as well as calculate the standard FID metric. The results suggest the model captures population distributions accurately and delivers a controllable method to generate realistic satellite imagery.      
### 44.Quantifying the importance of firms by means of reputation and network control  [ :arrow_down: ](https://arxiv.org/pdf/2101.05010.pdf)
>  The reputation of firms is largely channeled through their ownership structure. We use this relation to determine reputation spillovers between transnational companies and their participated companies in an ownership network core of 1318 firms. We then apply concepts of network controllability to identify minimum sets of driver nodes (MDS) of 314 firms in this network. The importance of these driver nodes is classified regarding their control contribution, their operating revenue, and their reputation. The latter two are also taken as proxies for the access costs when utilizing firms as driver nodes. Using an enrichment analysis, we find that firms with high reputation maintain the controllability of the network, but rarely become top drivers, whereas firms with medium reputation most likely become top driver nodes. We further show that MDSs with lower access costs can be used to control the reputation dynamics in the whole network.      
### 45.Machine learning approach for biopsy-based identification of eosinophilic esophagitis reveals importance of global features  [ :arrow_down: ](https://arxiv.org/pdf/2101.04989.pdf)
>  Goal: Eosinophilic esophagitis (EoE) is an allergic inflammatory condition characterized by eosinophil accumulation in the esophageal mucosa. EoE diagnosis includes a manual assessment of eosinophil levels in mucosal biopsies - a time-consuming, laborious task that is difficult to standardize. One of the main challenges in automating this process, like many other biopsy-based diagnostics, is detecting features that are small relative to the size of the biopsy. Results: In this work, we utilized hematoxylin- and eosin-stained slides from esophageal biopsies from patients with active EoE and control subjects to develop a platform based on a deep convolutional neural network (DCNN) that can classify esophageal biopsies with an accuracy of 85%, sensitivity of 82.5%, and specificity of 87%. Moreover, by combining several downscaling and cropping strategies, we show that some of the features contributing to the correct classification are global rather than specific, local features. Conclusions: We report the ability of artificial intelligence to identify EoE using computer vision analysis of esophageal biopsy slides. Further, the DCNN features associated with EoE are based on not only local eosinophils but also global histologic changes. Our approach can be used for other conditions that rely on biopsy-based histologic diagnostics.      
### 46.Deep Attention-based Representation Learning for Heart Sound Classification  [ :arrow_down: ](https://arxiv.org/pdf/2101.04979.pdf)
>  Cardiovascular diseases are the leading cause of deaths and severely threaten human health in daily life. On the one hand, there have been dramatically increasing demands from both the clinical practice and the smart home application for monitoring the heart status of subjects suffering from chronic cardiovascular diseases. On the other hand, experienced physicians who can perform an efficient auscultation are still lacking in terms of number. Automatic heart sound classification leveraging the power of advanced signal processing and machine learning technologies has shown encouraging results. Nevertheless, human hand-crafted features are expensive and time-consuming. To this end, we propose a novel deep representation learning method with an attention mechanism for heart sound classification. In this paradigm, high-level representations are learnt automatically from the recorded heart sound data. Particularly, a global attention pooling layer improves the performance of the learnt representations by estimating the contribution of each unit in feature maps. The Heart Sounds Shenzhen (HSS) corpus (170 subjects involved) is used to validate the proposed method. Experimental results validate that, our approach can achieve an unweighted average recall of 51.2% for classifying three categories of heart sounds, i. e., normal, mild, and moderate/severe annotated by cardiologists with the help of Echocardiography.      
### 47.Distributed Multi-Building Coordination for Demand Response  [ :arrow_down: ](https://arxiv.org/pdf/2101.04928.pdf)
>  This paper presents a distributed optimization algorithm tailored for solving optimal control problems arising in multi-building coordination. The buildings coordinated by a grid operator, join a demand response program to balance the voltage surge by using an energy cost defined criterion. In order to model the hierarchical structure of the building network, we formulate a distributed convex optimization problem with separable objectives and coupled affine equality constraints. A variant of the Augmented Lagrangian based Alternating Direction Inexact Newton (ALADIN) method for solving the considered class of problems is then presented along with a convergence guarantee. To illustrate the effectiveness of the proposed method, we compare it to the Alternating Direction Method of Multipliers (ADMM) by running both an ALADIN and an ADMM based model predictive controller on a benchmark case study.      
### 48.Piano Skills Assessment  [ :arrow_down: ](https://arxiv.org/pdf/2101.04884.pdf)
>  Can a computer determine a piano player's skill level? Is it preferable to base this assessment on visual analysis of the player's performance or should we trust our ears over our eyes? Since current CNNs have difficulty processing long video videos, how can shorter clips be sampled to best reflect the players skill level? In this work, we collect and release a first-of-its-kind dataset for multimodal skill assessment focusing on assessing piano player's skill level, answer the asked questions, initiate work in automated evaluation of piano playing skills and provide baselines for future work.      
### 49.A*HAR: A New Benchmark towards Semi-supervised learning for Class-imbalanced Human Activity Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2101.04859.pdf)
>  Despite the vast literature on Human Activity Recognition (HAR) with wearable inertial sensor data, it is perhaps surprising that there are few studies investigating semisupervised learning for HAR, particularly in a challenging scenario with class imbalance problem. In this work, we present a new benchmark, called A*HAR, towards semisupervised learning for class-imbalanced HAR. We evaluate state-of-the-art semi-supervised learning method on A*HAR, by combining Mean Teacher and Convolutional Neural Network. Interestingly, we find that Mean Teacher boosts the overall performance when training the classifier with fewer labelled samples and a large amount of unlabeled samples, but the classifier falls short in handling unbalanced activities. These findings lead to an interesting open problem, i.e., development of semi-supervised HAR algorithms that are class-imbalance aware without any prior knowledge on the class distribution for unlabeled samples. The dataset and benchmark evaluation are released at <a class="link-external link-https" href="https://github.com/I2RDL2/ASTAR-HAR" rel="external noopener nofollow">this https URL</a> for future research.      
### 50.A Recurrent Neural Network Approach to Roll Estimation for Needle Steering  [ :arrow_down: ](https://arxiv.org/pdf/2101.04856.pdf)
>  Steerable needles are a promising technology for delivering targeted therapies in the body in a minimally-invasive fashion, as they can curve around anatomical obstacles and hone in on anatomical targets. In order to accurately steer them, controllers must have full knowledge of the needle tip's orientation. However, current sensors either do not provide full orientation information or interfere with the needle's ability to deliver therapy. Further, torsional dynamics can vary and depend on many parameters making steerable needles difficult to accurately model, limiting the effectiveness of traditional observer methods. To overcome these limitations, we propose a model-free, learned-method that leverages LSTM neural networks to estimate the needle tip's orientation online. We validate our method by integrating it into a sliding-mode controller and steering the needle to targets in gelatin and ex vivo ovine brain tissue. We compare our method's performance against an Extended Kalman Filter, a model-based observer, achieving significantly lower targeting errors.      
### 51.GPS Spoofing Mitigation and Timing Risk Analysis in Networked PMUs via Stochastic Reachability  [ :arrow_down: ](https://arxiv.org/pdf/2101.04835.pdf)
>  To address PMU vulnerability against spoofing, we propose a set-valued state estimation technique known as Stochastic Reachability-based Distributed Kalman Filter (SR-DKF) that computes secure GPS timing across a network of receivers. Utilizing stochastic reachability, we estimate not only GPS time but also its stochastic reachable set, which is parameterized via probabilistic zonotope (p-Zonotope). While requiring known measurement error bounds in only non-spoofed conditions, we design a two-tier approach: We first perform measurement-level spoofing mitigation via deviation of measurement innovation from its expected p-Zonotope and second perform state-level timing risk analysis via intersection probability of estimated pZonotope with an unsafe set that violates IEEE C37.118.1a-2014 standards. We validate the proposed SR-DKF by subjecting a simulated receiver network to coordinated signal-level spoofing. We demonstrate improved GPS timing accuracy and successful spoofing mitigation via our SR-DKF. We validate the robustness of the estimated timing risk as the number of receivers is varied.      
### 52.Distribution System Voltage Prediction from Smart Inverters using Decentralized Regression  [ :arrow_down: ](https://arxiv.org/pdf/2101.04816.pdf)
>  As photovoltaic (PV) penetration continues to rise and smart inverter functionality continues to expand, smart inverters and other distributed energy resources (DERs) will play increasingly important roles in distribution system power management and security. In this paper, it is demonstrated that a constellation of smart inverters in a simulated distribution circuit can enable precise voltage predictions using an asynchronous and decentralized prediction algorithm. Using simulated data and a constellation of 15 inverters in a ring communication topology, the COLA algorithm is shown to accomplish the learning task required for voltage magnitude prediction with far less communication overhead than fully connected P2P learning protocols. Additionally, a dynamic stopping criterion is proposed that does not require a regularizer like the original COLA stopping criterion.      
### 53.Digital Elevation Model enhancement using Deep Learning  [ :arrow_down: ](https://arxiv.org/pdf/2101.04812.pdf)
>  We demonstrate high fidelity enhancement of planetary digital elevation models (DEMs) using optical images and deep learning with convolutional neural networks. Enhancement can be applied recursively to the limit of available optical data, representing a 90x resolution improvement in global Mars DEMs. Deep learning-based photoclinometry robustly recovers features obscured by non-ideal lighting conditions. Method can be automated at global scale. Analysis shows enhanced DEM slope errors are comparable with high resolution maps using conventional, labor intensive methods.      
### 54.Wireless Power Transfer for Future Networks: Signal Processing, Machine Learning, Computing, and Sensing  [ :arrow_down: ](https://arxiv.org/pdf/2101.04810.pdf)
>  Wireless power transfer (WPT) is an emerging paradigm that will enable using wireless to its full potential in future networks, not only to convey information but also to deliver energy. Such networks will enable trillions of future low-power devices to sense, compute, connect, and energize anywhere, anytime, and on the move. The design of such future networks brings new challenges and opportunities for signal processing, machine learning, sensing, and computing so as to make the best use of the RF radiations, spectrum, and network infrastructure in providing cost-effective and real-time power supplies to wireless devices and enable wireless-powered applications. In this paper, we first review recent signal processing techniques to make WPT and wireless information and power transfer as efficient as possible. Topics include power amplifier and energy harvester nonlinearities, active and passive beamforming, intelligent reflecting surfaces, receive combining with multi-antenna harvester, modulation, coding, waveform, massive MIMO, channel acquisition, transmit diversity, multi-user power region characterization, coordinated multipoint, and distributed antenna systems. Then, we overview two different design methodologies: the model and optimize approach relying on analytical system models, modern convex optimization, and communication theory, and the learning approach based on data-driven end-to-end learning and physics-based learning. We discuss the pros and cons of each approach, especially when accounting for various nonlinearities in wireless-powered networks, and identify interesting emerging opportunities for the approaches to complement each other. Finally, we identify new emerging wireless technologies where WPT may play a key role -- wireless-powered mobile edge computing and wireless-powered sensing -- arguing WPT, communication, computation, and sensing must be jointly designed.      
### 55.Embedded Computer Vision System Applied to a Four-Legged Line Follower Robot  [ :arrow_down: ](https://arxiv.org/pdf/2101.04804.pdf)
>  Robotics can be defined as the connection of perception to action. Taking this further, this project aims to drive a robot using an automated computer vision embedded system, connecting the robot's vision to its behavior. In order to implement a color recognition system on the robot, open source tools are chosen, such as Processing language, Android system, Arduino platform and Pixy camera. The constraints are clear: simplicity, replicability and financial viability. In order to integrate Robotics, Computer Vision and Image Processing, the robot is applied on a typical mobile robot's issue: line following. The problem of distinguishing the path from the background is analyzed through different approaches: the popular Otsu's Method, thresholding based on color combinations through experimentation and color tracking via hue and saturation. Decision making of where to move next is based on the line center of the path and is fully automated. Using a four-legged robot as platform and a camera as its only sensor, the robot is capable of successfully follow a line. From capturing the image to moving the robot, it's evident how integrative Robotics can be. The issue of this paper alone involves knowledge of Mechanical Engineering, Electronics, Control Systems and Programming. Everything related to this work was documented and made available on an open source online page, so it can be useful in learning and experimenting with robotics.      
### 56.Is NOMA Efficient in Multi-Antenna Networks? A Critical Look at Next Generation Multiple Access Techniques  [ :arrow_down: ](https://arxiv.org/pdf/2101.04802.pdf)
>  In this paper, we take a critical and fresh look at the downlink multi-antenna NOMA literature. Instead of contrasting NOMA with OMA, we contrast NOMA with two other baselines. The first is conventional Multi-User Linear Precoding (MULP). The second is Rate-Splitting Multiple Access (RSMA) based on multi-antenna Rate-Splitting (RS) and SIC. We show that there is some confusion about the benefits of NOMA, and we dispel the associated misconceptions. First, we highlight why NOMA is inefficient in multi-antenna settings based on basic multiplexing gain analysis. We stress that the issue lies in how the NOMA literature has been hastily applied to multi-antenna setups, resulting in a misuse of spatial dimensions and therefore loss in multiplexing gains and rate. Second, we show that NOMA incurs a severe multiplexing gain loss despite an increased receiver complexity due to an inefficient use of SIC receivers. Third, we emphasize that much of the merits of NOMA are due to the constant comparison to OMA instead of comparing it to MULP and RS baselines. We then expose the pivotal design constraint that multi-antenna NOMA requires one user to fully decode the messages of the other users. This design constraint is responsible for the multiplexing gain erosion, rate loss, and inefficient use of SIC receivers in multi-antenna settings. Our results confirm that NOMA should not be applied blindly to multi-antenna settings, highlight the scenarios where MULP outperforms NOMA and vice versa, and demonstrate the inefficiency, performance loss and complexity disadvantages of NOMA compared to RS. The first takeaway message is that, while NOMA is not beneficial in most multi-antenna deployments. The second takeaway message is that other non-orthogonal transmission frameworks, such as RS, exist which fully exploit the multiplexing gain and the benefits of SIC to boost the rate in multi-antenna settings.      
### 57.MP3net: coherent, minute-long music generation from raw audio with a simple convolutional GAN  [ :arrow_down: ](https://arxiv.org/pdf/2101.04785.pdf)
>  We present a deep convolutional GAN which leverages techniques from MP3/Vorbis audio compression to produce long, high-quality audio samples with long-range coherence. The model uses a Modified Discrete Cosine Transform (MDCT) data representation, which includes all phase information. Phase generation is hence integral part of the model. We leverage the auditory masking and psychoacoustic perception limit of the human ear to widen the true distribution and stabilize the training process. The model architecture is a deep 2D convolutional network, where each subsequent generator model block increases the resolution along the time axis and adds a higher octave along the frequency axis. The deeper layers are connected with all parts of the output and have the context of the full track. This enables generation of samples which exhibit long-range coherence. We use MP3net to create 95s stereo tracks with a 22kHz sample rate after training for 250h on a single Cloud TPUv2. An additional benefit of the CNN-based model architecture is that generation of new songs is almost instantaneous.      
### 58.Practical Speech Re-use Prevention in Voice-driven Services  [ :arrow_down: ](https://arxiv.org/pdf/2101.04773.pdf)
>  Voice-driven services (VDS) are being used in a variety of applications ranging from smart home control to payments using digital assistants. The input to such services is often captured via an open voice channel, e.g., using a microphone, in an unsupervised setting. One of the key operational security requirements in such setting is the freshness of the input speech. We present AEOLUS, a security overlay that proactively embeds a dynamic acoustic nonce at the time of user interaction, and detects the presence of the embedded nonce in the recorded speech to ensure freshness. We demonstrate that acoustic nonce can (i) be reliably embedded and retrieved, and (ii) be non-disruptive (and even imperceptible) to a VDS user. Optimal parameters (acoustic nonce's operating frequency, amplitude, and bitrate) are determined for (i) and (ii) from a practical perspective. Experimental results show that AEOLUS yields 0.5% FRR at 0% FAR for speech re-use prevention upto a distance of 4 meters in three real-world environments with different background noise levels. We also conduct a user study with 120 participants, which shows that the acoustic nonce does not degrade overall user experience for 94.16% of speech samples, on average, in these environments. AEOLUS can therefore be used in practice to prevent speech re-use and ensure the freshness of speech input.      
### 59.Thin Lenses and Thin Cameras  [ :arrow_down: ](https://arxiv.org/pdf/2101.04680.pdf)
>  Cassegrain designs can be used to build thin lenses. We analyze the relationships between system thickness and aperture sizes of the two mirrors as well as FoV size. Our analysis shows that decrease in lens thickness imposes tight constraint on the aperture and FoV size. To mitigate this limitation, we propose to fill the gaps between the primary and the secondary with high index material. The Gassegrain optics cuts the track length into half and high index material reduces ray angle and height, consequently the incident ray angle can be increased, i.e., the FoV angle is extended. Defining telephoto ratio as the ratio of lens thickness to focal length, we achieve telephoto ratios as small as 0.43 for a visible Cassegrain thin lens and 1.20 for an infrared Cassegrain thin lens. To achieve an arbitrary FoV coverage, we present an strategy by integrating multiple thin lenses on one plane with each unit covering a different FoV region. To avoid physically tilting each unit, we propose beam steering with metasurface. By image stitching, we obtain wide FoV images.      
### 60.Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR  [ :arrow_down: ](https://arxiv.org/pdf/1806.10306.pdf)
>  In automatic speech recognition (ASR) systems, recurrent neural network language models (RNNLM) are used to rescore a word lattice or N-best hypotheses list. Due to the expensive training, the RNNLM's vocabulary set accommodates only small shortlist of most frequent words. This leads to suboptimal performance if an input speech contains many out-of-shortlist (OOS) words. An effective solution is to increase the shortlist size and retrain the entire network which is highly inefficient. Therefore, we propose an efficient method to expand the shortlist set of a pretrained RNNLM without incurring expensive retraining and using additional training data. Our method exploits the structure of RNNLM which can be decoupled into three parts: input projection layer, middle layers, and output projection layer. Specifically, our method expands the word embedding matrices in projection layers and keeps the middle layers unchanged. In this approach, the functionality of the pretrained RNNLM will be correctly maintained as long as OOS words are properly modeled in two embedding spaces. We propose to model the OOS words by borrowing linguistic knowledge from appropriate in-shortlist words. Additionally, we propose to generate the list of OOS words to expand vocabulary in unsupervised manner by automatically extracting them from ASR output.      

# ArXiv eess --Tue, 6 Jul 2021
### 1.Reconfigurable Intelligent Surface Assisted Device-to-Device Communications  [ :arrow_down: ](https://arxiv.org/pdf/2107.02155.pdf)
>  Reconfigurable intelligent surface (RIS) technology is a promising method to enhance wireless communications services and to realize the smart radio environment. In this paper, we investigate the application of RIS in D2D communications, and maximize the sum of the transmission rate of the D2D underlaying networks in a new perspective. Instead of solving similarly formulated resource allocation problems for D2D communications, this paper treats the wireless environment as a variable by adjusting the position and phase shift of the RIS. To solve this non-convex problem, we propose a novel double deep Q-network (DDQN) based structure which is able to achieve the near-optimal performance with lower complexity and enhanced robustness. Simulation results illustrate that the proposed DDQN based structure can achieve a higher uplink rate compared to the benchmarks, meanwhile meeting the quality of service (QoS) requirements at the base station (BS) and D2D receivers.      
### 2.Economic Dispatch of an Integrated Microgrid Based on the Dynamic Process of CCGT Plant  [ :arrow_down: ](https://arxiv.org/pdf/2107.02113.pdf)
>  Intra-day economic dispatch of an integrated microgrid is a fundamental requirement to integrate distributed generators. The dynamic energy flows in cogeneration units present challenges to the energy management of the microgrid. In this paper, a novel approximate dynamic programming (ADP) approach is proposed to solve this problem based on value function approximation, which is distinct with the consideration of the dynamic process constraints of the combined-cycle gas turbine (CCGT) plant. First, we mathematically formulate the multi-time periods decision problem as a finite-horizon Markov decision process. To deal with the thermodynamic process, an augmented state vector of CCGT is introduced. Second, the proposed VFA-ADP algorithm is employed to derive the near-optimal real-time operation strategies. In addition, to guarantee the monotonicity of piecewise linear function, we apply the SPAR algorithm in the update process. To validate the effectiveness of the proposed method, we conduct experiments with comparisons to some traditional optimization methods. The results indicate that our proposed ADP method achieves better performance on the economic dispatch of the microgrid.      
### 3.Enhanced prediction for discrete-time input-delayed systems with unknown disturbances  [ :arrow_down: ](https://arxiv.org/pdf/2107.02004.pdf)
>  This paper deals with the problem of predicting the future state of discrete-time input-delayed systems in the presence of unknown disturbances that can affect both the input and the output equations of the plant. Since the disturbance is unknown, an exact prediction of the plant states is not feasible. We propose the use of a high-order extended Luenberger-type observer for the plant states, disturbances, and their finite difference variables. Then, a new method for computation of the prediction is proposed which, under certain assumptions, allows for enhanced prediction and consequently improved attenuation of the unknown disturbances. Detailed analysis of the performance of the proposed scheme is carried out, while linear matrix inequalities (LMIs) are used for the observer design in order to mitigate the prediction errors.      
### 4.Speech Synthesis from Text and Ultrasound Tongue Image-based Articulatory Input  [ :arrow_down: ](https://arxiv.org/pdf/2107.02003.pdf)
>  Articulatory information has been shown to be effective in improving the performance of HMM-based and DNN-based text-to-speech synthesis. Speech synthesis research focuses traditionally on text-to-speech conversion, when the input is text or an estimated linguistic representation, and the target is synthesized speech. However, a research field that has risen in the last decade is articulation-to-speech synthesis (with a target application of a Silent Speech Interface, SSI), when the goal is to synthesize speech from some representation of the movement of the articulatory organs. In this paper, we extend traditional (vocoder-based) DNN-TTS with articulatory input, estimated from ultrasound tongue images. We compare text-only, ultrasound-only, and combined inputs. Using data from eight speakers, we show that that the combined text and articulatory input can have advantages in limited-data scenarios, namely, it may increase the naturalness of synthesized speech compared to single text input. Besides, we analyze the ultrasound tongue recordings of several speakers, and show that misalignments in the ultrasound transducer positioning can have a negative effect on the final synthesis performance.      
### 5.A System Model-Based Approach for the Control of Power Park Modules for Grid Voltage and Frequency Services  [ :arrow_down: ](https://arxiv.org/pdf/2107.02000.pdf)
>  A new control approach is proposed for the grid insertion of Power Park Modules (PPMs). It allows full participation of these modules to ancillary services. This means that, not only their control have some positive impact on the grid frequency and voltage dynamics, but they can effectively participate to existing primary and secondary control loops together with the classic thermal/inertia synchronous generators and fulfill the same specifications both from the control and contractual points of view. To achieve such level of performances, a system approach based on an innovatory control model is proposed. The latter control model drops classic hypothesis for separation of voltage and frequency dynamics used till now in order to gather these dynamics into a small size model. From the system point of view, dynamics are grouped by time-scales of phenomena in the proposed control model. This results in more performant controls in comparison to classic approaches which orient controls to physical actuators (control of grid side converter and of generator side converter). Also, this allows coordination between control of converters and generator or, in case of multimachines specifications, among several PPMs. From the control synthesis point of view, classic robust approaches are used (like, e.g., H-infinity synthesis). Implementation and validation tests are presented for wind PPMs but the approach holds for any other type of PPM. These results will be further used to control the units of the new concept of Dynamic Virtual Power Plant introduced in the H2020 POSYTYF project.      
### 6.Design and Production of an Autonomous Rotary Composter Powered by Photovoltaic Energy  [ :arrow_down: ](https://arxiv.org/pdf/2107.01993.pdf)
>  The problem of household waste management is becoming more and more acute with the growth of economic development that the country of Morocco has experienced. Moreover, the management of this waste is a burden for the municipalities, in view of its cost, which is increasing with time. Therefore, in this work we present the design, the mechanical and photovoltaic study of a new autonomous solar composter intended mainly for households. It allows to transform organic waste in situ, into a good quality compost that serves as a soil conditioner, in a short time compared to other composting systems, these times do not exceed 4 weeks. This innovative technology will reduce the amount of waste going to final landfill, or incineration, and exploit the compost produced in gardening and horticulture, which will be a very effective solution for waste management in Morocco.      
### 7.A mmWave Oscillator Design Utilizing High-Q Active-Mode On-Chip MEMS Resonators for Improved Fundamental Limits of Phase Noise  [ :arrow_down: ](https://arxiv.org/pdf/2107.01953.pdf)
>  (RFT) allows very high-Q active mode resonators, promising crystal-less monolithic clock generation for mmWave systems. However, there is a strong need for design of mmWave oscillators that utilize the high-Q of active-mode RFT (AM-RFT) optimally, while handling unique challenges such as resonator's low electromechanical transduction. In this brief, we develop a theory and through design and post-layout simulations in 14 nm Global Foundry process, we show the first active oscillator with AM-RFT at 30 GHz, which improves the fundamental limits of phase noise and figure-of-merit as compared to the oscillators with conventional LC resonators. For AM-RFT with Q factor of 10K, post layout simulation results show that the proposed oscillator exhibits phase noise less than -140 dBc per Hz and figure-of-merit greater than 228 dBc per Hz at 1 MHz offset for 30 GHz center frequency, which are more than 25 dB better than the existing monolithic LC oscillators.      
### 8.Investigation of Practical Aspects of Single Channel Speech Separation for ASR  [ :arrow_down: ](https://arxiv.org/pdf/2107.01922.pdf)
>  Speech separation has been successfully applied as a frontend processing module of conversation transcription systems thanks to its ability to handle overlapped speech and its flexibility to combine with downstream tasks such as automatic speech recognition (ASR). However, a speech separation model often introduces target speech distortion, resulting in a sub-optimum word error rate (WER). In this paper, we describe our efforts to improve the performance of a single channel speech separation system. Specifically, we investigate a two-stage training scheme that firstly applies a feature level optimization criterion for pretraining, followed by an ASR-oriented optimization criterion using an end-to-end (E2E) speech recognition model. Meanwhile, to keep the model light-weight, we introduce a modified teacher-student learning technique for model compression. By combining those approaches, we achieve a absolute average WER improvement of 2.70% and 0.77% using models with less than 10M parameters compared with the previous state-of-the-art results on the LibriCSS dataset for utterance-wise evaluation and continuous evaluation, respectively      
### 9.PRNU Based Source Camera Identification for Webcam Videos  [ :arrow_down: ](https://arxiv.org/pdf/2107.01885.pdf)
>  This communication is about an application of image forensics where we use camera sensor fingerprints to identify source camera (SCI: Source Camera Identification) in webcam videos. Sensor or camera fingerprints are based on computing the intrinsic noise that is always present in this kind of sensors due to manufacturing imperfections. This is an unavoidable characteristic that links each sensor with its noise pattern. PRNU (Photo Response Non-Uniformity) has become the default technique to compute a camera fingerprint. There are many applications nowadays dealing with PRNU patterns for camera identification using still images. In this work we focus on video, more specifically on webcam video, because of the great importance of webcam video nowadays. Three possible methods for SCI are implemented and assessed in this work.      
### 10.Cost-Oriented Load Forecasting  [ :arrow_down: ](https://arxiv.org/pdf/2107.01861.pdf)
>  Accurate load prediction is an effective way to reduce power system operation costs. Traditionally, the mean square error (MSE) is a common-used loss function to guide the training of an accurate load forecasting model. However, the MSE loss function is unable to precisely reflect the real costs associated with forecasting errors because the cost caused by forecasting errors in the real power system is probably neither symmetric nor quadratic. To tackle this issue, this paper proposes a generalized cost-oriented load forecasting framework. Specifically, how to obtain a differentiable loss function that reflects real cost and how to integrate the loss function with regression models are studied. The economy and effectiveness of the proposed load forecasting method are verified by the case studies of an optimal dispatch problem that is built on the IEEE 30-bus system and the open load dataset from the Global Energy Forecasting Competition 2012 (GEFCom2012).      
### 11.Integrating Expert Knowledge with Domain Adaptation for Unsupervised Fault Diagnosis  [ :arrow_down: ](https://arxiv.org/pdf/2107.01849.pdf)
>  Data-driven fault diagnosis methods often require abundant labeled examples for each fault type. On the contrary, real-world data is often unlabeled and consists of mostly healthy observations and only few samples of faulty conditions. The lack of labels and fault samples imposes a significant challenge for existing data-driven fault diagnosis methods. In this paper, we aim to overcome this limitation by integrating expert knowledge with domain adaptation in a synthetic-to-real framework for unsupervised fault diagnosis. Motivated by the fact that domain experts often have a relatively good understanding on how different fault types affect healthy signals, in the first step of the proposed framework, a synthetic fault dataset is generated by augmenting real vibration samples of healthy bearings. This synthetic dataset integrates expert knowledge and encodes class information about the faults types. However, models trained solely based on the synthetic data often do not perform well because of the distinct distribution difference between the synthetically generated and real faults. To overcome this domain gap between the synthetic and real data, in the second step of the proposed framework, an imbalance-robust domain adaptation~(DA) approach is proposed to adapt the model from synthetic faults~(source) to the unlabeled real faults~(target) which suffer from severe class imbalance. The framework is evaluated on two unsupervised fault diagnosis cases for bearings, the CWRU laboratory dataset and a real-world wind-turbine dataset. Experimental results demonstrate that the generated faults are effective for encoding fault type information and the domain adaptation is robust against the different levels of class imbalance between faults.      
### 12.Dual Synchronous Generator: A New Solution for Grid-Forming  [ :arrow_down: ](https://arxiv.org/pdf/2107.01805.pdf)
>  In order to improve synchronous stability of the power system with high-penetration power electronics, it is necessary for voltage source converter (VSC) to provide inertial and frequency regulation. In practical application, VSC is better to be controlled as a current source due to its weak overcurrent capacity. According to the characteristic, a dual synchronous theory is proposed to analyze the synchronization between current sources in this paper. Based on dual synchronous theory, a dual synchronous generator (DSG) control is applied in VSC to form inertial current source. In addition, a braking control is embedded in DSG control to improve the transient stability of VSC. Finally, hardware-in-the-loop experiments verify the effectiveness of the theory and the control method.      
### 13.Energy Management Strategy for Unmanned Tracked Vehicles Based on Local Speed Planning  [ :arrow_down: ](https://arxiv.org/pdf/2107.01762.pdf)
>  The hybrid electric system has good potential for unmanned tracked vehicles due to its excellent power and economy. Due to unmanned tracked vehicles have no traditional driving devices, and the driving cycle is uncertain, it brings new challenges to conventional energy management strategies. This paper proposes a novel energy management strategy for unmanned tracked vehicles based on local speed planning. The contributions are threefold. Firstly, a local speed planning algorithm is adopted for the input of driving cycle prediction to avoid the dependence of traditional vehicles on driver's operation. Secondly, a prediction model based on Convolutional Neural Networks and Long Short-Term Memory (CNN-LSTM) is proposed, which is used to process both the planned and the historical velocity series to improve the prediction accuracy. Finally, based on the prediction results, the model predictive control algorithm is used to realize the real-time optimization of energy management. The validity of the method is verified by simulation using collected data from actual field experiments of our unmanned tracked vehicle. Compared with multi-step neural networks, the prediction model based on CNN-LSTM improves the prediction accuracy by 20%. Compared with the traditional regular energy management strategy, the energy management strategy based on model predictive control reduces fuel consumption by 7%.      
### 14.A comparative study of eight human auditory models of monaural processing  [ :arrow_down: ](https://arxiv.org/pdf/2107.01753.pdf)
>  A number of auditory models have been developed using diverging approaches, either physiological or perceptual, but they share comparable stages of signal processing, as they are inspired by the same constitutive parts of the auditory system. We compare eight monaural models that are openly accessible in the Auditory Modelling Toolbox. We discuss the considerations required to make the model outputs comparable to each other, as well as the results for the following model processing stages or their equivalents: outer and middle ear, cochlear filter bank, inner hair cell, auditory nerve synapse, cochlear nucleus, and inferior colliculus. The discussion includes some practical considerations related to the use of monaural stages in binaural frameworks.      
### 15.Controllable cardiac synthesis via disentangled anatomy arithmetic  [ :arrow_down: ](https://arxiv.org/pdf/2107.01748.pdf)
>  Acquiring annotated data at scale with rare diseases or conditions remains a challenge. It would be extremely useful to have a method that controllably synthesizes images that can correct such underrepresentation. Assuming a proper latent representation, the idea of a "latent vector arithmetic" could offer the means of achieving such synthesis. A proper representation must encode the fidelity of the input data, preserve invariance and equivariance, and permit arithmetic operations. Motivated by the ability to disentangle images into spatial anatomy (tensor) factors and accompanying imaging (vector) representations, we propose a framework termed "disentangled anatomy arithmetic", in which a generative model learns to combine anatomical factors of different input images such that when they are re-entangled with the desired imaging modality (e.g. MRI), plausible new cardiac images are created with the target characteristics. To encourage a realistic combination of anatomy factors after the arithmetic step, we propose a localized noise injection network that precedes the generator. Our model is used to generate realistic images, pathology labels, and segmentation masks that are used to augment the existing datasets and subsequently improve post-hoc classification and segmentation tasks. Code is publicly available at <a class="link-external link-https" href="https://github.com/vios-s/DAA-GAN" rel="external noopener nofollow">this https URL</a>.      
### 16.Scalable Zonotopic Under-approximation of Backward Reachable Sets for Uncertain Linear Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.01724.pdf)
>  Zonotopes are widely used for over-approximating forward reachable sets of uncertain linear systems. In this paper, we use zonotopes to achieve more scalable algorithms that under-approximate backward reachable sets for uncertain linear systems. The main difference is that the backward reachability analysis is a two-player game and involves Minkowski difference operations, but zonotopes are not closed under such operations. We under-approximate this Minkowski difference with a zonotope, which can be obtained by solving a linear optimization problem. We further develop an efficient zonotope order reduction technique to bound the complexity of the obtained zonotopic under-approximations. The proposed approach is evaluated against existing approaches using randomly generated instances, and illustrated with an aircraft position control system.      
### 17.Model Predictive Control for Electron Beam Stabilization in a Synchrotron  [ :arrow_down: ](https://arxiv.org/pdf/2107.01694.pdf)
>  Electron beam stabilization in a synchrotron is a disturbance rejection problem, with hundreds of inputs and outputs, that is sampled at frequencies higher than $10$ kHz. In this feasibility study, we focus on the practical issues of an efficient implementation of model predictive control (MPC) for the heavily ill-conditioned plant of the electron beam stabilization problem. To obtain a tractable control problem that can be solved using only a few iterations of the fast gradient method, we investigate different methods for preconditioning the resulting optimization problem and relate our findings to standard regularization techniques from cross-directional control. We summarize the single- and multi-core implementations of our control algorithm on a digital signal processor (DSP), and show that MPC can be executed at the rate required for synchrotron control. MPC overcomes various problems of standard electron beam stabilization techniques, and the successful implementation can increase the stability of photon beams in synchrotron light sources.      
### 18.COVID-VIT: Classification of COVID-19 from CT chest images based on vision transformer models  [ :arrow_down: ](https://arxiv.org/pdf/2107.01682.pdf)
>  This paper is responding to the MIA-COV19 challenge to classify COVID from non-COVID based on CT lung images. The COVID-19 virus has devastated the world in the last eighteen months by infecting more than 182 million people and causing over 3.9 million deaths. The overarching aim is to predict the diagnosis of the COVID-19 virus from chest radiographs, through the development of explainable vision transformer deep learning techniques, leading to population screening in a more rapid, accurate and transparent way. In this competition, there are 5381 three-dimensional (3D) datasets in total, including 1552 for training, 374 for evaluation and 3455 for testing. While most of the data volumes are in axial view, there are a number of subjects' data are in coronal or sagittal views with 1 or 2 slices are in axial view. Hence, while 3D data based classification is investigated, in this competition, 2D images remains the main focus. Two deep learning methods are studied, which are vision transformer (ViT) based on attention models and DenseNet that is built upon conventional convolutional neural network (CNN). Initial evaluation results based on validation datasets whereby the ground truth is known indicate that ViT performs better than DenseNet with F1 scores being 0.76 and 0.72 respectively. Codes are available at GitHub at &lt;https://github/xiaohong1/COVID-ViT&gt;.      
### 19.Optimal Signal Selection for Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2107.01676.pdf)
>  The focus of this research is sensor applications including radar and sonar. Optimal sensing means achieving the best signal quality with the least time and energy cost, which allows processing more data. This paper presents novel work by using an integer linear programming "algorithm" to achieve optimal sensing by selecting the best possible number of signals of a type or a combination of multiple types of signals to ensure the best sensing quality considering all given constraints. A solution based on a heuristic algorithm is implemented to improve the computing time performance. What is novel in this solution is synthesis of an optimized signal mix using information such as but not limited to signal quality, energy and computing time.      
### 20.Synchronization Strategies for Multi-agent Networked Control Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.01605.pdf)
>  With the advent of 21st century and increasing advancements in the field of technology and connectivity, inter-networking in real-time has achieved great importance. Distributed control and multi-agent paradigm has groped rapidly with history of big time failures of centralized systems in the past. The concepts of synchronization and network control systems have been used extensively in the near past to map, analyze and solve defined set of objectives. In this thesis, a diverse set of applications from power flow point of view are taken into consideration and modelled/analyzed using synchronization as the central theme. These systems are proposed (or assumed) to be network connected and its control has been devised accordingly. It has been shown how some examples from nature can help recreate similar dynamics synthetically and help achieve system objectives. Few of the applications of the smart world have been ascribed in the thesis and distributed control of these seen from a multi-agent perspective have been devised in order to better design and operate such systems in real-time. Synchronization happens to be the heart of all the networks, as all the agents work in tandem in order to provide to a common objective as well abide by the defined constraints. As an inflection to the work, I set up a platform for development of new distributed and fast acting control strategies for conventional as well as futuristic control systems existing/non-existing in the literature. As a major contribution of this dissertation, by combining the ideas from physics and power systems, I open up various interesting phenomena already existing in either fields to be explored for one another.      
### 21.Graphical State Space Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.01602.pdf)
>  In this paper, a new framework, named as graphical state space model, is proposed for the real time optimal estimation of one kind of nonlinear state space model. By discretizing this kind of system model as an equation which can not be solved by Extended Kalman filter, factor graph optimization can outperform Extended Kalman filter in some cases. A simple nonlinear example are given to demonstrate the efficiency of this framework.      
### 22.Wireless Indoor Simultaneous Localization and Mapping Using Reconfigurable Intelligent Surface  [ :arrow_down: ](https://arxiv.org/pdf/2107.01582.pdf)
>  Indoor wireless simultaneous localization and mapping (SLAM) is considered as a promising technique to provide positioning services in future 6G systems. However, the accuracy of traditional wireless SLAM system heavily relies on the quality of propagation paths, which is limited by the uncontrollable wireless environment. In this paper, we propose a novel SLAM system assisted by a reconfigurable intelligent surface (RIS) to address this issue. By configuring the phase shifts of the RIS, the strength of received signals can be enhanced to resist the disturbance of noise. However, the selection of phase shifts heavily influences the localization and mapping phase, which makes the design very challenging. To tackle this challenge, we formulate the RIS-assisted indoor SLAM optimization problem and design an error minimization algorithm for it. Simulations show that the RIS assisted SLAM system can decrease the positioning error by at least 31% compared with benchmark schemes.      
### 23.Virtual synchronous generator of PV generation without energy storage for frequency support in autonomous microgrid  [ :arrow_down: ](https://arxiv.org/pdf/2107.01560.pdf)
>  In autonomous microgrids frequency regulation (FR) is a critical issue, especially with a high level of penetration of the photovoltaic (PV) generation. In this study, a novel virtual synchronous generator (VSG) control for PV generation was introduced to provide frequency support without energy storage. PV generation reserve a part of the active power in accordance with the pre-defined power versus voltage curve. Based on the similarities of the synchronous generator power-angle characteristic curve and the PV array characteristic curve, PV voltage Vpv can be analogized to the power angle {\delta}. An emulated governor (droop control) and the swing equation control is designed and applied to the DC-DC converter. PV voltage deviation is subsequently generated and the pre-defined power versus voltage curve is modified to provide the primary frequency and inertia support. A simulation model of an autonomous microgrid with PV, storage, and diesel generator was built. The feasibility and effectiveness of the proposed VSG strategy are examined under different operating conditions.      
### 24.EditSpeech: A Text Based Speech Editing System Using Partial Inference and Bidirectional Fusion  [ :arrow_down: ](https://arxiv.org/pdf/2107.01554.pdf)
>  This paper presents the design, implementation and evaluation of a speech editing system, named EditSpeech, which allows a user to perform deletion, insertion and replacement of words in a given speech utterance, without causing audible degradation in speech quality and naturalness. The EditSpeech system is developed upon a neural text-to-speech (NTTS) synthesis framework. Partial inference and bidirectional fusion are proposed to effectively incorporate the contextual information related to the edited region and achieve smooth transition at both left and right boundaries. Distortion introduced to the unmodified parts of the utterance is alleviated. The EditSpeech system is developed and evaluated on English and Chinese in multi-speaker scenarios. Objective and subjective evaluation demonstrate that EditSpeech outperforms a few baseline systems in terms of low spectral distortion and preferred speech quality. Audio samples are available online for demonstration <a class="link-external link-https" href="https://daxintan-cuhk.github.io/EditSpeech/" rel="external noopener nofollow">this https URL</a> .      
### 25.Towards Neural Diarization for Unlimited Numbers of Speakers Using Global and Local Attractors  [ :arrow_down: ](https://arxiv.org/pdf/2107.01545.pdf)
>  Attractor-based end-to-end diarization is achieving comparable accuracy to the carefully tuned conventional clustering-based methods on challenging datasets. However, the main drawback is that it cannot deal with the case where the number of speakers is larger than the one observed during training. This is because its speaker counting relies on supervised learning. In this work, we introduce an unsupervised clustering process embedded in the attractor-based end-to-end diarization. We first split a sequence of frame-wise embeddings into short subsequences and then perform attractor-based diarization for each subsequence. Given subsequence-wise diarization results, inter-subsequence speaker correspondence is obtained by unsupervised clustering of the vectors computed from the attractors from all the subsequences. This makes it possible to produce diarization results of a large number of speakers for the whole recording even if the number of output speakers for each subsequence is limited. Experimental results showed that our method could produce accurate diarization results of an unseen number of speakers. Our method achieved 11.84 %, 28.33 %, and 19.49 % on the CALLHOME, DIHARD II, and DIHARD III datasets, respectively, each of which is better than the conventional end-to-end diarization methods.      
### 26.A N-Path Receiver With Harmonic Response Suppression  [ :arrow_down: ](https://arxiv.org/pdf/2107.01535.pdf)
>  A downconversion receiver employing a switch-based N-path filter with reduced harmonic response around the third- and fifth- LO harmonics is presented. The N-path filter is placed in a frequency-translation feedback loop that is effective at the 3rd and the 5th LO harmonics to mitigate harmonic downconversion. A pulse-width-modulated LO (PWM-LO) clocking scheme is used in the feedback upconverter to reduce the noise injected around the LO harmonic at the input of N-path downconverter. The compression resulting from blockers around the 3rd and the 5th LO harmonics is also suppressed as a result of reduced harmonic response. Compensation of peak frequency shift of the N-path response due to parasitic input capacitance is also described.      
### 27.TENET: A Time-reversal Enhancement Network for Noise-robust ASR  [ :arrow_down: ](https://arxiv.org/pdf/2107.01531.pdf)
>  Due to the unprecedented breakthroughs brought about by deep learning, speech enhancement (SE) techniques have been developed rapidly and play an important role prior to acoustic modeling to mitigate noise effects on speech. To increase the perceptual quality of speech, current state-of-the-art in the SE field adopts adversarial training by connecting an objective metric to the discriminator. However, there is no guarantee that optimizing the perceptual quality of speech will necessarily lead to improved automatic speech recognition (ASR) performance. In this study, we present TENET, a novel Time-reversal Enhancement NETwork, which leverages the transformation of an input noisy signal itself, i.e., the time-reversed version, in conjunction with the siamese network and complex dual-path transformer to promote SE performance for noise-robust ASR. Extensive experiments conducted on the Voicebank-DEMAND dataset show that TENET can achieve state-of-the-art results compared to a few top-of-the-line methods in terms of both SE and ASR evaluation metrics. To demonstrate the model generalization ability, we further evaluate TENET on the test set of scenarios contaminated with unseen noise, and the results also confirm the superiority of this promising method.      
### 28.COVID-Rate: An Automated Framework for Segmentation of COVID-19 Lesions from Chest CT Scans  [ :arrow_down: ](https://arxiv.org/pdf/2107.01527.pdf)
>  Novel Coronavirus disease (COVID-19) is a highly contagious respiratory infection that has had devastating effects on the world. Recently, new COVID-19 variants are emerging making the situation more challenging and threatening. Evaluation and quantification of COVID-19 lung abnormalities based on chest Computed Tomography (CT) scans can help determining the disease stage, efficiently allocating limited healthcare resources, and making informed treatment decisions. During pandemic era, however, visual assessment and quantification of COVID-19 lung lesions by expert radiologists become expensive and prone to error, which raises an urgent quest to develop practical autonomous solutions. In this context, first, the paper introduces an open access COVID-19 CT segmentation dataset containing 433 CT images from 82 patients that have been annotated by an expert radiologist. Second, a Deep Neural Network (DNN)-based framework is proposed, referred to as the COVID-Rate, that autonomously segments lung abnormalities associated with COVID-19 from chest CT scans. Performance of the proposed COVID-Rate framework is evaluated through several experiments based on the introduced and external datasets. The results show a dice score of 0:802 and specificity and sensitivity of 0:997 and 0:832, respectively. Furthermore, the results indicate that the COVID-Rate model can efficiently segment COVID-19 lesions in both 2D CT images and whole lung volumes. Results on the external dataset illustrate generalization capabilities of the COVID-Rate model to CT images obtained from a different scanner.      
### 29.Pulmonary Vessel Segmentation based on Orthogonal Fused U-Net++ of Chest CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.01502.pdf)
>  Pulmonary vessel segmentation is important for clinical diagnosis of pulmonary diseases, while is also challenging due to the complicated structure. In this work, we present an effective framework and refinement process of pulmonary vessel segmentation from chest computed tomographic (CT) images. The key to our approach is a 2.5D segmentation network applied from three orthogonal axes, which presents a robust and fully automated pulmonary vessel segmentation result with lower network complexity and memory usage compared to 3D networks. The slice radius is introduced to convolve the adjacent information of the center slice and the multi-planar fusion optimizes the presentation of intra- and inter- slice features. Besides, the tree-like structure of the pulmonary vessel is extracted in the post-processing process, which is used for segmentation refining and pruning. In the evaluation experiments, three fusion methods are tested and the most promising one is compared with the state-of-the-art 2D and 3D structures on 300 cases of lung images randomly selected from LIDC dataset. Our method outperforms other network structures by a large margin and achieves by far the highest average DICE score of 0.9272 and precision of 0.9310, as per our knowledge from the pulmonary vessel segmentation models available in the literature.      
### 30.Learning Decentralized Wireless Resource Allocations with Graph Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.01489.pdf)
>  We consider the broad class of decentralized optimal resource allocation problems in wireless networks, which can be formulated as a constrained statistical learning problems with a localized information structure. We develop the use of Aggregation Graph Neural Networks (Agg-GNNs), which process a sequence of delayed and potentially asynchronous graph aggregated state information obtained locally at each transmitter from multi-hop neighbors. We further utilize model-free primal-dual learning methods to optimize performance subject to constraints in the presence of delay and asynchrony inherent to decentralized networks. We demonstrate a permutation equivariance property of the resulting resource allocation policy that can be shown to facilitate transference to dynamic network configurations. The proposed framework is validated with numerical simulations that exhibit superior performance to baseline strategies.      
### 31.Custom Deep Neural Network for 3D Covid Chest CT-scan Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.01456.pdf)
>  3D CT-scan base on chest is one of the controversial topisc of the researcher nowadays. There are many tasks to diagnose the disease through CT-scan images, include Covid19. In this paper, we propose a method that custom and combine Deep Neural Network to classify the series of 3D CT-scans chest images. In our methods, we experiment with 2 backbones is DenseNet 121 and ResNet 101. In this proposal, we separate the experiment into 2 tasks, one is for 2 backbones combination of ResNet and DenseNet, one is for DenseNet backbones combination.      
### 32.Deployment Optimization for Meta-material Based Internet of Things  [ :arrow_down: ](https://arxiv.org/pdf/2107.01452.pdf)
>  In this paper, we propose a Meta-IoT system to achieve ubiquitous deployment and pervasive sensing for future Internet of Things (IoT). In such a system, sensors are composed of dedicated meta-materials whose frequency response of wireless signal is sensitive to environmental conditions. Therefore, we can obtain sensing results from reflected signals through Meta-IoT devices and the energy supplies for IoT devices can be removed. Nevertheless, in the Meta-IoT system, because the positions of the Meta-IoT devices decide the interference among the reflected signals, which may make the sensing results of different positions hard to be distinguished and the estimation function should integrate the results to reconstruct 3D distribution. It is a challenge to optimize the positions of the Meta-IoT devices to ensure sensing accuracy of 3D environmental conditions. To handle this challenge, we establish a mathematical model of Meta-IoT devices' sensing and transmission to calculate the interference between Meta-IoT devices. Then, an algorithm is proposed to jointly minimize the interference and reconstruction error by optimizing the Meta-IoT devices' position and the estimation function. The simulation results verify that the proposed system can obtain a 3D environmental conditions' distribution with high accuracy.      
### 33.Meta-material Sensors based Internet of Things for 6G Communications  [ :arrow_down: ](https://arxiv.org/pdf/2107.01432.pdf)
>  In the coming 6G communications, the internet of things (IoT) serves as a key enabler to collect environmental information and is expected to achieve ubiquitous deployment. However, it is challenging for traditional IoT sensors to meet this demand because of their requirement of power supplies and frequent maintenance, which is due to their sense-then-transmit working principle. To address this challenge, we propose a meta-IoT sensing system, where the IoT sensors are based on specially designed meta-materials. The meta-IoT sensors achieve simultaneous sensing and transmission and thus require no power supplies. In order to design a meta-IoT sensing system with optimal sensing accuracy, we jointly consider the sensing and transmission of meta-IoT sensors and propose an efficient algorithm to jointly optimizes the meta-IoT structure and the sensing function at the receiver of the system. As an example, we apply the proposed system and algorithm in sensing environmental temperature and humidity levels. Simulation results show that by using the proposed algorithm, the sensing accuracy can be significantly increased.      
### 34.WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative Cases and Vaticinating the Probability of Maturation to ARDS using Posteroanterior Chest X-Rays  [ :arrow_down: ](https://arxiv.org/pdf/2107.01392.pdf)
>  Coronavirus is a large virus family consisting of diverse viruses, some of which disseminate among mammals and others cause sickness among humans. COVID-19 is highly contagious and is rapidly spreading, rendering its early diagnosis of preeminent status. Researchers, medical specialists and organizations all over the globe have been working tirelessly to combat this virus and help in its containment. In this paper, a novel neural network called WisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays. The WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is a two-layered convolutional Neural Network (CNN), which takes chest x-ray images as input. Both layers of the proposed neural network consist of a number of neural networks each. The dataset used for this study consists of chest x-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on GitHub, and the chest x-ray images of healthy lungs and lungs affected by viral and bacterial pneumonia were obtained from Kaggle. The network not only pinpoints the presence of COVID-19, but also gives the probability of the disease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus, predicting the progression of the disease in the COVID-19 positive patients. The network also slender the occurrences of false negative cases by employing a high threshold value, thus aids in curbing the spread of the disease and gives an accuracy of 100% for successfully predicting COVID-19 among the chest x-rays of patients affected with COVID-19, bacterial and viral pneumonia.      
### 35.Low Rank Quaternion Matrix Recovery via Logarithmic Approximation  [ :arrow_down: ](https://arxiv.org/pdf/2107.01380.pdf)
>  In color image processing, image completion aims to restore missing entries from the incomplete observation image. Recently, great progress has been made in achieving completion by approximately solving the rank minimization problem. In this paper, we utilize a novel quaternion matrix logarithmic norm to approximate rank under the quaternion matrix framework. From one side, unlike the traditional matrix completion method that handles RGB channels separately, the quaternion-based method is able to avoid destroying the structure of images via putting the color image in a pure quaternion matrix. From the other side, the logarithmic norm induces a more accurate rank surrogate. Based on the logarithmic norm, we take advantage of not only truncated technique but also factorization strategy to achieve image restoration. Both strategies are optimized based on the alternating minimization framework. The experimental results demonstrate that the use of logarithmic surrogates in the quaternion domain is more superior in solving the problem of color images completion.      
### 36.EAR-NET: Error Attention Refining Network For Retinal Vessel Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.01351.pdf)
>  The precise detection of blood vessels in retinal images is crucial to the early diagnosis of the retinal vascular diseases, e.g., diabetic, hypertensive and solar retinopathies. Existing works often fail in predicting the abnormal areas, e.g, sudden brighter and darker areas and are inclined to predict a pixel to background due to the significant class imbalance, leading to high accuracy and specificity while low sensitivity. To that end, we propose a novel error attention refining network (ERA-Net) that is capable of learning and predicting the potential false predictions in a two-stage manner for effective retinal vessel segmentation. The proposed ERA-Net in the refine stage drives the model to focus on and refine the segmentation errors produced in the initial training stage. To achieve this, unlike most previous attention approaches that run in an unsupervised manner, we introduce a novel error attention mechanism which considers the differences between the ground truth and the initial segmentation masks as the ground truth to supervise the attention map learning. Experimental results demonstrate that our method achieves state-of-the-art performance on two common retinal blood vessel datasets.      
### 37.CT Image Harmonization for Enhancing Radiomics Studies  [ :arrow_down: ](https://arxiv.org/pdf/2107.01337.pdf)
>  While remarkable advances have been made in Computed Tomography (CT), capturing CT images with non-standardized protocols causes low reproducibility regarding radiomic features, forming a barrier on CT image analysis in a large scale. RadiomicGAN is developed to effectively mitigate the discrepancy caused by using non-standard reconstruction kernels. RadiomicGAN consists of hybrid neural blocks including both pre-trained and trainable layers adopted to learn radiomic feature distributions efficiently. A novel training approach, called Dynamic Window-based Training, has been developed to smoothly transform the pre-trained model to the medical imaging domain. Model performance evaluated using 1401 radiomic features show that RadiomicGAN clearly outperforms the state-of-art image standardization models.      
### 38.VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and Labeling of Individual Ribs on Chest X-rays  [ :arrow_down: ](https://arxiv.org/pdf/2107.01327.pdf)
>  We introduce a new benchmark dataset, namely VinDr-RibCXR, for automatic segmentation and labeling of individual ribs from chest X-ray (CXR) scans. The VinDr-RibCXR contains 245 CXRs with corresponding ground truth annotations provided by human experts. A set of state-of-the-art segmentation models are trained on 196 images from the VinDr-RibCXR to segment and label 20 individual ribs. Our best performing model obtains a Dice score of 0.834 (95% CI, 0.810--0.853) on an independent test set of 49 images. Our study, therefore, serves as a proof of concept and baseline performance for future research.      
### 39.A study of CNN capacity applied to Left Venticle Segmentation in Cardiac MRI  [ :arrow_down: ](https://arxiv.org/pdf/2107.01318.pdf)
>  CNN (Convolutional Neural Network) models have been successfully used for segmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance Imaging), providing clinical <a class="link-external link-http" href="http://measurements.In" rel="external noopener nofollow">this http URL</a> practice, two questions arise with deployment of CNNs: 1) when is it better to use a shallow model instead of a deeper one? 2) how the size of a dataset might change the network performance? We propose a framework to answer them, by experimenting with deep and shallow versions of three U-Net families, trained from scratch in six subsets varying from 100 to 10,000 images, different network sizes, learning rates and regularization values. 1620 models were evaluated using 5-foldcross-validation by loss and DICE. The results indicate that: sample size affects performance more than architecture or hyper-parameters; in small samples the performance is more sensitive to hyper-parameters than architecture; the performance difference between shallow and deeper networks is not the same across families.      
### 40.Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.01275.pdf)
>  Recently, attention-based encoder-decoder (AED) models have shown high performance for end-to-end automatic speech recognition (ASR) across several tasks. Addressing overconfidence in such models, in this paper we introduce the concept of relaxed attention, which is a simple gradual injection of a uniform distribution to the encoder-decoder attention weights during training that is easily implemented with two lines of code. We investigate the effect of relaxed attention across different AED model architectures and two prominent ASR tasks, Wall Street Journal (WSJ) and Librispeech. We found that transformers trained with relaxed attention outperform the standard baseline models consistently during decoding with external language models. On WSJ, we set a new benchmark for transformer-based end-to-end speech recognition with a word error rate of 3.65%, outperforming state of the art (4.20%) by 13.1% relative, while introducing only a single hyperparameter. Upon acceptance, models will be published on github.      
### 41.Unbiasing Procedures for Scale-invariant Multi-reference Alignment  [ :arrow_down: ](https://arxiv.org/pdf/2107.01274.pdf)
>  This article discusses a generalization of the 1-dimensional multi-reference alignment problem. The goal is to recover a hidden signal from many noisy observations, where each noisy observation includes a random translation and random dilation of the hidden signal, as well as high additive noise. We propose a method that recovers the power spectrum of the hidden signal by applying a data-driven, nonlinear unbiasing procedure, and thus the hidden signal is obtained up to an unknown phase. An unbiased estimator of the power spectrum is defined, whose error depends on the sample size and noise levels, and we precisely quantify the convergence rate of the proposed estimator. The unbiasing procedure relies on knowledge of the dilation distribution, and we implement an optimization procedure to learn the dilation variance when this parameter is unknown. Our theoretical work is supported by extensive numerical experiments on a wide range of signals.      
### 42.Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition  [ :arrow_down: ](https://arxiv.org/pdf/2107.01269.pdf)
>  Attention-based end-to-end automatic speech recognition (ASR) systems have recently demonstrated state-of-the-art results for numerous tasks. However, the application of self-attention and attention-based encoder-decoder models remains challenging for streaming ASR, where each word must be recognized shortly after it was spoken. In this work, we present the dual causal/non-causal self-attention (DCN) architecture, which in contrast to restricted self-attention prevents the overall context to grow beyond the look-ahead of a single layer when used in a deep architecture. DCN is compared to chunk-based and restricted self-attention using streaming transformer and conformer architectures, showing improved ASR performance over restricted self-attention and competitive ASR results compared to chunk-based self-attention, while providing the advantage of frame-synchronous processing. Combined with triggered attention, the proposed streaming end-to-end ASR systems obtained state-of-the-art results on the LibriSpeech, HKUST, and Switchboard ASR tasks.      
### 43.Ensemble Kalman Filter (EnKF) for Reinforcement Learning (RL)  [ :arrow_down: ](https://arxiv.org/pdf/2107.01244.pdf)
>  This paper is concerned with the problem of representing and learning the optimal control law for the linear quadratic Gaussian (LQG) optimal control problem. In recent years, there is a growing interest in re-visiting this classical problem, in part due to the successes of reinforcement learning (RL). The main question of this body of research (and also of our paper) is to approximate the optimal control law {\em without} explicitly solving the Riccati equation. For this purpose, a novel simulation-based algorithm, namely an ensemble Kalman filter (EnKF), is introduced in this paper. The algorithm is used to obtain formulae for optimal control, expressed entirely in terms of the EnKF particles. For the general partially observed LQG problem, the proposed EnKF is combined with a standard EnKF (for the estimation problem) to obtain the optimal control input based on the use of the separation principle. A nonlinear extension of the algorithm is also discussed which clarifies the duality roots of the proposed EnKF. The theoretical results and algorithms are illustrated with numerical experiments.      
### 44.No-Reference Quality Assessment for Colored Point Cloud and Mesh Based on Natural Scene Statistics  [ :arrow_down: ](https://arxiv.org/pdf/2107.02041.pdf)
>  To improve the viewer's quality of experience and optimize processing systems in computer graphics applications, the 3D quality assessment (3D-QA) has become an important task in the multimedia area. Point cloud and mesh are the two most widely used electronic representation formats of 3D models, the quality of which is quite sensitive to operations like simplification and compression. Therefore, many studies concerning point cloud quality assessment (PCQA) and mesh quality assessment (MQA) have been carried out to measure the visual quality degradations caused by lossy operations. However, a large part of previous studies utilizes full-reference (FR) metrics, which means they may fail to predict the accurate quality level of 3D models when the reference 3D model is not available. Furthermore, limited numbers of 3D-QA metrics are carried out to take color features into consideration, which significantly restricts the effectiveness and scope of application. In many quality assessment studies, natural scene statistics (NSS) have shown a good ability to quantify the distortion of natural scenes to statistical parameters. Therefore, we propose an NSS-based no-reference quality assessment metric for colored 3D models. In this paper, quality-aware features are extracted from the aspects of color and geometry directly from the 3D models. Then the statistic parameters are estimated using different distribution models to describe the characteristic of the 3D models. Our method is mainly validated on the colored point cloud quality assessment database (SJTU-PCQA) and the colored mesh quality assessment database (CMDM). The experimental results show that the proposed method outperforms all the state-of-art NR 3D-QA metrics and obtains an acceptable gap with the state-of-art FR 3D-QA metrics.      
### 45.DeepWL: Robust EPID based Winston-Lutz Analysis using Deep Learning and Synthetic Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2107.01976.pdf)
>  Radiation therapy requires clinical linear accelerators to be mechanically and dosimetrically calibrated to a high standard. One important quality assurance test is the Winston-Lutz test which localizes the radiation isocentre of the linac. In the current work we demonstrate a novel method of analysing EPID based Winston-Lutz QA images using a deep learning model trained only on synthetic image <a class="link-external link-http" href="http://data.In" rel="external noopener nofollow">this http URL</a> addition, we propose a novel method of generating the synthetic WL images and associated ground-truth masks using an optical ray-tracing engine to fake mega-voltage EPID images. The model called DeepWL was trained on 1500 synthetic WL images using data augmentation techniques for 180 epochs. The model was built using Keras with a TensorFlow backend on an Intel Core i5 6500T CPU and trained in approximately 15 hours. DeepWL was shown to produce ball bearing and multi-leaf collimator field segmentations with a mean dice coefficient of 0.964 and 0.994 respectively on previously unseen synthetic testing data. When DeepWL was applied to WL data measured on an EPID, the predicted mean displacements were shown to be statistically similar to the Canny Edge detection method. However, the DeepWL predictions for the ball bearing locations were shown to correlate better with manual annotations compared with the Canny edge detection algorithm. DeepWL was demonstrated to analyse Winston-Lutz images with accuracy suitable for routine linac quality assurance with some statistical evidence that it may outperform Canny Edge detection methods in terms of segmentation robustness and the resultant displacement predictions.      
### 46.DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling  [ :arrow_down: ](https://arxiv.org/pdf/2107.01875.pdf)
>  Rap generation, which aims to produce lyrics and corresponding singing beats, needs to model both rhymes and rhythms. Previous works for rap generation focused on rhyming lyrics but ignored rhythmic beats, which are important for rap performance. In this paper, we develop DeepRapper, a Transformer-based rap generation system that can model both rhymes and rhythms. Since there is no available rap dataset with rhythmic beats, we develop a data mining pipeline to collect a large-scale rap dataset, which includes a large number of rap songs with aligned lyrics and rhythmic beats. Second, we design a Transformer-based autoregressive language model which carefully models rhymes and rhythms. Specifically, we generate lyrics in the reverse order with rhyme representation and constraint for rhyme enhancement and insert a beat symbol into lyrics for rhythm/beat modeling. To our knowledge, DeepRapper is the first system to generate rap with both rhymes and rhythms. Both objective and subjective evaluations demonstrate that DeepRapper generates creative and high-quality raps with rhymes and rhythms. Code will be released on GitHub.      
### 47.Supporting decisions by unleashing multiple mindsets using pairwise comparisons method  [ :arrow_down: ](https://arxiv.org/pdf/2107.01731.pdf)
>  Inconsistency in pairwise comparison judgements is often perceived as an unwanted phenomenon and researchers have proposed a number of techniques to either reduce it or to correct it. We take a viewpoint that this inconsistency unleashes different mindsets of the decision maker(s) that should be taken into account when generating recommendations as decision support. With this aim we consider the spanning trees analysis which is a recently emerging idea for use with the pairwise comparison approach that represents the plurality of mindsets (in terms of a plurality of vectors corresponding to different spanning trees). Until now, the multiplicity of the vectors supplied by the spanning trees approach have been amalgamated into a single preference vector, losing the information about the plurality of mindsets. To preserve this information, we propose a novel methodology taking an approach similar to Stochastic Multi-criteria Acceptability Analysis. Considering all the rankings of alternatives corresponding to the different mindsets, our methodology gives the probability that an alternative attains a given ranking position as well as the probability that an alternative is preferred to another one. Since the exponential number of spanning trees makes their enumeration prohibitive, we propose computing approximate probabilities using statistical sampling of the spanning trees. Our approach is also appealing because it can be applied also to incomplete sets of pairwise comparisons. We demonstrate its usefulness with a didactic example as well as with an application to a real-life case of selecting a Telecom backbone infrastructure for rural areas.      
### 48.A convex optimization approach to online set-membership EIV identification of LTV systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.01714.pdf)
>  This paper addresses the problem of recursive set-membership identification for linear time varying (LTV) systems when both input and output measurements are affected by bounded additive noise. First we formulate the problem of online computation of the parameter uncertainty intervals (PUIs) in terms of nonconvex polynomial optimization. Then, we propose a convex relaxation approach based on McCormick envelopes to solve the formulated problem to the global optimum by means of linear programming. The effectiveness of the proposed identification scheme is demonstrated by means of two simulation examples.      
### 49.Alternating direction method of multipliers applied to medical image restoration  [ :arrow_down: ](https://arxiv.org/pdf/2107.01653.pdf)
>  We investigate the effects of the regularization parameter for the norm () and penalty parameter () in the alternating direction method of multipliers (ADMM) on the quality of restored medical images. Simulation studies are performed using images degraded by a point spread function (PSF) and Gaussian noise. The j-th column of the system matrix () is calculated by convolving the image with unity at pixel j and zero at all other pixels and the PSF. The simulation studies show that the mean structural similarity index is maximal when is approximately 10 to 20, where , with and being the transpose of A and the observed data, respectively. The restored image became blurred with a decrease in . This study will be useful for identifying optimal parameter values in the ADMM when applied to medical image restoration.      
### 50.Applications And Potentials Of Intelligent Swarms For Magnetospheric Studies  [ :arrow_down: ](https://arxiv.org/pdf/2107.01601.pdf)
>  Earth's magnetosphere is vital for today's technologically dependent society. To date, numerous design studies have been conducted and over a dozen science missions have own to study the magnetosphere. However, a majority of these solutions relied on large monolithic satellites, which limited the spatial resolution of these investigations, as did the technological limitations of the past. To counter these limitations, we propose the use of a satellite swarm carrying numerous and distributed payloads for magnetospheric measurements. Our mission is named APIS (Applications and Potentials of Intelligent Swarms), which aims to characterize fundamental plasma processes in the Earth's magnetosphere and measure the effect of the solar wind on our magnetosphere. We propose a swarm of 40 CubeSats in two highly-elliptical orbits around the Earth, which perform radio tomography in the magnetotail at 8-12 Earth Radii (RE) downstream, and the subsolar magnetosphere at 8-12RE upstream. In addition, in-situ measurements of the magnetic and electric fields, plasma density will be performed by on-board instruments. <br>In this article, we present an outline of previous missions and designs for magnetospheric studies, along with the science drivers and motivation for the APIS mission. Furthermore, preliminary design results are included to show the feasibility of such a mission. The science requirements drive the APIS mission design, the mission operation and the system requirements. In addition to the various science payloads, critical subsystems of the satellites are investigated e.g., navigation, communication, processing and power systems. We summarize our findings, along with the potential next steps to strengthen our design study.      
### 51.Unified Identification and Tuning Approach Using Deep Neural Networks For Visual Servoing Applications  [ :arrow_down: ](https://arxiv.org/pdf/2107.01581.pdf)
>  Vision based control of Unmanned Aerial Vehicles (UAVs) has been adopted by a wide range of applications due to the availability of low-cost on-board sensors and computers. Tuning such systems to work properly requires extensive domain specific experience which limits the growth of emerging applications. Moreover, obtaining performance limits of UAV based visual servoing with the current state-of-the-art is not possible due to the complexity of the models used. In this paper, we present a systematic approach for real-time identification and tuning of visual servoing systems based on a novel robustified version of the recent deep neural networks with the modified relay feedback test (DNN-MRFT) approach. The proposed robust DNN-MRFT algorithm can be used with a multitude of vision sensors and estimation algorithms despite the high levels of sensor's noise. Sensitivity of MRFT to perturbations is investigated and its effect on identification and tuning performance is analyzed. DNN-MRFT was able to detect performance changes due to the use of slower vision sensors, or due to the integration of accelerometer measurements. Experimental identification results were closely matching simulation results, which can be used to explain system behaviour and anticipate the closed loop performance limits given a certain hardware and software setup. Finally, we demonstrate the capability of the DNN-MRFT tuned visual servoing systems to reject external disturbances. Some advantages of the suggested robust identification approach compared to existing visual servoing design approaches are presented.      
### 52.Arabic Code-Switching Speech Recognition using Monolingual Data  [ :arrow_down: ](https://arxiv.org/pdf/2107.01573.pdf)
>  Code-switching in automatic speech recognition (ASR) is an important challenge due to globalization. Recent research in multilingual ASR shows potential improvement over monolingual systems. We study key issues related to multilingual modeling for ASR through a series of large-scale ASR experiments. Our innovative framework deploys a multi-graph approach in the weighted finite state transducers (WFST) framework. We compare our WFST decoding strategies with a transformer sequence to sequence system trained on the same data. Given a code-switching scenario between Arabic and English languages, our results show that the WFST decoding approaches were more suitable for the intersentential code-switching datasets. In addition, the transformer system performed better for intrasentential code-switching task. With this study, we release an artificially generated development and test sets, along with ecological code-switching test set, to benchmark the ASR performance.      
### 53.Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation  [ :arrow_down: ](https://arxiv.org/pdf/2107.01549.pdf)
>  In this paper, we present a novel modeling method for single-channel multi-talker overlapped automatic speech recognition (ASR) systems. Fully neural network based end-to-end models have dramatically improved the performance of multi-taker overlapped ASR tasks. One promising approach for end-to-end modeling is autoregressive modeling with serialized output training in which transcriptions of multiple speakers are recursively generated one after another. This enables us to naturally capture relationships between speakers. However, the conventional modeling method cannot explicitly take into account the speaker attributes of individual utterances such as gender and age information. In fact, the performance deteriorates when each speaker is the same gender or is close in age. To address this problem, we propose unified autoregressive modeling for joint end-to-end multi-talker overlapped ASR and speaker attribute estimation. Our key idea is to handle gender and age estimation tasks within the unified autoregressive modeling. In the proposed method, transformer-based autoregressive model recursively generates not only textual tokens but also attribute tokens of each speaker. This enables us to effectively utilize speaker attributes for improving multi-talker overlapped ASR. Experiments on Japanese multi-talker overlapped ASR tasks demonstrate the effectiveness of the proposed method.      
### 54.STAR-IOS Aided NOMA Networks: Channel Model Approximation and Performance Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2107.01543.pdf)
>  Simultaneous transmitting and reflecting intelligent omini-surfaces (STAR-IOSs) are able to achieve full coverage "smart radio environments". By splitting the energy or altering the active number of STAR-IOS elements, STAR-IOSs provide high flexibility of successive interference cancellation (SIC) orders for non-orthogonal multiple access (NOMA) systems. Based on the aforementioned advantages, this paper investigates a STAR-IOS-aided downlink NOMA network with randomly deployed users. We first propose three tractable channel models for different application scenarios, namely the central limit model, the curve fitting model, and the M-fold convolution model. More specifically, the central limit model fits the scenarios with large-size STAR-IOSs while the curve fitting model is extended to evaluate multi-cell networks. However, these two models cannot obtain accurate diversity orders. Hence, we figure out the M-fold convolution model to derive accurate diversity orders. We consider three protocols for STAR-IOSs, namely, the energy splitting (ES) protocol, the time switching (TS) protocol, and the mode switching (MS) protocol. Based on the ES protocol, we derive analytical outage probability expressions for the paired NOMA users by the central limit model and the curve fitting model. Based on three STAR-IOS protocols, we derive the diversity gains of NOMA users by the M-fold convolution model. The analytical results reveal that the diversity gain of NOMA users is equal to the active number of STAR-IOS elements. Numerical results indicate that 1) in high signal-to-noise ratio regions, the central limit model performs as an upper bound, while a lower bound is obtained by the curve fitting model; 2) the TS protocol has the best performance but requesting more time blocks than other protocols; 3) the ES protocol outperforms the MS protocol as the ES protocol has higher diversity gains.      
### 55.Development of a Conversation State Recognition System  [ :arrow_down: ](https://arxiv.org/pdf/2107.01462.pdf)
>  With the evolution of the concept of Speaker diarization using LSTM, it is relatively easier to understand the speaker identities for specific segments of input audio stream data than manually tagging the data. With such a concept, it is highly desirable to consider the possibility of using the identified speaker identities to aid in recognizing the Speaker States in a conversation. In this study, the Markov Chains are used to identify and update the Speaker States for the next conversations between the same set of speakers, to enable identification of their states in the most natural and long conversations. The model is based on several audio samples from natural conversations of three or greater than three speakers in two datasets with overall total error percentages for recognized states being lesser than or equal to 12%. The findings imply that the proposed extension to the Speaker diarization is effective to predict the states for a conversation.      
### 56.A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification  [ :arrow_down: ](https://arxiv.org/pdf/2107.01461.pdf)
>  We propose a novel neural model compression strategy combining data augmentation, knowledge transfer, pruning, and quantization for device-robust acoustic scene classification (ASC). Specifically, we tackle the ASC task in a low-resource environment leveraging a recently proposed advanced neural network pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a sub-network neural model associated with a small amount non-zero model parameters. The effectiveness of LTH for low-complexity acoustic modeling is assessed by investigating various data augmentation and compression schemes, and we report an efficient joint framework for low-complexity multi-device ASC, called Acoustic Lottery. Acoustic Lottery could compress an ASC model over $1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and Log loss of 0.76) compared to its not compressed seed model. All results reported in this work are based on a joint effort of four groups, namely GT-USTC-UKE-Tencent, aiming to address the "Low-Complexity Acoustic Scene Classification (ASC) with Multiple Devices" in the DCASE 2021 Challenge Task 1a.      
### 57.Imaging dynamics beneath turbid media via parallelized single-photon detection  [ :arrow_down: ](https://arxiv.org/pdf/2107.01422.pdf)
>  Noninvasive optical imaging through dynamic scattering media has numerous important biomedical applications but still remains a challenging task. While standard methods aim to form images based upon optical absorption or fluorescent emission, it is also well-established that the temporal correlation of scattered coherent light diffuses through tissue much like optical intensity. Few works to date, however, have aimed to experimentally measure and process such data to demonstrate deep-tissue imaging of decorrelation dynamics. In this work, we take advantage of a single-photon avalanche diode (SPAD) array camera, with over one thousand detectors, to simultaneously detect speckle fluctuations at the single-photon level from 12 different phantom tissue surface locations delivered via a customized fiber bundle array. We then apply a deep neural network to convert the acquired single-photon measurements into video of scattering dynamics beneath rapidly decorrelating liquid tissue phantoms. We demonstrate the ability to record video of dynamic events occurring 5-8 mm beneath a decorrelating tissue phantom with mm-scale resolution and at a 2.5-10 Hz frame rate.      
### 58.Impact of Channel Aging on Zero-Forcing Precoding in Cell-Free Massive MIMO Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.01404.pdf)
>  In the context of cell-free massive multi-input multi-output (mMIMO), zero-forcing precoding (ZFP) requires the exchange of instantaneous channel state information and precoded data symbols via a fronthaul network. It causes considerable propagation and processing delays, which degrade performance. This letter analyzes the impact of channel aging on the performance of ZFP in cell-free mMIMO. The aging effects of not only user mobility but also phase noise are considered. Numerical results in terms of per-user spectral efficiency are illustrated.      
### 59.Cell-Free Massive MIMO-OFDM Transmission over Frequency-Selective Fading Channels  [ :arrow_down: ](https://arxiv.org/pdf/2107.01402.pdf)
>  This letter presents and analyzes orthogonal frequency-division multiplexing (OFDM)-based multi-carrier transmission for cell-free massive multi-input multi-output (CFmMIMO) over frequency-selective fading channels. Frequency-domain conjugate beamforming, pilot assignment, and user-specific resource allocation are proposed. CFmMIMO-OFDM is scalable to serve a massive number of users and is flexible to offer diverse data rates for heterogeneous applications.      
### 60.The coarsest lattice that determines a discrete multidimensional system  [ :arrow_down: ](https://arxiv.org/pdf/2107.01368.pdf)
>  A discrete multidimensional system is the set of solutions to a system of partial difference equations defined on the lattice $\Z^n$. This paper shows that it is determined by a unique coarsest sublattice, in the sense that the solutions of the system on this sublattice determine the solutions on $\Z^n$; it is therefore the correct domain of definition of the discrete system. This sublattice is the linear, higher order analogue of an invariant manifold for a vector field. In turn, the defining sublattice is determined by a Galois group of symmetries that leave invariant the equations defining the system. These results find application in understanding properties of the system such as controllability and autonomy.      
### 61.Examining average and discounted reward optimality criteria in reinforcement learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.01348.pdf)
>  In reinforcement learning (RL), the goal is to obtain an optimal policy, for which the optimality criterion is fundamentally important. Two major optimality criteria are average and discounted rewards, where the later is typically considered as an approximation to the former. While the discounted reward is more popular, it is problematic to apply in environments that have no natural notion of discounting. This motivates us to revisit a) the progression of optimality criteria in dynamic programming, b) justification for and complication of an artificial discount factor, and c) benefits of directly maximizing the average reward. Our contributions include a thorough examination of the relationship between average and discounted rewards, as well as a discussion of their pros and cons in RL. We emphasize that average-reward RL methods possess the ingredient and mechanism for developing the general discounting-free optimality criterion (Veinott, 1969) in RL.      
### 62.Short-term probabilistic photovoltaic power forecast based on deep convolutional long short-term memory network and kernel density estimation  [ :arrow_down: ](https://arxiv.org/pdf/2107.01343.pdf)
>  Solar energy is a clean and renewable energy. Photovoltaic (PV) power is an important way to utilize solar energy. Accurate PV power forecast is crucial to the large-scale application of PV power and the stability of electricity grid. This paper proposes a novel method for short-term photovoltaic power forecast using deep convolutional long short-term memory (ConvLSTM) network and kernel density estimation (KDE). In the proposed method, ConvLSTM is used to forecast the future photovoltaic power and KDE is used for estimating the joint probabilistic density function and giving the probabilistic confidence interval. Experiments in an actual photovoltaic power station verify the effectiveness of the proposed method. Comparison experiments with convolutional neural network (CNN) and long short-term memory network (LSTM)shows that ConvLSTM can combine the advantages of both CNN and LSTM and significantly outperform CNN and LSTM in terms of forecast accuracy. Through further comparison with other five conventional methods including multilayer perceptron (MLP), support vector regression (SVR), extreme learning machine (ELM), classification and regression tree (CART) and gradient boosting decision tree (GBDT), ConvLSTM can significantly improve the forecast accuracy by more than 20% for most of the five methods and the superiorities of ConvLSTM are further verified.      
### 63.SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial Network  [ :arrow_down: ](https://arxiv.org/pdf/2107.01330.pdf)
>  Single-pixel imaging is a novel imaging scheme that has gained popularity due to its huge computational gain and potential for a low-cost alternative to imaging beyond the visible spectrum. The traditional reconstruction methods struggle to produce a clear recovery when one limits the number of illumination patterns from a spatial light modulator. As a remedy, several deep-learning-based solutions have been proposed which lack good generalization ability due to the architectural setup and loss functions. In this paper, we propose a generative adversarial network-based reconstruction framework for single-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images with 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This facilitates much faster reconstruction making our method suitable for single-pixel video. Furthermore, our ResNet-like architecture for the generator leads to useful representation learning that allows us to reconstruct completely unseen objects. The experimental results demonstrate that SPI-GAN achieves significant performance gain, e.g. near 3dB PSNR gain, over the current state-of-the-art method.      
### 64.The HCCL Speaker Verification System for Far-Field Speaker Verification Challenge  [ :arrow_down: ](https://arxiv.org/pdf/2107.01329.pdf)
>  This paper describes the systems submitted by team HCCL to the Far-Field Speaker Verification Challenge. Our previous work in the AIshell Speaker Verification Challenge 2019 shows that the powerful modeling abilities of Neural Network architectures can provide exceptional performance for this kind of task. Therefore, in this challenge, we focus on constructing deep Neural Network architectures based on TDNN, Resnet and Res2net blocks. Most of the developed systems consist of Neural Network embeddings are applied with PLDA backend. Firstly, the speed perturbation method is applied to augment data and significant performance improvements are achieved. Then, we explore the use of AMsoftmax loss function and propose to join a CE-loss branch when we train model using AMsoftmax loss. In addition, the impact of score normalization on performance is also investigated. The final system, a fusion of four systems, achieves minDCF 0.5342, EER 5.05\% on task1 eval set, and achieves minDCF 0.5193, EER 5.47\% on task3 eval set.      
### 65.Physical Layer Security for NOMA-Enabled Multi-Access Edge Computing Wireless Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.01322.pdf)
>  Multi-access edge computing (MEC) has been regarded as a promising technique for enhancing computation capabilities for wireless networks. In this paper, we study physical layer security in an MEC system where multiple users offload partial of their computation tasks to a base station simultaneously based on non-orthogonal multiple access (NOMA), in the presence of a malicious eavesdropper. Secrecy outage probability is adopted to measure the security performance of the computation offloading against eavesdropping attacks. We aim to minimize the sum energy consumption of all the users, subject to constraints in terms of the secrecy offloading rate, the secrecy outage probability, and the decoding order of NOMA. Although the original optimization problem is non-convex and challenging to solve, we put forward an efficient algorithm based on sequential convex approximation and penalty dual decomposition. Numerical results are eventually provided to validate the convergence of the proposed algorithm and its superior energy efficiency with secrecy requirements.      
### 66.Accelerating Kinodynamic RRT* Through Dimensionality Reduction  [ :arrow_down: ](https://arxiv.org/pdf/2107.01259.pdf)
>  Sampling-based motion planning algorithms such as RRT* are well-known for their ability to quickly find an initial solution and then converge to the optimal solution asymptotically. However, the convergence rate can be slow for highdimensional planning problems, particularly for dynamical systems where the sampling space is not just the configuration space but the full state space. In this paper, we introduce the idea of using a partial-final-state-free (PFF) optimal controller in kinodynamic RRT* [1] to reduce the dimensionality of the sampling space. Instead of sampling the full state space, the proposed accelerated kinodynamic RRT*, called Kino-RRT*, only samples part of the state space, while the rest of the states are selected by the PFF optimal controller. We also propose a delayed and intermittent update of the optimal arrival time of all the edges in the RRT* tree to decrease the computation complexity of the algorithm. We tested the proposed algorithm using 4-D and 10-D state-space linear systems and showed that Kino-RRT* converges much faster than the kinodynamic RRT* algorithm.      

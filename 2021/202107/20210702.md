# ArXiv eess --Fri, 2 Jul 2021
### 1.ESPnet-ST IWSLT 2021 Offline Speech Translation System  [ :arrow_down: ](https://arxiv.org/pdf/2107.00636.pdf)
>  This paper describes the ESPnet-ST group's IWSLT 2021 submission in the offline speech translation track. This year we made various efforts on training data, architecture, and audio segmentation. On the data side, we investigated sequence-level knowledge distillation (SeqKD) for end-to-end (E2E) speech translation. Specifically, we used multi-referenced SeqKD from multiple teachers trained on different amounts of bitext. On the architecture side, we adopted the Conformer encoder and the Multi-Decoder architecture, which equips dedicated decoders for speech recognition and translation tasks in a unified encoder-decoder model and enables search in both source and target language spaces during inference. We also significantly improved audio segmentation by using the pyannote.audio toolkit and merging multiple short segments for long context modeling. Experimental evaluations showed that each of them contributed to large improvements in translation performance. Our best E2E system combined all the above techniques with model ensembling and achieved 31.4 BLEU on the 2-ref of tst2021 and 21.2 BLEU and 19.3 BLEU on the two single references of tst2021.      
### 2.StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR  [ :arrow_down: ](https://arxiv.org/pdf/2107.00635.pdf)
>  While attention-based encoder-decoder (AED) models have been successfully extended to the online variants for streaming automatic speech recognition (ASR), such as monotonic chunkwise attention (MoChA), the models still have a large label emission latency because of the unconstrained end-to-end training objective. Previous works tackled this problem by leveraging alignment information to control the timing to emit tokens during training. In this work, we propose a simple alignment-free regularization method, StableEmit, to encourage MoChA to emit tokens earlier. StableEmit discounts the selection probabilities in hard monotonic attention for token boundary detection by a constant factor and regularizes them to recover the total attention mass during training. As a result, the scale of the selection probabilities is increased, and the values can reach a threshold for token emission earlier, leading to a reduction of emission latency and deletion errors. Moreover, StableEmit can be combined with methods that constraint alignments to further improve the accuracy and latency. Experimental evaluations with LSTM and Conformer encoders demonstrate that StableEmit significantly reduces the recognition errors and the emission latency simultaneously. We also show that the use of alignment information is complementary in both metrics.      
### 3.Pretext Tasks selection for multitask self-supervised speech representation learning  [ :arrow_down: ](https://arxiv.org/pdf/2107.00594.pdf)
>  Through solving pretext tasks, self-supervised learning leverages unlabeled data to extract useful latent representations replacing traditional input features in the downstream task. In various application domains, including computer vision, natural language processing and audio/speech signal processing, a wide range of features where engineered through decades of research efforts. As it turns out, learning to predict such features has proven to be a particularly relevant pretext task leading to building useful self-supervised representations that prove to be effective for downstream tasks. However, methods and common practices for combining such pretext tasks, where each task targets a different group of features for better performance on the downstream task have not been explored and understood properly. In fact, the process relies almost exclusively on a computationally heavy experimental procedure, which becomes intractable with the increase of the number of pretext tasks. This paper introduces a method to select a group of pretext tasks among a set of candidates. The method we propose estimates properly calibrated weights for the partial losses corresponding to the considered pretext tasks during the self-supervised training process. The experiments conducted on speaker recognition and automatic speech recognition validate our approach, as the groups selected and weighted with our method perform better than classic baselines, thus facilitating the selection and combination of relevant pseudo-labels for self-supervised representation learning.      
### 4.Proposed new dynamic power insertion method for stabilized power generation based on battery energy storage system  [ :arrow_down: ](https://arxiv.org/pdf/2107.00570.pdf)
>  The solar energy is clean and future energy for electricity generation. Its energy has enormous potential but do not optimal to utilized caused by intermittent energy. The intermittent radiance and ambient temperature influence the energy produced fluctuates and unstable. These power fluctuations affect system stability and frequency. To overcome this problem, several methods for PV power stabilization have been developed. One of them is the Stabilized Power Generation where PV output power is to a certain power value. The result of SPG method is reducing in PV power fluctuations but still unstable. For reaching the stable condition of PV Power output, the Dynamic Power Insertion method is proposed which is a modification of the SPG method with energy storage batteries. DPI improve the SPG method and make PV power stable with active power management with charge and discharge action. The battery is using as energy storage when PV power is larger than Power limit. On the other hand battery as an energy source for active power insertion at PV power is smaller than Power limit. Thus the output power in each condition can be maintained as Power PV equals to P limit. For test this method, DPI modules are built on ARM lpc1768 NXP and monitored with the Thing speak webserver (simulated with Simulink MatLab Software). The experimental results of DPI can stabilize PV power fluctuation at its setting power with an error of 5 percent.      
### 5.Image Restoration for Remote Sensing: Overview and Toolbox  [ :arrow_down: ](https://arxiv.org/pdf/2107.00557.pdf)
>  Remote sensing provides valuable information about objects or areas from a distance in either active (e.g., RADAR and LiDAR) or passive (e.g., multispectral and hyperspectral) modes. The quality of data acquired by remotely sensed imaging sensors (both active and passive) is often degraded by a variety of noise types and artifacts. Image restoration, which is a vibrant field of research in the remote sensing community, is the task of recovering the true unknown image from the degraded observed image. Each imaging sensor induces unique noise types and artifacts into the observed image. This fact has led to the expansion of restoration techniques in different paths according to each sensor type. This review paper brings together the advances of image restoration techniques with particular focuses on synthetic aperture radar and hyperspectral images as the most active sub-fields of image restoration in the remote sensing community. We, therefore, provide a comprehensive, discipline-specific starting point for researchers at different levels (i.e., students, researchers, and senior researchers) willing to investigate the vibrant topic of data restoration by supplying sufficient detail and references. Additionally, this review paper accompanies a toolbox to provide a platform to encourage interested students and researchers in the field to further explore the restoration techniques and fast-forward the community. The toolboxes are provided in <a class="link-external link-https" href="https://github.com/ImageRestorationToolbox" rel="external noopener nofollow">this https URL</a>.      
### 6.Using Terminal Circuit for Power System Electromagnetic Transient Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2107.00540.pdf)
>  The modern power system is evolving with increasing penetration of power electronics introducing complicated electromagnetic phenomenon. Electromagnetic transient (EMT) simulation is essential to understand power system behavior under disturbance which however is one of the most sophisticated and time-consuming applications in power system. To improve the electromagnetic transient simulation efficiency while keeping the simulation accuracy, this paper proposes to model and simulate power system electromagnetic transients by very large-scale integrated circuit (VLSI) as a preliminary exploration to eventually represent power system by VLSI circuit chip avoiding numerical calculation. To proof the concept, a simple 5 bus system is modeled and simulated to verify the feasibility of the proposed approach.      
### 7.Multistage Stochastic Model Predictive Control for Urban Automated Driving  [ :arrow_down: ](https://arxiv.org/pdf/2107.00529.pdf)
>  Trajectory planning in urban automated driving is challenging because of the high uncertainty resulting from the unknown future motion of other traffic participants. Robust approaches guarantee safety, but tend to result in overly conservative motion planning. Hence, we propose to use Stochastic Model Predictive Control for vehicle control in urban driving, allowing to efficiently plan the vehicle trajectory, while maintaining the risk probability sufficiently low. For motion optimization, we propose to use a two-stage hierarchical structure that plans the trajectory and the maneuver separately. A high-level layer takes advantage of a long prediction horizon and of an abstract model to plan the optimal maneuver, and a lower level is in charge of executing the selected maneuver by properly planning the vehicle's trajectory. Numerical simulations are included, showing the potential of our proposal.      
### 8.Adaptive 3D descattering with a dynamic synthesis network  [ :arrow_down: ](https://arxiv.org/pdf/2107.00484.pdf)
>  Deep learning has been broadly applied to imaging in scattering applications. A common framework is to train a "descattering" neural network for image recovery by removing scattering artifacts. To achieve the best results on a broad spectrum of scattering conditions, individual "expert" networks have to be trained for each condition. However, the performance of the expert sharply degrades when the scattering level at the testing time differs from the training. An alternative approach is to train a "generalist" network using data from a variety of scattering conditions. However, the generalist generally suffers from worse performance as compared to the expert trained for each scattering condition. Here, we develop a drastically different approach, termed dynamic synthesis network (DSN), that can dynamically adjust the model weights and adapt to different scattering conditions. The adaptability is achieved by a novel architecture that enables dynamically synthesizing a network by blending multiple experts using a gating network. Notably, our DSN adaptively removes scattering artifacts across a continuum of scattering conditions regardless of whether the condition has been used for the training, and consistently outperforms the generalist. By training the DSN entirely on a multiple-scattering simulator, we experimentally demonstrate the network's adaptability and robustness for 3D descattering in holographic 3D particle imaging. We expect the same concept can be adapted to many other imaging applications, such as denoising, and imaging through scattering media. Broadly, our dynamic synthesis framework opens up a new paradigm for designing highly adaptive deep learning and computational imaging techniques.      
### 9.SinGAN-Seg: Synthetic Training Data Generation for Medical Image Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2107.00471.pdf)
>  Processing medical data to find abnormalities is a time-consuming and costly task, requiring tremendous efforts from medical experts. Therefore, Ai has become a popular tool for the automatic processing of medical data, acting as a supportive tool for doctors. AI tools highly depend on data for training the models. However, there are several constraints to access to large amounts of medical data to train machine learning algorithms in the medical domain, e.g., due to privacy concerns and the costly, time-consuming medical data annotation process. To address this, in this paper we present a novel synthetic data generation pipeline called SinGAN-Seg to produce synthetic medical data with the corresponding annotated ground truth masks. We show that these synthetic data generation pipelines can be used as an alternative to bypass privacy concerns and as an alternative way to produce artificial segmentation datasets with corresponding ground truth masks to avoid the tedious medical data annotation process. As a proof of concept, we used an open polyp segmentation dataset. By training UNet++ using both the real polyp segmentation dataset and the corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we show that the synthetic data can achieve a very close performance to the real data when the real segmentation datasets are large enough. In addition, we show that synthetic data generated from the SinGAN-Seg pipeline improving the performance of segmentation algorithms when the training dataset is very small. Since our SinGAN-Seg pipeline is applicable for any medical dataset, this pipeline can be used with any other segmentation datasets.      
### 10.Physics-Informed Neural Networks for Minimising Worst-Case Violations in DC Optimal Power Flow  [ :arrow_down: ](https://arxiv.org/pdf/2107.00465.pdf)
>  Physics-informed neural networks exploit the existing models of the underlying physical systems to generate higher accuracy results with fewer data. Such approaches can help drastically reduce the computation time and generate a good estimate of computationally intensive processes in power systems, such as dynamic security assessment or optimal power flow. Combined with the extraction of worst-case guarantees for the neural network performance, such neural networks can be applied in safety-critical applications in power systems and build a high level of trust among power system operators. This paper takes the first step and applies, for the first time to our knowledge, Physics-Informed Neural Networks with Worst-Case Guarantees for the DC Optimal Power Flow problem. We look for guarantees related to (i) maximum constraint violations, (ii) maximum distance between predicted and optimal decision variables, and (iii) maximum sub-optimality in the entire input domain. In a range of PGLib-OPF networks, we demonstrate how physics-informed neural networks can be supplied with worst-case guarantees and how they can lead to reduced worst-case violations compared with conventional neural networks.      
### 11.Deep Hierarchical Super-Resolution for Scientific Data Reduction and Visualization  [ :arrow_down: ](https://arxiv.org/pdf/2107.00462.pdf)
>  We present an approach for hierarchical super resolution (SR) using neural networks on an octree data representation. We train a hierarchy of neural networks, each capable of 2x upscaling in each spatial dimension between two levels of detail, and use these networks in tandem to facilitate large scale factor super resolution, scaling with the number of trained networks. We utilize these networks in a hierarchical super resolution algorithm that upscales multiresolution data to a uniform high resolution without introducing seam artifacts on octree node boundaries. We evaluate application of this algorithm in a data reduction framework by dynamically downscaling input data to an octree-based data structure to represent the multiresolution data before compressing for additional storage reduction. We demonstrate that our approach avoids seam artifacts common to multiresolution data formats, and show how neural network super resolution assisted data reduction can preserve global features better than compressors alone at the same compression ratios.      
### 12.A Discrete-time Reputation-based Resilient Consensus Algorithm for Synchronous or Asynchronous Communications  [ :arrow_down: ](https://arxiv.org/pdf/2107.00431.pdf)
>  We tackle the problem of a set of agents achieving resilient consensus in the presence of attacked agents. We present a discrete-time reputation-based consensus algorithm for synchronous and asynchronous networks by developing a local strategy where, at each time, each agent assigns a reputation (between zero and one) to each neighbor. The reputation is then used to weigh the neighbors' values in the update of its state. Under mild assumptions, we show that: (i) the proposed method converges exponentially to the consensus of the regular agents; (ii) if a regular agent identifies a neighbor as an attacked node, then it is indeed an attacked node; (iii) if the consensus value of the normal nodes differs from that of any of the attacked nodes' values, then the reputation that a regular agent assigns to the attacked neighbors goes to zero. Further, we extend our method to achieve resilience in the scenarios where there are noisy nodes, dynamic networks and stochastic node selection. Finally, we illustrate our algorithm with several examples, and we delineate some attacking scenarios that can be dealt by the current proposal but not by the state-of-the-art approaches.      
### 13.Machine learning based iterative learning control for non-repetitive time-varying systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.00421.pdf)
>  The repetitive tracking task for time-varying systems (TVSs) with non-repetitive time-varying parameters, which is also called non-repetitive TVSs, is realized in this paper using iterative learning control (ILC). A machine learning (ML) based nominal model update mechanism, which utilizes the linear regression technique to update the nominal model at each ILC trial only using the current trial information, is proposed for non-repetitive TVSs in order to enhance the ILC performance. Given that the ML mechanism forces the model uncertainties to remain within the ILC robust tolerance, an ILC update law is proposed to deal with non-repetitive TVSs. How to tune parameters inside ML and ILC algorithms to achieve the desired aggregate performance is also provided. The robustness and reliability of the proposed method are verified by simulations. Comparison with current state-of-the-art demonstrates its superior control performance in terms of controlling precision. This paper broadens ILC applications from time-invariant systems to non-repetitive TVSs, adopts ML regression technique to estimate non-repetitive time-varying parameters between two ILC trials and proposes a detailed parameter tuning mechanism to achieve desired performance, which are the main contributions.      
### 14.Supervised Segmentation with Domain Adaptation for Small Sampled Orbital CT Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.00418.pdf)
>  Deep neural networks (DNNs) have been widely used for medical image analysis. However, the lack of access a to large-scale annotated dataset poses a great challenge, especially in the case of rare diseases, or new domains for the research society. Transfer of pre-trained features, from the relatively large dataset is a considerable solution. In this paper, we have explored supervised segmentation using domain adaptation for optic nerve and orbital tumor, when only small sampled CT images are given. Even the lung image database consortium image collection (LIDC-IDRI) is a cross-domain to orbital CT, but the proposed domain adaptation method improved the performance of attention U-Net for the segmentation in public optic nerve dataset and our clinical orbital tumor dataset. The code and dataset are available at <a class="link-external link-https" href="https://github.com/cmcbigdata" rel="external noopener nofollow">this https URL</a>.      
### 15.Plug-and-Play Quantum Adaptive Denoiser for Deconvolving Poisson Noisy Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.00407.pdf)
>  A new Plug-and-Play (PnP) alternating direction of multipliers (ADMM) scheme is proposed in this paper, by embedding a recently introduced adaptive denoiser using the Schroedinger equation's solutions of quantum physics. The potential of the proposed model is studied for Poisson image deconvolution, which is a common problem occurring in number of imaging applications, such as, for example, limited photon acquisition or X-ray computed tomography. Numerical results show the efficiency and good adaptability of the proposed scheme compared to recent state-of-the-art techniques, for both high and low signal-to-noise ratio scenarios. This performance gain regardless of the amount of noise affecting the observations is explained by the flexibility of the embedded quantum denoiser constructed without anticipating any prior statistics about the noise, which is one of the main advantages of this method.      
### 16.Lossless Coding of Point Cloud Geometry using a Deep Generative Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.00400.pdf)
>  This paper proposes a lossless point cloud (PC) geometry compression method that uses neural networks to estimate the probability distribution of voxel occupancy. First, to take into account the PC sparsity, our method adaptively partitions a point cloud into multiple voxel block sizes. This partitioning is signalled via an octree. Second, we employ a deep auto-regressive generative model to estimate the occupancy probability of each voxel given the previously encoded ones. We then employ the estimated probabilities to code efficiently a block using a context-based arithmetic coder. Our context has variable size and can expand beyond the current block to learn more accurate probabilities. We also consider using data augmentation techniques to increase the generalization capability of the learned probability models, in particular in the presence of noise and lower-density point clouds. Experimental evaluation, performed on a variety of point clouds from four different datasets and with diverse characteristics, demonstrates that our method reduces significantly (by up to 30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.      
### 17.Explainable nonlinear modelling of multiple time series with invertible neural networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.00391.pdf)
>  A method for nonlinear topology identification is proposed, based on the assumption that a collection of time series are generated in two steps: i) a vector autoregressive process in a latent space, and ii) a nonlinear, component-wise, monotonically increasing observation mapping. The latter mappings are assumed invertible, and are modelled as shallow neural networks, so that their inverse can be numerically evaluated, and their parameters can be learned using a technique inspired in deep learning. Due to the function inversion, the back-propagation step is not straightforward, and this paper explains the steps needed to calculate the gradients applying implicit differentiation. Whereas the model explainability is the same as that for linear VAR processes, preliminary numerical tests show that the prediction error becomes smaller.      
### 18.SISAL Revisited  [ :arrow_down: ](https://arxiv.org/pdf/2107.00386.pdf)
>  Simplex identification via split augmented Lagrangian (SISAL) is a popularly-used algorithm in blind unmixing of hyperspectral images. Developed by José M. Bioucas-Dias in 2009, the algorithm is fundamentally relevant to tackling simplex-structured matrix factorization, and by extension, non-negative matrix factorization, which have many applications under their umbrellas. In this article, we revisit SISAL and provide new meanings to this quintessential algorithm. The formulation of SISAL was motivated from a geometric perspective, with no noise. We show that SISAL can be explained as a heuristic from a probabilistic simplex component analysis framework, which is statistical and is, by principle, more powerful in accommodating the presence of noise. The algorithm for SISAL was designed based on a successive convex approximation method, with a focus on practical utility. It was not known, by analyses, whether the SISAL algorithm has any kind of guarantee of convergence to a stationary point. By establishing associations between the SISAL algorithm and a line-search-based proximal gradient method, we confirm that SISAL can indeed guarantee convergence to a stationary point. Our re-explanation of SISAL also reveals new formulations and algorithms. The performance of these new possibilities is demonstrated by numerical experiments.      
### 19.AoI Minimization in Energy Harvesting and Spectrum Sharing Enabled 6G Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.00340.pdf)
>  Spectrum sharing is a method to solve the problem of frequency spectrum deficiency. This paper studies a novel AI based spectrum sharing and energy harvesting system in which the freshness of information (AoI) is guaranteed. The system includes a primary user with access rights to the spectrum and a secondary user. The secondary user is an energy harvesting sensor that intends to use the primary user spectrum opportunistically. The problem is formulated as partially observable Markov decision processes (POMDPs) and solved using two methods: a deep Q-network (DQN) and dueling double deep Q-Network (D3QN) to achieve the optimal policy. The purpose is to choose the best action adaptively in every time slot based on its situation in both overlay and underlay modes to minimize the average AoI of the secondary user. Finally, simulation experiments are performed to evaluate the effectiveness of the proposed scheme compared to the overlay mode. According to the results, the average AoI in the proposed system is less than that of the existing models, including only overlay mode. The average user access improved from 30% in the overlay mode to 45% in the DQN and 48% in the D3QN.      
### 20.Learned Global Optimization for Inverse Scattering Problems -- Matching Global Search with Computational Efficiency  [ :arrow_down: ](https://arxiv.org/pdf/2107.00332.pdf)
>  The computationally-efficient solution of fully non-linear microwave inverse scattering problems (ISPs) is addressed. An innovative System-by-Design (SbD) based method is proposed to enable, for the first time to the best of the authors knowledge, an effective, robust, and time-efficient exploitation of an evolutionary algorithm (EA) to perform the global minimization of the data-mismatch cost function. According to the SbD paradigm as suitably applied to ISPs, the proposed approach founds on (i) a smart re-formulation of the ISP based on the definition of a minimum-dimensionality and representative set of degrees-of-freedom (DoFs) and on (ii) the artificial-intelligence (AI)-driven integration of a customized global search technique with a digital twin (DT) predictor based on the Gaussian Process (GP) theory. Representative numerical and experimental results are provided to assess the effectiveness and the efficiency of the proposed approach also in comparison with competitive state-of-the-art inversion techniques.      
### 21.Real-time Dispatchable Region of Active Distribution Networks Based on a Tight Convex Relaxation Model  [ :arrow_down: ](https://arxiv.org/pdf/2107.00329.pdf)
>  The uncertainty in distributed renewable generation poses security threats to the real-time operation of distribution systems. The real-time dispatchable region (RTDR) can be used to assess the ability of power systems to accommodate renewable generation at a given base point. DC and linearized AC power flow models are typically used for bulk power systems, but they are not suitable for low-voltage distribution networks with large r/x ratios. To balance accuracy and computational efficiency, this paper proposes an RTDR model of AC distribution networks using tight convex relaxation. Convex hull relaxation is adopted to reformulate the AC power flow equations, and the convex hull is approximated by a polyhedron without much loss of accuracy. Furthermore, an efficient adaptive constraint generation algorithm is employed to construct an approximate RTDR to meet the requirements of real-time dispatch. Case studies on the modified IEEE 33-bus distribution system validate the computational efficiency and accuracy of the proposed method.      
### 22.Prediction of tone detection thresholds in interaurally delayed noise based on interaural phase difference fluctuations  [ :arrow_down: ](https://arxiv.org/pdf/2107.00320.pdf)
>  Differences between the interaural phase of a noise and a target tone improve detection thresholds. The maximum masking release is obtained for detecting an antiphasic tone (S$\pi$) in diotic noise (N0). It has been shown in several studies that this benefit gradually declines as an interaural delay is applied to the N0S$\pi$ complex. This decline has been attributed to the reduced interaural coherence of the noise. Here, we report detection thresholds for a 500 Hz tone in masking noise with up to 8 ms interaural delay and bandwidths from 25 to 1000 Hz. When reducing the noise bandwidth from 100 to 50 and 25 Hz, the masking release at 8 ms delay increases, as expected for increasing temporal coherence with decreasing bandwidth. For bandwidths of 100 to 1000 Hz, no significant difference was observed and detection thresholds with these noises have a delay dependence that is fully described by the temporal coherence imposed by the typical monaurally determined auditory filter bandwidth. A minimalistic binaural model is suggested based on interaural phase difference fluctuations without the assumption of delay lines.      
### 23.Explainable Diabetic Retinopathy Detection and Retinal Image Generation  [ :arrow_down: ](https://arxiv.org/pdf/2107.00296.pdf)
>  Though deep learning has shown successful performance in classifying the label and severity stage of certain diseases, most of them give few explanations on how to make predictions. Inspired by Koch's Postulates, the foundation in evidence-based medicine (EBM) to identify the pathogen, we propose to exploit the interpretability of deep learning application in medical diagnosis. By determining and isolating the neuron activation patterns on which diabetic retinopathy (DR) detector relies to make decisions, we demonstrate the direct relation between the isolated neuron activation and lesions for a pathological explanation. To be specific, we first define novel pathological descriptors using activated neurons of the DR detector to encode both spatial and appearance information of lesions. Then, to visualize the symptom encoded in the descriptor, we propose Patho-GAN, a new network to synthesize medically plausible retinal images. By manipulating these descriptors, we could even arbitrarily control the position, quantity, and categories of generated lesions. We also show that our synthesized images carry the symptoms directly related to diabetic retinopathy diagnosis. Our generated images are both qualitatively and quantitatively superior to the ones by previous methods. Besides, compared to existing methods that take hours to generate an image, our second level speed endows the potential to be an effective solution for data augmentation.      
### 24.DivergentNets: Medical Image Segmentation by Network Ensemble  [ :arrow_down: ](https://arxiv.org/pdf/2107.00283.pdf)
>  Detection of colon polyps has become a trending topic in the intersecting fields of machine learning and gastrointestinal endoscopy. The focus has mainly been on per-frame classification. More recently, polyp segmentation has gained attention in the medical community. Segmentation has the advantage of being more accurate than per-frame classification or object detection as it can show the affected area in greater detail. For our contribution to the EndoCV 2021 segmentation challenge, we propose two separate approaches. First, a segmentation model named TriUNet composed of three separate UNet models. Second, we combine TriUNet with an ensemble of well-known segmentation models, namely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called DivergentNets to produce more generalizable medical image segmentation masks. In addition, we propose a modified Dice loss that calculates loss only for a single class when performing multiclass segmentation, forcing the model to focus on what is most important. Overall, the proposed methods achieved the best average scores for each respective round in the challenge, with TriUNet being the winning model in Round I and DivergentNets being the winning model in Round II of the segmentation generalization challenge at EndoCV 2021. The implementation of our approach is made publicly available on GitHub.      
### 25.Performance evaluation of gust load alleviation systems for flexible aircraft via optimal control  [ :arrow_down: ](https://arxiv.org/pdf/2107.00266.pdf)
>  The dynamical response of an aircraft subject to gust perturbations is a key element in a preliminary design phase. In particular, the loads induced by gusts along the wing should not exceed some limit values and should even ideally be decreased. Active control is one lever to address this problem. However, evaluating the benefit that active control may bring considering some actuators characteristics or some delay in the loop is a difficult task, especially in the early design phase. This problem is addressed in this paper with an open-loop optimal control framework and more specifically with a direct transcription method resulting in a linear optimisation problem. The approach is illustrated on a realistic aeroelastic aircraft model built with a coupled fluid-structure solver which order is reduced to decrease the number of optimisation variables.      
### 26.Feasibility of Haralick's Texture Features for the Classification of Chromogenic In-situ Hybridization Images  [ :arrow_down: ](https://arxiv.org/pdf/2107.00235.pdf)
>  This paper presents a proof of concept for the usefulness of second-order texture features for the qualitative analysis and classification of chromogenic in-situ hybridization whole slide images in high-throughput imaging experiments. The challenge is that currently, the gold standard for gene expression grading in such images is expert assessment. The idea of the research team is to use different approaches in the analysis of these images that will be used for structural segmentation and functional analysis in gene expression. The article presents such perspective idea to select a number of textural features that are going to be used for classification. In our experiment, natural grouping of image samples (tiles) depending on their local texture properties was explored in an unsupervised classification procedure. The features are reduced to two dimensions with fuzzy c-means clustering. The overall conclusion of this experiment is that Haralick features are a viable choice for classification and analysis of chromogenic in-situ hybridization image data. The principal component analysis approach produced slightly more "understandable" from an annotator's point of view classes.      
### 27.Secure Transmission with Different Security Requirements Based on Covert Communication and Information-Theoretic Security in Presence of Friendly Jammer  [ :arrow_down: ](https://arxiv.org/pdf/2107.00210.pdf)
>  In this paper, we investigate joint information-theoretic security and covert communication on a network in the presence of a single transmitter (Alice), a friendly jammer, a single untrusted user, two legitimate users, and a single warden of the channel (Willie). In the considered network, one of the authorized users, Bob, needs a secure and covert communication, and therefore his message must be sent securely, and at the same time, the existence of his communication with the transmitter should not be detected by the channel's warden, Willie, Meanwhile, another authorized user, Carol, needs covert communication. The purpose of secure communication is to prevent the message being decoded by the untrusted user who is present on the network, which leads us to use one of the physical layer security methods, named the secure transmission of information theory. In some cases, in addition to protecting the content of the message, it is important for the user that the existence of the transmission not being detected by an adversary, which leads us to covert communication. In the proposed network model, it is assumed that for covert communication requirements, Alice will not send any messages to legitimate users in one time slot and in another time slot will send to them both (Bob and Carol). One of the main challenges in covert communication is low transmission rate, because we have to reduce the transmission power such that the main message get hide in background noise.      
### 28.Joint Optimization of Autonomous Electric Vehicle Fleet Operations and Charging Station Siting  [ :arrow_down: ](https://arxiv.org/pdf/2107.00165.pdf)
>  Charging infrastructure is the coupling link between power and transportation networks, thus determining charging station siting is necessary for planning of power and transportation systems. While previous works have either optimized for charging station siting given historic travel behavior, or optimized fleet routing and charging given an assumed placement of the stations, this paper introduces a linear program that optimizes for station siting and macroscopic fleet operations in a joint fashion. Given an electricity retail rate and a set of travel demand requests, the optimization minimizes total cost for an autonomous EV fleet comprising of travel costs, station procurement costs, fleet procurement costs, and electricity costs, including demand charges. Specifically, the optimization returns the number of charging plugs for each charging rate (e.g., Level 2, DC fast charging) at each candidate location, as well as the optimal routing and charging of the fleet. From a case-study of an electric vehicle fleet operating in San Francisco, our results show that, albeit with range limitations, small EVs with low procurement costs and high energy efficiencies are the most cost-effective in terms of total ownership costs. Furthermore, the optimal siting of charging stations is more spatially distributed than the current siting of stations, consisting mainly of high-power Level 2 AC stations (16.8 kW) with a small share of DC fast charging stations and no standard 7.7kW Level 2 stations. Optimal siting reduces the total costs, empty vehicle travel, and peak charging load by up to 10%.      
### 29.Hierarchical Control of Utility-Scale Solar PV Plants for Mitigation of Generation Variability and Ancillary Service Provision  [ :arrow_down: ](https://arxiv.org/pdf/2107.00160.pdf)
>  Renewable energy technologies including solar and wind inevitably play a leading role in meeting the growing demand for a decarbonized and clean power grid. However, these technologies are highly dependent of meteorological conditions of power plant site and the challenge remains on how to cope with their short-term and momentarily variability. This paper presents a hierarchical control system to provide ancillary services from a solar PV power plant to the grid without the need for additional non-solar resources. With coordinated management of each inverter in the system, the control system commands the power plant to proactively curtail a fraction of its instantaneous maximum power potential, which gives the plant enough headroom to ramp up or down power production from the overall power plant, for a service such as regulation reserve, even under changing cloud cover conditions. A case study from a site in Hawaii with one-second resolution solar irradiance data is used to verify the efficacy of the proposed control system. The algorithm is subsequently compared with an alternative control technology from the literature, the grouping control algorithm; the results show that the proposed hierarchical control system is over 10 times more effective in reducing generator mileage to support power fluctuations from solar PV power plants.      
### 30.Intelligent Anomaly Mitigation in Cyber-Physical Inverter-based Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.00151.pdf)
>  The distributed cooperative controllers for inverter-based systems rely on communication networks that make them vulnerable to cyber anomalies. In addition, the distortion effects of such anomalies may also propagate throughout inverter-based cyber-physical systems due to the cooperative cyber layer. In this paper, an intelligent anomaly mitigation technique for such systems is presented utilizing data driven artificial intelligence tools that employ artificial neural networks. The proposed technique is implemented in secondary voltage control of distributed cooperative control-based microgrid, and results are validated by comparison with existing distributed secondary control and real-time simulations on real-time simulator OPAL-RT.      
### 31.Greedy Decentralized Auction-based Task Allocation for Multi-Agent Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.00144.pdf)
>  We propose a decentralized auction-based algorithm for the solution of dynamic task allocation problems for spatially distributed multi-agent systems. In our approach, each member of the multi-agent team is assigned to at most one task from a set of spatially distributed tasks, while several agents can be allocated to the same task. The task assignment is dynamic since it is updated at discrete time stages (iterations) to account for the current states of the agents as the latter move towards the tasks assigned to them at the previous stage. Our proposed methods can find applications in problems of resource allocation by intelligent machines such as the delivery of packages by a fleet of unmanned or semi-autonomous aerial vehicles. In our approach, the task allocation accounts for both the cost incurred by the agents for the completion of their assigned tasks (e.g., energy or fuel consumption) and the rewards earned for their completion (which may reflect, for instance, the agents' satisfaction). We propose a Greedy Coalition Auction Algorithm (GCAA) in which the agents possess bid vectors representing their best evaluations of the task utilities. The agents propose bids, deduce an allocation based on their bid vectors and update them after each iteration. The solution estimate of the proposed task allocation algorithm converges after a finite number of iterations which cannot exceed the number of agents. Finally, we use numerical simulations to illustrate the effectiveness of the proposed task allocation algorithm (in terms of performance and computation time) in several scenarios involving multiple agents and tasks distributed over a spatial 2D domain.      
### 32.Automated Detection and Diagnosis of Diabetic Retinopathy: A Comprehensive Survey  [ :arrow_down: ](https://arxiv.org/pdf/2107.00115.pdf)
>  Diabetic Retinopathy (DR) is a leading cause of vision loss in the world,. In the past few Diabetic Retinopathy (DR) is a leading cause of vision loss in the world. In the past few years, Artificial Intelligence (AI) based approaches have been used to detect and grade DR. Early detection enables appropriate treatment and thus prevents vision loss, Both fundus and optical coherence tomography (OCT) images are used to image the retina. With deep learning/machine learning apprroaches it is possible to extract features from the images and detect the presence of DR. Multiple strategies are implemented to detect and grade the presence of DR using classification, segmentation, and hybrid techniques. This review covers the literature dealing with AI approaches to DR that have been published in the open literature over a five year span (2016-2021). In addition a comprehensive list of available DR datasets is reported. Both the PICO (P-patient, I-intervention, C-control O-outcome) and Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA)2009 search strategies were employed. We summarize a total of 114 published articles which conformed to the scope of the review. In addition a list of 43 major datasets is presented.      
### 33.{QuickFlex: a Fast Algorithm for Flexible Region Construction for the TSO-DSO Coordination  [ :arrow_down: ](https://arxiv.org/pdf/2107.00114.pdf)
>  Most of the new technological changes in power systems are expected to take place in distribution grids. The enormous potential for distribution flexibility could meet the transmission system's needs, changing the paradigm of generator-centric energy and ancillary services provided to a demand-centric one, by placing more importance on smaller resources, such as flexible demands and electric vehicles. For unlocking such capabilities, it is essential to understand the aggregated flexibility that can be harvested from the large population of new technologies located in distribution grids. Distribution grids, therefore, could provide aggregated flexibility at the transmission level. To date, most computational methods for estimating the aggregated flexibility at the interface between distribution grids and transmission grids have the drawback of requiring significant computational time, which hinders their applicability. This paper presents a new algorithm, coined as QuickFlex} for constructing the flexibility domain of distribution grids. Contrary to previous methods, a priory flexibility domain accuracy can be selected. Our method requires few iterations for constructing the flexibility region. The number of iterations needed is mainly independent of the distribution grid's input size and flexible elements. Numerical experiments are performed in four grids ranging from 5 nodes to 123 nodes. It is shown that QuickFlex outperforms existing proposals in the literature in both speed and accuracy.      
### 34.Using Self-Supervised Feature Extractors with Attention for Automatic COVID-19 Detection from Speech  [ :arrow_down: ](https://arxiv.org/pdf/2107.00112.pdf)
>  The ComParE 2021 COVID-19 Speech Sub-challenge provides a test-bed for the evaluation of automatic detectors of COVID-19 from speech. Such models can be of value by providing test triaging capabilities to health authorities, working alongside traditional testing methods. Herein, we leverage the usage of pre-trained, problem agnostic, speech representations and evaluate their use for this task. We compare the obtained results against a CNN architecture trained from scratch and traditional frequency-domain representations. We also evaluate the usage of Self-Attention Pooling as an utterance-level information aggregation method. Experimental results demonstrate that models trained on features extracted from self-supervised models perform similarly or outperform fully-supervised models and models based on handcrafted features. Our best model improves the Unweighted Average Recall (UAR) from 69.0\% to 72.3\% on a development set comprised of only full-band examples and achieves 64.4\% on the test set. Furthermore, we study where the network is attending, attempting to draw some conclusions regarding its explainability. In this relatively small dataset, we find the network attends especially to vowels and aspirates.      
### 35.Transit-Gym: A Simulation and Evaluation Engine for Analysis of Bus Transit Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.00105.pdf)
>  Public-transit systems face a number of operational challenges: (a) changing ridership patterns requiring optimization of fixed line services, (b) optimizing vehicle-to-trip assignments to reduce maintenance and operation codes, and (c) ensuring equitable and fair coverage to areas with low ridership. Optimizing these objectives presents a hard computational problem due to the size and complexity of the decision space. State-of-the-art methods formulate these problems as variants of the vehicle routing problem and use data-driven heuristics for optimizing the procedures. However, the evaluation and training of these algorithms require large datasets that provide realistic coverage of various operational uncertainties. This paper presents a dynamic simulation platform, called Transit-Gym, that can bridge this gap by providing the ability to simulate scenarios, focusing on variation of demand models, variations of route networks, and variations of vehicle-to-trip assignments. The central contribution of this work is a domain-specific language and associated experimentation tool-chain and infrastructure to enable subject-matter experts to intuitively specify, simulate, and analyze large-scale transit scenarios and their parametric variations. Of particular significance is an integrated microscopic energy consumption model that also helps to analyze the energy cost of various transit decisions made by the transportation agency of a city.      
### 36.Sequence-level Confidence Classifier for ASR Utterance Accuracy and Application to Acoustic Models  [ :arrow_down: ](https://arxiv.org/pdf/2107.00099.pdf)
>  Scores from traditional confidence classifiers (CCs) in automatic speech recognition (ASR) systems lack universal interpretation and vary with updates to the underlying confidence or acoustic models (AMs). In this work, we build interpretable confidence scores with an objective to closely align with ASR accuracy. We propose a new sequence-level CC with a richer context providing CC scores highly correlated with ASR accuracy and scores stable across CC updates. Hence, expanding CC applications. Recently, AM customization has gained traction with the widespread use of unified models. Conventional adaptation strategies that customize AM expect well-matched data for the target domain with gold-standard transcriptions. We propose a cost-effective method of using CC scores to select an optimal adaptation data set, where we maximize ASR gains from minimal data. We study data in various confidence ranges and optimally choose data for AM adaptation with KL-Divergence regularization. On the Microsoft voice search task, data selection for supervised adaptation using the sequence-level confidence scores achieves word error rate reduction (WERR) of 8.5% for row-convolution LSTM (RC-LSTM) and 5.2% for latency-controlled bidirectional LSTM (LC-BLSTM). In the semi-supervised case, with ASR hypotheses as labels, our method provides WERR of 5.9% and 2.8% for RC-LSTM and LC-BLSTM, respectively.      
### 37.Super Twisting based Lyapunov Redesign for Uncertain Linear Delay Systems  [ :arrow_down: ](https://arxiv.org/pdf/2107.00094.pdf)
>  We present a new continuous Lyapunov Redesign (LR) methodology for the robust stabilization of a class of uncertain time-delay systems that is based on the so-called Super Twisting Algorithm. The main feature of the proposed approach is that allows one to simultaneously adjust the chattering effect and achieve asymptotic stabilization of the uncertain system, which is lost when continuous approximation of the unit control is considered. At the basis of the Super Twisting based LR methodology is a class of Lyapunov-Krasovskii functionals, whose particular form of its time derivative allows one to define a delay-free sliding manifold on which some class of smooth uncertainties are compensated.      
### 38.A uniform reaching phase strategy in adaptive sliding mode control  [ :arrow_down: ](https://arxiv.org/pdf/2107.00069.pdf)
>  In adaptive sliding mode control methods, an updating gain strategy associated with finite-time convergence to the sliding set is essential to deal with matched bounded perturbations with unknown upper-bound. However, the estimation of the finite time of any adaptive design is a complicated task since it depends not only on the upper-bound of unknown perturbation but also on the size of initial conditions. This brief proposes a uniform adaptive reaching phase strategy (ARPS) within a predefined reaching-time. Moreover, as a case of study, the barrier function approach is extended for perturbed MIMO systems with uncertain control matrix. The usage of proposed ARPS in the MIMO case solves simultaneously two issues: giving a uniform reaching phase with a predefined reaching-time and adapting to the perturbation norm while in a predefined vicinity of the sliding manifold.      
### 39.Computationally efficient spatial rendering of late reverberation in virtual acoustic environments  [ :arrow_down: ](https://arxiv.org/pdf/2107.00004.pdf)
>  For 6-DOF (degrees of freedom) interactive virtual acoustic environments (VAEs), the spatial rendering of diffuse late reverberation in addition to early (specular) reflections is important. In the interest of computational efficiency, the acoustic simulation of the late reverberation can be simplified by using a limited number of spatially distributed virtual reverb sources (VRS) each radiating incoherent signals. A sufficient number of VRS is needed to approximate spatially anisotropic late reverberation, e.g., in a room with inhomogeneous distribution of absorption at the boundaries. Here, a highly efficient and perceptually plausible method to generate and spatially render late reverberation is suggested, extending the room acoustics simulator RAZR [Wendt et al., J. Audio Eng. Soc., 62, 11 (2014)]. The room dimensions and frequency-dependent absorption coefficients at the wall boundaries are used to determine the parameters of a physically-based feedback delay network (FDN) to generate the incoherent VRS signals. The VRS are spatially distributed around the listener with weighting factors representing the spatially subsampled distribution of absorption coefficients on the wall boundaries. The minimum number of VRS required to be perceptually distinguishable from the maximum (reference) number of 96 VRS was assessed in a listening test conducted with a spherical loudspeaker array within an anechoic room. For the resulting low numbers of VRS suited for spatial rendering, optimal physically-based parameter choices for the FDN are discussed.      
### 40.Improving Sound Event Classification by Increasing Shift Invariance in Convolutional Neural Networks  [ :arrow_down: ](https://arxiv.org/pdf/2107.00623.pdf)
>  Recent studies have put into question the commonly assumed shift invariance property of convolutional networks, showing that small shifts in the input can affect the output predictions substantially. In this paper, we ask whether lack of shift invariance is a problem in sound event classification, and whether there are benefits in addressing it. Specifically, we evaluate two pooling methods to improve shift invariance in CNNs, based on low-pass filtering and adaptive sampling of incoming feature maps. These methods are implemented via small architectural modifications inserted into the pooling layers of CNNs. We evaluate the effect of these architectural changes on the FSD50K dataset using models of different capacity and in presence of strong regularization. We show that these modifications consistently improve sound event classification in all cases considered, without adding any (or adding very few) trainable parameters, which makes them an appealing alternative to conventional pooling layers. The outcome is a new state-of-the-art mAP of 0.541 on the FSD50K classification benchmark.      
### 41.A linear phase evolution model for reduction of temporal unwrapping and field estimation errors in multi-echo GRE  [ :arrow_down: ](https://arxiv.org/pdf/2107.00615.pdf)
>  This article aims at developing a model based optimization for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by application of unity rank approximation to the Hankel matrix formed using the complex exponential of the channel combined phase at each echo time. For the purpose of maintaining consistency with the observed complex data, the linear phase evolution model is formulated as an optimization problem with a cost function that involves a fidelity term and a unity rank prior, implemented using alternating minimization. Itoh s algorithm applied to the multi-echo phase estimated from this linear phase evolution model is able to reduce the unwrapping errors as compared to the unwrapping when directly applied to the measured phase. Secondly, the improved accuracy of the frequency fit in comparison to estimation using weighted least-square regression and penalized maximum likelihood is demonstrated using numerical simulation of field perturbation due to magnetic susceptibility effect. It is shown that the field can be estimated with 80 percent reduction in mean absolute error in comparison to wLSR and 66 percent reduction with respect to penalized maximum likelihood. The improvement in performance becomes more pronounced with increasing strengths of field gradient magnitudes and echo spacing.      
### 42.Formal verification of octorotor flight envelope using barrier functions and SMT solving  [ :arrow_down: ](https://arxiv.org/pdf/2107.00612.pdf)
>  This paper introduces an approach for formally verifying the safety of the flight controller of an octorotor platform. Our method involves finding regions of the octorotor's state space that are considered safe, and which can be proven to be invariant with respect to the dynamics. Specifically, exponential barrier functions are used to construct candidate invariant regions near desired commanded states. The proof that these regions are invariant is discovered automatically using the dReal SMT solver, which ensures the accurate command tracking of the octorotor to within a certain margin of error. Rotor failures in which rotor thrusts become stuck at fixed values are considered and accounted for via a pseudo-inverse control allocator. The safety of the control allocator is verified in dReal by checking that the thrusts demanded by the allocator never exceed the capability of the rotors. We apply our approach on a specific octorotor example and verify the desired command tracking properties of the controller under normal conditions and various combinations of rotor failures.      
### 43.Scalable Node-Disjoint and Edge-Disjoint Multi-wavelength Routing  [ :arrow_down: ](https://arxiv.org/pdf/2107.00609.pdf)
>  Probabilistic message-passing algorithms are developed for routing transmissions in multi-wavelength optical communication networks, under node and edge-disjoint routing constraints and for various objective functions. Global routing optimization is a hard computational task on its own but is made much more difficult under the node/edge-disjoint constraints and in the presence of multiple wavelengths, a problem which dominates routing efficiency in real optical communication networks that carry most of the world's Internet traffic. The scalable principled method we have developed is exact on trees but provides good approximate solutions on locally tree-like graphs. It accommodates a variety of objective functions that correspond to low latency, load balancing and consolidation of routes, and can be easily extended to include heterogeneous signal-to-noise values on edges and a restriction on the available wavelengths per edge. It can be used for routing and managing transmissions on existing topologies as well as for designing and modifying optical communication networks. Additionally, it provides the tool for settling an open and much debated question on the merit of wavelength-switching nodes and the added capabilities they provide. The methods have been tested on generated networks such as random-regular, Erdős Rényi and power-law graphs, as well as on the UK and US optical communication networks. They show excellent performance with respect to existing methodology on small networks and have been scaled up to network sizes that are beyond the reach of most existing algorithms.      
### 44.Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in Edge Industrial IoT  [ :arrow_down: ](https://arxiv.org/pdf/2107.00481.pdf)
>  Edge computing provides a promising paradigm to support the implementation of Industrial Internet of Things (IIoT) by offloading tasks to nearby edge nodes. Meanwhile, the increasing network size makes it impractical for centralized data processing due to limited bandwidth, and consequently a decentralized learning scheme is preferable. Reinforcement learning (RL) has been widely investigated and shown to be a promising solution for decision-making and optimal control processes. For RL in a decentralized setup, edge nodes (agents) connected through a communication network aim to work collaboratively to find a policy to optimize the global reward as the sum of local rewards. However, communication costs, scalability and adaptation in complex environments with heterogeneous agents may significantly limit the performance of decentralized RL. Alternating direction method of multipliers (ADMM) has a structure that allows for decentralized implementation, and has shown faster convergence than gradient descent based methods. Therefore, we propose an adaptive stochastic incremental ADMM (asI-ADMM) algorithm and apply the asI-ADMM to decentralized RL with edge-computing-empowered IIoT networks. We provide convergence properties for proposed algorithms by designing a Lyapunov function and prove that the asI-ADMM has $O(\frac{1}{k}) +O(\frac{1}{M})$ convergence rate where $k$ and $ M$ are the number of iterations and batch samples, respectively. Then, we test our algorithm with two supervised learning problems. For performance evaluation, we simulate two applications in decentralized RL settings with homogeneous and heterogeneous agents. The experiment results show that our proposed algorithms outperform the state of the art in terms of communication costs and scalability, and can well adapt to complex IoT environments.      
### 45.What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2107.00439.pdf)
>  End-to-end DNN architectures have pushed the state-of-the-art in speech technologies, as well as in other spheres of AI, leading researchers to train more complex and deeper models. These improvements came at the cost of transparency. DNNs are innately opaque and difficult to interpret. We no longer understand what features are learned, where they are preserved, and how they inter-operate. Such an analysis is important for better model understanding, debugging and to ensure fairness in ethical decision making. In this work, we analyze the representations trained within deep speech models, towards the task of speaker recognition, dialect identification and reconstruction of masked signals. We carry a layer- and neuron-level analysis on the utterance-level representations captured within pretrained speech models for speaker, language and channel properties. We study: is this information captured in the learned representations? where is it preserved? how is it distributed? and can we identify a minimal subset of network that posses this information. Using diagnostic classifiers, we answered these questions. Our results reveal: (i) channel and gender information is omnipresent and is redundantly distributed (ii) complex properties such as dialectal information is encoded only in the task-oriented pretrained network and is localised in the upper layers (iii) a minimal subset of neurons can be extracted to encode the predefined property (iv) salient neurons are sometimes shared between properties and can highlights presence of biases in the network. Our cross-architectural comparison indicates that (v) the pretrained models captures speaker-invariant information and (vi) the pretrained CNNs models are competitive to the Transformers for encoding information for the studied properties. To the best of our knowledge, this is the first study to investigate neuron analysis on the speech models.      
### 46.Stability and Robustness Analysis of Plug-Pulling using an Aerial Manipulator  [ :arrow_down: ](https://arxiv.org/pdf/2107.00353.pdf)
>  In this paper, an autonomous aerial manipulation task of pulling a plug out of an electric socket is conducted, where maintaining the stability and robustness is challenging due to sudden disappearance of a large interaction force. The abrupt change in the dynamical model before and after the separation of the plug can cause destabilization or mission failure. To accomplish aerial plug-pulling, we employ the concept of hybrid automata to divide the task into three operative modes, i.e, wire-pulling, stabilizing, and free-flight. Also, a strategy for trajectory generation and a design of disturbance-observer-based controllers for each operative mode are presented. Furthermore, the theory of hybrid automata is used to prove the stability and robustness during the mode transition. We validate the proposed trajectory generation and control method by an actual wire-pulling experiment with a multirotor-based aerial manipulator.      
### 47.End-to-end Compression Towards Machine Vision: Network Architecture Design and Optimization  [ :arrow_down: ](https://arxiv.org/pdf/2107.00328.pdf)
>  The research of visual signal compression has a long history. Fueled by deep learning, exciting progress has been made recently. Despite achieving better compression performance, existing end-to-end compression algorithms are still designed towards better signal quality in terms of rate-distortion optimization. In this paper, we show that the design and optimization of network architecture could be further improved for compression towards machine vision. We propose an inverted bottleneck structure for end-to-end compression towards machine vision, which specifically accounts for efficient representation of the semantic information. Moreover, we quest the capability of optimization by incorporating the analytics accuracy into the optimization process, and the optimality is further explored with generalized rate-accuracy optimization in an iterative manner. We use object detection as a showcase for end-to-end compression towards machine vision, and extensive experiments show that the proposed scheme achieves significant BD-rate savings in terms of analysis performance. Moreover, the promise of the scheme is also demonstrated with strong generalization capability towards other machine vision tasks, due to the enabling of signal-level reconstruction.      
### 48.Spotting adversarial samples for speaker verification by neural vocoders  [ :arrow_down: ](https://arxiv.org/pdf/2107.00309.pdf)
>  Automatic speaker verification (ASV), one of the most important technology for biometric identification, has been widely adopted in security-critic applications, including transaction authentication and access control. However, previous works have shown ASV is seriously vulnerable to recently emerged adversarial attacks, yet effective countermeasures against them are limited. In this paper, we adopt neural vocoders to spot adversarial samples for ASV. We use neural vocoder to re-synthesize audio and find that the difference between the ASV scores for the original and re-synthesized audio is a good indicator to distinguish genuine and adversarial samples. As the very beginning work in this direction of detecting adversarial samples for ASV, there is no reliable baseline for comparison. So we first implement Griffin-Lim for detection and set it as our baseline. The proposed method accomplishes effective detection performance and outperforms all the baselines in all the settings. We also show the neural vocoder adopted in the detection framework is dataset independent. Our codes will be made open-source for future works to do comparison.      
### 49.An Objective Evaluation Framework for Pathological Speech Synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2107.00308.pdf)
>  The development of pathological speech systems is currently hindered by the lack of a standardised objective evaluation framework. In this work, (1) we utilise existing detection and analysis techniques to propose a general framework for the consistent evaluation of synthetic pathological speech. This framework evaluates the voice quality and the intelligibility aspects of speech and is shown to be complementary using our experiments. (2) Using our proposed evaluation framework, we develop and test a dysarthric voice conversion system (VC) using CycleGAN-VC and a PSOLA-based speech rate modification technique. We show that the developed system is able to synthesise dysarthric speech with different levels of speech intelligibility.      
### 50.Sonority Measurement Using System, Source, and Suprasegmental Information  [ :arrow_down: ](https://arxiv.org/pdf/2107.00297.pdf)
>  Sonorant sounds are characterized by regions with prominent formant structure, high energy and high degree of periodicity. In this work, the vocal-tract system, excitation source and suprasegmental features derived from the speech signal are analyzed to measure the sonority information present in each of them. Vocal-tract system information is extracted from the Hilbert envelope of numerator of group delay function. It is derived from zero time windowed speech signal that provides better resolution of the formants. A five-dimensional feature set is computed from the estimated formants to measure the prominence of the spectral peaks. A feature representing strength of excitation is derived from the Hilbert envelope of linear prediction residual, which represents the source information. Correlation of speech over ten consecutive pitch periods is used as the suprasegmental feature representing periodicity information. The combination of evidences from the three different aspects of speech provides better discrimination among different sonorant classes, compared to the baseline MFCC features. The usefulness of the proposed sonority feature is demonstrated in the tasks of phoneme recognition and sonorant classification.      
### 51.The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021  [ :arrow_down: ](https://arxiv.org/pdf/2107.00279.pdf)
>  This paper describes USTC-NELSLIP's submissions to the IWSLT2021 Simultaneous Speech Translation task. We proposed a novel simultaneous translation model, Cross Attention Augmented Transducer (CAAT), which extends conventional RNN-T to sequence-to-sequence tasks without monotonic constraints, e.g., simultaneous translation. Experiments on speech-to-text (S2T) and text-to-text (T2T) simultaneous translation tasks shows CAAT achieves better quality-latency trade-offs compared to \textit{wait-k}, one of the previous state-of-the-art approaches. Based on CAAT architecture and data augmentation, we build S2T and T2T simultaneous translation systems in this evaluation campaign. Compared to last year's optimal systems, our S2T simultaneous translation system improves by an average of 11.3 BLEU for all latency regimes, and our T2T simultaneous translation system improves by an average of 4.6 BLEU.      
### 52.Audiovisual Singing Voice Separation  [ :arrow_down: ](https://arxiv.org/pdf/2107.00231.pdf)
>  Separating a song into vocal and accompaniment components is an active research topic, and recent years witnessed an increased performance from supervised training using deep learning techniques. We propose to apply the visual information corresponding to the singers' vocal activities to further improve the quality of the separated vocal signals. The video frontend model takes the input of mouth movement and fuses it into the feature embeddings of an audio-based separation framework. To facilitate the network to learn audiovisual correlation of singing activities, we add extra vocal signals irrelevant to the mouth movement to the audio mixture during training. We create two audiovisual singing performance datasets for training and evaluation, respectively, one curated from audition recordings on the Internet, and the other recorded in house. The proposed method outperforms audio-based methods in terms of separation quality on most test recordings. This advantage is especially pronounced when there are backing vocals in the accompaniment, which poses a great challenge for audio-only methods.      
### 53.Word-Free Spoken Language Understanding for Mandarin-Chinese  [ :arrow_down: ](https://arxiv.org/pdf/2107.00186.pdf)
>  Spoken dialogue systems such as Siri and Alexa provide great convenience to people's everyday life. However, current spoken language understanding (SLU) pipelines largely depend on automatic speech recognition (ASR) modules, which require a large amount of language-specific training data. In this paper, we propose a Transformer-based SLU system that works directly on phones. This acoustic-based SLU system consists of only two blocks and does not require the presence of ASR module. The first block is a universal phone recognition system, and the second block is a Transformer-based language model for phones. We verify the effectiveness of the system on an intent classification dataset in Mandarin Chinese.      
### 54.Attention-based multi-channel speaker verification with ad-hoc microphone arrays  [ :arrow_down: ](https://arxiv.org/pdf/2107.00178.pdf)
>  Recently, ad-hoc microphone array has been widely studied. Unlike traditional microphone array settings, the spatial arrangement and number of microphones of ad-hoc microphone arrays are not known in advance, which hinders the adaptation of traditional speaker verification technologies to ad-hoc microphone arrays. To overcome this weakness, in this paper, we propose attention-based multi-channel speaker verification with ad-hoc microphone arrays. Specifically, we add an inter-channel processing layer and a global fusion layer after the pooling layer of a single-channel speaker verification system. The inter-channel processing layer applies a so-called residual self-attention along the channel dimension for allocating weights to different microphones. The global fusion layer integrates all channels in a way that is independent to the number of the input channels. We further replace the softmax operator in the residual self-attention with sparsemax, which forces the channel weights of very noisy channels to zero. Experimental results with ad-hoc microphone arrays of over 30 channels demonstrate the effectiveness of the proposed methods. For example, the multi-channel speaker verification with sparsemax achieves an equal error rate (EER) of over 20% lower than oracle one-best system on semi-real data sets, and over 30% lower on simulation data sets, in test scenarios with both matched and mismatched channel numbers.      
### 55.One-class Steel Detector Using Patch GAN Discriminator for Visualising Anomalous Feature Map  [ :arrow_down: ](https://arxiv.org/pdf/2107.00143.pdf)
>  For steel product manufacturing in indoor factories, steel defect detection is important for quality control. For example, a steel sheet is extremely delicate, and must be accurately inspected. However, to maintain the painted steel parts of the infrastructure around a severe outdoor environment, corrosion detection is critical for predictive maintenance. In this paper, we propose a general-purpose application for steel anomaly detection that consists of the following four components. The first, a learner, is a unit image classification network to determine whether the region of interest or background has been recognised, after dividing the original large sized image into 256 square unit images. The second, an extractor, is a discriminator feature encoder based on a pre-trained steel generator with a patch generative adversarial network discriminator(GAN). The third, an anomaly detector, is a one-class support vector machine(SVM) to predict the anomaly score using the discriminator feature. The fourth, an indicator, is an anomalous probability map used to visually explain the anomalous features. Furthermore, we demonstrated our method through the inspection of steel sheet defects with 13,774 unit images using high-speed cameras, and painted steel corrosion with 19,766 unit images based on an eye inspection of the photographs. Finally, we visualise anomalous feature maps of steel using a strip and painted steel inspection dataset      
### 56.Which Echo Chamber? Regions of Attraction in Learning with Decision-Dependent Distributions  [ :arrow_down: ](https://arxiv.org/pdf/2107.00055.pdf)
>  As data-driven methods are deployed in real-world settings, the processes that generate the observed data will often react to the decisions of the learner. For example, a data source may have some incentive for the algorithm to provide a particular label (e.g. approve a bank loan), and manipulate their features accordingly. Work in strategic classification and decision-dependent distributions seeks to characterize the closed-loop behavior of deploying learning algorithms by explicitly considering the effect of the classifier on the underlying data distribution. More recently, works in performative prediction seek to classify the closed-loop behavior by considering general properties of the mapping from classifier to data distribution, rather than an explicit form. Building on this notion, we analyze repeated risk minimization as the perturbed trajectories of the gradient flows of performative risk minimization. We consider the case where there may be multiple local minimizers of performative risk, motivated by real world situations where the initial conditions may have significant impact on the long-term behavior of the system. As a motivating example, we consider a company whose current employee demographics affect the applicant pool they interview: the initial demographics of the company can affect the long-term hiring policies of the company. We provide sufficient conditions to characterize the region of attraction for the various equilibria in this settings. Additionally, we introduce the notion of performative alignment, which provides a geometric condition on the convergence of repeated risk minimization to performative risk minimizers.      
### 57.Web-based Structural Identifiability Analyzer  [ :arrow_down: ](https://arxiv.org/pdf/2106.15066.pdf)
>  Parameter identifiability describes whether, for a given differential model, one can determine parameter values from model equations. Knowing global or local identifiability properties allows construction of better practical experiments to identify parameters from experimental data. In this work, we present a web-based software tool that allows to answer specific identifiability queries. Concretely, our toolbox can determine identifiability of individual parameters of the model and also provide all functions of parameters that are identifiable (also called identifiable combinations) from single or multiple experiments. The program is freely available at https://maple.cloud/app/6509768948056064.      

# ArXiv eess --Thu, 1 Jul 2021
### 1.Limited-Fronthaul Cell-Free Hybrid Beamforming with Distributed Deep Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.16194.pdf)
>  Cell-free massive MIMO (CF-mMIMO) systems represent a promising approach to increase the spectral efficiency of wireless communication systems. However, near-optimal solutions require a large amount of signaling exchange between access points (APs) and the network controller (NC). In addition, the use of hybrid beamforming in each AP reduces the number of power hungry RF chains, but imposes a large computational complexity to find near-optimal precoders. In this letter, we propose two unsupervised deep neural networks (DNN) architectures, fully and partially distributed, that can perform coordinated hybrid beamforming with zero or limited communication overhead between APs and NC, while achieving near-optimal sum-rate with a reduced computational complexity compared to conventional near-optimal solutions.      
### 2.The energy revolution: cyber physical advances and opportunities for smart local energy systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.16157.pdf)
>  We have designed a two-stage, 10-step process to give organisations a method to analyse small local energy systems (SLES) projects based on their Cyber Physical System components in order to develop future-proof energy systems. <br>SLES are often developed for a specific range of use cases and functions, and these match the specific requirements and needs of the community, location or site under consideration. During the design and commissioning, new and specific cyber physical architectures are developed. These are the control and data systems that are needed to bridge the gap between the physical assets, the captured data and the control signals. Often, the cyber physical architecture and infrastructure is focused on functionality and the delivery of the specific applications. <br>But we find that technologies and approaches have arisen from other fields that, if used within SLES, could support the flexibility, scalability and reusability vital to their success. As these can improve the operational data systems then they can also be used to enhance predictive functions If used and deployed effectively, these new approaches can offer longer term improvements in the use and effectiveness of SLES, while allowing the concepts and designs to be capitalised upon through wider roll-out and the offering of commercial services or products.      
### 3.mmWave Spatial-Temporal Single Harmonic Switching Transmitter Arrays for High back-off Beamforming Efficiency  [ :arrow_down: ](https://arxiv.org/pdf/2106.16127.pdf)
>  This paper presents a spatial-temporal single harmonic switching (STHS) transmitter array architecture with enhanced efficiency in the power back-off (PBO) region. STHS is an electromagnetic and circuit co-designed and jointly optimized transmitter array that realizes beamforming and back-off power generation at the same time. The temporal dimension is originally added in STHS to achieve back-off efficiency enhancement, which can be combined with conventional power back-off enhancement methods such as Doherty amplifiers and envelope tracking. The design is validated through a simulation of a two-stage power amplifier in 65-nm CMOS at 77 GHz, which achieves a peak drain efficiency (DE) of 24.2%, a 22% DE at 3-dB PBO, 16% DE at 6-dB PBO, and 10.2% at 9-dB PBO. The efficiency exhibits a 57% improvement at 3-dB PBO, 100% improvement at 6-dB PBO, and 190% improvement at 9-dB PBO compared with class A/B amplifier.      
### 4.Global Optimality of Inverter Dynamic Voltage Support  [ :arrow_down: ](https://arxiv.org/pdf/2106.16096.pdf)
>  This paper investigates the dynamic voltage support (DVS) control of inverter-based resources (IBRs) under voltage sags to enhance the low-voltage ride-through performance. We first revisit the prevalent droop control from an optimization perspective to elaborate on why it usually suffers from suboptimality. Then, we formulate the DVS problem as an optimization program that maximizes the positive-sequence voltage magnitude at the point of common coupling (PCC) subject to the current, active power, and stability constraints. The program is inherently nonconvex due to the active power limits, of which the global optimality is not guaranteed by off-the-shelf solvers. In this context, we perform the optimality analysis to explore the global optimum analytically. It is found that the unique global optimum has three scenarios/stages (S1--S3), which depends on the specific relationship among grid voltage, grid strength, as well as physical limits of IBRs. The closed-form solutions in S1 and S3 are derived and the optimality conditions for S2 are provided, which guarantees the optimality and compatibility with the fast real-time control. We implement the optimum with a grid-connected photovoltaic (PV) power plant by integrating a DVS controller. Dynamic simulations are carried out under different scenarios to test our proposal and compare it with other existing methods. Additionally, the robustness of optimality against model errors is discussed and numerically demonstrated.      
### 5.Reservoir Based Edge Training on RF Data To Deliver Intelligent and Efficient IoT Spectrum Sensors  [ :arrow_down: ](https://arxiv.org/pdf/2106.16087.pdf)
>  Current radio frequency (RF) sensors at the Edge lack the computational resources to support practical, in-situ training for intelligent spectrum monitoring, and sensor data classification in general. We propose a solution via Deep Delay Loop Reservoir Computing (DLR), a processing architecture that supports general machine learning algorithms on compact mobile devices by leveraging delay-loop reservoir computing in combination with innovative electrooptical hardware. With both digital and photonic realizations of our design of the loops, DLR delivers reductions in form factor, hardware complexity and latency, compared to the State-of-the-Art (SoA). The main impact of the reservoir is to project the input data into a higher dimensional space of reservoir state vectors in order to linearly separate the input classes. Once the classes are well separated, traditionally complex, power-hungry classification models are no longer needed for the learning process. Yet, even with simple classifiers based on Ridge regression (RR), the complexity grows at least quadratically with the input size. Hence, the hardware reduction required for training on compact devices is in contradiction with the large dimension of state vectors. DLR employs a RR-based classifier to exceed the SoA accuracy, while further reducing power consumption by leveraging the architecture of parallel (split) loops. We present DLR architectures composed of multiple smaller loops whose state vectors are linearly combined to create a lower dimensional input into Ridge regression. We demonstrate the advantages of using DLR for two distinct applications: RF Specific Emitter Identification (SEI) for IoT authentication, and wireless protocol recognition for IoT situational awareness.      
### 6.HybridDeepRx: Deep Learning Receiver for High-EVM Signals  [ :arrow_down: ](https://arxiv.org/pdf/2106.16079.pdf)
>  In this paper, we propose a machine learning (ML) based physical layer receiver solution for demodulating OFDM signals that are subject to a high level of nonlinear distortion. Specifically, a novel deep learning based convolutional neural network receiver is devised, containing layers in both time- and frequency domains, allowing to demodulate and decode the transmitted bits reliably despite the high error vector magnitude (EVM) in the transmit signal. Extensive set of numerical results is provided, in the context of 5G NR uplink incorporating also measured terminal power amplifier characteristics. The obtained results show that the proposed receiver system is able to clearly outperform classical linear receivers as well as existing ML receiver approaches, especially when the EVM is high in comparison with modulation order. The proposed ML receiver can thus facilitate pushing the terminal power amplifier (PA) systems deeper into saturation, and thereon improve the terminal power-efficiency, radiated power and network coverage.      
### 7.Identification of Linear Systems with Multiplicative Noise from Multiple Trajectory Data  [ :arrow_down: ](https://arxiv.org/pdf/2106.16078.pdf)
>  We study identification of linear systems with multiplicative noise from multiple trajectory data. A least-squares algorithm, based on exploratory inputs, is proposed to simultaneously estimate the parameters of the nominal system and the covariance matrix of the multiplicative noise. The algorithm does not need prior knowledge of the noise or stability of the system, but requires mild conditions of inputs and relatively small length for each trajectory. Identifiability of the noise covariance matrix is studied, showing that there exists an equivalent class of matrices that generate the same second-moment dynamic of system states. It is demonstrated how to obtain the equivalent class based on estimates of the noise covariance. Asymptotic consistency of the algorithm is verified under sufficiently exciting inputs and system controllability conditions. Non-asymptotic estimation performance is also analyzed under the assumption that system states and noise are bounded, providing vanishing high-probability bounds as the number of trajectories grows to infinity. The results are illustrated by numerical simulations.      
### 8.Resilient UAV Swarm Communications with Graph Convolutional Neural Network  [ :arrow_down: ](https://arxiv.org/pdf/2106.16048.pdf)
>  In this paper, we study the self-healing problem of unmanned aerial vehicle (UAV) swarm network (USNET) that is required to quickly rebuild the communication connectivity under unpredictable external disruptions (UEDs). Firstly, to cope with the one-off UEDs, we propose a graph convolutional neural network (GCN) and find the recovery topology of the USNET in an on-line manner. Secondly, to cope with general UEDs, we develop a GCN based trajectory planning algorithm that can make UAVs rebuild the communication connectivity during the self-healing process. We also design a meta learning scheme to facilitate the on-line executions of the GCN. Numerical results show that the proposed algorithms can rebuild the communication connectivity of the USNET more quickly than the existing algorithms under both one-off UEDs and general UEDs. The simulation results also show that the meta learning scheme can not only enhance the performance of the GCN but also reduce the time complexity of the on-line executions.      
### 9.ResViT: Residual vision transformers for multi-modal medical image synthesis  [ :arrow_down: ](https://arxiv.org/pdf/2106.16031.pdf)
>  Multi-modal imaging is a key healthcare technology in the diagnosis and management of disease, but it is often underutilized due to costs associated with multiple separate scans. This limitation yields the need for synthesis of unacquired modalities from the subset of available modalities. In recent years, generative adversarial network (GAN) models with superior depiction of structural details have been established as state-of-the-art in numerous medical image synthesis tasks. However, GANs are characteristically based on convolutional neural network (CNN) backbones that perform local processing with compact filters. This inductive bias, in turn, compromises learning of long-range spatial dependencies. While attention maps incorporated in GANs can multiplicatively modulate CNN features to emphasize critical image regions, their capture of global context is mostly implicit. Here, we propose a novel generative adversarial approach for medical image synthesis, ResViT, to combine local precision of convolution operators with contextual sensitivity of vision transformers. Based on an encoder-decoder architecture, ResViT employs a central bottleneck comprising novel aggregated residual transformer (ART) blocks that synergistically combine convolutional and transformer modules. Comprehensive demonstrations are performed for synthesizing missing sequences in multi-contrast MRI and CT images from MRI. Our results indicate the superiority of ResViT against competing methods in terms of qualitative observations and quantitative metrics.      
### 10.Fast processing explains the effect of sound reflection on binaural unmasking  [ :arrow_down: ](https://arxiv.org/pdf/2106.16024.pdf)
>  Sound reflections and late reverberation alter energetic and binaural cues of a target source, thereby affecting it's detection in noise. Two experiments investigated detection of harmonic complex tones, centered around 500 Hz, in noise in a virtual room with different modifications of simulated room impulse responses (RIR). Stimuli were auralized using the SOFE's loudspeakers in anechoic space. The target was presented from the front or at 0$^\circ$ azimuth, while an anechoic noise masker was simultaneously presented at 0$^\circ$. In the first experiment, early reflections were progressively added to the RIR and detection thresholds of the reverberant target were measured. For a frontal sound source, detection thresholds decreased while adding the first 45 ms of early reflections, whereas for a lateral sound source thresholds remained constant. In the second experiment, early reflections were cut out while late reflections were kept along with the direct sound. Results for a target at 0$^\circ$ show that even reflections as late as 150 ms reduce detection thresholds compared to only the direct sound. A binaural model with a sluggishness component following the computation of binaural unmasking in short windows predicts measured and literature results better than when large windows are used.      
### 11.Learning without Data: Physics-Informed Neural Networks for Fast Time-Domain Simulation  [ :arrow_down: ](https://arxiv.org/pdf/2106.15987.pdf)
>  In order to drastically reduce the heavy computational burden associated with time-domain simulations, this paper introduces a Physics-Informed Neural Network (PINN) to directly learn the solutions of power system dynamics. In contrast to the limitations of classical model order reduction approaches, commonly used to accelerate time-domain simulations, PINNs can universally approximate any continuous function with an arbitrary degree of accuracy. One of the novelties of this paper is that we avoid the need for any training data. We achieve this by incorporating the governing differential equations and an implicit Runge-Kutta (RK) integration scheme directly into the training process of the PINN; through this approach, PINNs can predict the trajectory of a dynamical power system at any discrete time step. The resulting Runge-Kutta-based physics-informed neural networks (RK-PINNs) can yield up to 100 times faster evaluations of the dynamics compared to standard time-domain simulations. We demonstrate the methodology on a single-machine infinite bus system governed by the swing equation. We show that RK-PINNs can accurately and quickly predict the solution trajectories.      
### 12.AI-Based Secure NOMA and Cognitive Radio enabled Green Communications: Channel State Information and Battery Value Uncertainties  [ :arrow_down: ](https://arxiv.org/pdf/2106.15964.pdf)
>  In this paper, the security-aware robust resource allocation in energy harvesting cognitive radio networks is considered with cooperation between two transmitters while there are uncertainties in channel gains and battery energy value. To be specific, the primary access point harvests energy from the green resource and uses time switching protocol to send the energy and data towards the secondary access point (SAP). Using power-domain non-orthogonal multiple access technique, the SAP helps the primary network to improve the security of data transmission by using the frequency band of the primary network. In this regard, we introduce the problem of maximizing the proportional-fair energy efficiency (PFEE) considering uncertainty in the channel gains and battery energy value subject to the practical constraints. Moreover, the channel gain of the eavesdropper is assumed to be unknown. Employing the decentralized partially observable Markov decision process, we investigate the solution of the corresponding resource allocation problem. We exploit multi-agent with single reward deep deterministic policy gradient (MASRDDPG) and recurrent deterministic policy gradient (RDPG) methods. These methods are compared with the state-of-the-art ones like multi-agent and single-agent DDPG. Simulation results show that both MASRDDPG and RDPG methods, outperform the state-of-the-art methods by providing more PFEE to the network.      
### 13.BLNet: A Fast Deep Learning Framework for Low-Light Image Enhancement with Noise Removal and Color Restoration  [ :arrow_down: ](https://arxiv.org/pdf/2106.15953.pdf)
>  Images obtained in real-world low-light conditions are not only low in brightness, but they also suffer from many other types of degradation, such as color bias, unknown noise, detail loss and halo artifacts. In this paper, we propose a very fast deep learning framework called Bringing the Lightness (denoted as BLNet) that consists of two U-Nets with a series of well-designed loss functions to tackle all of the above degradations. Based on Retinex Theory, the decomposition net in our model can decompose low-light images into reflectance and illumination and remove noise in the reflectance during the decomposition phase. We propose a Noise and Color Bias Control module (NCBC Module) that contains a convolutional neural network and two loss functions (noise loss and color loss). This module is only used to calculate the loss functions during the training phase, so our method is very fast during the test phase. This module can smooth the reflectance to achieve the purpose of noise removal while preserving details and edge information and controlling color bias. We propose a network that can be trained to learn the mapping between low-light and normal-light illumination and enhance the brightness of images taken in low-light illumination. We train and evaluate the performance of our proposed model over the real-world Low-Light (LOL) dataset), and we also test our model over several other frequently used datasets (LIME, DICM and MEF datasets). We conduct extensive experiments to demonstrate that our approach achieves a promising effect with good rubustness and generalization and outperforms many other state-of-the-art methods qualitatively and quantitatively. Our method achieves high speed because we use loss functions instead of introducing additional denoisers for noise removal and color correction. The code and model are available at <a class="link-external link-https" href="https://github.com/weixinxu666/BLNet" rel="external noopener nofollow">this https URL</a>.      
### 14.An Integrated Framework for Two-pass Personalized Voice Trigger  [ :arrow_down: ](https://arxiv.org/pdf/2106.15950.pdf)
>  In this paper, we present the XMUSPEECH system for Task 1 of 2020 Personalized Voice Trigger Challenge (PVTC2020). Task 1 is a joint wake-up word detection with speaker verification on close talking data. The whole system consists of a keyword spotting (KWS) sub-system and a speaker verification (SV) sub-system. For the KWS system, we applied a Temporal Depthwise Separable Convolution Residual Network (TDSC-ResNet) to improve the system's performance. For the SV system, we proposed a multi-task learning network, where phonetic branch is trained with the character label of the utterance, and speaker branch is trained with the label of the speaker. Phonetic branch is optimized with connectionist temporal classification (CTC) loss, which is treated as an auxiliary module for speaker branch. Experiments show that our system gets significant improvements compared with baseline system.      
### 15.Learnable Reconstruction Methods from RGB Images to Hyperspectral Imaging: A Survey  [ :arrow_down: ](https://arxiv.org/pdf/2106.15944.pdf)
>  Hyperspectral imaging enables versatile applications due to its competence in capturing abundant spatial and spectral information, which are crucial for identifying substances. However, the devices for acquiring hyperspectral images are expensive and complicated. Therefore, many alternative spectral imaging methods have been proposed by directly reconstructing the hyperspectral information from lower-cost, more available RGB images. We present a thorough investigation of these state-of-the-art spectral reconstruction methods from the widespread RGB images. A systematic study and comparison of more than 25 methods has revealed that most of the data-driven deep learning methods are superior to prior-based methods in terms of reconstruction accuracy and quality despite lower speeds. This comprehensive review can serve as a fruitful reference source for peer researchers, thus further inspiring future development directions in related domains.      
### 16.Zames-Falb Multipliers: don't panic  [ :arrow_down: ](https://arxiv.org/pdf/2106.15913.pdf)
>  Zames-Falb multipliers are mathematical constructs which can be used to prove stability of so-called Lur'e systems: systems that consist of a feedback interconnection of a linear element and a static nonlinear element. The main advantage of Zames-Falb multipliers is that they enable "passivity"-like results to be obtained but with a level of conservatism much lower than \emph{pure} passivity results. However, some of the papers describing the development of the Zames-Falb multiplier machinery are somewhat abstruse and not entirely clear. This article attempts to provide a relatively simple construction of Zames and Falb's main results which will hopefully be understandable to most graduate-level control engineers.      
### 17.Graph Signal Restoration Using Nested Deep Algorithm Unrolling  [ :arrow_down: ](https://arxiv.org/pdf/2106.15910.pdf)
>  Graph signal processing is a ubiquitous task in many applications such as sensor, social, transportation and brain networks, point cloud processing, and graph neural networks. Graph signals are often corrupted through sensing processes, and need to be restored for the above applications. In this paper, we propose two graph signal restoration methods based on deep algorithm unrolling (DAU). First, we present a graph signal denoiser by unrolling iterations of the alternating direction method of multiplier (ADMM). We then propose a general restoration method for linear degradation by unrolling iterations of Plug-and-Play ADMM (PnP-ADMM). In the second method, the unrolled ADMM-based denoiser is incorporated as a submodule. Therefore, our restoration method has a nested DAU structure. Thanks to DAU, parameters in the proposed denoising/restoration methods are trainable in an end-to-end manner. Since the proposed restoration methods are based on iterations of a (convex) optimization algorithm, the method is interpretable and keeps the number of parameters small because we only need to tune graph-independent regularization parameters. We solve two main problems in existing graph signal restoration methods: 1) limited performance of convex optimization algorithms due to fixed parameters which are often determined manually. 2) large number of parameters of graph neural networks that result in difficulty of training. Several experiments for graph signal denoising and interpolation are performed on synthetic and real-world data. The proposed methods show performance improvements to several existing methods in terms of root mean squared error in both tasks.      
### 18.Effect of acoustic scene complexity and visual scene representation on auditory perception in virtual audio-visual environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.15909.pdf)
>  In daily life, social interaction and acoustic communication often take place in complex acoustic environments (CAE) with a variety of interfering sounds and reverberation. For hearing research and evaluation of hearing systems simulated CAEs using virtual reality techniques have gained interest in the context of ecologically validity. In the current study, the effect of scene complexity and visual representation of the scene on psychoacoustic measures like sound source location, distance perception, loudness, speech intelligibility, and listening effort in a virtual audio-visual environment was investigated. A 3-dimensional, 86-channel loudspeaker array was used to render the sound field in combination with or without a head-mounted display (HMD) to create an immersive stereoscopic visual representation of the scene. The scene consisted of a ring of eight (virtual) loudspeakers which played a target speech stimulus and non-sense speech interferers in several spatial conditions. Either an anechoic (snowy outdoor scenery) or echoic environment (loft apartment) with a reverberation time (T60) of about 1.5 s was simulated. In addition to varying the number of interferers, scene complexity was varied by assessing the psychoacoustic measures in isolated consecutive measurements or simultaneously. Results showed no significant effect of wearing the HMD on the data. Loudness and distance perception showed significantly different results when they were measured simultaneously instead of consecutively in isolation. The advantage of the suggested setup is that it can be directly transferred to a corresponding real room, enabling a 1:1 comparison and verification of the perception experiments in the real and virtual environment.      
### 19.Fast whole-slide cartography in colon cancer histology using superpixels and CNN classification  [ :arrow_down: ](https://arxiv.org/pdf/2106.15893.pdf)
>  Whole-slide-image cartography is the process of automatically detecting and outlining different tissue types in digitized histological specimen. This semantic segmentation provides a basis for many follow-up analyses and can potentially guide subsequent medical decisions. Due to their large size, whole-slide-images typically have to be divided into smaller patches which are then analyzed individually using machine learning-based approaches. Thereby, local dependencies of image regions get lost and since a whole-slide-image comprises many thousands of such patches this process is inherently slow. We propose to subdivide the image into coherent regions prior to classification by grouping visually similar adjacent image pixels into larger segments, i.e. superpixels. Afterwards, only a random subset of patches per superpixel is classified and patch labels are combined into a single superpixel label. The algorithm has been developed and validated on a dataset of 159 hand-annotated whole-slide-images of colon resections and its performance has been compared to a standard patch-based approach. The algorithm shows an average speed-up of 41% on the test data and the overall accuracy is increased from 93.8% to 95.7%. We additionally propose a metric for identifying superpixels with an uncertain classification so they can be excluded from further analysis. Finally, we evaluate two potential medical applications, namely tumor area estimation including tumor invasive margin generation and tumor composition analysis.      
### 20.Spatial resolution of late reverberation in virtual acoustic environments  [ :arrow_down: ](https://arxiv.org/pdf/2106.15888.pdf)
>  Late reverberation involves the superposition of many sound reflections resulting in a diffuse sound field. Since the spatially resolved perception of individual diffuse reflections is impossible, simplifications can potentially be made for modelling late reverberation in room acoustics simulations with reduced spatial resolution. Such simplifications are desired for interactive, real-time virtual acoustic environments with applications in hearing research and for the evaluation of hearing supportive devices. In this context, the number and spatial arrangement of loudspeakers used for playback additionally affect spatial resolution. The current study assessed the minimum number of spatially evenly distributed virtual late reverberation sources required to perceptually approximate spatially highly resolved isotropic and anisotropic late reverberation and to technically approximate a spherically isotropic diffuse sound field. The spatial resolution of the rendering was systematically reduced by using subsets of the loudspeakers of an 86-channel spherical loudspeaker array in an anechoic chamber. It was tested whether listeners can distinguish lower spatial resolutions for the rendering of late reverberation from the highest achievable spatial resolution in different simulated rooms. Rendering of early reflections was kept fixed. The coherence of the sound field across a pair of microphones at ear and behind-the-ear hearing device distance was assessed to separate the effects of number of virtual sources and loudspeaker array geometry. Results show that between 12 and 24 reverberation sources are required.      
### 21.A Weather-Dependent Hybrid RF/FSO Satellite Communication for Improved Power Efficiency  [ :arrow_down: ](https://arxiv.org/pdf/2106.15858.pdf)
>  Recent studies have shown that satellite communication (SatCom) will have a fundamental role in the next generation non-terrestrial networks (NTN). In SatCom, radio-frequency (RF) or free-space optical (FSO) communications can be used depending on the communication environment. Motivated by the complementary nature of RF and FSO communication, we propose a hybrid RF/FSO transmission strategy for SatCom, where the satellite selects RF or FSO link depending on the weather conditions obtained from the context-aware sensor. To quantify the performance of the proposed network, we derive the outage probability by considering different weather conditions. Furthermore, we investigate the impact of non-zero boresight pointing errors and illustrate the benefits of the aperture averaging to mitigate the effect of misalignment. Finally, we suggest effective design guidelines that can be useful for system designers. The results have shown that the proposed strategy performs better than the dual-mode conventional hybrid RF/FSO communication in terms of outage probability, offering almost 5 dB gain.      
### 22.Dual Aspect Self-Attention based on Transformer for Remaining Useful Life Prediction  [ :arrow_down: ](https://arxiv.org/pdf/2106.15842.pdf)
>  Remaining useful life prediction (RUL) is one of the key technologies of condition-based maintenance, which is important to maintain the reliability and safety of industrial equipments. While deep learning has achieved great success in RUL prediction, existing methods have difficulties in processing long sequences and extracting information from the sensor and time step aspects. In this paper, we propose Dual Aspect Self-attention based on Transformer (DAST), a novel deep RUL prediction method. DAST consists of two encoders, which work in parallel to simultaneously extract features of different sensors and time steps. Solely based on self-attention, the DAST encoders are more effective in processing long data sequences, and are capable of adaptively learning to focus on more important parts of input. Moreover, the parallel feature extraction design avoids mutual influence of information from two aspects. Experimental results on two real turbofan engine datasets show that our method significantly outperforms state-of-the-art methods.      
### 23.DF-Conformer: Integrated architecture of Conv-TasNet and Conformer using linear complexity self-attention for speech enhancement  [ :arrow_down: ](https://arxiv.org/pdf/2106.15813.pdf)
>  Single-channel speech enhancement (SE) is an important task in speech processing. A widely used framework combines an analysis/synthesis filterbank with a mask prediction network, such as the Conv-TasNet architecture. In such systems, the denoising performance and computational efficiency are mainly affected by the structure of the mask prediction network. In this study, we aim to improve the sequential modeling ability of Conv-TasNet architectures by integrating Conformer layers into a new mask prediction network. To make the model computationally feasible, we extend the Conformer using linear complexity attention and stacked 1-D dilated depthwise convolution layers. We trained the model on 3,396 hours of noisy speech data, and show that (i) the use of linear complexity attention avoids high computational complexity, and (ii) our model achieves higher scale-invariant signal-to-noise ratio than the improved time-dilated convolution network (TDCN++), an extended version of Conv-TasNet.      
### 24.Frequency-Constrained Resilient Scheduling of Microgrid: A Distributionally Robust Approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.15801.pdf)
>  In order to prevent the potential frequency instability due to the high Power Electronics (PE) penetration under an unintentional islanding event, this paper presents a novel microgrid scheduling model which explicitly models the system frequency dynamics as well as the long/short term uncertainty associated with renewable energy resources and load. Synthetic Inertia (SI) control is applied to regulating the active power output of the Inverter-Based Generators (IBGs) to support the post-islanding frequency evaluation. The uncertainty associated with the noncritical load shedding is explicitly modeled based on the distributionally robust formulation to ensure resilient operation during islanding events. The resulted frequency constraints are derived analytically and reformulated into Second-Order Cone (SOC) form, which are further incorporated into the microgrid scheduling model, enabling optimal SI provision of Renewable Energy Sources (RESs) from the micorgrid perspective. With the SOC relaxation of the AC power flow constraints, the overall problem is constructed as a mixed-integer SOC Programming (MISOCP). The effectiveness of the proposed model is demonstrated based on modified IEEE 14-bus system.      
### 25.Dynamic Imaging using Deep Bi-linear Unsupervised Regularization (DEBLUR)  [ :arrow_down: ](https://arxiv.org/pdf/2106.15785.pdf)
>  Bilinear models that decompose dynamic data to spatial and temporal factors are powerful and memory-efficient tools for the recovery of dynamic MRI data. These methods rely on sparsity and energy compaction priors on the factors to regularize the recovery. The quality of the recovered images depend on the specific priors. Motivated by deep image prior, we introduce a novel bilinear model whose factors are represented using convolutional neural networks (CNNs). The CNN parameters are learned from the undersampled data off the same subject. To reduce the run time and to improve performance, we initialize the CNN parameters. We use sparsity regularization of the network parameters to minimize the overfitting of the network to measurement noise. Our experiments on free breathing and ungated cardiac cine data acquired using a navigated golden-angle gradient-echo radial sequence show the ability of our method to provide reduced spatial blurring as compared to low-rank and SToRM reconstructions.      
### 26.10-mega pixel snapshot compressive imaging with a hybrid coded aperture  [ :arrow_down: ](https://arxiv.org/pdf/2106.15765.pdf)
>  High resolution images are widely used in our daily life, whereas high-speed video capture is challenging due to the low frame rate of cameras working at the high resolution mode. Digging deeper, the main bottleneck lies in the low throughput of existing imaging systems. Towards this end, snapshot compressive imaging (SCI) was proposed as a promising solution to improve the throughput of imaging systems by compressive sampling and computational reconstruction. During acquisition, multiple high-speed images are encoded and collapsed to a single measurement. After this, algorithms are employed to retrieve the video frames from the coded snapshot. Recently developed Plug-and-Play (PnP) algorithms make it possible for SCI reconstruction in large-scale problems. However, the lack of high-resolution encoding systems still precludes SCI's wide application. In this paper, we build a novel hybrid coded aperture snapshot compressive imaging (HCA-SCI) system by incorporating a dynamic liquid crystal on silicon and a high-resolution lithography mask. We further implement a PnP reconstruction algorithm with cascaded denoisers for high quality reconstruction. Based on the proposed HCA-SCI system and algorithm, we achieve a 10-mega pixel SCI system to capture high-speed scenes, leading to a high throughput of 4.6G voxels per second. Both simulation and real data experiments verify the feasibility and performance of our proposed HCA-SCI scheme.      
### 27.RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid Detection in Three-Dimensional Fluorescence Microscopy Images  [ :arrow_down: ](https://arxiv.org/pdf/2106.15753.pdf)
>  Robust and accurate nuclei centroid detection is important for the understanding of biological structures in fluorescence microscopy images. Existing automated nuclei localization methods face three main challenges: (1) Most of object detection methods work only on 2D images and are difficult to extend to 3D volumes; (2) Segmentation-based models can be used on 3D volumes but it is computational expensive for large microscopy volumes and they have difficulty distinguishing different instances of objects; (3) Hand annotated ground truth is limited for 3D microscopy volumes. To address these issues, we present a scalable approach for nuclei centroid detection of 3D microscopy volumes. We describe the RCNN-SliceNet to detect 2D nuclei centroids for each slice of the volume from different directions and 3D agglomerative hierarchical clustering (AHC) is used to estimate the 3D centroids of nuclei in a volume. The model was trained with the synthetic microscopy data generated using Spatially Constrained Cycle-Consistent Adversarial Networks (SpCycleGAN) and tested on different types of real 3D microscopy data. Extensive experimental results demonstrate that our proposed method can accurately count and detect the nuclei centroids in a 3D microscopy volume.      
### 28.Probabilistic Control of Heterogeneous Swarms Subject to Graph Temporal Logic Specifications: A Decentralized and Scalable Approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.15729.pdf)
>  We develop a probabilistic control algorithm, $\texttt{GTLProCo}$, for swarms of agents with heterogeneous dynamics and objectives, subject to high-level task specifications. The resulting algorithm not only achieves decentralized control of the swarm but also significantly improves scalability over state-of-the-art existing algorithms. Specifically, we study a setting in which the agents move along the nodes of a graph, and the high-level task specifications for the swarm are expressed in a recently-proposed language called graph temporal logic (GTL). By constraining the distribution of the swarm over the nodes of the graph, GTL can specify a wide range of properties, including safety, progress, and response. $\texttt{GTLProCo}$, agnostic to the number of agents comprising the swarm, controls the density distribution of the swarm in a decentralized and probabilistic manner. To this end, it synthesizes a time-varying Markov chain modeling the time evolution of the density distribution under the GTL constraints. We first identify a subset of GTL, namely reach-avoid specifications, for which we can reduce the synthesis of such a Markov chain to either linear or semi-definite programs. Then, in the general case, we formulate the synthesis of the Markov chain as a mixed-integer nonlinear program (MINLP). We exploit the structure of the problem to provide an efficient sequential mixed-integer linear programming scheme with trust regions to solve the MINLP. We empirically demonstrate that our sequential scheme is at least three orders of magnitude faster than off-the-shelf MINLP solvers and illustrate the effectiveness of $\texttt{GTLProCo}$ in several swarm scenarios.      
### 29.Recent Advances in Fibrosis and Scar Segmentation from Cardiac MRI: A State-of-the-Art Review and Future Perspectives  [ :arrow_down: ](https://arxiv.org/pdf/2106.15707.pdf)
>  Segmentation of cardiac fibrosis and scar are essential for clinical diagnosis and can provide invaluable guidance for the treatment of cardiac diseases. Late Gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) has been successful for its efficacy in guiding the clinical diagnosis and treatment reliably. For LGE CMR, many methods have demonstrated success in accurately segmenting scarring regions. Co-registration with other non-contrast-agent (non-CA) modalities, balanced steady-state free precession (bSSFP) and cine magnetic resonance imaging (MRI) for example, can further enhance the efficacy of automated segmentation of cardiac anatomies. Many conventional methods have been proposed to provide automated or semi-automated segmentation of scars. With the development of deep learning in recent years, we can also see more advanced methods that are more efficient in providing more accurate segmentations. This paper conducts a state-of-the-art review of conventional and current state-of-the-art approaches utilising different modalities for accurate cardiac fibrosis and scar segmentation.      
### 30.Bilateral Market for Distribution-level Coordination of Flexible Resources using Volttron  [ :arrow_down: ](https://arxiv.org/pdf/2106.15702.pdf)
>  Increasing penetrations of distributed energy resources (DERs) and responsive loads (RLs) in the electric power distribution systems calls for a mechanism for joint supply-demand coordination. Recently, several transactive/bilateral coordination mechanisms have been proposed for the distribution-level coordination of flexible resources. Implementing a transactive market coordination approach requires a secure, reliable, and computationally efficient multi-agent platform. An example of such a platform is VOLTTRON, developed by the Pacific Northwest National Laboratories (PNNL). The VOLTTRON platform allows the market actors to exchange information and execute proper control actions in a decentralized way. This paper aims to provide a proof-of-concept of the transactive market coordination approach via a small-scale demonstration on the VOLTTRON platform. The steps needed to implement the proposed market architecture using virtual machines and VOLTTRON are thoroughly described, and illustrative examples are provided to show the market-clearing process for different scenarios.      
### 31.A Semantic Model for Interacting Cyber-Physical Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15661.pdf)
>  We propose a component-based semantic model for Cyber-Physical Systems (CPSs) wherein the notion of a component abstracts the internal details of both cyber and physical processes, to expose a uniform semantic model of their externally observable behaviors expressed as sets of sequences of observations. We introduce algebraic operations on such sequences to model different kinds of component composition. These composition operators yield the externally observable behavior of their resulting composite components through specifications of interactions of the behaviors of their constituent components, as they, e.g., synchronize with or mutually exclude each other's alternative behaviors. Our framework is expressive enough to allow articulation of properties that coordinate desired interactions among composed components within the framework, also as component behavior. We demonstrate the usefulness of our formalism through examples of coordination properties in a CPS consisting of two robots interacting through shared physical resources.      
### 32.Towards a generalized monaural and binaural auditory model for psychoacoustics and speech intelligibility  [ :arrow_down: ](https://arxiv.org/pdf/2106.15659.pdf)
>  Auditory perception involves cues in the monaural auditory pathways as well as binaural cues based on differences between the ears. So far auditory models have often focused on either monaural or binaural experiments in isolation. Although binaural models typically build upon stages of (existing) monaural models, only a few attempts have been made to extend a monaural model by a binaural stage using a unified decision stage for monaural and binaural cues. In such approaches, a typical prototype of binaural processing has been the classical equalization-cancelation mechanism, which either involves signal-adaptive delays and provides a single channel output or can be implemented with tapped delays providing a high-dimensional multichannel output. This contribution extends the (monaural) generalized envelope power spectrum model by a non-adaptive binaural stage with only a few, fixed output channels. The binaural stage resembles features of physiologically motivated hemispheric binaural processing, as simplified signal processing stages, yielding a 5-channel monaural and binaural matrix feature "decoder" (BMFD). The back end of the existing monaural model is applied to the 5-channel BMFD output and calculates short-time envelope power and power features. The model is evaluated and discussed for a baseline database of monaural and binaural psychoacoustic experiments from the literature.      
### 33.Alternating Direction Method of Multiplier-Based Distributed Planning Model for Natural Gas, Electricity Network, and Regional Integrated Energy Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.15655.pdf)
>  Regional integrated energy system coupling with multienergy devices, energy storage devices, and renewable energy devices has been regarded as one of the most promising solutions for future energy systems. Planning for existing natural gas and electricity network expansion, regional integrated energy system locations, or system equipment types and capacities are urgent problems in infrastructure development. This article employs a joint planning model to address these; however, the joint planning model ignores the potential ownerships by three agents, for which investment decisions are generally made by different investors. In this work, the joint planning model is decomposed into three distributed planning subproblems related to the corresponding stakeholders, and the alternating direction method of multipliers is adopted to solve the tripartite distributed planning problem. The effectiveness of the planning model is verified on an updated version of the Institute of Electrical and Electronics Engineers (IEEE) 24-bus electric system, the Belgian 20-node natural gas system, and three assumed integrated energy systems. Simulation results illustrate that a distributed planning model is more sensitive to individual load differences, which is precisely the defect of the joint planning model. Moreover, the algorithm performance considering rates of convergence and the impacts of penalty parameters is further analyzed      
### 34.Multi-Scale Spectrogram Modelling for Neural Text-to-Speech  [ :arrow_down: ](https://arxiv.org/pdf/2106.15649.pdf)
>  We propose a novel Multi-Scale Spectrogram (MSS) modelling approach to synthesise speech with an improved coarse and fine-grained prosody. We present a generic multi-scale spectrogram prediction mechanism where the system first predicts coarser scale mel-spectrograms that capture the suprasegmental information in speech, and later uses these coarser scale mel-spectrograms to predict finer scale mel-spectrograms capturing fine-grained prosody. <br>We present details for two specific versions of MSS called Word-level MSS and Sentence-level MSS where the scales in our system are motivated by the linguistic units. The Word-level MSS models word, phoneme, and frame-level spectrograms while Sentence-level MSS models sentence-level spectrogram in addition. <br>Subjective evaluations show that Word-level MSS performs statistically significantly better compared to the baseline on two voices.      
### 35.Hierarchical Phenotyping and Graph Modeling of Spatial Architecture in Lymphoid Neoplasms  [ :arrow_down: ](https://arxiv.org/pdf/2106.16174.pdf)
>  The cells and their spatial patterns in the tumor microenvironment (TME) play a key role in tumor evolution, and yet remains an understudied topic in computational pathology. This study, to the best of our knowledge, is among the first to hybrid local and global graph methods to profile orchestration and interaction of cellular components. To address the challenge in hematolymphoid cancers where the cell classes in TME are unclear, we first implemented cell level unsupervised learning and identified two new cell subtypes. Local cell graphs or supercells were built for each image by considering the individual cell's geospatial location and classes. Then, we applied supercell level clustering and identified two new cell communities. In the end, we built global graphs to abstract spatial interaction patterns and extract features for disease diagnosis. We evaluate the proposed algorithm on H\&amp;E slides of 60 hematolymphoid neoplasm patients and further compared it with three cell level graph-based algorithms, including the global cell graph, cluster cell graph, and FLocK. The proposed algorithm achieves a mean diagnosis accuracy of 0.703 with the repeated 5-fold cross-validation scheme. In conclusion, our algorithm shows superior performance over the existing methods and can be potentially applied to other cancer types.      
### 36.Multi-Modal Chorus Recognition for Improving Song Search  [ :arrow_down: ](https://arxiv.org/pdf/2106.16153.pdf)
>  We discuss a novel task, Chorus Recognition, which could potentially benefit downstream tasks such as song search and music summarization. Different from the existing tasks such as music summarization or lyrics summarization relying on single-modal information, this paper models chorus recognition as a multi-modal one by utilizing both the lyrics and the tune information of songs. We propose a multi-modal Chorus Recognition model that considers diverse features. Besides, we also create and publish the first Chorus Recognition dataset containing 627 songs for public use. Our empirical study performed on the dataset demonstrates that our approach outperforms several baselines in chorus recognition. In addition, our approach also helps to improve the accuracy of its downstream task - song search by more than 10.6%.      
### 37.6G V2X Technologies and Orchestrated Sensing for Autonomous Driving  [ :arrow_down: ](https://arxiv.org/pdf/2106.16146.pdf)
>  6G technology targets to revolutionize the mobility industry by revamping the role of wireless connections. In this article, we draw out our vision on an intelligent, cooperative, and sustainable mobility environment of the future, discussing how 6G will positively impact mobility services and applications. The scenario in focus is a densely populated area by smart connected entities that are mutually connected over a 6G virtual bus, which enables access to an extensive and always up-to-date set of context-sensitive information. The augmented dataset is functional to let vehicles engage in adaptive and cooperative learning mechanisms, enabling fully automated functionalities with higher communication integrity and reduced risk of accidents while being a sentient and collaborative processing node of the same ecosystem. Smart sensing and communication technologies are discussed herein, and their convergence is devised by the pervasiveness of artificial intelligence in centralized or distributed and federated network architectures.      
### 38.Non-orthogonal HARQ for URLLC Design and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.16144.pdf)
>  The fifth-generation (5G) of mobile standards is expected to provide ultra-reliability and low-latency communications (URLLC) for various applications and services, such as online gaming, wireless industrial control, augmented reality, and self driving cars. Meeting the contradictory requirements of URLLC, i.e., ultra-reliability and low-latency, is considered to be very challenging, especially in bandwidth-limited scenarios. Most communication strategies rely on hybrid automatic repeat request (HARQ) to improve reliability at the expense of increased packet latency due to the retransmission of failing packets. To guarantee high-reliability and very low latency simultaneously, we enhance HARQ retransmission mechanism to achieve reliability with guaranteed packet level latency and in-time delivery. The proposed non-orthogonal HARQ (N-HARQ) utilizes non-orthogonal sharing of time slots for conducting retransmission. The reliability and delay analysis of the proposed N-HARQ in the finite block length (FBL) regime shows very high performance gain in packet delivery delay over conventional HARQ in both additive white Gaussian noise (AWGN) and Rayleigh fading channels. We also propose an optimization framework to further enhance the performance of N-HARQ for single and multiple retransmission cases.      
### 39.Machine Learning-enhanced Receive Processing for MU-MIMO OFDM Systems  [ :arrow_down: ](https://arxiv.org/pdf/2106.16074.pdf)
>  Machine learning (ML) can be used in various ways to improve multi-user multiple-input multiple-output (MU-MIMO) receive processing. Typical approaches either augment a single processing step, such as symbol detection, or replace multiple steps jointly by a single neural network (NN). These techniques demonstrate promising results but often assume perfect channel state information (CSI) or fail to satisfy the interpretability and scalability constraints imposed by practical systems. In this paper, we propose a new strategy which preserves the benefits of a conventional receiver, but enhances specific parts with ML components. The key idea is to exploit the orthogonal frequency-division multiplexing (OFDM) signal structure to improve both the demapping and the computation of the channel estimation error statistics. Evaluation results show that the proposed ML-enhanced receiver beats practical baselines on all considered scenarios, with significant gains at high speeds.      
### 40.IMS' Systems for the IWSLT 2021 Low-Resource Speech Translation Task  [ :arrow_down: ](https://arxiv.org/pdf/2106.16055.pdf)
>  This paper describes the submission to the IWSLT 2021 Low-Resource Speech Translation Shared Task by IMS team. We utilize state-of-the-art models combined with several data augmentation, multi-task and transfer learning approaches for the automatic speech recognition (ASR) and machine translation (MT) steps of our cascaded system. Moreover, we also explore the feasibility of a full end-to-end speech translation (ST) model in the case of very constrained amount of ground truth labeled data. Our best system achieves the best performance among all submitted systems for Congolese Swahili to English and French with BLEU scores 7.7 and 13.7 respectively, and the second best result for Coastal Swahili to English with BLEU score 14.9.      
### 41.An Experimental Analysis on Drone-Mounted Access Points for Improved Latency-Reliability  [ :arrow_down: ](https://arxiv.org/pdf/2106.16051.pdf)
>  The anticipated densification of contemporary communications infrastructure expects the use of drone small cells (DSCs). Thus, we experimentally evaluate the capability of providing local and personalized coverage with a drone mounted Wi-Fi access point that uses the nearby LTE infrastructure as a backhaul in areas with mixed line of sight(LoS) and Non-LoS (NLoS) links to the local cellular infrastructure. To assess the potential of DSCs for reliable and low latency communication of outdoor users, we measure the channel quality and the total round trip latency of the system. For a drone following the ground user, the DSC-provided network extends the coverage for an extra 6.4% when compared to the classical LTE-direct link. Moreover, the DSC setup provides latencies that are consistently smaller than 50 msfor 95% of the experiment. Within the coverage of the LTE-direct connection, we observed a latency ceiling of 120ms for 95% reliability of the LTE-direct connection. The highest latency observed for the DSC system was 1200ms, while the LTE-direct link never exceeded 500 ms. As such, DSC setups are not only essential in NLoS situations, but consistently improve the latency of users in outdoor scenarios.      
### 42.End-to-End Learning of OFDM Waveforms with PAPR and ACLR Constraints  [ :arrow_down: ](https://arxiv.org/pdf/2106.16039.pdf)
>  Orthogonal frequency-division multiplexing (OFDM) is widely used in modern wireless networks thanks to its efficient handling of multipath environment. However, it suffers from a poor peak-to-average power ratio (PAPR) which requires a large power backoff, degrading the power amplifier (PA) efficiency. In this work, we propose to use a neural network (NN) at the transmitter to learn a high-dimensional modulation scheme allowing to control the PAPR and adjacent channel leakage ratio (ACLR). On the receiver side, a NN-based receiver is implemented to carry out demapping of the transmitted bits. The two NNs operate on top of OFDM, and are jointly optimized in and end-to-end manner using a training algorithm that enforces constraints on the PAPR and ACLR. Simulation results show that the learned waveforms enable higher information rates than a tone reservation baseline, while satisfying predefined PAPR and ACLR targets.      
### 43.A Generative Model for Raw Audio Using Transformer Architectures  [ :arrow_down: ](https://arxiv.org/pdf/2106.16036.pdf)
>  This paper proposes a novel way of doing audio synthesis at the waveform level using Transformer architectures. We propose a deep neural network for generating waveforms, similar to wavenet \cite{oord2016wavenet}. This is fully probabilistic, auto-regressive, and causal, i.e. each sample generated depends only on the previously observed samples. Our approach outperforms a widely used wavenet architecture by up to 9\% on a similar dataset for predicting the next step. Using the attention mechanism, we enable the architecture to learn which audio samples are important for the prediction of the future sample. We show how causal transformer generative models can be used for raw waveform synthesis. We also show that this performance can be improved by another 2\% by conditioning samples over a wider context. The flexibility of the current model to synthesize audio from latent representations suggests a large number of potential applications. The novel approach of using generative transformer architectures for raw audio synthesis is, however, still far away from generating any meaningful music, without using latent codes/meta-data to aid the generation process.      
### 44.Single-Step Adversarial Training for Semantic Segmentation  [ :arrow_down: ](https://arxiv.org/pdf/2106.15998.pdf)
>  Even though deep neural networks succeed on many different tasks including semantic segmentation, they lack on robustness against adversarial examples. To counteract this exploit, often adversarial training is used. However, it is known that adversarial training with weak adversarial attacks (e.g. using the Fast Gradient Method) does not improve the robustness against stronger attacks. Recent research shows that it is possible to increase the robustness of such single-step methods by choosing an appropriate step size during the training. Finding such a step size, without increasing the computational effort of single-step adversarial training, is still an open challenge. In this work we address the computationally particularly demanding task of semantic segmentation and propose a new step size control algorithm that increases the robustness of single-step adversarial training. The proposed algorithm does not increase the computational effort of single-step adversarial training considerably and also simplifies training, because it is free of meta-parameter. We show that the robustness of our approach can compete with multi-step adversarial training on two popular benchmarks for semantic segmentation.      
### 45.End-to-End Spoken Language Understanding using RNN-Transducer ASR  [ :arrow_down: ](https://arxiv.org/pdf/2106.15919.pdf)
>  We propose an end-to-end trained spoken language understanding (SLU) system that extracts transcripts, intents and slots from an input speech utterance. It consists of a streaming recurrent neural network transducer (RNNT) based automatic speech recognition (ASR) model connected to a neural natural language understanding (NLU) model through a neural interface. This interface allows for end-to-end training using multi-task RNNT and NLU losses. Additionally, we introduce semantic sequence loss training for the joint RNNT-NLU system that allows direct optimization of non-differentiable SLU metrics. This end-to-end SLU model paradigm can leverage state-of-the-art advancements and pretrained models in both ASR and NLU research communities, outperforming recently proposed direct speech-to-semantics models, and conventional pipelined ASR and NLU systems. We show that this method improves both ASR and NLU metrics on both public SLU datasets and large proprietary datasets.      
### 46.Communication conditions in virtual acoustic scenes in an underground station  [ :arrow_down: ](https://arxiv.org/pdf/2106.15916.pdf)
>  Underground stations are a common communication situation in towns: we talk with friends or colleagues, listen to announcements or shop for titbits while background noise and reverberation are challenging communication. Here, we perform an acoustical analysis of two communication scenes in an underground station in Munich and test speech intelligibility. The acoustical conditions were measured in the station and are compared to simulations in the real-time Simulated Open Field Environment (rtSOFE). We compare binaural room impulse responses measured with an artificial head in the station to modeled impulse responses for free-field auralization via 60 loudspeakers in the rtSOFE. We used the image source method to model early reflections and a set of multi-microphone recordings to model late reverberation. The first communication scene consists of 12 equidistant (1.6 m) horizontally spaced source positions around a listener, simulating different direction-dependent spatial unmasking conditions. The second scene mimics an approaching speaker across six radially spaced source positions (from 1 m to 10 m) with varying direct sound level and thus direct-to-reverberant energy. The acoustic parameters of the underground station show a moderate amount of reverberation (T30 in octave bands was between 2.3 s and 0.6 s and early-decay times between 1.46 s and 0.46 s). The binaural and energetic parameters of the auralization were in a close match to the measurement. Measured speech reception thresholds were within the error of the speech test, letting us to conclude that the auralized simulation reproduces acoustic and perceptually relevant parameters for speech intelligibility with high accuracy.      
### 47.Towards establishing formal verification and inductive code synthesis in the PLC domain  [ :arrow_down: ](https://arxiv.org/pdf/2106.15878.pdf)
>  Nowadays, formal methods are used in various areas for the verification of programs or for code generation from models in order to increase the quality of software and to reduce costs. However, there are still fields in which formal methods have not been widely adopted, despite the large set of possible benefits offered. This is the case for the area of programmable logic controllers (PLC). This article aims to evaluate the potential of formal methods in the context of PLC development. For this purpose, the general concepts of formal methods are first introduced and then transferred to the PLC area, resulting in an engineering-oriented description of the technology that is based on common concepts from PLC development. Based on this description, PLC professionals with varying degrees of experience were interviewed for their perspective on the topic and to identify possible use cases within the PLC domain. The survey results indicate the technology's high potential in the PLC area, either as a tool to directly support the developer or as a key element within a model-based systems engineering toolchain. The evaluation of the survey results is performed with the aid of a demo application that communicates with the Totally Integrated Automation Portal from Siemens and generates programs via Fastsynth, a model-based open source code generator. Benchmarks based on an industry-related PLC project show satisfactory synthesis times and a successful integration into the workflow of a PLC developer.      
### 48.Robust and Interpretable Temporal Convolution Network for Event Detection in Lung Sound Recordings  [ :arrow_down: ](https://arxiv.org/pdf/2106.15835.pdf)
>  This paper proposes a novel framework for lung sound event detection, segmenting continuous lung sound recordings into discrete events and performing recognition on each event. Exploiting the lightweight nature of Temporal Convolution Networks (TCNs) and their superior results compared to their recurrent counterparts, we propose a lightweight, yet robust, and completely interpretable framework for lung sound event detection. We propose the use of a multi-branch TCN architecture and exploit a novel fusion strategy to combine the resultant features from these branches. This not only allows the network to retain the most salient information across different temporal granularities and disregards irrelevant information, but also allows our network to process recordings of arbitrary length. Results: The proposed method is evaluated on multiple public and in-house benchmarks of irregular and noisy recordings of the respiratory auscultation process for the identification of numerous auscultation events including inhalation, exhalation, crackles, wheeze, stridor, and rhonchi. We exceed the state-of-the-art results in all evaluations. Furthermore, we empirically analyse the effect of the proposed multi-branch TCN architecture and the feature fusion strategy and provide quantitative and qualitative evaluations to illustrate their efficiency. Moreover, we provide an end-to-end model interpretation pipeline that interprets the operations of all the components of the proposed framework. Our analysis of different feature fusion strategies shows that the proposed feature concatenation method leads to better suppression of non-informative features, which drastically reduces the classifier overhead resulting in a robust lightweight network.The lightweight nature of our model allows it to be deployed in end-user devices such as smartphones, and it has the ability to generate predictions in real-time.      
### 49.Koopman Spectrum Nonlinear Regulator and Provably Efficient Online Learning  [ :arrow_down: ](https://arxiv.org/pdf/2106.15775.pdf)
>  Most modern reinforcement learning algorithms optimize a cumulative single-step cost along a trajectory. The optimized motions are often 'unnatural', representing, for example, behaviors with sudden accelerations that waste energy and lack predictability. In this work, we present a novel paradigm of controlling nonlinear systems via the minimization of the Koopman spectrum cost: a cost over the Koopman operator of the controlled dynamics. This induces a broader class of dynamical behaviors that evolve over stable manifolds such as nonlinear oscillators, closed loops, and smooth movements. We demonstrate that some dynamics realizations that are not possible with a cumulative cost are feasible in this paradigm. Moreover, we present a provably efficient online learning algorithm for our problem that enjoys a sub-linear regret bound under some structural assumptions.      
### 50.Online Offloading Scheduling for NOMA-Aided MEC Under Partial Device Knowledge  [ :arrow_down: ](https://arxiv.org/pdf/2106.15773.pdf)
>  By exploiting the superiority of non-orthogonal multiple access (NOMA), NOMA-aided mobile edge computing (MEC) can provide scalable and low-latency computing services for the Internet of Things. However, given the prevalent stochasticity of wireless networks and sophisticated signal processing of NOMA, it is critical but challenging to design an efficient task offloading algorithm for NOMA-aided MEC, especially under a large number of devices. This paper presents an online algorithm that jointly optimizes offloading decisions and resource allocation to maximize the long-term system utility (i.e., a measure of throughput and fairness). Since the optimization variables are temporary coupled, we first apply Lyapunov technique to decouple the long-term stochastic optimization into a series of per-slot deterministic subproblems, which does not require any prior knowledge of network dynamics. Second, we propose to transform the non-convex per-slot subproblem of optimizing NOMA power allocation equivalently to a convex form by introducing a set of auxiliary variables, whereby the time-complexity is reduced from the exponential complexity to $\mathcal{O} (M^{3/2})$. The proposed algorithm is proved to be asymptotically optimal, even under partial knowledge of the device states at the base station. Simulation results validate the superiority of the proposed algorithm in terms of system utility, stability improvement, and the overhead reduction.      
### 51.UAV-assisted Online Machine Learning over Multi-Tiered Networks: A Hierarchical Nested Personalized Federated Learning Approach  [ :arrow_down: ](https://arxiv.org/pdf/2106.15734.pdf)
>  We consider distributed machine learning (ML) through unmanned aerial vehicles (UAVs) for geo-distributed device clusters. We propose five new technologies/techniques: (i) stratified UAV swarms with leader, worker, and coordinator UAVs, (ii) hierarchical nested personalized federated learning (HN-PFL): a holistic distributed ML framework for personalized model training across the worker-leader-core network hierarchy, (iii) cooperative UAV resource pooling for distributed ML using the UAVs' local computational capabilities, (iv) aerial data caching and relaying for efficient data relaying to conduct ML, and (v) concept/model drift, capturing online data variations at the devices. We split the UAV-enabled model training problem as two parts. (a) Network-aware HN-PFL, where we optimize a tradeoff between energy consumption and ML model performance by configuring data offloading among devices-UAVs and UAV-UAVs, UAVs' CPU frequencies, and mini-batch sizes subject to communication/computation network heterogeneity. We tackle this optimization problem via the method of posynomial condensation and propose a distributed algorithm with a performance guarantee. (b) Macro-trajectory and learning duration design, which we formulate as a sequential decision making problem, tackled via deep reinforcement learning. Our simulations demonstrate the superiority of our methodology with regards to the distributed ML performance, the optimization of network resources, and the swarm trajectory efficiency.      
### 52.Alzheimer's Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs  [ :arrow_down: ](https://arxiv.org/pdf/2106.15684.pdf)
>  We present two multimodal fusion-based deep learning models that consume ASR transcribed speech and acoustic data simultaneously to classify whether a speaker in a structured diagnostic task has Alzheimer's Disease and to what degree, evaluating the ADReSSo challenge 2021 data. Our best model, a BiLSTM with highway layers using words, word probabilities, disfluency features, pause information, and a variety of acoustic features, achieves an accuracy of 84% and RSME error prediction of 4.26 on MMSE cognitive scores. While predicting cognitive decline is more challenging, our models show improvement using the multimodal approach and word probabilities, disfluency and pause information over word-only models. We show considerable gains for AD classification using multimodal fusion and gating, which can effectively deal with noisy inputs from acoustic features and ASR hypotheses.      
### 53.Data-Driven Operator Theoretic Methods for Phase Space Learning and Analysis  [ :arrow_down: ](https://arxiv.org/pdf/2106.15678.pdf)
>  This paper uses data-driven operator theoretic approaches to explore the global phase space of a dynamical system. We defined conditions for discovering new invariant subspaces in the state space of a dynamical system starting from an invariant subspace based on the spectral properties of the Koopman operator. When the system evolution is known locally in several invariant subspaces in the state space of a dynamical system, a phase space stitching result is derived that yields the global Koopman operator. Additionally, in the case of equivariant systems, a phase space stitching result is developed to identify the global Koopman operator using the symmetry properties between the invariant subspaces of the dynamical system and time-series data from any one of the invariant subspaces. Finally, these results are extended to topologically conjugate dynamical systems; in particular, the relation between the Koopman tuple of topologically conjugate systems is established. The proposed results are demonstrated on several second-order nonlinear dynamical systems including a bistable toggle switch. Our method elucidates a strategy for designing discovery experiments: experiment execution can be done in many steps, and models from different invariant subspaces can be combined to approximate the global Koopman operator.      
